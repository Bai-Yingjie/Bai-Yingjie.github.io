
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>优化linux网络栈: 接收路径(网摘) · My Notes</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Bai Yingjie">
        
        
    
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-plus/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-prism/prism.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-wide-page/wide.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-hide-navigation-buttons/index.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-theme-comscore/test.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    


    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="networking_优化linux网络栈_发送路径.html" />
    
    
    <link rel="prev" href="networking_杂记1.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    简介
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="recent_topics.html">
            
                <a href="recent_topics.html">
            
                    
                    recent topics
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="as_title_kaiyuan.html">
            
                <a href="as_title_kaiyuan.html">
            
                    
                    开源
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="my_opensource.html">
            
                <a href="my_opensource.html">
            
                    
                    我的开源项目
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="my_upstream.html">
            
                <a href="my_upstream.html">
            
                    
                    我的upstream commit
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="as_title_system.html">
            
                <a href="as_title_system.html">
            
                    
                    系统分析和性能
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="as_title_perf_misc.html">
            
                <a href="as_title_perf_misc.html">
            
                    
                    调试和分析记录系列
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1.1" data-path="profiling_调试和分析记录5.html">
            
                <a href="profiling_调试和分析记录5.html">
            
                    
                    调试和分析记录5
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.2" data-path="profiling_调试和分析记录4.html">
            
                <a href="profiling_调试和分析记录4.html">
            
                    
                    调试和分析记录4
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.3" data-path="profiling_调试和分析记录3.html">
            
                <a href="profiling_调试和分析记录3.html">
            
                    
                    调试和分析记录3
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.4" data-path="profiling_调试和分析记录2.html">
            
                <a href="profiling_调试和分析记录2.html">
            
                    
                    调试和分析记录2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.5" data-path="profiling_调试和分析记录1.html">
            
                <a href="profiling_调试和分析记录1.html">
            
                    
                    调试和分析记录1
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="调试和分析工具概览.html">
            
                <a href="调试和分析工具概览.html">
            
                    
                    profiling和debugging工具相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" data-path="profiling_Linux内核调试的方式以及工具集锦.html">
            
                <a href="profiling_Linux内核调试的方式以及工具集锦.html">
            
                    
                    Linux内核调试的方式以及工具集锦(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" data-path="profiling_user_space_Ptrace_Utrace_Uprobes.html">
            
                <a href="profiling_user_space_Ptrace_Utrace_Uprobes.html">
            
                    
                    Ptrace, Utrace, Uprobes: Lightweight, Dynamic Tracing of User Apps
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.3" data-path="debugging_gdb备忘录.html">
            
                <a href="debugging_gdb备忘录.html">
            
                    
                    gdb备忘录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.4" data-path="profiling_perf命令备忘录.html">
            
                <a href="profiling_perf命令备忘录.html">
            
                    
                    perf命令备忘录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.5" data-path="profiling_perf命令备忘录2.html">
            
                <a href="profiling_perf命令备忘录2.html">
            
                    
                    perf命令备忘录2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.6" data-path="profiling_perf学习笔记之实战篇.html">
            
                <a href="profiling_perf学习笔记之实战篇.html">
            
                    
                    perf学习笔记之实战篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.7" data-path="profiling_perf学习笔记之入门篇.html">
            
                <a href="profiling_perf学习笔记之入门篇.html">
            
                    
                    perf学习笔记之入门篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.8" data-path="profiling_用kprobe和perf_记录函数参数.html">
            
                <a href="profiling_用kprobe和perf_记录函数参数.html">
            
                    
                    使用kprobe和perf结合记录函数参数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.9" data-path="profiling_ftrace和trace-cmd记录.html">
            
                <a href="profiling_ftrace和trace-cmd记录.html">
            
                    
                    ftrace和trace-cmd记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.10" data-path="profiling_ftrace使用实例.html">
            
                <a href="profiling_ftrace使用实例.html">
            
                    
                    ftrace使用实例
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.11" data-path="profiling_systemtap实例.html">
            
                <a href="profiling_systemtap实例.html">
            
                    
                    systemtap实例
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.12" data-path="profiling_systemtap基础.html">
            
                <a href="profiling_systemtap基础.html">
            
                    
                    systemtap基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.13" data-path="profiling_perf-tools_example.html">
            
                <a href="profiling_perf-tools_example.html">
            
                    
                    perf-tools 系统tracing工具集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.14" data-path="profiling_Comparing_SystemTap_and_bpftrace.html">
            
                <a href="profiling_Comparing_SystemTap_and_bpftrace.html">
            
                    
                    Comparing SystemTap and bpftrace(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.15" data-path="system_analysis_bcc和ebpf.html">
            
                <a href="system_analysis_bcc和ebpf.html">
            
                    
                    bcc和ebpf(starting)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.16" data-path="profiling_valgrind体验.html">
            
                <a href="profiling_valgrind体验.html">
            
                    
                    体验valgrind
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="as_title_os_perf.html">
            
                <a href="as_title_os_perf.html">
            
                    
                    profiling和debugging实例
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.3.1" data-path="debugging_gshellos_socket_leak.html">
            
                <a href="debugging_gshellos_socket_leak.html">
            
                    
                    gshell socket leak调查
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.2" data-path="profiling_调查ftrace显示调用栈全0问题.html">
            
                <a href="profiling_调查ftrace显示调用栈全0问题.html">
            
                    
                    调查ftrace显示调用栈全0问题
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.3" data-path="profiling_eoe_filter写tap设备失败问题.html">
            
                <a href="profiling_eoe_filter写tap设备失败问题.html">
            
                    
                    eoe_filter写tap设备失败问题
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.4" data-path="performance_ovs进程调查.html">
            
                <a href="performance_ovs进程调查.html">
            
                    
                    OVS进程调查
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.5" data-path="performance_ping流程和函数调用解析.html">
            
                <a href="performance_ping流程和函数调用解析.html">
            
                    
                    ping流程和函数调用解析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.6" data-path="profiling_VM互相ping场景下的延迟分析.html">
            
                <a href="profiling_VM互相ping场景下的延迟分析.html">
            
                    
                    VM互相ping场景下的延迟分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.7" data-path="debugging_ftrace_谁创建了bond0设备.html">
            
                <a href="debugging_ftrace_谁创建了bond0设备.html">
            
                    
                    谁创建了bond0设备: ftrace kprobe uprobe perf综合使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.8" data-path="profiling_unixbench之filecopy分析.html">
            
                <a href="profiling_unixbench之filecopy分析.html">
            
                    
                    unixbench之file copy分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.9" data-path="profiling_lmbench之lat_tcp分析.html">
            
                <a href="profiling_lmbench之lat_tcp分析.html">
            
                    
                    lmbench之lat_tcp分析
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="as_title_arch_perf.html">
            
                <a href="as_title_arch_perf.html">
            
                    
                    CPU ARCH相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.4.1" data-path="performance_CPU_microarchiteture_pmu.html">
            
                <a href="performance_CPU_microarchiteture_pmu.html">
            
                    
                    Top-down Microarchitecture Analysis Method(网摘)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="as_title_cloud.html">
            
                <a href="as_title_cloud.html">
            
                    
                    Cloud和容器相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="container_linux_namespaces.html">
            
                <a href="container_linux_namespaces.html">
            
                    
                    linux名字空间
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="cloud_杂记.html">
            
                <a href="cloud_杂记.html">
            
                    
                    云杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="container_当代容器读书笔记.html">
            
                <a href="container_当代容器读书笔记.html">
            
                    
                    当代容器读书笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="multi-arch_docker_binfmt_misc.html">
            
                <a href="multi-arch_docker_binfmt_misc.html">
            
                    
                    multi-arch docker 和 binfmt_misc
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="as_title_vdevice.html">
            
                <a href="as_title_vdevice.html">
            
                    
                    CPU和device虚拟化
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="as_title_gvisor.html">
            
                <a href="as_title_gvisor.html">
            
                    
                    gvisor
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1.1" data-path="golang_gvisor代码_KVM.html">
            
                <a href="golang_gvisor代码_KVM.html">
            
                    
                    gvisor KVM模式代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.2" data-path="golang_gvisor调试.html">
            
                <a href="golang_gvisor调试.html">
            
                    
                    gvisor调试
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.3" data-path="golang_gvisor_ptrace.html">
            
                <a href="golang_gvisor_ptrace.html">
            
                    
                    gvisor ptrace模式介绍(网摘)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="rust_vmm_brief.html">
            
                <a href="rust_vmm_brief.html">
            
                    
                    rust VMM(virtual machine monitor)
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="rust_vmm_简介.html">
            
                <a href="rust_vmm_简介.html">
            
                    
                    rust-vmm简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2" data-path="rust_firecracker_代码.html">
            
                <a href="rust_firecracker_代码.html">
            
                    
                    firecracker代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.3" data-path="rust_firecracker_使用.html">
            
                <a href="rust_firecracker_使用.html">
            
                    
                    firecracker使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.4" data-path="rust_cloud-hypervisor_代码.html">
            
                <a href="rust_cloud-hypervisor_代码.html">
            
                    
                    cloud hypervisor代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.5" data-path="rust_cloud-hypervisor_使用.html">
            
                <a href="rust_cloud-hypervisor_使用.html">
            
                    
                    cloud hypervisor使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.6" data-path="rust_cloud-hypervisor_问题与解决.html">
            
                <a href="rust_cloud-hypervisor_问题与解决.html">
            
                    
                    cloud hypervisor问题与解决
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.7" data-path="rust_virtiofsd_代码.html">
            
                <a href="rust_virtiofsd_代码.html">
            
                    
                    virtiofsd代码阅读
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.8" data-path="rust_virtio_vhost_libs.html">
            
                <a href="rust_virtio_vhost_libs.html">
            
                    
                    vhost virtio相关的rust库
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="virtualization_virtio规范阅读笔记.html">
            
                <a href="virtualization_virtio规范阅读笔记.html">
            
                    
                    virtio规范阅读笔记.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="qemu_ovs_虚拟化环境.html">
            
                <a href="qemu_ovs_虚拟化环境.html">
            
                    
                    qemu OVS 虚拟化环境准备
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="qemu使用.html">
            
                <a href="qemu使用.html">
            
                    
                    Qemu使用(old)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.6" data-path="qemu_binary_translation.html">
            
                <a href="qemu_binary_translation.html">
            
                    
                    QEMU 指令翻译
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="as_title_networking.html">
            
                <a href="as_title_networking.html">
            
                    
                    计算机网络相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="networking_杂记2.html">
            
                <a href="networking_杂记2.html">
            
                    
                    networking杂记2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="networking_杂记1.html">
            
                <a href="networking_杂记1.html">
            
                    
                    networking杂记1
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.6.3" data-path="networking_优化linux网络栈_接收路径.html">
            
                <a href="networking_优化linux网络栈_接收路径.html">
            
                    
                    优化linux网络栈: 接收路径(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="networking_优化linux网络栈_发送路径.html">
            
                <a href="networking_优化linux网络栈_发送路径.html">
            
                    
                    优化linux网络栈: 发送路径(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.5" data-path="networking_Potential_Performance_Bottleneck_in_Linux_TCP.html">
            
                <a href="networking_Potential_Performance_Bottleneck_in_Linux_TCP.html">
            
                    
                    Potential Performance Bottleneck in Linux TCP(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6" data-path="networking_xdp入门.html">
            
                <a href="networking_xdp入门.html">
            
                    
                    Get started with XDP(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.7" data-path="networking_linux收包路径图解.html">
            
                <a href="networking_linux收包路径图解.html">
            
                    
                    linux收包路径图解(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.8" data-path="vpp_compiling_on_alpine.md">
            
                <span>
            
                    
                    alpine编译vpp
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9" data-path="as_title_qemu_ovs.html">
            
                <a href="as_title_qemu_ovs.html">
            
                    
                    Qemu OVS和DPDK
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.9.1" data-path="OVS_DPDK_编译运行.html">
            
                <a href="OVS_DPDK_编译运行.html">
            
                    
                    OVS-DPDK编译运行
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9.2" data-path="OVS_架构和代码.html">
            
                <a href="OVS_架构和代码.html">
            
                    
                    OVS架构和代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9.3" data-path="OVS_DPDK_performance_HXT_ARM_server.html">
            
                <a href="OVS_DPDK_performance_HXT_ARM_server.html">
            
                    
                    OVS-DPDK for ARM server 性能测试环境
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9.4" data-path="DPDK_Mellanox.html">
            
                <a href="DPDK_Mellanox.html">
            
                    
                    DPDK Mellanox
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9.5" data-path="OVS_phy-vm-phy.html">
            
                <a href="OVS_phy-vm-phy.html">
            
                    
                    OVS PHY-VM-PHY
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9.6" data-path="networking_网络虚拟化用例记录.html">
            
                <a href="networking_网络虚拟化用例记录.html">
            
                    
                    网络虚拟化用例记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9.7" data-path="networking_网络虚拟化操作记录.html">
            
                <a href="networking_网络虚拟化操作记录.html">
            
                    
                    网络虚拟化操作记录
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.10" data-path="as_title_virtnet.html">
            
                <a href="as_title_virtnet.html">
            
                    
                    虚拟化网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.10.1" data-path="networking_tc_filter_连接veth和tap.html">
            
                <a href="networking_tc_filter_连接veth和tap.html">
            
                    
                    Connecting a veth device to tap
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10.2" data-path="networking_multicast_vxlan_flannel.html">
            
                <a href="networking_multicast_vxlan_flannel.html">
            
                    
                    multicast vxlan和flannel
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10.3" data-path="networking_virtio网络介绍.html">
            
                <a href="networking_virtio网络介绍.html">
            
                    
                    virtio网络介绍(网摘): vhost-net virtio-net vhost-user SRIOV
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10.4" data-path="networking_virtualization_杂记.html">
            
                <a href="networking_virtualization_杂记.html">
            
                    
                    虚拟化网络杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10.5" data-path="networking_linux虚拟网络接口.html">
            
                <a href="networking_linux虚拟网络接口.html">
            
                    
                    linux虚拟网络接口(网摘)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="as_title_arm_server.html">
            
                <a href="as_title_arm_server.html">
            
                    
                    ARM server
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="arm_server_杂记.html">
            
                <a href="arm_server_杂记.html">
            
                    
                    Arm server 杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="server_知识点.html">
            
                <a href="server_知识点.html">
            
                    
                    server知识点
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="as_title_embedded.html">
            
                <a href="as_title_embedded.html">
            
                    
                    嵌入式系统开发调试
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="embedded_debugging.html">
            
                <a href="embedded_debugging.html">
            
                    
                    嵌入式调试杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="uboot_杂记.html">
            
                <a href="uboot_杂记.html">
            
                    
                    uboot杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="buildroot_杂记.html">
            
                <a href="buildroot_杂记.html">
            
                    
                    buildroot杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.4" data-path="toolchain_升级gcc问题解决.html">
            
                <a href="toolchain_升级gcc问题解决.html">
            
                    
                    升级GCC7.3问题解决
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5" data-path="kernel_异常打印分析实例.html">
            
                <a href="kernel_异常打印分析实例.html">
            
                    
                    kernel bug异常打印分析
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="as_title_linuxdaily.html">
            
                <a href="as_title_linuxdaily.html">
            
                    
                    Linux工程实践
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="linux_日常使用.html">
            
                <a href="linux_日常使用.html">
            
                    
                    日常linux使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="git_日常使用.html">
            
                <a href="git_日常使用.html">
            
                    
                    日常git使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="向kernel提交补丁.html">
            
                <a href="向kernel提交补丁.html">
            
                    
                    向kernel提交补丁
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.4" data-path="linux_ssh_relay.html">
            
                <a href="linux_ssh_relay.html">
            
                    
                    ssh relay
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.5" data-path="gitlab_ci.html">
            
                <a href="gitlab_ci.html">
            
                    
                    gitlab CI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.6" data-path="docker_操作记录.html">
            
                <a href="docker_操作记录.html">
            
                    
                    docker操作记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.7" data-path="centos_操作记录.html">
            
                <a href="centos_操作记录.html">
            
                    
                    centos操作记录
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="as_title_golang.html">
            
                <a href="as_title_golang.html">
            
                    
                    Golang
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="as_title_golang1.html">
            
                <a href="as_title_golang1.html">
            
                    
                    入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1.1" data-path="golang_语法基础.html">
            
                <a href="golang_语法基础.html">
            
                    
                    Golang 语法基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.1.2" data-path="golang_json性能.html">
            
                <a href="golang_json性能.html">
            
                    
                    Golang json性能比较
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="golang_原理.html">
            
                <a href="golang_原理.html">
            
                    
                    Golang 原理相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.2.1" data-path="golang_interface原理.html">
            
                <a href="golang_interface原理.html">
            
                    
                    Golang interface原理(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2.2" data-path="golang_内存分配.html">
            
                <a href="golang_内存分配.html">
            
                    
                    Golang 内存分配(网摘)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="golang_标准库.html">
            
                <a href="golang_标准库.html">
            
                    
                    Golang 标准库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.4" data-path="golang_泛型.html">
            
                <a href="golang_泛型.html">
            
                    
                    Golang 泛型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.5" data-path="golang_我的反射代码.html">
            
                <a href="golang_我的反射代码.html">
            
                    
                    Golang 我的反射代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.6" data-path="golang_问答.html">
            
                <a href="golang_问答.html">
            
                    
                    Golang 问答
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.7" data-path="golang_高效go.html">
            
                <a href="golang_高效go.html">
            
                    
                    Golang 高效go
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.8" data-path="golang_进阶.html">
            
                <a href="golang_进阶.html">
            
                    
                    Golang 进阶
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9" data-path="as_title_golang2.html">
            
                <a href="as_title_golang2.html">
            
                    
                    Golang 杂记
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.9.1" data-path="golang_杂记1.html">
            
                <a href="golang_杂记1.html">
            
                    
                    Golang 杂记1
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9.2" data-path="golang_杂记2.html">
            
                <a href="golang_杂记2.html">
            
                    
                    Golang 杂记2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9.3" data-path="golang_杂记3.html">
            
                <a href="golang_杂记3.html">
            
                    
                    Golang 杂记3
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9.4" data-path="golang_lib选型.html">
            
                <a href="golang_lib选型.html">
            
                    
                    Golang lib选型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9.5" data-path="golang_mod_proxy.html">
            
                <a href="golang_mod_proxy.html">
            
                    
                    go mod和go proxy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9.6" data-path="golang_汇编_arm64.html">
            
                <a href="golang_汇编_arm64.html">
            
                    
                    Golang 汇编语法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9.7" data-path="golang_cgo_swig.html">
            
                <a href="golang_cgo_swig.html">
            
                    
                    go调用c可以用swig
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10.10" data-path="as_title_golang3.html">
            
                <a href="as_title_golang3.html">
            
                    
                    Golang 环境和工具链生成
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.10.1" data-path="golang_toolchain_ppc.html">
            
                <a href="golang_toolchain_ppc.html">
            
                    
                    go tools增加ppc32支持
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.10.2" data-path="golang_toolchain_compile_gccgo.html">
            
                <a href="golang_toolchain_compile_gccgo.html">
            
                    
                    编译gccgo
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.10.3" data-path="golang_go_on_mips.html">
            
                <a href="golang_go_on_mips.html">
            
                    
                    go on mips boards(not so updated)
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.10.3.1" data-path="golang_go_on_mips_part1.html">
            
                <a href="golang_go_on_mips_part1.html">
            
                    
                    part 1: cross compile go
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.10.3.2" data-path="golang_go_on_mips_part2.html">
            
                <a href="golang_go_on_mips_part2.html">
            
                    
                    part 2: build native go compiler
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.10.3.3" data-path="golang_go_on_mips_part3.html">
            
                <a href="golang_go_on_mips_part3.html">
            
                    
                    part 3: gccgo experiments
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.10.3.4" data-path="golang_go_on_mips_part4.html">
            
                <a href="golang_go_on_mips_part4.html">
            
                    
                    part 4: Golang json performance
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.10.3.5" data-path="golang_gentoo_on_mips_board_and_build_go.html">
            
                <a href="golang_gentoo_on_mips_board_and_build_go.html">
            
                    
                    Gentoo on mips board and build go
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10.11" data-path="as_title_golang4.html">
            
                <a href="as_title_golang4.html">
            
                    
                    微服务
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.11.1" data-path="golang_micro.html">
            
                <a href="golang_micro.html">
            
                    
                    go-micro和micro
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.11.2" data-path="golang_微服务概念.html">
            
                <a href="golang_微服务概念.html">
            
                    
                    微服务概念
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10.12" data-path="as_title_golang5.html">
            
                <a href="as_title_golang5.html">
            
                    
                    解释器和编解码
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.12.1" data-path="golang_yeagi.html">
            
                <a href="golang_yeagi.html">
            
                    
                    解释器yeagi
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.12.2" data-path="golang_tengo.html">
            
                <a href="golang_tengo.html">
            
                    
                    解释器tengo
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.12.3" data-path="golang_govaluate.html">
            
                <a href="golang_govaluate.html">
            
                    
                    解释器govaluate
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.12.4" data-path="golang_encoding_gotiny.html">
            
                <a href="golang_encoding_gotiny.html">
            
                    
                    gotiny编解码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.12.5" data-path="golang_abs.html">
            
                <a href="golang_abs.html">
            
                    
                    解释器abs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10.13" data-path="as_title_golang6.html">
            
                <a href="as_title_golang6.html">
            
                    
                    调试和性能
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.13.1" data-path="golang_调试记录.html">
            
                <a href="golang_调试记录.html">
            
                    
                    Golang 调试记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.13.2" data-path="golang_topid性能优化.html">
            
                <a href="golang_topid性能优化.html">
            
                    
                    Golang topid性能优化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.13.3" data-path="golang_gshell性能调试.html">
            
                <a href="golang_gshell性能调试.html">
            
                    
                    Golang gshell性能调试
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10.14" data-path="as_title_golang7.html">
            
                <a href="as_title_golang7.html">
            
                    
                    网络和消息中间件
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.14.1" data-path="golang_zmq.html">
            
                <a href="golang_zmq.html">
            
                    
                    消息中间件基本概念和zero mq
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.14.2" data-path="golang_mango.html">
            
                <a href="golang_mango.html">
            
                    
                    消息中间件mango
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.14.3" data-path="golang_libp2p.html">
            
                <a href="golang_libp2p.html">
            
                    
                    Golang p2p网络
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="as_title_rust.html">
            
                <a href="as_title_rust.html">
            
                    
                    Rust
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="rust_入门_brief.html">
            
                <a href="rust_入门_brief.html">
            
                    
                    Rust 入门系列
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1.1" data-path="rust_books.html">
            
                <a href="rust_books.html">
            
                    
                    Rust reference books
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.1.2" data-path="rust_入门1.html">
            
                <a href="rust_入门1.html">
            
                    
                    Rust 安装和基础语法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.1.3" data-path="rust_入门2.html">
            
                <a href="rust_入门2.html">
            
                    
                    Rust 泛型和内存所有权
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.1.4" data-path="rust_入门3.html">
            
                <a href="rust_入门3.html">
            
                    
                    Rust 闭包 容器 迭代器 生成器 线程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.1.5" data-path="rust_工程构建.html">
            
                <a href="rust_工程构建.html">
            
                    
                    Rust 工程构建
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="rust_coding_brief.html">
            
                <a href="rust_coding_brief.html">
            
                    
                    Rust 代码积累
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.2.1" data-path="rust_by_example_misc.html">
            
                <a href="rust_by_example_misc.html">
            
                    
                    Rust by example杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2.2" data-path="rust_序列化.html">
            
                <a href="rust_序列化.html">
            
                    
                    Rust 序列化原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2.3" data-path="rust_知识点积累.html">
            
                <a href="rust_知识点积累.html">
            
                    
                    Rust 知识点更新
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2.4" data-path="rust_adaptiveservice.html">
            
                <a href="rust_adaptiveservice.html">
            
                    
                    rust版本的adaptiveservice探索
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2.5" data-path="rust_常用设施.html">
            
                <a href="rust_常用设施.html">
            
                    
                    Rust 常用设施
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2.6" data-path="rust_代码小段.html">
            
                <a href="rust_代码小段.html">
            
                    
                    Rust 代码小段
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2.7" data-path="rust_错误处理.html">
            
                <a href="rust_错误处理.html">
            
                    
                    Rust 错误处理(网摘)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="others.html">
            
                <a href="others.html">
            
                    
                    其他
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.3.1" data-path="rust_mdbook_使用.html">
            
                <a href="rust_mdbook_使用.html">
            
                    
                    Rust 使用mdbook
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="as_title_scripts.html">
            
                <a href="as_title_scripts.html">
            
                    
                    脚本
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.12.1" data-path="shell_变量.html">
            
                <a href="shell_变量.html">
            
                    
                    shell变量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.2" data-path="shell_基础篇.html">
            
                <a href="shell_基础篇.html">
            
                    
                    shell命令和脚本记录-基础篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.3" data-path="shell_高级篇.html">
            
                <a href="shell_高级篇.html">
            
                    
                    shell命令和脚本记录-高级篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.4" data-path="shell_脚本片段.html">
            
                <a href="shell_脚本片段.html">
            
                    
                    shell脚本片段
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.5" data-path="python_记录.html">
            
                <a href="python_记录.html">
            
                    
                    python记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.6" data-path="lua_记录.html">
            
                <a href="lua_记录.html">
            
                    
                    lua记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.7" data-path="shell_rds脚本阅读.html">
            
                <a href="shell_rds脚本阅读.html">
            
                    
                    RDS脚本阅读
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.8" data-path="Project_Euler.html">
            
                <a href="Project_Euler.html">
            
                    
                    Project Euler
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="as_title_app.html">
            
                <a href="as_title_app.html">
            
                    
                    应用相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.13.1" data-path="app_sysbench代码分析.html">
            
                <a href="app_sysbench代码分析.html">
            
                    
                    sysbench代码分析
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="as_title_algorithm.html">
            
                <a href="as_title_algorithm.html">
            
                    
                    算法相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.14.1" data-path="algorithm_radix_tree.html">
            
                <a href="algorithm_radix_tree.html">
            
                    
                    基数(radix)树(网摘)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="as_title_cos.html">
            
                <a href="as_title_cos.html">
            
                    
                    C和Operating System
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.15.1" data-path="system_libc_part1.html">
            
                <a href="system_libc_part1.html">
            
                    
                    libc概览1
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.2" data-path="system_libc_part2.html">
            
                <a href="system_libc_part2.html">
            
                    
                    libc概览2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.3" data-path="system_libc_part3.html">
            
                <a href="system_libc_part3.html">
            
                    
                    libc概览3
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.4" data-path="system_原理杂记.html">
            
                <a href="system_原理杂记.html">
            
                    
                    系统原理杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.5" data-path="system_alpine.html">
            
                <a href="system_alpine.html">
            
                    
                    Alpine Linux
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.6" data-path="system_进程间通信.html">
            
                <a href="system_进程间通信.html">
            
                    
                    进程间通信
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.7" data-path="system_特殊功能fd.html">
            
                <a href="system_特殊功能fd.html">
            
                    
                    eventfd timerfd signalfd和fd共享
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.8" data-path="c_automake_autoconf.html">
            
                <a href="c_automake_autoconf.html">
            
                    
                    automake autoconf
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.9" data-path="makefile_原理和实践.html">
            
                <a href="makefile_原理和实践.html">
            
                    
                    makefile
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.10" data-path="c_编程杂记高级篇.html">
            
                <a href="c_编程杂记高级篇.html">
            
                    
                    C编程杂记高级篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.11" data-path="c_编程杂记基础篇.html">
            
                <a href="c_编程杂记基础篇.html">
            
                    
                    C编程杂记基础篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.12" data-path="c_networking_socket高阶用法.html">
            
                <a href="c_networking_socket高阶用法.html">
            
                    
                    网络编程: Advanced Socket Topics(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.13" data-path="c_protobuf介绍.html">
            
                <a href="c_protobuf介绍.html">
            
                    
                    序列化: protobuf介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.14" data-path="c_进程间通信_共享文件和共享内存.html">
            
                <a href="c_进程间通信_共享文件和共享内存.html">
            
                    
                    进程间通信: 共享文件和共享内存(网摘)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.15" data-path="c_pthread_condition和mutex.html">
            
                <a href="c_pthread_condition和mutex.html">
            
                    
                    并发 任务 事件 和锁.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.16" data-path="kernel_user_space_howto.html">
            
                <a href="kernel_user_space_howto.html">
            
                    
                    kernel space和user space交互(网摘, linux2.6)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.17" data-path="CentOS_系统性能优化配置.html">
            
                <a href="CentOS_系统性能优化配置.html">
            
                    
                    CentOS 性能优化系统配置
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.18" data-path="OS_gentoo使用.html">
            
                <a href="OS_gentoo使用.html">
            
                    
                    gentoo使用记录
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="as_title_driver.html">
            
                <a href="as_title_driver.html">
            
                    
                    内核 设备和驱动相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.1" data-path="device_driver_地址空间类型和DMA.html">
            
                <a href="device_driver_地址空间类型和DMA.html">
            
                    
                    地址空间类型和DMA
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.2" data-path="platform_device_driver.html">
            
                <a href="platform_device_driver.html">
            
                    
                    平台驱动杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.3" data-path="platform_device_driver2.html">
            
                <a href="platform_device_driver2.html">
            
                    
                    平台驱动杂记2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.4" data-path="device_driver_pci驱动概述.html">
            
                <a href="device_driver_pci驱动概述.html">
            
                    
                    pci驱动概述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.5" data-path="device_driver_内核中的时间和延迟操作.html">
            
                <a href="device_driver_内核中的时间和延迟操作.html">
            
                    
                    内核中的时间和延迟操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.6" data-path="device_driver_杂记.html">
            
                <a href="device_driver_杂记.html">
            
                    
                    驱动调试杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.7" data-path="device_localbus_16bit读写.html">
            
                <a href="device_localbus_16bit读写.html">
            
                    
                    CPLD做8bit到16bit转换
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.8" data-path="driver_位域和大小端.html">
            
                <a href="driver_位域和大小端.html">
            
                    
                    位域和大小端
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.9" data-path="as_title_driver1.html">
            
                <a href="as_title_driver1.html">
            
                    
                    nand
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.9.1" data-path="device_driver_octeon_nand.html">
            
                <a href="device_driver_octeon_nand.html">
            
                    
                    octeon nand flash驱动
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.9.2" data-path="device_driver_nand概率写失败问题分析.html">
            
                <a href="device_driver_nand概率写失败问题分析.html">
            
                    
                    Nand flash概率写失败问题分析
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16.10" data-path="octeon_remote_pci.html">
            
                <a href="octeon_remote_pci.html">
            
                    
                    octeon remote-pci.c阅读
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.11" data-path="Device_VFIO_notes.html">
            
                <a href="Device_VFIO_notes.html">
            
                    
                    VFIO简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.12" data-path="as_title_driver2.html">
            
                <a href="as_title_driver2.html">
            
                    
                    智能网卡和DPDK
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.12.1" data-path="smartNIC_智能网卡对比.html">
            
                <a href="smartNIC_智能网卡对比.html">
            
                    
                    智能网卡对比
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.12.2" data-path="octeon_pci_NIC.html">
            
                <a href="octeon_pci_NIC.html">
            
                    
                    octeon PCI NIC
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.12.3" data-path="as_title_driver3.html">
            
                <a href="as_title_driver3.html">
            
                    
                    octeon liquidIO
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.12.3.1" data-path="smartNIC_liquidIO_代码阅读app篇.html">
            
                <a href="smartNIC_liquidIO_代码阅读app篇.html">
            
                    
                    PCI-NIC 代码阅读 --app篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.12.3.2" data-path="smartNIC_liquidIO_代码阅读api篇.html">
            
                <a href="smartNIC_liquidIO_代码阅读api篇.html">
            
                    
                    PCI-NIC 代码阅读 --api篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.12.3.3" data-path="smartNIC_liquidIO_代码阅读driver篇之结构体.html">
            
                <a href="smartNIC_liquidIO_代码阅读driver篇之结构体.html">
            
                    
                    PCI-NIC 代码阅读 --driver篇之结构体
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.12.3.4" data-path="smartNIC_liquidIO_代码阅读driver篇.html">
            
                <a href="smartNIC_liquidIO_代码阅读driver篇.html">
            
                    
                    PCI-NIC 代码阅读 --driver篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16.12.3.5" data-path="smartNIC_liquidIO_代码阅读真NIC篇.html">
            
                <a href="smartNIC_liquidIO_代码阅读真NIC篇.html">
            
                    
                    PCI-NIC 代码阅读 --真NIC篇
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16.12.4" data-path="networking_dpdk使用_2014.html">
            
                <a href="networking_dpdk使用_2014.html">
            
                    
                    DPDK使用(2014)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16.13" data-path="device_nvme要点介绍.html">
            
                <a href="device_nvme要点介绍.html">
            
                    
                    nvme要点介绍
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="as_title_cpu.html">
            
                <a href="as_title_cpu.html">
            
                    
                    CPU Arch相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.17.1" data-path="CPU_interconnection_networks.html">
            
                <a href="CPU_interconnection_networks.html">
            
                    
                    CPU核互联模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.2" data-path="cache_CPU和cache一致性原理.html">
            
                <a href="cache_CPU和cache一致性原理.html">
            
                    
                    CPU和cache一致性原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3" data-path="as_title_cpu1.html">
            
                <a href="as_title_cpu1.html">
            
                    
                    ARM64
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.17.3.1" data-path="CPU_ARM64_知识杂记.html">
            
                <a href="CPU_ARM64_知识杂记.html">
            
                    
                    aarch64架构知识杂记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3.2" data-path="CPU_ARM64_thunder_overview.html">
            
                <a href="CPU_ARM64_thunder_overview.html">
            
                    
                    thunder 概览
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3.3" data-path="CPU_ARM64_thunder_开发板操作记录.html">
            
                <a href="CPU_ARM64_thunder_开发板操作记录.html">
            
                    
                    thunder 开发板操作记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3.4" data-path="CPU_ARM64_thunder_bdk.html">
            
                <a href="CPU_ARM64_thunder_bdk.html">
            
                    
                    thunder BDK
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3.5" data-path="CPU_ARM64_thunder_efi_rtc.html">
            
                <a href="CPU_ARM64_thunder_efi_rtc.html">
            
                    
                    thunder RTC时间和efi
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3.6" data-path="CPU_ARM64_thunder_uefi_fdt.html">
            
                <a href="CPU_ARM64_thunder_uefi_fdt.html">
            
                    
                    thunder uefi和fdt
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3.7" data-path="CPU_ARM64_thunder_atf.html">
            
                <a href="CPU_ARM64_thunder_atf.html">
            
                    
                    thunder atf
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.3.8" data-path="CPU_ARM64_thunder_kernel_boot.html">
            
                <a href="CPU_ARM64_thunder_kernel_boot.html">
            
                    
                    thunder kernel启动打印流程
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.17.4" data-path="as_title_cpu2.html">
            
                <a href="as_title_cpu2.html">
            
                    
                    PPC
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.17.4.1" data-path="CPU_PPC启动多核Linux_流程和内存映射.html">
            
                <a href="CPU_PPC启动多核Linux_流程和内存映射.html">
            
                    
                    PPC启动多核linux: 流程和内存映射
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.4.2" data-path="CPU_PPC_kernel升级记录.html">
            
                <a href="CPU_PPC_kernel升级记录.html">
            
                    
                    PPC kernel升级记录
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.17.5" data-path="as_title_cpu3.html">
            
                <a href="as_title_cpu3.html">
            
                    
                    MIPS
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.17.5.1" data-path="CPU_MIPS_octeon地址空间和寄存器访问.html">
            
                <a href="CPU_MIPS_octeon地址空间和寄存器访问.html">
            
                    
                    octeon 地址空间和寄存器访问
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.2" data-path="CPU_MIPS_octeon操作记录.html">
            
                <a href="CPU_MIPS_octeon操作记录.html">
            
                    
                    octeon 操作记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.3" data-path="CPU_MIPS_octeon_包处理性能.html">
            
                <a href="CPU_MIPS_octeon_包处理性能.html">
            
                    
                    octeon 系列处理器包处理性能
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.4" data-path="CPU_MIPS_octeon_ddr调试记录.html">
            
                <a href="CPU_MIPS_octeon_ddr调试记录.html">
            
                    
                    octeon DDR调试
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.5" data-path="CPU_MIPS_octeon_BDK.html">
            
                <a href="CPU_MIPS_octeon_BDK.html">
            
                    
                    octeon CN78xx BDK
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.6" data-path="kernel_增加ECC中断.html">
            
                <a href="kernel_增加ECC中断.html">
            
                    
                    octeon 增加ECC中断
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.7" data-path="CPU_MIPS_octeon_hw-ddr2代码走读.html">
            
                <a href="CPU_MIPS_octeon_hw-ddr2代码走读.html">
            
                    
                    octeon hw-ddr2代码走读
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.8" data-path="CPU_MIPS_octeon_reboot调试和ddr中断.html">
            
                <a href="CPU_MIPS_octeon_reboot调试和ddr中断.html">
            
                    
                    octeon reboot调试和DDR中断
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.9" data-path="CPU_MIPS_octeon中断.html">
            
                <a href="CPU_MIPS_octeon中断.html">
            
                    
                    octeon 中断
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.10" data-path="CPU_MIPS_octeon原子操作.html">
            
                <a href="CPU_MIPS_octeon原子操作.html">
            
                    
                    octeon 原子操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17.5.11" data-path="CPU_MIPS_octeon网口代码分析.html">
            
                <a href="CPU_MIPS_octeon网口代码分析.html">
            
                    
                    octeon 网口代码分析
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >优化linux网络栈: 接收路径(网摘)</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div class="search-plus" id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon "></span><a href="#special-thanks"><b>1. </b>Special thanks</a></li><li><span class="title-icon "></span><a href="#general-advice-on-monitoring-and-tuning-the-linux-networking-stack"><b>2. </b>General advice on monitoring and tuning the Linux networking stack</a></li><li><span class="title-icon "></span><a href="#overview"><b>3. </b>Overview</a></li><li><span class="title-icon "></span><a href="#detailed-look"><b>4. </b>Detailed Look</a></li><ul><li><span class="title-icon "></span><a href="#network-device-driver"><b>4.1. </b>Network Device Driver</a></li><ul><li><span class="title-icon "></span><a href="#initialization"><b>4.1.1. </b>Initialization</a></li><li><span class="title-icon "></span><a href="#network-device-initialization"><b>4.1.2. </b>Network device initialization</a></li><li><span class="title-icon "></span><a href="#bringing-a-network-device-up"><b>4.1.3. </b>Bringing a network device up</a></li><li><span class="title-icon "></span><a href="#monitoring-network-devices"><b>4.1.4. </b>Monitoring network devices</a></li><li><span class="title-icon "></span><a href="#tuning-network-devices"><b>4.1.5. </b>Tuning network devices</a></li></ul><li><span class="title-icon "></span><a href="#softirqs"><b>4.2. </b>SoftIRQs</a></li><ul><li><span class="title-icon "></span><a href="#what-is-a-softirq"><b>4.2.1. </b>What is a softirq?</a></li><li><span class="title-icon "></span><a href="#ksoftirqd"><b>4.2.2. </b>ksoftirqd</a></li><li><span class="title-icon "></span><a href="#dosoftirq"><b>4.2.3. </b>__do_softirq</a></li><li><span class="title-icon "></span><a href="#monitoring"><b>4.2.4. </b>Monitoring</a></li></ul><li><span class="title-icon "></span><a href="#linux-network-device-subsystem"><b>4.3. </b>Linux network device subsystem</a></li><ul><li><span class="title-icon "></span><a href="#initialization-of-network-device-subsystem"><b>4.3.1. </b>Initialization of network device subsystem</a></li><li><span class="title-icon "></span><a href="#data-arrives"><b>4.3.2. </b>Data arrives</a></li><li><span class="title-icon "></span><a href="#network-data-processing-begins"><b>4.3.3. </b>Network data processing begins</a></li><li><span class="title-icon "></span><a href="#generic-receive-offloading-gro"><b>4.3.4. </b>Generic Receive Offloading (GRO)</a></li><li><span class="title-icon "></span><a href="#napigroreceive"><b>4.3.5. </b>napi_gro_receive</a></li><li><span class="title-icon "></span><a href="#napiskbfinish"><b>4.3.6. </b>napi_skb_finish</a></li></ul><li><span class="title-icon "></span><a href="#receive-packet-steering-rps"><b>4.4. </b>Receive Packet Steering (RPS)</a></li><ul><li><span class="title-icon "></span><a href="#tuning-enabling-rps"><b>4.4.1. </b>Tuning: Enabling RPS</a></li></ul><li><span class="title-icon "></span><a href="#receive-flow-steering-rfs"><b>4.5. </b>Receive Flow Steering (RFS)</a></li><ul><li><span class="title-icon "></span><a href="#tuning-enabling-rfs"><b>4.5.1. </b>Tuning: Enabling RFS</a></li></ul><li><span class="title-icon "></span><a href="#hardware-accelerated-receive-flow-steering-arfs"><b>4.6. </b>Hardware accelerated Receive Flow Steering (aRFS)</a></li><ul><li><span class="title-icon "></span><a href="#tuning-enabling-accelerated-rfs-arfs"><b>4.6.1. </b>Tuning: Enabling accelerated RFS (aRFS)</a></li></ul><li><span class="title-icon "></span><a href="#moving-up-the-network-stack-with-netifreceiveskb"><b>4.7. </b>Moving up the network stack with netif_receive_skb</a></li><ul><li><span class="title-icon "></span><a href="#tuning-rx-packet-timestamping"><b>4.7.1. </b>Tuning: RX packet timestamping</a></li></ul><li><span class="title-icon "></span><a href="#netifreceiveskb"><b>4.8. </b>netif_receive_skb</a></li><ul><li><span class="title-icon "></span><a href="#without-rps-default-setting"><b>4.8.1. </b>Without RPS (default setting)</a></li><li><span class="title-icon "></span><a href="#with-rps-enabled"><b>4.8.2. </b>With RPS enabled</a></li><li><span class="title-icon "></span><a href="#backlog-queue-napi-poller"><b>4.8.3. </b>backlog queue NAPI poller</a></li><li><span class="title-icon "></span><a href="#processbacklog"><b>4.8.4. </b>process_backlog</a></li><li><span class="title-icon "></span><a href="#netifreceiveskbcore-delivers-data-to-packet-taps-and-protocol-layers"><b>4.8.5. </b>__netif_receive_skb_core delivers data to packet taps and protocol layers</a></li><li><span class="title-icon "></span><a href="#packet-tap-delivery"><b>4.8.6. </b>Packet tap delivery</a></li><li><span class="title-icon "></span><a href="#protocol-layer-delivery"><b>4.8.7. </b>Protocol layer delivery</a></li></ul><li><span class="title-icon "></span><a href="#protocol-layer-registration"><b>4.9. </b>Protocol layer registration</a></li><ul><li><span class="title-icon "></span><a href="#ip-protocol-layer"><b>4.9.1. </b>IP protocol layer</a></li><li><span class="title-icon "></span><a href="#higher-level-protocol-registration"><b>4.9.2. </b>Higher level protocol registration</a></li><li><span class="title-icon "></span><a href="#udp-protocol-layer"><b>4.9.3. </b>UDP protocol layer</a></li><li><span class="title-icon "></span><a href="#queuing-data-to-a-socket"><b>4.9.4. </b>Queuing data to a socket</a></li></ul><li><span class="title-icon "></span><a href="#extras"><b>4.10. </b>Extras</a></li><ul><li><span class="title-icon "></span><a href="#timestamping"><b>4.10.1. </b>Timestamping</a></li><li><span class="title-icon "></span><a href="#busy-polling-for-low-latency-sockets"><b>4.10.2. </b>Busy polling for low latency sockets</a></li><li><span class="title-icon "></span><a href="#netpoll-support-for-networking-in-critical-contexts"><b>4.10.3. </b>Netpoll: support for networking in critical contexts</a></li><li><span class="title-icon "></span><a href="#soincomingcpu"><b>4.10.4. </b>SO_INCOMING_CPU</a></li><li><span class="title-icon "></span><a href="#dma-engines"><b>4.10.5. </b>DMA Engines</a></li></ul></ul><li><span class="title-icon "></span><a href="#conclusion"><b>5. </b>Conclusion</a></li><li><span class="title-icon "></span><a href="#help-with-linux-networking-or-other-systems"><b>6. </b>Help with Linux networking or other systems</a></li><li><span class="title-icon "></span><a href="#related-posts"><b>7. </b>Related posts</a></li></ul></div><a href="#special-thanks" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><ul>
<li><a href="#special-thanks">Special thanks</a></li>
<li><a href="#general-advice-on-monitoring-and-tuning-the-linux-networking-stack">General advice on monitoring and tuning the Linux networking stack</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#detailed-look">Detailed Look</a><ul>
<li><a href="#network-device-driver">Network Device Driver</a><ul>
<li><a href="#initialization">Initialization</a><ul>
<li><a href="#pci-initialization">PCI initialization</a></li>
<li><a href="#pci-probe">PCI probe</a><ul>
<li><a href="#a-peek-into-pci-initialization">A peek into PCI initialization</a></li>
</ul>
</li>
<li><a href="#more-linux-pci-driver-information">More Linux PCI driver information</a></li>
</ul>
</li>
<li><a href="#network-device-initialization">Network device initialization</a><ul>
<li><a href="#struct-net_device_ops"><code>struct net_device_ops</code></a></li>
<li><a href="#ethtool-registration"><code>ethtool</code> registration</a></li>
<li><a href="#irqs">IRQs</a></li>
<li><a href="#napi">NAPI</a></li>
<li><a href="#napi-initialization-in-the-igb-driver">NAPI initialization in the <code>igb</code> driver</a></li>
</ul>
</li>
<li><a href="#bringing-a-network-device-up">Bringing a network device up</a><ul>
<li><a href="#preparing-to-receive-data-from-the-network">Preparing to receive data from the network</a></li>
<li><a href="#enable-napi">Enable NAPI</a></li>
<li><a href="#register-an-interrupt-handler">Register an interrupt handler</a></li>
<li><a href="#enable-interrupts">Enable Interrupts</a></li>
<li><a href="#the-network-device-is-now-up">The network device is now up</a></li>
</ul>
</li>
<li><a href="#monitoring-network-devices">Monitoring network devices</a><ul>
<li><a href="#using-ethtool--s">Using <code>ethtool -S</code></a></li>
<li><a href="#using-sysfs">Using sysfs</a></li>
<li><a href="#using-procnetdev">Using <code>/proc/net/dev</code></a></li>
</ul>
</li>
<li><a href="#tuning-network-devices">Tuning network devices</a><ul>
<li><a href="#check-the-number-of-rx-queues-being-used">Check the number of RX queues being used</a></li>
<li><a href="#adjusting-the-number-of-rx-queues">Adjusting the number of RX queues</a></li>
<li><a href="#adjusting-the-size-of-the-rx-queues">Adjusting the size of the RX queues</a></li>
<li><a href="#adjusting-the-processing-weight-of-rx-queues">Adjusting the processing weight of RX queues</a></li>
<li><a href="#adjusting-the-rx-hash-fields-for-network-flows">Adjusting the rx hash fields for network flows</a></li>
<li><a href="#ntuple-filtering-for-steering-network-flows">ntuple filtering for steering network flows</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#softirqs">SoftIRQs</a><ul>
<li><a href="#what-is-a-softirq">What is a softirq?</a></li>
<li><a href="#ksoftirqd"><code>ksoftirqd</code></a></li>
<li><a href="#__do_softirq"><code>__do_softirq</code></a></li>
<li><a href="#monitoring">Monitoring</a><ul>
<li><a href="#procsoftirqs"><code>/proc/softirqs</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#linux-network-device-subsystem">Linux network device subsystem</a><ul>
<li><a href="#initialization-of-network-device-subsystem">Initialization of network device subsystem</a><ul>
<li><a href="#initialization-of-struct-softnet_data-structures">Initialization of <code>struct softnet_data</code> structures</a></li>
<li><a href="#initialization-of-softirq-handlers">Initialization of softirq handlers</a></li>
</ul>
</li>
<li><a href="#data-arrives">Data arrives</a><ul>
<li><a href="#interrupt-handler">Interrupt handler</a></li>
<li><a href="#napi-and-napi_schedule">NAPI and <code>napi_schedule</code></a></li>
<li><a href="#a-note-about-cpu-and-network-data-processing">A note about CPU and network data processing</a></li>
<li><a href="#monitoring-network-data-arrival">Monitoring network data arrival</a><ul>
<li><a href="#hardware-interrupt-requests">Hardware interrupt requests</a></li>
</ul>
</li>
<li><a href="#tuning-network-data-arrival">Tuning network data arrival</a><ul>
<li><a href="#interrupt-coalescing">Interrupt coalescing</a></li>
<li><a href="#adjusting-irq-affinities">Adjusting IRQ affinities</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#network-data-processing-begins">Network data processing begins</a><ul>
<li><a href="#net_rx_action-processing-loop"><code>net_rx_action</code> processing loop</a></li>
<li><a href="#napi-poll-function-and-weight">NAPI <code>poll</code> function and <code>weight</code></a></li>
<li><a href="#the-napi--network-device-driver-contract">The NAPI / network device driver contract</a></li>
<li><a href="#finishing-the-net_rx_action-loop">Finishing the <code>net_rx_action</code> loop</a></li>
<li><a href="#exiting-the-loop-when-limits-are-reached">Exiting the loop when limits are reached</a></li>
<li><a href="#napi-poll">NAPI poll</a><ul>
<li><a href="#igb_poll"><code>igb_poll</code></a></li>
<li><a href="#igb_clean_rx_irq"><code>igb_clean_rx_irq</code></a></li>
</ul>
</li>
<li><a href="#monitoring-network-data-processing">Monitoring network data processing</a><ul>
<li><a href="#procnetsoftnet_stat"><code>/proc/net/softnet_stat</code></a></li>
</ul>
</li>
<li><a href="#tuning-network-data-processing">Tuning network data processing</a><ul>
<li><a href="#adjusting-the-net_rx_action-budget">Adjusting the <code>net_rx_action</code> budget</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#generic-receive-offloading-gro">Generic Receive Offloading (GRO)</a><ul>
<li><a href="#tuning-adjusting-gro-settings-with-ethtool">Tuning: Adjusting GRO settings with <code>ethtool</code></a></li>
</ul>
</li>
<li><a href="#napi_gro_receive"><code>napi_gro_receive</code></a><ul>
<li><a href="#dev_gro_receive"><code>dev_gro_receive</code></a></li>
</ul>
</li>
<li><a href="#napi_skb_finish"><code>napi_skb_finish</code></a></li>
</ul>
</li>
<li><a href="#receive-packet-steering-rps">Receive Packet Steering (RPS)</a><ul>
<li><a href="#tuning-enabling-rps">Tuning: Enabling RPS</a></li>
</ul>
</li>
<li><a href="#receive-flow-steering-rfs">Receive Flow Steering (RFS)</a><ul>
<li><a href="#tuning-enabling-rfs">Tuning: Enabling RFS</a></li>
</ul>
</li>
<li><a href="#hardware-accelerated-receive-flow-steering-arfs">Hardware accelerated Receive Flow Steering (aRFS)</a><ul>
<li><a href="#tuning-enabling-accelerated-rfs-arfs">Tuning: Enabling accelerated RFS (aRFS)</a></li>
</ul>
</li>
<li><a href="#moving-up-the-network-stack-with-netif_receive_skb">Moving up the network stack with <code>netif_receive_skb</code></a><ul>
<li><a href="#tuning-rx-packet-timestamping">Tuning: RX packet timestamping</a></li>
</ul>
</li>
<li><a href="#netif_receive_skb"><code>netif_receive_skb</code></a><ul>
<li><a href="#without-rps-default-setting">Without RPS (default setting)</a></li>
<li><a href="#with-rps-enabled">With RPS enabled</a><ul>
<li><a href="#enqueue_to_backlog"><code>enqueue_to_backlog</code></a></li>
<li><a href="#flow-limits">Flow limits</a></li>
<li><a href="#monitoring-monitor-drops-due-to-full-input_pkt_queue-or-flow-limit">Monitoring: Monitor drops due to full <code>input_pkt_queue</code> or flow limit</a></li>
<li><a href="#tuning">Tuning</a><ul>
<li><a href="#tuning-adjusting-netdev_max_backlog-to-prevent-drops">Tuning: Adjusting <code>netdev_max_backlog</code> to prevent drops</a></li>
<li><a href="#tuning-adjust-the-napi-weight-of-the-backlog-poll-loop">Tuning: Adjust the NAPI weight of the backlog <code>poll</code> loop</a></li>
<li><a href="#tuning-enabling-flow-limits-and-tuning-flow-limit-hash-table-size">Tuning: Enabling flow limits and tuning flow limit hash table size</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#backlog-queue-napi-poller">backlog queue NAPI poller</a></li>
<li><a href="#process_backlog"><code>process_backlog</code></a></li>
<li><a href="#__netif_receive_skb_core-delivers-data-to-packet-taps-and-protocol-layers"><code>__netif_receive_skb_core</code> delivers data to packet taps and protocol layers</a></li>
<li><a href="#packet-tap-delivery">Packet tap delivery</a></li>
<li><a href="#protocol-layer-delivery">Protocol layer delivery</a></li>
</ul>
</li>
<li><a href="#protocol-layer-registration">Protocol layer registration</a><ul>
<li><a href="#ip-protocol-layer">IP protocol layer</a><ul>
<li><a href="#ip_rcv"><code>ip_rcv</code></a></li>
<li><a href="#netfilter-and-iptables">netfilter and iptables</a></li>
<li><a href="#ip_rcv_finish"><code>ip_rcv_finish</code></a><ul>
<li><a href="#tuning-adjusting-ip-protocol-early-demux">Tuning: adjusting IP protocol early demux</a></li>
</ul>
</li>
<li><a href="#ip_local_deliver"><code>ip_local_deliver</code></a></li>
<li><a href="#ip_local_deliver_finish"><code>ip_local_deliver_finish</code></a></li>
<li><a href="#monitoring-ip-protocol-layer-statistics">Monitoring: IP protocol layer statistics</a></li>
</ul>
</li>
<li><a href="#higher-level-protocol-registration">Higher level protocol registration</a></li>
<li><a href="#udp-protocol-layer">UDP protocol layer</a><ul>
<li><a href="#udp_rcv"><code>udp_rcv</code></a></li>
<li><a href="#__udp4_lib_rcv"><code>__udp4_lib_rcv</code></a></li>
<li><a href="#udp_queue_rcv_skb"><code>udp_queue_rcv_skb</code></a></li>
<li><a href="#sk_rcvqueues_full"><code>sk_rcvqueues_full</code></a><ul>
<li><a href="#tuning-socket-receive-queue-memory">Tuning: Socket receive queue memory</a></li>
</ul>
</li>
<li><a href="#udp_queue_rcv_skb-1"><code>udp_queue_rcv_skb</code></a></li>
<li><a href="#__udp_queue_rcv_skb"><code>__udp_queue_rcv_skb</code></a></li>
<li><a href="#monitoring-udp-protocol-layer-statistics">Monitoring: UDP protocol layer statistics</a><ul>
<li><a href="#procnetsnmp"><code>/proc/net/snmp</code></a></li>
<li><a href="#procnetudp"><code>/proc/net/udp</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#queuing-data-to-a-socket">Queuing data to a socket</a></li>
</ul>
</li>
<li><a href="#extras">Extras</a><ul>
<li><a href="#timestamping">Timestamping</a></li>
<li><a href="#busy-polling-for-low-latency-sockets">Busy polling for low latency sockets</a></li>
<li><a href="#netpoll-support-for-networking-in-critical-contexts">Netpoll: support for networking in critical contexts</a></li>
<li><a href="#so_incoming_cpu"><code>SO_INCOMING_CPU</code></a></li>
<li><a href="#dma-engines">DMA Engines</a><ul>
<li><a href="#intels-io-acceleration-technology-ioat">Intel&#x2019;s I/O Acceleration Technology (IOAT)</a><ul>
<li><a href="#direct-cache-access-dca">Direct cache access (DCA)</a></li>
<li><a href="#monitoring-ioat-dma-engine">Monitoring IOAT DMA engine</a></li>
<li><a href="#tuning-ioat-dma-engine">Tuning IOAT DMA engine</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#help-with-linux-networking-or-other-systems">Help with Linux networking or other systems</a></li>
<li><a href="#related-posts">Related posts</a></li>
</ul>
<p><a href="https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/" target="_blank">&#x539F;&#x6587;&#x94FE;&#x63A5;</a></p>
<p>This blog post explains how computers running the Linux kernel receive packets, as well as how to monitor and tune each component of the networking stack as packets flow from the network toward userland programs.</p>
<p><strong>UPDATE</strong> We&#x2019;ve released the counterpart to this post: <a href="https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/" target="_blank">Monitoring and Tuning the Linux Networking Stack: Sending Data</a>.</p>
<p><strong>UPDATE</strong> Take a look at <a href="https://blog.packagecloud.io/eng/2016/10/11/monitoring-tuning-linux-networking-stack-receiving-data-illustrated/" target="_blank">the Illustrated Guide to Monitoring and Tuning the Linux Networking Stack: Receiving Data</a>, which adds some diagrams for the information presented below.</p>
<p>It is impossible to tune or monitor the Linux networking stack without reading the source code of the kernel and having a deep understanding of what exactly is happening.</p>
<p>This blog post will hopefully serve as a reference to anyone looking to do this.</p>
<h1 id="special-thanks"><a name="special-thanks" class="anchor-navigation-ex-anchor" href="#special-thanks"><i class="fa fa-link" aria-hidden="true"></i></a>1. Special thanks</h1>
<p>Special thanks to the folks at <a href="https://privateinternetaccess.com/" target="_blank">Private Internet Access</a> who hired us to research this information in conjunction with other network research and who have graciously allowed us to build upon the research and publish this information.</p>
<p>The information presented here builds upon the work done for <a href="https://privateinternetaccess.com/" target="_blank">Private Internet Access</a>, which was originally published as a 5 part series starting <a href="https://www.privateinternetaccess.com/blog/2016/01/linux-networking-stack-from-the-ground-up-part-1/" target="_blank">here</a>.</p>
<h1 id="general-advice-on-monitoring-and-tuning-the-linux-networking-stack"><a name="general-advice-on-monitoring-and-tuning-the-linux-networking-stack" class="anchor-navigation-ex-anchor" href="#general-advice-on-monitoring-and-tuning-the-linux-networking-stack"><i class="fa fa-link" aria-hidden="true"></i></a>2. General advice on monitoring and tuning the Linux networking stack</h1>
<p><strong>UPDATE</strong> We&#x2019;ve released the counterpart to this post: <a href="https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/" target="_blank">Monitoring and Tuning the Linux Networking Stack: Sending Data</a>.</p>
<p><strong>UPDATE</strong> Take a look at <a href="https://blog.packagecloud.io/eng/2016/10/11/monitoring-tuning-linux-networking-stack-receiving-data-illustrated/" target="_blank">the Illustrated Guide to Monitoring and Tuning the Linux Networking Stack: Receiving Data</a>, which adds some diagrams for the information presented below.</p>
<p>The networking stack is complex and there is no one size fits all solution. If the performance and health of your networking is critical to you or your business, you will have no choice but to invest a considerable amount of time, effort, and money into understanding how the various parts of the system interact.</p>
<p>Ideally, you should consider measuring packet drops at each layer of the network stack. That way you can determine and narrow down which component needs to be tuned.</p>
<p>This is where, I think, many operators go off track: the assumption is made that a set of sysctl settings or <code>/proc</code> values can simply be reused wholesale. In some cases, perhaps, but it turns out that the entire system is so nuanced and intertwined that if you desire to have meaningful monitoring or tuning, you must strive to understand how the system functions at a deep level. Otherwise, you can simply use the default settings, which should be good enough until further optimization (and the required investment to deduce those settings) is necessary.</p>
<p>Many of the example settings provided in this blog post are used solely for illustrative purposes and are not a recommendation for or against a certain configuration or default setting. Before adjusting any setting, you should develop a frame of reference around what you need to be monitoring to notice a meaningful change.</p>
<p>Adjusting networking settings while connected to the machine over a network is dangerous; you could very easily lock yourself out or completely take out your networking. Do not adjust these settings on production machines; instead make adjustments on new machines and rotate them into production, if possible.</p>
<h1 id="overview"><a name="overview" class="anchor-navigation-ex-anchor" href="#overview"><i class="fa fa-link" aria-hidden="true"></i></a>3. Overview</h1>
<p>For reference, you may want to have a copy of the device data sheet handy. This post will examine the Intel I350 Ethernet controller, controlled by the <code>igb</code> device driver. You can find that data sheet (warning: LARGE PDF) <a href="http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/ethernet-controller-i350-datasheet.pdf" target="_blank">here for your reference</a>.</p>
<p>The high level path a packet takes from arrival to socket receive buffer is as follows:</p>
<ol>
<li>Driver is loaded and initialized.</li>
<li>Packet arrives at the NIC from the network.</li>
<li>Packet is copied (via DMA) to a ring buffer in kernel memory.</li>
<li>Hardware interrupt is generated to let the system know a packet is in memory.</li>
<li>Driver calls into <a href="http://www.linuxfoundation.org/collaborate/workgroups/networking/napi" target="_blank">NAPI</a> to start a poll loop if one was not running already.</li>
<li><code>ksoftirqd</code> processes run on each CPU on the system. They are registered at boot time. The <code>ksoftirqd</code> processes pull packets off the ring buffer by calling the NAPI <code>poll</code> function that the device driver registered during initialization.</li>
<li>Memory regions in the ring buffer that have had network data written to them are unmapped.</li>
<li>Data that was DMA&#x2019;d into memory is passed up the networking layer as an &#x2018;skb&#x2019; for more processing.</li>
<li>Incoming network data frames are distributed among multiple CPUs if packet steering is enabled or if the NIC has multiple receive queues.</li>
<li>Network data frames are handed to the protocol layers from the queues.</li>
<li>Protocol layers process data.</li>
<li>Data is added to receive buffers attached to sockets by protocol layers.</li>
</ol>
<p>This entire flow will be examined in detail in the following sections.</p>
<p>The protocol layers examined below are the IP and UDP protocol layers. Much of the information presented will serve as a reference for other protocol layers, as well.</p>
<h1 id="detailed-look"><a name="detailed-look" class="anchor-navigation-ex-anchor" href="#detailed-look"><i class="fa fa-link" aria-hidden="true"></i></a>4. Detailed Look</h1>
<p><strong>UPDATE</strong> We&#x2019;ve released the counterpart to this post: <a href="https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/" target="_blank">Monitoring and Tuning the Linux Networking Stack: Sending Data</a>.</p>
<p><strong>UPDATE</strong> Take a look at <a href="https://blog.packagecloud.io/eng/2016/10/11/monitoring-tuning-linux-networking-stack-receiving-data-illustrated/" target="_blank">the Illustrated Guide to Monitoring and Tuning the Linux Networking Stack: Receiving Data</a>, which adds some diagrams for the information presented below.</p>
<p>This blog post will be examining the Linux kernel version 3.13.0 with links to code on GitHub and code snippets throughout this post.</p>
<p>Understanding exactly how packets are received in the Linux kernel is very involved. We&#x2019;ll need to closely examine and understand how a network driver works, so that parts of the network stack later are more clear.</p>
<p>This blog post will look at the <code>igb</code> network driver. This driver is used for a relatively common server NIC, the Intel Ethernet Controller I350. So, let&#x2019;s start by understanding how the <code>igb</code> network driver works.</p>
<h2 id="network-device-driver"><a name="network-device-driver" class="anchor-navigation-ex-anchor" href="#network-device-driver"><i class="fa fa-link" aria-hidden="true"></i></a>4.1. Network Device Driver</h2>
<h3 id="initialization"><a name="initialization" class="anchor-navigation-ex-anchor" href="#initialization"><i class="fa fa-link" aria-hidden="true"></i></a>4.1.1. Initialization</h3>
<p>A driver registers an initialization function which is called by the kernel when the driver is loaded. This function is registered by using the <code>module_init</code> macro.</p>
<p>The <code>igb</code> initialization function (<code>igb_init_module</code>) and its registration with <code>module_init</code> can be found in <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L676-L697" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>.</p>
<p>Both are fairly straightforward:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/**
 *  igb_init_module - Driver Registration Routine
 *
 *  igb_init_module is the first routine called when the driver is
 *  loaded. All it does is register with the PCI subsystem.
 **/</span>
<span class="token keyword">static</span> <span class="token keyword">int</span> __init <span class="token function">igb_init_module</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token keyword">int</span> ret<span class="token punctuation">;</span>
  <span class="token function">pr_info</span><span class="token punctuation">(</span><span class="token string">&quot;%s - version %s\n&quot;</span><span class="token punctuation">,</span> igb_driver_string<span class="token punctuation">,</span> igb_driver_version<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">pr_info</span><span class="token punctuation">(</span><span class="token string">&quot;%s\n&quot;</span><span class="token punctuation">,</span> igb_copyright<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">/* ... */</span>

  ret <span class="token operator">=</span> <span class="token function">pci_register_driver</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>igb_driver<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> ret<span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token function">module_init</span><span class="token punctuation">(</span>igb_init_module<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>The bulk of the work to initialize the device happens with the call to <code>pci_register_driver</code> as we&#x2019;ll see next.</p>
<h4 id="pci-initialization"><a name="pci-initialization" class="anchor-navigation-ex-anchor" href="#pci-initialization"><i class="fa fa-link" aria-hidden="true"></i></a>PCI initialization</h4>
<p>The Intel I350 network card is a <a href="https://en.wikipedia.org/wiki/PCI_Express" target="_blank">PCI express</a> device.</p>
<p>PCI devices identify themselves with a series of registers in the <a href="https://en.wikipedia.org/wiki/PCI_configuration_space#Standardized_registers" target="_blank">PCI Configuration Space</a>.</p>
<p>When a device driver is compiled, a macro named <code>MODULE_DEVICE_TABLE</code> (from <a href="https://github.com/torvalds/linux/blob/v3.13/include/linux/module.h#L145-L146" target="_blank"><code>include/module.h</code></a>) is used to export a table of PCI device IDs identifying devices that the device driver can control. The table is also registered as part of a structure, as we&#x2019;ll see shortly.</p>
<p>The kernel uses this table to determine which device driver to load to control the device.</p>
<p>That&#x2019;s how the OS can figure out which devices are connected to the system and which driver should be used to talk to the device.</p>
<p>This table and the PCI device IDs for the <code>igb</code> driver can be found in <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L79-L117" target="_blank"><code>drivers/net/ethernet/intel/igb/igb_main.c</code></a> and <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/e1000_hw.h#L41-L75" target="_blank"><code>drivers/net/ethernet/intel/igb/e1000_hw.h</code></a>, respectively:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token function">DEFINE_PCI_DEVICE_TABLE</span><span class="token punctuation">(</span>igb_pci_tbl<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I354_BACKPLANE_1GBPS<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I354_SGMII<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I354_BACKPLANE_2_5GBPS<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I211_COPPER<span class="token punctuation">)</span><span class="token punctuation">,</span> board_82575 <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I210_COPPER<span class="token punctuation">)</span><span class="token punctuation">,</span> board_82575 <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I210_FIBER<span class="token punctuation">)</span><span class="token punctuation">,</span> board_82575 <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I210_SERDES<span class="token punctuation">)</span><span class="token punctuation">,</span> board_82575 <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I210_SGMII<span class="token punctuation">)</span><span class="token punctuation">,</span> board_82575 <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I210_COPPER_FLASHLESS<span class="token punctuation">)</span><span class="token punctuation">,</span> board_82575 <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span> <span class="token function">PCI_VDEVICE</span><span class="token punctuation">(</span>INTEL<span class="token punctuation">,</span> E1000_DEV_ID_I210_SERDES_FLASHLESS<span class="token punctuation">)</span><span class="token punctuation">,</span> board_82575 <span class="token punctuation">}</span><span class="token punctuation">,</span>

  <span class="token comment">/* ... */</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token function">MODULE_DEVICE_TABLE</span><span class="token punctuation">(</span>pci<span class="token punctuation">,</span> igb_pci_tbl<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>As seen in the previous section, <code>pci_register_driver</code> is called in the driver&#x2019;s initialization function.</p>
<p>This function registers a structure of pointers. Most of the pointers are function pointers, but the PCI device ID table is also registered. The kernel uses the functions registered by the driver to bring the PCI device up.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L238-L249" target="_blank"><code>drivers/net/ethernet/intel/igb/igb_main.c</code></a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">struct</span> <span class="token class-name">pci_driver</span> igb_driver <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token punctuation">.</span>name     <span class="token operator">=</span> igb_driver_name<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>id_table <span class="token operator">=</span> igb_pci_tbl<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>probe    <span class="token operator">=</span> igb_probe<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>remove   <span class="token operator">=</span> igb_remove<span class="token punctuation">,</span>

  <span class="token comment">/* ... */</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre>
<h4 id="pci-probe"><a name="pci-probe" class="anchor-navigation-ex-anchor" href="#pci-probe"><i class="fa fa-link" aria-hidden="true"></i></a>PCI probe</h4>
<p>Once a device has been identified by its PCI IDs, the kernel can then select the proper driver to use to control the device. Each PCI driver registers a probe function with the PCI system in the kernel. The kernel calls this function for devices which have not yet been claimed by a device driver. Once a device is claimed, other drivers will not be asked about the device. Most drivers have a lot of code that runs to get the device ready for use. The exact things done vary from driver to driver.</p>
<p>Some typical operations to perform include:</p>
<ol>
<li>Enabling the PCI device.</li>
<li>Requesting memory ranges and <a href="http://wiki.osdev.org/I/O_Ports" target="_blank">IO ports</a>.</li>
<li>Setting the <a href="https://en.wikipedia.org/wiki/Direct_memory_access" target="_blank">DMA</a> mask.</li>
<li>The ethtool (described more below) functions the driver supports are registered.</li>
<li>Any watchdog tasks needed (for example, e1000e has a watchdog task to check if the hardware is hung).</li>
<li>Other device specific stuff like workarounds or dealing with hardware specific quirks or similar.</li>
<li>The creation, initialization, and registration of a <code>struct net_device_ops</code> structure. This structure contains function pointers to the various functions needed for opening the device, sending data to the network, setting the MAC address, and more.</li>
<li>The creation, initialization, and registration of a high level <code>struct net_device</code> which represents a network device.</li>
</ol>
<p>Let&#x2019;s take a quick look at some of these operations in the <code>igb</code> driver in the function <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L2005-L2429" target="_blank"><code>igb_probe</code></a>.</p>
<h5 id="a-peek-into-pci-initialization"><a name="a-peek-into-pci-initialization" class="anchor-navigation-ex-anchor" href="#a-peek-into-pci-initialization"><i class="fa fa-link" aria-hidden="true"></i></a>A peek into PCI initialization</h5>
<p>The following code from the <code>igb_probe</code> function does some basic PCI configuration. From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L2038-L2059" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>:</p>
<pre class="language-"><code class="lang-c">err <span class="token operator">=</span> <span class="token function">pci_enable_device_mem</span><span class="token punctuation">(</span>pdev<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/* ... */</span>

err <span class="token operator">=</span> <span class="token function">dma_set_mask_and_coherent</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>pdev<span class="token operator">-&gt;</span>dev<span class="token punctuation">,</span> <span class="token function">DMA_BIT_MASK</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/* ... */</span>

err <span class="token operator">=</span> <span class="token function">pci_request_selected_regions</span><span class="token punctuation">(</span>pdev<span class="token punctuation">,</span> <span class="token function">pci_select_bars</span><span class="token punctuation">(</span>pdev<span class="token punctuation">,</span>
           IORESOURCE_MEM<span class="token punctuation">)</span><span class="token punctuation">,</span>
           igb_driver_name<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">pci_enable_pcie_error_reporting</span><span class="token punctuation">(</span>pdev<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">pci_set_master</span><span class="token punctuation">(</span>pdev<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">pci_save_state</span><span class="token punctuation">(</span>pdev<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>First, the device is initialized with <code>pci_enable_device_mem</code>. This will wake up the device if it is suspended, enable memory resources, and more.</p>
<p>Next, the <a href="https://en.wikipedia.org/wiki/Direct_memory_access" target="_blank">DMA</a> mask will be set. This device can read and write to 64bit memory addresses, so <code>dma_set_mask_and_coherent</code> is called with <code>DMA_BIT_MASK(64)</code>.</p>
<p>Memory regions will be reserved with a call to <code>pci_request_selected_regions</code>, <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/PCI/pcieaer-howto.txt" target="_blank">PCI Express Advanced Error Reporting</a> is enabled (if the PCI AER driver is loaded), DMA is enabled with a call to <code>pci_set_master</code>, and the PCI configuration space is saved with a call to <code>pci_save_state</code>.</p>
<p>Phew.</p>
<h4 id="more-linux-pci-driver-information"><a name="more-linux-pci-driver-information" class="anchor-navigation-ex-anchor" href="#more-linux-pci-driver-information"><i class="fa fa-link" aria-hidden="true"></i></a>More Linux PCI driver information</h4>
<p>Going into the full explanation of how PCI devices work is beyond the scope of this post, but <a href="http://free-electrons.com/doc/pci-drivers.pdf" target="_blank">this excellent talk</a>, <a href="http://wiki.osdev.org/PCI" target="_blank">this wiki</a>, and <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/PCI/pci.txt" target="_blank">this text file from the linux kernel</a> are excellent resources.</p>
<h3 id="network-device-initialization"><a name="network-device-initialization" class="anchor-navigation-ex-anchor" href="#network-device-initialization"><i class="fa fa-link" aria-hidden="true"></i></a>4.1.2. Network device initialization</h3>
<p>The <code>igb_probe</code> function does some important network device initialization. In addition to the PCI specific work, it will do more general networking and network device work:</p>
<ol>
<li>The <code>struct net_device_ops</code> is registered.</li>
<li><code>ethtool</code> operations are registered.</li>
<li>The default MAC address is obtained from the NIC.</li>
<li><code>net_device</code> feature flags are set.</li>
<li>And lots more.</li>
</ol>
<p>Let&#x2019;s take a look at each of these as they will be interesting later.</p>
<h4 id="struct-netdeviceops"><a name="struct-netdeviceops" class="anchor-navigation-ex-anchor" href="#struct-netdeviceops"><i class="fa fa-link" aria-hidden="true"></i></a><code>struct net_device_ops</code></h4>
<p>The <code>struct net_device_ops</code> contains function pointers to lots of important operations that the network subsystem needs to control the device. We&#x2019;ll be mentioning this structure many times throughout the rest of this post.</p>
<p>This <code>net_device_ops</code> structure is attached to a <code>struct net_device</code> in <code>igb_probe</code>. From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L2090" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>)</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">igb_probe</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">pci_dev</span> <span class="token operator">*</span>pdev<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">pci_device_id</span> <span class="token operator">*</span>ent<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token comment">/* ... */</span>

  netdev<span class="token operator">-&gt;</span>netdev_ops <span class="token operator">=</span> <span class="token operator">&amp;</span>igb_netdev_ops<span class="token punctuation">;</span>
</code></pre>
<p>And the functions that this <code>net_device_ops</code> structure holds pointers to are set in the same file. From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L1905-L1913" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">net_device_ops</span> igb_netdev_ops <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token punctuation">.</span>ndo_open               <span class="token operator">=</span> igb_open<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>ndo_stop               <span class="token operator">=</span> igb_close<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>ndo_start_xmit         <span class="token operator">=</span> igb_xmit_frame<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>ndo_get_stats64        <span class="token operator">=</span> igb_get_stats64<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>ndo_set_rx_mode        <span class="token operator">=</span> igb_set_rx_mode<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>ndo_set_mac_address    <span class="token operator">=</span> igb_set_mac<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>ndo_change_mtu         <span class="token operator">=</span> igb_change_mtu<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>ndo_do_ioctl           <span class="token operator">=</span> igb_ioctl<span class="token punctuation">,</span>

  <span class="token comment">/* ... */</span>
</code></pre>
<p>As you can see, there are several interesting fields in this <code>struct</code> like <code>ndo_open</code>, <code>ndo_stop</code>, <code>ndo_start_xmit</code>, and <code>ndo_get_stats64</code> which hold the addresses of functions implemented by the <code>igb</code> driver.</p>
<p>We&#x2019;ll be looking at some of these in more detail later.</p>
<h4 id="ethtool-registration"><a name="ethtool-registration" class="anchor-navigation-ex-anchor" href="#ethtool-registration"><i class="fa fa-link" aria-hidden="true"></i></a><code>ethtool</code> registration</h4>
<p><a href="https://www.kernel.org/pub/software/network/ethtool/" target="_blank"><code>ethtool</code></a> is a command line program you can use to get and set various driver and hardware options. You can install it on Ubuntu by running <code>apt-get install ethtool</code>.</p>
<p>A common use of <code>ethtool</code> is to gather detailed statistics from network devices. Other <code>ethtool</code> settings of interest will be described later.</p>
<p>The <code>ethtool</code> program talks to device drivers by using the <a href="http://man7.org/linux/man-pages/man2/ioctl.2.html" target="_blank"><code>ioctl</code></a> system call. The device drivers register a series of functions that run for the <code>ethtool</code> operations and the kernel provides the glue.</p>
<p>When an <code>ioctl</code> call is made from <code>ethtool</code>, the kernel finds the <code>ethtool</code> structure registered by the appropriate driver and executes the functions registered. The driver&#x2019;s <code>ethtool</code> function implementation can do anything from change a simple software flag in the driver to adjusting how the actual NIC hardware works by writing register values to the device.</p>
<p>The <code>igb</code> driver registers its <code>ethtool</code> operations in <code>igb_probe</code> by calling <code>igb_set_ethtool_ops</code>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">igb_probe</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">pci_dev</span> <span class="token operator">*</span>pdev<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">pci_device_id</span> <span class="token operator">*</span>ent<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token comment">/* ... */</span>

  <span class="token function">igb_set_ethtool_ops</span><span class="token punctuation">(</span>netdev<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>All of the <code>igb</code> driver&#x2019;s <code>ethtool</code> code can be found in the file <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_ethtool.c" target="_blank"><code>drivers/net/ethernet/intel/igb/igb_ethtool.c</code></a> along with the <code>igb_set_ethtool_ops</code> function.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_ethtool.c#L3012-L3015" target="_blank"><code>drivers/net/ethernet/intel/igb/igb_ethtool.c</code></a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">void</span> <span class="token function">igb_set_ethtool_ops</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">net_device</span> <span class="token operator">*</span>netdev<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token function">SET_ETHTOOL_OPS</span><span class="token punctuation">(</span>netdev<span class="token punctuation">,</span> <span class="token operator">&amp;</span>igb_ethtool_ops<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Above that, you can find the <code>igb_ethtool_ops</code> structure with the <code>ethtool</code> functions the <code>igb</code> driver supports set to the appropriate fields.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_ethtool.c#L2970-L2979" target="_blank"><code>drivers/net/ethernet/intel/igb/igb_ethtool.c</code></a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">ethtool_ops</span> igb_ethtool_ops <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token punctuation">.</span>get_settings           <span class="token operator">=</span> igb_get_settings<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>set_settings           <span class="token operator">=</span> igb_set_settings<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>get_drvinfo            <span class="token operator">=</span> igb_get_drvinfo<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>get_regs_len           <span class="token operator">=</span> igb_get_regs_len<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>get_regs               <span class="token operator">=</span> igb_get_regs<span class="token punctuation">,</span>
  <span class="token comment">/* ... */</span>
</code></pre>
<p>It is up to the individual drivers to determine which <code>ethtool</code> functions are relevant and which should be implemented. Not all drivers implement all <code>ethtool</code> functions, unfortunately.</p>
<p>One interesting <code>ethtool</code> function is <code>get_ethtool_stats</code>, which (if implemented) produces detailed statistics counters that are tracked either in software in the driver or via the device itself.</p>
<p>The monitoring section below will show how to use <code>ethtool</code> to access these detailed statistics.</p>
<h4 id="irqs"><a name="irqs" class="anchor-navigation-ex-anchor" href="#irqs"><i class="fa fa-link" aria-hidden="true"></i></a>IRQs</h4>
<p>When a data frame is written to RAM via <a href="https://en.wikipedia.org/wiki/Direct_memory_access" target="_blank">DMA</a>, how does the NIC tell the rest of the system that data is ready to be processed?</p>
<p>Traditionally, a NIC would generate an <a href="https://en.wikipedia.org/wiki/Interrupt_request_(PC_architecture" target="_blank">interrupt request (IRQ)</a>) indicating data had arrived. There are three common types of IRQs: MSI-X, MSI, and legacy IRQs. These will be touched upon shortly. A device generating an IRQ when data has been written to RAM via DMA is simple enough, but if large numbers of data frames arrive this can lead to a large number of IRQs being generated. The more IRQs that are generated, the less CPU time is available for higher level tasks like user processes.</p>
<p>The <a href="http://www.linuxfoundation.org/collaborate/workgroups/networking/napi" target="_blank">New Api (NAPI)</a> was created as a mechanism for reducing the number of IRQs generated by network devices on packet arrival. While NAPI reduces the number of IRQs, it cannot eliminate them completely.</p>
<p>We&#x2019;ll see why that is, exactly, in later sections.</p>
<h4 id="napi"><a name="napi" class="anchor-navigation-ex-anchor" href="#napi"><i class="fa fa-link" aria-hidden="true"></i></a>NAPI</h4>
<p><a href="http://www.linuxfoundation.org/collaborate/workgroups/networking/napi" target="_blank">NAPI</a> differs from the legacy method of harvesting data in several important ways. NAPI allows a device driver to register a <code>poll</code> function that the NAPI subsystem will call to harvest data frames.</p>
<p>The intended use of NAPI in network device drivers is as follows:</p>
<ol>
<li>NAPI is enabled by the driver, but is in the off position initially.</li>
<li>A packet arrives and is DMA&#x2019;d to memory by the NIC.</li>
<li>An IRQ is generated by the NIC which triggers the IRQ handler in the driver.</li>
<li>The driver wakes up the NAPI subsystem using a softirq (more on these later). This will begin harvesting packets by calling the driver&#x2019;s registered <code>poll</code> function in a separate thread of execution.</li>
<li>The driver should disable further IRQs from the NIC. This is done to allow the NAPI subsystem to process packets without interruption from the device.</li>
<li>Once there is no more work to do, the NAPI subsystem is disabled and IRQs from the device are re-enabled.</li>
<li>The process starts back at step 2.</li>
</ol>
<p>This method of gathering data frames has reduced overhead compared to the legacy method because many data frames can be consumed at a time without having to deal with processing each of them one IRQ at a time.</p>
<p>The device driver implements a <code>poll</code> function and registers it with NAPI by calling <code>netif_napi_add</code>. When registering a NAPI <code>poll</code> function with <code>netif_napi_add</code>, the driver will also specify the <code>weight</code>. Most of the drivers hardcode a value of <code>64</code>. This value and its meaning will be described in more detail below.</p>
<p>Typically, drivers register their NAPI <code>poll</code> functions during driver initialization.</p>
<h4 id="napi-initialization-in-the-igb-driver"><a name="napi-initialization-in-the-igb-driver" class="anchor-navigation-ex-anchor" href="#napi-initialization-in-the-igb-driver"><i class="fa fa-link" aria-hidden="true"></i></a>NAPI initialization in the <code>igb</code> driver</h4>
<p>The <code>igb</code> driver does this via a long call chain:</p>
<ol>
<li><code>igb_probe</code> calls <code>igb_sw_init</code>.</li>
<li><code>igb_sw_init</code> calls <code>igb_init_interrupt_scheme</code>.</li>
<li><code>igb_init_interrupt_scheme</code> calls <code>igb_alloc_q_vectors</code>.</li>
<li><code>igb_alloc_q_vectors</code> calls <code>igb_alloc_q_vector</code>.</li>
<li><code>igb_alloc_q_vector</code> calls <code>netif_napi_add</code>.</li>
</ol>
<p>This call trace results in a few high level things happening:</p>
<ol>
<li>If <a href="https://en.wikipedia.org/wiki/Message_Signaled_Interrupts#MSI-X" target="_blank">MSI-X</a> is supported, it will be enabled with a call to <code>pci_enable_msix</code>.</li>
<li>Various settings are computed and initialized; most notably the number of transmit and receive queues that the device and driver will use for sending and receiving packets.</li>
<li><code>igb_alloc_q_vector</code> is called once for every transmit and receive queue that will be created.</li>
<li>Each call to <code>igb_alloc_q_vector</code> calls <code>netif_napi_add</code> to register a <code>poll</code> function for that queue and an instance of <code>struct napi_struct</code> that will be passed to <code>poll</code> when called to harvest packets.</li>
</ol>
<p>Let&#x2019;s take a look at <code>igb_alloc_q_vector</code> to see how the <code>poll</code> callback and its private data are registered.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L1145-L1271" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">igb_alloc_q_vector</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">igb_adapter</span> <span class="token operator">*</span>adapter<span class="token punctuation">,</span>
                              <span class="token keyword">int</span> v_count<span class="token punctuation">,</span> <span class="token keyword">int</span> v_idx<span class="token punctuation">,</span>
                              <span class="token keyword">int</span> txr_count<span class="token punctuation">,</span> <span class="token keyword">int</span> txr_idx<span class="token punctuation">,</span>
                              <span class="token keyword">int</span> rxr_count<span class="token punctuation">,</span> <span class="token keyword">int</span> rxr_idx<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token comment">/* ... */</span>

  <span class="token comment">/* allocate q_vector and rings */</span>
  q_vector <span class="token operator">=</span> <span class="token function">kzalloc</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> GFP_KERNEL<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>q_vector<span class="token punctuation">)</span>
          <span class="token keyword">return</span> <span class="token operator">-</span>ENOMEM<span class="token punctuation">;</span>

  <span class="token comment">/* initialize NAPI */</span>
  <span class="token function">netif_napi_add</span><span class="token punctuation">(</span>adapter<span class="token operator">-&gt;</span>netdev<span class="token punctuation">,</span> <span class="token operator">&amp;</span>q_vector<span class="token operator">-&gt;</span>napi<span class="token punctuation">,</span> igb_poll<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">/* ... */</span>
</code></pre>
<p>The above code is allocation memory for a receive queue and registering the function <code>igb_poll</code> with the NAPI subsystem. It provides a reference to the <code>struct napi_struct</code> associated with this newly created RX queue (<code>&amp;q_vector-&gt;napi</code> above). This will be passed into <code>igb_poll</code> when called by the NAPI subsystem when it comes time to harvest packets from this RX queue.</p>
<p>This will be important later when we examine the flow of data from drivers up the network stack.</p>
<h3 id="bringing-a-network-device-up"><a name="bringing-a-network-device-up" class="anchor-navigation-ex-anchor" href="#bringing-a-network-device-up"><i class="fa fa-link" aria-hidden="true"></i></a>4.1.3. Bringing a network device up</h3>
<p>Recall the <code>net_device_ops</code> structure we saw earlier which registered a set of functions for bringing the network device up, transmitting packets, setting the MAC address, etc.</p>
<p>When a network device is brought up (for example, with <code>ifconfig eth0 up</code>), the function attached to the <code>ndo_open</code> field of the <code>net_device_ops</code> structure is called.</p>
<p>The <code>ndo_open</code> function will typically do things like:</p>
<ol>
<li>Allocate RX and TX queue memory</li>
<li>Enable NAPI</li>
<li>Register an interrupt handler</li>
<li>Enable hardware interrupts</li>
<li>And more.</li>
</ol>
<p>In the case of the <code>igb</code> driver, the function attached to the <code>ndo_open</code> field of the <code>net_device_ops</code> structure is called <code>igb_open</code>.</p>
<h5 id="preparing-to-receive-data-from-the-network"><a name="preparing-to-receive-data-from-the-network" class="anchor-navigation-ex-anchor" href="#preparing-to-receive-data-from-the-network"><i class="fa fa-link" aria-hidden="true"></i></a>Preparing to receive data from the network</h5>
<p>Most NICs you&#x2019;ll find today will use <a href="https://en.wikipedia.org/wiki/Direct_memory_access" target="_blank">DMA</a> to write data directly into RAM where the OS can retrieve the data for processing. The data structure most NICs use for this purpose resembles a queue built on circular buffer (or a ring buffer).</p>
<p>In order to do this, the device driver must work with the OS to reserve a region of memory that the NIC hardware can use. Once this region is reserved, the hardware is informed of its location and incoming data will be written to RAM where it will later be picked up and processed by the networking subsystem.</p>
<p>This seems simple enough, but what if the packet rate was high enough that a single CPU was not able to properly process all incoming packets? The data structure is built on a fixed length region of memory, so incoming packets would be dropped.</p>
<p>This is where something known as known as <a href="https://en.wikipedia.org/wiki/Network_interface_controller#RSS" target="_blank">Receive Side Scaling (RSS)</a> or multiqueue can help.</p>
<p>Some devices have the ability to write incoming packets to several different regions of RAM simultaneously; each region is a separate queue. This allows the OS to use multiple CPUs to process incoming data in parallel, starting at the hardware level. This feature is not supported by all NICs.</p>
<p>The Intel I350 NIC does support multiple queues. We can see evidence of this in the <code>igb</code> driver. One of the first things the <code>igb</code> driver does when it is brought up is call a function named <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L2801-L2804" target="_blank"><code>igb_setup_all_rx_resources</code></a>. This function calls another function, <code>igb_setup_rx_resources</code>, once for each RX queue to arrange for DMA-able memory where the device will write incoming data.</p>
<p>If you are curious how exactly this works, please see the <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/DMA-API-HOWTO.txt" target="_blank">Linux kernel&#x2019;s DMA API HOWTO</a>.</p>
<p>It turns out the number and size of the RX queues can be tuned by using <code>ethtool</code>. Tuning these values can have a noticeable impact on the number of frames which are processed vs the number of frames which are dropped.</p>
<p>The NIC uses a hash function on the packet header fields (like source, destination, port, etc) to determine which RX queue the data should be directed to.</p>
<p>Some NICs let you adjust the weight of the RX queues, so you can send more traffic to specific queues.</p>
<p>Fewer NICs let you adjust this hash function itself. If you can adjust the hash function, you can send certain flows to specific RX queues for processing or even drop the packets at the hardware level, if desired.</p>
<p>We&#x2019;ll take a look at how to tune these settings shortly.</p>
<h5 id="enable-napi"><a name="enable-napi" class="anchor-navigation-ex-anchor" href="#enable-napi"><i class="fa fa-link" aria-hidden="true"></i></a>Enable NAPI</h5>
<p>When a network device is brought up, a driver will usually enable <a href="http://www.linuxfoundation.org/collaborate/workgroups/networking/napi" target="_blank">NAPI</a>.</p>
<p>We saw earlier how drivers register <code>poll</code> functions with NAPI, but NAPI is not usually enabled until the device is brought up.</p>
<p>Enabling NAPI is relatively straight forward. A call to <code>napi_enable</code> will flip a bit in the <code>struct napi_struct</code> to indicate that it is now enabled. As mentioned above, while NAPI will be enabled it will be in the off position.</p>
<p>In the case of the <code>igb</code> driver, NAPI is enabled for each <code>q_vector</code> that was initialized when the driver was loaded or when the queue count or size are changed with <code>ethtool</code>.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L2833-L2834" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> adapter<span class="token operator">-&gt;</span>num_q_vectors<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>
  <span class="token function">napi_enable</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>adapter<span class="token operator">-&gt;</span>q_vector<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">-&gt;</span>napi<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<h5 id="register-an-interrupt-handler"><a name="register-an-interrupt-handler" class="anchor-navigation-ex-anchor" href="#register-an-interrupt-handler"><i class="fa fa-link" aria-hidden="true"></i></a>Register an interrupt handler</h5>
<p>After enabling NAPI, the next step is to register an interrupt handler. There are different methods a device can use to signal an interrupt: MSI-X, MSI, and legacy interrupts. As such, the code differs from device to device depending on what the supported interrupt methods are for a particular piece of hardware.</p>
<p>The driver must determine which method is supported by the device and register the appropriate handler function that will execute when the interrupt is received.</p>
<p>Some drivers, like the <code>igb</code> driver, will try to register an interrupt handler with each method, falling back to the next untested method on failure.</p>
<p>MSI-X interrupts are the preferred method, especially for NICs that support multiple RX queues. This is because each RX queue can have its own hardware interrupt assigned, which can then be handled by a specific CPU (with <code>irqbalance</code> or by modifying <code>/proc/irq/IRQ_NUMBER/smp_affinity</code>). As we&#x2019;ll see shortly, the CPU that handles the interrupt will be the CPU that processes the packet. In this way, arriving packets can be processed by separate CPUs from the hardware interrupt level up through the networking stack.</p>
<p>If MSI-X is unavailable, MSI still presents advantages over legacy interrupts and will be used by the driver if the device supports it. Read <a href="https://en.wikipedia.org/wiki/Message_Signaled_Interrupts" target="_blank">this useful wiki page</a> for more information about MSI and MSI-X.</p>
<p>In the <code>igb</code> driver, the functions <code>igb_msix_ring</code>, <code>igb_intr_msi</code>, <code>igb_intr</code> are the interrupt handler methods for the MSI-X, MSI, and legacy interrupt modes, respectively.</p>
<p>You can find the code in the driver which attempts each interrupt method in <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L1360-L1413" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">igb_request_irq</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">igb_adapter</span> <span class="token operator">*</span>adapter<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token keyword">struct</span> <span class="token class-name">net_device</span> <span class="token operator">*</span>netdev <span class="token operator">=</span> adapter<span class="token operator">-&gt;</span>netdev<span class="token punctuation">;</span>
  <span class="token keyword">struct</span> <span class="token class-name">pci_dev</span> <span class="token operator">*</span>pdev <span class="token operator">=</span> adapter<span class="token operator">-&gt;</span>pdev<span class="token punctuation">;</span>
  <span class="token keyword">int</span> err <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span>adapter<span class="token operator">-&gt;</span>msix_entries<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    err <span class="token operator">=</span> <span class="token function">igb_request_msix</span><span class="token punctuation">(</span>adapter<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>err<span class="token punctuation">)</span>
      <span class="token keyword">goto</span> request_done<span class="token punctuation">;</span>
    <span class="token comment">/* fall back to MSI */</span>

    <span class="token comment">/* ... */</span>
  <span class="token punctuation">}</span>

  <span class="token comment">/* ... */</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span>adapter<span class="token operator">-&gt;</span>flags <span class="token operator">&amp;</span> IGB_FLAG_HAS_MSI<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    err <span class="token operator">=</span> <span class="token function">request_irq</span><span class="token punctuation">(</span>pdev<span class="token operator">-&gt;</span>irq<span class="token punctuation">,</span> igb_intr_msi<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>
          netdev<span class="token operator">-&gt;</span>name<span class="token punctuation">,</span> adapter<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>err<span class="token punctuation">)</span>
      <span class="token keyword">goto</span> request_done<span class="token punctuation">;</span>

    <span class="token comment">/* fall back to legacy interrupts */</span>

    <span class="token comment">/* ... */</span>
  <span class="token punctuation">}</span>

  err <span class="token operator">=</span> <span class="token function">request_irq</span><span class="token punctuation">(</span>pdev<span class="token operator">-&gt;</span>irq<span class="token punctuation">,</span> igb_intr<span class="token punctuation">,</span> IRQF_SHARED<span class="token punctuation">,</span>
        netdev<span class="token operator">-&gt;</span>name<span class="token punctuation">,</span> adapter<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span>err<span class="token punctuation">)</span>
    <span class="token function">dev_err</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>pdev<span class="token operator">-&gt;</span>dev<span class="token punctuation">,</span> <span class="token string">&quot;Error %d getting interrupt\n&quot;</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span><span class="token punctuation">;</span>

request_done<span class="token operator">:</span>
  <span class="token keyword">return</span> err<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>As you can see in the abbreviated code above, the driver first attempts to set an MSI-X interrupt handler with <code>igb_request_msix</code>, falling back to MSI on failure. Next, <code>request_irq</code> is used to register <code>igb_intr_msi</code>, the MSI interrupt handler. If this fails, the driver falls back to legacy interrupts. <code>request_irq</code> is used again to register the legacy interrupt handler <code>igb_intr</code>.</p>
<p>And this is how the <code>igb</code> driver registers a function that will be executed when the NIC raises an interrupt signaling that data has arrived and is ready for processing.</p>
<h5 id="enable-interrupts"><a name="enable-interrupts" class="anchor-navigation-ex-anchor" href="#enable-interrupts"><i class="fa fa-link" aria-hidden="true"></i></a>Enable Interrupts</h5>
<p>At this point, almost everything is setup. The only thing left is to enable interrupts from the NIC and wait for data to arrive. Enabling interrupts is hardware specific, but the <code>igb</code> driver does this in <code>__igb_open</code> by calling a helper function named <code>igb_irq_enable</code>.</p>
<p>Interrupts are enabled for this device by writing to registers:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">igb_irq_enable</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">igb_adapter</span> <span class="token operator">*</span>adapter<span class="token punctuation">)</span>
<span class="token punctuation">{</span>

  <span class="token comment">/* ... */</span>

    <span class="token function">wr32</span><span class="token punctuation">(</span>E1000_IMS<span class="token punctuation">,</span> IMS_ENABLE_MASK <span class="token operator">|</span> E1000_IMS_DRSTA<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">wr32</span><span class="token punctuation">(</span>E1000_IAM<span class="token punctuation">,</span> IMS_ENABLE_MASK <span class="token operator">|</span> E1000_IMS_DRSTA<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">/* ... */</span>
<span class="token punctuation">}</span>
</code></pre>
<h5 id="the-network-device-is-now-up"><a name="the-network-device-is-now-up" class="anchor-navigation-ex-anchor" href="#the-network-device-is-now-up"><i class="fa fa-link" aria-hidden="true"></i></a>The network device is now up</h5>
<p>Drivers may do a few more things like start timers, work queues, or other hardware-specific setup. Once that is completed. the network device is up and ready for use.</p>
<p>Let&#x2019;s take a look at monitoring and tuning settings for network device drivers.</p>
<h3 id="monitoring-network-devices"><a name="monitoring-network-devices" class="anchor-navigation-ex-anchor" href="#monitoring-network-devices"><i class="fa fa-link" aria-hidden="true"></i></a>4.1.4. Monitoring network devices</h3>
<p>There are several different ways to monitor your network devices offering different levels of granularity and complexity. Let&#x2019;s start with most granular and move to least granular.</p>
<h4 id="using-ethtool--s"><a name="using-ethtool--s" class="anchor-navigation-ex-anchor" href="#using-ethtool--s"><i class="fa fa-link" aria-hidden="true"></i></a>Using <code>ethtool -S</code></h4>
<p>You can install <code>ethtool</code> on an Ubuntu system by running: <code>sudo apt-get install ethtool</code>.</p>
<p>Once it is installed, you can access the statistics by passing the <code>-S</code> flag along with the name of the network device you want statistics about.</p>
<p>Monitor detailed NIC device statistics (e.g., packet drops) with <code>ethtool -S</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-S</span> eth0
NIC statistics:
     rx_packets: <span class="token number">597028087</span>
     tx_packets: <span class="token number">5924278060</span>
     rx_bytes: <span class="token number">112643393747</span>
     tx_bytes: <span class="token number">990080156714</span>
     rx_broadcast: <span class="token number">96</span>
     tx_broadcast: <span class="token number">116</span>
     rx_multicast: <span class="token number">20294528</span>
     <span class="token punctuation">..</span><span class="token punctuation">..</span>
</code></pre>
<p>Monitoring this data can be difficult. It is easy to obtain, but there is no standardization of the field values. Different drivers, or even different versions of the <em>same</em> driver might produce different field names that have the same meaning.</p>
<p>You should look for values with &#x201C;drop&#x201D;, &#x201C;buffer&#x201D;, &#x201C;miss&#x201D;, etc in the label. Next, you will have to read your driver source. You&#x2019;ll be able to determine which values are accounted for totally in software (e.g., incremented when there is no memory) and which values come directly from hardware via a register read. In the case of a register value, you should consult the data sheet for your hardware to determine what the meaning of the counter really is; many of the labels given via <code>ethtool</code> can be misleading.</p>
<h4 id="using-sysfs"><a name="using-sysfs" class="anchor-navigation-ex-anchor" href="#using-sysfs"><i class="fa fa-link" aria-hidden="true"></i></a>Using sysfs</h4>
<p>sysfs also provides a lot of statistics values, but they are slightly higher level than the direct NIC level stats provided.</p>
<p>You can find the number of dropped incoming network data frames for, e.g. eth0 by using <code>cat</code> on a file.</p>
<p>Monitor higher level NIC statistics with sysfs.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /sys/class/net/eth0/statistics/rx_dropped
<span class="token number">2</span>
</code></pre>
<p>The counter values will be split into files like <code>collisions</code>, <code>rx_dropped</code>, <code>rx_errors</code>, <code>rx_missed_errors</code>, etc.</p>
<p>Unfortunately, it is up to the drivers to decide what the meaning of each field is, and thus, when to increment them and where the values come from. You may notice that some drivers count a certain type of error condition as a drop, but other drivers may count the same as a miss.</p>
<p>If these values are critical to you, you will need to read your driver source to understand exactly what your driver thinks each of these values means.</p>
<h4 id="using-procnetdev"><a name="using-procnetdev" class="anchor-navigation-ex-anchor" href="#using-procnetdev"><i class="fa fa-link" aria-hidden="true"></i></a>Using <code>/proc/net/dev</code></h4>
<p>An even higher level file is <code>/proc/net/dev</code> which provides high-level summary-esque information for each network adapter on the system.</p>
<p>Monitor high level NIC statistics by reading <code>/proc/net/dev</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/net/dev
Inter-<span class="token operator">|</span>   Receive                                                <span class="token operator">|</span>  Transmit
 face <span class="token operator">|</span>bytes    packets errs drop fifo frame compressed multicast<span class="token operator">|</span>bytes    packets errs drop fifo colls carrier compressed
  eth0: <span class="token number">110346752214</span> <span class="token number">597737500</span>    <span class="token number">0</span>    <span class="token number">2</span>    <span class="token number">0</span>     <span class="token number">0</span>          <span class="token number">0</span>  <span class="token number">20963860</span> <span class="token number">990024805984</span> <span class="token number">6066582604</span>    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>       <span class="token number">0</span>          <span class="token number">0</span>
    lo: <span class="token number">428349463836</span> <span class="token number">1579868535</span>    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>          <span class="token number">0</span>         <span class="token number">0</span> <span class="token number">428349463836</span> <span class="token number">1579868535</span>    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>       <span class="token number">0</span>          <span class="token number">0</span>
</code></pre>
<p>This file shows a subset of the values you&#x2019;ll find in the sysfs files mentioned above, but it may serve as a useful general reference.</p>
<p>The caveat mentioned above applies here, as well: if these values are important to you, you will still need to read your driver source to understand exactly when, where, and why they are incremented to ensure your understanding of an error, drop, or fifo are the same as your driver.</p>
<h3 id="tuning-network-devices"><a name="tuning-network-devices" class="anchor-navigation-ex-anchor" href="#tuning-network-devices"><i class="fa fa-link" aria-hidden="true"></i></a>4.1.5. Tuning network devices</h3>
<h4 id="check-the-number-of-rx-queues-being-used"><a name="check-the-number-of-rx-queues-being-used" class="anchor-navigation-ex-anchor" href="#check-the-number-of-rx-queues-being-used"><i class="fa fa-link" aria-hidden="true"></i></a>Check the number of RX queues being used</h4>
<p>If your NIC and the device driver loaded on your system support RSS / multiqueue, you can usually adjust the number of RX queues (also called RX channels), by using <code>ethtool</code>.</p>
<p>Check the number of NIC receive queues with <code>ethtool</code></p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-l</span> eth0
Channel parameters <span class="token keyword">for</span> eth0:
Pre-set maximums:
RX:   <span class="token number">0</span>
TX:   <span class="token number">0</span>
Other:    <span class="token number">0</span>
Combined: <span class="token number">8</span>
Current hardware settings:
RX:   <span class="token number">0</span>
TX:   <span class="token number">0</span>
Other:    <span class="token number">0</span>
Combined: <span class="token number">4</span>
</code></pre>
<p>This output is displaying the pre-set maximums (enforced by the driver and the hardware) and the current settings.</p>
<p><strong>Note:</strong> not all device drivers will have support for this operation.</p>
<p>Error seen if your NIC doesn&apos;t support this operation.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-l</span> eth0
Channel parameters <span class="token keyword">for</span> eth0:
Cannot get device channel parameters
<span class="token builtin class-name">:</span> Operation not supported
</code></pre>
<p>This means that your driver has not implemented the ethtool <code>get_channels</code> operation. This could be because the NIC doesn&#x2019;t support adjusting the number of queues, doesn&#x2019;t support RSS / multiqueue, or your driver has not been updated to handle this feature.</p>
<h4 id="adjusting-the-number-of-rx-queues"><a name="adjusting-the-number-of-rx-queues" class="anchor-navigation-ex-anchor" href="#adjusting-the-number-of-rx-queues"><i class="fa fa-link" aria-hidden="true"></i></a>Adjusting the number of RX queues</h4>
<p>Once you&#x2019;ve found the current and maximum queue count, you can adjust the values by using <code>sudo ethtool -L</code>.</p>
<p><strong>Note:</strong> some devices and their drivers only support combined queues that are paired for transmit and receive, as in the example in the above section.</p>
<p>Set combined NIC transmit and receive queues to 8 with <code>ethtool -L</code></p>
<p><code>$ sudo ethtool -L eth0 combined 8</code></p>
<p>If your device and driver support individual settings for RX and TX and you&#x2019;d like to change only the RX queue count to 8, you would run:</p>
<p>Set the number of NIC receive queues to 8 with <code>ethtool -L</code>.</p>
<p><code>$ sudo ethtool -L eth0 rx 8</code></p>
<p><strong>Note:</strong> making these changes will, for most drivers, take the interface down and then bring it back up; connections to this interface will be interrupted. This may not matter much for a one-time change, though.</p>
<h4 id="adjusting-the-size-of-the-rx-queues"><a name="adjusting-the-size-of-the-rx-queues" class="anchor-navigation-ex-anchor" href="#adjusting-the-size-of-the-rx-queues"><i class="fa fa-link" aria-hidden="true"></i></a>Adjusting the size of the RX queues</h4>
<p>Some NICs and their drivers also support adjusting the size of the RX queue. Exactly how this works is hardware specific, but luckily <code>ethtool</code> provides a generic way for users to adjust the size. Increasing the size of the RX queue can help prevent network data drops at the NIC during periods where large numbers of data frames are received. Data may still be dropped in software, though, and other tuning is required to reduce or eliminate drops completely.</p>
<p>Check current NIC queue sizes with <code>ethtool -g</code></p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-g</span> eth0
Ring parameters <span class="token keyword">for</span> eth0:
Pre-set maximums:
RX:   <span class="token number">4096</span>
RX Mini:  <span class="token number">0</span>
RX Jumbo: <span class="token number">0</span>
TX:   <span class="token number">4096</span>
Current hardware settings:
RX:   <span class="token number">512</span>
RX Mini:  <span class="token number">0</span>
RX Jumbo: <span class="token number">0</span>
TX:   <span class="token number">512</span>
</code></pre>
<p>the above output indicates that the hardware supports up to 4096 receive and transmit descriptors, but it is currently only using 512.</p>
<p>Increase size of each RX queue to 4096 with <code>ethtool -G</code></p>
<p><code>$ sudo ethtool -G eth0 rx 4096</code></p>
<p><strong>Note:</strong> making these changes will, for most drivers, take the interface down and then bring it back up; connections to this interface will be interrupted. This may not matter much for a one-time change, though.</p>
<h4 id="adjusting-the-processing-weight-of-rx-queues"><a name="adjusting-the-processing-weight-of-rx-queues" class="anchor-navigation-ex-anchor" href="#adjusting-the-processing-weight-of-rx-queues"><i class="fa fa-link" aria-hidden="true"></i></a>Adjusting the processing weight of RX queues</h4>
<p>Some NICs support the ability to adjust the distribution of network data among the RX queues by setting a weight.</p>
<p>You can configure this if:</p>
<ul>
<li>Your NIC supports flow indirection.</li>
<li>Your driver implements the <code>ethtool</code> functions <code>get_rxfh_indir_size</code> and <code>get_rxfh_indir</code>.</li>
<li>You are running a new enough version of <code>ethtool</code> that has support for the command line options <code>-x</code> and <code>-X</code> to show and set the indirection table, respectively.</li>
</ul>
<p>Check the RX flow indirection table with <code>ethtool -x</code></p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-x</span> eth0
RX flow <span class="token builtin class-name">hash</span> indirection table <span class="token keyword">for</span> eth3 with <span class="token number">2</span> RX ring<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:
<span class="token number">0</span>: <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span>
<span class="token number">8</span>: <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span>
<span class="token number">16</span>: <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span>
<span class="token number">24</span>: <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span>
</code></pre>
<p>This output shows packet hash values on the left, with receive queue 0 and 1 listed. So, a packet which hashes to 2 will be delivered to receive queue 0, while a packet which hashes to 3 will be delivered to receive queue 1.</p>
<p>Example: spread processing evenly between first 2 RX queues</p>
<p><code>$ sudo ethtool -X eth0 equal 2</code></p>
<p>If you want to set custom weights to alter the number of packets which hit certain receive queues (and thus CPUs), you can specify those on the command line, as well:</p>
<p>Set custom RX queue weights with <code>ethtool -X</code></p>
<p><code>$ sudo ethtool -X eth0 weight 6 2</code></p>
<p>The above command specifies a weight of 6 for rx queue 0 and 2 for rx queue 1, pushing much more data to be processed on queue 0.</p>
<p>Some NICs will also let you adjust the fields which be used in the hash algorithm, as we&#x2019;ll see now.</p>
<h4 id="adjusting-the-rx-hash-fields-for-network-flows"><a name="adjusting-the-rx-hash-fields-for-network-flows" class="anchor-navigation-ex-anchor" href="#adjusting-the-rx-hash-fields-for-network-flows"><i class="fa fa-link" aria-hidden="true"></i></a>Adjusting the rx hash fields for network flows</h4>
<p>You can use <code>ethtool</code> to adjust the fields that will be used when computing a hash for use with RSS.</p>
<p>Check which fields are used for UDP RX flow hash with <code>ethtool -n</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-n</span> eth0 rx-flow-hash udp4
UDP over IPV4 flows use these fields <span class="token keyword">for</span> computing Hash flow key:
IP SA
IP DA
</code></pre>
<p>For eth0, the fields that are used for computing a hash on UDP flows is the IPv4 source and destination addresses. Let&#x2019;s include the source and destination ports:</p>
<p>Set UDP RX flow hash fields with <code>ethtool -N</code>.</p>
<p><code>$ sudo ethtool -N eth0 rx-flow-hash udp4 sdfn</code></p>
<p>The <code>sdfn</code> string is a bit cryptic; check the <code>ethtool</code> man page for an explanation of each letter.</p>
<p>Adjusting the fields to take a hash on is useful, but <code>ntuple</code> filtering is even more useful for finer grained control over which flows will be handled by which RX queue.</p>
<h4 id="ntuple-filtering-for-steering-network-flows"><a name="ntuple-filtering-for-steering-network-flows" class="anchor-navigation-ex-anchor" href="#ntuple-filtering-for-steering-network-flows"><i class="fa fa-link" aria-hidden="true"></i></a>ntuple filtering for steering network flows</h4>
<p>Some NICs support a feature known as &#x201C;ntuple filtering.&#x201D; This feature allows the user to specify (via <code>ethtool</code>) a set of parameters to use to filter incoming network data in hardware and queue it to a particular RX queue. For example, the user can specify that TCP packets destined to a particular port should be sent to RX queue 1.</p>
<p>On Intel NICs this feature is commonly known as <a href="http://www.intel.com/content/www/us/en/ethernet-products/ethernet-flow-director-video.html" target="_blank">Intel Ethernet Flow Director</a>. Other NIC vendors may have other marketing names for this feature.</p>
<p>As we&#x2019;ll see later, ntuple filtering is a crucial component of another feature called Accelerated Receive Flow Steering (aRFS), which makes using ntuple much easier if your NIC supports it. aRFS will be covered later.</p>
<p>This feature can be useful if the operational requirements of the system involve maximizing data locality with the hope of increasing CPU cache hit rates when processing network data. For example consider the following configuration for a webserver running on port 80:</p>
<ul>
<li>A webserver running on port 80 is pinned to run on CPU 2.</li>
<li>IRQs for an RX queue are assigned to be processed by CPU 2.</li>
<li>TCP traffic destined to port 80 is &#x2018;filtered&#x2019; with ntuple to CPU 2.</li>
<li>All incoming traffic to port 80 is then processed by CPU 2 starting at data arrival to the userland program.</li>
<li>Careful monitoring of the system including cache hit rates and networking stack latency will be needed to determine effectiveness.</li>
</ul>
<p>As mentioned, ntuple filtering can be configured with <code>ethtool</code>, but first, you&#x2019;ll need to ensure that this feature is enabled on your device.</p>
<p>Check if ntuple filters are enabled with <code>ethtool -k</code></p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-k</span> eth0
Offload parameters <span class="token keyword">for</span> eth0:
<span class="token punctuation">..</span>.
ntuple-filters: off
receive-hashing: on
</code></pre>
<p>As you can see, <code>ntuple-filters</code> are set to off on this device.</p>
<p>Enable ntuple filters with <code>ethtool -K</code></p>
<p><code>$ sudo ethtool -K eth0 ntuple on</code></p>
<p>Once you&#x2019;ve enabled ntuple filters, or verified that it is enabled, you can check the existing ntuple rules by using <code>ethtool</code>:</p>
<p>Check existing ntuple filters with <code>ethtool -u</code></p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-u</span> eth0
<span class="token number">40</span> RX rings available
Total <span class="token number">0</span> rules
</code></pre>
<p>As you can see, this device has no ntuple filter rules. You can add a rule by specifying it on the command line to <code>ethtool</code>. Let&#x2019;s add a rule to direct all TCP traffic with a destination port of 80 to RX queue 2:</p>
<p>Add ntuple filter to send TCP flows with destination port 80 to RX queue 2</p>
<p><code>$ sudo ethtool -U eth0 flow-type tcp4 dst-port 80 action 2</code></p>
<p>You can also use ntuple filtering to drop packets for particular flows at the hardware level. This can be useful for mitigating heavy incoming traffic from specific IP addresses. For more information about configuring ntuple filter rules, see the <code>ethtool</code> man page.</p>
<p>You can usually get statistics about the success (or failure) of your ntuple rules by checking values output from <code>ethtool -S [device name]</code>. For example, on Intel NICs, the statistics <code>fdir_match</code> and <code>fdir_miss</code> calculate the number of matches and misses for your ntuple filtering rules. Consult your device driver source and device data sheet for tracking down statistics counters (if available).</p>
<h2 id="softirqs"><a name="softirqs" class="anchor-navigation-ex-anchor" href="#softirqs"><i class="fa fa-link" aria-hidden="true"></i></a>4.2. SoftIRQs</h2>
<p>Before examining the network stack, we&#x2019;ll need to take a short detour to examine something in the Linux kernel called SoftIRQs.</p>
<h3 id="what-is-a-softirq"><a name="what-is-a-softirq" class="anchor-navigation-ex-anchor" href="#what-is-a-softirq"><i class="fa fa-link" aria-hidden="true"></i></a>4.2.1. What is a softirq?</h3>
<p>The softirq system in the Linux kernel is a mechanism for executing code outside of the context of an interrupt handler implemented in a driver. This system is important because hardware interrupts may be disabled during all or part of the execution of an interrupt handler. The longer interrupts are disabled, the greater chance that events may be missed. So, it is important to defer any long running actions outside of the interrupt handler so that it can complete as quickly as possible and re-enable interrupts from the device.</p>
<p>There are other mechanisms that can be used for deferring work in the kernel, but for the purposes of the networking stack, we&#x2019;ll be looking at softirqs.</p>
<p>The softirq system can be imagined as a series of kernel threads (one per CPU) that run handler functions which have been registered for different softirq events. If you&#x2019;ve ever looked at top and seen <code>ksoftirqd/0</code> in the list of kernel threads, you were looking at the softirq kernel thread running on CPU 0.</p>
<p>Kernel subsystems (like networking) can register a softirq handler by executing the <code>open_softirq</code> function. We&#x2019;ll see later how the networking system registers its softirq handlers. For now, let&#x2019;s learn a bit more about how softirqs work.</p>
<h3 id="ksoftirqd"><a name="ksoftirqd" class="anchor-navigation-ex-anchor" href="#ksoftirqd"><i class="fa fa-link" aria-hidden="true"></i></a>4.2.2. ksoftirqd</h3>
<p>Since softirqs are so important for deferring the work of device drivers, you might imagine that the <code>ksoftirqd</code> process is spawned pretty early in the life cycle of the kernel and you&#x2019;d be correct.</p>
<p>Looking at the code found in <a href="https://github.com/torvalds/linux/blob/v3.13/kernel/softirq.c#L743-L758" target="_blank">kernel/softirq.c</a> reveals how the <code>ksoftirqd</code> system is initialized:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">struct</span> <span class="token class-name">smp_hotplug_thread</span> softirq_threads <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token punctuation">.</span>store              <span class="token operator">=</span> <span class="token operator">&amp;</span>ksoftirqd<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>thread_should_run  <span class="token operator">=</span> ksoftirqd_should_run<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>thread_fn          <span class="token operator">=</span> run_ksoftirqd<span class="token punctuation">,</span>
  <span class="token punctuation">.</span>thread_comm        <span class="token operator">=</span> <span class="token string">&quot;ksoftirqd/%u&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>

<span class="token keyword">static</span> __init <span class="token keyword">int</span> <span class="token function">spawn_ksoftirqd</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token function">register_cpu_notifier</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cpu_nfb<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token function">BUG_ON</span><span class="token punctuation">(</span><span class="token function">smpboot_register_percpu_thread</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>softirq_threads<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token function">early_initcall</span><span class="token punctuation">(</span>spawn_ksoftirqd<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>As you can see from the <code>struct smp_hotplug_thread</code> definition above, there are two function pointers being registered: <code>ksoftirqd_should_run</code> and <code>run_ksoftirqd</code>.</p>
<p>Both of these functions are called from <a href="https://github.com/torvalds/linux/blob/v3.13/kernel/smpboot.c#L94-L163" target="_blank">kernel/smpboot.c</a> as part of something which resembles an event loop.</p>
<p>The code in <code>kernel/smpboot.c</code> first calls <code>ksoftirqd_should_run</code> which determines if there are any pending softirqs and, if there are pending softirqs, <code>run_ksoftirqd</code> is executed. The <code>run_ksoftirqd</code> does some minor bookkeeping before it calls <code>__do_softirq</code>.</p>
<h3 id="dosoftirq"><a name="dosoftirq" class="anchor-navigation-ex-anchor" href="#dosoftirq"><i class="fa fa-link" aria-hidden="true"></i></a>4.2.3. __do_softirq</h3>
<p>The <code>__do_softirq</code> function does a few interesting things:</p>
<ul>
<li>determines which softirq is pending</li>
<li>softirq time is accounted for statistics purposes</li>
<li>softirq execution statistics are incremented</li>
<li>the softirq handler for the pending softirq (which was registered with a call to <code>open_softirq</code>) is executed.</li>
</ul>
<p>So, when you look at graphs of CPU usage and see <code>softirq</code> or <code>si</code> you now know that this is measuring the amount of CPU usage happening in a deferred work context.</p>
<h3 id="monitoring"><a name="monitoring" class="anchor-navigation-ex-anchor" href="#monitoring"><i class="fa fa-link" aria-hidden="true"></i></a>4.2.4. Monitoring</h3>
<h4 id="procsoftirqs"><a name="procsoftirqs" class="anchor-navigation-ex-anchor" href="#procsoftirqs"><i class="fa fa-link" aria-hidden="true"></i></a><code>/proc/softirqs</code></h4>
<p>The <code>softirq</code> system increments statistic counters which can be read from <code>/proc/softirqs</code> Monitoring these statistics can give you a sense for the rate at which softirqs for various events are being generated.</p>
<p>Check softIRQ stats by reading <code>/proc/softirqs</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/softirqs
                    CPU0       CPU1       CPU2       CPU3
          HI:          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span>
       TIMER: <span class="token number">2831512516</span> <span class="token number">1337085411</span> <span class="token number">1103326083</span> <span class="token number">1423923272</span>
      NET_TX:   <span class="token number">15774435</span>     <span class="token number">779806</span>     <span class="token number">733217</span>     <span class="token number">749512</span>
      NET_RX: <span class="token number">1671622615</span> <span class="token number">1257853535</span> <span class="token number">2088429526</span> <span class="token number">2674732223</span>
       BLOCK: <span class="token number">1800253852</span>    <span class="token number">1466177</span>    <span class="token number">1791366</span>     <span class="token number">634534</span>
BLOCK_IOPOLL:          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span>
     TASKLET:         <span class="token number">25</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span>
       SCHED: <span class="token number">2642378225</span> <span class="token number">1711756029</span>  <span class="token number">629040543</span>  <span class="token number">682215771</span>
     HRTIMER:    <span class="token number">2547911</span>    <span class="token number">2046898</span>    <span class="token number">1558136</span>    <span class="token number">1521176</span>
         RCU: <span class="token number">2056528783</span> <span class="token number">4231862865</span> <span class="token number">3545088730</span>  <span class="token number">844379888</span>
</code></pre>
<p>This file can give you an idea of how your network receive (<code>NET_RX</code>) processing is currently distributed across your CPUs. If it is distributed unevenly, you will see a larger count value for some CPUs than others. This is one indicator that you might be able to benefit from Receive Packet Steering / Receive Flow Steering described below. Be careful using just this file when monitoring your performance: during periods of high network activity you would expect to see the rate <code>NET_RX</code> increments increase, but this isn&#x2019;t necessarily the case. It turns out that this is a bit nuanced, because there are additional tuning knobs in the network stack that can affect the rate at which <code>NET_RX</code> softirqs will fire, which we&#x2019;ll see soon.</p>
<p>You should be aware of this, however, so that if you adjust the other tuning knobs you will know to examine <code>/proc/softirqs</code> and expect to see a change.</p>
<p>Now, let&#x2019;s move on to the networking stack and trace how network data is received from top to bottom.</p>
<h2 id="linux-network-device-subsystem"><a name="linux-network-device-subsystem" class="anchor-navigation-ex-anchor" href="#linux-network-device-subsystem"><i class="fa fa-link" aria-hidden="true"></i></a>4.3. Linux network device subsystem</h2>
<p>Now that we&#x2019;ve taken a look in to how network drivers and softirqs work, let&#x2019;s see how the Linux network device subsystem is initialized. Then, we can follow the path of a packet starting with its arrival.</p>
<h3 id="initialization-of-network-device-subsystem"><a name="initialization-of-network-device-subsystem" class="anchor-navigation-ex-anchor" href="#initialization-of-network-device-subsystem"><i class="fa fa-link" aria-hidden="true"></i></a>4.3.1. Initialization of network device subsystem</h3>
<p>The network device (netdev) subsystem is initialized in the function <code>net_dev_init</code>. Lots of interesting things happen in this initialization function.</p>
<h4 id="initialization-of-struct-softnetdata-structures"><a name="initialization-of-struct-softnetdata-structures" class="anchor-navigation-ex-anchor" href="#initialization-of-struct-softnetdata-structures"><i class="fa fa-link" aria-hidden="true"></i></a>Initialization of <code>struct softnet_data</code> structures</h4>
<p><code>net_dev_init</code> creates a set of <code>struct softnet_data</code> structures for each CPU on the system. These structures will hold pointers to several important things for processing network data:</p>
<ul>
<li>List for NAPI structures to be registered to this CPU.</li>
<li>A backlog for data processing.</li>
<li>The processing <code>weight</code>.</li>
<li>The <a href="https://en.wikipedia.org/wiki/Large_receive_offload" target="_blank">receive offload</a> structure list.</li>
<li><a href="https://lwn.net/Articles/362339/" target="_blank">Receive packet steering</a> settings.</li>
<li>And more.</li>
</ul>
<p>Each of these will be examined in greater detail later as we progress up the stack.</p>
<h4 id="initialization-of-softirq-handlers"><a name="initialization-of-softirq-handlers" class="anchor-navigation-ex-anchor" href="#initialization-of-softirq-handlers"><i class="fa fa-link" aria-hidden="true"></i></a>Initialization of softirq handlers</h4>
<p><code>net_dev_init</code> registers a transmit and receive softirq handler which will be used to process incoming or outgoing network data. The code for this is pretty straight forward:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">int</span> __init <span class="token function">net_dev_init</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token comment">/* ... */</span>

  <span class="token function">open_softirq</span><span class="token punctuation">(</span>NET_TX_SOFTIRQ<span class="token punctuation">,</span> net_tx_action<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">open_softirq</span><span class="token punctuation">(</span>NET_RX_SOFTIRQ<span class="token punctuation">,</span> net_rx_action<span class="token punctuation">)</span><span class="token punctuation">;</span>

 <span class="token comment">/* ... */</span>
<span class="token punctuation">}</span>
</code></pre>
<p>We&#x2019;ll see soon how the driver&#x2019;s interrupt handler will &#x201C;raise&#x201D; (or trigger) the <code>net_rx_action</code> function registered to the <code>NET_RX_SOFTIRQ</code> softirq.</p>
<h3 id="data-arrives"><a name="data-arrives" class="anchor-navigation-ex-anchor" href="#data-arrives"><i class="fa fa-link" aria-hidden="true"></i></a>4.3.2. Data arrives</h3>
<p>At long last; network data arrives!</p>
<p>Assuming that the RX queue has enough available descriptors, the packet is written to RAM via DMA. The device then raises the interrupt that is assigned to it (or in the case of MSI-X, the interrupt tied to the rx queue the packet arrived on).</p>
<h4 id="interrupt-handler"><a name="interrupt-handler" class="anchor-navigation-ex-anchor" href="#interrupt-handler"><i class="fa fa-link" aria-hidden="true"></i></a>Interrupt handler</h4>
<p>In general, the interrupt handler which runs when an interrupt is raised should try to defer as much processing as possible to happen outside the interrupt context. This is crucial because while an interrupt is being processed, other interrupts may be blocked.</p>
<p>Let&#x2019;s take a look at the source for the MSI-X interrupt handler; it will really help illustrate the idea that the interrupt handler does as little work as possible.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L5148-L5158" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token class-name">irqreturn_t</span> <span class="token function">igb_msix_ring</span><span class="token punctuation">(</span><span class="token keyword">int</span> irq<span class="token punctuation">,</span> <span class="token keyword">void</span> <span class="token operator">*</span>data<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token keyword">struct</span> <span class="token class-name">igb_q_vector</span> <span class="token operator">*</span>q_vector <span class="token operator">=</span> data<span class="token punctuation">;</span>

  <span class="token comment">/* Write the ITR value calculated from the previous interrupt. */</span>
  <span class="token function">igb_write_itr</span><span class="token punctuation">(</span>q_vector<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token function">napi_schedule</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>q_vector<span class="token operator">-&gt;</span>napi<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">return</span> IRQ_HANDLED<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>This interrupt handler is very short and performs 2 very quick operations before returning.</p>
<p>First, this function calls <code>igb_write_itr</code> which simply updates a hardware specific register. In this case, the register that is updated is one which is used to track the rate hardware interrupts are arriving.</p>
<p>This register is used in conjunction with a hardware feature called &#x201C;Interrupt Throttling&#x201D; (also called &#x201C;Interrupt Coalescing&#x201D;) which can be used to to pace the delivery of interrupts to the CPU. We&#x2019;ll see soon how <code>ethtool</code> provides a mechanism for adjusting the rate at which IRQs fire.</p>
<p>Secondly, <code>napi_schedule</code> is called which wakes up the NAPI processing loop if it was not already active. Note that the NAPI processing loop executes in a softirq; the NAPI processing loop does not execute from the interrupt handler. The interrupt handler simply causes it to start executing if it was not already.</p>
<p>The actual code showing exactly how this works is important; it will guide our understanding of how network data is processed on multi-CPU systems.</p>
<h4 id="napi-and-napischedule"><a name="napi-and-napischedule" class="anchor-navigation-ex-anchor" href="#napi-and-napischedule"><i class="fa fa-link" aria-hidden="true"></i></a>NAPI and <code>napi_schedule</code></h4>
<p>Let&#x2019;s figure out how the <code>napi_schedule</code> call from the hardware interrupt handler works.</p>
<p>Remember, NAPI exists specifically to harvest network data without needing interrupts from the NIC to signal that data is ready for processing. As mentioned earlier, the NAPI <code>poll</code> loop is bootstrapped by receiving a hardware interrupt. In other words: NAPI is enabled, but off, until the first packet arrives at which point the NIC raises an IRQ and NAPI is started. There are a few other cases, as we&#x2019;ll see soon, where NAPI can be disabled and will need a hardware interrupt to be raised before it will be started again.</p>
<p>The NAPI poll loop is started when the interrupt handler in the driver calls <code>napi_schedule</code>. <code>napi_schedule</code> is actually just a wrapper function defined in a header file which calls down to <code>__napi_schedule</code>.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L4154-L4168" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/**
 * __napi_schedule - schedule for receive
 * @n: entry to schedule
 *
 * The entry&apos;s receive function will be scheduled to run
 */</span>
<span class="token keyword">void</span> <span class="token function">__napi_schedule</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">napi_struct</span> <span class="token operator">*</span>n<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token keyword">unsigned</span> <span class="token keyword">long</span> flags<span class="token punctuation">;</span>

  <span class="token function">local_irq_save</span><span class="token punctuation">(</span>flags<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">____napi_schedule</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token function">__get_cpu_var</span><span class="token punctuation">(</span>softnet_data<span class="token punctuation">)</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">local_irq_restore</span><span class="token punctuation">(</span>flags<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token function">EXPORT_SYMBOL</span><span class="token punctuation">(</span>__napi_schedule<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>This code is using <code>__get_cpu_var</code> to get the <code>softnet_data</code> structure that is registered to the current CPU. This <code>softnet_data</code> structure and the <code>struct napi_struct</code> structure handed up from the driver are passed into <code>____napi_schedule</code>. Wow, that&#x2019;s a lot of underscores ;)</p>
<p>Let&#x2019;s take a look at <code>____napi_schedule</code>, from <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L2914-L2920" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/* Called with irq disabled */</span>
<span class="token keyword">static</span> <span class="token keyword">inline</span> <span class="token keyword">void</span> <span class="token function">____napi_schedule</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">softnet_data</span> <span class="token operator">*</span>sd<span class="token punctuation">,</span>
                                     <span class="token keyword">struct</span> <span class="token class-name">napi_struct</span> <span class="token operator">*</span>napi<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
  <span class="token function">list_add_tail</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>napi<span class="token operator">-&gt;</span>poll_list<span class="token punctuation">,</span> <span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>poll_list<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">__raise_softirq_irqoff</span><span class="token punctuation">(</span>NET_RX_SOFTIRQ<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>This code does two important things:</p>
<ol>
<li>The <code>struct napi_struct</code> handed up from the device driver&#x2019;s interrupt handler code is added to the <code>poll_list</code> attached to the <code>softnet_data</code> structure associated with the current CPU.</li>
<li><code>__raise_softirq_irqoff</code> is used to &#x201C;raise&#x201D; (or trigger) a NET_RX_SOFTIRQ softirq. This will cause the <code>net_rx_action</code> registered during the network device subsystem initialization to be executed, if it&#x2019;s not currently being executed.</li>
</ol>
<p>As we&#x2019;ll see shortly, the softirq handler function <code>net_rx_action</code> will call the NAPI <code>poll</code> function to harvest packets.</p>
<h4 id="a-note-about-cpu-and-network-data-processing"><a name="a-note-about-cpu-and-network-data-processing" class="anchor-navigation-ex-anchor" href="#a-note-about-cpu-and-network-data-processing"><i class="fa fa-link" aria-hidden="true"></i></a>A note about CPU and network data processing</h4>
<p>Note that all the code we&#x2019;ve seen so far to defer work from a hardware interrupt handler to a softirq has been using structures associated with the current CPU.</p>
<p>While the driver&#x2019;s IRQ handler itself does very little work itself, the softirq handler will execute on the same CPU as the driver&#x2019;s IRQ handler.</p>
<p>This why setting the CPU a particular IRQ will be handled by is important: that CPU will be used not only to execute the interrupt handler in the driver, but the same CPU will also be used when harvesting packets in a softirq via NAPI.</p>
<p>As we&#x2019;ll see later, things like <a href="https://lwn.net/Articles/362339/" target="_blank">Receive Packet Steering</a> can distribute some of this work to other CPUs further up the network stack.</p>
<h4 id="monitoring-network-data-arrival"><a name="monitoring-network-data-arrival" class="anchor-navigation-ex-anchor" href="#monitoring-network-data-arrival"><i class="fa fa-link" aria-hidden="true"></i></a>Monitoring network data arrival</h4>
<h5 id="hardware-interrupt-requests"><a name="hardware-interrupt-requests" class="anchor-navigation-ex-anchor" href="#hardware-interrupt-requests"><i class="fa fa-link" aria-hidden="true"></i></a>Hardware interrupt requests</h5>
<p><strong>Note:</strong> monitoring hardware IRQs does not give a complete picture of packet processing health. Many drivers turn off hardware IRQs while NAPI is running, as we&apos;ll see later. It is one important part of your whole monitoring solution.</p>
<p>Check hardware interrupt stats by reading <code>/proc/interrupts</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/interrupts
            CPU0       CPU1       CPU2       CPU3
   <span class="token number">0</span>:         <span class="token number">46</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-IO-APIC-edge      timer
   <span class="token number">1</span>:          <span class="token number">3</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-IO-APIC-edge      i8042
  <span class="token number">30</span>: <span class="token number">3361234770</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-IO-APIC-fasteoi   aacraid
  <span class="token number">64</span>:          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> DMAR_MSI-edge      dmar0
  <span class="token number">65</span>:          <span class="token number">1</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-PCI-MSI-edge      eth0
  <span class="token number">66</span>:  <span class="token number">863649703</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-PCI-MSI-edge      eth0-TxRx-0
  <span class="token number">67</span>:  <span class="token number">986285573</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-PCI-MSI-edge      eth0-TxRx-1
  <span class="token number">68</span>:         <span class="token number">45</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-PCI-MSI-edge      eth0-TxRx-2
  <span class="token number">69</span>:        <span class="token number">394</span>          <span class="token number">0</span>          <span class="token number">0</span>          <span class="token number">0</span> IR-PCI-MSI-edge      eth0-TxRx-3
 NMI:    <span class="token number">9729927</span>    <span class="token number">4008190</span>    <span class="token number">3068645</span>    <span class="token number">3375402</span>  Non-maskable interrupts
 LOC: <span class="token number">2913290785</span> <span class="token number">1585321306</span> <span class="token number">1495872829</span> <span class="token number">1803524526</span>  Local timer interrupts
</code></pre>
<p>You can monitor the statistics in <code>/proc/interrupts</code> to see how the number and rate of hardware interrupts change as packets arrive and to ensure that each RX queue for your NIC is being handled by an appropriate CPU. As we&#x2019;ll see shortly, this number only tells us how many hardware interrupts have happened, but it is <em>not</em> necessarily a good metric for understanding how much data has been received or processed as many drivers will disable NIC IRQs as part of their contract with the NAPI subsystem. Further, using interrupt coalescing will also affect the statistics gathered from this file. Monitoring this file can help you determine if the interrupt coalescing settings you select are actually working.</p>
<p>To get a more complete picture of your network processing health, you&#x2019;ll need to monitor <code>/proc/softirqs</code> (as mentioned above) and additional files in <code>/proc</code> that we&#x2019;ll cover below.</p>
<h4 id="tuning-network-data-arrival"><a name="tuning-network-data-arrival" class="anchor-navigation-ex-anchor" href="#tuning-network-data-arrival"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning network data arrival</h4>
<h5 id="interrupt-coalescing"><a name="interrupt-coalescing" class="anchor-navigation-ex-anchor" href="#interrupt-coalescing"><i class="fa fa-link" aria-hidden="true"></i></a>Interrupt coalescing</h5>
<p><a href="https://en.wikipedia.org/wiki/Interrupt_coalescing" target="_blank">Interrupt coalescing</a> is a method of preventing interrupts from being raised by a device to a CPU until a specific amount of work or number of events are pending.</p>
<p>This can help prevent <a href="https://en.wikipedia.org/wiki/Interrupt_storm" target="_blank">interrupt storms</a> and can help increase throughput or latency, depending on the settings used. Fewer interrupts generated result in higher throughput, increased latency, and lower CPU usage. More interrupts generated result in the opposite: lower latency, lower throughput, but also increased CPU usage.</p>
<p>Historically, earlier versions of the <code>igb</code>, <code>e1000</code>, and other drivers included support for a parameter called <code>InterruptThrottleRate</code>. This parameter has been replaced in more recent drivers with a generic <code>ethtool</code> function.</p>
<p>Get the current IRQ coalescing settings with <code>ethtool -c</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-c</span> eth0
Coalesce parameters <span class="token keyword">for</span> eth0:
Adaptive RX: off  TX: off
stats-block-usecs: <span class="token number">0</span>
sample-interval: <span class="token number">0</span>
pkt-rate-low: <span class="token number">0</span>
pkt-rate-high: <span class="token number">0</span>
<span class="token punctuation">..</span>.
</code></pre>
<p><code>ethtool</code> provides a generic interface for setting various coalescing settings. Keep in mind, however, that not every device or driver will support every setting. You should check your driver documentation or driver source code to determine what is, or is not, supported. As per the ethtool documentation: &#x201C;Anything not implemented by the driver causes these values to be silently ignored.&#x201D;</p>
<p>One interesting option that some drivers support is &#x201C;adaptive RX/TX IRQ coalescing.&#x201D; This option is typically implemented in hardware. The driver usually needs to do some work to inform the NIC that this feature is enabled and some bookkeeping as well (as seen in the <code>igb</code> driver code above).</p>
<p>The result of enabling adaptive RX/TX IRQ coalescing is that interrupt delivery will be adjusted to improve latency when packet rate is low and also improve throughput when packet rate is high.</p>
<p>Enable adaptive RX IRQ coalescing with <code>ethtool -C</code></p>
<p><code>$ sudo ethtool -C eth0 adaptive-rx on</code></p>
<p>You can also use <code>ethtool -C</code> to set several options. Some of the more common options to set are:</p>
<ul>
<li><code>rx-usecs</code>: How many usecs to delay an RX interrupt after a packet arrives.</li>
<li><code>rx-frames</code>: Maximum number of data frames to receive before an RX interrupt.</li>
<li><code>rx-usecs-irq</code>: How many usecs to delay an RX interrupt while an interrupt is being serviced by the host.</li>
<li><code>rx-frames-irq</code>: Maximum number of data frames to receive before an RX interrupt is generated while the system is servicing an interrupt.</li>
</ul>
<p>And many, many more.</p>
<p><strong>Reminder</strong> that your hardware and driver may only support a subset of the options listed above. You should consult your driver source code and your hardware data sheet for more information on supported coalescing options.</p>
<p>Unfortunately, the options you can set aren&#x2019;t well documented anywhere except in a header file. Check the source of <a href="https://github.com/torvalds/linux/blob/v3.13/include/uapi/linux/ethtool.h#L184-L255" target="_blank">include/uapi/linux/ethtool.h</a> to find an explanation of each option supported by <code>ethtool</code> (but not necessarily your driver and NIC).</p>
<p><strong>Note:</strong> while interrupt coalescing seems to be a very useful optimization at first glance, the rest of the networking stack internals also come into the fold when attempting to optimize. Interrupt coalescing can be useful in some cases, but you should ensure that the rest of your networking stack is also tuned properly. Simply modifying your coalescing settings alone will likely provide minimal benefit in and of itself.</p>
<h5 id="adjusting-irq-affinities"><a name="adjusting-irq-affinities" class="anchor-navigation-ex-anchor" href="#adjusting-irq-affinities"><i class="fa fa-link" aria-hidden="true"></i></a>Adjusting IRQ affinities</h5>
<p>If your NIC supports RSS / multiqueue or if you are attempting to optimize for data locality, you may wish to use a specific set of CPUs for handling interrupts generated by your NIC.</p>
<p>Setting specific CPUs allows you to segment which CPUs will be used for processing which IRQs. These changes may affect how upper layers operate, as we&#x2019;ve seen for the networking stack.</p>
<p>If you do decide to adjust your IRQ affinities, you should first check if you running the <code>irqbalance</code> daemon. This daemon tries to automatically balance IRQs to CPUs and it may overwrite your settings. If you are running <code>irqbalance</code>, you should either disable <code>irqbalance</code> or use the <code>--banirq</code> in conjunction with <code>IRQBALANCE_BANNED_CPUS</code> to let <code>irqbalance</code> know that it shouldn&#x2019;t touch a set of IRQs and CPUs that you want to assign yourself.</p>
<p>Next, you should check the file <code>/proc/interrupts</code> for a list of the IRQ numbers for each network RX queue for your NIC.</p>
<p>Finally, you can adjust the which CPUs each of those IRQs will be handled by modifying <code>/proc/irq/IRQ_NUMBER/smp_affinity</code> for each IRQ number.</p>
<p>You simply write a hexadecimal bitmask to this file to instruct the kernel which CPUs it should use for handling the IRQ.</p>
<p>Example: Set the IRQ affinity for IRQ 8 to CPU 0</p>
<p><code>$ sudo bash -c &apos;echo 1 &gt; /proc/irq/8/smp_affinity&apos;</code></p>
<h3 id="network-data-processing-begins"><a name="network-data-processing-begins" class="anchor-navigation-ex-anchor" href="#network-data-processing-begins"><i class="fa fa-link" aria-hidden="true"></i></a>4.3.3. Network data processing begins</h3>
<p>Once the softirq code determines that a softirq is pending, begins processing, and executes <code>net_rx_action</code>, network data processing begins.</p>
<p>Let&#x2019;s take a look at portions of the <code>net_rx_action</code> processing loop to understand how it works, which pieces are tunable, and what can be monitored.</p>
<h4 id="netrxaction-processing-loop"><a name="netrxaction-processing-loop" class="anchor-navigation-ex-anchor" href="#netrxaction-processing-loop"><i class="fa fa-link" aria-hidden="true"></i></a><code>net_rx_action</code> processing loop</h4>
<p><code>net_rx_action</code> begins the processing of packets from the memory the packets were DMA&#x2019;d into by the device.</p>
<p>The function iterates through the list of NAPI structures that are queued for the current CPU, dequeuing each structure, and operating on it.</p>
<p>The processing loop bounds the amount of work and execution time that can be consumed by the registered NAPI <code>poll</code> functions. It does this in two ways:</p>
<ol>
<li>By keeping track of a work <code>budget</code> (which can be adjusted), and</li>
<li>Checking the elapsed time</li>
</ol>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L4300-L4309" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c">  <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">list_empty</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>poll_list<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">struct</span> <span class="token class-name">napi_struct</span> <span class="token operator">*</span>n<span class="token punctuation">;</span>
    <span class="token keyword">int</span> work<span class="token punctuation">,</span> weight<span class="token punctuation">;</span>

    <span class="token comment">/* If softirq window is exhausted then punt.
     * Allow this to run for 2 jiffies since which will allow
     * an average latency of 1.5/HZ.
     */</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span>budget <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token operator">||</span> <span class="token function">time_after_eq</span><span class="token punctuation">(</span>jiffies<span class="token punctuation">,</span> time_limit<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token keyword">goto</span> softnet_break<span class="token punctuation">;</span>
</code></pre>
<p>This is how the kernel prevents packet processing from consuming the entire CPU. The <code>budget</code> above is the total available budget that will be spent among each of the available NAPI structures registered to this CPU.</p>
<p>This is another reason why multiqueue NICs should have the IRQ affinity carefully tuned. Recall that the CPU which handles the IRQ from the device will be the CPU where the softirq handler will execute and, as a result, will also be the CPU where the above loop and budget computation runs.</p>
<p>Systems with multiple NICs each with multiple queues can end up in a situation where multiple NAPI structs are registered to the same CPU. Data processing for all NAPI structs on the same CPU spend from the same <code>budget</code>.</p>
<p>If you don&#x2019;t have enough CPUs to distribute your NIC&#x2019;s IRQs, you can consider increasing the <code>net_rx_action</code> <code>budget</code> to allow for more packet processing for each CPU. Increasing the budget will increase CPU usage (specifically <code>sitime</code> or <code>si</code> in <code>top</code> or other programs), but should reduce latency as data will be processed more promptly.</p>
<p><strong>Note:</strong> the CPU will still be bounded by a time limit of 2 <a href="http://elinux.org/Kernel_Timer_Systems#Timer_Wheel.2C_Jiffies_and_HZ_.28or.2C_the_way_it_was.29" target="_blank">jiffies</a>, regardless of the assigned budget.</p>
<h4 id="napi-poll-function-and-weight"><a name="napi-poll-function-and-weight" class="anchor-navigation-ex-anchor" href="#napi-poll-function-and-weight"><i class="fa fa-link" aria-hidden="true"></i></a>NAPI <code>poll</code> function and <code>weight</code></h4>
<p>Recall that network device drivers use <code>netif_napi_add</code> for registering <code>poll</code> function. As we saw earlier in this post, the <code>igb</code> driver has a piece of code like this:</p>
<pre class="language-"><code class="lang-c">  <span class="token comment">/* initialize NAPI */</span>
  <span class="token function">netif_napi_add</span><span class="token punctuation">(</span>adapter<span class="token operator">-&gt;</span>netdev<span class="token punctuation">,</span> <span class="token operator">&amp;</span>q_vector<span class="token operator">-&gt;</span>napi<span class="token punctuation">,</span> igb_poll<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>This registers a NAPI structure with a hardcoded weight of 64. We&#x2019;ll see now how this is used in the <code>net_rx_action</code> processing loop.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L4322-L4338" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c">weight <span class="token operator">=</span> n<span class="token operator">-&gt;</span>weight<span class="token punctuation">;</span>

work <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">test_bit</span><span class="token punctuation">(</span>NAPI_STATE_SCHED<span class="token punctuation">,</span> <span class="token operator">&amp;</span>n<span class="token operator">-&gt;</span>state<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        work <span class="token operator">=</span> n<span class="token operator">-&gt;</span><span class="token function">poll</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> weight<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">trace_napi_poll</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token function">WARN_ON_ONCE</span><span class="token punctuation">(</span>work <span class="token operator">&gt;</span> weight<span class="token punctuation">)</span><span class="token punctuation">;</span>

budget <span class="token operator">-=</span> work<span class="token punctuation">;</span>
</code></pre>
<p>This code obtains the weight which was registered to the NAPI struct (<code>64</code> in the above driver code) and passes it into the <code>poll</code> function which was also registered to the NAPI struct (<code>igb_poll</code> in the above code).</p>
<p>The <code>poll</code> function returns the number of data frames that were processed. This amount is saved above as <code>work</code>, which is then subtracted from the overall <code>budget</code>.</p>
<p>So, assuming:</p>
<ol>
<li>You are using a weight of <code>64</code> from your driver (all drivers were hardcoded with this value in Linux 3.13.0), and</li>
<li>You have your <code>budget</code> set to the default of <code>300</code></li>
</ol>
<p>Your system would <strong>stop</strong> processing data when either:</p>
<ol>
<li>The <code>igb_poll</code> function was called at most 5 times (less if no data to process as we&#x2019;ll see next), OR</li>
<li>At least 2 jiffies of time have elapsed.</li>
</ol>
<h4 id="the-napi--network-device-driver-contract"><a name="the-napi--network-device-driver-contract" class="anchor-navigation-ex-anchor" href="#the-napi--network-device-driver-contract"><i class="fa fa-link" aria-hidden="true"></i></a>The NAPI / network device driver contract</h4>
<p>One important piece of information about the contract between the NAPI subsystem and device drivers which has not been mentioned yet are the requirements around shutting down NAPI.</p>
<p>This part of the contract is as follows:</p>
<ul>
<li>If a driver&#x2019;s <code>poll</code> function consumes its entire weight (which is hardcoded to <code>64</code>) it must <strong>NOT</strong> modify NAPI state. The <code>net_rx_action</code> loop will take over.</li>
<li>If a driver&#x2019;s <code>poll</code> function does <strong>NOT</strong> consume its entire weight, it must disable NAPI. NAPI will be re-enabled next time an IRQ is received and the driver&#x2019;s IRQ handler calls <code>napi_schedule</code>.</li>
</ul>
<p>We&#x2019;ll see how <code>net_rx_action</code> deals with the first part of that contract now. Next, the <code>poll</code> function is examined, we&#x2019;ll see how the second part of that contract is handled.</p>
<h4 id="finishing-the-netrxaction-loop"><a name="finishing-the-netrxaction-loop" class="anchor-navigation-ex-anchor" href="#finishing-the-netrxaction-loop"><i class="fa fa-link" aria-hidden="true"></i></a>Finishing the <code>net_rx_action</code> loop</h4>
<p>The <code>net_rx_action</code> processing loop finishes up with one last section of code that deals with the first part of the NAPI contract explained in the previous section. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L4342-L4363" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/* Drivers must not modify the NAPI state if they
 * consume the entire weight.  In such cases this code
 * still &quot;owns&quot; the NAPI instance and therefore can
 * move the instance around on the list at-will.
 */</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span>work <span class="token operator">==</span> weight<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span><span class="token function">napi_disable_pending</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token function">local_irq_enable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">napi_complete</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">local_irq_disable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>n<span class="token operator">-&gt;</span>gro_list<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token comment">/* flush too old packets
       * If HZ &lt; 1000, flush all packets.
       */</span>
      <span class="token function">local_irq_enable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token function">napi_gro_flush</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> HZ <span class="token operator">&gt;=</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token function">local_irq_disable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token function">list_move_tail</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>n<span class="token operator">-&gt;</span>poll_list<span class="token punctuation">,</span> <span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>poll_list<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>If the entire work is consumed, there are two cases that <code>net_rx_action</code> handles:</p>
<ol>
<li>The network device should be shutdown (e.g. because the user ran <code>ifconfig eth0 down</code>),</li>
<li>If the device is <em>not</em> being shutdown, check if there&#x2019;s a generic receive offload (GRO) list. If the <a href="http://www.makelinux.net/books/lkd2/ch10lev1sec2" target="_blank">timer tick rate</a> is &gt;= 1000, all GRO&#x2019;d network flows that were recently updated will be flushed. We&#x2019;ll dig into GRO in detail later. Move the NAPI structure to the end of the list for this CPU so the next iteration of the loop will get the next NAPI structure registered.</li>
</ol>
<p>And that is how the packet processing loop invokes the driver&#x2019;s registered <code>poll</code> function to process packets. As we&#x2019;ll see shortly, the <code>poll</code> function will harvest network data and send it up the stack to be processed.</p>
<h4 id="exiting-the-loop-when-limits-are-reached"><a name="exiting-the-loop-when-limits-are-reached" class="anchor-navigation-ex-anchor" href="#exiting-the-loop-when-limits-are-reached"><i class="fa fa-link" aria-hidden="true"></i></a>Exiting the loop when limits are reached</h4>
<p>The <code>net_rx_action</code> loop will exit when either:</p>
<ul>
<li>The poll list registered for this CPU has no more NAPI structures (<code>!list_empty(&amp;sd-&gt;poll_list)</code>), or</li>
<li>The remaining budget is &lt;= 0, or</li>
<li>The time limit of 2 jiffies has been reached</li>
</ul>
<p>Here&#x2019;s this code we saw earlier again:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/* If softirq window is exhausted then punt.
 * Allow this to run for 2 jiffies since which will allow
 * an average latency of 1.5/HZ.
 */</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span>budget <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token operator">||</span> <span class="token function">time_after_eq</span><span class="token punctuation">(</span>jiffies<span class="token punctuation">,</span> time_limit<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">goto</span> softnet_break<span class="token punctuation">;</span>
</code></pre>
<p>If you follow the <code>softnet_break</code> label you stumble upon something interesting. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L4380-L4383" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c">softnet_break<span class="token operator">:</span>
  sd<span class="token operator">-&gt;</span>time_squeeze<span class="token operator">++</span><span class="token punctuation">;</span>
  <span class="token function">__raise_softirq_irqoff</span><span class="token punctuation">(</span>NET_RX_SOFTIRQ<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">goto</span> out<span class="token punctuation">;</span>
</code></pre>
<p>The <code>struct softnet_data</code> structure has some statistics incremented and the softirq <code>NET_RX_SOFTIRQ</code> is shut down. The <code>time_squeeze</code> field is a measure of the number of times <code>net_rx_action</code> had more work to do but either the budget was exhausted or the time limit was reached before it could be completed. This is a <strong>tremendously</strong> useful counter for understanding bottlenecks in network processing. We&#x2019;ll see shortly how to monitor this value. The <code>NET_RX_SOFTIRQ</code> is disabled to free up processing time for other tasks. This makes sense as this small stub of code is only executed when more work could have been done, but we don&#x2019;t want to monopolize the CPU.</p>
<p>Execution is then transferred to the <code>out</code> label. Execution can also make it to the <code>out</code> label if there were no more NAPI structures to process, in other words, there is more budget than there is network activity and all the drivers have shut NAPI off and there is nothing left for <code>net_rx_action</code> to do.</p>
<p>The <code>out</code> section does one important thing before returning from <code>net_rx_action</code>: it calls <code>net_rps_action_and_irq_enable</code>. This function serves an important purpose if <a href="https://lwn.net/Articles/362339/" target="_blank">Receive Packet Steering</a> is enabled; it wakes up remote CPUs to start processing network data.</p>
<p>We&#x2019;ll see more about how RPS works later. For now, let&#x2019;s see how to monitor the health of the <code>net_rx_action</code> processing loop and move on to the inner working of NAPI <code>poll</code> functions so we can progress up the network stack.</p>
<h4 id="napi-poll"><a name="napi-poll" class="anchor-navigation-ex-anchor" href="#napi-poll"><i class="fa fa-link" aria-hidden="true"></i></a>NAPI poll</h4>
<p>Recall in previous sections that device drivers allocate a region of memory for the device to perform DMA to incoming packets. Just as it is the responsibility of the driver to allocate those regions, it is also the responsibility of the driver to unmap those regions, harvest the data, and send it up the network stack.</p>
<p>Let&#x2019;s take a look at how the <code>igb</code> driver does this to get an idea of how this works in practice.</p>
<h5 id="igbpoll"><a name="igbpoll" class="anchor-navigation-ex-anchor" href="#igbpoll"><i class="fa fa-link" aria-hidden="true"></i></a><code>igb_poll</code></h5>
<p>At long last, we can finally examine our friend <code>igb_poll</code>. It turns out the code for <code>igb_poll</code> is deceptively simple. Let&#x2019;s take a look. From <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L5987-L6018" target="_blank">drivers/net/ethernet/intel/igb/igb_main.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/**
 *  igb_poll - NAPI Rx polling callback
 *  @napi: napi polling structure
 *  @budget: count of how many packets we should handle
 **/</span>
<span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">igb_poll</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">napi_struct</span> <span class="token operator">*</span>napi<span class="token punctuation">,</span> <span class="token keyword">int</span> budget<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
        <span class="token keyword">struct</span> <span class="token class-name">igb_q_vector</span> <span class="token operator">*</span>q_vector <span class="token operator">=</span> <span class="token function">container_of</span><span class="token punctuation">(</span>napi<span class="token punctuation">,</span>
                                                     <span class="token keyword">struct</span> <span class="token class-name">igb_q_vector</span><span class="token punctuation">,</span>
                                                     napi<span class="token punctuation">)</span><span class="token punctuation">;</span>
        bool clean_complete <span class="token operator">=</span> true<span class="token punctuation">;</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifdef</span> <span class="token expression">CONFIG_IGB_DCA</span></span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>q_vector<span class="token operator">-&gt;</span>adapter<span class="token operator">-&gt;</span>flags <span class="token operator">&amp;</span> IGB_FLAG_DCA_ENABLED<span class="token punctuation">)</span>
                <span class="token function">igb_update_dca</span><span class="token punctuation">(</span>q_vector<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span>

        <span class="token comment">/* ... */</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>q_vector<span class="token operator">-&gt;</span>rx<span class="token punctuation">.</span>ring<span class="token punctuation">)</span>
                clean_complete <span class="token operator">&amp;=</span> <span class="token function">igb_clean_rx_irq</span><span class="token punctuation">(</span>q_vector<span class="token punctuation">,</span> budget<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">/* If all work not completed, return budget and keep polling */</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>clean_complete<span class="token punctuation">)</span>
                <span class="token keyword">return</span> budget<span class="token punctuation">;</span>

        <span class="token comment">/* If not enough Rx work done, exit the polling mode */</span>
        <span class="token function">napi_complete</span><span class="token punctuation">(</span>napi<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">igb_ring_irq_enable</span><span class="token punctuation">(</span>q_vector<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>This code does a few interesting things:</p>
<ul>
<li>If <a href="https://lwn.net/Articles/247493/" target="_blank">Direct Cache Access (DCA)</a> support is enabled in the kernel, the CPU cache is warmed so that accesses to the RX ring will hit CPU cache. You can read more about DCA in the Extras section at the end of this blog post.</li>
<li>Next, <code>igb_clean_rx_irq</code> is called which does the heavy lifting, as we&#x2019;ll see next.</li>
<li>Next, <code>clean_complete</code> is checked to determine if there was still more work that could have been done. If so, the <code>budget</code> (remember, this was hardcoded to <code>64</code>) is returned. As we saw earlier, <code>net_rx_action</code> will move this NAPI structure to the end of the poll list.</li>
<li>Otherwise, the driver turns off NAPI by calling <code>napi_complete</code> and re-enables interrupts by calling <code>igb_ring_irq_enable</code>. The next interrupt that arrives will re-enable NAPI.</li>
</ul>
<p>Let&#x2019;s see how <code>igb_clean_rx_irq</code> sends network data up the stack.</p>
<h5 id="igbcleanrxirq"><a name="igbcleanrxirq" class="anchor-navigation-ex-anchor" href="#igbcleanrxirq"><i class="fa fa-link" aria-hidden="true"></i></a><code>igb_clean_rx_irq</code></h5>
<p>The <code>igb_clean_rx_irq</code> function is a loop which processes one packet at a time until the <code>budget</code> is reached or no additional data is left to process.</p>
<p>The loop in this function does a few important things:</p>
<ol>
<li>Allocates additional buffers for receiving data as used buffers are cleaned out. Additional buffers are added <code>IGB_RX_BUFFER_WRITE</code> (16) at a time.</li>
<li>Fetch a buffer from the RX queue and store it in an <code>skb</code> structure.</li>
<li>Check if the buffer is an &#x201C;End of Packet&#x201D; buffer. If so, continue processing. Otherwise, continue fetching additional buffers from the RX queue, adding them to the <code>skb</code>. This is necessary if a received data frame is larger than the buffer size.</li>
<li>Verify that the layout and headers of the data are correct.</li>
<li>The number of bytes processed statistic counter is increased by <code>skb-&gt;len</code>.</li>
<li>Set the hash, checksum, timestamp, VLAN id, and protocol fields of the skb. The hash, checksum, timestamp, and VLAN id are provided by the hardware. If the hardware is signaling a checksum error, the <code>csum_error</code> statistic is incremented. If the checksum succeeded and the data is UDP or TCP data, the <code>skb</code> is marked as <code>CHECKSUM_UNNECESSARY</code>. If the checksum failed, the protocol stacks are left to deal with this packet. The protocol is computed with a call to <code>eth_type_trans</code> and stored in the <code>skb</code> struct.</li>
<li>The constructed <code>skb</code> is handed up the network stack with a call to <code>napi_gro_receive</code>.</li>
<li>The number of packets processed statistics counter is incremented.</li>
<li>The loop continues until the number of packets processed reaches the budget.</li>
</ol>
<p>Once the loop terminates, the function assigns statistics counters for rx packets and bytes processed.</p>
<p>Now it&#x2019;s time to take two detours prior to proceeding up the network stack. First, let&#x2019;s see how to monitor and tune the network subsystem&#x2019;s softirqs. Next, let&#x2019;s talk about Generic Receive Offloading (GRO). After that, the rest of the networking stack will make more sense as we enter <code>napi_gro_receive</code>.</p>
<h4 id="monitoring-network-data-processing"><a name="monitoring-network-data-processing" class="anchor-navigation-ex-anchor" href="#monitoring-network-data-processing"><i class="fa fa-link" aria-hidden="true"></i></a>Monitoring network data processing</h4>
<h5 id="procnetsoftnetstat"><a name="procnetsoftnetstat" class="anchor-navigation-ex-anchor" href="#procnetsoftnetstat"><i class="fa fa-link" aria-hidden="true"></i></a><code>/proc/net/softnet_stat</code></h5>
<p>As seen in the previous section, <code>net_rx_action</code> increments a statistic when exiting the <code>net_rx_action</code> loop and when additional work could have been done, but either the <code>budget</code> or the time limit for the softirq was hit. This statistic is tracked as part of the <code>struct softnet_data</code> associated with the CPU.</p>
<p>These statistics are output to a file in proc: <code>/proc/net/softnet_stat</code> for which there is, unfortunately, very little documentation. The fields in the file in proc are not labeled and could change between kernel releases.</p>
<p>In Linux 3.13.0, you can find which values map to which field in <code>/proc/net/softnet_stat</code> by reading the kernel source. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/net-procfs.c#L161-L165" target="_blank">net/core/net-procfs.c</a>:</p>
<pre class="language-"><code class="lang-c">  <span class="token function">seq_printf</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span>
       <span class="token string">&quot;%08x %08x %08x %08x %08x %08x %08x %08x %08x %08x %08x\n&quot;</span><span class="token punctuation">,</span>
       sd<span class="token operator">-&gt;</span>processed<span class="token punctuation">,</span> sd<span class="token operator">-&gt;</span>dropped<span class="token punctuation">,</span> sd<span class="token operator">-&gt;</span>time_squeeze<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>
       <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token comment">/* was fastroute */</span>
       sd<span class="token operator">-&gt;</span>cpu_collision<span class="token punctuation">,</span> sd<span class="token operator">-&gt;</span>received_rps<span class="token punctuation">,</span> flow_limit_count<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Many of these statistics have confusing names and are incremented in places where you might not expect. An explanation of when and where each of these is incremented will be provided as the network stack is examined. Since the <code>squeeze_time</code> statistic was seen in <code>net_rx_action</code>, I thought it made sense to document this file now.</p>
<p>Monitor network data processing statistics by reading <code>/proc/net/softnet_stat</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/net/softnet_stat
6dcad223 00000000 00000001 00000000 00000000 00000000 00000000 00000000 00000000 00000000
6f0e1565 00000000 00000002 00000000 00000000 00000000 00000000 00000000 00000000 00000000
660774ec 00000000 00000003 00000000 00000000 00000000 00000000 00000000 00000000 00000000
61c99331 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
6794b1b3 00000000 00000005 00000000 00000000 00000000 00000000 00000000 00000000 00000000
6488cb92 00000000 00000001 00000000 00000000 00000000 00000000 00000000 00000000 00000000
</code></pre>
<p>Important details about <code>/proc/net/softnet_stat</code>:</p>
<ul>
<li>Each line of <code>/proc/net/softnet_stat</code> corresponds to a <code>struct softnet_data</code> structure, of which there is 1 per CPU.</li>
<li>The values are separated by a single space and are displayed in hexadecimal</li>
<li>The first value, <code>sd-&gt;processed</code>, is the number of network frames processed. This can be more than the total number of network frames received if you are using ethernet bonding. There are cases where the ethernet bonding driver will trigger network data to be re-processed, which would increment the <code>sd-&gt;processed</code> count more than once for the same packet.</li>
<li>The second value, <code>sd-&gt;dropped</code>, is the number of network frames dropped because there was no room on the processing queue. More on this later.</li>
<li>The third value, <code>sd-&gt;time_squeeze</code>, is (as we saw) the number of times the <code>net_rx_action</code> loop terminated because the budget was consumed or the time limit was reached, but more work could have been. Increasing the <code>budget</code> as explained earlier can help reduce this.</li>
<li>The next 5 values are always 0.</li>
<li>The ninth value, <code>sd-&gt;cpu_collision</code>, is a count of the number of times a collision occurred when trying to obtain a device lock when transmitting packets. This article is about receive, so this statistic will not be seen below.</li>
<li>The tenth value, <code>sd-&gt;received_rps</code>, is a count of the number of times this CPU has been woken up to process packets via an <a href="https://en.wikipedia.org/wiki/Inter-processor_interrupt" target="_blank">Inter-processor Interrupt</a></li>
<li>The last value, <code>flow_limit_count</code>, is a count of the number of times the flow limit has been reached. Flow limiting is an optional <a href="https://lwn.net/Articles/362339" target="_blank">Receive Packet Steering</a> feature that will be examined shortly.</li>
</ul>
<p>If you decide to monitor this file and graph the results, you must be extremely careful that the ordering of these fields hasn&#x2019;t changed and that the meaning of each field has been preserved. You will need to read the kernel source to verify this.</p>
<h4 id="tuning-network-data-processing"><a name="tuning-network-data-processing" class="anchor-navigation-ex-anchor" href="#tuning-network-data-processing"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning network data processing</h4>
<h5 id="adjusting-the-netrxaction-budget"><a name="adjusting-the-netrxaction-budget" class="anchor-navigation-ex-anchor" href="#adjusting-the-netrxaction-budget"><i class="fa fa-link" aria-hidden="true"></i></a>Adjusting the <code>net_rx_action</code> budget</h5>
<p>You can adjust the <code>net_rx_action</code> budget, which determines how much packet processing can be spent among all NAPI structures registered to a CPU by setting a sysctl value named <code>net.core.netdev_budget</code>.</p>
<p>Example: set the overall packet processing budget to 600.</p>
<p><code>$ sudo sysctl -w net.core.netdev_budget=600</code></p>
<p>You may also want to write this setting to your <code>/etc/sysctl.conf</code> file so that changes persist between reboots.</p>
<p>The default value on Linux 3.13.0 is 300.</p>
<h3 id="generic-receive-offloading-gro"><a name="generic-receive-offloading-gro" class="anchor-navigation-ex-anchor" href="#generic-receive-offloading-gro"><i class="fa fa-link" aria-hidden="true"></i></a>4.3.4. Generic Receive Offloading (GRO)</h3>
<p>Generic Receive Offloading (GRO) is a software implementation of a hardware optimization that is known as Large Receive Offloading (LRO).</p>
<p>The main idea behind both methods is that reducing the number of packets passed up the network stack by combining &#x201C;similar enough&#x201D; packets together can reduce CPU usage. For example, imagine a case where a large file transfer is occurring and most of the packets contain chunks of data in the file. Instead of sending small packets up the stack one at a time, the incoming packets can be combined into one packet with a huge payload. That packet can then be passed up the stack. This allows the protocol layers to process a single packet&#x2019;s headers while delivering bigger chunks of data to the user program.</p>
<p>The problem with this sort of optimization is, of course, information loss. If a packet had some important option or flag set, that option or flag could be lost if the packet is coalesced into another. And this is exactly why most people don&#x2019;t use or encourage the use of LRO. LRO implementations, generally speaking, had very lax rules for coalescing packets.</p>
<p>GRO was introduced as an implementation of LRO in software, but with more strict rules around which packets can be coalesced.</p>
<p>By the way: if you have ever used <code>tcpdump</code> and seen unrealistically large incoming packet sizes, it is most likely because your system has GRO enabled. As you&#x2019;ll see soon, packet capture taps are inserted further up the stack, after GRO has already happened.</p>
<h4 id="tuning-adjusting-gro-settings-with-ethtool"><a name="tuning-adjusting-gro-settings-with-ethtool" class="anchor-navigation-ex-anchor" href="#tuning-adjusting-gro-settings-with-ethtool"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning: Adjusting GRO settings with <code>ethtool</code></h4>
<p>You can use <code>ethtool</code> to check if GRO is enabled and also to adjust the setting.</p>
<p>Use <code>ethtool -k</code> to check your GRO settings.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">ethtool</span> <span class="token parameter variable">-k</span> eth0 <span class="token operator">|</span> <span class="token function">grep</span> generic-receive-offload
generic-receive-offload: on
</code></pre>
<p>As you can see, on this system I have <code>generic-receive-offload</code> set to on.</p>
<p>Use <code>ethtool -K</code> to enable (or disable) GRO.</p>
<p><code>$ sudo ethtool -K eth0 gro on</code></p>
<p><strong>Note:</strong> making these changes will, for most drivers, take the interface down and then bring it back up; connections to this interface will be interrupted. This may not matter much for a one-time change, though.</p>
<h3 id="napigroreceive"><a name="napigroreceive" class="anchor-navigation-ex-anchor" href="#napigroreceive"><i class="fa fa-link" aria-hidden="true"></i></a>4.3.5. napi_gro_receive</h3>
<p>The function <code>napi_gro_receive</code> deals processing network data for GRO (if GRO is enabled for the system) and sending the data up the stack toward the protocol layers. Much of this logic is handled in a function called <code>dev_gro_receive</code>.</p>
<h4 id="devgroreceive"><a name="devgroreceive" class="anchor-navigation-ex-anchor" href="#devgroreceive"><i class="fa fa-link" aria-hidden="true"></i></a><code>dev_gro_receive</code></h4>
<p>This function begins by checking if GRO is enabled and, if so, preparing to do GRO. In the case where GRO is enabled, a list of GRO offload filters is traversed to allow the higher level protocol stacks to act on a piece of data which is being considered for GRO. This is done so that the protocol layers can let the network device layer know if this packet is part of a <a href="https://en.wikipedia.org/wiki/Traffic_flow_(computer_networking" target="_blank">network flow</a>) that is currently being receive offloaded and handle anything protocol specific that should happen for GRO. For example, the TCP protocol will need to decide if/when to ACK a packet that is being coalesced into an existing packet.</p>
<p>Here&#x2019;s the code from <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3844-L3856" target="_blank"><code>net/core/dev.c</code></a> which does this:</p>
<pre class="language-"><code class="lang-c"><span class="token function">list_for_each_entry_rcu</span><span class="token punctuation">(</span>ptype<span class="token punctuation">,</span> head<span class="token punctuation">,</span> list<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>ptype<span class="token operator">-&gt;</span>type <span class="token operator">!=</span> type <span class="token operator">||</span> <span class="token operator">!</span>ptype<span class="token operator">-&gt;</span>callbacks<span class="token punctuation">.</span>gro_receive<span class="token punctuation">)</span>
    <span class="token keyword">continue</span><span class="token punctuation">;</span>

  <span class="token function">skb_set_network_header</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> <span class="token function">skb_gro_offset</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">skb_reset_mac_len</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">NAPI_GRO_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-&gt;</span>same_flow <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
  <span class="token function">NAPI_GRO_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-&gt;</span>flush <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
  <span class="token function">NAPI_GRO_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-&gt;</span>free <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>

  pp <span class="token operator">=</span> ptype<span class="token operator">-&gt;</span>callbacks<span class="token punctuation">.</span><span class="token function">gro_receive</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>napi<span class="token operator">-&gt;</span>gro_list<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">break</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>If the protocol layers indicated that it is time to flush the GRO&#x2019;d packet, that is taken care of next. This happens with a call to <code>napi_gro_complete</code>, which calls a <code>gro_complete</code> callback for the protocol layers and then passes the packet up the stack by calling <code>netif_receive_skb</code>.</p>
<p>Here&#x2019;s the code from <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3862-L3872" target="_blank"><code>net/core/dev.c</code></a> which does this:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">if</span> <span class="token punctuation">(</span>pp<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">struct</span> <span class="token class-name">sk_buff</span> <span class="token operator">*</span>nskb <span class="token operator">=</span> <span class="token operator">*</span>pp<span class="token punctuation">;</span>

  <span class="token operator">*</span>pp <span class="token operator">=</span> nskb<span class="token operator">-&gt;</span>next<span class="token punctuation">;</span>
  nskb<span class="token operator">-&gt;</span>next <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
  <span class="token function">napi_gro_complete</span><span class="token punctuation">(</span>nskb<span class="token punctuation">)</span><span class="token punctuation">;</span>
  napi<span class="token operator">-&gt;</span>gro_count<span class="token operator">--</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Next, if the protocol layers merged this packet to an existing flow, <code>napi_gro_receive</code> simply returns as there&#x2019;s nothing else to do.</p>
<p>If the packet was not merged and there are fewer than <code>MAX_GRO_SKBS</code> (8) GRO flows on the system, a new entry is added to the <code>gro_list</code> on the NAPI structure for this CPU.</p>
<p>Here&#x2019;s the code from <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3877-L3886" target="_blank"><code>net/core/dev.c</code></a> which does this:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">NAPI_GRO_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-&gt;</span>flush <span class="token operator">||</span> napi<span class="token operator">-&gt;</span>gro_count <span class="token operator">&gt;=</span> MAX_GRO_SKBS<span class="token punctuation">)</span>
  <span class="token keyword">goto</span> normal<span class="token punctuation">;</span>

napi<span class="token operator">-&gt;</span>gro_count<span class="token operator">++</span><span class="token punctuation">;</span>
<span class="token function">NAPI_GRO_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-&gt;</span>count <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token function">NAPI_GRO_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-&gt;</span>age <span class="token operator">=</span> jiffies<span class="token punctuation">;</span>
<span class="token function">skb_shinfo</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-&gt;</span>gso_size <span class="token operator">=</span> <span class="token function">skb_gro_len</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
skb<span class="token operator">-&gt;</span>next <span class="token operator">=</span> napi<span class="token operator">-&gt;</span>gro_list<span class="token punctuation">;</span>
napi<span class="token operator">-&gt;</span>gro_list <span class="token operator">=</span> skb<span class="token punctuation">;</span>
ret <span class="token operator">=</span> GRO_HELD<span class="token punctuation">;</span>
</code></pre>
<p>And that is how the GRO system in the Linux networking stack works.</p>
<h3 id="napiskbfinish"><a name="napiskbfinish" class="anchor-navigation-ex-anchor" href="#napiskbfinish"><i class="fa fa-link" aria-hidden="true"></i></a>4.3.6. napi_skb_finish</h3>
<p>Once <code>dev_gro_receive</code> completes, <code>napi_skb_finish</code> is called which either frees unneeded data structures because a packet has been merged, or calls <code>netif_receive_skb</code> to pass the data up the network stack (because there were already <code>MAX_GRO_SKBS</code> flows being GRO&#x2019;d).</p>
<p>Next, it&#x2019;s time for <code>netif_receive_skb</code> to see how data is handed off to the protocol layers. Before this can be examined, we&#x2019;ll need to take a look at Receive Packet Steering (RPS) first.</p>
<h2 id="receive-packet-steering-rps"><a name="receive-packet-steering-rps" class="anchor-navigation-ex-anchor" href="#receive-packet-steering-rps"><i class="fa fa-link" aria-hidden="true"></i></a>4.4. Receive Packet Steering (RPS)</h2>
<p>Recall earlier how we discussed that network device drivers register a NAPI <code>poll</code> function. Each <code>NAPI</code> poller instance is executed in the context of a softirq of which there is one per CPU. Further recall that the CPU which the driver&#x2019;s IRQ handler runs on will wake its softirq processing loop to process packets.</p>
<p>In other words: a single CPU processes the hardware interrupt and polls for packets to process incoming data.</p>
<p>Some NICs (like the Intel I350) support multiple queues at the hardware level. This means incoming packets can be DMA&#x2019;d to a separate memory region for each queue, with a separate NAPI structure to manage polling this region, as well. Thus multiple CPUs will handle interrupts from the device and also process packets.</p>
<p>This feature is typically called Receive Side Scaling (RSS).</p>
<p><a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L99-L222" target="_blank">Receive Packet Steering (RPS)</a> is a software implementation of RSS. Since it is implemented in software, this means it can be enabled for any NIC, even NICs which have only a single RX queue. However, since it is in software, this means that RPS can only enter into the flow after a packet has been harvested from the DMA memory region.</p>
<p>This means that you wouldn&#x2019;t notice a decrease in CPU time spent handling IRQs or the NAPI <code>poll</code> loop, but you can distribute the load for processing the packet after it&#x2019;s been harvested and reduce CPU time from there up the network stack.</p>
<p>RPS works by generating a hash for incoming data to determine which CPU should process the data. The data is then enqueued to the per-CPU receive network backlog to be processed. An <a href="https://en.wikipedia.org/wiki/Inter-processor_interrupt" target="_blank">Inter-processor Interrupt (IPI)</a> is delivered to the CPU owning the backlog. This helps to kick-start backlog processing if it is not currently processing data on the backlog. The <code>/proc/net/softnet_stat</code> contains a count of the number of times each <code>softnet_data</code> struct has received an IPI (the <code>received_rps</code> field).</p>
<p>Thus, <code>netif_receive_skb</code> will either continue sending network data up the networking stack, or hand it over to RPS for processing on a different CPU.</p>
<h3 id="tuning-enabling-rps"><a name="tuning-enabling-rps" class="anchor-navigation-ex-anchor" href="#tuning-enabling-rps"><i class="fa fa-link" aria-hidden="true"></i></a>4.4.1. Tuning: Enabling RPS</h3>
<p>For RPS to work, it must be enabled in the kernel configuration (it is on Ubuntu for kernel 3.13.0), and a bitmask describing which CPUs should process packets for a given interface and RX queue.</p>
<p>You can find some documentation about these bitmasks in the <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L138-L164" target="_blank">kernel documentation</a>.</p>
<p>In short, the bitmasks to modify are found in:</p>
<p><code>/sys/class/net/DEVICE_NAME/queues/QUEUE/rps_cpus</code></p>
<p>So, for <code>eth0</code> and receive queue 0, you would modify the file: <code>/sys/class/net/eth0/queues/rx-0/rps_cpus</code> with a hexadecimal number indicating which CPUs should process packets from <code>eth0</code>&#x2019;s receive queue 0. As <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L160-L164" target="_blank">the documentation</a> points out, RPS may be unnecessary in certain configurations.</p>
<p><strong>Note:</strong> enabling RPS to distribute packet processing to CPUs which were previously not processing packets will cause the number of <code>NET_RX</code> softirqs to increase for that CPU, as well as the <code>si</code> or <code>sitime</code> in the CPU usage graph. You can compare before and after of your softirq and CPU usage graphs to confirm that RPS is configured properly to your liking.</p>
<h2 id="receive-flow-steering-rfs"><a name="receive-flow-steering-rfs" class="anchor-navigation-ex-anchor" href="#receive-flow-steering-rfs"><i class="fa fa-link" aria-hidden="true"></i></a>4.5. Receive Flow Steering (RFS)</h2>
<p>Receive flow steering (RFS) is used in conjunction with RPS. RPS attempts to distribute incoming packet load amongst multiple CPUs, but does not take into account any data locality issues for maximizing CPU cache hit rates. You can use RFS to help increase cache hit rates by directing packets for the same flow to the same CPU for processing.</p>
<h3 id="tuning-enabling-rfs"><a name="tuning-enabling-rfs" class="anchor-navigation-ex-anchor" href="#tuning-enabling-rfs"><i class="fa fa-link" aria-hidden="true"></i></a>4.5.1. Tuning: Enabling RFS</h3>
<p>For RFS to work, you must have RPS enabled and configured.</p>
<p>RFS keeps track of a global hash table of all flows and the size of this hash table can be adjusted by setting the <code>net.core.rps_sock_flow_entries</code> sysctl.</p>
<p>Increase the size of the RFS socket flow hash by setting a <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.core.rps_sock_flow_entries=32768</code></p>
<p>Next, you can also set the number of flows per RX queue by writing this value to the sysfs file named <code>rps_flow_cnt</code> for each RX queue.</p>
<p>Example: increase the number of flows for RX queue 0 on eth0 to 2048.</p>
<p><code>$ sudo bash -c &apos;echo 2048 &gt; /sys/class/net/eth0/queues/rx-0/rps_flow_cnt&apos;</code></p>
<h2 id="hardware-accelerated-receive-flow-steering-arfs"><a name="hardware-accelerated-receive-flow-steering-arfs" class="anchor-navigation-ex-anchor" href="#hardware-accelerated-receive-flow-steering-arfs"><i class="fa fa-link" aria-hidden="true"></i></a>4.6. Hardware accelerated Receive Flow Steering (aRFS)</h2>
<p>RFS can be sped up with the use of hardware acceleration; the NIC and the kernel can work together to determine which flows should be processed on which CPUs. To use this feature, it must be supported by the NIC and your driver.</p>
<p>Consult your NIC&#x2019;s data sheet to determine if this feature is supported. If your NIC&#x2019;s driver exposes a function called <code>ndo_rx_flow_steer</code>, then the driver has support for accelerated RFS.</p>
<h3 id="tuning-enabling-accelerated-rfs-arfs"><a name="tuning-enabling-accelerated-rfs-arfs" class="anchor-navigation-ex-anchor" href="#tuning-enabling-accelerated-rfs-arfs"><i class="fa fa-link" aria-hidden="true"></i></a>4.6.1. Tuning: Enabling accelerated RFS (aRFS)</h3>
<p>Assuming that your NIC and driver support it, you can enable accelerated RFS by enabling and configuring a set of things:</p>
<ol>
<li>Have RPS enabled and configured.</li>
<li>Have RFS enabled and configured.</li>
<li>Your kernel has <code>CONFIG_RFS_ACCEL</code> enabled at compile time. The Ubuntu kernel 3.13.0 does.</li>
<li>Have ntuple support enabled for the device, as described previously. You can use <code>ethtool</code> to verify that ntuple support is enabled for the device.</li>
<li>Configure your IRQ settings to ensure each RX queue is handled by one of your desired network processing CPUs.</li>
</ol>
<p>Once the above is configured, accelerated RFS will be used to automatically move data to the RX queue tied to a CPU core that is processing data for that flow and you won&#x2019;t need to specify an ntuple filter rule manually for each flow.</p>
<h2 id="moving-up-the-network-stack-with-netifreceiveskb"><a name="moving-up-the-network-stack-with-netifreceiveskb" class="anchor-navigation-ex-anchor" href="#moving-up-the-network-stack-with-netifreceiveskb"><i class="fa fa-link" aria-hidden="true"></i></a>4.7. Moving up the network stack with netif_receive_skb</h2>
<p>Picking up where we left off with <code>netif_receive_skb</code>, which is called from a few places. The two most common (and also the two we&#x2019;ve already looked at):</p>
<ul>
<li><code>napi_skb_finish</code> if the packet is not going to be merged to an existing GRO&#x2019;d flow, OR</li>
<li><code>napi_gro_complete</code> if the protocol layers indicated that it&#x2019;s time to flush the flow, OR</li>
</ul>
<p><strong>Reminder:</strong> <code>netif_receive_skb</code> and its descendants are operating in the context of a the softirq processing loop and you&apos;ll see the time spent here accounted for as <code>sitime</code> or <code>si</code> with tools like <code>top</code>.</p>
<p><code>netif_receive_skb</code> begins by first checking a <code>sysctl</code> value to determine if the user has requested receive timestamping before or after a packet hits the backlog queue. If this setting is enabled, the data is timestamped now, prior to it hitting RPS (and the CPU&#x2019;s associated backlog queue). If this setting is disabled, it will be timestamped after it hits the queue. This can be used to distribute the load of timestamping amongst multiple CPUs if RPS is enabled, but will introduce some delay as a result.</p>
<h3 id="tuning-rx-packet-timestamping"><a name="tuning-rx-packet-timestamping" class="anchor-navigation-ex-anchor" href="#tuning-rx-packet-timestamping"><i class="fa fa-link" aria-hidden="true"></i></a>4.7.1. Tuning: RX packet timestamping</h3>
<p>You can tune when packets will be timestamped after they are received by adjusting a sysctl named <code>net.core.netdev_tstamp_prequeue</code>:</p>
<p>Disable timestamping for RX packets by adjusting a <code>sysctl</code></p>
<p><code>$ sudo sysctl -w net.core.netdev_tstamp_prequeue=0</code></p>
<p>The default value is 1. Please see the previous section for an explanation as to what this setting means, exactly.</p>
<h2 id="netifreceiveskb"><a name="netifreceiveskb" class="anchor-navigation-ex-anchor" href="#netifreceiveskb"><i class="fa fa-link" aria-hidden="true"></i></a>4.8. netif_receive_skb</h2>
<p>After the timestamping is dealt with, <code>netif_receive_skb</code> operates differently depending on whether or not RPS is enabled. Let&#x2019;s start with the simpler path first: RPS disabled.</p>
<h3 id="without-rps-default-setting"><a name="without-rps-default-setting" class="anchor-navigation-ex-anchor" href="#without-rps-default-setting"><i class="fa fa-link" aria-hidden="true"></i></a>4.8.1. Without RPS (default setting)</h3>
<p>If RPS is not enabled, <code>__netif_receive_skb</code> is called which does some bookkeeping and then calls <code>__netif_receive_skb_core</code> to move data closer to the protocol stacks.</p>
<p>We&#x2019;ll see precisely how <code>__netif_receive_skb_core</code> works, but first let&#x2019;s see how the RPS enabled code path works, as that code will also call <code>__netif_receive_skb_core</code>.</p>
<h3 id="with-rps-enabled"><a name="with-rps-enabled" class="anchor-navigation-ex-anchor" href="#with-rps-enabled"><i class="fa fa-link" aria-hidden="true"></i></a>4.8.2. With RPS enabled</h3>
<p>If RPS is enabled, after the timestamping options mentioned above are dealt with, <code>netif_receive_skb</code> will perform some computations to determine which CPU&#x2019;s backlog queue should be used. This is done by using the function <code>get_rps_cpu</code>. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3699-L3705" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c">cpu <span class="token operator">=</span> <span class="token function">get_rps_cpu</span><span class="token punctuation">(</span>skb<span class="token operator">-&gt;</span>dev<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> <span class="token operator">&amp;</span>rflow<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">if</span> <span class="token punctuation">(</span>cpu <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  ret <span class="token operator">=</span> <span class="token function">enqueue_to_backlog</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> cpu<span class="token punctuation">,</span> <span class="token operator">&amp;</span>rflow<span class="token operator">-&gt;</span>last_qtail<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">rcu_read_unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> ret<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p><code>get_rps_cpu</code> will take into account RFS and aRFS settings as described above to ensure the the data gets queued to the desired CPU&#x2019;s backlog with a call to <code>enqueue_to_backlog</code>.</p>
<h4 id="enqueuetobacklog"><a name="enqueuetobacklog" class="anchor-navigation-ex-anchor" href="#enqueuetobacklog"><i class="fa fa-link" aria-hidden="true"></i></a><code>enqueue_to_backlog</code></h4>
<p>This function begins by getting a pointer to the remote CPU&#x2019;s <code>softnet_data</code> structure, which contains a pointer to the <code>input_pkt_queue</code>. Next, the queue length of the <code>input_pkt_queue</code> of the remote CPU is checked. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3199-L3200" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c">qlen <span class="token operator">=</span> <span class="token function">skb_queue_len</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>input_pkt_queue<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>qlen <span class="token operator">&lt;=</span> netdev_max_backlog <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token function">skb_flow_limit</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> qlen<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
</code></pre>
<p>The length of <code>input_pkt_queue</code> is first compared to <code>netdev_max_backlog</code>. If the queue is longer than this value, the data is <strong>dropped</strong>. Similarly, the flow limit is checked and if it has been exceeded, the data is <strong>dropped</strong>. In both cases the drop count on the <code>softnet_data</code> structure is incremented. Note that this is the <code>softnet_data</code> structure of the CPU the data was going to be queued to. Read the section above about <code>/proc/net/softnet_stat</code> to learn how to get the drop count for monitoring purposes.</p>
<p><code>enqueue_to_backlog</code> is not called in many places. It is called for RPS-enabled packet processing and also from <code>netif_rx</code>. Most drivers should <strong>not</strong> be using <code>netif_rx</code> and should instead be using <code>netif_receive_skb</code>. If you are not using RPS and your driver is not using <code>netif_rx</code>, increasing the backlog won&#x2019;t produce any noticeable effect on your system as it is not used.</p>
<p><strong>Note</strong>: You need to check the driver you are using. If it calls <code>netif_receive_skb</code> and you are <strong>not</strong> using RPS, increasing the <code>netdev_max_backlog</code> will not yield any performance improvement because no data will ever make it to the <code>input_pkt_queue</code>.</p>
<p>Assuming that the <code>input_pkt_queue</code> is small enough and the flow limit (more about this, next) hasn&#x2019;t been reached (or is disabled), the data can be queued. The logic here is a bit funny, but can be summarized as:</p>
<ul>
<li>If the queue is empty: check if NAPI has been started on the remote CPU. If not, check if an IPI is queued to be sent. If not, queue one and start the NAPI processing loop by calling <code>____napi_schedule</code>. Proceed to queuing the data.</li>
<li>If the queue is not empty, or the previously described operation has completed, enqueue the data.</li>
</ul>
<p>The code is a bit tricky with its use of <code>goto</code>, so read it carefully. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3201-L3218" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c">  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">skb_queue_len</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>input_pkt_queue<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
enqueue<span class="token operator">:</span>
         <span class="token function">__skb_queue_tail</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>input_pkt_queue<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token function">input_queue_tail_incr_save</span><span class="token punctuation">(</span>sd<span class="token punctuation">,</span> qtail<span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token function">rps_unlock</span><span class="token punctuation">(</span>sd<span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token function">local_irq_restore</span><span class="token punctuation">(</span>flags<span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token keyword">return</span> NET_RX_SUCCESS<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>

 <span class="token comment">/* Schedule NAPI for backlog device
  * We can use non atomic operation since we own the queue lock
  */</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">__test_and_set_bit</span><span class="token punctuation">(</span>NAPI_STATE_SCHED<span class="token punctuation">,</span> <span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>backlog<span class="token punctuation">.</span>state<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
         <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">rps_ipi_queued</span><span class="token punctuation">(</span>sd<span class="token punctuation">)</span><span class="token punctuation">)</span>
                 <span class="token function">____napi_schedule</span><span class="token punctuation">(</span>sd<span class="token punctuation">,</span> <span class="token operator">&amp;</span>sd<span class="token operator">-&gt;</span>backlog<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token keyword">goto</span> enqueue<span class="token punctuation">;</span>
</code></pre>
<h4 id="flow-limits"><a name="flow-limits" class="anchor-navigation-ex-anchor" href="#flow-limits"><i class="fa fa-link" aria-hidden="true"></i></a>Flow limits</h4>
<p>RPS distributes packet processing load amongst multiple CPUs, but a single large flow can monopolize CPU processing time and starve smaller flows. Flow limits are a feature that can be used to limit the number of packets queued to the backlog for each flow to a certain amount. This can help ensure that smaller flows are processed even though much larger flows are pushing packets in.</p>
<p>The if statement above from <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3199-L3200" target="_blank">net/core/dev.c</a> checks the flow limit with a call to <code>skb_flow_limit</code>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">if</span> <span class="token punctuation">(</span>qlen <span class="token operator">&lt;=</span> netdev_max_backlog <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token function">skb_flow_limit</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> qlen<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
</code></pre>
<p>This code is checking that there is still room in the queue and that the <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L166-L188" target="_blank">flow limit</a> has not been reached. By default, flow limits are disabled. In order to enable flow limits, you must specify a bitmap (similar to RPS&#x2019; bitmap).</p>
<h4 id="monitoring-monitor-drops-due-to-full-inputpktqueue-or-flow-limit"><a name="monitoring-monitor-drops-due-to-full-inputpktqueue-or-flow-limit" class="anchor-navigation-ex-anchor" href="#monitoring-monitor-drops-due-to-full-inputpktqueue-or-flow-limit"><i class="fa fa-link" aria-hidden="true"></i></a>Monitoring: Monitor drops due to full <code>input_pkt_queue</code> or flow limit</h4>
<p>See the section above about monitoring <code>/proc/net/softnet_stat</code>. The <code>dropped</code> field is a counter that gets incremented each time data is dropped instead of queued to a CPU&#x2019;s <code>input_pkt_queue</code>.</p>
<h4 id="tuning"><a name="tuning" class="anchor-navigation-ex-anchor" href="#tuning"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning</h4>
<h5 id="tuning-adjusting-netdevmaxbacklog-to-prevent-drops"><a name="tuning-adjusting-netdevmaxbacklog-to-prevent-drops" class="anchor-navigation-ex-anchor" href="#tuning-adjusting-netdevmaxbacklog-to-prevent-drops"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning: Adjusting <code>netdev_max_backlog</code> to prevent drops</h5>
<p>Before adjusting this tuning value, see the note in the previous section.</p>
<p>You can help prevent drops in <code>enqueue_to_backlog</code> by increasing the <code>netdev_max_backlog</code> if you are using RPS or if your driver calls <code>netif_rx</code>.</p>
<p>Example: increase backlog to 3000 with <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.core.netdev_max_backlog=3000</code></p>
<p>The default value is 1000.</p>
<h5 id="tuning-adjust-the-napi-weight-of-the-backlog-poll-loop"><a name="tuning-adjust-the-napi-weight-of-the-backlog-poll-loop" class="anchor-navigation-ex-anchor" href="#tuning-adjust-the-napi-weight-of-the-backlog-poll-loop"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning: Adjust the NAPI weight of the backlog <code>poll</code> loop</h5>
<p>You can adjust the weight of the backlog&#x2019;s NAPI poller by setting the <code>net.core.dev_weight</code> sysctl. Adjusting this value determines how much of the overall budget the backlog <code>poll</code> loop can consume (see the section above about adjusting <code>net.core.netdev_budget</code>):</p>
<p>Example: increase the NAPI <code>poll</code> backlog processing loop with <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.core.dev_weight=600</code></p>
<p>The default value is 64.</p>
<p>Remember, backlog processing runs in the softirq context similar to the device driver&#x2019;s registered <code>poll</code> function and will be limited by the overall <code>budget</code> and a time limit, as described in previous sections.</p>
<h5 id="tuning-enabling-flow-limits-and-tuning-flow-limit-hash-table-size"><a name="tuning-enabling-flow-limits-and-tuning-flow-limit-hash-table-size" class="anchor-navigation-ex-anchor" href="#tuning-enabling-flow-limits-and-tuning-flow-limit-hash-table-size"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning: Enabling flow limits and tuning flow limit hash table size</h5>
<p>Set the size of the flow limit table with a <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.core.flow_limit_table_len=8192</code></p>
<p>The default value is 4096.</p>
<p>This change only affects newly allocated flow hash tables. So, if you&#x2019;d like to increase the table size, you should do it before you enable flow limits.</p>
<p>To enable <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L166-L188" target="_blank">flow limits</a> you should specify a bitmask in <code>/proc/sys/net/core/flow_limit_cpu_bitmap</code> similar to the RPS bitmask which indicates which CPUs have flow limits enabled.</p>
<h3 id="backlog-queue-napi-poller"><a name="backlog-queue-napi-poller" class="anchor-navigation-ex-anchor" href="#backlog-queue-napi-poller"><i class="fa fa-link" aria-hidden="true"></i></a>4.8.3. backlog queue NAPI poller</h3>
<p>The per-CPU backlog queue plugs into NAPI the same way a device driver does. A <code>poll</code> function is provided that is used to process packets from the softirq context. A <code>weight</code> is also provided, just as a device driver would.</p>
<p>This NAPI struct is provided during initialization of the networking system. From <code>net_dev_init</code> in <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L6952-L6955" target="_blank"><code>net/core/dev.c</code></a>:</p>
<pre class="language-"><code class="lang-c">sd<span class="token operator">-&gt;</span>backlog<span class="token punctuation">.</span>poll <span class="token operator">=</span> process_backlog<span class="token punctuation">;</span>
sd<span class="token operator">-&gt;</span>backlog<span class="token punctuation">.</span>weight <span class="token operator">=</span> weight_p<span class="token punctuation">;</span>
sd<span class="token operator">-&gt;</span>backlog<span class="token punctuation">.</span>gro_list <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
sd<span class="token operator">-&gt;</span>backlog<span class="token punctuation">.</span>gro_count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
</code></pre>
<p>The backlog NAPI structure differs from the device driver NAPI structure in that the <code>weight</code> parameter is adjustable, where as drivers hardcode their NAPI weight to 64. We&#x2019;ll see in the tuning section below how to adjust the weight using a <code>sysctl</code>.</p>
<h3 id="processbacklog"><a name="processbacklog" class="anchor-navigation-ex-anchor" href="#processbacklog"><i class="fa fa-link" aria-hidden="true"></i></a>4.8.4. process_backlog</h3>
<p>The <code>process_backlog</code> function is a loop which runs until its weight (as described in the previous section) has been consumed or no more data remains on the backlog.</p>
<p>Each piece of data on the backlog queue is removed from the backlog queue and passed on to <code>__netif_receive_skb</code>. The code path once the data hits <code>__netif_receive_skb</code> is the same as explained above for the RPS disabled case. Namely, <code>__netif_receive_skb</code> does some bookkeeping prior to calling <code>__netif_receive_skb_core</code> to pass network data up to the protocol layers.</p>
<p><code>process_backlog</code> follows the same contract with NAPI that device drivers do, which is: NAPI is disabled if the total weight will not be used. The poller is restarted with the call to <code>____napi_schedule</code> from <code>enqueue_to_backlog</code> as described above.</p>
<p>The function returns the amount of work done, which <code>net_rx_action</code> (described above) will subtract from the budget (which is adjusted with the <code>net.core.netdev_budget</code>, as described above).</p>
<h3 id="netifreceiveskbcore-delivers-data-to-packet-taps-and-protocol-layers"><a name="netifreceiveskbcore-delivers-data-to-packet-taps-and-protocol-layers" class="anchor-navigation-ex-anchor" href="#netifreceiveskbcore-delivers-data-to-packet-taps-and-protocol-layers"><i class="fa fa-link" aria-hidden="true"></i></a>4.8.5. __netif_receive_skb_core delivers data to packet taps and protocol layers</h3>
<p><code>__netif_receive_skb_core</code> performs the heavy lifting of delivering the data to protocol stacks. Before it does this, it checks if any packet taps have been installed which are catching all incoming packets. One example of something that does this is the <code>AF_PACKET</code> address family, typically used via the <a href="http://www.tcpdump.org/manpages/pcap.3pcap.html" target="_blank">libpcap library</a>.</p>
<p>If such a tap exists, the data is delivered there first then to the protocol layers next.</p>
<h3 id="packet-tap-delivery"><a name="packet-tap-delivery" class="anchor-navigation-ex-anchor" href="#packet-tap-delivery"><i class="fa fa-link" aria-hidden="true"></i></a>4.8.6. Packet tap delivery</h3>
<p>If a packet tap is installed (usually via libpcap), the packet is delivered there with the following code from <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3548-L3554" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token function">list_for_each_entry_rcu</span><span class="token punctuation">(</span>ptype<span class="token punctuation">,</span> <span class="token operator">&amp;</span>ptype_all<span class="token punctuation">,</span> list<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>ptype<span class="token operator">-&gt;</span>dev <span class="token operator">||</span> ptype<span class="token operator">-&gt;</span>dev <span class="token operator">==</span> skb<span class="token operator">-&gt;</span>dev<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>pt_prev<span class="token punctuation">)</span>
      ret <span class="token operator">=</span> <span class="token function">deliver_skb</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> pt_prev<span class="token punctuation">,</span> orig_dev<span class="token punctuation">)</span><span class="token punctuation">;</span>
    pt_prev <span class="token operator">=</span> ptype<span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>If you are curious about how the path of the data through pcap, read <a href="https://github.com/torvalds/linux/blob/v3.13/net/packet/af_packet.c" target="_blank">net/packet/af_packet.c</a>.</p>
<h3 id="protocol-layer-delivery"><a name="protocol-layer-delivery" class="anchor-navigation-ex-anchor" href="#protocol-layer-delivery"><i class="fa fa-link" aria-hidden="true"></i></a>4.8.7. Protocol layer delivery</h3>
<p>Once the taps have been satisfied, <code>__netif_receive_skb_core</code> delivers data to protocol layers. It does this by obtaining the protocol field from the data and iterating across a list of deliver functions registered for that protocol type.</p>
<p>This can be seen in <code>__netif_receive_skb_core</code> in <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3548-L3554" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c">type <span class="token operator">=</span> skb<span class="token operator">-&gt;</span>protocol<span class="token punctuation">;</span>
<span class="token function">list_for_each_entry_rcu</span><span class="token punctuation">(</span>ptype<span class="token punctuation">,</span>
                <span class="token operator">&amp;</span>ptype_base<span class="token punctuation">[</span><span class="token function">ntohs</span><span class="token punctuation">(</span>type<span class="token punctuation">)</span> <span class="token operator">&amp;</span> PTYPE_HASH_MASK<span class="token punctuation">]</span><span class="token punctuation">,</span> list<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>ptype<span class="token operator">-&gt;</span>type <span class="token operator">==</span> type <span class="token operator">&amp;&amp;</span>
            <span class="token punctuation">(</span>ptype<span class="token operator">-&gt;</span>dev <span class="token operator">==</span> null_or_dev <span class="token operator">||</span> ptype<span class="token operator">-&gt;</span>dev <span class="token operator">==</span> skb<span class="token operator">-&gt;</span>dev <span class="token operator">||</span>
             ptype<span class="token operator">-&gt;</span>dev <span class="token operator">==</span> orig_dev<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span>pt_prev<span class="token punctuation">)</span>
                        ret <span class="token operator">=</span> <span class="token function">deliver_skb</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> pt_prev<span class="token punctuation">,</span> orig_dev<span class="token punctuation">)</span><span class="token punctuation">;</span>
                pt_prev <span class="token operator">=</span> ptype<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>The <code>ptype_base</code> identifier above is defined as a hash table of lists in <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L146" target="_blank">net/core/dev.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">struct</span> <span class="token class-name">list_head</span> ptype_base<span class="token punctuation">[</span>PTYPE_HASH_SIZE<span class="token punctuation">]</span> __read_mostly<span class="token punctuation">;</span>
</code></pre>
<p>Each protocol layer adds a filter to a list at a given slot in the hash table, computed with a helper function called <code>ptype_head</code>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">inline</span> <span class="token keyword">struct</span> <span class="token class-name">list_head</span> <span class="token operator">*</span><span class="token function">ptype_head</span><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">packet_type</span> <span class="token operator">*</span>pt<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>pt<span class="token operator">-&gt;</span>type <span class="token operator">==</span> <span class="token function">htons</span><span class="token punctuation">(</span>ETH_P_ALL<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">return</span> <span class="token operator">&amp;</span>ptype_all<span class="token punctuation">;</span>
        <span class="token keyword">else</span>
                <span class="token keyword">return</span> <span class="token operator">&amp;</span>ptype_base<span class="token punctuation">[</span><span class="token function">ntohs</span><span class="token punctuation">(</span>pt<span class="token operator">-&gt;</span>type<span class="token punctuation">)</span> <span class="token operator">&amp;</span> PTYPE_HASH_MASK<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Adding a filter to the list is accomplished with a call to <code>dev_add_pack</code>. That is how protocol layers register themselves for network data delivery for their protocol type.</p>
<p>And now you know how network data gets from the NIC to the protocol layer.</p>
<h2 id="protocol-layer-registration"><a name="protocol-layer-registration" class="anchor-navigation-ex-anchor" href="#protocol-layer-registration"><i class="fa fa-link" aria-hidden="true"></i></a>4.9. Protocol layer registration</h2>
<p>Now that we know how data is delivered to the protocol stacks from the network device subsystem, let&#x2019;s see how a protocol layer registers itself.</p>
<p>This blog post is going to examine the IP protocol stack as it is a commonly used protocol and will be relevant to most readers.</p>
<h3 id="ip-protocol-layer"><a name="ip-protocol-layer" class="anchor-navigation-ex-anchor" href="#ip-protocol-layer"><i class="fa fa-link" aria-hidden="true"></i></a>4.9.1. IP protocol layer</h3>
<p>The IP protocol layer plugs itself into the <code>ptype_base</code> hash table so that data will be delivered to it from the network device layer described in previous sections.</p>
<p>This happens in the function <code>inet_init</code> from <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/af_inet.c#L1788" target="_blank">net/ipv4/af_inet.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token function">dev_add_pack</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>ip_packet_type<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>This registers the IP packet type structure defined at <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/af_inet.c#L1673-L1676" target="_blank">net/ipv4/af_inet.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">struct</span> <span class="token class-name">packet_type</span> ip_packet_type __read_mostly <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token punctuation">.</span>type <span class="token operator">=</span> <span class="token function">cpu_to_be16</span><span class="token punctuation">(</span>ETH_P_IP<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">.</span>func <span class="token operator">=</span> ip_rcv<span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre>
<p><code>__netif_receive_skb_core</code> calls <code>deliver_skb</code> (as seen in the above section), which calls <code>func</code> (in this case, <code>ip_rcv</code>).</p>
<h4 id="iprcv"><a name="iprcv" class="anchor-navigation-ex-anchor" href="#iprcv"><i class="fa fa-link" aria-hidden="true"></i></a><code>ip_rcv</code></h4>
<p>The <code>ip_rcv</code> function is pretty straight-forward at a high level. There are several integrity checks to ensure the data is valid. Statistics counters are bumped, as well.</p>
<p><code>ip_rcv</code> ends by passing the packet to <code>ip_rcv_finish</code> by way of <a href="https://en.wikipedia.org/wiki/Netfilter" target="_blank">netfilter</a>. This is done so that any <a href="https://en.wikipedia.org/wiki/Iptables" target="_blank">iptables</a> rules that should be matched at the IP protocol layer can take a look at the packet before it continues on.</p>
<p>We can see the code which hands the data over to netfilter at the end of <code>ip_rcv</code> in <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/ip_input.c#L453-L454" target="_blank">net/ipv4/ip_input.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">return</span> <span class="token function">NF_HOOK</span><span class="token punctuation">(</span>NFPROTO_IPV4<span class="token punctuation">,</span> NF_INET_PRE_ROUTING<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> dev<span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span> ip_rcv_finish<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<h4 id="netfilter-and-iptables"><a name="netfilter-and-iptables" class="anchor-navigation-ex-anchor" href="#netfilter-and-iptables"><i class="fa fa-link" aria-hidden="true"></i></a>netfilter and iptables</h4>
<p>In the interest of brevity (and my RSI), I&#x2019;ve decided to skip my deep dive into netfilter, iptables, and conntrack.</p>
<p>The short version is that <code>NF_HOOK_THRESH</code> will check if any filters are installed and attempt to return execution back to the IP protocol layer to avoid going deeper into netfilter and anything that hooks in below that like iptables and conntrack.</p>
<p>Keep in mind: if you have numerous or very complex netfilter or iptables rules, those rules will be executed in the softirq context and can lead to latency in your network stack. This may be unavoidable, though, if you need to have a particular set of rules installed.</p>
<h4 id="iprcvfinish"><a name="iprcvfinish" class="anchor-navigation-ex-anchor" href="#iprcvfinish"><i class="fa fa-link" aria-hidden="true"></i></a><code>ip_rcv_finish</code></h4>
<p>Once net filter has had a chance to take a look at the data and decide what to do with it, <code>ip_rcv_finish</code> is called. This only happens if the data is not being dropped by netfilter, of course.</p>
<p><code>ip_rcv_finish</code> begins with an optimization. In order to deliver the packet to proper place, a <code>dst_entry</code> from the routing system needs to be in place. In order to obtain one, the code initially attempts to call the <code>early_demux</code> function from the higher level protocol that this data is destined for.</p>
<p>The <code>early_demux</code> routine is an <a href="https://patchwork.ozlabs.org/patch/280718/" target="_blank">optimization</a> which attempts to find the <code>dst_entry</code> needed to deliver the packet by checking if a <code>dst_entry</code> is cached on the socket structure.</p>
<p>Here&#x2019;s what that looks like from <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/ip_input.c#L317-L327" target="_blank">net/ipv4/ip_input.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">if</span> <span class="token punctuation">(</span>sysctl_ip_early_demux <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token function">skb_dst</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> skb<span class="token operator">-&gt;</span>sk <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">net_protocol</span> <span class="token operator">*</span>ipprot<span class="token punctuation">;</span>
  <span class="token keyword">int</span> protocol <span class="token operator">=</span> iph<span class="token operator">-&gt;</span>protocol<span class="token punctuation">;</span>

  ipprot <span class="token operator">=</span> <span class="token function">rcu_dereference</span><span class="token punctuation">(</span>inet_protos<span class="token punctuation">[</span>protocol<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>ipprot <span class="token operator">&amp;&amp;</span> ipprot<span class="token operator">-&gt;</span>early_demux<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    ipprot<span class="token operator">-&gt;</span><span class="token function">early_demux</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">/* must reload iph, skb-&gt;head might have changed */</span>
    iph <span class="token operator">=</span> <span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>As you can see above, this code is guarded by a sysctl <code>sysctl_ip_early_demux</code>. By default <code>early_demux</code> is enabled. The next section includes information about how to disable it and why you might want to.</p>
<p>If the optimization is enabled and there is no cached entry (because this is the first packet arriving), the packet will be handed off to the routing system in the kernel where the <code>dst_entry</code> will be computed and assigned.</p>
<p>Once the routing layer completes, statistics counters are updated and the function ends by calling <code>dst_input(skb)</code> which in turn calls the input function pointer on the packet&#x2019;s <code>dst_entry</code> structure that was affixed by the routing system.</p>
<p>If the packet&#x2019;s final destination is the local system, the routing system will attach the function <code>ip_local_deliver</code> to the input function pointer in the <code>dst_entry</code> structure on the packet.</p>
<h5 id="tuning-adjusting-ip-protocol-early-demux"><a name="tuning-adjusting-ip-protocol-early-demux" class="anchor-navigation-ex-anchor" href="#tuning-adjusting-ip-protocol-early-demux"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning: adjusting IP protocol early demux</h5>
<p>Disable the <code>early_demux</code> optimization by setting a <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.ipv4.ip_early_demux=0</code></p>
<p>The default value is 1; <code>early_demux</code> is enabled.</p>
<p>This sysctl was added as some users saw a <a href="https://patchwork.ozlabs.org/patch/166441/" target="_blank">~5% decrease in throughput</a> with the <code>early_demux</code> optimization in some cases.</p>
<h4 id="iplocaldeliver"><a name="iplocaldeliver" class="anchor-navigation-ex-anchor" href="#iplocaldeliver"><i class="fa fa-link" aria-hidden="true"></i></a><code>ip_local_deliver</code></h4>
<p>Recall how we saw the following pattern in the IP protocol layer:</p>
<ol>
<li>Calls to <code>ip_rcv</code> do some initial bookkeeping.</li>
<li>Packet is handed off to netfilter for processing, with a pointer to a callback to be executed when processing finishes.</li>
<li><code>ip_rcv_finish</code> is the callback which finished processing and continued working toward pushing the packet up the networking stack.</li>
</ol>
<p><code>ip_local_deliver</code> has the same pattern. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/ip_input.c#L241-L258" target="_blank">net/ipv4/ip_input.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/*
 *      Deliver IP Packets to the higher protocol layers.
 */</span>
<span class="token keyword">int</span> <span class="token function">ip_local_deliver</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">sk_buff</span> <span class="token operator">*</span>skb<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
        <span class="token comment">/*
         *      Reassemble IP fragments.
         */</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">ip_is_fragment</span><span class="token punctuation">(</span><span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">ip_defrag</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> IP_DEFRAG_LOCAL_DELIVER<span class="token punctuation">)</span><span class="token punctuation">)</span>
                        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token keyword">return</span> <span class="token function">NF_HOOK</span><span class="token punctuation">(</span>NFPROTO_IPV4<span class="token punctuation">,</span> NF_INET_LOCAL_IN<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> skb<span class="token operator">-&gt;</span>dev<span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span>
                       ip_local_deliver_finish<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Once netfilter has had a chance to take a look at the data, <code>ip_local_deliver_finish</code> will be called, assuming the data is not dropped first by netfilter.</p>
<h4 id="iplocaldeliverfinish"><a name="iplocaldeliverfinish" class="anchor-navigation-ex-anchor" href="#iplocaldeliverfinish"><i class="fa fa-link" aria-hidden="true"></i></a><code>ip_local_deliver_finish</code></h4>
<p><code>ip_local_deliver_finish</code> obtains the protocol from the packet, looks up a <code>net_protocol</code> structure registered for that protocol, and calls the function pointed to by <code>handler</code> in the <code>net_protocol</code> structure.</p>
<p>This hands the packet up to the higher level protocol layer.</p>
<h4 id="monitoring-ip-protocol-layer-statistics"><a name="monitoring-ip-protocol-layer-statistics" class="anchor-navigation-ex-anchor" href="#monitoring-ip-protocol-layer-statistics"><i class="fa fa-link" aria-hidden="true"></i></a>Monitoring: IP protocol layer statistics</h4>
<p>Monitor detailed IP protocol statistics by reading <code>/proc/net/snmp</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/net/snmp
Ip: Forwarding DefaultTTL InReceives InHdrErrors InAddrErrors ForwDatagrams InUnknownProtos InDiscards InDelivers OutRequests OutDiscards OutNoRoutes ReasmTimeout ReasmReqds ReasmOKs ReasmFails FragOKs FragFails FragCreates
Ip: <span class="token number">1</span> <span class="token number">64</span> <span class="token number">25922988125</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">15771700</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">25898327616</span> <span class="token number">22789396404</span> <span class="token number">12987882</span> <span class="token number">51</span> <span class="token number">1</span> <span class="token number">10129840</span> <span class="token number">2196520</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
<span class="token punctuation">..</span>.
</code></pre>
<p>This file contains statistics for several protocol layers. The IP protocol layer appears first. The first line contains space separate names for each of the corresponding values in the next line.</p>
<p>In the IP protocol layer, you will find statistics counters being bumped. Those counters are referenced by a C enum. All of the valid enum values and the field names they correspond to in <code>/proc/net/snmp</code> can be found in <a href="https://github.com/torvalds/linux/blob/v3.13/include/uapi/linux/snmp.h#L10-L59" target="_blank">include/uapi/linux/snmp.h</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">enum</span>
<span class="token punctuation">{</span>
  IPSTATS_MIB_NUM <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>
<span class="token comment">/* frequently written fields in fast path, kept in same cache line */</span>
  IPSTATS_MIB_INPKTS<span class="token punctuation">,</span>     <span class="token comment">/* InReceives */</span>
  IPSTATS_MIB_INOCTETS<span class="token punctuation">,</span>     <span class="token comment">/* InOctets */</span>
  IPSTATS_MIB_INDELIVERS<span class="token punctuation">,</span>     <span class="token comment">/* InDelivers */</span>
  IPSTATS_MIB_OUTFORWDATAGRAMS<span class="token punctuation">,</span>   <span class="token comment">/* OutForwDatagrams */</span>
  IPSTATS_MIB_OUTPKTS<span class="token punctuation">,</span>      <span class="token comment">/* OutRequests */</span>
  IPSTATS_MIB_OUTOCTETS<span class="token punctuation">,</span>      <span class="token comment">/* OutOctets */</span>

  <span class="token comment">/* ... */</span>
</code></pre>
<p>Monitor extended IP protocol statistics by reading <code>/proc/net/netstat</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/net/netstat <span class="token operator">|</span> <span class="token function">grep</span> IpExt
IpExt: InNoRoutes InTruncatedPkts InMcastPkts OutMcastPkts InBcastPkts OutBcastPkts InOctets OutOctets InMcastOctets OutMcastOctets InBcastOctets OutBcastOctets InCsumErrors InNoECTPkts InECT0Pktsu InCEPkts
IpExt: <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">277959</span> <span class="token number">0</span> <span class="token number">14568040307695</span> <span class="token number">32991309088496</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">58649349</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
</code></pre>
<p>The format is similar to <code>/proc/net/snmp</code>, except the lines are prefixed with <code>IpExt</code>.</p>
<p>Some interesting statistics:</p>
<ul>
<li><code>InReceives</code>: The total number of IP packets that reached <code>ip_rcv</code> before any data integrity checks.</li>
<li><code>InHdrErrors</code>: Total number of IP packets with corrupted headers. The header was too short, too long, non-existent, had the wrong IP protocol version number, etc.</li>
<li><code>InAddrErrors</code>: Total number of IP packets where the host was unreachable.</li>
<li><code>ForwDatagrams</code>: Total number of IP packets that have been forwarded.</li>
<li><code>InUnknownProtos</code>: Total number of IP packets with unknown or unsupported protocol specified in the header.</li>
<li><code>InDiscards</code>: Total number of IP packets discarded due to memory allocation failure or checksum failure when packets are trimmed.</li>
<li><code>InDelivers</code>: Total number of IP packets successfully delivered to higher protocol layers. Keep in mind that those protocol layers may drop data even if the IP layer does not.</li>
<li><code>InCsumErrors</code>: Total number of IP Packets with checksum errors.</li>
</ul>
<p>Note that each of these is incremented in really specific locations in the IP layer. Code gets moved around from time to time and double counting errors or other accounting bugs can sneak in. If these statistics are important to you, you are strongly encouraged to read the IP protocol layer source code for the metrics that are important to you so you understand when they are (and are not) being incremented.</p>
<h3 id="higher-level-protocol-registration"><a name="higher-level-protocol-registration" class="anchor-navigation-ex-anchor" href="#higher-level-protocol-registration"><i class="fa fa-link" aria-hidden="true"></i></a>4.9.2. Higher level protocol registration</h3>
<p>This blog post will examine UDP, but the TCP protocol handler is registered the same way and at the same time as the UDP protocol handler.</p>
<p>In <code>net/ipv4/af_inet.c</code>, the structure definitions which contain the handler functions for connecting the UDP, TCP , and ICMP protocols to the IP protocol layer can be found. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/af_inet.c#L1526-L1547" target="_blank">net/ipv4/af_inet.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">net_protocol</span> tcp_protocol <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token punctuation">.</span>early_demux    <span class="token operator">=</span>       tcp_v4_early_demux<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>handler        <span class="token operator">=</span>       tcp_v4_rcv<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>err_handler    <span class="token operator">=</span>       tcp_v4_err<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>no_policy      <span class="token operator">=</span>       <span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token punctuation">.</span>netns_ok       <span class="token operator">=</span>       <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>

<span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">net_protocol</span> udp_protocol <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token punctuation">.</span>early_demux <span class="token operator">=</span>  udp_v4_early_demux<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>handler <span class="token operator">=</span>      udp_rcv<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>err_handler <span class="token operator">=</span>  udp_err<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>no_policy <span class="token operator">=</span>    <span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token punctuation">.</span>netns_ok <span class="token operator">=</span>     <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>

<span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">net_protocol</span> icmp_protocol <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token punctuation">.</span>handler <span class="token operator">=</span>      icmp_rcv<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>err_handler <span class="token operator">=</span>  icmp_err<span class="token punctuation">,</span>
        <span class="token punctuation">.</span>no_policy <span class="token operator">=</span>    <span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token punctuation">.</span>netns_ok <span class="token operator">=</span>     <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre>
<p>These structures are registered in the initialization code of the inet address family. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/af_inet.c#L1720-L1725" target="_blank">net/ipv4/af_inet.c</a>:</p>
<pre class="language-"><code class="lang-c"> <span class="token comment">/*
  *      Add all the base protocols.
  */</span>

 <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">inet_add_protocol</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>icmp_protocol<span class="token punctuation">,</span> IPPROTO_ICMP<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
         <span class="token function">pr_crit</span><span class="token punctuation">(</span><span class="token string">&quot;%s: Cannot add ICMP protocol\n&quot;</span><span class="token punctuation">,</span> <span class="token constant">__func__</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">inet_add_protocol</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>udp_protocol<span class="token punctuation">,</span> IPPROTO_UDP<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
         <span class="token function">pr_crit</span><span class="token punctuation">(</span><span class="token string">&quot;%s: Cannot add UDP protocol\n&quot;</span><span class="token punctuation">,</span> <span class="token constant">__func__</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">inet_add_protocol</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>tcp_protocol<span class="token punctuation">,</span> IPPROTO_TCP<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
         <span class="token function">pr_crit</span><span class="token punctuation">(</span><span class="token string">&quot;%s: Cannot add TCP protocol\n&quot;</span><span class="token punctuation">,</span> <span class="token constant">__func__</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>We&#x2019;re going to be looking at the UDP protocol layer. As seen above, the <code>handler</code> function for UDP is called <code>udp_rcv</code>.</p>
<p>This is the entry point into the UDP layer where the IP layer hands data. Let&#x2019;s continue our journey there.</p>
<h3 id="udp-protocol-layer"><a name="udp-protocol-layer" class="anchor-navigation-ex-anchor" href="#udp-protocol-layer"><i class="fa fa-link" aria-hidden="true"></i></a>4.9.3. UDP protocol layer</h3>
<p>The code for the UDP protocol layer can be found in: <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c" target="_blank">net/ipv4/udp.c</a>.</p>
<h4 id="udprcv"><a name="udprcv" class="anchor-navigation-ex-anchor" href="#udprcv"><i class="fa fa-link" aria-hidden="true"></i></a><code>udp_rcv</code></h4>
<p>The code for the <code>udp_rcv</code> function is just a single line which calls directly into <code>__udp4_lib_rcv</code> to handle receiving the datagram.</p>
<h4 id="udp4librcv"><a name="udp4librcv" class="anchor-navigation-ex-anchor" href="#udp4librcv"><i class="fa fa-link" aria-hidden="true"></i></a><code>__udp4_lib_rcv</code></h4>
<p>The <code>__udp4_lib_rcv</code> function will check to ensure the packet is valid and obtain the UDP header, UDP datagram length, source address, and destination address. Next, are some additional integrity checks and checksum verification.</p>
<p>Recall that earlier in the IP protocol layer, we saw that an optimization is performed to attach a <code>dst_entry</code> to the packet before it is handed off to the upper layer protocol (UDP in our case).</p>
<p>If a socket and corresponding <code>dst_entry</code> were found, <code>__udp4_lib_rcv</code> will queue the packet to the socket:</p>
<pre class="language-"><code class="lang-c">sk <span class="token operator">=</span> <span class="token function">skb_steal_sock</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>sk<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">struct</span> <span class="token class-name">dst_entry</span> <span class="token operator">*</span>dst <span class="token operator">=</span> <span class="token function">skb_dst</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">int</span> ret<span class="token punctuation">;</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span>sk<span class="token operator">-&gt;</span>sk_rx_dst <span class="token operator">!=</span> dst<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token function">udp_sk_rx_dst_set</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> dst<span class="token punctuation">)</span><span class="token punctuation">;</span>

  ret <span class="token operator">=</span> <span class="token function">udp_queue_rcv_skb</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">sock_put</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token comment">/* a return value &gt; 0 means to resubmit the input, but
   * it wants the return to be -protocol, or 0
   */</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>ret <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>ret<span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
</code></pre>
<p>If there is no socket attached from the early_demux operation, a receiving socket will now be looked up by calling <code>__udp4_lib_lookup_skb</code>.</p>
<p>In both cases described above, the datagram will be queued to the socket:</p>
<pre class="language-"><code class="lang-c">ret <span class="token operator">=</span> <span class="token function">udp_queue_rcv_skb</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">sock_put</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>If no socket was found, the datagram will be dropped:</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/* No socket. Drop packet silently, if checksum is wrong */</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">udp_lib_checksum_complete</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">goto</span> csum_error<span class="token punctuation">;</span>

<span class="token function">UDP_INC_STATS_BH</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> UDP_MIB_NOPORTS<span class="token punctuation">,</span> proto <span class="token operator">==</span> IPPROTO_UDPLITE<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">icmp_send</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> ICMP_DEST_UNREACH<span class="token punctuation">,</span> ICMP_PORT_UNREACH<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/*
 * Hmm.  We got an UDP packet to a port to which we
 * don&apos;t wanna listen.  Ignore it.
 */</span>
<span class="token function">kfree_skb</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
</code></pre>
<h4 id="udpqueuercvskb"><a name="udpqueuercvskb" class="anchor-navigation-ex-anchor" href="#udpqueuercvskb"><i class="fa fa-link" aria-hidden="true"></i></a><code>udp_queue_rcv_skb</code></h4>
<p>The initial parts of this function are as follows:</p>
<ol>
<li>Determine if the socket associated with the datagram is an <a href="https://tools.ietf.org/html/rfc3948" target="_blank">encapsulation</a> socket. If so, pass the packet up to that layer&#x2019;s handler function before proceeding.</li>
<li>Determine if the datagram is a UDP-Lite datagram and do some integrity checks.</li>
<li>Verify the UDP checksum of the datagram and drop it if the checksum fails.</li>
</ol>
<p>Finally, we arrive at the receive queue logic which begins by checking if the receive queue for the socket is full. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c#L1548-L1549" target="_blank"><code>net/ipv4/udp.c</code></a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">sk_rcvqueues_full</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> sk<span class="token operator">-&gt;</span>sk_rcvbuf<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">goto</span> drop<span class="token punctuation">;</span>
</code></pre>
<h4 id="skrcvqueuesfull"><a name="skrcvqueuesfull" class="anchor-navigation-ex-anchor" href="#skrcvqueuesfull"><i class="fa fa-link" aria-hidden="true"></i></a><code>sk_rcvqueues_full</code></h4>
<p>The <code>sk_rcvqueues_full</code> function checks the socket&#x2019;s backlog length and the socket&#x2019;s <code>sk_rmem_alloc</code> to determine if the sum is greater than the <code>sk_rcvbuf</code> for the socket (<code>sk-&gt;sk_rcvbuf</code> in the above code snippet):</p>
<pre class="language-"><code class="lang-c"><span class="token comment">/*
 * Take into account size of receive queue and backlog queue
 * Do not take into account this skb truesize,
 * to allow even a single big packet to come.
 */</span>
<span class="token keyword">static</span> <span class="token keyword">inline</span> bool <span class="token function">sk_rcvqueues_full</span><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">sock</span> <span class="token operator">*</span>sk<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">sk_buff</span> <span class="token operator">*</span>skb<span class="token punctuation">,</span>
                                     <span class="token keyword">unsigned</span> <span class="token keyword">int</span> limit<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
        <span class="token keyword">unsigned</span> <span class="token keyword">int</span> qsize <span class="token operator">=</span> sk<span class="token operator">-&gt;</span>sk_backlog<span class="token punctuation">.</span>len <span class="token operator">+</span> <span class="token function">atomic_read</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sk<span class="token operator">-&gt;</span>sk_rmem_alloc<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">return</span> qsize <span class="token operator">&gt;</span> limit<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Tuning these values is a bit tricky as there are many things that can be adjusted.</p>
<h5 id="tuning-socket-receive-queue-memory"><a name="tuning-socket-receive-queue-memory" class="anchor-navigation-ex-anchor" href="#tuning-socket-receive-queue-memory"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning: Socket receive queue memory</h5>
<p>The <code>sk-&gt;sk_rcvbuf</code> (called limit in <code>sk_rcvqueues_full</code> above) value can be increased to whatever the sysctl <code>net.core.rmem_max</code> is set to.</p>
<p>Increase the maximum receive buffer size by setting a <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.core.rmem_max=8388608</code></p>
<p><code>sk-&gt;sk_rcvbuf</code> starts at the <code>net.core.rmem_default</code> value, which can also be adjusted by setting a sysctl, like so:</p>
<p>Adjust the default initial receive buffer size by setting a <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.core.rmem_default=8388608</code></p>
<p>You can also set the <code>sk-&gt;sk_rcvbuf</code> size by calling <a href="http://www.manpagez.com/man/2/setsockopt/" target="_blank"><code>setsockopt</code></a> from your application and passing <code>SO_RCVBUF</code>. The maximum you can set with <code>setsockopt</code> is <code>net.core.rmem_max</code>.</p>
<p>However, you can override the <code>net.core.rmem_max</code> limit by calling <code>setsockopt</code> and passing <code>SO_RCVBUFFORCE</code>, but the user running the application will need the <code>CAP_NET_ADMIN</code> capability.</p>
<p>The <code>sk-&gt;sk_rmem_alloc</code> value is incremented by calls to <code>skb_set_owner_r</code> which set the owner socket of a datagram. We&#x2019;ll see this called later in the UDP layer.</p>
<p>The <code>sk-&gt;sk_backlog.len</code> is incremented by calls to <code>sk_add_backlog</code>, which we&#x2019;ll see next.</p>
<h4 id="udpqueuercvskb_1"><a name="udpqueuercvskb_1" class="anchor-navigation-ex-anchor" href="#udpqueuercvskb_1"><i class="fa fa-link" aria-hidden="true"></i></a><code>udp_queue_rcv_skb</code></h4>
<p>Once it&#x2019;s been verified that the queue is not full, progress toward queuing the datagram can continue. From <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c#L1554-L1561" target="_blank">net/ipv4/udp.c</a>:</p>
<pre class="language-"><code class="lang-c"><span class="token function">bh_lock_sock</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">sock_owned_by_user</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">)</span>
  rc <span class="token operator">=</span> <span class="token function">__udp_queue_rcv_skb</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">sk_add_backlog</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> sk<span class="token operator">-&gt;</span>sk_rcvbuf<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token function">bh_unlock_sock</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">goto</span> drop<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token function">bh_unlock_sock</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">return</span> rc<span class="token punctuation">;</span>
</code></pre>
<p>The first step is determine if the socket currently has any system calls against it from a userland program. If it does <strong>not</strong>, the datagram can be added to the receive queue with a call to <code>__udp_queue_rcv_skb</code>. If it does, the datagram is queued to the backlog with a call to <code>sk_add_backlog</code>.</p>
<p>The datagrams on the backlog are added to the receive queue when socket system calls release the socket with a call to <code>release_sock</code> in the kernel.</p>
<h4 id="udpqueuercvskb_2"><a name="udpqueuercvskb_2" class="anchor-navigation-ex-anchor" href="#udpqueuercvskb_2"><i class="fa fa-link" aria-hidden="true"></i></a><code>__udp_queue_rcv_skb</code></h4>
<p>The <code>__udp_queue_rcv_skb</code> function adds datagrams to the receive queue by calling <code>sock_queue_rcv_skb</code> and bumps statistics counters if the datagram could not be added to the receive queue for the socket.</p>
<p>From <a href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c#L1431-L1443" target="_blank">net/ipv4/udp.c</a>:</p>
<pre class="language-"><code class="lang-c">rc <span class="token operator">=</span> <span class="token function">sock_queue_rcv_skb</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>rc <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">int</span> is_udplite <span class="token operator">=</span> <span class="token function">IS_UDPLITE</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">/* Note that an ENOMEM error is charged twice */</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>rc <span class="token operator">==</span> <span class="token operator">-</span>ENOMEM<span class="token punctuation">)</span>
    <span class="token function">UDP_INC_STATS_BH</span><span class="token punctuation">(</span><span class="token function">sock_net</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">,</span> UDP_MIB_RCVBUFERRORS<span class="token punctuation">,</span>is_udplite<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token function">UDP_INC_STATS_BH</span><span class="token punctuation">(</span><span class="token function">sock_net</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">,</span> UDP_MIB_INERRORS<span class="token punctuation">,</span> is_udplite<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">kfree_skb</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">trace_udp_fail_queue_rcv_skb</span><span class="token punctuation">(</span>rc<span class="token punctuation">,</span> sk<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<h4 id="monitoring-udp-protocol-layer-statistics"><a name="monitoring-udp-protocol-layer-statistics" class="anchor-navigation-ex-anchor" href="#monitoring-udp-protocol-layer-statistics"><i class="fa fa-link" aria-hidden="true"></i></a>Monitoring: UDP protocol layer statistics</h4>
<p>Two very useful files for getting UDP protocol statistics are:</p>
<ul>
<li><code>/proc/net/snmp</code></li>
<li><code>/proc/net/udp</code></li>
</ul>
<h5 id="procnetsnmp"><a name="procnetsnmp" class="anchor-navigation-ex-anchor" href="#procnetsnmp"><i class="fa fa-link" aria-hidden="true"></i></a><code>/proc/net/snmp</code></h5>
<p>Monitor detailed UDP protocol statistics by reading <code>/proc/net/snmp</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/net/snmp <span class="token operator">|</span> <span class="token function">grep</span> Udp<span class="token punctuation">\</span>:
Udp: InDatagrams NoPorts InErrors OutDatagrams RcvbufErrors SndbufErrors
Udp: <span class="token number">16314</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">17161</span> <span class="token number">0</span> <span class="token number">0</span>
</code></pre>
<p>Much like the detailed statistics found in this file for the IP protocol, you will need to read the protocol layer source to determine exactly when and where these values are incremented.</p>
<ul>
<li><code>InDatagrams</code>: Incremented when <code>recvmsg</code> was used by a userland program to read datagram. Also incremented when a UDP packet is encapsulated and sent back for processing.</li>
<li><code>NoPorts</code>: Incremented when UDP packets arrive destined for a port where no program is listening.</li>
<li><code>InErrors</code>: Incremented in several cases: no memory in the receive queue, when a bad checksum is seen, and if <code>sk_add_backlog</code> fails to add the datagram.</li>
<li><code>OutDatagrams</code>: Incremented when a UDP packet is handed down without error to the IP protocol layer to be sent.</li>
<li><code>RcvbufErrors</code>: Incremented when <code>sock_queue_rcv_skb</code> reports that no memory is available; this happens if <code>sk-&gt;sk_rmem_alloc</code> is greater than or equal to <code>sk-&gt;sk_rcvbuf</code>.</li>
<li><code>SndbufErrors</code>: Incremented if the IP protocol layer reported an error when trying to send the packet and no error queue has been setup. Also incremented if no send queue space or kernel memory are available.</li>
<li><code>InCsumErrors</code>: Incremented when a UDP checksum failure is detected. Note that in all cases I could find, <code>InCsumErrors</code> is incrememnted at the same time as <code>InErrors</code>. Thus, <code>InErrors</code> - <code>InCsumErros</code> should yield the count of memory related errors on the receive side.</li>
</ul>
<h5 id="procnetudp"><a name="procnetudp" class="anchor-navigation-ex-anchor" href="#procnetudp"><i class="fa fa-link" aria-hidden="true"></i></a><code>/proc/net/udp</code></h5>
<p>Monitor UDP socket statistics by reading <code>/proc/net/udp</code></p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /proc/net/udp
  sl  local_address rem_address   st tx_queue rx_queue <span class="token function">tr</span> tm-<span class="token operator">&gt;</span>when retrnsmt   uid  <span class="token function">timeout</span> inode ref pointer drops
  <span class="token number">515</span>: 00000000:B346 00000000:0000 07 00000000:00000000 00:00000000 00000000   <span class="token number">104</span>        <span class="token number">0</span> <span class="token number">7518</span> <span class="token number">2</span> 0000000000000000 <span class="token number">0</span>
  <span class="token number">558</span>: 00000000:0371 00000000:0000 07 00000000:00000000 00:00000000 00000000     <span class="token number">0</span>        <span class="token number">0</span> <span class="token number">7408</span> <span class="token number">2</span> 0000000000000000 <span class="token number">0</span>
  <span class="token number">588</span>: 0100007F:038F 00000000:0000 07 00000000:00000000 00:00000000 00000000     <span class="token number">0</span>        <span class="token number">0</span> <span class="token number">7511</span> <span class="token number">2</span> 0000000000000000 <span class="token number">0</span>
  <span class="token number">769</span>: 00000000:0044 00000000:0000 07 00000000:00000000 00:00000000 00000000     <span class="token number">0</span>        <span class="token number">0</span> <span class="token number">7673</span> <span class="token number">2</span> 0000000000000000 <span class="token number">0</span>
  <span class="token number">812</span>: 00000000:006F 00000000:0000 07 00000000:00000000 00:00000000 00000000     <span class="token number">0</span>        <span class="token number">0</span> <span class="token number">7407</span> <span class="token number">2</span> 0000000000000000 <span class="token number">0</span>
</code></pre>
<p>The first line describes each of the fields in the lines following:</p>
<ul>
<li><code>sl</code>: Kernel hash slot for the socket</li>
<li><code>local_address</code>: Hexadecimal local address of the socket and port number, separated by <code>:</code>.</li>
<li><code>rem_address</code>: Hexadecimal remote address of the socket and port number, separated by <code>:</code>.</li>
<li><code>st</code>: The state of the socket. Oddly enough, the UDP protocol layer seems to use some TCP socket states. In the example above, <code>7</code> is <code>TCP_CLOSE</code>.</li>
<li><code>tx_queue</code>: The amount of memory allocated in the kernel for outgoing UDP datagrams.</li>
<li><code>rx_queue</code>: The amount of memory allocated in the kernel for incoming UDP datagrams.</li>
<li><code>tr</code>, <code>tm-&gt;when</code>, <code>retrnsmt</code>: These fields are unused by the UDP protocol layer.</li>
<li><code>uid</code>: The effective user id of the user who created this socket.</li>
<li><code>timeout</code>: Unused by the UDP protocol layer.</li>
<li><code>inode</code>: The inode number corresponding to this socket. You can use this to help you determine which user process has this socket open. Check <code>/proc/[pid]/fd</code>, which will contain symlinks to <code>socket[:inode]</code>.</li>
<li><code>ref</code>: The current reference count for the socket.</li>
<li><code>pointer</code>: The memory address in the kernel of the <code>struct sock</code>.</li>
<li><code>drops</code>: The number of datagram drops associated with this socket. Note that this does not include any drops related to sending datagrams (on corked UDP sockets or otherwise); this is only incremented in receive paths as of the kernel version examined by this blog post.</li>
</ul>
<p>The code which outputs this can <a href="https://github.com/torvalds/linux/blob/master/net/ipv4/udp.c#L2396-L2431" target="_blank">be found in <code>net/ipv4/udp.c</code></a>.</p>
<h3 id="queuing-data-to-a-socket"><a name="queuing-data-to-a-socket" class="anchor-navigation-ex-anchor" href="#queuing-data-to-a-socket"><i class="fa fa-link" aria-hidden="true"></i></a>4.9.4. Queuing data to a socket</h3>
<p>Network data is queued to a socket with a call to <code>sock_queue_rcv</code>. This function does a few things before adding the datagram to the queue:</p>
<ol>
<li>The socket&#x2019;s allocated memory is checked to determine if it has exceeded the receive buffer size. If so, the drop count for the socket is incremented.</li>
<li>Next <code>sk_filter</code> is used to process any Berkeley Packet Filter filters that have been applied to the socket.</li>
<li><code>sk_rmem_schedule</code> is run to ensure sufficient receive buffer space exists to accept this datagram.</li>
<li>Next the size of the datagram is charged to the socket with a call to <code>skb_set_owner_r</code>. This increments <code>sk-&gt;sk_rmem_alloc</code>.</li>
<li>The data is added to the queue with a call to <code>__skb_queue_tail</code>.</li>
<li>Finally, any processes waiting on data to arrive in the socket are notified with a call to the <code>sk_data_ready</code> notification handler function.</li>
</ol>
<p>And that is how data arrives at a system and traverses the network stack until it reaches a socket and is ready to be read by a user program.</p>
<h2 id="extras"><a name="extras" class="anchor-navigation-ex-anchor" href="#extras"><i class="fa fa-link" aria-hidden="true"></i></a>4.10. Extras</h2>
<p>There are a few extra things worth mentioning that are worth mentioning which didn&#x2019;t seem quite right anywhere else.</p>
<h3 id="timestamping"><a name="timestamping" class="anchor-navigation-ex-anchor" href="#timestamping"><i class="fa fa-link" aria-hidden="true"></i></a>4.10.1. Timestamping</h3>
<p>As mentioned in the above blog post, the networking stack can collect timestamps of incoming data. There are sysctl values controlling when/how to collect timestamps when used in conjunction with RPS; see the above post for more information on RPS, timestamping, and where, exactly, in the network stack receive timestamping happens. Some NICs even support timestamping in hardware, too.</p>
<p>This is a useful feature if you&#x2019;d like to try to determine how much latency the kernel network stack is adding to receiving packets.</p>
<p>The <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/timestamping.txt" target="_blank">kernel documentation about timestamping</a> is excellent and there is even an included sample program and Makefile <a href="https://github.com/torvalds/linux/tree/v3.13/Documentation/networking/timestamping" target="_blank">you can check out!</a>.</p>
<p>Determine which timestamp modes your driver and device support with <code>ethtool -T</code>.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">sudo</span> <span class="token function">ethtool</span> <span class="token parameter variable">-T</span> eth0
Time stamping parameters <span class="token keyword">for</span> eth0:
Capabilities:
  software-transmit     <span class="token punctuation">(</span>SOF_TIMESTAMPING_TX_SOFTWARE<span class="token punctuation">)</span>
  software-receive      <span class="token punctuation">(</span>SOF_TIMESTAMPING_RX_SOFTWARE<span class="token punctuation">)</span>
  software-system-clock <span class="token punctuation">(</span>SOF_TIMESTAMPING_SOFTWARE<span class="token punctuation">)</span>
PTP Hardware Clock: none
Hardware Transmit Timestamp Modes: none
Hardware Receive Filter Modes: none
</code></pre>
<p>This NIC, unfortunately, does not support hardware receive timestamping, but software timestamping can still be used on this system to help me determine how much latency the kernel is adding to my packet receive path.</p>
<h3 id="busy-polling-for-low-latency-sockets"><a name="busy-polling-for-low-latency-sockets" class="anchor-navigation-ex-anchor" href="#busy-polling-for-low-latency-sockets"><i class="fa fa-link" aria-hidden="true"></i></a>4.10.2. Busy polling for low latency sockets</h3>
<p>It is possible to use a socket option called <code>SO_BUSY_POLL</code> which will cause the kernel to busy poll for new data when a blocking receive is done and there is no data.</p>
<p>IMPORTANT NOTE: For this option to work, your device driver must support it. Linux kernel 3.13.0&#x2019;s <code>igb</code> driver does not support this option. The <code>ixgbe</code> driver, however, does. If your driver has a function set to the <code>ndo_busy_poll</code> field of its <code>struct net_device_ops</code> structure (mentioned in the above blog post), it supports <code>SO_BUSY_POLL</code>.</p>
<p>A great paper explaining how this works and how to use it is available <a href="http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/open-source-kernel-enhancements-paper.pdf" target="_blank">from Intel</a>.</p>
<p>When using this socket option for a single socket, you should pass a time value in microseconds as the amount of time to busy poll in the device driver&#x2019;s receive queue for new data. When you issue a blocking read to this socket after setting this value, the kernel will busy poll for new data.</p>
<p>You can also set the sysctl value <code>net.core.busy_poll</code> to a time value in microseconds of how long calls with <code>poll</code> or <code>select</code> should busy poll waiting for new data to arrive, as well.</p>
<p>This option can reduce latency, but will increase CPU usage and power consumption.</p>
<h3 id="netpoll-support-for-networking-in-critical-contexts"><a name="netpoll-support-for-networking-in-critical-contexts" class="anchor-navigation-ex-anchor" href="#netpoll-support-for-networking-in-critical-contexts"><i class="fa fa-link" aria-hidden="true"></i></a>4.10.3. Netpoll: support for networking in critical contexts</h3>
<p>The Linux kernel provides a way for device drivers to be used to send and receive data on a NIC when the kernel has crashed. The API for this is called Netpoll and it is used by a few things, but most notably: <a href="http://sysprogs.com/VisualKernel/kgdboe/launch/" target="_blank">kgdb</a>, <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/netconsole.txt" target="_blank">netconsole</a>.</p>
<p>Most drivers support Netpoll; your driver needs to implement the <code>ndo_poll_controller</code> function and attach it to the <code>struct net_device_ops</code> that is registered during probe (as seen above).</p>
<p>When the networking device subsystem performs operations on incoming or outgoing data, the netpoll system is checked first to determine if the packet is destined for netpoll.</p>
<p>For example, we can see the following code in <code>__netif_receive_skb_core</code> from <a href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3511-L3514" target="_blank"><code>net/dev/core.c</code></a>:</p>
<pre class="language-"><code class="lang-c"><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">__netif_receive_skb_core</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">sk_buff</span> <span class="token operator">*</span>skb<span class="token punctuation">,</span> bool pfmemalloc<span class="token punctuation">)</span>
<span class="token punctuation">{</span>

  <span class="token comment">/* ... */</span>

  <span class="token comment">/* if we&apos;ve gotten here through NAPI, check netpoll */</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">netpoll_receive_skb</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">goto</span> out<span class="token punctuation">;</span>

  <span class="token comment">/* ... */</span>
<span class="token punctuation">}</span>
</code></pre>
<p>The Netpoll checks happen early in most of the Linux network device subsystem code that deals with transmitting or receiving network data.</p>
<p>Consumers of the Netpoll API can register <code>struct netpoll</code> structures by calling <code>netpoll_setup</code>. The <code>struct netpoll</code> structure has function pointers for attaching receive hooks, and the API exports a function for sending data.</p>
<p>If you are interested in using the Netpoll API, you should take a look at the <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/netconsole.c" target="_blank"><code>netconsole</code> driver</a>, the Netpoll API header file, <a href="https://github.com/torvalds/linux/blob/v3.13/include/linux/netpoll.h" target="_blank"><code>include/linux/netpoll.h</code></a>, and <a href="http://people.redhat.com/~jmoyer/netpoll-linux_kongress-2005.pdf" target="_blank">this excellent talk</a>.</p>
<h3 id="soincomingcpu"><a name="soincomingcpu" class="anchor-navigation-ex-anchor" href="#soincomingcpu"><i class="fa fa-link" aria-hidden="true"></i></a>4.10.4. SO_INCOMING_CPU</h3>
<p>The <code>SO_INCOMING_CPU</code> flag was not added until Linux 3.19, but it is useful enough that it should be included in this blog post.</p>
<p>You can use <code>getsockopt</code> with the <code>SO_INCOMING_CPU</code> option to determine which CPU is processing network packets for a particular socket. Your application can then use this information to hand sockets off to threads running on the desired CPU to help increase data locality and CPU cache hits.</p>
<p>The <a href="https://patchwork.ozlabs.org/patch/408257/" target="_blank">mailing list message</a> introducing <code>SO_INCOMING_CPU</code> provides a short example architecture where this option is useful.</p>
<h3 id="dma-engines"><a name="dma-engines" class="anchor-navigation-ex-anchor" href="#dma-engines"><i class="fa fa-link" aria-hidden="true"></i></a>4.10.5. DMA Engines</h3>
<p>A <a href="https://en.wikipedia.org/wiki/Direct_memory_access" target="_blank">DMA</a> engine is a piece of hardware that allows the CPU to offload large copy operations. This frees the CPU to do other tasks while memory copies are done with hardware. Enabling the use of a DMA engine and running code that takes advantage of it, should yield reduced CPU usage.</p>
<p>The Linux kernel has a generic DMA engine interface that DMA engine driver authors can plug into. You can read more about the Linux DMA engine interface in the <a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/dmaengine.txt" target="_blank">kernel source Documentation</a>.</p>
<p>While there are a few DMA engines that the kernel supports, we&#x2019;re going to discuss one in particular that is quite common: the <a href="https://en.wikipedia.org/wiki/I/O_Acceleration_Technology" target="_blank">Intel IOAT DMA engine</a>.</p>
<h4 id="intels-io-acceleration-technology-ioat"><a name="intels-io-acceleration-technology-ioat" class="anchor-navigation-ex-anchor" href="#intels-io-acceleration-technology-ioat"><i class="fa fa-link" aria-hidden="true"></i></a>Intel&#x2019;s I/O Acceleration Technology (IOAT)</h4>
<p>Many servers include the <a href="http://www.intel.com/content/www/us/en/wireless-network/accel-technology.html" target="_blank">Intel I/O AT bundle</a>, which is comprised of a series of performance changes.</p>
<p>One of those changes is the inclusion of a hardware DMA engine. You can check your <code>dmesg</code> output for <code>ioatdma</code> to determine if the module is being loaded and if it has found supported hardware.</p>
<p>The DMA offload engine is used in a few places, most notably in the TCP stack.</p>
<p>Support for the Intel IOAT DMA engine was included in Linux 2.6.18, but was disabled later in 3.13.11.10 due to some unfortunate <a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=77873803363c9e831fc1d1e6895c084279090c22" target="_blank">data corruption bugs</a>.</p>
<p>Users on kernels before 3.13.11.10 may be using the <code>ioatdma</code> module on their servers by default. Perhaps this will be fixed in future kernel releases.</p>
<h5 id="direct-cache-access-dca"><a name="direct-cache-access-dca" class="anchor-navigation-ex-anchor" href="#direct-cache-access-dca"><i class="fa fa-link" aria-hidden="true"></i></a>Direct cache access (DCA)</h5>
<p>Another interesting feature included with the <a href="http://www.intel.com/content/www/us/en/wireless-network/accel-technology.html" target="_blank">Intel I/O AT bundle</a> is Direct Cache Access (DCA).</p>
<p>This feature allows network devices (via their drivers) to place network data directly in the CPU cache. How this works, exactly, is driver specific. For the <code>igb</code> driver, you can check <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L5202-L5219" target="_blank">the code for the function <code>igb_update_dca</code></a>, as well as the code for <a href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L5182-L5200" target="_blank"><code>igb_update_rx_dca</code></a>. The <code>igb</code> driver uses DCA by writing a register value to the NIC.</p>
<p>To use DCA, you will need to ensure that DCA is enabled in your BIOS, the <code>dca</code> module is loaded, and that your network card and driver both support DCA.</p>
<h5 id="monitoring-ioat-dma-engine"><a name="monitoring-ioat-dma-engine" class="anchor-navigation-ex-anchor" href="#monitoring-ioat-dma-engine"><i class="fa fa-link" aria-hidden="true"></i></a>Monitoring IOAT DMA engine</h5>
<p>If you are using the <code>ioatdma</code> module despite the risk of data corruption mentioned above, you can monitor it by examining some entries in <code>sysfs</code>.</p>
<p>Monitor the total number of offloaded <code>memcpy</code> operations for a DMA channel.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /sys/class/dma/dma0chan0/memcpy_count
<span class="token number">123205655</span>
</code></pre>
<p>Similarly, to get the number of bytes offloaded by this DMA channel, you&#x2019;d run a command like:</p>
<p>Monitor total number of bytes transferred for a DMA channel.</p>
<pre class="language-"><code class="lang-sh">$ <span class="token function">cat</span> /sys/class/dma/dma0chan0/bytes_transferred
<span class="token number">131791916307</span>
</code></pre>
<h5 id="tuning-ioat-dma-engine"><a name="tuning-ioat-dma-engine" class="anchor-navigation-ex-anchor" href="#tuning-ioat-dma-engine"><i class="fa fa-link" aria-hidden="true"></i></a>Tuning IOAT DMA engine</h5>
<p>The IOAT DMA engine is only used when packet size is above a certain threshold. That threshold is called the <code>copybreak</code>. This check is in place because for small copies, the overhead of setting up and using the DMA engine is not worth the accelerated transfer.</p>
<p>Adjust the DMA engine copybreak with a <code>sysctl</code>.</p>
<p><code>$ sudo sysctl -w net.ipv4.tcp_dma_copybreak=2048</code></p>
<p>The default value is 4096.</p>
<h1 id="conclusion"><a name="conclusion" class="anchor-navigation-ex-anchor" href="#conclusion"><i class="fa fa-link" aria-hidden="true"></i></a>5. Conclusion</h1>
<p>The Linux networking stack is complicated.</p>
<p>It is impossible to monitor or tune it (or any other complex piece of software) without understanding at a deep level exactly what&#x2019;s going on. Often, out in the wild of the Internet, you may stumble across a sample <code>sysctl.conf</code> that contains a set of sysctl values that should be copied and pasted on to your computer. This is probably not the best way to optimize your networking stack.</p>
<p>Monitoring the networking stack requires careful accounting of network data at every layer. Starting with the drivers and proceeding up. That way you can determine where exactly drops and errors are occurring and then adjust settings to determine how to reduce the errors you are seeing.</p>
<p>There is, unfortunately, no easy way out.</p>
<h1 id="help-with-linux-networking-or-other-systems"><a name="help-with-linux-networking-or-other-systems" class="anchor-navigation-ex-anchor" href="#help-with-linux-networking-or-other-systems"><i class="fa fa-link" aria-hidden="true"></i></a>6. Help with Linux networking or other systems</h1>
<p>Need some extra help navigating the network stack? Have questions about anything in this post or related things not covered? Send us an <a href="mailto:support@packagecloud.io" target="_blank">email</a> and let us know how we can help.</p>
<h1 id="related-posts"><a name="related-posts" class="anchor-navigation-ex-anchor" href="#related-posts"><i class="fa fa-link" aria-hidden="true"></i></a>7. Related posts</h1>
<p>If you enjoyed this post, you may enjoy some of our other low-level technical posts:</p>
<ul>
<li><a href="https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/" target="_blank">Monitoring and Tuning the Linux Networking Stack: Sending Data</a></li>
<li><a href="https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/" target="_blank">The Definitive Guide to Linux System Calls</a></li>
<li><a href="https://blog.packagecloud.io/eng/2016/02/29/how-does-strace-work/" target="_blank">How does <code>strace</code> work?</a></li>
<li><a href="https://blog.packagecloud.io/eng/2016/03/14/how-does-ltrace-work/" target="_blank">How does <code>ltrace</code> work?</a></li>
<li><a href="https://blog.packagecloud.io/eng/2016/03/21/apt-hash-sum-mismatch/" target="_blank">APT Hash sum mismatch</a></li>
<li><a href="https://blog.packagecloud.io/eng/2014/10/28/howto-gpg-sign-verify-deb-packages-apt-repositories/" target="_blank">HOWTO: GPG sign and verify deb packages and APT repositories</a></li>
<li><a href="https://blog.packagecloud.io/eng/2014/11/24/howto-gpg-sign-verify-rpm-packages-yum-repositories/" target="_blank">HOWTO: GPG sign and verify RPM packages and yum repositories</a></li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="networking_杂记1.html" class="navigation navigation-prev " aria-label="Previous page: networking杂记1">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="networking_优化linux网络栈_发送路径.html" class="navigation navigation-next " aria-label="Next page: 优化linux网络栈: 发送路径(网摘)">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"优化linux网络栈: 接收路径(网摘)","level":"1.6.3","depth":2,"next":{"title":"优化linux网络栈: 发送路径(网摘)","level":"1.6.4","depth":2,"path":"notes/networking_优化linux网络栈_发送路径.md","ref":"notes/networking_优化linux网络栈_发送路径.md","articles":[]},"previous":{"title":"networking杂记1","level":"1.6.2","depth":2,"path":"notes/networking_杂记1.md","ref":"notes/networking_杂记1.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-livereload","-sharing","-lunr","-search","search-plus","-highlight","theme-comscore","prism","code","chapter-fold","github","splitter","wide-page","hide-navigation-buttons","anchor-navigation-ex","sequence@0.1.1","mermaid-gb3"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"chapter-fold":{},"prism":{"css":["prismjs/themes/prism.css"],"ignore":["mermaid","sequence"]},"sequence":{"theme":"simple"},"github":{"url":"https://github.com/Bai-Yingjie/Bai-Yingjie.github.io"},"splitter":{},"wide-page":{},"code":{"copyButtons":true},"fontsettings":{"theme":"white","family":"sans","size":2},"hide-navigation-buttons":{},"mermaid-gb3":{},"anchor-navigation-ex":{"mode":"float","pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"isRewritePageTitle":true,"showLevel":true,"tocLevel1Icon":"fa fa-hand-o-right","tocLevel2Icon":"fa fa-hand-o-right","tocLevel3Icon":"fa fa-hand-o-right","showGoTop":true,"isShowTocTitleIcon":true,"printLog":false,"multipleH1":true,"associatedWithSummary":true,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false}},"theme-comscore":{},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"search-plus":{}},"theme":"default","author":"Bai Yingjie","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"My Notes","language":"zh-hans","gitbook":"*"},"file":{"path":"notes/networking_优化linux网络栈_接收路径.md","mtime":"2024-05-07T02:12:59.275Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2024-05-07T02:13:53.958Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search-plus/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-plus/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mermaid-gb3/book/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-theme-comscore/test.js"></script>
        
    

    <script src="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.min.js"></script>

    </body>
</html>

