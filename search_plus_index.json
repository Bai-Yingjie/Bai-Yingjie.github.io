{"./":{"url":"./","title":"简介","keywords":"","body":"Bai-Yingjie.github.io 个人笔记汇总 https://bai-yingjie.github.io/ "},"notes/as_title.html":{"url":"notes/as_title.html","title":"Golang","keywords":"","body":"如题 "},"notes/golang_语法基础.html":{"url":"notes/golang_语法基础.html","title":"语法基础","keywords":"","body":" 初始化和空值 结构体 声明空切片 new切片 空切片的实例化 总结 字符串支持比较操作符 空白标识符 空白标识符和err 空白标识符和编译unused检查 空白标识符和类型检查 go 是静态类型语言 interface类型的变量可以重复赋值为任意类型 可以在循环里用:语法糖赋值 连续赋值可以支持重复声明 结构体和json反射 结构体定义里的反射字段 反射 Golang的单引号、双引号与反引号 变长参数 flag包用来解析cmd参数 内置len copy 和cap 字符串 字节数组 符文 常量和iota 格式化和scan print scan 减小go可执行文件的size go doc看说明 go内置pacakge go 环境变量 go test框架 远程包 go 工程布局(layout) 典型的go workspace布局 完整布局参考 go知识点 值传递和指针类型 struct 形式 结构体方法 基于指针对象的方法 继承 结构体可以比较 new分配内存 工厂模式初始化 接口 interface 类型断言 类型断言判断对象是否实现了一个接口 goroutine 通道 带缓冲的通道 通道用close来关闭 切片 切片的append map 集合 delete可以删除元素 range 初始化和空值 结构体 先说结论, 初始化时没有赋值的结构体, 其内容是零值, 但这个对象的地址不是nil; 这个对象也不能和nil比较 type MystructStr struct { s string a int } var ms MystructStr //ms是在地址0xc0000d00e0上的24字节大小的结构体 ({ 0 0}, main.MystructStr)@[*0xc0000d00e0, 24] //&ms不是nil, ms本身也不能和nil比较 声明空切片 对于切片, map等对象来说, 变量名代指切片; 切片的地址可以和nil比较, 切片也可以和nil比较, 这是两码事. 切片和nil可以比较是go语法的规定. var sl []int //判断成立, 会打印 //这里应该理解成, sl的内容为空; 注意sl的内容为空, 不是说它本身的地址是nil. //做为一个变量, sl本身的地址不可能为nil. if sl == nil { fmt.Println(\"nillll\") } new切片 对于new返回的地址, sn是真正的地址类似于sn := &[]int{}, 变量名指切片的地址那么sn就不是nil, 但它指向一个空的切片 sn := new([]int) if sn != nil { fmt.Println(sn) } //结果 &[] 空切片的实例化 //si不为nil si := []int{} 总结 //len(s1)=0;cap(s1)=0;s1==nil var s1 []int //len(s1)=0;cap(s1)=0;s2!=nil s2 := []int{} //len(s3)=0;cap(s3)=0;s3!=nil s3 := make([]int, 0) 指针是否为nil说的是指针是否指向东西. 切片等结构体头也类似于指针. 所以切片是否为nil也说的是切片头是否指向实际的东西 只有var s1 []int形式的声明, 声明了一个切片变量, 只是个声明, 没有给\"指针\"赋值, 所以此时s1为nil new也没有实例化, 但new返回指针, 指向interface对象本身, 所以也不是nil 其他形式, 比如:= make, 都会实例化, 即接口的\"指针\"字段都指向实例. 所以都不是nil 字符串支持比较操作符 原生的比较符可以直接用来比较字符串 ==, !=, >=, . 它们都返回bool值 另外一种写法是func Compare(str1, str2 string) int result1 := \"GFG\" > \"Geeks\" fmt.Println(\"Result 1: \", result1) result2 := \"GFG\" = \"for\" fmt.Println(\"Result 3: \", result3) result4 := \"Geeks\" 空白标识符 空白标识符可以占位任何类型 空白标识符和err if _, err := os.Stat(path); os.IsNotExist(err) { fmt.Printf(\"%s does not exist\\n\", path) } 有时为了省事, 直接把err给\"占位\"了, 这样是不对的. // Bad! This code will crash if path does not exist. fi, _ := os.Stat(path) if fi.IsDir() { fmt.Printf(\"%s is a directory\\n\", path) } 空白标识符和编译unused检查 go会检查代码, 没有用的import和变量会报错误. 用占位符可以让编译器happy: 这里fmt和io以及变量fd没有使用, 一般编译会报错, 用占位符就不会. package main import ( \"fmt\" \"io\" \"log\" \"os\" ) var _ = fmt.Printf // For debugging; delete when done. var _ io.Reader // For debugging; delete when done. func main() { fd, err := os.Open(\"test.go\") if err != nil { log.Fatal(err) } // TODO: use fd. _ = fd } 把import的包赋值给占位符, 相当于不用这个包, 但包里的init会被调用. import _ \"net/http/pprof\" 空白标识符和类型检查 go的类型检查发生在编译时, 传入的对象必须和函数的参数类型一致. 但也可以运行时检查: 下面是json的encoder代码, 它检查如果传入的值实现了json.Marshaler接口, 就调用这个值的MarshalJSON方法, 而不是调用标准的MarshalJSON方法. m, ok := val.(json.Marshaler) 这种运行时检查很常见, 比如判断一个值是否实现了某个接口, 可以这样: 用空白标识符来占位返回的值, 只看ok. if _, ok := val.(json.Marshaler); ok { fmt.Printf(\"value %v of type %T implements json.Marshaler\\n\", val, val) } json.Marshaler和json.RawMessage的定义 Linux Mint 19.1 Tessa $ go doc json.Marshaler type Marshaler interface { MarshalJSON() ([]byte, error) } Marshaler is the interface implemented by types that can marshal themselves into valid JSON. yingjieb@yingjieb-VirtualBox ~/repo/myrepo/try Linux Mint 19.1 Tessa $ go doc json.RawMessage type RawMessage []byte RawMessage is a raw encoded JSON value. It implements Marshaler and Unmarshaler and can be used to delay JSON decoding or precompute a JSON encoding. func (m RawMessage) MarshalJSON() ([]byte, error) func (m *RawMessage) UnmarshalJSON(data []byte) error 如果json.Marshaler的定义变了, 那么一个原本实现了这个接口的类型,就不再有效了. 此时只有等到运行时的类型断言才能知道, 有办法在编译时就知道吗? 可以: 用空白标识符可以进行静态检查: 这里用_代替变量名 //这里是个强制转换, 把nil转换为(*RawMessage) //我认为这里转换为(RawMessage)也行. var _ json.Marshaler = (*RawMessage)(nil) 如果json.Marshaler接口变化了, 这段代码就编不过. go 是静态类型语言 虽然go有语法糖, 可以根据右值来自动解析数据类型. 但不要把它当作动态语言来用了. // 编译器自动知道mys是string mys := \"hhhh\" // 给mys赋值64会报错: cannot use 64 (type int) as type string in assignment mys = 64 动态语言, 变量可以随便赋值为不同种类的. interface类型的变量可以重复赋值为任意类型 The interface{} (empty interface) type describes an interface with zero methods. Every Go type implements at least zero methods and therefore satisfies the empty interface. func describe(i interface{}) { fmt.Printf(\"(%v, %T)\\n\", i, i) } var mi interface{} mi = \"a string\" describe(mi) mi = 2011 describe(mi) mi = 2.777 describe(mi) #输出 (a string, string) (2011, int) (2.777, float64) 可以在循环里用:语法糖赋值 func main() { fmt.Println(\"Hello, playground\") for i := 0; i 连续赋值可以支持重复声明 一般在一个语句块里, 不能对单个变量重复用:=声明; 但可以对连续变量重复声明 Unlike regular variable declarations, a short variable declaration may redeclare variables provided they were originally declared earlier in the same block with the same type, and at least one of the non-blank variables is new. As a consequence, redeclaration can only appear in a multi-variable short declaration. Redeclaration does not introduce a new variable; it just assigns a new value to the original. v := 1 v := 2 fmt.Println(v) // 编译时, 只有v的第二次冒号赋值会报错. ./prog.go:18:4: no new variables on left side of := // 但下面是可以的 func main() { a, b := 1, 2 c, b := 3, 4 fmt.Println(a, b, c) } // 一个经常见的例子是 f, err := os.Open(name) if err != nil { return err } d, err := f.Stat() if err != nil { f.Close() return err } codeUsing(f, d) 注: open等调用返回的error是个内建的类型, 必须用if err != nil来判断; 不能用if err来判断, 因为error类型不是bool类型 ./prog.go:11:2: non-bool err (type error) used as if condition 结构体和json反射 结构体定义里的反射字段 先定义和json对应的struct, 要导出的字段首字母大写. json.Unmarshal()把json转为struct json.Marshal()把struct转为json 这里的反射大概是指//可以选择的控制字段有三种： // -：不要解析这个字段 // omitempty：当字段为空（默认值）时，不要解析这个字段。比如 false、0、nil、长度为 0 的 array，map，slice，string // FieldName：当解析 json 的时候，使用这个名字 type StudentWithOption struct { StudentId string //默认使用原定义中的值 StudentName string `json:\"sname\"` // 解析（encode/decode） 的时候，使用 `sname`，而不是 `Field` StudentClass string `json:\"class,omitempty\"` // 解析的时候使用 `class`，如果struct 中这个值为空，就忽略它 StudentTeacher string `json:\"-\"` // 解析的时候忽略该字段。默认情况下会解析这个字段，因为它是大写字母开头的 } //与json数据对应的结构体 type Server struct { ServerName string ServerIP string } // 数组对应slice type ServerSlice struct { Servers []Server } //将JSON数据解析成结构体 package main import ( \"encoding/json\" \"fmt\" ) func main() { var s ServerSlice str := `{\"servers\":[{\"serverName\":\"TianJin\",\"serverIP\":\"127.0.0.1\"}, {\"serverName\":\"Beijing\",\"serverIP\":\"127.0.0.2\"}]}` json.Unmarshal([]byte(str), &s) fmt.Println(s) } ----output----- {[{TianJin 127.0.0.1} {Beijing 127.0.0.2}]} 反射 Reflection（反射）在计算机中表示 程序能够检查自身结构的能力，尤其是类型 func main() { var x float64 = 3.4 fmt.Println(reflect.TypeOf(x)) //float64 t := reflect.TypeOf(x) fmt.Println(t) //float64 // 注: 我认为其输出也可以叫reflect.Type fmt.Println(reflect.TypeOf(t)) //*reflect.rtype //相关代码在 go/src/reflect/value.go v := reflect.ValueOf(x) fmt.Println(v) //3.4 fmt.Println(reflect.TypeOf(v)) //reflect.Value fmt.Println(v.Interface()) //3.4 fmt.Println(v.Type()) //float64 } 变量包括（type, value）两部分 type 包括 static type和concrete type. 简单来说 static type是你在编码是看见的类型(如int、string)，concrete type是runtime系统看见的类型 类型断言能否成功，取决于变量的concrete type，而不是static type. 因此，一个 reader变量如果它的concrete type也实现了write方法的话，它也可以被类型断言为writer. 只有interface类型才有反射一说 每个interface变量都有一个对应pair，pair中记录了实际变量的值和类型 (value, type) reflect包api //ValueOf用来获取输入参数接口中的数据的值，如果接口为空则返回0 func ValueOf(i interface{}) Value {...} //func TypeOf(i interface{}) Type {...} func TypeOf(i interface{}) Type {...} 反射可以大大提高程序的灵活性，使得interface{}有更大的发挥余地 反射必须结合interface才玩得转 变量的type要是concrete type的（也就是interface变量）才有反射一说 反射可以将“接口类型变量”转换为“反射类型对象” 反射使用 TypeOf 和 ValueOf 函数从接口中获取目标对象信息 反射可以将“反射类型对象”转换为“接口类型变量 reflect.value.Interface().(已知的类型) 遍历reflect.Type的Field获取其Field 反射可以修改反射类型对象，但是其值必须是“addressable” 想要利用反射修改对象状态，前提是 interface.data 是 settable,即 pointer-interface 通过反射可以“动态”调用方法 因为Golang本身不支持模板，因此在以往需要使用模板的场景下往往就需要使用反射(reflect)来实现 Golang的单引号、双引号与反引号 Go语言的字符串类型string在本质上就与其他语言的字符串类型不同： Java的String、C++的std::string以及Python3的str类型都只是定宽字符序列 Go语言的字符串是一个用UTF-8编码的变宽字符序列，它的每一个字符都用一个或多个字节表示 即：一个Go语言字符串是一个任意字节的常量序列。 Golang的双引号和反引号都可用于表示一个常量字符串，不同在于： 双引号用来创建可解析的字符串字面量(支持转义，但不能用来引用多行) 反引号用来创建原生的字符串字面量，这些字符串可能由多行组成(不支持任何转义序列)，原生的字符串字面量多用于书写多行消息、HTML以及正则表达式 而单引号则用于表示Golang的一个特殊类型：rune，类似其他语言的byte但又不完全一样，是指：码点字面量（Unicode code point），不做任何转义的原始内容。 变长参数 func append(slice []Type, elems ...Type) []Type //举例 orig, err := ioutil.ReadFile(file) //这里orig后面的三个点, 是展开orig的意思 in := append([]byte{}, orig...) //举例 func sum(nums ...int) { fmt.Print(nums, \" \") //输出如 [1, 2, 3] 之类的数组 total := 0 for _, num := range nums { //要的是值而不是下标 total += num } fmt.Println(total) } func main() { sum(1, 2) sum(1, 2, 3) //传数组 nums := []int{1, 2, 3, 4} //相当于把nums打散成元素, 依次传入sum sum(nums...) } flag包用来解析cmd参数 import \"flag\" //定义flag, flag.Int返回一个指针: *int var ip = flag.Int(\"flagname\", 1234, \"help message for flagname\") flag.Var(&flagVal, \"name\", \"help message for flagname\") //定义完了调用, 调用完了指针才会有内容 flag.Parse() //代码里使用flag fmt.Println(\"ip has value \", *ip) fmt.Println(\"flagvar has value \", flagvar) //cmd参数形式 --flag -flag -flag=x --flag=x -flag x // non-boolean flags only //integer可以是如下形式, 也可以为负数 1234, 0664, 0x1234 //Bool可以是 1, 0, t, f, T, F, true, false, TRUE, FALSE, True, False 内置len copy 和cap // cap是最大容量, len是实际容量 func cap(v Type) int func len(v Type) int func copy(dst, src []Type) int 字符串 字节数组 符文 []byte: byte数组 b := []byte(\"ABC€\") fmt.Println(b) // [65 66 67 226 130 172] //go的string是unicode编码(变长)的byte数组 s := string([]byte{65, 66, 67, 226, 130, 172}) fmt.Println(s) // ABC€ character € is encoded in UTF-8 using 3 bytes string: 本质上是只读的的byte数组, 对string的index返回对应的byte; 对大于255的字符(character)来说, 占多个byte func main() { const placeOfInterest = `⌘` fmt.Printf(\"plain string: \") fmt.Printf(\"%s\", placeOfInterest) fmt.Printf(\"\\n\") fmt.Printf(\"quoted string: \") fmt.Printf(\"%+q\", placeOfInterest) fmt.Printf(\"\\n\") fmt.Printf(\"hex bytes: \") for i := 0; i UTF-8用1到6个字节编码Unicode字符 rune: 是int32的别名 常量和iota 在常量表达式里面使用iota, 从0开始, 每行加一. type Stereotype int const ( TypicalNoob Stereotype = iota // 0 TypicalHipster // 1 TypicalHipster = iota TypicalUnixWizard // 2 TypicalUnixWizard = iota TypicalStartupFounder // 3 TypicalStartupFounder = iota ) //如果两个const的赋值语句的表达式是一样的，那么可以省略后一个赋值表达式。 type AudioOutput int const ( OutMute AudioOutput = iota // 0 OutMono // 1 OutStereo // 2 _ _ OutSurround // 5 ) type Allergen int const ( IgEggs Allergen = 1 格式化和scan print // 定义示例类型和变量 type Human struct { Name string } var people = Human{Name:\"zhangsan\"} 普通占位符 占位符 说明 举例 输出 %v 相应值的默认格式。 Printf(\"%v\", people) {zhangsan}， %+v 打印结构体时，会添加字段名 Printf(\"%+v\", people) {Name:zhangsan} %#v 相应值的Go语法表示 Printf(\"%#v\", people) main.Human{Name:\"zhangsan\"} %T 相应值的类型的Go语法表示 Printf(\"%T\", people) main.Human %% 字面上的百分号，并非值的占位符 Printf(\"%%\") % func describe(i interface{}) { fmt.Printf(\"(%v, %T)\\n\", i, i) } 整数占位符 占位符 说明 举例 输出 %b 二进制表示 Printf(\"%b\", 5) 101 %c 相应Unicode码点所表示的字符 Printf(\"%c\", 0x4E2D) 中 %d 十进制表示 Printf(\"%d\", 0x12) 18 %o 八进制表示 Printf(\"%d\", 10) 12 %q 单引号围绕的字符字面值，由Go语法安全地转义 Printf(\"%q\", 0x4E2D) '中' %x 十六进制表示，字母形式为小写 a-f Printf(\"%x\", 13) d %X 十六进制表示，字母形式为大写 A-F Printf(\"%x\", 13) D %U Unicode格式：U+1234，等同于 \"U+%04X\" Printf(\"%U\", 0x4E2D) U+4E2D 字符串与字节切片 占位符 说明 举例 输出 %s 输出字符串表示（string类型或[]byte) Printf(\"%s\", []byte(\"Go语言\")) Go语言 %q 双引号围绕的字符串，由Go语法安全地转义 Printf(\"%q\", \"Go语言\") \"Go语言\" %x 十六进制，小写字母，每字节两个字符 Printf(\"%x\", \"golang\") 676f6c616e67 %X 十六进制，大写字母，每字节两个字符 Printf(\"%X\", \"golang\") 676F6C616E67 指针 占位符 说明 举例 输出 %p 十六进制表示，前缀 0x Printf(\"%p\", &people) 0x4f57f0 其它标记 占位符 说明 举例 输出 + 总打印数值的正负号；对于%q（%+q）保证只输出ASCII编码的字符。 Printf(\"%+q\", \"中文\") \"\\u4e2d\\u6587\" - 在右侧而非左侧填充空格（左对齐该区域） # 备用格式：为八进制添加前导 0（%#o） Printf(\"%#U\", '中') U+4E2D 为十六进制添加前导 0x（%#x）或 0X（%#X），为 %p（%#p）去掉前导 0x； 如果可能的话，%q（%#q）会打印原始 （即反引号围绕的）字符串； 如果是可打印字符，%U（%#U）会写出该字符的 Unicode 编码形式（如字符 x 会被打印成 U+0078 'x'）。 ' ' (空格)为数值中省略的正负号留出空白（% d）； 以十六进制（% x, % X）打印字符串或切片时，在字节之间用空格隔开 0 填充前导的0而非空格；对于数字，这会将填充移到正负号之后 scan package main import ( \"fmt\" ) func main() { var name string var age int n, err := fmt.Sscanf(\"Kim is 22 years old\", \"%s is %d years old\", &name, &age) if err != nil { panic(err) } fmt.Printf(\"%d: %s, %d\\n\", n, name, age) } 减小go可执行文件的size #之前是15M, 带符号表 go build -ldflags \"-s -w\" main.go #之后是7.3M, 不带符号表 go tool link -h -s disable symbol table -w disable DWARF generation 不影响panic的打印信息 比如, 在hello.go加入一行panic() # 不要符号表, 不要DWARF go build -ldflags \"-s -w\" hello.go # 还是有panic信息 $ ./hello panic: goroutine 1 [running]: main.main() /repo/yingjieb/godev/practice/src/examples/hello.go:39 +0xa3 注: 如果是gccgo, strip符号表会导致panic的打印没有调用栈信息. go doc看说明 #格式化输出的 go doc fmt #命令行解析的 do doc flag #导出变量的, via HTTP at /debug/vars in JSON format ??? go doc expvar go内置pacakge go的内置package在toolchain的src目录下, 都是go文件. yingjieb@yingjieb-VirtualBox ~/repo/gorepo/go/src Linux Mint 19.1 Tessa $ ls all.bash archive builtin clean.rc container debug flag html io make.bat mime os race.bat run.bat strconv testdata unicode all.bat bootstrap.bash bytes cmd context encoding fmt image iostest.bash Make.dist naclmake.bash path reflect run.rc strings testing unsafe all.rc bufio clean.bash cmp.bash crypto errors go index log make.rc nacltest.bash plugin regexp runtime sync text androidtest.bash buildall.bash clean.bat compress database expvar hash internal make.bash math net race.bash run.bash sort syscall time go 环境变量 $GOROOT : go toolchain的目录, 在编译go toolchain时写入默认值为all.bash的上级目录, 比如/root/go-mips64; 可用来在多个go toolchain间切换; buildroot默认在HOST_GO_ROOT = $(HOST_DIR)/lib/go, 见package/go/go.mk $GOOS and $GOARCH : 目标OS和CPU arch, 比如linux 和mips64. 默认是$GOHOSTOS and $GOHOSTARCH $GOPATH : 所有go程序的工作目录, 默认是用户home/go $GOBIN : go可执行二进制目录, 用go命令安装的bin在此. 默认是$GOPATH/bin 比如go get golang.org/x/tools/cmd/godoc下载, 编译, 安装$GOBIN/godoc 参考: go环境变量 Linux Mint 19.1 Tessa $ go env GOARCH=\"amd64\" GOBIN=\"\" GOCACHE=\"/home/yingjieb/.cache/go-build\" GOEXE=\"\" GOHOSTARCH=\"amd64\" GOHOSTOS=\"linux\" GOOS=\"linux\" GOPATH=\"/home/yingjieb/go\" GORACE=\"\" GOROOT=\"/usr/lib/go-1.10\" GOTMPDIR=\"\" GOTOOLDIR=\"/usr/lib/go-1.10/pkg/tool/linux_amd64\" GCCGO=\"gccgo\" CC=\"gcc\" CXX=\"g++\" CGO_ENABLED=\"1\" CGO_CFLAGS=\"-g -O2\" CGO_CPPFLAGS=\"\" CGO_CXXFLAGS=\"-g -O2\" CGO_FFLAGS=\"-g -O2\" CGO_LDFLAGS=\"-g -O2\" PKG_CONFIG=\"pkg-config\" GOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build439003515=/tmp/go-build -gno-record-gcc-switches\" go test框架 go有个集成的test框架, 包括 go test命令 需包含testing包 被test的package下面, 创建xxx_test.go, 包含func TestXxx(t *testing.T) 比如package stringutil里实现了字符串反转的方法, 那么, 它的test要这么写 package stringutil import \"testing\" func TestReverse(t *testing.T) { cases := []struct { in, want string }{ {\"Hello, world\", \"dlrow ,olleH\"}, {\"Hello, 世界\", \"界世 ,olleH\"}, {\"\", \"\"}, } for _, c := range cases { got := Reverse(c.in) if got != c.want { t.Errorf(\"Reverse(%q) == %q, want %q\", c.in, got, c.want) } } } 测试时, #从任意地方运行 go test github.com/user/stringutil #如果从这个package下面运行 go test 远程包 有的包在github上, 用go get命令可以从远程repo下载 编译 安装指定包. $ go get github.com/golang/example/hello $ $GOPATH/bin/hello Hello, Go examples! 被import的远程包, 本地没有的, 会被自动下载到workspace. go 工程布局(layout) 参考: https://golang.org/doc/code.html go开发约定: go的所有程序都放在一个workspace下面 这个workspace下面放了很多repo, 用git或hg管理起来 package name就是其package路径的basename, 比如crypto/rot13的package name就是rot13 go不要求package name是唯一的, 但要求其路径是唯一的. 一个repo包括一个或多个package 一个package放在一个目录下面, 包括一个或多个go源文件 一个package在workspace的路径, 就是它被import的路径 被import的package可以是remote的repo, go会自动下载到workspace里面 典型的go workspace布局 bin/ hello # command executable outyet # command executable src/ github.com/golang/example/ .git/ # Git repository metadata hello/ hello.go # command source outyet/ main.go # command source main_test.go # test source stringutil/ reverse.go # package source reverse_test.go # test source golang.org/x/image/ .git/ # Git repository metadata bmp/ reader.go # package source writer.go # package source ... (many more repositories and packages omitted) ... $GOPATH就是这个workspaceexport PATH=$PATH:$(go env GOPATH)/bin export GOPATH=$(go env GOPATH) go install就是把编译好的可执行文件拷贝到$GOPATH/bin 比如可以在任意的地方执行go install github.com/user/hello go会去$GOPATH/src找 对你写的go lib(不是以package main开头的是lib)来说, go build会把编译好的package保存在local build cache里 go的package xxx, 这里的xxx是import路径的base name. 在引用的时候, 用相对src的路径引用 package main import ( \"fmt\" \"github.com/user/stringutil\" ) func main() { fmt.Println(stringutil.Reverse(\"!oG ,olleH\")) } 此时源文件布局如下: bin/ hello # command executable src/ github.com/user/ hello/ hello.go # command source stringutil/ reverse.go # package source 完整布局参考 https://github.com/golang-standards/project-layout go知识点 package main import \"fmt\" func main() { /* 这是我的第一个简单的程序 */ fmt.Println(\"Hello, World!\") } #运行 go run hello.go #只编译 go build hello.go package main package关键词表示这个文件属于哪个包, 一般都是多个源文件属于同一个包. import告诉go编译器要使用的包 func main是程序开始执行的函数, 每个可执行的go程序必须包含main函数. 一般情况下, 程序会第一个执行main. 但如果有init()函数, 会先执行init() {不能占单独的一行 每行不必用;结尾 用+可以连接字符串, 比如fmt.Println(\"Google\" + \"Runoob\"), 得到GoogleRunoob 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）。 go的数据类型有bool byte(类似uint8) rune(类似int32) uintptr(无符号整型, 用于存放指针) int(32位或64位, 和体系架构有关) uint8/16/32/64 int8/16/32/64 float float32 float64 string struct channel 指针 数组 func 切片 interface map等 var a string = \"Runoob\" //也可以省略类型, 编译器根据赋值自动推断 var a = \"RUNOOB\" var b, c int = 1, 2 fmt.Println(a, b, c) //没有初始化的变量, 默认为0, 或空字符串\"\", 或nil, 比如: var a *int var a []int var a map[string] int var a chan int var a func(string) int var a error // error 是接口 //也可以省略var, 用v_name := value形式, 但只能在函数体内出现? f := \"Runoob\" //空白标识符_只能写, 不能读, 用于占位, 抛弃不想要的值; 比如下面的值5就被抛弃了 _, b = 5, 7 //取地址&和取值*和C一样 用type_name(expression)做类型转换 Go 没有三目运算符，所以不支持 ?: 形式的条件判断 循环只有forfunc main() { //也可以不要true, 直接一个for就行了 for true { fmt.Printf(\"这是无限循环。\\n\"); } } //一般的for形式都支持, 里面可以有break continue goto for C 函数定义形式, 可以有多个返回值 func function_name( [parameter list] ) [return_types] { 函数体 } /* 函数返回两个数的最大值 */ func max(num1, num2 int) int { /* 声明局部变量 */ var result int if (num1 > num2) { result = num1 } else { result = num2 } return result } 函数可以直接\"赋值\"给变量, 在大部分现代语言中, 函数也可以当作变量 func main(){ /* 声明函数变量 */ getSquareRoot := func(x float64) float64 { return math.Sqrt(x) } /* 使用函数 */ fmt.Println(getSquareRoot(9)) } go的闭包, 在这里就是函数返回值是另一个函数 //Go 语言支持匿名函数，可作为闭包。匿名函数是一个\"内联\"语句或表达式。匿名函数的优越性在于可以直接使用函数内的变量，不必申明。 //以下实例中，我们创建了函数 getSequence() ，返回另外一个函数。该函数的目的是在闭包中递增 i 变量，代码如下： package main import \"fmt\" func getSequence() func() int { i:=0 return func() int { i+=1 return i } } func main(){ /* nextNumber 为一个函数，函数 i 为 0 */ nextNumber := getSequence() /* 调用 nextNumber 函数，i 变量自增 1 并返回 */ fmt.Println(nextNumber()) fmt.Println(nextNumber()) fmt.Println(nextNumber()) /* 创建新的函数 nextNumber1，并查看结果 */ //重新调用getSequence()函数, i是重新申请的变量 nextNumber1 := getSequence() //这里的number会重新开始编号 fmt.Println(nextNumber1()) fmt.Println(nextNumber1()) fmt.Println(nextNumber()) fmt.Println(nextNumber()) } //结果 1 2 3 1 2 //这里是nextNumber继续编号 4 5 //闭包也可以带参数 func main() { add_func := add(1,2) fmt.Println(add_func(1,1)) fmt.Println(add_func(0,0)) fmt.Println(add_func(2,2)) } // 闭包使用方法 //x1 x2是初始化add_func用的, x3 x4是传给add_func的 func add(x1, x2 int) func(x3 int,x4 int)(int,int,int) { i := 0 return func(x3 int,x4 int) (int,int,int){ i++ return i,x1+x2,x3+x4 } } //结果 1 3 2 2 3 0 3 3 4 和C一样, 局部变量在函数内使用; 全局变量在函数体外声明, 在整个包使用, 甚至可以被导出后的外部包使用. 数组变量定义: var variable_name [SIZE] variable_type, 和C一样, 下标从0开始 数组变量赋值var balance = [5]float32{1000.0, 2.0, 3.4, 7.0, 50.0} var balance = [...]float32{1000.0, 2.0, 3.4, 7.0, 50.0} var salary float32 = balance[9] var a = [5][2]int{ {0,0}, {1,2}, {2,4}, {3,6},{4,8}} 指针和引用 func main() { /* 定义局部变量 */ var a int = 100 var b int= 200 fmt.Printf(\"交换前 a 的值 : %d\\n\", a ) fmt.Printf(\"交换前 b 的值 : %d\\n\", b ) /* 调用函数用于交换值 * &a 指向 a 变量的地址 * &b 指向 b 变量的地址 */ swap(&a, &b); fmt.Printf(\"交换后 a 的值 : %d\\n\", a ) fmt.Printf(\"交换后 b 的值 : %d\\n\", b ) } func swap(x *int, y *int) { var temp int temp = *x /* 保存 x 地址的值 */ *x = *y /* 将 y 赋值给 x */ *y = temp /* 将 temp 赋值给 y */ } 结构体, 和c不同的是, 结构体指针访问成员的时候, 也是用. type Books struct { title string author string subject string book_id int } //声明结构体变量并初始化 //variable_name := structure_variable_type {value1, value2...valuen} //或 //variable_name := structure_variable_type { key1: value1, key2: value2..., keyn: valuen} fmt.Println(Books{\"Go 语言\", \"www.runoob.com\", \"Go 语言教程\", 6495407}) Book1.title = \"Go 语言\" Book1.author = \"www.runoob.com\" Book1.subject = \"Go 语言教程\" Book1.book_id = 6495407 切片, 数组的大小是固定的, 而切片大小可以变. \"动态数组\" func main() { /* 创建切片 */ numbers := []int{0,1,2,3,4,5,6,7,8} printSlice(numbers) /* 打印原始切片 */ fmt.Println(\"numbers ==\", numbers) /* 打印子切片从索引1(包含) 到索引4(不包含)*/ fmt.Println(\"numbers[1:4] ==\", numbers[1:4]) /* 默认下限为 0*/ fmt.Println(\"numbers[:3] ==\", numbers[:3]) /* 默认上限为 len(s)*/ fmt.Println(\"numbers[4:] ==\", numbers[4:]) numbers1 := make([]int,0,5) printSlice(numbers1) /* 打印子切片从索引 0(包含) 到索引 2(不包含) */ number2 := numbers[:2] printSlice(number2) /* 打印子切片从索引 2(包含) 到索引 5(不包含) */ number3 := numbers[2:5] printSlice(number3) } func printSlice(x []int){ fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(x),cap(x),x) } range关键字用于 for 循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素 func main() { //这是我们使用range去求一个slice的和。使用数组跟这个很类似 nums := []int{2, 3, 4} sum := 0 for _, num := range nums { sum += num } fmt.Println(\"sum:\", sum) //在数组上使用range将传入index和值两个变量。上面那个例子我们不需要使用该元素的序号，所以我们使用空白符\"_\"省略了。有时侯我们确实需要知道它的索引。 for i, num := range nums { if num == 3 { fmt.Println(\"index:\", i) } } //range也可以用在map的键值对上。 kvs := map[string]string{\"a\": \"apple\", \"b\": \"banana\"} for k, v := range kvs { fmt.Printf(\"%s -> %s\\n\", k, v) } //range也可以用来枚举Unicode字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。 for i, c := range \"go\" { fmt.Println(i, c) } } 值传递和指针类型 有人总结: golang中的传参是值传递, 但因为map channel和slice等内置数据结构本身是指针类型, 所以它们作为参数传递时, 相当于传递了指针. struct 形式 type Books struct { title string author string subject string book_id int } 结构体方法 Go 语言中同时有函数和方法。一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。所有给定类型的方法属于该类型的方法集 形式为: 注意和函数定义的区别 func(receiver type)methodName([参数列表]) [返回值列表]{ } 普通函数定义为: func function_name( [parameter list] ) [return_types] { 函数体 } package main import ( \"fmt\" ) type Student struct{ Name string Age int } func (stu *Student)Set(name string,age int){ stu.Name = name stu.Age = age } func main(){ var s Student s.Set(\"tome\",23) fmt.Println(s) } //注意:方法的访问控制也是通过大小写控制的 //在上面这个例子中需要注意一个地方 //func (stu *Student)Set(name string,age int) //这里使用的是(stu *Student)而不是(stu Student)这里其实是基于指针对象的方法 //当调用一个函数时，会对其每个参数值进行拷贝，如果一个函数需要更新一个变量，或者函数的其中一个参数是在太大 //我们希望能够避免进行这种默认的拷贝，这种情况下我们就需要用到指针了，所以在上一个代码例子中那样我们需要 //func (stu *Student)Set(name string,age int)来声明一个方法 基于指针对象的方法 package main import ( \"fmt\" ) type Point struct{ X float64 Y float64 } func (p *Point) ScaleBy(factor float64){ p.X *= factor p.Y *= factor } func main(){ //两种方法 //方法1 r := &Point{1,2} r.ScaleBy(2) fmt.Println(*r) //方法2 p := Point{1,2} pptr := &p pptr.ScaleBy(2) fmt.Println(p) //方法3 p2 := Point{1,2} (&p2).ScaleBy(2) fmt.Println(p2) //相对来说方法2和方法3有点笨拙 //方法4,go语言这里会自己判断p是一个Point类型的变量， //并且其方法需要一个Point指针作为指针接收器，直接可以用下面简单的方法 p3 := Point{1,2} p3.ScaleBy(2) fmt.Println(p3) } //上面例子中最后一种方法，编译器会隐式的帮我们用&p的方法去调用ScaleBy这个方法 继承 package main import ( \"fmt\" ) type People struct{ Name string Age int } type Student struct{ People Score int } func main(){ var s Student /* s.People.Name = \"tome\" s.People.Age = 23 */ //上面注释的用法可以简写为下面的方法 s.Name = \"tom\" s.Age = 23 s.Score = 100 fmt.Printf(\"%+v\\n\",s) //注意：关于字段冲突的问题，我们在People中定义了一个Name字段，在Student中再次定义Name,这个时候，我们通过s.Name获取的就是Student定义的Name字段 } 结构体可以比较 如果结构体的所有成员变量都是可比较的，那么结构体就可比较 如果结构体中存在不可比较的成员变量，那么结构体就不能比较 map和切片不能比较 package main import ( \"fmt\" ) type Point struct{ x int y int } func main(){ p1 := Point{1,2} p2 := Point{2,3} p3 := Point{1,2} fmt.Println(p1==p2) //false fmt.Println(p1==p3) //true } new分配内存 package main import ( \"fmt\" ) type Student struct { Id int Name string } func main() { s := new(Student) s.Id = 1 s.Name = \"test\" s1 := Student{Id: 2, Name: \"test1\"} fmt.Println(s, s1) } //输出结果: &{1 test} {2 test1} //s 的类型为指针，s1 为一个Student类型; //说明new的返回值是指针, 而用struct_type{}声明的变量是struct_type实例本身. 工厂模式初始化 go没有构造函数, 所以工厂模式很常用 package main import ( \"fmt\" ) type Student struct{ Name string Age int } func NewStudent(name string,age int) *Student{ return &Student { Name:name, Age:age, } } func main(){ s := NewStudent(\"tom\",23) fmt.Println(s.Name) } 接口 interface Go 语言提供了另外一种数据类型即接口，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方法就是实现了这个接口。 /* 定义接口 */ type interface_name interface { method_name1 [return_type] method_name2 [return_type] method_name3 [return_type] ... method_namen [return_type] } /* 定义结构体 */ type struct_name struct { /* variables */ } /* 实现接口方法 */ func (struct_name_variable struct_name) method_name1() [return_type] { /* 方法实现 */ } ... func (struct_name_variable struct_name) method_namen() [return_type] { /* 方法实现*/ } package main import ( \"fmt\" ) type Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\"I am Nokia, I can call you!\") } type IPhone struct { } func (iPhone IPhone) call() { fmt.Println(\"I am iPhone, I can call you!\") } func main() { //这是interface类型的变量 var phone Phone //new返回一个指针, 并对其内存清零; //也可以写成phone = NokiaPhone{}, 或phone = &NokiaPhone{} phone = new(NokiaPhone) phone.call() phone = new(IPhone) phone.call() } //在上面的例子中，我们定义了一个接口Phone，接口里面有一个方法call()。 //然后我们在main函数里面定义了一个Phone类型变量，并分别为之赋#值为NokiaPhone和IPhone。 //然后调用call()方法，输出结果如下： I am Nokia, I can call you! I am iPhone, I can call you! 类型断言 类型断言提供了一个机制找出接口底层对应的实际类型: t := i.(T) 这个语句在断言接口i中实际包含了类型T，然后把底层类型T的值赋值给变量t 如果断言失败，i中没有包含T，这条语句会触发panic 为了测试接口是否包含指定的类型，类型断言会返回2个值，底层类型实际对应的值和一个bool值，来报告断言是否成功 t, ok := i.(T) 如果i中包含T，则t是底层类型的实际值，变量ok是真 如果断言失败，ok变量是假，t是一个零值类型T，不会触发panic，这个语法和对map操作类似 只有interface有类型断言, 因为interface可以指向任何东西, 所以要有办法知道它的运行时类型: https://www.jianshu.com/p/6a46fc7b6e5b x.(T) 检查x的动态类型是否是T，其中x必须是接口值。 switch形式: func main() { var x interface{} x = 17 //fmt包看实际类型, 因为Printf的入参就是接口类型 fmt.Printf(\"type x is %T, value x is %d\\n\", x, x) //这是个特殊的type switch, switch后面是个赋值表达式, 但case的对象是类型 switch v := x.(type) { //case的顺序是有意义的，因为可能同时满足多个接口，不可以用fallthrough, default的位置无所谓。 case nil: fmt.Printf(\" x 的类型 :%T\", v) case int: fmt.Printf(\"x 是 int 型, 值为%v\", v) case float64: fmt.Printf(\"x 是 float64 型, 值为%v\", v) case func(int) float64: fmt.Printf(\"x 是 func(int) 型, 值为%p\", v) case bool, string: fmt.Printf(\"x 是 bool 或 string 型, 值为%v\", v) default: fmt.Printf(\"未知型\") } } //结果: type x is int, value x is 17 x 是 int 型, 值为17 类型断言判断对象是否实现了一个接口 判断val是否实现了json.Marshaler需要的接口, 即val是否为json.Marshaler类型. if _, ok := val.(json.Marshaler); ok { fmt.Printf(\"value %v of type %T implements json.Marshaler\\n\", val, val) } goroutine goroutine 是轻量级线程，goroutine 的调度是由 Golang 运行时进行管理的。 //语法 go 函数名(参数列表) //比如 go f(x, y, z) //并行执行, 就像shell的后台执行一样 package main import ( \"fmt\" \"time\" ) func say(s string) { for i := 0; i 通道 通道（channel）是用来传递数据的一个数据结构, 可用于两个 goroutine 之间通过传递一个指定类型的值来同步运行和通讯。操作符 // 声明一个通道很简单，我们使用chan关键字即可，通道在使用前必须先创建： ch := make(chan int) ch // 也可以不用make来声明channel, 用var也可以; 默认初始化为nil var c chan int fmt.Println(c) select语句形式上类似 switch 语句，但实际上和C里面的select差不多: 用于监听和channel有关的IO操作，当 IO 操作发生时，触发相应的动作. 和switch不同, select会对每个case, 都会对channel求值, 如果有可用的IO, 则随机执行其中一个case的后续指令. 如果没有可用的IO, 则执行default. 如果没有可用IO, 也没有default, 则一直阻塞到IO可用. 比如一个loadbalancer func (b *Banlancer) balance(work chan Request) { for { select { case req := package main import \"fmt\" func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c 带缓冲的通道 // 默认情况下，通道是不带缓冲区的。发送端发送数据，同时必须又接收端相应的接收数据。 // 通道可以设置缓冲区，通过 make 的第二个参数指定缓冲区大小： ch := make(chan int, 100) package main import \"fmt\" func main() { // 这里我们定义了一个可以存储整数类型的带缓冲通道 // 缓冲区大小为2 ch := make(chan int, 2) // 因为 ch 是带缓冲的通道，我们可以同时发送两个数据 // 而不用立刻需要去同步读取数据 ch 通道用close来关闭 //如果通道接收不到数据后 ok 就为 false，这时通道就可以使用 close() 函数来关闭 v, ok := package main import ( \"fmt\" ) func fibonacci(n int, c chan int) { x, y := 0, 1 for i := 0; i 切片 切片是对数组的描述, 一个数组可以有多个描述 用make创建切片的时候, make([]type, length, capacity), 其中, length表示切片的大小, capacity表示切片底层array的大小; capacity容量够的话, append()不会产生新的更大的array 切片的append arr从[0 1 2 3 4 5 6 7]变为[0 1 2 3 4 5 6 10]是因为s3 := append(s2, 10)，s2=[5 6]，再往后添加10的时候，把arr中的7变为了10。而后面再添加11、12时，因为已经超越了arr的cap，所以系统会重新分配更大的底层数组，而不再是对arr进行操作，原来的数组如果有人用就会依旧存在，如果没人用了就会自动垃圾回收 package main import \"fmt\" func main() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(\"arr: \", arr) // output：arr: [0 1 2 3 4 5 6 7] s1 := arr[2:6] s2 := s1[3:5] //其实s1的index只有0 1 2 3, 这里的3:5是3和4, 引用的是原始arr fmt.Println(\"s1: \", s1) // output：s1: [2 3 4 5] //len(s2)为2 fmt.Println(\"s2: \", s2) // output：s2: [5 6] s3 := append(s2, 10) s4 := append(s3, 11) s5 := append(s4, 12) fmt.Println(\"s3: \", s3) // output：s3: [5 6 10] fmt.Println(\"s4: \", s4) // output：s4: [5 6 10 11] fmt.Println(\"s5: \", s5) // output：s5: [5 6 10 11 12] fmt.Println(\"arr: \", arr) // output：arr: [0 1 2 3 4 5 6 10] } 当我们用append追加元素到切片时，如果容量不够，go就会创建一个新的切片变量, 并进行\"深拷贝\", 即把原来的array的元素值, 都拷贝到新的更大的array里面, 再append. 如果用量够用, 就不用\"深拷贝\"了 func main() { var sa []string //用%p可以打印sa的地址, sa本来就是个 fmt.Printf(\"addr:%p \\t\\tlen:%v content:%v\\n\",sa,len(sa),sa); for i:=0;i map 集合 Map 是一种无序的键值对的集合。Map 最重要的一点是通过 key 来快速检索数据，key 类似于索引，指向数据的值。 Map 是一种集合，所以我们可以像迭代数组和切片那样迭代它。不过，Map 是无序的，我们无法决定它的返回顺序，这是因为 Map 是使用 hash 表来实现的。 /* 声明变量，默认 map 是 nil */ var map_variable map[key_data_type]value_data_type /* 使用 make 函数 */ map_variable := make(map[key_data_type]value_data_type) package main import \"fmt\" func main() { var countryCapitalMap map[string]string /*创建集合 */ countryCapitalMap = make(map[string]string) /* map插入key - value对,各个国家对应的首都 */ countryCapitalMap [ \"France\" ] = \"Paris\" countryCapitalMap [ \"Italy\" ] = \"罗马\" countryCapitalMap [ \"Japan\" ] = \"东京\" countryCapitalMap [ \"India \" ] = \"新德里\" /*使用键输出地图值 */ for country := range countryCapitalMap { fmt.Println(country, \"首都是\", countryCapitalMap [country]) } /*查看元素在集合中是否存在 */ captial, ok := countryCapitalMap [ \"美国\" ] /*如果确定是真实的,则存在,否则不存在 */ /*fmt.Println(captial) */ /*fmt.Println(ok) */ if (ok) { fmt.Println(\"美国的首都是\", captial) } else { fmt.Println(\"美国的首都不存在\") } } //运行结果 France 首都是 Paris Italy 首都是 罗马 Japan 首都是 东京 India 首都是 新德里 美国的首都不存在 delete可以删除元素 range 用range可以对数组(array), 切片(slice), 通道(channel), 集合(map)进行遍历 package main import \"fmt\" func main() { //这是我们使用range去求一个slice的和。使用数组跟这个很类似 nums := []int{2, 3, 4} sum := 0 for _, num := range nums { sum += num } fmt.Println(\"sum:\", sum) //在数组上使用range将传入index和值两个变量。上面那个例子我们不需要使用该元素的序号，所以我们使用空白符\"_\"省略了。有时侯我们确实需要知道它的索引。 for i, num := range nums { if num == 3 { fmt.Println(\"index:\", i) } } //range也可以用在map的键值对上。 kvs := map[string]string{\"a\": \"apple\", \"b\": \"banana\"} for k, v := range kvs { fmt.Printf(\"%s -> %s\\n\", k, v) } //range也可以用来枚举Unicode字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。 for i, c := range \"go\" { fmt.Println(i, c) } } // 运行结果: sum: 9 index: 1 a -> apple b -> banana 0 103 1 111 "},"notes/golang_原理.html":{"url":"notes/golang_原理.html","title":"原理相关","keywords":"","body":" go的内存模型 例子1 例子2 业务逻辑上避免调用锁 for循环里的变量 变量每次进入循环都会初始化 变量的地址会变吗? 不会? 会! 结论: 理论解释 -- 表示怀疑 怀疑 合理解释 内置new函数也不是一定分配到堆 总结 修正 再修正 reflect.ValueOf ValueOf流程 什么是ifaceIndir Value的Elem()方法 emptyInterface和nonEmptyInterface ValueOf实例 结论 强制escape 问答 为什么看到value的kind是54? interface赋值给interface 直接赋值: interface只有一层 取地址赋值: interface包interface地址 结论 slice能当作\"出参\"传递 结论 slice和gc 具体例子 Remove all elements Keep allocated memory 结论 float32和data race 使用sync/atomic 再说reflect 什么是unaddressable 不能改变a 能改变a 为什么? 更进一步解释 结论 例子 原理 结论 再议interface interface{}回顾 set get性能损失如何? 结论 标准库的time.Now()如何取得系统时间? time.Now()的实现流程 clock_gettime系统调用 逃逸分析和变量分配 逃逸分析使用 逃逸分析实例 go的值和指针 map 初始化 hashmap结构体 make map变量的时候 遍历 hash算法 常用的hash算法 结论 Gc的演进 interface赋值 更正 interface的内部表达 reflect Type和interface reflect method reflect Value timer timer API 单次timer 周期性timer timer实现原理 add timer 触发timer time.NewTimer()注册了sendTime()回调 timer堆的维护 time包的NewTimer方法调用了runtime.startTimer 性能测试和结果 测试结果 结论 go1.14对timer的优化 go1.13的timer问题 1.14解决思路 系统监控 监控循环 检查timer 检查死锁 轮询网络 抢占处理器 垃圾回收 IO多路复用 golang对epoll的封装 数据结构 初始化 goroutine等待事件 调用epoll 截至日期 GC 垃圾收集器 go runtime调度器 相关的结构体表示 go比较快的5点 go的内存模型 对一个goroutine来说, 编译器和CPU可以合理的乱序, 但必须保证程序顺序的正确性. 即无关的指令才能reorder, 比如a = 1; b = 2;, 在另外一个routine观察可以先看到b = 2 多routine对共享变量的access(重点, 包括读和写), 必须用sync方法 对大于machine word(比如32bit)的值的读写, 是多个machine word size的操做, 它们的顺序未定义 init函数是在特殊的初始化gorotine里执行的, 但init函数可以启动新的goroutine. 被import包的init函数一定先于importer完成. main.main一定是最后执行 例子1 var a, b int func f() { a = 1 b = 2 } func g() { print(b) print(a) } func main() { go f() g() } 可能打印2然后是0. 即f()的b = 2先被g()观察到. 例子2 var a string var done bool func setup() { a = \"hello, world\" done = true } func doprint() { if !done { once.Do(setup) } print(a) } func twoprint() { go doprint() go doprint() } 在doprint()里, 观察到done的写入, 因为乱序执行, 不一定a = \"hello, world\"也完成了. 下面的代码也不对: var a string var done bool func setup() { a = \"hello, world\" done = true } func main() { go setup() for !done { } print(a) } 过了for !done之后, a可能依然是空. 更糟糕的是, 因为没有使用sync, done的写入不能保证一定被main观察到, 以至于main永远不退出. 下面的错误代码更有隐蔽性: type T struct { msg string } var g *T func setup() { t := new(T) t.msg = \"hello, world\" g = t } func main() { go setup() for g == nil { } print(g.msg) } 既是main看到g不是nil了, 也不能保证g.msg就有值了. 业务逻辑上避免调用锁 代码1 func (mq *msgQ) putMsg(mm *metaKnownMsg) { if _, ok := mm.msg.(HighPriorityMessage); ok { if mq.ingressHighChan == nil { mq.Lock() if mq.ingressHighChan == nil { mq.ingressHighChan = make(chan *metaKnownMsg, mq.qsize) } mq.Unlock() } mq.ingressHighChan 代码2 func (mq *msgQ) putMsg(mm *metaKnownMsg) { if _, ok := mm.msg.(HighPriorityMessage); ok { mq.Lock() if mq.ingressHighChan == nil { mq.ingressHighChan = make(chan *metaKnownMsg, mq.qsize) } mq.Unlock() mq.ingressHighChan 在并发场景下, 代码1比代码2理论上性能高非常多. 这里在ingressHighChan为空的时候, 需要新建队列. 这个事情只用做一次. 而代码2在每次进入函数的时候, 都要去获取锁, 那么比如说并发100个函数都走到这里, 就只有一个人能够获取到做, 其他人必须等待锁释放. 而接下来的99个人, 都必须串行的完成这个过程. 总结: 在业务逻辑侧尽量减少lock的调用. 比如这里已知队列为空的时候才调用锁. for循环里的变量 变量每次进入循环都会初始化 比如下面的代码: for { var a, b, c int fmt.Println(\"Hello, playground\", a, b, c) a = 9 fmt.Println(\"Hello, playground\", a, b, c) time.Sleep(time.Second) } 输出: Hello, playground 0 0 0 Hello, playground 9 0 0 Hello, playground 0 0 0 Hello, playground 9 0 0 可以看到: a,b,c都是for里面定义的变量, 初始为零值. 没毛病 循环体里面把a赋值为9, 随后打印a为9, 也没毛病. 本次循环体执行完毕后, 下次循环体执行时, a的值又从零值开始. -- 这里不能用C的思路去理解 变量的地址会变吗? 不会? 看下面的代码: for i := 0; i 输出: Hello, playground 0 824634355464 Hello, playground 9 824634355464 Hello, playground 0 824634355464 Hello, playground 9 824634355464 Hello, playground 0 824634355464 Hello, playground 9 824634355464 看起来变量a的地址并没有变化 会! func main() { for i := 0; i 输出: Hello, playground 0 824634388176 Hello, playground 9 824634388176 Hello, playground 0 824634388176 Hello, playground 9 824634388176 Hello, playground 0 824634388176 Hello, playground 9 824634388176 in main 0 824634499152 in go 9 824634499152 in main 0 824634499176 in go 9 824634499176 in main 0 824634499200 in go 9 824634499200 那么更进一步的问题: 这里go中看到的变量a地址, 和main中每次进入循环体时a的地址一样, 是否是因为它们在时间顺序上前者在后, 后者在前? 改成这样: for i := 0; i 在go函数里面, 先延迟一秒钟. 那么main的for循环会先执行完, goroutine都在后面执行. 结果如下, 说明go函数里面取得到的变量a, 就是本次循环体里面的变量a. in main 0 824634499136 in main 0 824634499152 in main 0 824634499168 in main 0 824634499184 in main 0 824634499200 in main 0 824634499216 in main 0 824634499232 in main 0 824634499248 in main 0 824634499264 in main 0 824634499280 in main 0 824634499296 in main 0 824634499312 in main 0 824634499328 in main 0 824634499344 in main 0 824634499360 in main 0 824634499376 in main 0 824634499392 in main 0 824634499408 in main 0 824634499424 in main 0 824634499440 in main 0 824634499456 in main 0 824634499472 in main 0 824634499488 in main 0 824634499504 in main 0 824634499520 in main 0 824634499536 in main 0 824634499552 in main 0 824634499568 in main 0 824634499584 in main 0 824634499600 in go 9 824634499136 in go 9 824634499600 in go 9 824634499584 in go 9 824634499568 in go 9 824634499552 in go 9 824634499536 in go 9 824634499520 in go 9 824634499504 in go 9 824634499488 in go 9 824634499472 in go 9 824634499456 in go 9 824634499184 in go 9 824634499424 in go 9 824634499408 in go 9 824634499392 in go 9 824634499376 in go 9 824634499360 in go 9 824634499344 in go 9 824634499328 in go 9 824634499312 in go 9 824634499296 in go 9 824634499280 in go 9 824634499264 in go 9 824634499248 in go 9 824634499232 in go 9 824634499216 in go 9 824634499200 in go 9 824634499440 in go 9 824634499168 in go 9 824634499152 结论: for循环体里的变量, 但按照下面的理论来说, 每次进入循环体, 都进入了一个新的scope, 变量地址应该会变化. 少数情况下, 循环体比较简单, 可能变量地址碰巧不变. --结论错误!!!!! for循环体里的变量, 被go函数捕获时, 用的是本次循环体里的变量. 即使循环体在main中异步的改变了该变量, 也不影响已经go出去的routine. --表面正确!!!! 正确结论见下面 理论解释 -- 表示怀疑 参考stackoverflow 有人问为什么在循环里可以: func main() { for i := 0; i 但自己手动写就编译不过: func main() { a := 77 fmt.Println(a) a := 77 fmt.Println(a) } 为啥? 专家的解答是: for循环每次进入循环体大括号块{}, 都是一个新的scope The reason is each time you enter a block of curly braces {} you're creating a new nested scope. When you declare the variable x at the top of the loop it is a new variable and it goes out of scope at the end of the loop. When the program comes back around to the top of the loop again it's another new scope. 有人给出了证据: func main() { for i := 0; i output 0x1040e0f8 0x1040e0fc 可以手动加{}来添加scope: func main() { a := 77 fmt.Println(&a) { a := 77 fmt.Println(&a) } } output 0x1040e0f8 0x1040e0fc 上面的例子就可以\"连续\"定义a两次, 但第二次是个新的变量地址 怀疑 证据例子中, 变量x的地址改变, 不是因为重新进入{}scope的原因. 比如把下面的\"证据\" func main() { for i := 0; i 结果 0x1040e0f8 0x1040e0fc 改成: func main() { for i := 0; i 注意第4行, 用了unsafe.Pointer取x的地址. 结果: 824634150736 824634150736 为什么结果不一样? 上面的证据显示x的地址改变了, 而下面的代码中x的地址没变. 合理解释 因为有fmt.Println(&x), 变量x逃逸到了堆中, 自然每次进入循环其地址都会改变. 而fmt.Println(uintptr(unsafe.Pointer(&x)))不会逃逸, x还是在栈上, 自然地址不变. 内置new函数也不是一定分配到堆 比如下面的代码, 不管是x := 77, 还是x := new(int), 连续两次的地址都是一样的 for i := 0; i 总结 for的循环变量, 比如i++和循环体里面的变量是两码事: for循环同一行的变量作用域在for里面没错, 但更像是在进入循环前定义的一样: for循环里面对循环变量的引用都是指向同一个东西 for循环体里面用var v int或vc := vc定义的变量, 并非同一个地址, 每次循环都是\"临时\"生成的. 所以上面在第13行的修改可以解决问题. 以后检查go出去的函数是否有这个问题, 只检查循环变量就行了 -- 结论正确, 但前面推导过程不对. 见下面 修正 变量地址是否改变, 要看 如果变量在栈上没有逃逸到堆, 那每次for循环里的变量地址是不变的 如果变量逃逸到堆, 那每次for循环里的变量地址不一样 fmt.Println类的函数会导致变量逃逸(大概率) go 函数造成的闭包引用会导致变量逃逸(必然) channel的send应该也会必然导致变量逃逸 不清楚的情况下, 请默认变量是同一个地址. 这样你可以更小心的避免\"无意中\"改变了一个你认为是独立的变量但实际是共享的, 因为你一开始就应该假定这个变量就是共享的. 错误代码示例: for { // fill bufMsg from network socket var tm streamTransportMsg dec.Decode(bufMsg, &tm) streamChan 注意这里取tm地址做为decode的\"出参\", 会实际改变tm底层的数据; 而chan的发送是异步的效果, 真正处理的routine可能看到的tm.msg已经改变. 再修正 上面的错误代码示例不准确 for { // fill bufMsg from network socket var tm streamTransportMsg dec.Decode(bufMsg, &tm) streamChan 另外一个goroutine从streamChan中得到streamTransportMsg的引用, 但看到的tm.msg会在for循环里改变, 不是因为tm的地址没变, 实际上tm的地址会变, 因为channel的发送会导致逃逸. 那错误的原因是tm.msg地址没变, 这是gotiny的Decode问题, 是另外一个故事. reflect.ValueOf ValueOf流程 // ValueOf returns a new Value initialized to the concrete value // stored in the interface i. ValueOf(nil) returns the zero Value. func ValueOf(i interface{}) Value { if i == nil { return Value{} } // TODO: Maybe allow contents of a Value to live on the stack. // For now we make the contents always escape to the heap. It // makes life easier in a few places (see chanrecv/mapassign // comment below). escapes(i) return unpackEface(i) } 从这个函数传进来的i, 不管之前是什么类型, 到这里都是eface, 即empty interface. 这里的escapes(i)我理解i这个interface变量的结构体是在栈上的, 但其\"contents\"要强制分配到heap中, 这里的contents就是i的指针域指向的实体. // unpackEface converts the empty interface i to a Value. func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(&i)) //明确知道i是个emptyInterface // NOTE: don't read e.word until we know whether it is really a pointer or not. t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} } 我们看到: reflect.Value只是unpackEface这个interface, 组成一个Value的结构体, 这中间并没有真正拷贝\"contents\", 而是把\"contents\"做为word返回. 这个word可以是指针, 也可以是值. 这里的Value是如下结构体: // Value is the reflection interface to a Go value. // // Not all methods apply to all kinds of values. Restrictions, // if any, are noted in the documentation for each method. // Use the Kind method to find out the kind of value before // calling kind-specific methods. Calling a method // inappropriate to the kind of type causes a run time panic. // // The zero Value represents no value. // Its IsValid method returns false, its Kind method returns Invalid, // its String method returns \"\", and all other methods panic. // Most functions and methods never return an invalid value. // If one does, its documentation states the conditions explicitly. // // A Value can be used concurrently by multiple goroutines provided that // the underlying Go value can be used concurrently for the equivalent // direct operations. // // To compare two Values, compare the results of the Interface method. // Using == on two Values does not compare the underlying values // they represent. type Value struct { // typ holds the type of the value represented by a Value. typ *rtype // Pointer-valued data or, if flagIndir is set, pointer to data. // Valid when either flagIndir is set or typ.pointers() is true. ptr unsafe.Pointer // flag holds metadata about the value. // The lowest bits are flag bits: // - flagStickyRO: obtained via unexported not embedded field, so read-only // - flagEmbedRO: obtained via unexported embedded field, so read-only // - flagIndir: val holds a pointer to the data // - flagAddr: v.CanAddr is true (implies flagIndir) // - flagMethod: v is a method value. // The next five bits give the Kind of the value. // This repeats typ.Kind() except for method values. // The remaining 23+ bits give a method number for method values. // If flag.kind() != Func, code can assume that flagMethod is unset. // If ifaceIndir(typ), code can assume that flagIndir is set. flag // A method value represents a curried method invocation // like r.Read for some receiver r. The typ+val+flag bits describe // the receiver r, but the flag's Kind bits say Func (methods are // functions), and the top bits of the flag give the method number // in r's type's method table. } 什么是ifaceIndir 在unpackEface中, 调用了函数ifaceIndir(t)来检查是否eface的data域是个指针(一般都是), 但也有时候这个data域直接存的就是值. // unpackEface converts the empty interface i to a Value. func (i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(&i)) //明确知道i是个emptyInterface // NOTE: don't read e.word until we know whether it is really a pointer or not. t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} //这里的e.word就是eface的data. } // ifaceIndir reports whether t is stored indirectly in an interface value. func ifaceIndir(t *rtype) bool { return t.kind&kindDirectIface == 0 } //rtype的kind字段, 第5位表示data指针实际存的是值. const ( kindDirectIface = 1 综上, eface和iface的data域不一定都是指针, 还可能是值. 这可能是个优化, 但其实挺费劲的. 都是指针多好. Value的Elem()方法 Elem()方法用于取得interface或者ptr的\"contents\" // Elem returns the value that the interface v contains // or that the pointer v points to. // It panics if v's Kind is not Interface or Ptr. // It returns the zero Value if v is nil. func (v Value) Elem() Value { k := v.kind() switch k { case Interface: var eface interface{} if v.typ.NumMethod() == 0 { eface = *(*interface{})(v.ptr) //ptr指向empty interface } else { eface = (interface{})(*(*interface { M() //临时构造一个带一个M方法的interface类型, 相当于eface = someOtherInterfaceWithMethod })(v.ptr)) //ptr指向带方法的interface } x := unpackEface(eface) if x.flag != 0 { x.flag |= v.flag.ro() //这里就是unsettable的来源? } return x case Ptr: ptr := v.ptr //默认是data, 只不过保存在ptr里面. 比如就是int 5 if v.flag&flagIndir != 0 { //指针 ptr = *(*unsafe.Pointer)(ptr) //解引用得到data } // The returned value's address is v's value. if ptr == nil { return Value{} } tt := (*ptrType)(unsafe.Pointer(v.typ)) typ := tt.elem fl := v.flag&flagRO | flagIndir | flagAddr //这里我有点困惑, 为什么要设置flagIndir | flagAddr? fl |= flag(typ.Kind()) return Value{typ, ptr, fl} } panic(&ValueError{\"reflect.Value.Elem\", v.kind()}) } 看起来Elem()也是操做ptr, 没有明显的值拷贝. emptyInterface和nonEmptyInterface emptyInterface比较简单 // emptyInterface is the header for an interface{} value. type emptyInterface struct { typ *rtype word unsafe.Pointer } 而nonEmptyInterface就复杂多了, 包括静态interface类型, concrete类型, 和方法表. 方法表容量有100000个之多, 但我判断这部分其实不占那么多内存的. // nonEmptyInterface is the header for an interface value with methods. type nonEmptyInterface struct { // see ../runtime/iface.go:/Itab itab *struct { ityp *rtype // static interface type typ *rtype // dynamic concrete type hash uint32 // copy of typ.hash _ [4]byte fun [100000]unsafe.Pointer // method table } word unsafe.Pointer } 上面是reflect的定义, 相应的runtime表达, 在src/runtime/runtime2.go中, 有: type iface struct { tab *itab data unsafe.Pointer } // layout of Itab known to compilers // allocated in non-garbage-collected memory // Needs to be in sync with // ../cmd/compile/internal/gc/reflect.go:/^func.dumptabs. type itab struct { inter *interfacetype _type *_type hash uint32 // copy of _type.hash. Used for type switches. _ [4]byte fun [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter. } type eface struct { _type *_type data unsafe.Pointer } func efaceOf(ep *interface{}) *eface { return (*eface)(unsafe.Pointer(ep)) } 基本上差不多. ValueOf实例 把一个指向interface类型的指针, 解引用后做ValueOf操做: // p是unsafe.Pointer, 已知指向reflect.Interface类型, rt是这个类型的TypeOf()后的reflect.Type if rt.NumMethod() == 0 { // 没有方法是eface ti := *(*interface{})(p) v := reflect.ValueOf(ti) } 此时p指向eface, 见上面eface定义; 在这个例子中, 这个interface的content是个gotiny.baseTyp结构体: // p是unsafe.Pointer, 已知指向reflect.Interface类型, rt是这个类型的TypeOf()后的reflect.Type if rt.NumMethod() > 0 { // 有方法是iface ti := *(*interface { M() })(p) v := reflect.ValueOf(ti) et := v.Type() } 此时p指向iface, 见上面iface定义; 在这个例子中, 这个interface是: // tint是int, 实现了io.ReadWriteCloser type tint int func (tint) Read([]byte) (int, error) { return 0, nil } func (tint) Write([]byte) (int, error) { return 0, nil } func (tint) Close() error { return nil } v1interface io.ReadWriteCloser = tint(2) 这里我们看到, ti在dlv看来, 其data是2. 我们知道一个interface的\"data\"域是个指针, 但这里的2刚好就是v1interface的值, 那么这个data已经不是指针而是值了, 是否是因为dlv\"自动\"解引用了呢? 在ValueOf(ti)的里面的unpackEface()中, ti被\"值拷贝\"(interface的值拷贝)到i: // unpackEface converts the empty interface i to a Value. func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(&i)) // NOTE: don't read e.word until we know whether it is really a pointer or not. t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} } 因为i在内存中是emptyInterface类型, 强转成e, 我们能借助dlv看到e的typ和word:注意到t的Kind是2(也就是int), 而word是个指针. 这个e就是i, 也就是ti. 所以我们看到v := reflect.ValueOf(ti)执行后, v就是ti的实际内存表达:但从此丢失了ti的method信息??? 结论 当类型的Kind是Interface的时候, 如果只有指向这个变量的指针p, 那么要区分p指向的到底是eface还是iface, 不能混用, 否则会panic. 所以要这样: // p是unsafe.Pointer, 已知指向reflect.Interface类型, rt是这个类型的TypeOf()后的reflect.Type if rt.NumMethod() > 0 { // 有方法是iface ti := *(*interface { M() })(p) v := reflect.ValueOf(ti) et := v.Type() } else { // 没有方法是eface ti := *(*interface{})(p) v := reflect.ValueOf(ti) et := v.Type() } 强制escape /usr/local/go/src/reflect/value.go 定义一个全局变量: var dummy struct { b bool x interface{} } 如果需要强制escape一个变量, 只需要赋值给dummy的x. 因为一个全局变量持有x的引用, 那x必须在heap里面. // Dummy annotation marking that the value x escapes, // for use in cases where the reflect code is so clever that // the compiler cannot follow. func escapes(x interface{}) { if dummy.b { dummy.x = x } } 问答 为什么看到value的kind是54? 如图?答: 这里的kind不是反射那个Kind, 或者说不完全是. 这里的kind是rtype类型的一个field. 真正的kind是这个field在与上kindMask, 相当于t.kind & 31 func (t *rtype) Kind() Kind { return Kind(t.kind & kindMask) } 所以54&31后, 是22. 22对应的Kind是reflect.Ptr interface赋值给interface 直接赋值: interface只有一层 我们知道interface的内部第二个field是个指针 type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 那么如果我把一个interface变量(t1i)赋值给另一个interface变量(t2i), 那么t2i的data是指向t1i的拷贝的吗? 比如 t := 9 var t1i interface{} t1i = t var t2i interface{} t2i = t1i 答: 不是. 首先, interface的赋值也有值拷贝, 前面说过的: 再理解一下 The second word in the interface value points at the actual data, in this case a copy of b. The assignment var s Stringer = b makes a copy of b rather than point at b for the same reason that var c uint64 = b makes a copy: if b later changes, s and c are supposed to have the original value, not the new one. 其次, 这里并不是把t2i这个interface的结构即eface结构拷贝一份, 并用t1i的data域来指向. 而是t2i发现赋值对象也是个interface, 就直接查其concrete类型再赋值. 所以我说interface变量只有一级, 不存在interface里面再包一层interface. 而一定是interface下面就是concrete类型. 注意我说的是运行时, 不是定义时. 定义时可以嵌套interface. 证明: fmt.Println(reflect.TypeOf(t1i).String())结果是int TypeOf(t1i)这步就有t1i赋值给入参的过程, 这个就是interface赋值给interface. 如果允许运行时嵌套interface, 那多层函数传递interface就会嵌套好多层. 用户不会知道里面有多少层interface的. 取地址赋值: interface包interface地址 如果把上面的代码改成 ti := int64(9) var tinterface interface{} tinterface = ti fmt.Println(reflect.TypeOf(tinterface).String()) var t2interface interface{} t2interface = &tinterface ti = 10 fmt.Println(t2interface) 那么t2interface的具体内存表达是什么样的? 答: t2interface的data指针是*interface{}类型, 应该就是指向tinterface 结论 ti := int64(9) var tinterface interface{} tinterface = ti fmt.Println(reflect.TypeOf(tinterface).String()) var t2interface interface{} t2interface = tinterface fmt.Println(reflect.TypeOf(t2interface).String()) var t3interface interface{} t3interface = &tinterface fmt.Println(reflect.TypeOf(t3interface).String()) var t4interface interface{} t4interface = &t3interface fmt.Println(reflect.TypeOf(t4interface).String()) 这段代码打印: int64 int64 *interface {} *interface {} 特别的, t4interface有3层嵌套, 包括&t3interface一层, &tinterface一层, 最后的int64(9)一层. 所以: interface i1值赋值给interface i2, 其concrete类型会传递(或者说短接)到\"第一层\".(t2interface的行为) interface i1值赋值给interface i2, 其i1的concrete的值会拷贝给i2. interface取地址赋值给interface, 并非传递, 而是嵌套.(t4interface的行为) slice能当作\"出参\"传递 比如io.Reader type Reader interface { Read(p []byte) (n int, err error) } 这里说的很清楚, Read reads up to len(p) bytes into p. 注意这里 p做为出参, Read函数内对p的修改是能够被调用者看到的. 但注意up to len(p), 因为p是调用者传入slice的\"浅拷贝\", 大小是不能改变的, append()函数等改变len()的不会体现到调用者看到的\"p\"中. 结论 在slice p被当作参数传递的过程中, 发生了slice的\"浅拷贝\", 浅拷贝共享底层数组, 所以对底层数组的修改能够被调用者看到, 其作用类似\"出参\". 但\"浅拷贝\"对slice本身的改变, 比如改变len, 原slice是看不到的. a := []int{1,2,3} a1 := a a1[2]=100 a1 = append(a1, 4) fmt.Println(a1) fmt.Println(a) //输出 [1 2 100 4] [1 2 100] slice和gc 对一个slice进行切片不会导致底层array被gc. 具体见https://stackoverflow.com/questions/28432658/does-go-garbage-collect-parts-of-slices As mentioned earlier, re-slicing a slice doesn't make a copy of the underlying array. The full array will be kept in memory until it is no longer referenced. Occasionally this can cause the program to hold all the data in memory when only a small piece of it is needed. Since the slice references the original array, as long as the slice is kept around the garbage collector can't release the array. 具体例子 https://yourbasic.org/golang/clear-slice/ Remove all elements To remove all elements, simply set the slice to nil. a := []string{\"A\", \"B\", \"C\", \"D\", \"E\"} a = nil fmt.Println(a, len(a), cap(a)) // [] 0 0 This will release the underlying array to the garbage collector (assuming there are no other references). Keep allocated memory To keep the underlying array, slice the slice to zero length. a := []string{\"A\", \"B\", \"C\", \"D\", \"E\"} a = a[:0] fmt.Println(a, len(a), cap(a)) // [] 0 5 If the slice is extended again, the original data reappears. fmt.Println(a[:2]) // [A B] 结论 对slice进行切片不会导致gc 即a = a[:0]不会把底层的array gc掉. float32和data race 在pidinfo.go中, 我使用了float32类型的变量userHz var userHz float32 = 100 我当时认为一个CPU对齐的32bit变量, 它的load和store操作是原子的. -- 好像理论上是的. 但go test -race还是认为这里有问题: 即同时读写这个变量被认为是数据竞争: WARNING: DATA RACE Read at 0x00000071c34c by goroutine 8: gitlabe1.ext.net.nokia.com/godevsig/system/pidinfo.(*TidInfo).CPUpercent() /builds/godevsig/system/pidinfo/pidinfo.go:480 +0x269 ... Previous write at 0x00000071c34c by goroutine 10: gitlabe1.ext.net.nokia.com/godevsig/system/pidinfo.hzUpdater() /builds/godevsig/system/pidinfo/pidinfo.go:331 +0x22c 使用sync/atomic // AtomicLoadFloat64 loads float64 atomically func AtomicLoadFloat64(addr *float64) float64 { return math.Float64frombits(atomic.LoadUint64((*uint64)(unsafe.Pointer(addr)))) } // AtomicStoreFloat64 stores float64 atomically func AtomicStoreFloat64(addr *float64, val float64) { atomic.StoreUint64((*uint64)(unsafe.Pointer(addr)), math.Float64bits(val)) } 再说reflect 什么是unaddressable 不能改变a package main import ( \"fmt\" \"reflect\" ) func main() { a := 55 fmt.Println(a) rv := reflect.ValueOf(a) fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } 上面的代码输出: 代码13行, 说值不能被寻址 55 55 panic: reflect: reflect.Value.SetInt using unaddressable value goroutine 1 [running]: reflect.flag.mustBeAssignableSlow(0x82) /usr/local/go-faketime/src/reflect/value.go:260 +0x138 reflect.flag.mustBeAssignable(...) /usr/local/go-faketime/src/reflect/value.go:247 reflect.Value.SetInt(0x4a4220, 0x54ab98, 0x82, 0x42) /usr/local/go-faketime/src/reflect/value.go:1633 +0x3b main.main() /tmp/sandbox505010953/prog.go:13 +0x1d9 能改变a 但下面的代码就能够修改变量a的值: package main import ( \"fmt\" \"reflect\" ) func main() { a := 55 fmt.Println(a) rptr := reflect.ValueOf(&a) rv := rptr.Elem() fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } 上面代码输出: 55 55 66 关键在于第11和12行. rptr是&a的值, 也就是a的地址; 而rv是rptr的解引用, 也即rv就是a. 对rv的值的改变, 就是对a的改变. 为什么? 在下面代码中, rv := reflect.ValueOf(a)实际上是得到a的副本的值 而如果rv.SetInt(66)能够成立的话, 也只能是set这个副本的值, 且这个修改也不会反应到a上. func main() { a := 55 fmt.Println(a) rv := reflect.ValueOf(a) fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } 那为什么这样可以? func main() { a := 55 fmt.Println(a) rptr := reflect.ValueOf(&a) rv := rptr.Elem() fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } rptr := reflect.ValueOf(&a)也是得到&a的副本的值. 但&a是个指针, 它的解引用rptr.Elem()就是a, 而不是a的副本. 所以可以修改a.副本发生在指针是没问题的. 更进一步解释 rv.SetInt(66)的源码如下: // SetInt sets v's underlying value to x. // It panics if v's Kind is not Int, Int8, Int16, Int32, or Int64, or if CanSet() is false. func (v Value) SetInt(x int64) { v.mustBeAssignable() switch k := v.kind(); k { default: panic(&ValueError{\"reflect.Value.SetInt\", v.kind()}) case Int: *(*int)(v.ptr) = int(x) case Int8: *(*int8)(v.ptr) = int8(x) case Int16: *(*int16)(v.ptr) = int16(x) case Int32: *(*int32)(v.ptr) = int32(x) case Int64: *(*int64)(v.ptr) = x } } 可以看到, 只有v有ptr才能赋值. 结论 其实很简单, 通过反射赋值, 实际上就是两个过程: 先取地址, 再赋值. ptr = &a *ptr = x 例子 var v interface{} a := 55 v = &a rptr := reflect.ValueOf(v) //unaddressable rptr.Set(reflect.New(rptr.Type().Elem())) //可以赋值, 相当于v = &b reflect.ValueOf(&v).Elem().Set(reflect.New(rptr.Type().Elem())) 原理 https://blog.golang.org/laws-of-reflection 结论 每个类型都对应一个_type结构, 描述了该类型的属性和方法 interface也是类型(也是type声明的), 用interfacetype来描述, 后者内部也包括了_type结构 空interface也是类型, 但没有方法 带方法的interface规定了方法集, 也保存在其_type中 interface的表达可以大概认为是(value, type)对, 更具体的说, 是个16字节的结构, 包括一个指针和实际的(concrete)类型// 没方法的interface type eface struct { _type *_type data unsafe.Pointer } // 有方法的interface type iface struct { tab *itab data unsafe.Pointer } interface变量的静态类型是代码中声明的类型, 这个类型会伴随这个interface变量一生, 不会改变 静态类型在编译阶段用来检查是否赋值成立 -- 即对方是否实现了我规定的方法集 静态类型规定了这个interface变量可以直接调用的方法. concrete类型(有时也称动态类型)是给interface变量赋值的时候, 实际的对象类型 interface变量的concrete类型会随着再次赋值而改变 类型断言的意义在于断言这个concrete类型是否满足断言 -- 用类型断言能够突破静态类型的限制, 调用concrete类型的其他方法 有方法的interface的itable是动态计算的 -- runtime通过匹配该interface类型的方法集和concrete对象类型的方法集, 来生成itable. -- 每个interface变量都有个动态生成的itable. 这个和编译时检查能否赋值不同 -- 但我没想明白, 似乎在编译阶段就能确定下来. 相关的说法是: 就是说可以在编译时搞, 但没必要. Go's dynamic type conversions mean that it isn't reasonable for the compiler or linker to precompute all possible itables: there are too many (interface type, concrete type) pairs, and most won't be needed 反射本质上是一种检测interface变量底层的(value, type)对的方法 -- 这里指concrete类型 reflect.Value类型其实就是这个interface变量的内部表达, 它本身既包含了\"值\", 也包含了类型. 所以reflect.Value有Type()方法得到其concrete类型 所以Value类型的Interface()方法能够再次\"组装(pack)\"一个interface变量, 返回一个空的interface{}类型 reflect.TypeOf()方法其实是个shortcut, 和先ValueOf()再Type()效果一样. reflect.Type类型是go内部的_type的表达 能否对Value类型进行Set()操作, 取决于是否这个Value对象是否是另一个对象的引用type Struct1 struct { A int64 } p := Struct1{} V := reflect.ValueOf(&p).Elem() V.FieldByName(\"A\").SetInt(100) 上面代码能工作, 因为V是对p的引用, 就能修改p的内容. 理解起来, 和f(x)不能改变x, 但f(&x)能改变x是一个道理 再议interface 主要是想考察一下, 我曾经用过的map接口 type intMap struct { ks []int // in insertion order mp map[int]interface{} } 这里面的key是int, value是interface{} 这个interface{}的使用会不会有性能问题? 这里的使用是指: set, 对value赋值, 和普通的map相比, 这里多了对interface{}赋值 get, 获取value func (im *intMap) set(k int, v interface{}) { _, has := im.mp[k] if !has { im.ks = append(im.ks, k) } im.mp[k] = v } func (im *intMap) get(k int) (interface{}, bool) { v, has := im.mp[k] return v, has } interface{}回顾 上图的Binary是uint64, 有两个方法 type Binary uint64 func (i Binary) String() string { return strconv.Uitob64(i.Get(), 2) } func (i Binary) Get() uint64 { return uint64(i) } s是个Stringer的interface{}, 是带方法的. 但它的itable表只有String一个方法. Binary的Get方法不是Stringer的关注点, 不在Stringer的itable里面 itable是运行时动态计算的. 虽然在编译的时候, 编译器是可以知道这些信息的:S := Stringer(b)就包含了所有的关键点, 但在编译阶段就写好itable太粗暴了: interface{}和底层concrete类型的配对可以有非常多种, 很多在运行时可能都不真正需要. 动态itable基于 编译器给每个concrete类型都生成了类型描述, 包括它的方法(函数指针形式)列表 -- 实现表 编译器给每个interface类型也生成类型描述, 它也有方法列表. -- 需求表 运行时按照需求表来查实现表, 完成itable的构建 构建好的itable表会被cache, 同一个interface{}和concrete只会构建一次. set get性能损失如何? type intMap struct { ks []int // in insertion order mp map[int]interface{} } 这里的value是个empty的interface{}, go里面有专门的eface来表达: type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 那么对空interface赋值, 除了data域的值拷贝, 还有个_type *_type指针的赋值, 这里应该就是指向concrete类型的类型描述. 这样, 赋值完成后, 这个interface变量, 就有所有concrete变量的所有信息. 看起来多出来的_type *_type指针赋值, 并没有多少性能损耗. 在get的时候, 直接获取到interface, 通常需要类型断言才能被业务逻辑使用: 比如 //childpi是个空的interface{}类型 childpi, _ := pi.children.get(pid) //断言成*PidInfo才能使用 children = append(children, childpi.(*PidInfo)) 我猜从原理上, 这个类型断言就是看_type *_type是不是*PidInfo 看起来性能也没有多少损失 结论 我目前倾向没有多少性能损失的结论 标准库的time.Now()如何取得系统时间? time.Now()的实现流程 实际的系统时间是汇编代码, 比如mips64是在src/runtime/sys_linux_mips64x.s // func walltime() (sec int64, nsec int32) TEXT runtime·walltime(SB),NOSPLIT,$16 MOVW $0, R4 // CLOCK_REALTIME MOVV $0(R29), R5 MOVV $SYS_clock_gettime, R2 SYSCALL MOVV 0(R29), R3 // sec MOVV 8(R29), R5 // nsec MOVV R3, sec+0(FP) MOVW R5, nsec+8(FP) RET TEXT runtime·nanotime(SB),NOSPLIT,$16 MOVW $1, R4 // CLOCK_MONOTONIC MOVV $0(R29), R5 MOVV $SYS_clock_gettime, R2 SYSCALL MOVV 0(R29), R3 // sec MOVV 8(R29), R5 // nsec // sec is in R3, nsec in R5 // return nsec in R3 MOVV $1000000000, R4 MULVU R4, R3 MOVV LO, R3 ADDVU R5, R3 MOVV R3, ret+0(FP) RET 这里的walltime和nanotime会被time_now()调用. 在src/runtime/timestub.go中 time_now()是time.now的linkname. 即实际上time.now()就是runtime.time_now() package runtime import _ \"unsafe\" // for go:linkname //go:linkname time_now time.now func time_now() (sec int64, nsec int32, mono int64) { sec, nsec = walltime() return sec, nsec, nanotime() } 这里的问题是, 每次获取系统时间, 都有2次系统调用: 第一次是clock_gettime获取CLOCK_REALTIME 第二次是clock_gettime获取CLOCK_MONOTONIC 同时, 我们也看到, 虽然调用了系统调用, 但这个调用路径上没有埋伏runtime的调度等函数. 最后, 标准库time包的Now()调用了now() // Now returns the current local time. func Now() Time { sec, nsec, mono := now() mono -= startNano sec += unixToInternal - minWall if uint64(sec)>>33 != 0 { return Time{uint64(nsec), sec + minWall, Local} } return Time{hasMonotonic | uint64(sec) clock_gettime系统调用 man clock_gettime中说: #include int clock_gettime(clockid_t clk_id, struct timespec *tp); 这里的clk_id可以是从Epoch(1970年?)算起的绝对时间, 这个时间对所有进程都一样. 也可以是按进程角度看起来的时间 CLOCK_REALTIME: 系统时间, 墙上时间. wall clock CLOCK_REALTIME_COARSE: 系统时间, 精度稍差, 但快速的版本 CLOCK_MONOTONIC: 从开机算起的时间, 不能更改 CLOCK_MONOTONIC_COARSE: 精度稍差但快的版本 CLOCK_MONOTONIC_RAW: 硬件返回的时间, 不受NTP影响 CLOCK_PROCESS_CPUTIME_ID: 按进程算的时间 CLOCK_THREAD_CPUTIME_ID: 按线程算的时间 逃逸分析和变量分配 go的程序在编译的时候, 通过逃逸分析来确定变量是分配在栈上, 还是分配到堆上. 一个变量分配在哪里是编译时决定的 如果编译器通过分析得知, 一个变量可能脱离其声明时所在的函数作用域, 就会把这个变量分配到堆上. 否则, 编译器知道这个变量的所有引用都在此函数的生命周期内, 那这个变量就可以被安全的分配到栈上. 在堆上分配的开销相对很大, 编译器会插入CALL runtime.newobject(SB)的汇编代码来实现堆分配. 而栈分配就是简单的通过栈指针SP+偏移的引用. 一个典型的堆分配如图: 下面我们来简单了解一下编译器如何判断一个变量是否可能逃逸 逃逸分析使用 go build, go run, go test都支持-gcflags '-m -l'选项, 打开逃逸分析的输出. -m: 最多4个-m连用, 打开丰富的编译过程的逃逸分析记录 -l: 禁止inline, 让-m的信息更容易阅读 逃逸分析实例 比如下面的代码 package main import ( \"fmt\" \"unsafe\" ) var gr *int func change(r *int) { *r = *r + 1 //gr = r } func sum(a, b int) int { s := a + b change(&s) fmt.Println(s) //fmt.Println(&s) addr := uintptr(unsafe.Pointer(&s)) fmt.Printf(\"0x%x %v\\n\", addr, *(*int)(unsafe.Pointer(addr))) return s } func main() { a, b := 1, 2 c := sum(a, b) fmt.Println(c) } 使用逃逸分析结果如下, $ go run -gcflags '-m -l' hello.go # command-line-arguments ./hello.go:10:13: change r does not escape ./hello.go:18:13: sum ... argument does not escape ./hello.go:18:13: s escapes to heap ./hello.go:21:12: sum ... argument does not escape ./hello.go:21:13: addr escapes to heap ./hello.go:21:32: *(*int)(unsafe.Pointer(addr)) escapes to heap ./hello.go:28:13: main ... argument does not escape ./hello.go:28:13: c escapes to heap 4 0xc000096eb8 4 4 解释: 先看简单点的main函数, a和b两个int变量, 传给sum得到int c, 然后打印c. 首先, go里面都是值传递, main的a和b, 在传给sum的时候, 值已经分别被拷贝进sum的参数, 所以a和b不可能逃逸. c拷贝了sum函数的返回值, 在传递给Println的时候, 又发生了值拷贝, c只是int, 不可能逃逸. 但./hello.go:28:13: c escapes to heap是说c逃逸到堆了吗? 其实不是, 因为Println()的入参是interface{}, 而interface{}是由类型域和指针域组成的, 它的指针域指向底层的数据. 这里的意思是说, c的值被拷贝进一个堆的int变量(应该还是栈上), 被Println的入参interface变量的指针域指向. 所以并不是变量c本身逃逸到堆. 注: 通过反汇编发现, c的值拷贝也不是分配到堆上的. 如果改成fmt.Println(&c), 则c会逃逸. 因为Pringln持有了c的引用, 而没有什么办法能阻止一个函数再次\"传递\"这个引用到channel或者一个全局变量, 从而c的引用会被更广泛的持有. 所以编译器认为c会逃逸, 要分配到堆里, 由运行时GC来负责变量c的释放. 真正的逃逸会在变量声明的那行, 打印moved to heap: 变量名 比如, 如果第19行没有被注释, 则变量s会逃逸到堆. 逃逸分析会打印: ./hello.go:16:2: moved to heap: s 表示s真正的逃逸到堆了. 一般的, 取地址后赋值给interface{}, 则会更可能被编译器判定为逃逸. 注意这里说的是可能, 不是绝对. 有些情况下, 取地址赋值给interface{}不会导致逃逸. 比如下面代码片段: 测试版本go1.13 func changeInterface(r interface{}) { v := r.(*int) *v = *v + 1 } a, b := 1, 2 s := a + b changeInterface(&s) //同样是interface{}赋值, 这句不会导致s逃逸 fmt.Println(s) //值拷贝, 不会导致s逃逸 fmt.Println(&s) //fmt.Print函数族+取变量地址会导致变量逃逸到堆. 个人认为这个设定不是很合理. 编译器应该确切知道fmt.Println()有没有再\"散发\" `&s` 不是所有取地址都会逃逸. 比如sum里面调用了change(&s), 传递的是s的引用; 那s是有可能逃逸的, 但编译器发现change函数, 在没有赋值给全局变量gr的情况下(注释掉12行), 并没有实际上让s继续逃逸. 所以上面的代码, 逃逸分析得出, s还是分配到栈里. 同样是打印地址, addr := uintptr(unsafe.Pointer(&s))然后打印addr不会让s逃逸; 而fmt.Println(&s)则会让s逃逸. uintptr和unsafe.Pointer()的互相强转组合能阻断这种\"引用扩散\", 这可能是unsafe包名字的由来: 其引用的地址由于没有被记录在案, 可能被gc回收掉而不知道. 判断一个变量是否真正被编译器判定为逃逸, 看变量声明的那行是否有moved to heap: 变量名, 注意, 变量名 escapes to heap发生在使用改变量那一行, 个人认为不是说这个变量逃逸了. 还有一个办法来确认是否逃逸: 用go tool compile -S -m -l查看汇编. 比如本例中, 考察sum函数中的变量s, 只有编译器判定s会逃逸并打印moved to heap: s, 其汇编代码里才有CALL runtime.newobject(SB)表示真的调用运行时函数来给改变量分配内存空间. 而平常的s escapes to heap在调用fmt.Print族函数的时候都会出现, 个人理解并不是变量已经逃逸的意思, 也不是变量的拷贝被放到堆中. 下面的截图是本例代码的反汇编go tool objdump -S hello > hello.objdump在调用CALL fmt.Println(SB)之前, sum函数的所有操作的变量看起来都是基于SP的, 都是栈变量. 看起来传递给fmt.Println()的拷贝也并没有分配到堆上. 注: unsafe.Pointer有如下性质: unsafe.Pointer和任意的指针类型能互相转换 unsafe.Pointer和uintptr能互相转换 指针和uintptr不能直接互转 uintptr用于做\"指针\"计算 查看汇编 go tool compile -S -m -l hello.go 反汇编 go tool objdump -S hello > hello.objdump go的值和指针 代码: func Show(i interface{}) { if i == nil { fmt.Printf(\"type: %T, value: %#v\\n\", i, i) return } t := reflect.TypeOf(i) if t.Kind() != reflect.Ptr { fmt.Printf(\"type: %T, size: %d; value: %#v\\n\", i, t.Size(), i) } else { v := reflect.ValueOf(i) fmt.Printf(\"type: %T, size: %d; value: %#v, value size: %d\\n\", i, t.Size(), v.Elem(), t.Elem().Size()) } } 结论: 所有的指针都占8个字节 x86_64 type: int, size: 8; value: 99 type: *int, size: 8; value: 99, value size: 8 type: **int, size: 8; value: (*int)(0xc0000e01d0), value size: 8 type: *int, size: 8; value: 0, value size: 8 type: **int, size: 8; value: (*int)(0xc0000e0228), value size: 8 type: string, size: 16; value: \"hello world\" type: *string, size: 8; value: \"hello world\", value size: 16 type: , value: type: *os.File, size: 8; value: os.File{file:(*os.file)(0xc0000cc060)}, value size: 8 type: **os.File, size: 8; value: &os.File{file:(*os.file)(0xc0000cc060)}, value size: 8 补充: 逃逸分析命令 go build -gcflags '-m -l' go test -gcflags '-m -l' map golang的map底层是hash表实现的. 初始化 hashmap结构体 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } buckets是底层数组的指针, 用unsafe.Pointer来声明的 make map变量的时候 在make(map[k]v, hint)的时候 调用runtime/map.go // makemap implements Go map creation for make(map[k]v, hint). // If the compiler has determined that the map or the first bucket // can be created on the stack, h and/or bucket may be non-nil. // If h != nil, the map can be created directly in h. // If h.buckets != nil, bucket pointed to can be used as the first bucket. func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem > maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint 这个hash表的底层承载是数组(bukets), 最大容量是2^B即, 而B是uint8, 故数组元素最大2^256个, 非常大 每个数组元素叫buket, 能装载8个元素; 相同key的buket用链表链接(拉链式解决冲突) 如果make不指定capacity, 初始化hash表的时候默认使用B=0, 即空的bukets数组; 当后面第一次加数据的时候会扩容. -- Lazy模式 扩容时, 容量是原来的2倍. 因为是在runtime包里的, 这些都是运行时的行为. 遍历 用迭代器来遍历map, 用mapiterinit(t *maptype, h *hmap, it *hiter)来初始化一个迭代器, 编译器生成代码的时候会插入这个调用 / A hash iteration structure. // If you modify hiter, also change cmd/compile/internal/gc/reflect.go to indicate // the layout of this structure. type hiter struct { key unsafe.Pointer // Must be in first position. Write nil to indicate iteration end (see cmd/internal/gc/range.go). elem unsafe.Pointer // Must be in second position (see cmd/internal/gc/range.go). t *maptype h *hmap buckets unsafe.Pointer // bucket ptr at hash_iter initialization time bptr *bmap // current bucket overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // bucket iteration started at offset uint8 // intra-bucket offset to start from during iteration (should be big enough to hold bucketCnt-1) wrapped bool // already wrapped around from end of bucket array to beginning B uint8 i uint8 bucket uintptr checkBucket uintptr } func mapiterinit(t *maptype, h *hmap, it *hiter) { it.t = t it.h = h // grab snapshot of bucket state it.B = h.B it.buckets = h.buckets //起始点随机, 这是为什么range map出来的结果顺序不确定. r := uintptr(fastrand()) if h.B > 31-bucketCntBits { r += uintptr(fastrand()) > h.B & (bucketCnt - 1)) //it.bucket是当前的bucket指针, 指向底层buckets数组的元素, 即key对应的table中的index的元素 it.bucket = it.startBucket mapiternext(it) } mapiternext()是遍历map的执行主体, 编译器会在range语句里面反复调用它, 来得到下一个key, value对 func mapiternext(it *hiter) { h := it.h //不能同时写, 否则直接panic if h.flags&hashWriting != 0 { throw(\"concurrent map iteration and map write\") } //it.t.key里面包括了hash算法 t := it.t alg := t.key.alg //bucket是当前的bucket指针 bucket := it.bucket //b是当前的bucket指向的bmap, bmap是8个元素的结构 b := it.bptr //i是拉链8个元素的编号 i := it.i next: 如果当前bucket为空 如果又回到起始的bucket, 说明遍历结束了 it.key = nil it.elem = nil return //根据是否map在增长中, 来算下个pmap拉链元素的地址, 类似这样 b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) //指针++, 在it.buckets数组里往下移动一个单元 bucket++ //下一个bucket了, i为0 i = 0 //看当前的bucket链表, 一个bucket最多有8个元素 for ; i hash算法 hash算法是key的类型决定的, 详见:src/runtime/alg.go // typeAlg is also copied/used in reflect/type.go. // keep them in sync. type typeAlg struct { // function for hashing objects of this type // (ptr to object, seed) -> hash hash func(unsafe.Pointer, uintptr) uintptr // function for comparing objects of this type // (ptr to object A, ptr to object B) -> ==? equal func(unsafe.Pointer, unsafe.Pointer) bool } 常用的hash算法 实现hash算法的文件在src/runtime/hash64.go和src/runtime/hash32.go 注: 这两个文件有编译限制, 针对CPU类型的. var algarray = [alg_max]typeAlg{ alg_NOEQ: {nil, nil}, alg_MEM0: {memhash0, memequal0}, alg_MEM8: {memhash8, memequal8}, alg_MEM16: {memhash16, memequal16}, alg_MEM32: {memhash32, memequal32}, alg_MEM64: {memhash64, memequal64}, alg_MEM128: {memhash128, memequal128}, alg_STRING: {strhash, strequal}, //这个是interface的hash方法, 内部调用这个interface的hash方法 alg_INTER: {interhash, interequal}, alg_NILINTER: {nilinterhash, nilinterequal}, alg_FLOAT32: {f32hash, f32equal}, alg_FLOAT64: {f64hash, f64equal}, alg_CPLX64: {c64hash, c64equal}, alg_CPLX128: {c128hash, c128equal}, } //内存hash最普遍, 根据指针p的内容和一些素数常量来做操作 const ( // Constants for multiplication: four random odd 64-bit numbers. m1 = 16877499708836156737 m2 = 2820277070424839065 m3 = 9497967016996688599 m4 = 15839092249703872147 ) func memhash64(p unsafe.Pointer, seed uintptr) uintptr { h := uint64(seed + 8*hashkey[0]) h ^= uint64(readUnaligned32(p)) | uint64(readUnaligned32(add(p, 4)))> 29 h *= m3 h ^= h >> 32 return uintptr(h) } func strhash(a unsafe.Pointer, h uintptr) uintptr { x := (*stringStruct)(a) return memhash(x.str, h, uintptr(x.len)) } 有的架构硬件支持aeshash, 就使用这些硬件算法 func memhash(p unsafe.Pointer, seed, s uintptr) uintptr { if (GOARCH == \"amd64\" || GOARCH == \"arm64\") && GOOS != \"nacl\" && useAeshash { return aeshash(p, seed, s) } ... } 结论 golang的map实现是hash表, 拉链式处理冲突 golang在编译时的make(map[k]v, hint), 会被编译器当作makemap()的函数调用插入到目标代码里, 在runtime真正创建map时调用. 对map的range遍历, 会被编译器当作迭代器的函数调用, 供在runtime时调用 对map的遍历, 没有magic, 还是老老实实的对底层数组从头到尾遍历 根据key的类型不同, 用不同的hash函数, 最后一般会调到memhash(), 做内存hash 如果make时不指定capacity, 默认创建底层数组为0的map. 底层数组会在以后put元素时才创建, 而且刚开始不大; 要put的元素越来越多时, 这个底层数组会以2倍的速率随之扩容, 老的元素会被一个个的拷贝到新的2倍大小的数组里. hash函数虽然不变, 但hash出来算index的算法会根据底层数组大小改变. // A map is just a hash table. The data is arranged // into an array of buckets. Each bucket contains up to // 8 key/elem pairs. The low-order bits of the hash are // used to select a bucket. Each bucket contains a few // high-order bits of each hash to distinguish the entries // within a single bucket. // // If more than 8 keys hash to a bucket, we chain on // extra buckets. // // When the hashtable grows, we allocate a new array // of buckets twice as big. Buckets are incrementally // copied from the old bucket array to the new bucket array. // // Map iterators walk through the array of buckets and // return the keys in walk order (bucket #, then overflow // chain order, then bucket index). To maintain iteration // semantics, we never move keys within their bucket (if // we did, keys might be returned 0 or 2 times). When // growing the table, iterators remain iterating through the // old table and must check the new table if the bucket // they are iterating through has been moved (\"evacuated\") // to the new table. Gc的演进 v1.0 — 完全串行的标记和清除过程，需要暂停整个程序； v1.1 — 在多核主机并行执行垃圾收集的标记和清除阶段11； v1.3 — 运行时基于只有指针类型的值包含指针的假设增加了对栈内存的精确扫描支持，实现了真正精确的垃圾收集12； 将 unsafe.Pointer 类型转换成整数类型的值认定为不合法的，可能会造成悬挂指针等严重问题； v1.5 — 实现了基于三色标记清扫的并发垃圾收集器13； 大幅度降低垃圾收集的延迟从几百 ms 降低至 10ms 以下； 计算垃圾收集启动的合适时间并通过并发加速垃圾收集的过程； v1.6 — 实现了去中心化的垃圾收集协调器； 基于显式的状态机使得任意 Goroutine 都能触发垃圾收集的状态迁移； 使用密集的位图替代空闲链表表示的堆内存，降低清除阶段的 CPU 占用14； v1.7 — 通过并行栈收缩将垃圾收集的时间缩短至 2ms 以内15； v1.8 — 使用混合写屏障将垃圾收集的时间缩短至 0.5ms 以内16； v1.9 — 彻底移除暂停程序的重新扫描栈的过程17； v1.10 — 更新了垃圾收集调频器（Pacer）的实现，分离软硬堆大小的目标18； v1.12 — 使用新的标记终止算法简化垃圾收集器的几个阶段19； v1.13 — 通过新的 Scavenger 解决瞬时内存占用过高的应用程序向操作系统归还内存的问题20； v1.14 — 使用全新的页分配器优化内存分配的速度21； interface赋值 接口有两个字段, 一个是类型, 一个是指针. 那对一个空接口赋值, 是传值还是传地址? type Person struct{ name string } type IPerson interface{} func main() { var person Person = Person{\"John\"} var iPerson IPerson fmt.Println(person) // => John fmt.Println(iPerson) // => ...so looks like a pointer iPerson = person // ...this seems to be making a copy fmt.Println(iPerson) // => John person.name = \"Mike\" fmt.Println(person) // => Mike //这里说明, 对数据源的改变, 不会体现到interface里 //说明interface是值拷贝 fmt.Println(iPerson) // => John ...so looks like it wasn't a pointer, // or at least something was definitely copied } The second word in the interface value points at the actual data, in this case a copy of b. The assignment var s Stringer = b makes a copy of b rather than point at b for the same reason that var c uint64 = b makes a copy: if b later changes, s and c are supposed to have the original value, not the new one. 也就是说, 对空接口的赋值, 发生了值拷贝, 空接口的指针字段, 指向新的拷贝. 更正 又过了一段时间, 觉得上面的解释不对对interface的赋值是值拷贝没错. 但对string的值拷贝不拷贝其底层buffer.上面例子第11行, 对空接口iPerson的赋值, 发生了string的\"值拷贝\", 即只拷贝string的结构体, 不拷贝buffer.关键是第14行, 对原始变量person.name的赋值, 也只是把\"Mike\"这个string的结构体赋值给person.name, 并不是把\"Mike\"拷贝到person.name的buffer里. person.name的底层指针, 改为指向\"Mike\"iPerson的name结构体没有变化, 还是指向原\"John\" interface的内部表达 golang中的interface, 有两种表达 iface是有方法的 eface没有方法, 纯空接口 它们都有指向底层数据的指针. type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 参考: https://blog.gopheracademy.com/advent-2018/interfaces-and-reflect/ reflect Type和interface reflect method reflect Value timer 标准库time提供了go语言对时间和定时器的使用接口 timer API 单次timer Timer对象持有channel C. timer超时后, 会发送当前时间到channel C. func NewTimer(d Duration) *Timer 返回一个Timer对象 典型的应用场景是, 从一个管道读数据, 不想永远等下去, 而是设个超时时间. func WaitChannel(conn 周期性timer go里面叫Ticker, 和Timer类似, 但Ticker周期性的往channel发送数据 func NewTicker(d Duration) *Ticker 使用Ticker需要注意的是, 不用的Ticker要调用Stop方法来终止, 否则系统一直会执行这个Ticker. package main import ( \"fmt\" \"time\" ) func main() { ticker := time.NewTicker(time.Second) //不用时stop Ticker defer ticker.Stop() done := make(chan bool) go func() { time.Sleep(10 * time.Second) done timer实现原理 timer的底层实现在runtime里. 在系统监控的循环中，我们通过 runtime.nanotime 和 runtime.timeSleepUntil 获取当前时间和计时器下一次需要唤醒的时间. 其中runtime.timeSleepUntil()函数遍历所有的timer bucket, 返回最小的. func timeSleepUntil() int64 { next := int64(1 timers是个数组, 元素是{timersBucket堆, 和cacheline对齐的pad} const timersLen = 64 // timers contains \"per-P\" timer heaps. // // Timers are queued into timersBucket associated with the current P, // so each P may work with its own timers independently of other P instances. // // Each timersBucket may be associated with multiple P // if GOMAXPROCS > timersLen. var timers [timersLen]struct { timersBucket // The padding should eliminate false sharing // between timersBucket values. pad [cpu.CacheLinePadSize - unsafe.Sizeof(timersBucket{})%cpu.CacheLinePadSize]byte } go1.13里面, 这个数组的大小是64, 是固定的. 按理说应该是per CPU的, 但为了避免动态分配内存, 考虑到主流的CPU核数, 这里就固定了64. 注: 用unsafe.Sizeof可以得到结构体大小 timersBucket是个堆结构, 因为timer的操作都会涉及到排序, 堆的排序和查找性能都不错. type timersBucket struct { lock mutex //goroutine的指针 gp *g created bool sleeping bool rescheduling bool //因为所有timer都是排序的, 这是最小的sleep时间 sleepUntil int64 waitnote note //timer桶下面的所有timer t []*timer } timer结构体, 在timer到时后在timer桶的timerproc协程里执行f type timer struct { tb *timersBucket // the bucket the timer lives in i int // heap index // Timer wakes up at when, and then at when+period, ... (period > 0 only) // each time calling f(arg, now) in the timer goroutine, so f must be // a well-behaved function and not block. when int64 period int64 f func(interface{}, uintptr) arg interface{} seq uintptr } add timer 每个timer的桶都有一个goroutine; 如果add timer的时候, 排好序后该timer是桶里的第一个timer, 会唤醒阻塞的gotoutine; 如果是第一次建立timer桶, 会起goroutine timerproc来执行timer桶里的事件, 因为桶里的timer都是按时间排好序的, 一个goroutine就够了. func addtimer(t *timer) { tb := t.assignBucket() lock(&tb.lock) ok := tb.addtimerLocked(t) unlock(&tb.lock) if !ok { badTimer() } } timer桶的分配 func (t *timer) assignBucket() *timersBucket { //当前g的m的p的id号, 翻译过来就是CPU号 id := uint8(getg().m.p.ptr().id) % timersLen t.tb = &timers[id].timersBucket return t.tb } 真正实现addtimer的函数 func (tb *timersBucket) addtimerLocked(t *timer) bool { // when must never be negative; otherwise timerproc will overflow // during its delta calculation and never expire other runtime timers. if t.when t.when { tb.sleeping = false //这个waitnote是个uintptr, 底层是futex或者是semaphore //每个timer桶一个 notewakeup(&tb.waitnote) } if tb.rescheduling { tb.rescheduling = false goready(tb.gp, 0) } if !tb.created { tb.created = true //起个goroutine, go timerproc(tb) } } return true } 触发timer 按前面所述, add timer时会给每个timer 桶起一个\"守护\"协程timerproc, timer的触发就在这个协程中. 它负责检查桶内的timer, 执行超时后的回调函数, 然后休眠到下个timer到期. //每个timer桶都有一个这个goroutine, 用于到时后执行timer的回调; //大部分回调是time.sendTime()往channel写. func timerproc(tb *timersBucket) { tb.gp = getg() for { lock(&tb.lock) tb.sleeping = false now := nanotime() delta := int64(-1) for { if len(tb.t) == 0 { delta = -1 break } //第一个元素是超时时间最短的 t := tb.t[0] delta = t.when - now //超时时间没到 if delta > 0 { break } //时间到了 ok := true //是周期的timer if t.period > 0 { // leave in heap but adjust next time to fire //这里delta只能是0或负数, delta的偏差越大, 说明系统繁忙来不及响应? 越增大下次的超时时间 t.when += t.period * (1 + -delta/t.period) //重新加入堆排序 if !siftdownTimer(tb.t, 0) { ok = false } } else { //是一次性的timer // remove from heap last := len(tb.t) - 1 if last > 0 { tb.t[0] = tb.t[last] tb.t[0].i = 0 } tb.t[last] = nil tb.t = tb.t[:last] if last > 0 { if !siftdownTimer(tb.t, 0) { ok = false } } t.i = -1 // mark as removed } //f是这个timer的回调 f := t.f arg := t.arg seq := t.seq unlock(&tb.lock) if !ok { badTimer() } if raceenabled { raceacquire(unsafe.Pointer(t)) } //调用这个timer的回调函数, 这个函数必须不能阻塞, 因为这里持有timer桶的锁. //time.NewTimer方法, 传入的是sleep.go里的私有函数sendTime f(arg, seq) lock(&tb.lock) } if delta 0 { // No timers left - put goroutine to sleep. tb.rescheduling = true goparkunlock(&tb.lock, waitReasonTimerGoroutineIdle, traceEvGoBlock, 1) continue } // At least one timer pending. Sleep until then. tb.sleeping = true tb.sleepUntil = now + delta noteclear(&tb.waitnote) unlock(&tb.lock) //这个for循环把那个不是忙等, 而是根据delta时间来sleep. notetsleepg(&tb.waitnote, delta) //底层是futexsleep, 是带超时时间的futex系统调用 //每个timer桶都有个waitnote, 这个应该是futex锁 futexsleep(key32(&n.key), 0, ns) } } time.NewTimer()注册了sendTime()回调 time包的NewTimer()方法, 底层调用的是startTimer(), 向runtime添加timer func NewTimer(d Duration) *Timer { c := make(chan Time, 1) // 创建一个管道 t := &Timer{ // 构造Timer数据结构 C: c, // 新创建的管道 r: runtimeTimer{ when: when(d), // 触发时间 f: sendTime, // 触发后执行函数sendTime arg: c, // 触发后执行函数sendTime时附带的参数 }, } startTimer(&t.r) // 此处启动定时器，只是把runtimeTimer放到系统协程的堆中，由系统协程维护 return t } sendTime()只是向channel发送当前时间 //sleep.go func sendTime(c interface{}, seq uintptr) { // Non-blocking send of time on c. // Used in NewTimer, it cannot block anyway (buffer). // Used in NewTicker, dropping sends on the floor is // the desired behavior when the reader gets behind, // because the sends are periodic. select { //有default是非阻塞发送 case c.(chan Time) timer堆的维护 timer桶里面的所有timer, golang使用了4叉数的顺序存储结构([]*timer切片)来管理. 每次新增 删除 修改timer或者是timer到期, 都会对timer堆重新排序. 上图展示的是二叉堆，实际上Go实现时使用的是四叉堆，使用四叉堆的好处是堆的高度降低，堆调整时更快。 具体算法见: time.go siftupTimer()和siftdownTimer()函数 time包的NewTimer方法调用了runtime.startTimer 在src/time/sleep.go里面, 创建Timer实例的API NewTimer(), 调用了内部函数startTimer() // NewTimer creates a new Timer that will send // the current time on its channel after at least duration d. func NewTimer(d Duration) *Timer { c := make(chan Time, 1) t := &Timer{ C: c, r: runtimeTimer{ when: when(d), f: sendTime, arg: c, }, } startTimer(&t.r) return t } //而startTimer函数竟然在这个文件是个空函数 func startTimer(*runtimeTimer) 但在src/runtime/time.go里面, 有这样的声明: // startTimer adds t to the timer heap. //go:linkname startTimer time.startTimer func startTimer(t *timer) { if raceenabled { racerelease(unsafe.Pointer(t)) } addtimer(t) } 注意同名函数startTimer上面的注释, 似乎是某种链接黑科技: 把本地函数即runtime.startTimer函数, 当作time.startTimer来对待. go:linkname是给编译器看的指示. 详见官方说明 //go:linkname localname [importpath.name] The //go:linkname directive instructs the compiler to use “importpath.name” as the object file symbol name for the variable or function declared as “localname” in the source code. 性能测试和结果 在性能测试程序中, 我们起了N个go routine, 每个go routine起一个周期为1秒的timer, 即有N个timer同时周期性运行. timer超时后的动作非常简单(i++), 所以此测试几乎完全是测试golang timer机制的效率. MIPS板子为4核的CFNT-B golang的版本是1.13 测试程序使用taskset强制跑在单核上. 测试结果 Timer Number Sequential delay time Single core CPU load(MIPS) Single core CPU load(X86) 2000 0 ms 0 ~ 2.6% 0 ~ 0.7% 2000 20 ms 0 ~ 9.9% @ stable ~7.3% 0 ~ 5.9% @ stable ~4.6% 2000 Random in 30 ms Similar as 20 ms Similar as 20 ms 512 20 ms 0 ~ 2.6% @ stable ~2.0% 0 ~ 2.0% @ stable ~1.3% 20000 20 ms 0 ~ 50% @ stable ~43.7% 0 ~ 13.2% @ stable ~12.5% 结论 golang里每个CPU一个timer桶 桶内使用4叉树排序 每个桶有个单独的timer守护routine, 负责睡眠到下次timer到期, 执行timer的回调 timer的回调是time包注册的函数, 负责写channel, 对外不可见. go1.14对timer的优化 go1.13的timer问题 如上面所述, 每个P都有一个timer堆, 每个堆都有一个timerproc goroutine, 在这个routine中, 调用futexsleep是要休眠的; 注意这里的休眠是系统线程M直接休眠了, 这就要求M要和P解绑定, 意味着一次线程级别的上下文切换的开销: G5里面等待timerG5: , 系统把G5放在channel的reveive队列里, 超时时间到期时系统的timer机制会发送数据到这个channel来唤醒G5, 大致可以理解为G5在本地P的timer堆里休眠; 现在假设timer到期, timerproc(TP)被排到下一个被运行的goroutine TP开始执行, 但TP要求M休眠, 即TP\"带走\"了M, 和P分离 独立的P会触发wakep, 新建或寻找新的M并与之绑定; 接下来比如是从别的P里偷取G来运行 timer到期后, M被kernel唤醒, 会acquirep, 这里可能是抢占了当前的M TP里面通过channel唤醒G5, G5被放到本地P队列; 当然这次可能有多个timer同时超时, 它们对应的G都被放到运行队列 TP完成对timer的唤醒, 调用futex继续睡眠, 导致下一轮的M和P的分离. 综上, 1.13的问题在于: timperproc使用了阻塞的方式睡眠等待timer堆到期, 导致其所在的线程阻塞, 导致线程级别的上下文切换. 1.14解决思路 1.14中, 不使用timerproc来触发timer到期, 而是复用调度器的调度时机来检查timer是否超时. 调度器是没有单独goroutine的, 这样复用了以后, timer桶的检查点也没有单独的goroutine了. 少个gotouine不算什么, 关键是少了阻塞式的系统调用, 避免了timerporc里面的M因为要阻塞而与P分离操作. 系统监控 统监控是 Go 语言运行时的重要组成部分，它会每隔一段时间检查 Go 语言运行时，确保程序没有进入异常状态。 Go 语言的系统监控也起到了很重要的作用，它在内部启动了一个不会中止的循环，在循环的内部会轮询网络、抢占长期运行或者处于系统调用的 Goroutine 以及触发垃圾回收，通过这些行为，它能够让系统的运行状态变得更健康。 运行时通过系统监控来触发线程的抢占、网络的轮询和垃圾回收，保证 Go 语言运行时的可用性。系统监控能够很好地解决尾延迟的问题，减少调度器调度 Goroutine 的饥饿问题并保证计时器在尽可能准确的时间触发。 sysmon在独立的M(系统线程)中运行 监控循环 当 Go 语言程序启动时，运行时会在第一个 Goroutine 中调用 runtime.main 启动主程序，该函数会在系统栈中创建新的线程： func main() { ... if GOARCH != \"wasm\" { systemstack(func() { newm(sysmon, nil) }) } ... } runtime.newm 会创建一个存储待执行函数和处理器的新结构体 runtime.m。运行时执行系统监控不需要处理器，系统监控的 Goroutine 会直接在创建的线程上运行： func newm(fn func(), _p_ *p) { mp := allocm(_p_, fn) mp.nextp.set(_p_) mp.sigmask = initSigmask ... newm1(mp) } runtime.newm1 会调用特定平台的 runtime.newsproc 通过系统调用 clone 创建一个新的线程并在新的线程中执行 runtime.mstart： func newosproc(mp *m) { stk := unsafe.Pointer(mp.g0.stack.hi) var oset sigset sigprocmask(_SIG_SETMASK, &sigset_all, &oset) ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart))) sigprocmask(_SIG_SETMASK, &oset, nil) ... } 在新创建的线程中，我们会执行存储在 runtime.m 结构体中的 runtime.sysmon 函数启动系统监控： func sysmon() { sched.nmsys++ checkdead() lasttrace := int64(0) idle := 0 delay := uint32(0) for { if idle == 0 { delay = 20 } else if idle > 50 { delay *= 2 } if delay > 10*1000 { delay = 10 * 1000 } usleep(delay) ... } } 当运行时刚刚调用上述函数时，会先通过 runtime.checkdead 检查是否存在死锁，然后进入核心的监控循环；系统监控在每次循环开始时都会通过 usleep 挂起当前线程，该函数的参数是微秒，运行时会遵循以下的规则决定休眠时间： 初始的休眠时间是 20μs； 最长的休眠时间是 10ms； 当系统监控在 50 个循环中都没有唤醒 Goroutine 时，休眠时间在每个循环都会倍增； 当程序趋于稳定之后，系统监控的触发时间就会稳定在 10ms。它除了会检查死锁之外，还会在循环中完成以下的工作： 运行计时器 — 获取下一个需要被触发的计时器； 轮询网络 — 获取需要处理的到期文件描述符; 非阻塞地调用 runtime.netpoll 检查待执行的文件描述符并通过 runtime.injectglist 将所有处于就绪状态的 Goroutine 加入全局运行队列中 抢占处理器 — 抢占运行时间较长的或者处于系统调用的 Goroutine； 垃圾回收 — 在满足条件时触发垃圾收集回收内存； 检查timer 在系统监控的循环中，我们通过 runtime.nanotime 和 runtime.timeSleepUntil 获取当前时间和计时器下一次需要唤醒的时间. 在runtime/proc.go func sysmon() { for { //这个delay大概是10ms usleep(delay) //处理timer的优先级比较低, 比如只有在idle的时候才检查 if 各种条件 next := timeSleepUntil() now := nanotime() //没到超时时间, 需要Relax一下 osRelax(true) } } 检查死锁 计算系统中正在运行的线程个数, 如果为0, 则可能发生了死锁.进一步需要判断如果goroutine有可运行状态的, 则证明发生了死锁. 轮询网络 如果上一次轮询网络已经过去了 10ms，那么系统监控还会在循环中轮询网络，检查是否有待执行的文件描述符： func sysmon() { ... for { ... lastpoll := int64(atomic.Load64(&sched.lastpoll)) if netpollinited() && lastpoll != 0 && lastpoll+10*1000*1000 调用netpoll(0)非阻塞地检查待执行的文件描述符并通过 runtime.injectglist 将所有处于就绪状态的 Goroutine 加入全局运行队列中;该函数会将所有 Goroutine 的状态从 _Gwaiting 切换至 _Grunnable 并加入全局运行队列等待运行，如果当前程序中存在空闲的处理器，就会通过 runtime.startm 函数启动线程来执行这些任务。 抢占处理器 系统监控通过在循环中抢占处理器来避免同一个 Goroutine 占用线程太长时间造成饥饿问题。 垃圾回收 在最后，系统监控还会决定是否需要触发强制垃圾回收，runtime.sysmon 会构建 runtime.gcTrigger 结构体并调用 runtime.gcTrigger.test 函数判断是否需要触发垃圾回收： func sysmon() { ... for { ... if t := (gcTrigger{kind: gcTriggerTime, now: now}); t.test() && atomic.Load(&forcegc.idle) != 0 { lock(&forcegc.lock) forcegc.idle = 0 var list gList list.push(forcegc.g) injectglist(&list) unlock(&forcegc.lock) } ... } } 如果需要触发垃圾回收，我们会将用于垃圾回收的 Goroutine 加入全局队列，让调度器选择合适的处理器去执行。 参考: https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sysmon/ IO多路复用 golang中的go routine在发生IO调用时(read/write), 不是直接阻塞, 而是使用IO多路复用. goroutine调用read/write时, runtime会把fd加到epoll里等待ready, 同时调用runtime.gopark让出当前线程. Go 语言的运行时会在调度或者系统监控中调用 runtime.netpoll 轮询网络. 网络轮询器并不是由运行时中的某一个线程独立运行的，运行时中的调度和系统调用会通过 runtime.netpoll 与网络轮询器交换消息，获取待执行的 Goroutine 列表，并将待执行的 Goroutine 加入运行队列等待处理。 所有的文件 I/O、网络 I/O 和计时器都是由网络轮询器管理的，它是 Go 语言运行时重要的组成部分。 golang使用多路IO复用, 但没用select, 而是用的效率更高的epoll(在linux平台上), 见src/runtime/netpoll_epoll.go 不同平台使用的系统调用不同 参考: https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-netpoller/ golang对epoll的封装 golang要同时支持epoll, kqueue, windows上的接口, 它们都使用一组接口 //— 初始化网络轮询器，通过 sync.Once 和 netpollInited 变量保证函数只会调用一次； func netpollinit() //监听文件描述符上的边缘触发事件，创建事件并加入监听； func netpollopen(fd uintptr, pd *pollDesc) int32 //轮询网络并返回一组已经准备就绪的 Goroutine，传入的参数会决定它的行为； func netpoll(delta int64) gList //唤醒网络轮询器，例如：计时器向前修改时间时会通过该函数中断网络轮询器； func netpollBreak() // 判断文件描述符是否被轮询器使用； func netpollIsPollDescriptor(fd uintptr) bool 数据结构 type pollDesc struct { //描述符链表 link *pollDesc lock mutex fd uintptr ... rseq uintptr rg uintptr rt timer rd int64 wseq uintptr wg uintptr wt timer wd int64 } 初始化 因为文件 I/O、网络 I/O 以及计时器都依赖网络轮询器，所以 Go 语言会通过以下两条不同路径初始化网络轮询器： internal/poll.pollDesc.init — 通过 net.netFD.init 和 os.newFile 初始化网络 I/O 和文件 I/O 的轮询信息时； runtime.doaddtimer — 向处理器中增加新的计时器时； runtime.netpollinit()做了下面的几个事 调用 epollcreate1 创建一个新的 epoll 文件描述符，这个文件描述符会在整个程序的生命周期中使用； 通过 runtime.nonblockingPipe 创建一个用于通信的管道； 使用 epollctl 将用于读取数据的文件描述符打包成 epollevent 事件加入监听； goroutine等待事件 当我们在文件描述符上执行读写操作时，如果文件描述符不可读或者不可写，当前 Goroutine 就会执行 runtime.poll_runtime_pollWait 检查 runtime.pollDesc 的状态并调用 runtime.netpollblock 等待文件描述符的可读或者可写： func poll_runtime_pollWait(pd *pollDesc, mode int) int { ... for !netpollblock(pd, int32(mode), false) { ... } return 0 } //runtime.netpollblock 是 Goroutine 等待 I/O 事件的关键函数， //它会使用运行时提供的 runtime.gopark 让出当前线程，将 Goroutine 转换到休眠状态并等待运行时的唤醒。 func netpollblock(pd *pollDesc, mode int32, waitio bool) bool { gpp := &pd.rg if mode == 'w' { gpp = &pd.wg } ... if waitio || netpollcheckerr(pd, mode) == 0 { gopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5) } ... } 调用epoll 网络轮询器并不是由运行时中的某一个线程独立运行的，运行时中的调度和系统调用会通过 runtime.netpoll 与网络轮询器交换消息，获取待执行的 Goroutine 列表，并将待执行的 Goroutine 加入运行队列等待处理。 Go 语言的运行时会在调度或者系统监控中调用func netpoll(delay int64) gList轮询网络，该函数的执行过程可以分成以下几个部分： 根据传入的 delay 计算 epoll 系统调用需要等待的时间； 调用系统调用epollwait 等待可读或者可写事件的发生； 在循环中依次处理 epollevent 事件； 返回可读写的的goroutine列表, runtime会将列表中的全部 Goroutine 加入运行队列并等待调度器的调度 截至日期 网络轮询器和计时器的关系非常紧密，这不仅仅是因为网络轮询器负责计时器的唤醒，还因为文件和网络 I/O 的截止日期也由网络轮询器负责处理。截止日期在 I/O 操作中，尤其是网络调用中很关键，网络请求存在很高的不确定因素，我们需要设置一个截止日期保证程序的正常运行，这时就需要用到网络轮询器中的 runtime.poll_runtime_pollSetDeadline 函数 如果截至日期到了, 直接唤醒goroutine;Goroutine 在被唤醒之后就会意识到当前的 I/O 操作已经超时，可以根据需要选择重试请求或者中止调用。 GC 垃圾收集器 https://blog.golang.org/ismmkeynote go runtime调度器 相关的结构体表示 The G Struct : This represents a single go routine with it’s properties such as stack pointer, base of stack, it’s ID, it’s cache and it’s status The M Struct : This represents an OS thread. It also contains a pointer to the global queue of runnable goroutines, the current running goroutine and the reference to the scheduler The Sched Struct : It is a global struct and contains the queues free and waiting goroutines as well as threads. go比较快的5点 参考: https://dave.cheney.net/2014/06/07/five-things-that-make-go-fast go变量占的空间更小, 比如一个int, 和c一样, 占4个字节; 而python等动态语言要占24个字节 -- 他们把int当作一个object go编译器会做自动inline和死代码消除 C有stack变量, 也有malloc到堆上的变量; 而go有escape分析, 用来分析一个变量是否有函数外的引用, 没有的话, 分配在栈里; 此时就不需要GC 有的话, 分配在堆里, 需要GC.上面的代码, c分配在栈里, 因为它没有逃离CenterCursor()函数. goroutine, 更加轻量级的协作每个系统调用都会走这里, entersyscall通知runtime这个线程要阻塞了, runtime就把其他goroutine调度到新线程里去执行. 所以go程序会起几个系统线程, 然后go runtime来管理. goroutine的栈管理 普通进程的栈向下生长, 堆向上生长, 中间用guard page来隔离, guard page是只读的, 在之前调试时遇到过. 如果一个进程有多个线程, 那就有多个栈, 需要多个guard pagegoroutine不用guard page, 栈不够时自动分配go1.2的时候, 如果栈不够, 调用新的函数时, 会给新函数在堆里分配一个栈, 该函数返回就销毁这个栈. go1.3改了方法, 栈不够时, 分配一个新栈, 大小为2倍. 把之前所有的栈拷贝过来运行, 从此都用这个更大的新栈. 空间换时间. "},"notes/golang_杂记1.html":{"url":"notes/golang_杂记1.html","title":"杂记1","keywords":"","body":" 类型断言很慢吗? 结果 zlib压缩 gob编码 gob会缓存 结论 gob的编码规则 decode时使用指针方式避免interface的值拷贝 msg的值拷贝 优化成指针 interface也可以序列化, 但需要Register 输出 如果不Register会怎样? 顶层是interface{}的情况 能直接encode interface{} 使用interface的地址来encode Register()函数 非要Register()吗? 没有特列, append也是值拷贝 要用interface抽象行为, 就不要多一层struct马甲. interface{}变量可以直接和concrete类型的变量比较 Read不能保证全读 用io.ReadFull 没有io.WriteFull string强转 先return再defer, defer里面能看到return的值 包的初始化只执行一次 goroutine与channel 使用channel时一定要判断peer的goroutine是否还在1 问题场景 解决 使用channel时一定要判断peer的goroutine是否还在2 解决 写空的channel不会panic 简单的程序可以检测死锁 复杂的程序检测不出来, 直接卡住 patherror 永久阻塞 selectgo源码杂记 强转成切片指针 突破数组大小限制 切片截取 子切片共享底层数组 go test 测试对象方法 子项 性能测试 不推荐用self或者this指代receiver 范式 在链接阶段对全局变量赋值 使用场景 如何做到的? 链接选项 编译限制Build Constraints 使用-tags参数指定用户自定义constraints 无表达式的switch 无缓冲和缓冲为1的通道不一样 书 go内存模型 解决1: 用channel 解决2: 用sync sync的once 类型断言很慢吗? 答: 不慢, 甚至比直接函数调用还快... 黑科技 package main import ( \"testing\" ) type myint int64 type Inccer interface { inc() } func (i *myint) inc() { *i = *i + 1 } func BenchmarkIntmethod(b *testing.B) { i := new(myint) incnIntmethod(i, b.N) } func BenchmarkInterface(b *testing.B) { i := new(myint) incnInterface(i, b.N) } func BenchmarkTypeSwitch(b *testing.B) { i := new(myint) incnSwitch(i, b.N) } func BenchmarkTypeAssertion(b *testing.B) { i := new(myint) incnAssertion(i, b.N) } func incnIntmethod(i *myint, n int) { for k := 0; k 结果 yingjieb@3a9f377eee5d /repo/yingjieb/godev/practice/src/benchmarks/typeassertion $ go test -bench . goos: linux goarch: amd64 BenchmarkIntmethod-23 465990427 2.55 ns/op BenchmarkInterface-23 269690563 4.46 ns/op BenchmarkTypeSwitch-23 590743738 2.06 ns/op BenchmarkTypeAssertion-23 577222344 2.10 ns/op PASS ok _/repo/yingjieb/godev/practice/src/benchmarks/typeassertion 5.949s BenchmarkInterface: 通过interface直接调用最慢 BenchmarkIntmethod: 直接函数调用做为基准 BenchmarkTypeSwitch/BenchmarkTypeAssertion: 类型断言比直接函数调用还快!!!!! zlib压缩 zlib提供的压缩接口是io.Writer. 即z := zlib.NewWriter(s)是个io.Writer, 往里面写就是压缩写. 但要调用z.Close()接口做flush操作, close后数据才写入底层的io.Writer. 不想close的话, 调用Flush()接口也行. gob编码 json的编码体积偏大, 改用gob的性能和json差不多, 但体积能减小一半. gob专用于go程序之间的数据编码方法, 借鉴并改进了了很多GPB的设计, 应该说是go世界的首选序列化反序列化方法. gob会缓存 比如发送方连续两次发送 conn.enc.Encode(A) conn.enc.Encode(B) 在接收方看起来, 连续两次Decode, 能还原A和B的值 conn.enc.Decode(&A) conn.enc.Decode(&B) 如果两次Encode间隔很短, 比如连续的2次Encode, 在对端Decode的时候, 第一把decode A的时候, 可能已经缓存了部分B的字节, 第二把decode可以用这个缓存. 但如果A的后面是对原始io.Reader的直接操做, 比如: conn.enc.Decode(&A) io.Copy(os.Stdout, conn) 那么可能os.Stdout不会看到B, B缓存在第一把的Decode里面. 比如在发送方发送A和B之间加个sleep 1秒, 实验结果是对A的decode就不缓存. 结论 如果发送方encode间隔很短, gob会预取socket里面的紧跟着上次encode的内容, 那么: 接收方一直用gob去decode的话, 是没问题的. 但如果decode中途去直接操做io读, 是可能读不到数据的. gob的编码规则 以int为基础, size变长 第一次传输一个新的结构体的时候, 先传输这个结构体的定义, 即layout 后面传输的时候, 带结构体标识就可以了 即先描述这个东西长什么样子, 取个名字, 后面直接用名字指代. decode时使用指针方式避免interface的值拷贝 之前我的代码里定义了isMessageOut和messageIn两个接口 // messageOut represents a message to be sent type messageOut interface { isMessageOut() } // messageIn represents an incoming message, a handler is needed to process the message type messageIn interface { // reply(if not nil) is the data that will be sent back to the connection, // the message may be marshaled or compressed. // remember in golang assignment to interface is also value copy, // so return reply as &someStruct whenever possible in your handler implementation. handle() (reply messageOut, err error) } 我有个record类型的结构体要传输. 在接收端, 我定义了handle方法, 接收到messageIn类型的结构体就可以直接handle()了 type record struct { Timestamp int64 Payload recordPayload } func (rcd record) handle() (reply messageOut, err error) { fmt.Println(rcd) return nil, nil } func fakeServer() { ... var msg messageIn for { decoder.Decode(&msg) reply, err := msg.handle() } } 注意decoder.Decode(&msg), 要求msg必须是messageIn, decoder会自动分配concrete类型实例并赋值给msg. 如果对端发过来的消息concrete类型不是messageIn, Decode会返回错误, 类似这样: gob: local interface type *main.messageIn can only be decoded from remote interface type; received concrete type string 意思是对端发过来的是string类型, 我已经收好了; 但是你不是messageIn, 所以不符合用户要求. msg的值拷贝 上面的代码可以工作, 但有个性能问题. 注意到record的handle()接收record的值, 而不是指针. 所以第16行reply, err := msg.handle()时, 对msg发生了一次值拷贝. 在go里面, 值拷贝是浅拷贝, 一般性能开销不大. 因为浅拷贝遇到切片, 字符串, map等等\"引用\"属性的对象, 浅拷贝只拷贝\"指针\", 不拷贝内容. 但这里为了进一步避免浅拷贝, 需要想办法把record的实现改成下面:注意只多了个* func (rcd *record) handle() (reply messageOut, err error) { fmt.Println(rcd) return nil, nil } 编译没问题, 但运行时gob报错: gob: main.record is not assignable to type main.messageIn 熟悉interface的同学应该知道这里的意思其实是: decoder.Decode(&msg) decode出来的\"值\", 不是messageIn, 不能赋值给msg. 那decode出来的\"值\"是什么呢? 这就要提到gob要求interface的具体类型要注册, 我是这样注册的: //在初始化路径上调用一次 gob.Register(record{}) 那么decode出来的\"值\"就是record{}, 而record不是messageIn, *record才是 优化成指针 那么这样改就可以: 把*record注册给gob gob.Register(&record{}) interface也可以序列化, 但需要Register 比如下面的代码中, 要marshal的是record结构体. type record struct { Timestamp int64 // time.Now().Unix() Payload interface{} } 但它的Payload部分是个interface, 可以是 string []processInfo{}type processInfo struct { Pid int Ucpu string //%.2f Scpu string //%.2f Mem uint64 Name string } 一个是内置的字符串, 一个是自定义的结构体数组. 对record类型来说, 这两个类型都是叫Payload 前面说过, 每个新东西都要描述一番, 取个名字. 但对interface来说, 它有很多面孔. 一个描述是不够的. 所以gob规定, interface所指代的具体类型, 要先注册. 下面的Register()调用就注册了这个结构体数组 //把nil强转成目标类型的实例, 因为Register接收实例 //gob.Register([]processInfo{})也是可以的, 只要能得到实例 gob.Register([]processInfo(nil)) var tmp bytes.Buffer enc := gob.NewEncoder(&tmp) dec := gob.NewDecoder(&tmp) //模拟processInfo切片 err := enc.Encode(record{time.Now().Unix(), []processInfo{}}) fmt.Println(\"encoded:\", string(tmp.Bytes())) //模拟一个hello字符串 err := enc.Encode(record{time.Now().Unix(), \"hello\"}) fmt.Println(\"encoded:\", string(tmp.Bytes())) err = dec.Decode(&data) switch v := data.Payload.(type) { case []processInfo: fmt.Println(data.Timestamp, \"====processinfo \", v) case string: fmt.Println(data.Timestamp, \"====string \", v) } 输出 这里用string强转了bytes, 有些不能打印字符. $ ./topid -p 2 -snapshot //从这里可以看出来, 第一次描述了processInfo的layout encoded: .record TimestampPayload)[]main.processInfoD processInfoPidUcpu Scpu MemName .000.0kthreadd //能被decode还原 1590418131 ====processinfo [{2 0.00 0.00 0 kthreadd}] //Payload的string方式第一次出现 描述一下. 有些byte没打印, 但应该第一次的信息是全的. encoded: string hello 1590418131 ====string hello //后面的打印就不带layout信息了 encoded: ;[]main.processInfo.000.0kthreadd 1590418132 ====processinfo [{2 0.00 0.00 0 kthreadd}] encoded: ;[]main.processInfo.000.0kthreadd 1590418133 ====processinfo [{2 0.00 0.00 0 kthreadd}] ... //不知为何, 原始string还是每次有带. encoded: string hello 1590418161 ====string hello 如果不Register会怎样? 不管encode还是decode, 都会打印提示: gob: type not registered for interface: []main.processInfo 顶层是interface{}的情况 上面的例子中, bog可以编码结构体中间的field是interface{}的情况. 那么如果直接encode一个interface{}可以吗? 能decode吗? 先回答: 能; 能, 但需要技巧. 能直接encode interface{} encode的入参就是interface{}类型, 即任何类型都可以被encode. 一个interface{}变量在被赋值的时候, runtime知道它的concrete类型. 参考 神作: interface的运行时的lookup Go Data Structures: Interfaces gob会按照concreate类型传输. 所以这样的代码是可以被encode的. var msg interface{} // msg = anyvariable enc.Encode(msg) 但不能被decode. var msg interface{} dec.Decode(&msg) 报错误: gob: local interface type *interface {} can only be decoded from remote interface type; received concrete type sessionReq = struct { SessionTag string; SysInfo sysInfo = struct { BoardName string; CPUInfo string; KernelInfo string; PackageInfo packageInfo = struct { BuildVersion string; SwID string; BuildServer string; BuildDate string; Repo string; Branch string; }; }; } 这个错误说明两点: gob知道对方传输过来的结构体, 并且能精确解析 但gob不能把它decode给*interface {}, 即&msg; gob还提示, decode给interface必须对端也是interface类型. 使用interface的地址来encode gob支持interface的传输, 比如在再上面的record类型中的interface就可以被传输和decode. 但顶层的interface需要些技巧. 在encode的时候, 传入interface的地址就行. 这样: // encode var msg interface{} // msg = anyvariable enc.Encode(&msg) // decode var msg interface{} dec.Decode(&msg) 很对称, 挺好的. gob会对指针解引用, encode时&msg被赋值给内部interface{}时, gob发现这是个指针类型, 指向interface类型. 所以gob按照interface类型来传输 根据interface的传输规则, encode端和decode端都要提前注册具体类型到gob Register()函数 使用了Type的String方法获得类型的名称 func Register(value interface{}) { rt := reflect.TypeOf(value) name := rt.String() //处理指针的情况, 指针前面加* RegisterName(name, value) gob包默认注册了基础类型 func registerBasics() { Register(int(0)) Register(int8(0)) Register(int16(0)) Register(int32(0)) Register(int64(0)) Register(uint(0)) Register(uint8(0)) Register(uint16(0)) Register(uint32(0)) Register(uint64(0)) Register(float32(0)) Register(float64(0)) Register(complex64(0i)) Register(complex128(0i)) Register(uintptr(0)) Register(false) Register(\"\") Register([]byte(nil)) Register([]int(nil)) Register([]int8(nil)) Register([]int16(nil)) Register([]int32(nil)) Register([]int64(nil)) Register([]uint(nil)) Register([]uint8(nil)) Register([]uint16(nil)) Register([]uint32(nil)) Register([]uint64(nil)) Register([]float32(nil)) Register([]float64(nil)) Register([]complex64(nil)) Register([]complex128(nil)) Register([]uintptr(nil)) Register([]bool(nil)) Register([]string(nil)) } 非要Register()吗? 既然有实例就能注册, 为什么不在encode/decode时自动注册了, 非要搞一个Register()?答: 可能是因为用了反射比较慢的缘故. 注册一次就够了, 每次都\"注册\"反射开销大. 没有特列, append也是值拷贝 那问题是, 做为入参传入append的时候, 是否已经发生了一次值拷贝, 然后再拷贝到[]slice里面去? 要用interface抽象行为, 就不要多一层struct马甲. 少用通用的interface然后再在里面搞类型断言; 而是用具体的interface, 这样在编译阶段就能\"断言\"类型. 比如下面的第45行. package main import ( \"bytes\" \"encoding/json\" \"fmt\" //\"os\" \"bufio\" \"io\" ) type record interface { tag() string doPrint() } type teacher struct { Name string } type student struct { Id int Name string Class int Email string Message string } func (stdt *student) tag() string { return \"student\" } func (stdt *student) doPrint() { fmt.Println(\"do student\", stdt) } func (tc *teacher) tag() string { return \"teacher\" } func (tc *teacher) doPrint() { fmt.Println(\"do teacher\", tc) } func marshalRecord(w io.Writer, rcd record) error { jsn, err := json.Marshal(rcd) if err != nil { return err } w.Write([]byte(rcd.tag() + \": \")) w.Write(jsn) w.Write([]byte{'\\n'}) return nil } func main() { var b bytes.Buffer stdt := student{Id: 9527, Name: \"sam\", Class: 3, Email: \"sam@godev.com\", Message: \"hello\\n world\\n\"} err := marshalRecord(&b, &stdt) if err != nil { fmt.Println(err) } tc := teacher{Name: \"shuxue\"} err = marshalRecord(&b, &tc) if err != nil { fmt.Println(err) } //b.WriteTo(os.Stdout) r := bufio.NewReader(&b) for { line, err := r.ReadBytes('\\n') if err != nil { return } fmt.Printf(\"%s\", line) sep := bytes.Index(line, []byte{':'}) key := string(line[:sep]) value := line[sep+2:] fmt.Printf(\"key: %s\\n\", key) fmt.Printf(\"value: %s\\n\", value) var rcd record switch key { case \"student\": rcd = &student{} case \"teacher\": rcd = &teacher{} } err = json.Unmarshal(value, rcd) if err != nil { fmt.Println(err) return } rcd.doPrint() } } interface{}变量可以直接和concrete类型的变量比较 我实现了一个map, 提供set和get函数. get出来的value是个万能interface{}, func (im *intMap) set(k int, v interface{}) { _, has := im.mp[k] if !has { im.ks = append(im.ks, k) } im.mp[k] = v } func (im *intMap) get(k int) interface{} { v, has := im.mp[k] if has { return v } return nil } func main() { im := newIntMap(10) im.set(1, \"1234\") # v的类型是interface v := im.get(1) show(v) //interface变量可以直接和具体类型的值比较 if v == \"1234\" { fmt.Println(\"interface{} can be compared directly with string\") } im.set(2, &[]int{1, 2, 3}) v = im.get(2) //这里可以比较, 但地址是不一样的 if v == &[]int{1, 2, 3} { fmt.Println(\"should not be\") } show(v) im.set(3, struct{ a, b, c int }{1, 2, 3}) v = im.get(3) //结构体也可以比较, 但前提是结构体里面的元素都可以比较 if v == struct{ a, b, c int }{1, 2, 3} { fmt.Println(\"interface{} can be compared directly with comparable struct\") } show(v) im.set(4, 155) v = im.get(4) show(v) //可以直接和整型比较 if v == 155 { fmt.Println(\"interface{} can be compared directly with int\") } v = im.get(100) // 100不存在, v是nil // nil可以比较, 不会panic; 只是从来不一致. if v == 10086 { fmt.Println(\"nil interface{} can be compared, but never succeed\") } show(v) //切片不能比较 /* if v == []int{5,6,7} { fmt.Println(\"error! operator == not defined on slice\") } */ } //结果: string:(\"1234\") interface{} can be compared directly with string *[]int:([]int{1, 2, 3})@[0xc0000ac040] interface{} can be compared directly with comparable struct struct { a int; b int; c int }:(struct { a int; b int; c int }{a:1, b:2, c:3}) int:(155) interface{} can be compared directly with int :() Read不能保证全读 golang的Reader不保证能read完整的len(buf), 即使没有到EOF, Read也不保证完整的Read. 所以Read会返回已经读的字节数n type Reader interface { Read(p []byte) (n int, err error) } 在C里面, 系统调用read()可能被信号打断而提前返回, 俗称短读. 一般的做法是自己写个包装, 用while一直读, 直到读完为止. 用io.ReadFull 在go里, io包已经提供了这个包装, 就是 func ReadFull(r Reader, buf []byte) (n int, err error) ReadFull保证填满buf, 除非EOF时buf还没填满, 此时返回ErrUnexpectedEOF ReadFull实际上是调用ReadAtLeast func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error) { if len(buf) = min { err = nil } else if n > 0 && err == EOF { err = ErrUnexpectedEOF } return } ReadAtLeast()用一个循环反复Read() 没有io.WriteFull 标准库里面有ReadFull, 但没有WriteFull. 为什么呢? 有人还真实现了WriteFull, 有必要吗? 没必要: 因为read的语义允许short read而不返回error; 但write的语义是要写就都写完, 除非有错误. I would really rather not. ReadFull exists because Read is allowed to return less than was asked without an error. Write is not. I don't want to encourage people to think that buggy Writers are okay by introducing a buggy Writer fixer. string强转 结论: byte强转成string, 会去掉其中的0 buf := make([]byte, 32) buf = append(buf, '1', 0, '2') fmt.Println(buf) fmt.Println(string(buf)) //结果: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 49 0 50] 12 说明byte切片转成string, 每个byte都被扫描, 去掉其中的0. 也说明go里面的类型转换, 是有不小开销的. 先return再defer, defer里面能看到return的值 func checkHierarchy(p int) (err error) { //defer里面可以直接使用returned变量 defer func() { if err != nil { fmt.Println(err) } else { fmt.Println(\"no err returned\") } }() //对返回变量直接赋值是可以的 err = errors.New(\"default err\") if p == 1 { return nil } else if p == 2 || p == 3{ //相当于对err赋值. return fmt.Errorf(\"return: %d\", p) } //空的return会默认返回有名的return变量, 即上面的err return } func main() { checkHierarchy(1) checkHierarchy(2) checkHierarchy(3) checkHierarchy(4) } //输出 no err returned return: 2 return: 3 default err defer里面可以直接使用return变量 空的return会默认返回有名的return变量 程序里可以提前对有名的return变量赋值, 然后用空return返回该值. 带值的return实际上会给有名的return变量赋值, defer的时候看到的是return的指定值. defer在return之后执行 -- 先执行return那一行. 下面的代码会返回\"Change World\"而不是\"Hello World\" func foo() (result string) { defer func() { result = \"Change World\" // change value at the very last moment }() return \"Hello World\" } 包的初始化只执行一次 Package initialization is done only once even if package is imported many times. goroutine与channel goroutine的生命周期和channel要配合, routine的产生与消亡要考虑对channel的影响 使用channel时一定要判断peer的goroutine是否还在1 这个例子中,newPidInfo()函数中, 起了goroutine pi.checkThreads() func newPidInfo(pid int, ppi *PidInfo) (*PidInfo, error) { pi.hierarchyDone = make(chan int) go func() { pi.err = pi.checkThreads() }() pi.triggerAndWaitHierarchy() } func (pi *PidInfo) checkThreads() error { defer func() { pi.hierarchyDone pi.checkThreads()虽然做了异常分支的channel处理, 比如defer那句. 但这里还是出了channel问题. 问题场景 某次进程A要更新hierarchy, A发hierarchyCheck A的checkThreads守护routine收到hierarchyCheck信号, 开始doWork() A的doWork()里, 触发子进程B的hierarchyCheck 子进程B的checkThreads守护routine开始doWork() B的doWork()出错, B的hierarchyDone从异常分支写1, 通知A的doWork()往下走. 对应代码第20行 OK. 到这里还是正常的 下次A要更新hierarchy, A发hierarchyCheck A的checkThreads守护routine收到hierarchyCheck信号, 开始doWork() A的doWork()里, 不知什么原因, A还是认为自己有子进程B. 触发子进程B的hierarchyCheck 子进程B已经没有checkThreads守护routine A永远阻塞在第42行 本质上, 出现问题的原因是: 子进程B的goroutine的异常分支已经完善, 但goroutine异常退出后, 业务逻辑不应该再去用channel和子进程B交互. 即永远判断要交互的goroutine是否存在. 解决 triggerAndWaitHierarchy()加异常判断 func (pi *PidInfo) triggerAndWaitHierarchy() { //for some reason there is no checkThreads routine, thus nowhere we can send to and receive from //this can happen if the children file has the child, but actually the child is dying if pi.err != nil { //fmt.Println(pi.err) return } //trigger once, none blocking pi.hierarchyCheck 使用channel时一定要判断peer的goroutine是否还在2 比如下面的代码, 倒数第二行在写channel的时候, 对应的checkChild协程不一定能到达37行select. 实际上, 只有一个case的select可以只保留channel读部分. for _, tid := range pi.threadIds { tid := tid if pi.childCheckers[tid] == nil { s := childChecker{make(chan int), make(chan []int, 1)} checkChild := func() { f, err := os.Open(\"/proc/\" + pi.pidstr + \"/task/\" + strconv.Itoa(tid) + \"/children\") if err != nil { return } defer f.Close() doWork := func() []int { if _, err := f.Seek(0, 0); err != nil { return nil } buf, err := ioutil.ReadAll(f) if err != nil { return nil } //ToDo: return nil if buf is empty strs := strings.Fields(string(buf)) childrenIds := make([]int, len(strs)) for i := 0; i 实际上, 这里还有一个错误. 在后面的处理里, 下面代码倒数第二行, 会阻塞的从childCheckers[tid].children读出数据, 但如果上面的goroutine异常退出了, //use new refilled map pi.childCheckers = childCheckers //with initial capacity of the previous run pi.childrenIds = make([]int, 0, len(pi.childrenIds)) for _, tid := range pi.threadIds { //concatenate the children slices retrieved from channel to a single one pi.childrenIds = append(pi.childrenIds, 解决 在goroutine刚开始, 加defer函数, 默认退出时读/写channel 这里用的非阻塞读写. checkChild := func() { defer func() { select { case 写空的channel不会panic 简单的程序可以检测死锁 func main() { var c chan int c 复杂的程序检测不出来, 直接卡住 //pi.hierarchyDone是个空的channel for { select { case patherror // requires go1.13 and later func pathError(err error) bool { var perr *os.PathError if errors.As(err, &perr) { return true } return false } 永久阻塞 空的select永远等待 select {} selectgo源码杂记 selectgo()函数是select语句的runtime实现, 由编译器在编译时把select语句块转换为runtime的selectgo()的调用. 强转成切片指针 下面的代码是把一个指针, 强转成指向数组的指针; go里面强转不是万能的, 指针必须转成指针 cas1 := (*[1 和下面的效果类似 func main() { s := []int{1,2,3,4,5,6,7} sp := &s fmt.Println(sp) sp3 := (*[3]int)(unsafe.Pointer(&s[0])) fmt.Println(sp3) } //结果 &[1 2 3 4 5 6 7] &[1 2 3] 突破数组大小限制 func main() { s := [7]int{1,2,3,4,5,6,7} //数组的指针可以当数组用 sp := &s //如果s是切片, 则下面语句报错:(type *[]int does not support indexing) sp[1] = 999 fmt.Println(sp) //强转成指向数组的指针可以突破数组的length限制 //但要注意, 你明确知道在干什么. 否则, segment fault snp := (*[20]int)(unsafe.Pointer(&s[0])) snp[15] = 995 fmt.Println(snp) } 切片截取 比如slice是个切片, 那么slice[ i : j : k ]是截取slice并限制capacity的切片: Length: j - i Capacity: k - i 第三个参数的用法不常见, 但加了可以限制新切片的capacity的能力, 好处是防止越过capacity访问. 下面的代码取自selectgo, 就使用了第二个冒号, scases := cas1[:ncases:ncases] pollorder := order1[:ncases:ncases] lockorder := order1[ncases:][:ncases:ncases] 子切片共享底层数组 子切片的capacity和其主切片的capacity有关, 因为他们都共享底层的数组. 比如下面的例子证明了, 子切片的修改会影响到母切片. func main() { s := []int{1,2,3,4,5,6,7} s1 := s[0:3] fmt.Println(s) fmt.Println(s1) //修改切片s1会影响原切片s s1[1] = 999 fmt.Println(s) fmt.Println(s1) //非法访问, slice越界 //panic: runtime error: index out of range [5] with length 3 s1[5] = 888 } 结果: [1 2 3 4 5 6 7] [1 2 3] [1 999 3 4 5 6 7] [1 999 3] go test 测试对象方法 用Test对象名_方法名. 比如tengo代码中的 func TestScript_Run(t *testing.T) { s := tengo.NewScript([]byte(`a := b`)) err := s.Add(\"b\", 5) require.NoError(t, err) c, err := s.Run() require.NoError(t, err) require.NotNil(t, c) compiledGet(t, c, \"a\", int64(5)) } 子项 Test 函数可以调用t.Run func TestFoo(t *testing.T) { // t.Run(\"A=1\", func(t *testing.T) { ... }) t.Run(\"A=2\", func(t *testing.T) { ... }) t.Run(\"B=1\", func(t *testing.T) { ... }) // } go test可以指定子项: go test -run Foo # Run top-level tests matching \"Foo\", such as \"TestFooBar\" go test -run Foo/A= # For top-level tests matching \"Foo\", run subtests matching \"A=\" go test -run /A=1 # For all top-level tests, run subtests matching \"A=1\" 性能测试 用go test -bench func BenchmarkHello(b *testing.B) { big := NewBig() //开始循环测试之前先reset时间 b.ResetTimer() for i := 0; i 用b.RunParallel()来并发执行, 和-cpu 1,2,4配合, 可以测一个核, 两个核, 四个核的并发性能 go help testflag查看详细的选项 不推荐用self或者this指代receiver https://stackoverflow.com/questions/23482068/in-go-is-naming-the-receiver-variable-self-misleading-or-good-practice receiver有两个作用, 第一, 声明了类型和方法的绑定关系. 第二, 在运行时给方法额外传了这个类型的参数. 对v.Method()的调用时编译器的语法糖, 本质上是(T).Method(v). 参考这里 C++和Python的方法基于具体对象, 所以this和self隐含代指这个具体对象的内存地址, 和方法是紧耦合关系. 而go的方法基于类型, 和具体对象是松耦合关系, 具体的对象只是做为额外的参数传给方法. 以下代码可以运行, 没有错误 package main import \"fmt\" type T struct{} func (t T) Method(msg string) { fmt.Println(msg) } func main() { t := T{} t.Method(\"hello\") // this is valid //使用类型调用方法, 第一个参数是实例 (T).Method(t, \"world\") // this too } 范式 所以实例只是其中的一个参数, 要给个合适的名字, go惯例使用类型的第一个字母小写, 或者更贴切的名字. type MyStruct struct { Name string } //这个更符合go的范式 func (m *MyStruct) MyMethod() error { // do something useful } //self的语义并不贴切 func (self *MyStruct) MyMethod() error { // do something useful } 在链接阶段对全局变量赋值 使用场景 在vonu里面, 编译的时候传入了git commit id和编译时间; 在go build的时候用-ldflags传入 LDFLAGS=-ldflags '-X env.VOnuRevCommitId=$(VONUMGMT_REV_COMMIT_ID) -X \"env.VOnuBuildDate=$(VONUMGMT_BUILD_DATE)\"' go build $(LDFLAGS) -tags static $(APP_MAIN) 这个env.VOnuRevCommitId是env包里的一个全局变量 //定义的时候是nil var VOnuRevCommitId string //直接使用 func VOnuRevCommitIdInfo() string { return VOnuRevCommitId } 如何做到的? go build可以传入的选项有: -a 强制全部重编 -work 不删除临时目录 -race 打开竞争检查 -buildmode 比如共享库方式的选择 -compiler 选gccgo或者gc -gccgoflags -gcflags -ldflags arguments to pass on each go tool link invocation 这是本节的重点 -linkshared 链接共享库 -tags 自定义build constraints -trimpath 不保存绝对路径, 这个功能很好! 链接选项 其中-ldflags里面说到go tool link, 那就要看它的help go tool link -h //go tool link控制很底层的链接行为, 比如链接地址, 共享库路径 -T address 代码段起始地址 -X importpath.name=value 这就是本节用到的点, 定义package.name的变量未value, value是字符串 链接的时候\"初始化\"这个变量 -cpuprofile 写profiling信息到文件 -dumpdep -linkmode -buildmode // 对减小size有好处 -s disable symbol table -w disable DWARF generation 所以这里用了-X选项, 在链接的时候\"初始化\"变量值. 编译限制Build Constraints 详细说明: go doc build 编译限制用来指明一个文件是否要参与编译, 形式上要在文件开始的时候, \"注释\"编译限制, 比如: 只在linux并且使用cgo, 或者OS x并且使用cgo情况下编译该文件 // +build linux,cgo darwin,cgo 只在ignore情况下编译, 即不参与编译. 因为没有东西会匹配ignore. 用其他怪异的tag也行, 但ignore的意思更贴切 // +build ignore 这个注释必须在package语句之前 内置的tag有: During a particular build, the following words are satisfied: - the target operating system, as spelled by runtime.GOOS - the target architecture, as spelled by runtime.GOARCH - the compiler being used, either \"gc\" or \"gccgo\" - \"cgo\", if ctxt.CgoEnabled is true - \"go1.1\", from Go version 1.1 onward - \"go1.2\", from Go version 1.2 onward - \"go1.3\", from Go version 1.3 onward - \"go1.4\", from Go version 1.4 onward - \"go1.5\", from Go version 1.5 onward - \"go1.6\", from Go version 1.6 onward - \"go1.7\", from Go version 1.7 onward - \"go1.8\", from Go version 1.8 onward - \"go1.9\", from Go version 1.9 onward - \"go1.10\", from Go version 1.10 onward - \"go1.11\", from Go version 1.11 onward - \"go1.12\", from Go version 1.12 onward - \"go1.13\", from Go version 1.13 onward - \"go1.14\", from Go version 1.14 onward - any additional words listed in ctxt.BuildTags 另外, 如果文件名有如下形式, 则会被go build认为是隐含了对应tag的build constraint *_GOOS *_GOARCH *_GOOS_GOARCH 使用-tags参数指定用户自定义constraints 比如在kafka.go最开始添加: // +build !device 这里的device就是自定义的tag, 这里的意思是不带device的tag时, kafka.go才参与编译. 或者说有device的tag, kafka.go不编. 下面是测试结果: 带了device tag, $ RUNMODE=cloud go test -tags device --- FAIL: TestMsgCall (0.00s) msgchan_test.go:20: No message channel for kafka FAIL exit status 1 FAIL msgchan 0.002s 无表达式的switch switch 中的表达式是可选的，可以省略。如果省略表达式，则相当于 switch true，这种情况下会将每一个 case 的表达式的求值结果与 true 做比较，如果相等，则执行相应的代码。 func main() { num := 75 switch { // expression is omitted case num >= 0 && num = 51 && num = 101: fmt.Println(\"num is greater than 100\") } } 无缓冲和缓冲为1的通道不一样 无缓冲的通道，写会阻塞，直到有人读。 缓冲为1的通道，写第一个不会阻塞，而写第二个会。 书 https://www.cntofu.com/book/73/readme.html go内存模型 简单来说, 是和C语系一样: 可以编译时乱序, 执行时乱序(CPU特性) 那么, 下面的写法是不对的: 不能保证done在a的赋值之后执行. var a string var done bool func setup() { a = \"hello, world\" done = true } func main() { go setup() for !done { } print(a) } 下面的例子更有隐蔽性: 即使在main看来, g不是nil了, 也不能保证g.msg有值. type T struct { msg string } var g *T func setup() { t := new(T) t.msg = \"hello, world\" g = t } func main() { go setup() for g == nil { } print(g.msg) } 解决1: 用channel var c = make(chan int, 10) var a string func f() { a = \"hello, world\" c 解决2: 用sync var l sync.Mutex var a string func f() { a = \"hello, world\" l.Unlock() } func main() { l.Lock() go f() l.Lock() print(a) } sync的once once 保证之执行一次. var a string var once sync.Once func setup() { a = \"hello, world\" } func doprint() { once.Do(setup) print(a) } func twoprint() { go doprint() go doprint() } "},"notes/golang_杂记2.html":{"url":"notes/golang_杂记2.html","title":"杂记2","keywords":"","body":" 使用reflect的MethodByName调用方法 gob decode零值不赋值 现象 原始数据 代码逻辑 问题现象 解释 验证 结论 setuid 调用小写函数 使用了nohup命令启动gshelld, 还是收到signal退出 SIGHUP Types of signals ¶ 推测 解决 gshell的内存使用 recover不能捕获SIGSEGV类型的panic sigint会发给所有前台进程组 写已经closed的conn 场景 答案 结论 读写nil channel会永远阻塞 流式接口和go 流式函数链的go执行顺序 解读 运行结果和结论 go get和go mod go get go list go mod tidy 总结 go clean 清理编译cache 又犯了经典的goroutine引用闭包变量错误!!!!! 原因 解决 理论解释 总结 if else if 共享一个变量scope 经典的append地址错误 打印指针slice 解决: 给结构体加String方法 关于wait group 反例 从栈上获取变量地址 参考代码 运行时获取函数名 方法1 方法2 continue能返回N层for interface的理解 interface{}是青出于蓝 interface{}是带上下文的方法集合 runtime.Caller获取当前运行目录 An interface holding nil value is not nil net/http导致包变大 现象 解决 原因 结论 Options初始化 总结 空白import不会增加binary size reflect高阶用法 动态构建一个struct byName API -- 神奇的重名API reflect.Value的MethodByName方法 reflect.Type的MethodByName方法 go调用外部程序 text/template代码生成举例 map的重要属性 unaddressable 方法1 整体给map赋值 方法2 让value的类型为指针 结论 go的树状表达 存储data 改进存储 如果用key来存储data会怎样? golang的SIGABRT 关于syscall 标准syscall库的问题 解决 更好的syscall库 使用 ioctl c的ioctl接口 cmd argp go的ioctl接口 ioctl的宏定义在哪里? asm files mmap mmap返回的byte切片是哪里来的? fnctl RWLock死锁 float强转为int go generate go generate常使用的一些工具 godoc安装 godoc使用 package通配符和导入路径 package通配符... 导入路径 obj.function()中obj可以是nil 如何处理? 切片的reslicing 再议目录结构 具体error判断 函数赋值给变量 gob encode和网络io的结合 单步decoder.Decode(&msg) protobuf里面oneof转成go结构体 proto定义 转成的结构体 使用reflect的MethodByName调用方法 下面的代码在Handle()这个方法里面, 调用了同对象的DoHandle()方法. // Handle handles SessionRequest. func (msg *SessionRequest) Handle(stream as.ContextStream) (reply interface{}) { // ONLY use reflect when clients do not have full server functions built-in(aka lite build) handle := reflect.ValueOf(msg).MethodByName(\"DoHandle\") if handle.IsValid() && !handle.IsZero() { ret := handle.Call([]reflect.Value{reflect.ValueOf(stream)})[0] if !ret.IsValid() { return nil } return ret.Interface() } return nil } 被调用的方法必须大写开头. \"DoHandle\"可以, 但是如果这个函数是\"handle\", 就不行 返回值要先检查是否valid, 再检查是否是zero 使用Call()方法调用函数, 传参要自己知道该传什么, 返回值也要知道. 参数和返回值都是reflect.Value类型. gob decode零值不赋值 现象 我有一些cpu使用率的统计数据, 使用gob编码保存在文件中. 但decode出来的数据, 和原始数据不一样. 最典型的特征是, 似乎原值为0的时候, decode出来的数据的值可能\"很随机\" 原始数据 原始数据是如下结构体的切片 type procStat struct { Pid int Name string Ucpu float64 Scpu float64 Mem uint64 } type record struct { Time int64 Procs []procStat } 代码逻辑 在一个routine里, 随机生成record数据, 不断的写入文件; 在另一个routine里, 读这个文件decode. func main() { rand.Seed(time.Now().Unix()) flt := 0.01 fmt.Println(flt) fmt.Printf(\"%x\\n\", *(*uint64)(unsafe.Pointer(&flt))) file := \"gob.data\" records := make(map[int64][]procStat, 1000) go func() { f, _ := os.Create(file) defer f.Close() enc := gob.NewEncoder(f) for i := 0; i 小知识: float在内存中和整形的存储方式很不一样, 比如0.01在内存中是3f847ae147ae147b 问题现象 运行这段程序, 会走到reflect.DeepEqual为假的分支, 说明encode的数据和decode的数据不一样. 但还是很有规律的: $ go run gob.go 0.01 3f847ae147ae147b 2021-10-13 02:44:30 +0000 UTC 2021-10-13 02:44:32 +0000 UTC 2021-10-13 02:44:34 +0000 UTC 2021-10-13 02:44:36 +0000 UTC 2021-10-13 02:44:38 +0000 UTC enc done ---- {1634093070 [{34730 worker 0 0.86 11985} {63668 worker 0.65 0 11985} {54333 worker 0.93 0 11985} {45231 worker 0 0.76 11985} {19332 worker 0.82 0 11985} {51576 worker 0.59 0 11985} {16966 worker 0 0 11985} {17849 worker 0.84 0 11985} {18887 worker 0 0 11985} {36216 worker 0 0.87 11985}]} ---- {1634093072 [{45159 worker 0.79 0.86 11985} {22705 worker 0.94 0 11985} {15938 worker 0. 93 0 11985} {45296 worker 0.71 0.63 11985} {8740 worker 0.82 0.93 11985} {36634 worker 0.94 0 .76 11985} {26329 worker 0 0.99 11985} {1891 worker 0.94 0 11985} {33214 worker 0.7 0 11985} {33629 worker 0.75 0.64 11985}]} 2021-10-13 02:44:32 +0000 UTC Should: [{45159 worker 0.79 0 11985} {22705 worker 0.94 0 11985} {15938 worker 0 0 11985} {45296 wor ker 0.71 0.63 11985} {8740 worker 0 0.93 11985} {36634 worker 0.94 0.76 11985} {26329 worker 0 0.99 11985} {1891 worker 0.94 0 11985} {33214 worker 0.7 0 11985} {33629 worker 0.75 0.64 1 1985}] Got: [{45159 worker 0.79 0.86 11985} {22705 worker 0.94 0 11985} {15938 worker 0.93 0 11985} {452 96 worker 0.71 0.63 11985} {8740 worker 0.82 0.93 11985} {36634 worker 0.94 0.76 11985} {2632 9 worker 0 0.99 11985} {1891 worker 0.94 0 11985} {33214 worker 0.7 0 11985} {33629 worker 0. 75 0.64 11985}] ---- {1634093074 [{1940 worker 0.87 0.62 11985} {59400 worker 0.94 0.57 11985} {10964 worker 0.93 0 11985} {40707 worker 0.67 0.91 11985} {51810 worker 0.74 0.84 11985} {26919 worker 0.5 5 0.53 11985} {62442 worker 0 0.99 11985} {25 worker 0.97 0.78 11985} {4644 worker 0.79 0 119 85} {39752 worker 0.75 0.64 11985}]} 规律: 第一次时间戳时, enc和dec的数据是一致的, 此时还没有错误. 从第二次时间戳开始, dec的数据就开始发生\"跳变\", 表现是结构体中float64类型的两个field(Ucpu和Scpu), 应该是0值的地方, 不是零值, 比如:Should: [{45159 worker 0.79 0 11985} {22705 worker 0.94 0 11985} ... ] Got: [{45159 worker 0.79 0.86 11985} {22705 worker 0.94 0 11985} ...] 上面第一个procStat结构体的Scpu, 应该是0, 却变成了0.86 0.86似乎并不是\"随机\"的值, 经过发现, 正好是上一次recorde的同位置的值. 解释 在结论之前, 先排除几点: 和同时读写文件没有关系. 开始我们怀疑是文件写的同时, 又去文件读, 是否文件的内核态buffer没有\"及时\"写进去, 造成读文件的时候\"部分\"读, 造成数据异常. 但其实不是, 开始的时候我们让写的routine一直写, 后面改成写完close, 然后再读; 问题依旧 和float64的编解码有关吗? 似乎有关, 但如果编解码出错, 应该是全部float64的编解码都有问题. 但这里的现象是\"个别\"数据\"跳变\" 结合以上两点, 特别是第二点, 数据跳变似乎是跳变成了以前出现过的值. 那么这个0.86是哪里来的呢? 正好是上一次record的同位置的值: {34730 worker 0 0.86 11985} 那么现在现象比较明确了: 零值可能跳变 跳变的值是上一次同位置的值. 第49行, 在for之前定义了var rcd record, for里面的dec.Decode(&rcd)都是一直往这个地址decode. 第一次rcd全部是零值的时候, decode没问题; 但第二次rcd已经有了第一次的值了, 又如果gob在decode时候遇到零值, 比如下面Ucpu和Scpu是0, gob并不会给rcd的对应field赋值, 导致rcd的这部分值还是零值. type procStat struct { Pid int Name string Ucpu float64 Scpu float64 Mem uint64 } 验证 把49行换成51行, 即在for内部定义rcd, 结果就ok了. 我猜想是因为dec.Decode(&rcd)因为入参是interface{}, 导致rcd逃逸到堆. 因为是for内部定义的, 每次运行到var rcd record, 都会在堆里新分配rcd, 这样就不受前值影响. 把float64改成int, 按照上面的理论, 0值也会\"跳变\" type procStat struct { Pid int Name string Ucpu int Scpu int Mem uint64 } 经过验证, 确实零值也会跳变. 说明和float64编码没有关系. 结论 dec.Decode(&rcd)gob遇到零值, 不会给rcd相应的field赋值 所以, 需要每一次在使用rcd之前, 都要保证它为零值 要么在for里面定义rcd, 还要观察rcd是否真的逃逸到堆 要么手动给rcd赋值为0 所以, 在go里面, 涉及到解码, 或者对变量指针操做, 要特别注意一个变量在内存里的表达: 这个变量是同一个内存地址时, 通常都有bug 补充: 冒号定义变量var v := ...和new变量都不能保证分配新的变量地址 补充, 改成json编解码不会有这个问题, 估计json在遇到零值依然有赋值动作. setuid https://dustinspecker.com/posts/setuid-elevating-privileges/ 一个文件可以有setuid属性: Setuid, which stands for set user ID on execution, is a special type of file permission in Unix and Unix-like operating systems such as Linux and BSD. It is a security tool that permits users to run certain programs with escalated privileges. When an executable file's setuid permission is set, users may execute that program with a level of access that matches the user who owns the file. For instance, when a user wants to change their password, they run the passwd command. The passwd program is owned by the root account and marked as setuid, so the user is temporarily granted root access for that limited purpose. 命令: chmod u+s myfile chmod u+x myfile chmod g+s myfile2 一般都是谁执行myfile, 这个进程算谁的. 但如果由setuid属性的文件, 执行算这个文件的owner的. 比如这个文件的owner是root, 那普通用户执行这个带s属性的文件, 也有root权限. 调用小写函数 一般的, package的小写函数是没法直接调用的, 但有个办法可以绕过这个限制. 用go:linkname 比如标准库里 package reflect //go:linkname call runtime.reflectcall func call(argtype *rtype, fn, arg unsafe.Pointer, n uint32, retoffset uint32) reflect的call被link成了runtime.reflectcall, 也就是说, 调用reflect.call就是调用小写的runtime.reflectcall. 使用了nohup命令启动gshelld, 还是收到signal退出 nohup bin/gshell -wd rootregistry -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 -root -repo gitlabe1.ext.net.nokia.com/godevsig/grepo/master & 但gshell还是会退出 [2021/09/09 12:23:16.705595][daemon][WARN](adaptiveservice.go:215) signal: hangup [2021/09/09 12:23:16.705762][daemon][INFO](server.go:350) server closing [2021/09/09 12:23:16.705827][daemon][DEBUG](scalamsgq.go:49) msgq closed SIGHUP Types of signals ¶ The signals SIGKILL and SIGSTOP may not be caught by a program, and therefore cannot be affected by this package. Synchronous signals are signals triggered by errors in program execution: SIGBUS, SIGFPE, and SIGSEGV. These are only considered synchronous when caused by program execution, not when sent using os.Process.Kill or the kill program or some similar mechanism. In general, except as discussed below, Go programs will convert a synchronous signal into a run-time panic. The remaining signals are asynchronous signals. They are not triggered by program errors, but are instead sent from the kernel or from some other program. Of the asynchronous signals, the SIGHUP signal is sent when a program loses its controlling terminal. The SIGINT signal is sent when the user at the controlling terminal presses the interrupt character, which by default is ^C (Control-C). The SIGQUIT signal is sent when the user at the controlling terminal presses the quit character, which by default is ^\\ (Control-Backslash). In general you can cause a program to simply exit by pressing ^C, and you can cause it to exit with a stack dump by pressing ^. 注意上面的解释, 当主控制台丢失的时候, 会发SIGHUP给程序. SIGHUP的默认行为是程序退出: man 7 signal 搜索SIGHUP 推测 nohup命令ignore了SIGHUP, 从而其子进程也默认继承了这个irgnore的行为. 而gshell代码里, 显式捕捉了syscall.SIGHUP: func initSigCleaner(lg Logger) { sigOnce.Do(func() { // handle signal sigChan := make(chan os.Signal, 1) signal.Notify(sigChan, syscall.SIGINT, syscall.SIGHUP, syscall.SIGTERM) go func() { sig := 所以明明应该ignore的SIGHUP, 又发挥了作用... 解决 应该去掉这个syscall.SIGHUP的捕捉就好了, 还是用nohup启动. 更好的办法, 是用Ignore API: signal.Ignore(syscall.SIGHUP) gshell的内存使用 用到的可执行文件是bin/gshell, 命令: cat /proc/29961/smaps readelf -a 注: 内存\\场景 单daemon KB daemon + master gre .text RSS 2388 2388 + 2516 .text PSS 2388 1194 + 1322 .rodata RSS 2024 2088 + 2152 .rodata PSS 2024 1044 + 1108 .go.buildinfo RSS 144 144 + 144 .go.buildinfo PSS 144 96 + 96 .bss RSS 84 84 + 72 .bss PSS 84 84 + 72 栈? RSS 2244 2352 + 2772 栈? PSS 2244 2352 + 2772 堆? RSS 1504 1576 + 320 堆? PSS 1504 1576 + 320 n个routine栈 RSS 0/4 0/4 + 0/4 n个routine栈 PSS 0/4 0/4 + 0/4 系统栈1? RSS 68 68 + 68 系统栈1? PSS 68 68 + 68 系统栈2? RSS 12 12 + 12 系统栈2? PSS 12 12 + 12 vdso RSS 4 4 + 4 vdso PSS 0 0 + 0 结论: 同一个go的binary, 多次单独启动的情况下: 代码段.text是共享的 只读数据段.rodata是共享的 vdso等kernel so是共享的 其他好像都不共享 recover不能捕获SIGSEGV类型的panic 比如下面的代码: func() { defer func() { if err := recover(); err != nil { lg.Errorf(\"broken stream chan: %v\", err) } }() streamChan := *(*chan *streamTransportMsg)(unsafe.Pointer(uintptr(tm.dstChan))) // swap src and dst streamChan defer的函数中, recover并不能捕获下面的panic: fatal error: unexpected signal during runtime execution [signal SIGSEGV: segmentation violation code=0x80 addr=0x0 pc=0x40bbee] ... sigint会发给所有前台进程组 gshell daemon起了子进程gre-master, 在前台ctrl+c daemon, gre-master也会收到sigint, 两个进程都会消失. 但如果daemon进程自己panic挂掉, gre-master还会继续运行. 值得注意的是, 如果用kill命令指定向daemon进程发送signit, 那就指定pid才会收到信号, 也不会导致gre-master挂掉. 见system 原理杂记 写已经closed的conn 场景 机器A的进程a和机器B的进程b建立了TCP的conn a一直读, b一直写. a被杀掉, b会怎么样? 会写失败吗? 写会一直阻塞吗? 答案 b会写失败, error信息为: writev tcp 172.17.0.1:40757->172.17.0.4:34458: use of closed network connection 结论 不管是socket读, 还是socket写, 都能感知到connection已经关闭. 但前提是机器A不是突然断电. 在机器A还在但进程a被杀掉的情况下, A的kernel会关闭和B的连接, B的kernel和进程b都是知道对方(也就是A)连接中断了. 读写nil channel会永远阻塞 并且调用栈里面, 会明显的标识: [chan send (nil chan)] 比如: goroutine 34 [chan send (nil chan)]: github.com/godevsig/adaptiveservice.(*streamTransport).receiver.func1(0x5e7c48, 0xc0000c2ba0, 0xc0000a7140) /repo/yingjieb/github/godevsig/adaptiveservice/streamtransport.go:213 +0x49 created by github.com/godevsig/adaptiveservice.(*streamTransport).receiver /repo/yingjieb/github/godevsig/adaptiveservice/streamtransport.go:206 +0x8a 参考go规范: Receiving from a nil channel blocks forever A send on a nil channel blocks forever. 流式接口和go 我们知道流式接口就是说返回其自身的方法. 比如: // NewClient creates a client which discovers services. func NewClient() *Client { return &Client{ base: newBase(), discoverTimeout: -1, } } // WithinScopeOS sets the discover scope in same OS. func (c *Client) WithinScopeOS() *Client { c.withinScopeOS() return c } 这样就可以\"流式\"的初始化: c := NewClient().WithinScopeOS().WithDiscoverTimeout(0) 那么如果我向go这个流式函数链呢? 比如 go NewClient().WithinScopeOS().WithDiscoverTimeout(0) 其执行顺序是怎么样的? 流式函数链的go执行顺序 先看代码: package main import ( \"fmt\" \"time\" ) type test struct { name string } func NewTest(f func() string) *test { fmt.Println(\"in NewTest\") return &test{f()} } func (t *test) fa() *test { fmt.Println(t.name, \"in fa\") return t } func (t *test) fb(f func()) *test { fmt.Println(\"fb\") f() return t } func main() { fmt.Println(\"Hello, playground\") go NewTest( func() func() string { fmt.Println(\"before go? -- YES\") return func() string { return \"San\" } }()). fa(). fb( func() func() { fmt.Println(\"before go? -- NO\") return func() { fmt.Println(\"in go? -- YES\") } }()) time.Sleep(time.Second) } 解读 NewTest函数入参是个函数, 传入的时候返回闭包函数传给它 fa函数是普通的函数链上的一个 fb函数也是函数链上的, 但传入一个闭包函数给它. 大的调用关系是go NewTest(入参).fa().fb(入参) 运行结果和结论 结果: Hello, playground before go? -- YES in NewTest San in fa before go? -- NO fb in go? -- YES 结论是: 只有第一级函数, 即NewTest()的入参, 在这里是个函数, 是在go之前执行, 对应打印before go? -- YES 要注意, fb的入参函数, 是在go里面执行的. 所以说只有第一级的函数的入参才会在go之前被计算 go get和go mod 测试环境 go1.16, go mod模式 go get go get -u: 升级所有依赖, 递归包括依赖的依赖 go get -u all: 首先all会被扩展成main的所有依赖, 然后升级所有依赖. all是关键词, 详见go help packages go list go list -m all能列出当前用的所有的module(包括版本号) go list all能列出当前用的所有的package(import路径) go mod tidy 清理go.mod用的, 但似乎go.sum还是有很多\"历史\"版本, 这些版本并没有使用. 总结 go list -m all查看main的所有递归依赖版本 go的编译系统一般只有一个版本号. 当出现不同版本依赖时, 比如A依赖(X@v0.0.2), 但某个依赖指定了不同的版本号(比如X@v0.0.1), 我猜测根据兼容性公约, go的编译系统会选择新的版本号(v0.0.1)来编译. go clean 清理编译cache go clean -cache -i -r The -cache flag causes clean to remove the entire go build cache. The -i flag causes clean to remove the corresponding installed archive or binary (what 'go install' would create). The -r flag causes clean to be applied recursively to all the dependencies of the packages named by the import paths. The -n flag causes clean to print the remove commands it would execute, but not run them. The -modcache flag causes clean to remove the entire module download cache, including unpacked source code of versioned dependencies. 又犯了经典的goroutine引用闭包变量错误!!!!! 这是个比较隐蔽的先for在switch的结构, 很容易忘记go引用的闭包变量会异步的变化. for _, vc := range vcs { switch cmd.Cmd { case \"restart\": if vc.stat == vmStatExited { vm := vc.VM vm.In = null{} logFile, err := os.Create(vc.outputFile) if err != nil { greLogger.Errorln(errorHere(err)) break } vm.Out = logFile go func() { defer logFile.Close() vc.RestartedNum++ vc.runVM() }() ids = append(ids, vc.ID) } } } 现象是第15和16行, 在10次for循环里, 每次都是对同一个vc对象进行操做. 原因 这里第15和16行引用的是for的循环变量vc, 会被for循环更改. 解决 只在进入goroutine之前, 重新定义局部变量vc := vc, 这样goroutine里面的vc就引用的是局部变量vc.第13行定义的vc每次for循环都是个新的vc. for _, vc := range vcs { switch cmd.Cmd { case \"restart\": if vc.stat == vmStatExited { vm := vc.VM vm.In = null{} logFile, err := os.Create(vc.outputFile) if err != nil { greLogger.Errorln(errorHere(err)) break } vm.Out = logFile vc := vc go func() { defer logFile.Close() vc.RestartedNum++ vc.runVM() }() ids = append(ids, vc.ID) } } } 理论解释 参考https://stackoverflow.com/questions/39208162/why-i-can-redefine-the-same-variable-multiple-times-in-a-for-loop-but-cant-outs 有人问为什么在循环里可以: func main() { for i := 0; i 但自己手动写就编译不过: func main() { a := 77 fmt.Println(a) a := 77 fmt.Println(a) } 为啥? 专家的解答是: for循环每次进入循环体大括号块{}, 都是一个新的scope The reason is each time you enter a block of curly braces {} you're creating a new nested scope. When you declare the variable x at the top of the loop it is a new variable and it goes out of scope at the end of the loop. When the program comes back around to the top of the loop again it's another new scope. 有人给出了证据: func main() { for i := 0; i output 0x1040e0f8 0x1040e0fc 可以手动加{}来添加scope: func main() { a := 77 fmt.Println(&a) { a := 77 fmt.Println(&a) } } output 0x1040e0f8 0x1040e0fc 上面的例子就可以\"连续\"定义a两次, 但第二次是个新的变量地址 总结 for循环同一行的变量作用域在for里面没错, 但更像是在进入循环前定义的一样: for循环里面对循环变量的引用都是指向同一个东西 for循环里面用var v int或vc := vc定义的变量, 并非同一个地址, 每次循环都是\"临时\"生成的. 所以上面在第13行的修改可以解决问题. 以后检查go出去的函数是否有这个问题, 只检查循环变量就行了 if else if 共享一个变量scope 比如 var msg interface{} if ... { } else if msg, ok := msg.(ExclusiveMessage); ok { } else if msg, ok := msg.(Message); ok { } 第二个else if中的msg.(Message)实际上引用的是第一个else if中的msg, ok变量. 解决: 给if的变量取个不同的名字, 不要总叫msg 经典的append地址错误 背景是在vm运行的过程中, 调用callers()保存当下的调用栈所有栈帧. 下面的代码有错误: func (v *VM) callers() (frames []*frame) { curFrame := *v.curFrame curFrame.ip = v.ip - 1 frames = append(frames, &curFrame) for i := v.framesIndex - 1; i >= 1; i-- { //值复制, 避免v.frames变动造成curFrame变动 //v.frames是个数组 curFrame = v.frames[i-1] //注意这里搞错了, 每次都append同一个地址!!! 这个因为curFrame变量只有一个. frames = append(frames, &curFrame) } return frames } 改正: 这种情况下, 返回值的slice, 而不是指针slice. func (v *VM) callers() (frames []frame) { curFrame := *v.curFrame curFrame.ip = v.ip - 1 frames = append(frames, curFrame) for i := v.framesIndex - 1; i >= 1; i-- { curFrame = v.frames[i-1] frames = append(frames, curFrame) } return frames } 打印指针slice 我有个结构体, 现在想打印一个var wants []*want的slice type want struct { content []string unordered bool } 直接fmt.Printf(\"%v\", wants)会输出一个slice, 但元素都是指针. 怎么才能打印这些指针的值呢? 用fmt.Printf(\"%+v\", wants)和fmt.Printf(\"%#v\", wants)都不行. 解决: 给结构体加String方法 func (wt *want) String() string { var sb strings.Builder if wt.unordered { sb.WriteString(\"//unordered output:\\n\") } else { sb.WriteString(\"//output:\\n\") } for _, str := range wt.content { sb.WriteString(str + \"\\n\") } return sb.String() } 这样fmt.Printf(\"%v\", wants)就可以输出我们想要的内容了. 其原理是如果一个类型有自定义String()方法, Printf会调用这个自定义String()方法. 注意, 这里要用引用的receiver方式, 因为我们要打印指针. 关于wait group sync包的wait group用于主routine等待所有子routine退出. 在使用上需要注意: wg.Add(1)需要在go之前. wg.Done()需要在go里面. 即要严格按照官网的例子来写: var wg sync.WaitGroup var urls = []string{ \"http://www.golang.org/\", \"http://www.google.com/\", \"http://www.somestupidname.com/\", } for _, url := range urls { // Increment the WaitGroup counter. wg.Add(1) //注意这里, 在go之前Add() // Launch a goroutine to fetch the URL. go func(url string) { // Decrement the counter when the goroutine completes. defer wg.Done() //注意这里, 在go里面Done() // Fetch the URL. http.Get(url) }(url) } // Wait for all HTTP fetches to complete. wg.Wait() 下面解释一下: 在go之前Add(), 是要这个wg.Add(1) 一定 能被主routine调用到. 在go里面调wg.Done()很好理解, 表示事情在这个异步的goroutine里已经完成. 反例 通常大家容易犯的错误是把wg.Add(1)放到go的里面去做. 比如下面代码: clone一个VM, 然后在新的goroutine中run这个新的VM. 父VM需要记录这个新VM到其childVM map里面. func govm(fn) { newVM := vm.ShallowClone() gvm := &goroutineVM{ VM: newVM, waitChan: make(chan ret, 1), } vm.addChildVM(gvm.VM) go func() { //vm.addChildVM(gvm.VM) //不能在里面Add() val, err := gvm.RunCompiled(fn, args[1:]...) gvm.waitChan 如果第8行放到第10行做, 好像也在干活之前加了1, 干完活减1. 但实际情况是, 比如: 在父VM Abort时, 需要abort其所有的子VM. // Abort aborts the execution of current VM and all its descendant VMs. func (v *VM) Abort() { atomic.StoreInt64(&v.aborting, 1) close(v.abortChan) // broadcast to all receivers v.childCtl.Lock() for cvm := range v.childCtl.vmMap { cvm.Abort() } v.childCtl.Unlock() v.childCtl.Wait() // waits for all child VMs to exit } 现在假设父这样的操做序列: 新起3个VM然后马上abort govm(fn1) govm(fn2) govm(fn3) abort() 3个govm是异步在跑的, 当父VM routine运行到第4行abort()的时候, 在abort()跑到第10行v.childCtl.Wait()等待这个wait group的时候, 不能保证它的3个子VM都跑到了Add(1), 因为子VM的Add()可能还没有运行. 这样会导致在父routine的Wait()得到wait的个数小于实际的VM routine个数, 虽然VM起来以后这个wait个数是能够加到3的, 但已经过了父VM routine 的wait点(Abort()函数第10行), 最后的结果就是父VM routine不能把这3个VM routine都abort()掉. 从栈上获取变量地址 比如我要从下面的栈中, 取传递给github.com/d5/tengo/v2.(*VM).run的地址 goroutine 1 [running]: github.com/d5/tengo/v2.builtinGo(0xc0001360b0, 0x1, 0x1, 0x0, 0x0, 0xc0001360b0, 0x1) /repo/yingjieb/github/godevsig/tengo/builtins.go:409 +0x69 github.com/d5/tengo/v2.(*BuiltinFunction).Call(0x7993b0, 0xc0001360b0, 0x1, 0x1, 0xc000178010, 0x1, 0x7ff, 0x1) /repo/yingjieb/github/godevsig/tengo/objects.go:349 +0x48 github.com/d5/tengo/v2.(*VM).run(0xc00013e0d0) /repo/yingjieb/github/godevsig/tengo/vm.go:652 +0x3323 github.com/d5/tengo/v2.(*VM).Run(0xc00013e0d0, 0xc00013e0d0, 0x400) /repo/yingjieb/github/godevsig/tengo/vm.go:96 +0xc7 github.com/godevsig/gshellos.(*shell).runREPL(0xc000099ec8) /repo/yingjieb/github/godevsig/gshellos/gshellbuilder.go:101 +0x825 github.com/godevsig/gshellos.ShellMain(0x786a60, 0xc00005e750) /repo/yingjieb/github/godevsig/gshellos/gshellbuilder.go:197 +0x660 main.main() /repo/yingjieb/github/godevsig/gshellos/cmd/gshell/gshell.go:12 +0x26 下面是方法 首先在vm.go里面 var stackIdentifierVM string //应该是github.com/d5/tengo/v2.(*VM).run func init() { stackIdentifierVM = runtime.FuncForPC(reflect.ValueOf((*VM).run).Pointer()).Name() } 然后在需要用到VM地址的函数里: func builtinGo(args ...Object) (Object, error) { ... var buf [1024]byte n := runtime.Stack(buf[:], false) //取stack, 看从哪里调的. 本函数离(*VM).Run不远, 1024的buf够了 stk := string(buf[:n]) idx := strings.Index(stk, stackIdentifierVM) //找到stackIdentifierVM字符串, 也就是上面的\"github.com/d5/tengo/v2.(*VM).run\" stk2 := stk[idx+len(stackIdentifierVM)+1:] idx = strings.Index(stk2, \")\") addr, err := strconv.ParseUint(stk2[:idx], 0, 64) //转为int64 vm := (*VM)(unsafe.Pointer(uintptr(addr))) //用unsafe强制转为*VM newVM := vm.ShallowClone() //然后就可以使用这个vm的方法了 } 参考代码 # in vm.go var stackIdentifierVM = runtime.FuncForPC(reflect.ValueOf((*VM).run).Pointer()).Name() # in group.go func getVM() (*VM, error) { var buf [1024]byte n := runtime.Stack(buf[:], false) stk := string(buf[:n]) // find \"github.com/d5/tengo/v2.(*VM).run\" idx := strings.Index(stk, stackIdentifierVM) stk2 := stk[idx+len(stackIdentifierVM)+1:] idx = strings.Index(stk2, \")\") addr, err := strconv.ParseUint(stk2[:idx], 0, 64) if err != nil { return nil, fmt.Errorf(\"failed to get current VM from %s: %w\\n\", stk, err) } vm := (*VM)(unsafe.Pointer(uintptr(addr))) return vm, nil } 运行时获取函数名 比如我有个方法 func (v *VM) run() { } 现在想在另外一个函数里, 打印这个上面这个方法的名字: 方法1 fmt.Println(runtime.FuncForPC(reflect.ValueOf((*VM)(nil).run).Pointer()).Name()) //结果 github.com/d5/tengo/v2.(*VM).run-fm 方法2 fmt.Println(runtime.FuncForPC(reflect.ValueOf((*VM).run).Pointer()).Name()) //结果 github.com/d5/tengo/v2.(*VM).run 注意方法2和方法1的区别只是传入reflect.ValueOf的值不一样: (*VM)(nil).run的意思是先把nil强转成(*VM), 然后这个对象的run方法做为入参 (*VM).run直接就是方法, 说明本质上go把(receiver).method当成一个func定义. continue能返回N层for continue能够指定跳转lable(只能是for的lable) RowLoop: for y, row := range rows { for x, data := range row { if data == endOfRow { continue RowLoop } row[x] = data + bias(x, y) } } interface的理解 interface{}是青出于蓝 一个典型情况是, 底层对象实现了某些方法集合(蓝方法集合), 通过wrapper层, 提供给用户\"扩展\"版本的方法集合(青方法集合). 举例如下: mangos代码中, 底层通道的pipe抽象是transport.Pipe(TranPipe的别名),提供如下方法(蓝色接口): // TranPipe behaves like a full-duplex message-oriented connection between two // peers. Callers may call operations on a Pipe simultaneously from // different goroutines. (These are different from net.Conn because they // provide message oriented semantics.) // // Pipe is only intended for use by transport implementors, and should // not be directly used in applications. type TranPipe interface { // Send sends a complete message. In the event of a partial send, // the Pipe will be closed, and an error is returned. For reasons // of efficiency, we allow the message to be sent in a scatter/gather // list. Send(*Message) error // Recv receives a complete message. In the event that either a // complete message could not be received, an error is returned // to the caller and the Pipe is closed. // // To mitigate Denial-of-Service attacks, we limit the max message // size to 1M. Recv() (*Message, error) // Close closes the underlying transport. Further operations on // the Pipe will result in errors. Note that messages that are // queued in transport buffers may still be received by the remote // peer. Close() error // GetOption returns an arbitrary transport specific option on a // pipe. Options for pipes are read-only and specific to that // particular connection. If the property doesn't exist, then // ErrBadOption should be returned. GetOption(string) (interface{}, error) } 在internal/core/socket.go中, 用一个结构体\"包装\"了底层的transport.Pipe // pipe wraps the Pipe data structure with the stuff we need to keep // for the core. It implements the Pipe interface. type pipe struct { id uint32 p transport.Pipe //这个就是transport.Pipe的接口实例 l *listener d *dialer s *socket closeOnce sync.Once data interface{} // Protocol private added bool closing bool lock sync.Mutex // held across calls to remPipe and addPipe } 这个pipe实现了protocol.ProtocolPipe接口(青色接口): // ProtocolPipe represents the handle that a Protocol implementation has // to the underlying stream transport. It can be thought of as one side // of a TCP, IPC, or other type of connection. type ProtocolPipe interface { // ID returns a unique 31-bit value associated with this. // The value is unique for a given socket, at a given time. ID() uint32 // Close does what you think. Close() error // SendMsg sends a message. On success it returns nil. This is a // blocking call. SendMsg(*Message) error // RecvMsg receives a message. It blocks until the message is // received. On error, the pipe is closed and nil is returned. RecvMsg() *Message // SetPrivate is used to set protocol private data. SetPrivate(interface{}) // GetPrivate returns the previously stored protocol private data. GetPrivate() interface{} } 通过\"青出于蓝\"的操作, pipe struct对外屏蔽了transport.Pipe实例, 但对外提供了该有的函数. 即\"青出于蓝\"的核心不在于暴露蓝的实例, 而是提供青的功能函数. 所以interface{}的本质是提供方法规约, 同时隐藏了实例细节. 这是一个高度接口化(或者说是标准化)的世界, 比如在纺织厂语境下, 你提供的只有纺织工的操作的双手, 你的个性, 比如喜欢王菲的歌, 根本没必要也不值得被外人知道. 相对C++, go的interface概念摒弃了对象的\"数据\"属性, 只保留\"方法\"规约. 对象的\"数据\"自己来cook, 外人不关心; 外人只要你提供方法\"服务\"就行了. 注: 这里的pipe struct是小写, 其内部所有的field都是小写, 这个pipe不能被外部\"直接\"使用. 但可以通过调用核心层的函数, s.proto.AddPipe(p), \"注册\"自己: AddPipe是protocol实例的规定函数, 原型如下: AddPipe(ProtocolPipe) error 上面的p代表一个ProtocolPipe实例, 虽然全部都是小写, 但也不妨碍能被当作ProtocolPipe的interface来赋值. 即这里就把一个完全\"私有\"的实例, 通过满足ProtocolPipe规定的方法, 当作ProtocolPipe的实例被\"导出\"到外部使用. interface{}是带上下文的方法集合 带方法的interface{}的典型的使用场景是: 该interface{}变量是带上下文的函数集合. 比如mangos里面创建REQ的socket: func NewSocket() (protocol.Socket, error) { return protocol.MakeSocket(NewProtocol()), nil } 其中protocol.MakeSocket(proto Protocol) Socket的入参就是一个规定方法的interface{} type ProtocolBase interface { ProtocolContext // Info returns the information describing this protocol. Info() ProtocolInfo // XXX: Revisit these when we can use Pipe natively. // AddPipe is called when a new Pipe is added to the socket. // Typically this is as a result of connect or accept completing. // The pipe ID will be unique for the socket at this time. // The implementation must not call back into the socket, but it // may reject the pipe by returning a non-nil result. AddPipe(ProtocolPipe) error // RemovePipe is called when a Pipe is removed from the socket. // Typically this indicates a disconnected or closed connection. // This is called exactly once, after the underlying transport pipe // is closed. The Pipe ID will still be valid. RemovePipe(ProtocolPipe) // OpenContext is a request to create a unique instance of the // protocol state machine, allowing concurrent use of states on // a given protocol socket. Protocols that don't support this // should return ErrProtoOp. OpenContext() (ProtocolContext, error) } 所以: 核心层(比如这里的protocol层), 给其下辖的模块规定方法集, 满足这些方法集的实现就能享受核心层提供的好处(比如子模块享受核心层的MakeSocket()方法) 核心层是框架, 框架定好规矩(方法集) 子模块是实现, 实现了规定的方法集, 就能融入框架, 享受框架. 这里的例子是, 子模块调用核心层的函数protocol.MakeSocket(自己的接口实例), 传入自己的interface{}实现. 总结: 核心层定义接口, 针对接口做框架 子模块实现接口, 调用核心层的函数来完成任务. runtime.Caller获取当前运行目录 runtime.Caller(0)的第二个返回值是文件名, 对文件名的路径操作得到当前目录, 定位文件等等. _, f, _, _ := runtime.Caller(0) topDir := f[:strings.Index(f, \"extension\")] covFile := filepath.Base(strings.TrimSuffix(file, filepath.Ext(file))) covFileArg := fmt.Sprintf(\"-test.coverprofile=%sl2_%s.cov\", topDir, covFile) An interface holding nil value is not nil func main() { var a interface{} fmt.Printf(\"a == nil is %t\\n\", a == nil) var b interface{} var p *int = nil b = p fmt.Printf(\"b == nil is %t\\n\", b == nil) } 结果: a == nil is true b == nil is false b被赋值为p, p是nil. 但b不是nil 因为interface为nil的条件是2个: 值和类型都必须是nil \"An interface equals nil only if both type and value are nil.\" 这里b的值是nil, 但类型不是nil. 只声明没赋值的接口变量是nil 显式赋值为nil的接口变量是nil. 注意必须是b = nil这样的赋值才行. 补充: nil既是值, 也是一种类型. 另外, 可以对接口进行类型断言来查看其\"值\"是否为nil var v interface{} var a map[string]int v = a //此时v已经不是nil了, 因为v的类型变成了map[string]int //对v断言成mv, 那么mv就又是nil了 mv := v.(map[string]int) if mv == nil { return nil, nil } net/http导致包变大 现象 我import了网上的库, abs. 编译后发现有8.2M. 用nm命令查看二进制, 发现有很多net/http的符号. 但实际上, 我并没有显式引用任何网络相关的函数. 解决 调查发现, abs内部的一个package util中, 有一个文件引用了\"net/http\"包, 提供了一个函数从httpDownload(). 删除这个文件, 二进制的size直接减小了4M! 编译时间也缩短了很多. 而且还不影响功能 原因 那为什么代码里没有实际引用Download()函数, net/http还是被编译进去了呢? 是go的编译器不够聪明, 不能把\"dead code\"删掉吗? -- 不是. 虽然在编译阶段, 是按照packge来编译成.a的, 但这个阶段一般都会缓存到一个cache目录下. 在链接阶段, go的链接器能做到只链接用得到的符号. 但即使只是空引用import _ \"net/http\", 二进制的size就会增加4M, 说明net/http内部一定是有全局变量或者init()函数, 引用了自身的符号. 这个引用进一步把全部符号都拖入泥潭. 结论 不要引用net/http, 初非必须要http功能. 用nm查看二进制, 排查是否有net/http出现. Options初始化 readlineutil.go是github.com/chzyer/readline的一个简单封装, 提供一个类似bufio.Scaner的迭代器. 它的初始化很有设计感. 要点是 入参是变长的 入参的形式是函数 参数在函数里面执行 type Term struct { inst *readline.Instance io.Writer line string err error prevPrompt string } type Option func(*conf) type conf struct { rc *readline.Config } //options是个变长的入参, 格式是Option, 后者是个函数. func NewTerm(options ...Option) (*Term, error) { var c conf c.rc = new(readline.Config) c.rc.DisableAutoSaveHistory = true //执行入参函数 for _, o := range options { o(&c) } inst, err := readline.NewEx(c.rc) t := new(Term) t.inst = inst t.Writer = inst.Stdout() return t, nil } //返回闭包函数 func WithHistoryFile(filename string) Option { return func(c *conf) { c.rc.HistoryFile = filename } } //使用: t := NewTerm(WithHistoryFile(\"history\")) 相对于普通的设计: 多个入参, 类型不同, 显式指定. 比如func NewTerm(history string, prompt string, search bool, 等等) (*Term, error) 这样做的缺点很多: 如果是对外的API, 那这个API可能会经常变化; 比如增加个属性, 调用者要改代码才能编过 -- 即使老用户并不关心这个新增的属性, 也不准备用这个新功能. 参数通过位置传递, 多了不好看 入参是个结构体, 结构体的字段表述不同的属性; 这样入参不需要变长, 靠结构体的定义, 以及不同field的赋值来传入\"变化\" 解决了上面方案的变化问题, 部分解决了API更改的问题. -- 此时API的更改变更为struct{}的更改, 部分解决了老用户希望代码不变的问题 -- 部分赋值的struct是允许的. 但调用者还是要关心这个入参结构体的定义 结构体字段的赋值没有明显的位置感, key: value的形式可读性好点 入参变长, 全部是interface{} 足够灵活, 如果实在是外部需求变化大, 需要适应变化 繁琐: 需要在实现里不断的搞类型断言 对于本例的场景, 并不适合. 传入的参数需要表明目的. 本例范式: func NewTerm(options ...Option) 是对\"结构体\"入参的一种扩展, Option本质上是一个函数, 这个函数对\"cfg入参结构体\"中的一个字段进行配置 这样定义的对外API有良好的扩展性: 用户不必修改代码; cfg结构体对用户不可见. go-micro中, 就大量使用了Options范式: // Service is an interface for a micro service type Service interface { ... // Init initialises options Init(...Option) // Options returns the current options Options() Options ... } type Option func(*Options) type Options struct { A string B int C bool } 总结 设计一个对外的API时, 比较典型的是NewXxx的API, 或者Init()的API, 最好不用1, 简单点的场景用2, 复杂点的框架用4; 特殊情况用3 空白import不会增加binary size 比如一个empty.go, 本来不需要pidinfo包. 但还是引入了这个包 import _ \"pidinfo\" 可以编译, 编译后的binary只包括一点点pidinfo的代码. 整个size并没有变化. 还是2M. 如果调用了有限几个pidinfo里面的函数, 感觉go的编译器会自动remove dead code. reflect高阶用法 动态构建一个struct 用reflect可以创建一个\"任意没有定义过\"的结构体 核心是func StructOf(fields []StructField) Type API typ := reflect.StructOf([]reflect.StructField{ { Name: \"Height\", Type: reflect.TypeOf(float64(0)), Tag: `json:\"height\"`, }, { Name: \"Age\", Type: reflect.TypeOf(int(0)), Tag: `json:\"age\"`, }, }) v := reflect.New(typ).Elem() v.Field(0).SetFloat(0.4) v.Field(1).SetInt(2) s := v.Addr().Interface() w := new(bytes.Buffer) if err := json.NewEncoder(w).Encode(s); err != nil { panic(err) } fmt.Printf(\"value: %+v\\n\", s) fmt.Printf(\"json: %s\", w.Bytes()) r := bytes.NewReader([]byte(`{\"height\":1.5,\"age\":10}`)) if err := json.NewDecoder(r).Decode(s); err != nil { panic(err) } fmt.Printf(\"value: %+v\\n\", s) 结果: value: &{Height:0.4 Age:2} json: {\"height\":0.4,\"age\":2} value: &{Height:1.5 Age:10} byName API -- 神奇的重名API reflect.Value的MethodByName方法 从一个反射对象reflect.Value可以用方法名查到它的方法对象: func (v Value) MethodByName(name string) Value 返回一个\"function value\". 传参给返回的function不能带receiver, 因为它把Value v当作默认的receiver MethodByName returns a function value corresponding to the method of v with the given name. The arguments to a Call on the returned function should not include a receiver; the returned function will always use v as the receiver. It returns the zero Value if no method was found. stack over flow有个讨论, 里面由示例代码. 还有个更简单的 package main import \"fmt\" import \"reflect\" type T struct {} func (t *T) Foo() { fmt.Println(\"foo\") } func main() { var t T reflect.ValueOf(&t).MethodByName(\"Foo\").Call([]reflect.Value{}) } reflect.Type的MethodByName方法 reflect.Type的反射对象也有个同名的方法 reflect.Type是个接口, 它底层的具体类型必须实现一系列的函数 // MethodByName returns the method with that name in the type's // method set and a boolean indicating if the method was found. // // For a non-interface type T or *T, the returned Method's Type and Func // fields describe a function whose first argument is the receiver. // // For an interface type, the returned Method's Type field gives the // method signature, without a receiver, and the Func field is nil. MethodByName(string) (Method, bool) 返回的Method是个结构体 type Method struct { // Name is the method name. // PkgPath is the package path that qualifies a lower case (unexported) // method name. It is empty for upper case (exported) method names. // The combination of PkgPath and Name uniquely identifies a method // in a method set. // See https://golang.org/ref/spec#Uniqueness_of_identifiers Name string PkgPath string Type Type // method type Func Value // func with receiver as first argument Index int // index for Type.Method } 用返回的Method怎么调用函数??? go调用外部程序 这里以go解释器yaegi为例. dotCmd是dot -Tdot -o ast.dot // dotWriter returns an output stream to a dot(1) co-process where to write data in .dot format. func dotWriter(dotCmd string) io.WriteCloser { if dotCmd == \"\" { return nopCloser{ioutil.Discard} } fields := strings.Fields(dotCmd) //构建cmd cmd := exec.Command(fields[0], fields[1:]...) //cmd有StdinPipe函数, 返回 dotin, err := cmd.StdinPipe() if err != nil { log.Fatal(err) } //开始这个cmd, 但还没有输入 if err = cmd.Start(); err != nil { log.Fatal(err) } //返回输入的句柄 return dotin } 外部对dotWriter返回的io.WriteCloser写就可以pipe到cmd的输入. text/template代码生成举例 const model = `// Code generated by 'yaegi extract {{.PkgName}}'. DO NOT EDIT. {{.License}} {{if .BuildTags}}// +build {{.BuildTags}}{{end}} package {{.Dest}} import ( {{- range $key, $value := .Imports }} {{- if $value}} \"{{$key}}\" {{- end}} {{- end}} \"{{.PkgName}}\" \"reflect\" ) func init() { Symbols[\"{{.PkgName}}\"] = map[string]reflect.Value{ {{- if .Val}} // function, constant and variable definitions {{range $key, $value := .Val -}} {{- if $value.Addr -}} \"{{$key}}\": reflect.ValueOf(&{{$value.Name}}).Elem(), {{else -}} \"{{$key}}\": reflect.ValueOf({{$value.Name}}), {{end -}} {{end}} {{- end}} {{- if .Typ}} // type definitions {{range $key, $value := .Typ -}} \"{{$key}}\": reflect.ValueOf((*{{$value}})(nil)), {{end}} {{- end}} {{- if .Wrap}} // interface wrapper definitions {{range $key, $value := .Wrap -}} \"_{{$key}}\": reflect.ValueOf((*{{$value.Name}})(nil)), {{end}} {{- end}} } } {{range $key, $value := .Wrap -}} // {{$value.Name}} is an interface wrapper for {{$key}} type type {{$value.Name}} struct { {{range $m := $value.Method -}} W{{$m.Name}} func{{$m.Param}} {{$m.Result}} {{end}} } {{range $m := $value.Method -}} func (W {{$value.Name}}) {{$m.Name}}{{$m.Param}} {{$m.Result}} { {{$m.Ret}} W.W{{$m.Name}}{{$m.Arg}} } {{end}} {{end}} ` 使用的时候 base := template.New(\"extract\") parse, err := base.Parse(model) b := new(bytes.Buffer) data := map[string]interface{}{ \"Dest\": e.Dest, \"Imports\": imports, //这里的imports是个map \"PkgName\": importPath, \"Val\": val, \"Typ\": typ, \"Wrap\": wrap, \"BuildTags\": buildTags, \"License\": e.License, } err = parse.Execute(b, data) // gofmt source, err := format.Source(b.Bytes()) //此时source里面就是替换后的代码 注: 替换的变量是通过map[string]interface{}传入的, 其值为万能interface 值可以是map, 比如上面的imports; 对应模板里面用range来遍历. map的重要属性 unaddressable 这样操作map是可以的: type User struct { name string } users := make(map[int]User) users[5] = User{\"Steve\"} 但下面这样不行: users[5].name = \"Mark\" //cannot assign to struct field users[5].name in map 为什么呢? 问答在这里 答: map的value是不能被寻址的(by语言设计), 虽然users[5]看起来像是寻找到了一个User, 但在go里面所有的传递都是值传递, users[5].name = \"Mark\"也隐含发生了值拷贝: 从原User拷到了临时的不可见的User. 对后者的赋值= Mmark\"是没有任何意义的, 即使可以, 也不会改变原User的name. 所以在编译阶段, 就会提示错误. 同样的, 这样也会报错: (&users[5]).name = \"Mark\" //cannot take the address of users[5] 那如何更改value呢? 方法1 整体给map赋值 t := users[5] t.name = \"Mark\" users[5] = t 上面的代码中, 首先显式的值拷贝到t, 更改t, 再把t拷贝进users这个map. 这里User类型的实例的拷贝都发生了2次. 方法2 让value的类型为指针 users := make(map[int]*User) 此时users[5]虽然也是值拷贝, 但拷贝出来的指针还是指向底层数据, 就可以更改了. 结论 map的value为值类型时, 不能被寻址; 所以不能\"原地\"修改 可以把map的value设计为指针类型, 支持\"原地\"修改. 但这样会给gc带来压力 也可以用copy-改-copy进map的方式修改 go的树状表达 在C里面, 定义一个node时, next域必须是ListNode的指针 struct ListNode{ int val; ListNode* next; }; 在go里面, 一个tree的最简单, 最天然的表达是map: map的value还是个tree type astTree map[string]astTree 注意到这里, value实际上是它对自己的表达: 自己包括自己(而不是指针), 能行吗? --可以. 下面的例子说明这么写没有任何问题 var ast astTree = nil ast = astTree{\"hello\":nil, \"wolrd\":{\"111\":nil}} fmt.Println(ast) 结果是 map[hello:map[] wolrd:map[111:map[]]] 解释: 实际上, map是个固定size的结构体, 有着类似指针的性质, 比如上面代码中, var ast astTree = nil, map可以赋值为nil. 既然是固定size, 那astTree的value就可以是自身astTree 但是, type astTree map[string]astTree这样树的表达, 语法上可以, 但没有实际意义: 这个树的节点上, 只有做为string的key能存储有意义的数据 -- 一个树, 除了结构表达, 还需要存储data才能发挥实际的作用. 存储data 把ast定义成一个结构体: type astTree struct { data int ast map[string]astTree } 初始化: func main() { fmt.Println(\"Hello, playground\") //var ast astTree = nil ast := astTree{23, map[string]astTree{\"hello\":astTree{}, \"nihao\":astTree{}}} ast.ast[\"world\"] = astTree{} fmt.Println(ast) } //输出 Hello, playground {23 map[hello:{0 map[]} nihao:{0 map[]} world:{0 map[]}]} 但这样有点太丑了. 而且因为map的value元素为值类型的undressable因素, 不能用ast.ast[\"world\"].data =100这样的原地修改方法. 改进存储 按照map的value为指针类型可以寻址的特点, 改进如下: type asTree struct { data int subTrees map[string]*asTree } func main() { fmt.Println(\"Hello, playground\") ast := asTree{23, map[string]*asTree{\"hello\":&asTree{}, \"nihao\":&asTree{}}} ast.subTrees[\"world\"] = &asTree{} ast.subTrees[\"world\"].data =100 ast.subTrees[\"world\"].subTrees = map[string]*asTree{\"shanghai\":&asTree{}} ast.subTrees[\"world\"].subTrees[\"shanghai\"].subTrees = map[string]*asTree{\"pudong\":&asTree{}} fmt.Println(ast) fmt.Println(ast.subTrees[\"world\"]) ast.subTrees[\"world\"].subTrees[\"shanghai\"].data = 2013 fmt.Println(ast.subTrees[\"world\"].subTrees[\"shanghai\"]) } //输出 Hello, playground {23 map[hello:0xc000010200 nihao:0xc000010210 world:0xc000010220]} &{100 map[shanghai:0xc000010230]} &{2013 map[pudong:0xc000010240]} 如果用key来存储data会怎样? type useFullData struct { data1 int data2 string } type asTree map[useFullData]asTree 这样遍历是可以用k, v := range(asTree)来遍历的 但key本质上是种索引, key应该是某种不变的东西. key用来查询并得到数据. 用key来存储数据的问题是, 如果要存储的数据会变化, 那key就变了. golang的SIGABRT 在配置了GOTRACEBACK=crash的情况下, go程序会在panic的时候, 打印所有goroutine的调用栈(这个和GOTRACEBACK=system效果一样), 而且还会发SIGABRT(6号signal)触发core dump. man 7 signal说的很清楚, 每个signal都有默认的性情(disposition): Signal Value Action Comment ────────────────────────────────────────────────────────────────────── SIGHUP 1 Term Hangup detected on controlling terminal or death of controlling process SIGINT 2 Term Interrupt from keyboard SIGQUIT 3 Core Quit from keyboard SIGILL 4 Core Illegal Instruction SIGABRT 6 Core Abort signal from abort(3) SIGFPE 8 Core Floating-point exception SIGKILL 9 Term Kill signal SIGSEGV 11 Core Invalid memory reference SIGPIPE 13 Term Broken pipe: write to pipe with no readers; see pipe(7) SIGALRM 14 Term Timer signal from alarm(2) SIGTERM 15 Term Termination signal SIGUSR1 30,10,16 Term User-defined signal 1 SIGUSR2 31,12,17 Term User-defined signal 2 SIGCHLD 20,17,18 Ign Child stopped or terminated SIGCONT 19,18,25 Cont Continue if stopped SIGSTOP 17,19,23 Stop Stop process SIGTSTP 18,20,24 Stop Stop typed at terminal SIGTTIN 21,21,26 Stop Terminal input for background process SIGTTOU 22,22,27 Stop Terminal output for background process SIGABRT的性情就是触发core dump机制. 内核会走core dump流程. 所以, 在GOTRACEBACK=crash情况下 go程序会先打印panic调用栈(所有go routine) 然后主动调用类似c的abort()函数触发SIGABRT给自己 然后kernel会走core dump流程. 关于syscall syscall提供了对底层os的原始封装. 从go1.4开始 官方推荐使用golang.org/x/sys来代替syscall. 标准库的syscall提供了一些基本的const常量. 比如 EPOLLERR = 0x8 EPOLLET = -0x80000000 EPOLLHUP = 0x10 EPOLLIN = 0x1 EPOLLMSG = 0x400 EPOLLONESHOT = 0x40000000 EPOLLOUT = 0x4 EPOLLPRI = 0x2 EPOLLRDBAND = 0x80 EPOLLRDHUP = 0x2000 EPOLLRDNORM = 0x40 EPOLLWRBAND = 0x200 EPOLLWRNORM = 0x100 EPOLL_CLOEXEC = 0x80000 EPOLL_CTL_ADD = 0x1 EPOLL_CTL_DEL = 0x2 EPOLL_CTL_MOD = 0x3 syscall和CPU arch强相关, 默认显示GOARCH的对应的包. 一般是amd64 用 $GOOS and $GOARCH来切换其他的组合. 实际的代码在对应的组合, 比如/usr/local/go/src/syscall/zerrors_linux_arm64.go 标准syscall库的问题 复杂, 维护的很差, 表现在难于测试, 必须跟随OS的ARCH的改动 缺少文档, 兼容性难以保证 解决 syscall在go1.3code freeze 从go1.4开始, 使用一个新库, 新库分为plan9, unix, windows三个子类 在2014年左右就完成了 Note that we cannot clean up the existing syscall package to any meaningful extent because of the compatibility guarantee. We can freeze and, in effect, deprecate it, however. 更好的syscall库 简介在此, 这个简介在2014年左右 库地址: https://github.com/golang/sys 使用 go get -u golang.org/x/sys ioctl unix/zsyscall_linux.go中 func ioctl(fd int, req uint, arg uintptr) (err error) { _, _, e1 := Syscall(SYS_IOCTL, uintptr(fd), uintptr(req), uintptr(arg)) if e1 != 0 { err = errnoErr(e1) } return } 注意到这里的ioctl是小写的, 外面不能引用. c的ioctl接口 #include int ioctl(int fd, unsigned long request, ...); ioctl是对设备文件用的. 第二个参数是设备相关的request code, 第三个参数是个指针(char *argp). 这个request是个编码, 指示argp是入参还是出参, argp的字节数 ioctl对应驱动的实现: int (*ioctl) (struct inode * node, struct file *filp, unsigned int cmd, unsigned long arg); 这篇文章讲的比较清楚. cmd cmd为32bit, 是个组合, 包括几个部分 分类:8bit 类内序号: 8bit 数据传输方向: 2bit_IOC_NONE _IOC_READ _IOC_WRITE _IOC_READ|_IOC_WRITE 数据大小: 剩下的14bit argp 应用层的ioctl的第三个参数是\"...\"，这个跟printf的\"...\"可不一样，printf中是意味这你可以传任意个数的参数，而ioctl最多也只能传一个，\"...\"的意思是让内核不要检查这个参数的类型。也就是说，从用户层可以传入任何参数，只要你传入的个数是1. 一般会有两种的传参方法： 整数，那可是省力又省心，直接使用就可以了。 指针，通过指针的就传什么类型都可以了，当然用起来就比较烦。在驱动里使用copy_xx_user函数从用户态传输数据 go的ioctl接口 前面说过, go的ioctl是小写的, \"内部专供\" 但在unix/ioctl.go中, 封装了几个对外开放的接口: // ioctl itself should not be exposed directly, but additional get/set // functions for specific types are permissible. // IoctlSetInt performs an ioctl operation which sets an integer value // on fd, using the specified request number. func IoctlSetInt(fd int, req uint, value int) error // IoctlSetPointerInt performs an ioctl operation which sets an // integer value on fd, using the specified request number. The ioctl // argument is called with a pointer to the integer value, rather than // passing the integer value directly. func IoctlSetPointerInt(fd int, req uint, value int) error // IoctlSetWinsize performs an ioctl on fd with a *Winsize argument. // // To change fd's window size, the req argument should be TIOCSWINSZ. func IoctlSetWinsize(fd int, req uint, value *Winsize) error // IoctlSetTermios performs an ioctl on fd with a *Termios. // // The req value will usually be TCSETA or TIOCSETA. func IoctlSetTermios(fd int, req uint, value *Termios) error // IoctlGetInt performs an ioctl operation which gets an integer value // from fd, using the specified request number. // // A few ioctl requests use the return value as an output parameter; // for those, IoctlRetInt should be used instead of this function. func IoctlGetInt(fd int, req uint) (int, error) func IoctlGetWinsize(fd int, req uint) (*Winsize, error) func IoctlGetTermios(fd int, req uint) (*Termios, error) 结合C版本的ioctl分析, 这几个API怕是不够. IoctlSetInt和IoctlSetPointerInt能cover简单的int传输的需求 IoctlGetWinsize和IoctlGetTermios都是传递特殊功能结构体的. unix/syscall_linux.go中, 还有几个API: func IoctlRetInt(fd int, req uint) (int, error) func IoctlSetRTCTime(fd int, value *RTCTime) error func IoctlGetUint32(fd int, req uint) (uint32, error) func IoctlGetRTCTime(fd int) (*RTCTime, error) ioctl的宏定义在哪里? 在unix/zerrors_linux.go和unix/zerrors_linux_amd64.go 不用的OS和ARCH对应不同的文件 比如 //unix/zerrors_linux.go EPOLLIN = 0x1 //unix/zerrors_linux_amd64.go RTC_RD_TIME = 0x80247009 asm files ioctl调用的Syscall是在asm里面手写的 见https://github.com/golang/sys/tree/master/unix The hand-written assembly file at asm_${GOOS}_${GOARCH}.s implements system call dispatch. There are three entry points: func Syscall(trap, a1, a2, a3 uintptr) (r1, r2, err uintptr) func Syscall6(trap, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2, err uintptr) func RawSyscall(trap, a1, a2, a3 uintptr) (r1, r2, err uintptr) The first and second are the standard ones; they differ only in how many arguments can be passed to the kernel. The third is for low-level use by the ForkExec wrapper. Unlike the first two, it does not call into the scheduler to let it know that a system call is running. When porting Go to an new architecture/OS, this file must be implemented for each GOOS/GOARCH pair. mmap unix/syscall_linux.go //返回一个byte切片 func Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error) { return mapper.Mmap(fd, offset, length, prot, flags) } 使用: // +build aix darwin dragonfly freebsd linux netbsd openbsd solaris package unix_test import ( \"runtime\" \"testing\" \"golang.org/x/sys/unix\" ) func TestMmap(t *testing.T) { b, err := unix.Mmap(-1, 0, unix.Getpagesize(), unix.PROT_NONE, unix.MAP_ANON|unix.MAP_PRIVATE) if err != nil { t.Fatalf(\"Mmap: %v\", err) } if err := unix.Mprotect(b, unix.PROT_READ|unix.PROT_WRITE); err != nil { t.Fatalf(\"Mprotect: %v\", err) } //可以直接使用这个byte切片来修改内容 b[0] = 42 if runtime.GOOS == \"aix\" { t.Skip(\"msync returns invalid argument for AIX, skipping msync test\") } else { //msync系统调用是用来flush内容copy到真正的文件, mumap也有这个功能. if err := unix.Msync(b, unix.MS_SYNC); err != nil { t.Fatalf(\"Msync: %v\", err) } } //msync以后, 这块内存就可以\"建议\"内核, 不需要了 if err := unix.Madvise(b, unix.MADV_DONTNEED); err != nil { t.Fatalf(\"Madvise: %v\", err) } //最后使用munmap解除映射 if err := unix.Munmap(b); err != nil { t.Fatalf(\"Munmap: %v\", err) } } 百度上的结论写的不错: 最终被映射文件的内容的长度不会超过文件本身的初始大小，即映射不能改变文件的大小； 可以用于进程通信的有效地址空间大小大体上受限于被映射文件的大小，但不完全受限于文件大小。打开文件被截短为5个people结构大小，而在 map_normalfile1中初始化了10个people数据结构，在恰当时候（map_normalfile1输出initialize over 之后，输出umap ok之前）调用map_normalfile2会发现map_normalfile2将输出全部10个people结构的值，后面将给出详细讨论。 　　注：在linux中，内存的保护是以页为基本单位的，即使被映射文件只有一个字节大小，内核也会为映射分配一个页面大小的内存。当被映射文件小于一个页面大小时，进程可以对从mmap()返回地址开始的一个页面大小进行访问，而不会出错；但是，如果对一个页面以外的地址空间进行访问，则导致错误发生，后面将进一步描述。因此，可用于进程间通信的有效地址空间大小不会超过文件大小及一个页面大小的和。 文件一旦被映射后，调用mmap()的进程对返回地址的访问是对某一内存区域的访问，暂时脱离了磁盘上文件的影响。所有对mmap()返回地址空间的操作只在内存中有意义，只有在调用了munmap()后或者msync()时，才把内存中的相应内容写回磁盘文件，所写内容仍然不能超过文件的大小。 mmap返回的byte切片是哪里来的? unix/syscall_linux.go中, Mmap的实现是 func Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error) { return mapper.Mmap(fd, offset, length, prot, flags) } 而这个mapper的实现在unix/syscall_unix.go func (m *mmapper) Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error) { if length 可以看到 Syscall交互的数据都是uintptr类型 Mmap返回的data []byte, 并不是通常动态申请的buffer, 而是用Syscall返回的地址, 经过黑科技构造成的切片. 注: 复习一下指针转换的知识 unsafe.Pointer有如下性质: unsafe.Pointer和任意的指针类型能互相转换 unsafe.Pointer和uintptr能互相转换 指针和uintptr不能直接互转 fnctl unix/fcntl.go中, 对fnctl也有个简单的封装 RWLock死锁 在持有mtx.Lock()的时候, 在里面再次获取RLock会死锁 比如下面的结构会死锁. mtx.Lock() 调用一个函数() 函数里面再次获取读锁 mtx.RLock() ... mtx.RUnlock() mtx.Unlock() 死锁发生时, goroutine会显示semacquire状态 goroutine 1 [semacquire]: 其调用栈路径上能看到是重复获取锁 官方文档说的很清楚, RLock()不支持重复获取(recursive lock) float强转为int go的强转和C的表现是一致的, 比如把3.1415926强转为int, C和go都是得到3, 即浮点的整数部分. go generate go generate用于执行go代码注释中的动作 中文说明 官方说明 执行go generate时，有一些环境变量可以使用: $GOARCH 体系架构 (arm、amd64等待) $GOOS OS环境(linux、windows等) $GOFILE 当前处理中的文件名 $GOLINE 当前命令在文件中的行号 $GOPACKAGE 当前处理文件的包名 $DOLLAR 固定的\"$\",不清楚用途 假设我们有个main.go文件，内容如下： package main import \"fmt\" //go:generate echo hello //go:generate go run main.go //go:generate echo file=$GOFILE pkg=$GOPACKAGE func main() { fmt.Println(\"main func\") } 执行“go generate”后，输出如下： $ go generate hello main func file=main.go pkg=main 最后的build步骤就两步 all: go generate && go build . go generate常使用的一些工具 在学习go generate的过程中，我还看到了一篇generate的常用工具的wiki，我并没有全部使用过，在此与大家分享，希望能提升开发效率，https://github.com/golang/go/wiki/GoGenerateTools。 go generate仅在您有使用它的工具时才有用！这是生成代码的有用工具的不完整列表。 goyacc – Go的Yacc。 stringer – 实现fmt.Stringer枚举的接口。 gostringer – fmt.GoStringer为枚举实现接口。 jsonenums – 枚举的实现json.Marshaler和json.Unmarshaler接口。 go-syncmap – 使用软件包作为的通用模板生成Go代码sync.Map。 go-syncpool – 使用软件包作为的通用模板生成Go代码sync.Pool。 go-atomicvalue – 使用软件包作为的通用模板生成Go代码atomic.Value。 go-nulljson – 使用包作为实现database/sql.Scanner和的通用模板生成Go代码database/sql/driver.Valuer。 go-enum – 使用包作为实现接口的通用模板生成Go代码fmt.Stringer| binary| json| text| sql| yaml枚举。 go-import – 执行非go文件的自动导入。 gojson – 从示例json文档生成go结构定义。 vfsgen – 生成静态实现给定虚拟文件系统的vfsdata.go文件。 goreuse – 使用包作为通用模板通过替换定义来生成Go代码。 embedfiles – 将文件嵌入Go代码。 ragel – 状态机编译器 peachpy – 嵌入在Python中的x86-64汇编器，生成Go汇编 bundle – Bundle创建适用于包含在特定目标软件包中的源软件包的单一源文件版本。 msgp – MessagePack的Go代码生成器 protobuf – protobuf thriftrw – thrift gogen-avro – avro swagger-gen-types – 从swagger定义中去生成代码 avo – 使用Go生成汇编代码 Wire – Go的编译时依赖注入 sumgen – 从sum-type声明生成接口方法实现 interface-extractor – 生成所需类型的接口，仅在包内使用方法。 deep-copy – 为给定类型创建深度复制方法。 godoc安装 godoc属于golang.org/x/tools/ 根据https://github.com/golang/tools的说法, 最简单的安装: go get -u golang.org/x/tools/... 注意后面的三个点也是要的. 安装完毕后, 在GOPATH的bin下面, 会有很多tools $ ls /repo/yingjieb/go/bin/ authtest callgraph cover findcall gitauth godoc gopackages gotype helper lostcancel present shadow stress toolstash benchcmp compilebench digraph fiximports go-contrib-init goimports gorename goyacc html2article netrcauth present2md splitdwarf stringer unmarshal bundle cookieauth eg getgo godex gomvpkg gostacks guru ifaceassert nilness server ssadump stringintconv 注: go get是先下载后安装packages, 包括依赖的包 godoc使用 在自己的repo下面敲 yingjieb@godev-server /repo/yingjieb/godevsig/compatible $ /repo/yingjieb/go/bin/godoc -http 0.0.0.0:6060 using module mode; GOMOD=/repo/yingjieb/godevsig/compatible/go.mod # 我的repo下面有go.mod, godoc支持gomod yingjieb@godev-server /repo/yingjieb/godevsig/compatible $ ls go.mod LICENSE log msgdriven README.md package通配符和导入路径 package通配符... 比如go get, go install命令最后的packages, 是个import路径. 如果包含特殊的通配格式..., 这个路径就是pattern匹配模式. ...匹配任何字符串, 包括空串. 有两个特例: 结尾的/...匹配任何东西. 比如net/...匹配net net/http ...不匹配vendor. 比如./...不匹配 ./vendor ./mycode/vendor. 想匹配vendor要显式写. 比如./vendor/... 导入路径 支持本地导入路径和远程导入路径 导入路径可以重命名 比如 import \"example.org/pkg/foo\" go get会请求如下的page https://example.org/pkg/foo?go-get=1 (preferred) http://example.org/pkg/foo?go-get=1 (fallback, only with -insecure) 如果取下来的page有如下的元数据 指示example.org实际上是code.org/r/p/exproj, go tool会clone后面这个库, 但路径是example.org the go tool will verify that https://example.org/?go-get=1 contains the same meta tag and then git clone https://code.org/r/p/exproj into GOPATH/src/example.org. go mod模式下, 支持类似的机制: 元数据格式为 obj.function()中obj可以是nil 通常我们会认为如果obj是空指针, 那么这个调用会产生空指针引用, 进而panic. 实际上不是的, obj是nil, 不影响堆function()的调用. 代码如下: type people struct { name string } func (p *people) who() { //注意这一行, 即使p是nil, 这个函数也是会被调用. fmt.Println(\"me\") //访问p.name会panic, 但如果没有下面这一行, 整个程序可以正常执行. //fmt.Println(p.name) } var team map[string]*people = make(map[string]*people) func main() { team[\"wang\"].who() san := people{\"zhang san\"} san.who() } 如何处理? 在C里面, 代码里经常要判断指针是否为空. 那么是不是这里我们也要判断? 答案是不需要. 首先, 如果对象都已经是空了, 说明哪里肯定出了问题. 那不如就让它panic, go会打印调用栈来帮助分析问题. 而为什么在C里面, 我们要判断? 因为C程序只能segmentation fault, 除了coredump没有更多的信息. 而分析coredump成本比较大. 所以C程序员习惯自己来处理空指针错误, 通常也是打印错误. 对于GO程序员, runtime会接管SIGSEGV, 在空指针访问的时候, 自动打印调用栈. 所以, go的理念是: 如果确实有问题, 程序要崩要趁早; 崩在第一现场 切片的reslicing 对于一个切片, 比如ss = [\"stdout\"], 其len为1. 对它进行re slicing的操作ss[1:]是合法的. 即slice[len():len()]是合法的, 比如ss[1:1:1], 本身这样写, 就是矛盾的: 最左边的1要求从1开始, 包括1; 但是中间的1要求到1结束, 不包括1; 最后的1表示只有1个容量. go语法支持这种re slicing, 结果就是len()为0的切片. 再议目录结构 Go 语言项目中的每一个文件目录都代表着一个独立的命名空间，也就是一个单独的包，当我们想要引用其他文件夹的目录时，首先需要使用 import 关键字引入相应的文件目录，再通过 pkg.xxx 的形式引用其他目录定义的结构体、函数或者常量 不要使用src目录 命令行执行程序放在/cmd里: /cmd/server/main.go直接编译出来的文件就是server api定义给外部的接口api └── protobuf-spec └── oceanbookpb ├── oceanbook.pb.go └── oceanbook.proto 参考: 如何写出优雅的 Go 语言代码 具体error判断 下面的代码里, 返回的err不为nil, 但也不好用类型断言来判断err具体类型(可能出错函数直接返回的是errors.New()) 那么还可以通过判断字符串来得到具体的错误, 下面第6行. var err error e.epollFd, err = syscall.EpollCreate(1) switch { case err == nil: break case err.Error() == \"function not implemented\": // Some arch (arm64) do not implement EpollCreate(). if e.epollFd, err = syscall.EpollCreate1(0); err != nil { e.mu.Unlock() return err } default: e.mu.Unlock() return err } 函数赋值给变量 openFileOrig是个函数, 可以直接赋值给变量openFile, 相当于C里面的函数指针. var ( mu sync.Mutex maxSpeed int64 = -1 openFile = openFileOrig ) func openFileOrig(path string, flag int) (io.ReadCloser, error) { f, err := fs.Open(path, flag) if err != nil { return nil, err } return f, nil } gob encode和网络io的结合 goroutine 5 [IO wait]: internal/poll.runtime_pollWait(0x7f1c3dbe3ec8, 0x72, 0xffffffffffffffff) /usr/local/go/src/runtime/netpoll.go:184 +0x55 internal/poll.(*pollDesc).wait(0xc000104218, 0x72, 0x1000, 0x1000, 0xffffffffffffffff) /usr/local/go/src/internal/poll/fd_poll_runtime.go:87 +0x45 internal/poll.(*pollDesc).waitRead(...) /usr/local/go/src/internal/poll/fd_poll_runtime.go:92 internal/poll.(*FD).Read(0xc000104200, 0xc000149000, 0x1000, 0x1000, 0x0, 0x0, 0x0) /usr/local/go/src/internal/poll/fd_unix.go:169 +0x1cf net.(*netFD).Read(0xc000104200, 0xc000149000, 0x1000, 0x1000, 0xc0001c9c50, 0x42e031, 0x5a4478) /usr/local/go/src/net/fd_unix.go:202 +0x4f net.(*conn).Read(0xc000010018, 0xc000149000, 0x1000, 0x1000, 0x0, 0x0, 0x0) /usr/local/go/src/net/net.go:184 +0x68 bufio.(*Reader).Read(0xc0000c86c0, 0xc0000c47d0, 0x1, 0x9, 0x4ad2d8, 0x0, 0x0) /usr/local/go/src/bufio/bufio.go:226 +0x26a io.ReadAtLeast(0x5cb4e0, 0xc0000c86c0, 0xc0000c47d0, 0x1, 0x9, 0x1, 0x6bfea0, 0xc0000fc000, 0x0) /usr/local/go/src/io/io.go:310 +0x87 io.ReadFull(...) /usr/local/go/src/io/io.go:329 encoding/gob.decodeUintReader(0x5cb4e0, 0xc0000c86c0, 0xc0000c47d0, 0x9, 0x9, 0x30, 0x27, 0x0, 0x0) /usr/local/go/src/encoding/gob/decode.go:120 +0x6f encoding/gob.(*Decoder).recvMessage(0xc000104380, 0x0) /usr/local/go/src/encoding/gob/decoder.go:81 +0x57 encoding/gob.(*Decoder).decodeTypeSequence(0xc000104380, 0xc0000c6000, 0x59b95d) /usr/local/go/src/encoding/gob/decoder.go:143 +0x10c encoding/gob.(*Decoder).DecodeValue(0xc000104380, 0x54f1c0, 0xc0000ad900, 0x16, 0x0, 0x0) /usr/local/go/src/encoding/gob/decoder.go:211 +0x10b encoding/gob.(*Decoder).Decode(0xc000104380, 0x54f1c0, 0xc0000ad900, 0x0, 0x0) /usr/local/go/src/encoding/gob/decoder.go:188 +0x16d main.inputDispacher(0x5cdb60, 0xc0000d7840, 0x5cec80, 0xc000010018) /repo/yingjieb/godev/practice/src/tools/topid.go:334 +0x12d created by main.main /repo/yingjieb/godev/practice/src/tools/topid.go:558 +0xe22 单步decoder.Decode(&msg) gob decode使用了反射 gob是二进制编码, 在解码时, 先从io stream读出count, 再根据count读出对应的字节数来解码. var msg messageIn dec.Decode(&msg) // 入参e interface{}被赋值为&msg value := reflect.ValueOf(e) //value.Type().Kind() 必须是reflect.Ptr dec.DecodeValue(value) //入参v reflect.Value被赋值为value dec.mutex.Lock() defer dec.mutex.Unlock() dec.buf.Reset() dec.err = nil id := dec.decodeTypeSequence(false) for dec.err == nil if dec.buf.Len() == 0 if !dec.recvMessage() //先从底层io.Reader读count, 再按照count读具体的字节数 比如典型的:n, err := io.ReadFull(r, buf[0:1]) b := buf[0] // gob编码中, 小于128的用一个字节表示 if b protobuf里面oneof转成go结构体 oneof对应go结构里的interface, 并且自动生成isMessageName_MyField的interface, 和响应格式的签名方法 自动生成GetXxx方法 生成的结构体里面还有些隐藏的字段:XXX_开头的, 可能是protobuf自己用的. 参考: https://developers.google.com/protocol-buffers/docs/reference/go-generated proto定义 // Messages specifically used to retrieve and configure BIP PM counters for GPON message GPONBIPWrapper { string onu_name = 1; // vOnuMgmt -> vProxy uint32 chnl_term_id = 2; // vProxy -> Device (to be changed later to chnl_term_name) uint32 onu_id = 3; // vProxy -> Device oneof msg { ConfigureBERInterval config_ber_interval = 4; // vOnuMgmt -> vProxy -> Device ConfigureBERIntervalResponse config_ber_interval_response = 5; // Device -> vProxy -> vOnuMgmt GetBIPCounters get_bip_counters = 6; // vOnuMgmt -> vProxy -> Device GetBIPCountersResponse get_bip_counters_response = 7; // Device -> vProxy -> vOnuMgmt } } 转成的结构体 // Messages specifically used to retrieve and configure BIP PM counters for GPON type GPONBIPWrapper struct { OnuName string `protobuf:\"bytes,1,opt,name=onu_name,json=onuName,proto3\" json:\"onu_name,omitempty\"` ChnlTermId uint32 `protobuf:\"varint,2,opt,name=chnl_term_id,json=chnlTermId,proto3\" json:\"chnl_term_id,omitempty\"` OnuId uint32 `protobuf:\"varint,3,opt,name=onu_id,json=onuId,proto3\" json:\"onu_id,omitempty\"` // Types that are valid to be assigned to Msg: // *GPONBIPWrapper_ConfigBerInterval // *GPONBIPWrapper_ConfigBerIntervalResponse // *GPONBIPWrapper_GetBipCounters // *GPONBIPWrapper_GetBipCountersResponse Msg isGPONBIPWrapper_Msg `protobuf_oneof:\"msg\"` XXX_NoUnkeyedLiteral struct{} `json:\"-\"` XXX_unrecognized []byte `json:\"-\"` XXX_sizecache int32 `json:\"-\"` } type isGPONBIPWrapper_Msg interface { isGPONBIPWrapper_Msg() } func (*GPONBIPWrapper_ConfigBerInterval) isGPONBIPWrapper_Msg() {} func (*GPONBIPWrapper_ConfigBerIntervalResponse) isGPONBIPWrapper_Msg() {} func (*GPONBIPWrapper_GetBipCounters) isGPONBIPWrapper_Msg() {} func (*GPONBIPWrapper_GetBipCountersResponse) isGPONBIPWrapper_Msg() {} func (m *GPONBIPWrapper) GetMsg() isGPONBIPWrapper_Msg { if m != nil { return m.Msg } return nil } "},"notes/golang_杂记3.html":{"url":"notes/golang_杂记3.html","title":"杂记3","keywords":"","body":" go按位取反(bitwise not) go的相等性(==) 普通类型的比较 指针的相等性 channel的相等性 interface的相等性 结构体的相等性 Array的相等性 string []byte用bytes.Equal比较 reflect.DeepEqual万能比较 cmp包 通过unix socket发送fd 发送 接收 发送2 接收2 创建临时文件并mmap成结构体 memfd_create()系统调用 gvisor中的使用场景 用正则表达式 遍历/proc/self/maps 递归缩进打印error 读go micro cmd cmd.APP() 已经注册的cmd cli相关的cmd cli子命令 client接口 pattern match 读fs_linux.go 善用字符串库函数--strings.Join 切片的插入 匿名函数执行 go按位取反(bitwise not) go没有专用的取反操作符, 但用异或可以取反: func main() { var bitwisenot byte = 0x0F // printing the number in 8-Bit fmt.Printf(\"%08b\\n\", bitwisenot) // 00001111 fmt.Printf(\"%08b\\n\", ^bitwisenot) // 11110000 fmt.Printf(\"%08b\\n\", 1^bitwisenot) // 00001110 和上面结果不一样 fmt.Printf(\"%08b\\n\", ^0x0F) // -0010000 默认数字都是int fmt.Printf(\"%08b\\n\", ^(int)(0x0F)) // -0010000 fmt.Printf(\"%08b\\n\", ^(uint)(0x0F)) // 1111111111111111111111111111111111111111111111111111111111110000 不带符号位 } 结果: 00001111 11110000 00001110 -0010000 -0010000 1111111111111111111111111111111111111111111111111111111111110000 go的相等性(==) 首先, map和slice不能用==比较 function也不能比较. f := func(int) int { return 1 } g := func(int) int { return 2 } f == g //这样比较会编译错误 但function可以跟nil比较. 普通类型的比较 boo, int, float, complex的比较就是普通比较. 但需要注意的是float的NaN不等于NaN nan := math.NaN() pos_inf := math.Inf(1) neg_inf := math.Inf(-1) fmt.Println(nan == nan) // false fmt.Println(pos_inf == pos_inf) // true fmt.Println(neg_inf == neg_inf) // true fmt.Println(pos_inf == neg_inf) // false 指针的相等性 要么两个指针都是nil, 要么两个指针指向同样的地址: var p1, p2 *string name := \"foo\" fmt.Println(p1 == p2) // true p1 = &name p2 = &name fmt.Println(p1) // 0x40c148 fmt.Println(p2) // 0x40c148 fmt.Println(&p1) // 0x40c138 fmt.Println(&p2) // 0x40c140 fmt.Println(*p1) // foo fmt.Println(*p2) // foo fmt.Println(p1 == p2) // true 需要注意的是, 两个不同的empty struct(即空的struct实例)的地址可能相等 A struct or array type has size zero if it contains no fields (or elements, respectively) that have a size greater than zero. Two distinct zero-size variables may have the same address in memory. type S struct{} func main() { var p1, p2 *S s1 := S{} s2 := S{} p1 = &s1 p2 = &s2 fmt.Printf(\"%p\\n\", p1) // 0x1e52bc fmt.Printf(\"%p\\n\", p2) // 0x1e52bc fmt.Println(p1) // &{} fmt.Println(p2) // &{} fmt.Println(&p1) // 0x40c138 fmt.Println(&p2) // 0x40c140 fmt.Println(*p1) // {} fmt.Println(*p2) // {} fmt.Println(p1 == p2) // true 本来s1和s2不是一个东西, 当都是空, 他们的地址相同, 所以相等. } 如果结构体非空, S struct {f int}, p1和p2就不相等了. channel的相等性 满足下面条件之一 两个chnnel都是nil 两个都是从同一个make函数生成的 func f(ch1 chan int, ch2 *chan int) { fmt.Println(ch1 == *ch2) // true } func main() { var ch1, ch2 chan int fmt.Println(ch1 == ch2) // true ch1 = make(chan int) ch2 = make(chan int) fmt.Println(ch1 == ch2) // false ch2 = ch1 fmt.Printf(\"%p\\n\", &ch1) // 0x40c138 fmt.Printf(\"%p\\n\", &ch2) // 0x40c140 fmt.Println(ch1 == ch2) // true f(ch1, &ch1) } interface的相等性 两个interface都是nil(注意动态类型也要是nil)type I interface{ m() } type T []byte func (t T) m() {} func main() { var t T fmt.Println(t == nil) // true var i I = t fmt.Println(i == nil) // false fmt.Println(reflect.TypeOf(i)) // main.T fmt.Println(reflect.ValueOf(i).IsNil()) // true } 动态类型相同, 并且动态值相等type A int type B = A type C int type I interface{ m() } func (a A) m() {} func (c C) m() {} func main() { var a I = A(1) var b I = B(1) var c I = C(1) fmt.Println(a == b) // true 这里A和B是强别名(=号别名), 类型是一样的. fmt.Println(b == c) // false 类型不同不相等 fmt.Println(a == c) // false 类型不同不相等 } 类型I的interface变量i可以和普通类型X的实例x比较, 只要 类型X实现了接口I 类型X可以比较 所以i和x比较, 如果i的动态类型是X, i的动态值又等于x, 那么i和x相等 type I interface{ m() } type X int func (x X) m() {} type Y int func (y Y) m() {} type Z int func main() { var i I = X(1) fmt.Println(i == X(1)) // true fmt.Println(i == Y(1)) // false // fmt.Println(i == Z(1)) // mismatched types I and C // fmt.Println(i == 1) // mismatched types I and int } 如果动态类型相等, 但这个类型不能比较, 则会产生panic: type A []byte func main() { var i interface{} = A{} var j interface{} = A{} fmt.Println(i == j) } panic: runtime error: comparing uncomparable type main.A 如果动态类型不一样, 那就直接不等: type A []byte type B []byte func main() { // A{} == A{} // slice can only be compared to nil var i interface{} = A{} var j interface{} = B{} fmt.Println(i == j) // false } 结构体的相等性 首先, 结构体可以直接用==操作符比较. 如果里面的非_域都相等, 则两个结构体相等. 注意, 结构体里面的大写, 小写域都要相等. type A struct { _ float64 f1 int F2 string } type B struct { _ float64 f1 int F2 string } func main() { fmt.Println(A{1.1, 2, \"x\"} == A{0.1, 2, \"x\"}) // true // fmt.Println(A{} == B{}) // mismatched types A and B } 当判断x==y时, 只有x可以赋值给y或者y可以赋值给x才能用==操做符. 所以下面的判断是不行的, 编译时就会报错. A{} == B{} Array的相等性 注意这里说的是Array, 不是slice. Array里面的每个元素都相等的话, 两个array相等. type T struct { name string age int _ float64 } func main() { x := [...]float64{1.1, 2, 3.14} fmt.Println(x == [...]float64{1.1, 2, 3.14}) // true y := [1]T{{\"foo\", 1, 0}} fmt.Println(y == [1]T{{\"foo\", 1, 1}}) // true } string string的比较按照[]byte按字节比较. fmt.Println(strings.ToUpper(\"ł\") == \"Ł\") // true fmt.Println(\"foo\" == \"foo\") // true fmt.Println(\"foo\" == \"FOO\") // false fmt.Println(\"Michał\" == \"Michal\") // false fmt.Println(\"żondło\" == \"żondło\") // true fmt.Println(\"żondło\" != \"żondło\") // false fmt.Println(strings.EqualFold(\"ąĆź\", \"ĄćŹ\")) // true []byte用bytes.Equal比较 切片不能直接比较. 但bytes.Equal可以比较两个[]byte s1 := []byte{'f', 'o', 'o'} s2 := []byte{'f', 'o', 'o'} fmt.Println(bytes.Equal(s1, s2)) // true s2 = []byte{'b', 'a', 'r'} fmt.Println(bytes.Equal(s1, s2)) // false s2 = []byte{'f', 'O', 'O'} fmt.Println(bytes.EqualFold(s1, s2)) // true s1 = []byte(\"źdźbło\") s2 = []byte(\"źdŹbŁO\") fmt.Println(bytes.EqualFold(s1, s2)) // true s1 = []byte{} s2 = nil fmt.Println(bytes.Equal(s1, s2)) // true reflect.DeepEqual万能比较 func DeepEqual(x, y interface{}) bool可以比较任意两个值. 比如map m1 := map[string]int{\"foo\": 1, \"bar\": 2} m2 := map[string]int{\"foo\": 1, \"bar\": 2} // fmt.Println(m1 == m2) // map can only be compared to nil fmt.Println(reflect.DeepEqual(m1, m2)) // true m2 = map[string]int{\"foo\": 1, \"bar\": 3} fmt.Println(reflect.DeepEqual(m1, m2)) // false m3 := map[string]interface{}{\"foo\": [2]int{1,2}} m4 := map[string]interface{}{\"foo\": [2]int{1,2}} fmt.Println(reflect.DeepEqual(m3, m4)) // true var m5 map[float64]string fmt.Println(reflect.DeepEqual(m5, nil)) // false fmt.Println(m5 == nil) // true 比如slice s := []string{\"foo\"} fmt.Println(reflect.DeepEqual(s, []string{\"foo\"})) // true fmt.Println(reflect.DeepEqual(s, []string{\"bar\"})) // false s = nil fmt.Println(reflect.DeepEqual(s, []string{})) // false s = []string{} fmt.Println(reflect.DeepEqual(s, []string{})) // true 比如结构体 type T struct { name string Age int } func main() { t := T{\"foo\", 10} fmt.Println(reflect.DeepEqual(t, T{\"bar\", 20})) // false fmt.Println(reflect.DeepEqual(t, T{\"bar\", 10})) // false fmt.Println(reflect.DeepEqual(t, T{\"foo\", 10})) // true } cmp包 google提供了cmp包, 可以打印两个值的差异 import ( \"fmt\" \"github.com/google/go-cmp/cmp\" ) type T struct { Name string Age int City string } func main() { x := T{\"Michał\", 99, \"London\"} y := T{\"Adam\", 88, \"London\"} if diff := cmp.Diff(x, y); diff != \"\" { fmt.Println(diff) } } 输出 main.T{ - Name: \"Michał\", + Name: \"Adam\", - Age: 99, + Age: 88, City: \"London\", } 通过unix socket发送fd gvisor的pkg/unet/unet.go里面提供了listen, accept等方法 unet是给server端用的. 比如read和write方法, 先尝试用阻塞式的unix.RawSyscall(unix.SYS_RECVMSG, ...), 不行再用对fd的pollunix.Syscall6(unix.SYS_PPOLL, ...) 还提供了通过unix socket发送/接收fd的方法: // PackFDs packs the given list of FDs in the control message. // // This must be used prior to WriteVec. func (c *ControlMessage) PackFDs(fds ...int) { *c = ControlMessage(unix.UnixRights(fds...)) } // ExtractFDs returns the list of FDs in the control message. // // Either this or CloseFDs should be used after EnableFDs. func (c *ControlMessage) ExtractFDs() ([]int, error) { msgs, err := unix.ParseSocketControlMessage(*c) if err != nil { return nil, err } var fds []int for _, msg := range msgs { thisFds, err := unix.ParseUnixRights(&msg) if err != nil { // Different control message. return nil, err } for _, fd := range thisFds { if fd >= 0 { fds = append(fds, fd) } } } return fds, nil } 被extract出来的fd可以用比如下面的函数来生成一个File对象. //比如调用 os.NewFile(uintptr(fd), \"urpc\") // NewFile returns a new File with the given file descriptor and // name. The returned value will be nil if fd is not a valid file // descriptor. On Unix systems, if the file descriptor is in // non-blocking mode, NewFile will attempt to return a pollable File // (one for which the SetDeadline methods work). // // After passing it to NewFile, fd may become invalid under the same // conditions described in the comments of the Fd method, and the same // constraints apply. func NewFile(fd uintptr, name string) *File 发送 //@pkg/lisafs/sock.go // writeTo writes the passed iovec to the UDS and donates any passed FDs. func writeTo(sock *unet.Socket, iovec [][]byte, dataLen int, fds []int) error { w := sock.Writer(true) //这里的fds是可选的, 会做为control msg来发送 if len(fds) > 0 { w.PackFDs(fds...) } for n := 0; n 接收 //@pkg/lisafs/sock.go // readFrom fills the passed buffer with data from the socket. It also returns // any donated FDs. func readFrom(sock *unet.Socket, buf []byte, wantFDs uint8) ([]int, error) { r := sock.Reader(true) r.EnableFDs(int(wantFDs)) n := len(buf) for got := 0; got 发送2 //@pkg/urpc/urpc.go // marshal sends the given FD and json struct. func marshal(s *unet.Socket, v interface{}, fs []*os.File) error { // Marshal to a buffer. data, err := json.Marshal(v) if err != nil { log.Warningf(\"urpc: error marshalling %s: %s\", fmt.Sprintf(\"%v\", v), err.Error()) return err } // Write to the socket. w := s.Writer(true) if fs != nil { var fds []int for _, f := range fs { fds = append(fds, int(f.Fd())) } w.PackFDs(fds...) } ... } 接收2 //@pkg/urpc/urpc.go // unmarhsal receives an FD (optional) and unmarshals the given struct. func unmarshal(s *unet.Socket, v interface{}) ([]*os.File, error) { // Receive a single byte. r := s.Reader(true) r.EnableFDs(maxFiles) firstByte := make([]byte, 1) // Extract any FDs that may be there. if _, err := r.ReadVec([][]byte{firstByte}); err != nil { return nil, err } fds, err := r.ExtractFDs() ... } 创建临时文件并mmap成结构体 memfd_create()系统调用 #include int memfd_create(const char *name, unsigned int flags); 用tmpfs创建一个临时文件, 这个文件和通常文件系统没关系, 但可以支持所有文件操做. 可以用这个文件来共享内存: 进程A调用memfd_create(), 返回fd 进程B去打开/proc//fd/(pid是进程A的pid, fd是A调用memfd_create()返回的fd号.), 打开后可以mmap, 就看到进程A一样的内容了. gvisor中的使用场景 //RTMemoryStats是要被mmap的结构体 // RTMemoryStatsSize is the size of the RTMemoryStats struct. var RTMemoryStatsSize = unsafe.Sizeof(RTMemoryStats{}) // RTMemoryStatsPointer casts addr to a RTMemoryStats pointer. func RTMemoryStatsPointer(addr uintptr) *RTMemoryStats { return (*RTMemoryStats)(unsafe.Pointer(addr)) } const name = \"memory-usage\" fd, err := memutil.CreateMemFD(name, 0) p, err := unix.BytePtrFromString(name) fd, _, e := unix.Syscall(unix.SYS_MEMFD_CREATE, uintptr(unsafe.Pointer(p)), uintptr(flags), 0) file := os.NewFile(uintptr(fd), name) //设置文件大小为结构体RTMemoryStatsSize的大小 file.Truncate(int64(RTMemoryStatsSize)) //mmap这个文件 mmap, err := memutil.MapFile(0, RTMemoryStatsSize, unix.PROT_READ|unix.PROT_WRITE, unix.MAP_SHARED, file.Fd(), 0) //现在全局变量MemoryAccounting.RTMemoryStats就指向了这个文件. //直接用那个结构体不香吗? MemoryAccounting = &MemoryLocked{ File: file, RTMemoryStats: RTMemoryStatsPointer(mmap), } 用正则表达式 遍历/proc/self/maps 比如一个程序想解析当前进程的进程空间: $ cat /proc/self/maps 55cb9cb6b000-55cb9cb73000 r-xp 00000000 fc:02 396 /bin/cat 55cb9cd72000-55cb9cd73000 r--p 00007000 fc:02 396 /bin/cat 55cb9cd73000-55cb9cd74000 rw-p 00008000 fc:02 396 /bin/cat 55cb9e7a2000-55cb9e7c3000 rw-p 00000000 00:00 0 [heap] 7f3367281000-7f336754d000 r--p 00000000 fc:02 7228 /usr/lib/locale/locale-archive 7f336754d000-7f3367734000 r-xp 00000000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f3367734000-7f3367934000 ---p 001e7000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f3367934000-7f3367938000 r--p 001e7000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f3367938000-7f336793a000 rw-p 001eb000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f336793a000-7f336793e000 rw-p 00000000 00:00 0 7f336793e000-7f3367967000 r-xp 00000000 fc:02 44717 /lib/x86_64-linux-gnu/ld-2.27.so 7f3367b33000-7f3367b57000 rw-p 00000000 00:00 0 7f3367b67000-7f3367b68000 r--p 00029000 fc:02 44717 /lib/x86_64-linux-gnu/ld-2.27.so 7f3367b68000-7f3367b69000 rw-p 0002a000 fc:02 44717 /lib/x86_64-linux-gnu/ld-2.27.so 7f3367b69000-7f3367b6a000 rw-p 00000000 00:00 0 7fff4ad74000-7fff4ad95000 rw-p 00000000 00:00 0 [stack] 7fff4adda000-7fff4addd000 r--p 00000000 00:00 0 [vvar] 7fff4addd000-7fff4addf000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] 可以用regex // mapsLine matches a single line from /proc/PID/maps. var mapsLine = regexp.MustCompile(\"([0-9a-f]+)-([0-9a-f]+) ([r-][w-][x-][sp]) ([0-9a-f]+) [0-9a-f]{2,3}:[0-9a-f]{2,} [0-9]+\\\\s+(.*)\") func parseMaps() { f, err := os.Open(\"/proc/self/maps\") r := bufio.NewReader(f) for { b, err := r.ReadBytes('\\n') m := mapsLine.FindSubmatch(b) start, err := strconv.ParseUint(string(m[1]), 16, 64) end, err := strconv.ParseUint(string(m[2]), 16, 64) read := m[3][0] == 'r' write := m[3][1] == 'w' execute := m[3][2] == 'x' shared := m[3][3] == 's' offset, err := strconv.ParseUint(string(m[4]), 16, 64) } } 递归缩进打印error type vmError struct { self error children []error } func (vme vmError) Error() string { var b strings.Builder fmt.Fprintf(&b, \"----\\n\") if vme.self != nil { fmt.Fprintf(&b, \"%v\\n\", vme.self) } for _, err := range vme.children { for _, s := range strings.Split(err.Error(), \"\\n\") { if s != \"\\tat -\" { fmt.Fprintf(&b, \"\\t%s\\n\", s) } } } return b.String() } 读go micro cmd micro的入口命令, 只调用了一个函数 这里import中的的v2选择了v2的tag. package main import ( \"github.com/micro/micro/v2/cmd\" ) func main() { cmd.Init() } 这里的Init原型很特别: cmd/cmd.go中, // Init initialised the command line func Init(options ...micro.Option) { Setup(cmd.App(), options...) cmd.Init( cmd.Name(name), cmd.Description(description), cmd.Version(buildVersion()), ) } 这里面的Option是type Option func(*Options), 一个函数签名, 入参是*Options Options是个巨大的结构体, 包含了所有的micro的概念. type Options struct { Auth auth.Auth Broker broker.Broker Cmd cmd.Cmd Config config.Config Client client.Client Server server.Server Store store.Store Registry registry.Registry Runtime runtime.Runtime Transport transport.Transport Profile profile.Profile // Before and After funcs BeforeStart []func() error BeforeStop []func() error AfterStart []func() error AfterStop []func() error // Other options for implementations of the interface // can be stored in a context Context context.Context Signal bool } cmd.APP() func App() *cli.App { //这里的DefaultCmd是个interface, 由newCmd实例化 //即var DefaultCmd = newCmd() return DefaultCmd.App() } type cmd struct { opts Options app *cli.App } //newCmd返回的是Cmd这个interface func newCmd(opts ...Option) Cmd { //实际的cmd是上面的结构体 cmd := new(cmd) cmd.opts = options cmd.app = cli.NewApp() //返回cmd实例, 但从外面看起来是Cmd interface return cmd } //综上, DefaultCmd.App()实际上就是 func (c *cmd) App() *cli.App { return c.app } //那么c.app实际上就是cli.NewApp()的实例化结果. 上面的cli.NewApp()在github.com/micro/cli/v2, 它实际上是urfave/cli的fork. 已经注册的cmd cmd/cmd.go app.Commands = append(app.Commands, new.Commands()...) app.Commands = append(app.Commands, runtime.Commands(options...)...) app.Commands = append(app.Commands, store.Commands(options...)...) app.Commands = append(app.Commands, config.Commands(options...)...) app.Commands = append(app.Commands, api.Commands(options...)...) app.Commands = append(app.Commands, auth.Commands()...) app.Commands = append(app.Commands, bot.Commands()...) app.Commands = append(app.Commands, cli.Commands()...) app.Commands = append(app.Commands, broker.Commands(options...)...) app.Commands = append(app.Commands, health.Commands(options...)...) app.Commands = append(app.Commands, proxy.Commands(options...)...) app.Commands = append(app.Commands, router.Commands(options...)...) app.Commands = append(app.Commands, tunnel.Commands(options...)...) app.Commands = append(app.Commands, network.Commands(options...)...) app.Commands = append(app.Commands, registry.Commands(options...)...) app.Commands = append(app.Commands, debug.Commands(options...)...) app.Commands = append(app.Commands, server.Commands(options...)...) app.Commands = append(app.Commands, service.Commands(options...)...) app.Commands = append(app.Commands, build.Commands()...) app.Commands = append(app.Commands, web.Commands(options...)...) cli相关的cmd cli除了注册了自己的cmd, 还注册了call stream publish等命令. 而且cli.Commands()中, cli命令本身和所有的子命令都是同级的. 只是cli被安排在了第一个 func Commands() []*cli.Command { commands := []*cli.Command{ { Name: \"cli\", Usage: \"Run the interactive CLI\", Action: Run, }, { Name: \"call\", Usage: \"Call a service e.g micro call greeter Say.Hello '{\\\"name\\\": \\\"John\\\"}\", //注意这里的Print是个闭包函数, 返回callService的包装. 类似装饰器 Action: Print(callService), Flags: []cli.Flag{ &cli.StringFlag{ Name: \"address\", Usage: \"Set the address of the service instance to call\", EnvVars: []string{\"MICRO_ADDRESS\"}, }, &cli.StringFlag{ Name: \"output, o\", Usage: \"Set the output format; json (default), raw\", EnvVars: []string{\"MICRO_OUTPUT\"}, }, &cli.StringSliceFlag{ Name: \"metadata\", Usage: \"A list of key-value pairs to be forwarded as metadata\", EnvVars: []string{\"MICRO_METADATA\"}, }, }, }, ... } } cli命令对应的Action是Run. 这个Run是个典型的Read-Eval-Print-Loop, 基本上是 for { //先readline() args, err := r.Readline() //准备参数 args = strings.TrimSpace(args) parts := strings.Split(args, \" \") //找到cmd cmd, ok := commands[name] //执行cmd rsp, err := cmd.exec(c, parts[1:]) println(string(rsp)) } micro的交互式cli很简单, 就是在顶层有个循环来readline, 执行cmd. 没有其他功能. cli子命令 这些子命令, 比如call, publish, 实际调用的是internal/command/cli/command.go中的 func CallService(c *cli.Context, args []string) ([]byte, error) { 参数和返回值都通过json格式编码 d := json.NewDecoder(strings.NewReader(req)) ctx := callContext(c) creq := (*cmd.DefaultOptions().Client).NewRequest(service, endpoint, request, client.WithContentType(\"application/json\")) //实际调用的是client的call接口, 这是个同步调用, 发req, 等rsp err = (*cmd.DefaultOptions().Client).Call(ctx, creq, &rsp, opts...) //等待rsp并打印结果. } client接口 client是micro的核心抽象, 接口定义如下: // Client is the interface used to make requests to services. // It supports Request/Response via Transport and Publishing via the Broker. // It also supports bidirectional streaming of requests. type Client interface { Init(...Option) error Options() Options NewMessage(topic string, msg interface{}, opts ...MessageOption) Message NewRequest(service, endpoint string, req interface{}, reqOpts ...RequestOption) Request Call(ctx context.Context, req Request, rsp interface{}, opts ...CallOption) error Stream(ctx context.Context, req Request, opts ...CallOption) (Stream, error) Publish(ctx context.Context, msg Message, opts ...PublishOption) error String() string } client支持Req/Rsp(通过Transport抽象), 支持Pub/Sub(通过Broker)抽象, 还支持stream模式. pattern match 简单的*通配符匹配 func patternMatchs(str, pattern string) bool { if len(pattern) == 0 { return false } strs := strings.Split(pattern, \"*\") //fmt.Println(strs, len(strs)) var pos, index int if index = strings.Index(str, strs[0]); index != 0 { return false } end := strs[len(strs)-1] if index = strings.LastIndex(str, end); index+len(end) != len(str) { return false } for i, substr := range strs { if i == 0 || i == len(strs)-1 || len(substr) == 0 { continue } index = strings.Index(str[pos:], substr) if index == -1 { return false } pos += index + len(substr) } return true } 读fs_linux.go periph.io/x/periph@v3.6.2+incompatible/host/sysfs/fs_linux.go 善用字符串库函数--strings.Join 比如解析或|关系, 普通的思路是自己组类似flag1|flag2|flag3的字符串. 实际上, 下面的代码片段先把flag1 flag2 flag3分别append到[]string切片, 最后用strings.Join(out, \"|\")加或|操作符. func (e epollEvent) String() string { var out []string for _, b := range bitmaskString { if e&b.e != 0 { out = append(out, b.s) e &^= b.e } } if e != 0 { out = append(out, \"0x\"+strconv.FormatUint(uint64(e), 16)) } if len(out) == 0 { out = []string{\"0\"} } return strings.Join(out, \"|\") } 切片的插入 这个切片是个二叉树的顺序表的表达, 和sort包的思路一致. 先找到r.Name的位置i, 然后用append一个nil的方式把切片扩一个位置出来, 然后用内置的copy函数把i后面的元素往后都挪一个位置; 最后把位置i的元素填上. 为了把位置i后面的元素都挪一个位置, 代价是把这后面的所有元素都copy一遍 这里的copy实际上是overlap的, copy的时候, 源为l[i:], 目的是l[i+1:], 目的比源向后移动一个位置, 而且目的的元素个数也少了一个. 注意, 如果按照普通的for循环式的copy思路, src和dst重叠时不能正常工作的. 有人讨论说golang的copy语义类似memmove memcpy: 当src和dst重叠时, 结果不确定 memmove: src和dst可以重叠, 结果是正确的拷贝; 可以理解成有个临时缓冲做中转. 实际上并不需要中间buffer, 只需要在开始的时候判断是从前往后拷贝还是从后往前拷贝就行了. 结论: golang的copy支持overlap, 可以正确的拷贝 func insertRef(l []*Ref, r *Ref) []*Ref { n := r.Name i := search(len(l), func(i int) bool { return l[i].Name > n }) l = append(l, nil) copy(l[i+1:], l[i:]) l[i] = r return l } 下面是对应的快排 注意在search函数里, 并不需要传入要查找的切片; search调用f的时候, f会比较切片元素, f会访问切片. 在本例中, f能访问insertRef函数的l []*Ref变量, 这也是一种闭包形式? // search implements the same algorithm as sort.Search(). // // It was extracted to to not depend on sort, which depends on reflect. func search(n int, f func(int) bool) int { lo := 0 for hi := n; lo > 1); !f(i) { lo = i + 1 } else { hi = i } } return lo } 匿名函数执行 下面的例子中, 匿名行数在定义后就执行, 就像普通的代码块执行一样: 变量r和err都能直接被匿名函数引用到. 那为什么要用func(){}()这种形式呢? 首先, 匿名函数也是要函数栈的, 多了匿名函数性能上不会更好; 但是, 因为遍历全局的map byName byNumber 有锁操作, 那么使用匿名函数配合defer关键词来加锁和解锁, 代码更优雅. 如果不要这个匿名的壳子, 要么不用defer, 自己找地方加unlock; 还想用defer的话, defer会在r.Open()后执行. 估计这里的逻辑是: 一定要在r.Open()前unlock func Open(name string) (i2c.BusCloser, error) { var r *Ref var err error func() { mu.Lock() defer mu.Unlock() if len(byName) == 0 { err = errors.New(\"i2creg: no bus found; did you forget to call Init()?\") return } if len(name) == 0 { r = getDefault() return } // Try by name, by alias, by number. if r = byName[name]; r == nil { if r = byAlias[name]; r == nil { if i, err2 := strconv.Atoi(name); err2 == nil { r = byNumber[i] } } } }() if err != nil { return nil, err } if r == nil { return nil, errors.New(\"i2creg: can't open unknown bus: \" + strconv.Quote(name)) } return r.Open() } "},"notes/golang_高效go.html":{"url":"notes/golang_高效go.html","title":"高效go","keywords":"","body":" 高效go web服务器例子 代码 运行 panic流程和普通执行流程 panic recover recover里面可以改变量值 总结 错误处理 error定义和使用 errors包 自己实现error接口 error和类型断言的例子 进一步看error如何返回的 错误处理化简 channel和并发 channel channel用于同步 channel用于semaphore 一个channel有多个goroutine接收 函数和channel都是first class值: channel in channel 通道in通道的另一个例子 分割和并发 用channel管理message buffer 接口嵌套 结构体嵌套 例子 logger 接口和方法 即使一个int类型也可以带方法 chan带方法 函数也可以带方法!!! 多态 接口和类型断言 方法 接口 gofmt 注释即文档 if可以有初始化语句 for是三种C循环的统一 switch接受非常量 多返回值 defer 用defer做函数trace 在panic场景下, defer的最大好处是panic链上的defer都会被调用到 new和make分配数据 new 数组和切片的区别 make 数组 切片 map 打印 append和...扩展 全局变量初始化和init 高效go https://golang.org/doc/effective_go.html#concurrency web服务器例子 这个web服务器, 利用了chart.apis.google.com提供的api, 把文本转化成二维码. 但你需要把data都放到URL中去做query. 代码 下面的代码, 可以把文本的输入, 通过google的api, 转换成一个QR code. 然后你就可以用手机扫描这个文本类型的QR码, 就能看到对应的文本 package main //这几个库都是标准库 import ( \"flag\" \"html/template\" \"log\" \"net/http\" ) //这里设置默认的http port是1718 var addr = flag.String(\"addr\", \":1718\", \"http service address\") // Q=17, R=18 //根据下面的描述生成模板, 这个模板html被server执行来显示这个页面 var templ = template.Must(template.New(\"qr\").Parse(templateStr)) func main() { flag.Parse() //把函数QR挂到http的根目录 http.Handle(\"/\", http.HandlerFunc(QR)) //开始运行这个server err := http.ListenAndServe(*addr, nil) //QR函数接收到http的request, 里面包含了data if err != nil { log.Fatal(\"ListenAndServe:\", err) } } func QR(w http.ResponseWriter, req *http.Request) { //data从一个叫s的表格而来 templ.Execute(w, req.FormValue(\"s\")) } // html/template很强大, 这里只用了一点点. // 它把req.FormValue(\"s\")返回来的data, 写入下面的模板中 const templateStr = ` QR Link Generator {{if .}} {{.}} {{end}} 具体的template用法在此 运行 #把上面的代码保存为goweb.go #代码格式化 gofmt -w goweb.go #编译 go build goweb.go #直接运行 ./goweb 浏览器打开http://192.168.56.101:1718/, 这个ip就是运行goweb的机器的ip. 会有个很简单的输入框, 输入一些文本后点Show QR就能显示二维码 手机扫描二维码就能还原文本. panic流程和普通执行流程 比如下面的流程: a{ b{ defer c{ recover() }() d{ e{ } f{ } } } g{ } } 比如d()里面panic了 正常的执行流程, 是有上有下的: 先深度执行到f(), 然后return路径沿途返回 panic流程一定是一直向上的, 如果沿途的defer里面没有recover, panic流程向上回溯到这个goroutine的顶层函数停止. 比如在e()里面panic, 它后面的函数就不执行了, 直接向上回溯, 而且只有沿途的defer函数会被执行: While executing a function F, an explicit call to panic or a run-time panic terminates the execution of F. Any functions deferred by F are then executed as usual. Next, any deferred functions run by F's caller are run, and so on up to any deferred by the top-level function in the executing goroutine. At that point, the program is terminated and the error condition is reported, including the value of the argument to panic. This termination sequence is called panicking. recover()阻止了panic的向上的流程, 还是比如e()中panic了, 但在b()的defer列表里, 要执行的c()里面recover, 那么b()正常返回到a(), 接着正常向下执行g() panic panic是go的内建函数, 用于在程序无法运行下去的时候退出 var user = os.Getenv(\"USER\") func init() { if user == \"\" { panic(\"no value for $USER\") } } 那么panic的时候, 执行了什么? panic立即终止执行当前的函数, 向上回溯当前goroutine的调用栈, 依次执行沿途的deferred函数, 然后die. 什么时候隐含有panic? 比如: 类型断言失败, 且没有用ok捕捉第二个返回值 slice越界 recover 可以在panic之后, 用recover恢复go的控制权. 这要求recover要在defer的函数里执行, 因为只有沿途的deferred函数会被panic执行. 在这个例子中: server的一个worker挂了, 调用了panic, 在它的defer函数里, 用recover重新获取执行权. recover函数停止panic发起的unwinding调用栈, 返回当时传给panic的参数. 这里recover停止panic, 效果是干净的关闭失败的goroutine, 其他的goroutien不受影响. recover只在defer的函数里调用才有用. 不是defer的函数, recover什么都不做, 直接返回nil. func server(workChan 注意, 上面的表述中, recover只有在defer的函数里面被调用, 才能生效. 比如下面的代码, recover()什么都不做. 因为它本身就是defer的函数, 而不是被defer的函数调用. package main func main() { defer recover() panic(\"panic\") } 正确的写法是 package main func main() { defer func() { recover() }() panic(\"panic\") } If recover is called outside the deferred function it will not stop a panicking sequence. 所以go的panic加recover的效果, 和C的longjump有点像. 这里补充一下, 如果没有这个recover, 很可能因为这个goroutine调用了panic, 导致整个程序退出. 因为panic会依次回溯defer的函数, 遇到这里的recover, 就停止回溯. 效果就是在safelyDo这一层级停止panic, 程序从此返回, 这个goroutine终结, 但整个程序继续运行. recover里面可以改变量值 // Error is the type of a parse error; it satisfies the error interface. type Error string func (e Error) Error() string { return string(e) } // error is a method of *Regexp that reports parsing errors by // panicking with an Error. func (regexp *Regexp) error(err string) { panic(Error(err)) } // re模块调用error方法时, 就会调用panic // error方法时小写的, 它是个私有方法.和builtin的error重名了, 但没影响? if pos == 0 { re.error(\"'*' illegal at start of expression\") } // Compile returns a parsed representation of the regular expression. func Compile(str string) (regexp *Regexp, err error) { regexp = new(Regexp) // doParse will panic if there is a parse error. defer func() { if e := recover(); e != nil { //recover里面, 依然可以改变量值 regexp = nil // Clear return value. //如果断言失败, 会再次触发panic //这里的作用是, 其他错误情况下, 会继续panic err = e.(Error) // Will re-panic if not a parse error. } }() return regexp.doParse(str), nil } 这里的第二次panic, 和第一次panic一起, 会被crash report记录, 但他们的值不通. 总结 panic和recover常组合用来错误处理, 而不是真正的停止程序运行. 错误处理 先看看C语言版本的open: 成功返回fd, 失败返回-1; 需要单独查errno才能知道失败的原因 Linux Mint 19.1 Tessa $ man 2 open OPEN(2) Linux Programmer's Manual OPEN(2) NAME open, openat, creat - open and possibly create a file SYNOPSIS #include #include #include int open(const char *pathname, int flags); int open(const char *pathname, int flags, mode_t mode); RETURN VALUE open(), openat(), and creat() return the new file descriptor, or -1 if an error occurred (in which case, errno is set appropriately). go的函数支持多返回值, 在错误处理时能返回更多的信息. 比如go的os.Open方法: 失败的时候不仅返回nil, 还返回一个error值 Linux Mint 19.1 Tessa $ go doc os.Open func Open(name string) (*File, error) Open opens the named file for reading. If successful, methods on the returned file can be used for reading; the associated file descriptor has mode O_RDONLY. If there is an error, it will be of type *PathError. error定义和使用 在go传统中, error是个builtin的interface, 即任何实现了Error()方法的类型, 都可以被看作是error对象. src/builtin/builtin.go, 里面还有close(), len()等内建函数. type error interface { Error() string } 在使用时, 一种方式是: 如果open失败, log.Fatal(err)记下log然后程序退出. f, err := os.Open(\"filename.ext\") if err != nil { log.Fatal(err) } // do something with the open *File f errors包 errors包提供了对error简单的封装: 注意errorString是个私有结构, 对外不可见 // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 使用errors.New函数, 可以返回errorString, 但是以error类型返回的. 外部不知道有errorString // New returns an error that formats as the given text. func New(text string) error { return &errorString{text} } 在你的函数里, 你不用自己实现Error()方法, 用errors.New就可以了: func Sqrt(f float64) (float64, error) { if f 在后面, 我们会用fmt.Errorf来代替errors.New 你的函数最终被别人调用, 出错时, 可以调用err.Error()方法返回字符串, 也可以直接print: f, err := Sqrt(-1) if err != nil { fmt.Println(err) } err是个error类型的接口变量, 根据上文, 它又为什么能直接print呢? 见下面, 类型断言. 动态判断类型, 如果是error类型, 调用它的Error()方法. 比如这样: 这段代码在go/src/fmt/print.go具体来说, fmt.Println会先看类型, 先是基础类型, 不是基础类型default是走上面的代码. 前面说过, 用errors.New返回一个error对象, 但New()只接受一个字符串. 用fmt.Errorf可以接受一个带格式化的字符串, 按照Printf的格式打印成字符串, 内部再调用errors.New()返回error. 所以可以这样写: 能带更多的信息 func Sqrt(f float64) (float64, error) { if f 自己实现error接口 通常, 用fmt.Errorf就足够好了, 但还有更高级的写法. 实现了error的Error()方法, 就是error类型 比如json包里, 定义了一个SyntaxError类型, 如果解析json文件出错时, 就把它作为error类型返回. 注意, SyntaxError带一个叫Offset的数据, 后面要用到. type SyntaxError struct { msg string // description of error Offset int64 // error occurred after reading Offset bytes } func (e *SyntaxError) Error() string { return e.msg } 当调用json.Decode的人, 发现出错的时候, 他可以检查这个Offset: 这要用到类型断言 if err := dec.Decode(&val); err != nil { if serr, ok := err.(*json.SyntaxError); ok { line, col := findLine(f, serr.Offset) return fmt.Errorf(\"%s:%d:%d: %v\", f.Name(), line, col, err) } return err } 为啥要在调用函数里搞这些呢? 在SyntaxError的Error()直接写好不就完了吗? error和类型断言的例子 通过类型断言, 可以从err中提取更多的信息: for try := 0; try 进一步看error如何返回的 前面说了, os.Open返回的error会是os.PathError的指针. Linux Mint 19.1 Tessa $ go doc os.PathError type PathError struct { Op string Path string Err error } PathError records an error and the operation and file path that caused it. func (e *PathError) Error() string func (e *PathError) Timeout() bool 解释如下: // PathError records an error and the operation and // file path that caused it. type PathError struct { Op string // \"open\", \"unlink\", etc. Path string // The associated file. Err error // Returned by the system call. } func (e *PathError) Error() string { return e.Op + \" \" + e.Path + \": \" + e.Err.Error() } open失败的meesage像这样: open /etc/passwx: no such file or directory os.Open()最终会调用私有函数:func openFileNolog(name string, flag int, perm FileMode) (*File, error) open失败的时候, 返回return nil, &PathError{\"open\", name, e} 前面说了, PathError实现了Error()方法, 就可以被当做error类型使用. 注: 为什么要对PathError{\"open\", name, e}取地址呢? 答: 对error类型来说, 它是interface, 既可以接受值, 也可以是取地址后的引用. 取决于对应方法的实现方式. 这里PathError实现Error原型是: func (e *PathError) Error() string 它的receiver是pointer receiver, 是指针, 这里要返回PathError取地址; 否则编译不过. 如果receiver的声明是非指针方式, 那么取不取地址都行. type Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\"I am Nokia, I can call you!\") } //这是interface类型的变量 var phone Phone //可以写成phone = NokiaPhone{}, 或phone = &NokiaPhone{} //结果是一样的 phone.call() 参考: https://blog.golang.org/error-handling-and-go 错误处理化简 go的错误处理是类似C的, 在出错时记录, 调用者来检查. 这样的好处是, 错误能被及时的处理; 但相比于python等语言的try catch机制, go的代码会繁琐. 比如http的处理函数里面, 第10行和第14行, 有一样的错误打印. 代码逻辑按步骤, 调用不同的处理函数, 出错时都要给user返回http错误码: 500 (\"Internal Server Error\") 如果后面处理的步骤增多, 会有大量的重复代码. func init() { http.HandleFunc(\"/view\", viewRecord) } func viewRecord(w http.ResponseWriter, r *http.Request) { c := appengine.NewContext(r) key := datastore.NewKey(c, \"Record\", r.FormValue(\"id\"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { http.Error(w, err.Error(), 500) return } if err := viewTemplate.Execute(w, record); err != nil { http.Error(w, err.Error(), 500) } } 在C里面, 可以定义宏函数, 或者wrapper函数, 把要调用的函数包装一下, 统一返回错误码. 在go里, 用函数的方法可以解决这个问题: http的ServeHTTP方法的格式没有返回值 type Handler interface { ServeHTTP(ResponseWriter, *Request) } 通过函数的方法, 可以实际上带上返回值: //定义一个带返回error的函数类型 type appHandler func(http.ResponseWriter, *http.Request) error //实现ServeHTTP方法, 满足http.Handler func (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { if err := fn(w, r); err != nil { http.Error(w, err.Error(), 500) } } //实现具体的viewRecord函数, 从形式上, 它是有error返回值的. func viewRecord(w http.ResponseWriter, r *http.Request) error { c := appengine.NewContext(r) key := datastore.NewKey(c, \"Record\", r.FormValue(\"id\"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { return err } return viewTemplate.Execute(w, record) } 上面实现了带error返回的viewRecord, 它符合appHandler类型的形式, 所以有ServeHTTP方法: 即函数的方法(方法的receiver是函数) 这里的ServeHTTP方法调用了它的receiver函数, 统一处理错误, 通过http发送给user错误码500; ServeHTTP会被http框架调用, 进而receiver函数被调用. 那么如何注册viewRecord函数为http.Handler呢? package http // import \"net/http\" func Handle(pattern string, handler Handler) Handle registers the handler for the given pattern in the DefaultServeMux. The documentation for ServeMux explains how patterns are matched. //按照上面的说明, 注册viewRecord: 强制转换为appHandler即可 func init() { http.Handle(\"/view\", appHandler(viewRecord)) } 注: 此例子充分说明了: go中的函数是一等公民 上面的例子可以更进一步, 不只返回error, 还返回更多的信息: //返回一个专用结构: 包含error接口 type appError struct { Error error Message string Code int } //现在appHandler类型返回appError对象指针 type appHandler func(http.ResponseWriter, *http.Request) *appError func (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { if e := fn(w, r); e != nil { // e is *appError, not os.Error. c := appengine.NewContext(r) c.Errorf(\"%v\", e.Error) http.Error(w, e.Message, e.Code) } } //现在返回的错误信息更丰富了 func viewRecord(w http.ResponseWriter, r *http.Request) *appError { c := appengine.NewContext(r) key := datastore.NewKey(c, \"Record\", r.FormValue(\"id\"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { return &appError{err, \"Record not found\", 404} } if err := viewTemplate.Execute(w, record); err != nil { return &appError{err, \"Can't display record\", 500} } return nil } channel和并发 go处理并发的哲学很简单: 不共享内存, 所有共享走channel 这个哲学能从设计上, 就避免了竞争. Do not communicate by sharing memory; instead, share memory by communicating. 比如: go list.Sort() // run list.Sort concurrently; don't wait for it. 这有点像shell的后台运行& 单独这样除了能在后台跑sort, 没有特别的好处. 一般还要配合某种同步机制, 通知其他相关线程. go里面用channel来通知. 一个func里面, 也可以用go来运行goroutine func Announce(message string, delay time.Duration) { go func() { time.Sleep(delay) fmt.Println(message) }() // Note the parentheses - must call the function. } go的函数, 实际上都是闭包, 它需要的变量, 比如上面的message, 只要在用就会存在. channel 默认的size是0, 表示unbuffered通道 ci := make(chan int) // unbuffered channel of integers cj := make(chan int, 0) // unbuffered channel of integers cs := make(chan *os.File, 100) // buffered channel of pointers to Files unbuffered通道是同步安全的. channel用于同步 接上面sort的例子, sort完成后, 通过channel发送完成的\"通知\". 主程序在某个地方等待这个\"通知\". c := make(chan int) // Allocate a channel. // Start the sort in a goroutine; when it completes, signal on the channel. go func() { list.Sort() c 如果是unbufferd的通道, 发送者阻塞, 直到接收方接收到这个值. 如果是buffered模式, 则发送方只阻塞到值被拷贝进通道. 如果这个buffer满了, 则发送方一直阻塞到接收方收到值. channel用于semaphore 下面的例子中, serve函数把进入的请求, 分发给handle执行. handle是并发执行的. 它们都先写channel, 直到到达最大并发数:MaxOutstanding 这演示了sem这个channel的容量, 决定了这个生产-消费模型的最大并发数. 在到达并发数之前, handle都是并发的; 到达之后, 只有等有的handle退出, 才能执行新的handle. var sem = make(chan int, MaxOutstanding) func handle(r *Request) { //这里并不是和自己互斥; 而是可能会有最多MaxOutstanding个handle同时运行, 它们之间互斥. sem 这个design有个问题, Serve为每个请求起个goroutine来处理, 虽然最大并发被限制为MaxOutstanding, 但新的goroutine还是在被创建. 如果进来的请求太快, 资源消耗会很快. 可以在Serve里面限制goroutine的生成速度: 用range.range遍历通道queue, 如果通道不关闭, 那么range不会结束; 只在没有数据时阻塞. 但这个修改有个bug, 见下文 func Serve(queue chan *Request) { for req := range queue { //并不是range来控制go routine的生成速度 //而是说把sem 这里的bug在于, 作为循环变量, for里的req只有一个地址, 会被所有goroutine共享. 导致最后这些\"handle\"都在处理同一个req. 那么需要把req复制一份, 传给handle 这个req是个Request指针, 每次range得到一个新的req指针. 闭包函数增加个参数, 然后把req传进去: go是值传递, 所以req指针的值对每个goroutine都是unique的. func Serve(queue chan *Request) { for req := range queue { sem 还有一个写法: 在循环体里面: req := req形成一个新的副本. 名字都一样, 作用域不同. 看着有点怪, 但很合法, 也是go的一种常见写法. func Serve(queue chan *Request) { for req := range queue { req := req // Create new instance of req for the goroutine. sem 一个channel有多个goroutine接收 channel应该是天然支持多对多的模型. 对channel做range也支持多个goroutine对同一个channel做range 其实range就是个iterator? 上面的Serve例子, 用一个更省资源的方法来实现: 起固定个数的goroutine, 每个goroutine都直接从req通道读请求. quit是bool类型的通道, 主线程等待这个信号退出. func handle(queue chan *Request) { //每个handle都会对这个queue做range, 如果都等待, 那唤醒谁呢? for r := range queue { process(r) } } func Serve(clientRequests chan *Request, quit chan bool) { // Start handlers for i := 0; i 函数和channel都是first class值: channel in channel first class意思是, 函数和channel级别和int是一样的, 可以在任何地方传递.比如: channels of channels这里的f是个函数变量, resultChan是个chan int类型的变量这个Request被client用来发送请求, 它发一个切片, 一个函数, 和通过chennal传递的结果 type Request struct { args []int f func([]int) int resultChan chan int } 为什么不直接用个int放结果呢? 比如result int 因为client要用通道来等待server返回结果. client提供一个sum方法, 当做f, make(chan int)当做resultChan func sum(a []int) (s int) { for _, v := range a { s += v } return } request := &Request{[]int{3, 4, 5}, sum, make(chan int)} // Send request //这里是go重要的特征: request里面包括了函数变量和channel变量, 它们通过clientRequests 这个channel传递 clientRequests 在server端: 每个handle按照request里面的f方法, 计算出结果, 传递给request内部的通道. 这个结果会\"直达\"给对应的client. 不需要锁. func handle(queue chan *Request) { for req := range queue { req.resultChan 虽然只是演示代码, 但这个是个支持rate限制, 并发, 无锁的RPC框架. 通道in通道的另一个例子 package main import ( \"fmt\" \"math/rand\" \"sync\" \"time\" ) func main() { reqs := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} // 存放结果的channel的channel outs := make(chan chan int, len(reqs)) var wg sync.WaitGroup wg.Add(len(reqs)) for _, x := range reqs { o := handle(&wg, x) outs 分割和并发 比如一个切片, 如果对每个元素的操作都是独立的, 那么这个结构就是很理想的可以多核并行的结构. type Vector []float64 // Apply the operation to v[i], v[i+1] ... up to v[n-1]. func (v Vector) DoSome(i, n int, u Vector, c chan int) { for ; i 这时可以用一个buffered channel来实现并发, channel的size为CPU个数. const numCPU = 4 // number of CPU cores func (v Vector) DoAll(u Vector) { c := make(chan int, numCPU) // Buffering optional but sensible. for i := 0; i 这里的CPU个数是hardcode, 可以动态获取: var numCPU = runtime.NumCPU() //传入0是查询, 传入个正数是设置 var numCPU = runtime.GOMAXPROCS(0) 用channel管理message buffer 虽然go有垃圾回收, 但有时候还是希望能维护一个机制, 可以不用一直alloc buffer, 尽可能的reuse buffer. 用buffered channel可以实现, 把它当做一个free list. 比如: client端, 从freeList取buffer, freeList为空时申请新的buffer. 然后从网络读消息填充buffer, 再通过和server的通道serverChan 传递. //100个room的freeList var freeList = make(chan *Buffer, 100) var serverChan = make(chan *Buffer) func client() { for { var b *Buffer // Grab a buffer if available; allocate if not. //有default的select不会阻塞 select { //从freeList取buffer, 如果有, 就直接用 case b = 结合下面的server代码, server从serverChan 读buffer, 处理完还到freeList里面. func server() { for { b := 仔细想想, 这段代码有几个问题: serverChan 是个unbuffered的通道, 如果只有一个client和一个server, 实际是用不到100个元素的freeList通道的. 因为client和server会串行在通道上.答: 是的. 一个client和一个server是的. 我理解这里可以有多个client和多个server, 虽然通过serverChan 是串行的, 但通过channel很快, 多个server都能得到buffer同时进行处理. 多个client也基本不用等待serverChan, 有请求丢过去就行, 会有server马上响应. 通道的两端是多对多的情况下, 通道本身永远不会是瓶颈; 极端情况下, 100个server都在处理buffer, 这时freeList为空, 此时client需要重新alloc buffer. 这样buffer数会多于100, 这多出来的buffer 在哪里被丢弃? 内存泄漏了吗?答: 在server的select的default分支里丢弃; 内存不会泄漏, 因为go有垃圾回收 有垃圾回收为啥还要这样搞? 全部新申请buffer不行吗?答: 可以. 但这样垃圾回收任务变繁重, 性能差点. 对高吞吐的网络buffer来说, 一般都要reuse buffer. 接口嵌套 比如下面的ReadWriter 就是Reader和Writer的组合. 只有接口才能被嵌套进接口. type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } // ReadWriter is the interface that combines the Reader and Writer interfaces. type ReadWriter interface { Reader Writer } 结构体嵌套 比如bufio的ReadWriter, 包括一个Reader类型的指针, 和一个Writer类型的指针. 但没有名字, 只有类型. 这就叫嵌入. go编译器会默认把类型名当做变量名, 所以可以用ReadWriter.Reader来访问它包含的Reader成员. // ReadWriter stores pointers to a Reader and a Writer. // It implements io.ReadWriter. type ReadWriter struct { *Reader // *bufio.Reader *Writer // *bufio.Writer } 嵌入的好处是, ReadWriter 直接就有了Reader和writer的方法. 注意是, 直接, 即ReadWriter.Read和ReadWriter.Write 这里的Reader和Writer结构体分别实现的Read和Write方法, 是符合io.Reader和io.Writer接口的. 所以ReadWriter符合所有3个接口: io.Reader, io.Writer, 和 io.ReadWriter 需要注意的是, 比如var rw ReadWriter, 虽然调用方法的形式是rw.Read, 但实际的receive对象是 rw.Reader.Read, 也就是说, outer类型(ReadWriter)直接\"拥有\"Read方法, 但实际传入的还是inner类型(Reader) 一个啰嗦的写法是: named方式包含对象, 然后定义一个\"forward\"方法, 比如这样: 效果是一样的. type ReadWriter struct { reader *Reader writer *Writer } func (rw *ReadWriter) Read(p []byte) (n int, err error) { return rw.reader.Read(p) } 例子 logger type Job struct { Command string *log.Logger } 因为嵌入了log.Logger, Job可以直接使用Print, Printf, Println等log.Logger方法 在初始化后, 就可以使用了: job.Println(\"starting now...\") 初始化Job就像一般的初始化一样: 定义一个\"构造\"函数, go没有构造函数机制, 一般都是一个初始化函数. func NewJob(command string, logger *log.Logger) *Job { return &Job{command, logger} } 或者这样初始化: job := &Job{command, log.New(os.Stderr, \"Job: \", log.Ldate)} 如果需要引用其内嵌的域, 前面说过, 直接用job.Logger 注意这里, Job实现了自己的Printf, 所以引用Logger的Printf就要通过Logger func (job *Job) Printf(format string, args ...interface{}) { job.Logger.Printf(\"%q: %s\", job.Command, fmt.Sprintf(format, args...)) } 这里的Job和它的嵌入对象都有Printf方法, 有类似冲突的时候, 看嵌套层级: 层级少的方法会被使用.但有时候同一个层级的嵌套可能有同名的方法, 如果最外层不用这个同名的方法, 也没问题;如果调用, 那通常是错误. 接口和方法 几乎任何东西都可以满足一个interface定义的接口, 比如, 任何实现了Handler接口的对象, 都可以处理http请求. 在http包里: type Handler interface { ServeHTTP(ResponseWriter, *Request) } //调用http.Handle来使用这个interface func Handle(pattern string, handler Handler) ResponseWriter被http handler用来构建http 响应, go doc http.ResponseWriter看到: type ResponseWriter interface { Header() Header Write([]byte) (int, error) WriteHeader(statusCode int) ResponseWriter实现了Write方法, 这个方法满足io.Writer要求, 可以在任何io.Writer可以使用的地方使用. Request是对client的http请求的抽象. 下面是个很简单但完整的http handler实现, 可以统计http请求的次数: // Simple counter server. type Counter struct { n int } func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) { ctr.n++ //注意, 这里Fprintf是向w里面打印, 即直接打印到http的response fmt.Fprintf(w, \"counter = %d\\n\", ctr.n) } 如何attach这个ctr到一个url地址. import \"net/http\" ... ctr := new(Counter) http.Handle(\"/counter\", ctr) 即使一个int类型也可以带方法 // Simpler counter server. type Counter int func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) { *ctr++ fmt.Fprintf(w, \"counter = %d\\n\", *ctr) } chan带方法 有时你希望在url被访问的时候, 得到通知, 可以在chan上挂这个http的handler // A channel that sends a notification on each visit. // (Probably want the channel to be buffered.) type Chan chan *http.Request func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) { ch 函数也可以带方法!!! 比如想访问/args来得到运行这个http server时的参数, 在http包里, 是这样写的: 把func(ResponseWriter, *Request)作为一个type, 可以带方法 // The HandlerFunc type is an adapter to allow the use of // ordinary functions as HTTP handlers. If f is a function // with the appropriate signature, HandlerFunc(f) is a // Handler object that calls f. type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, req). func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) { f(w, req) } 这可能开起来有点奇怪, 在f的方法中, 调用了f本身. 但这和chan作为receiver本质上差不多. 所以, 这么写的好处是, 符合func(ResponseWriter, *Request)形式的函数, 都可以使用ServeHTTP方法 // Argument server. func ArgServer(w http.ResponseWriter, req *http.Request) { fmt.Fprintln(w, os.Args) } //把ArgServer转换为http.HandlerFunc类型, 就有ServeHTTP方法. http.Handle(\"/args\", http.HandlerFunc(ArgServer)) 注: 在使用时, 要把ArgServer转换成HandlerFunc类型才能使用这个类型带的方法. 这是否也可以理解成修饰器? 用type关键字定义一个函数类的类型, 这个类型可以实现别的接口规定的方法, 在这个方法里, 再调用函数自身. 函数还是这个函数, 但可以被不同的人(接口), 用不同的形式(接口方法)来调用. 多态 多态的意思是, 一个通用方法, 在各个子类里面实现, 但对外接口统一, 通常是父类定义好的(虚函数). 在基类中定义了一个虚拟函数，然后在派生类中又定义一个同名，同参数表的函数，这就是多态。多态是这3种情况中唯一采用动态绑定技术的一种情况。也就是说，通过一个基类指针来操作对象，如果对象是基类对象，就会调用基类中的那个函数，如果对象实际是派生类对象，就会调用派声类中的那个函数，调用哪个函数并不由函数的参数表决定，而是由函数的实际类型决定. 一个操作随着所传递或捆绑的对象类型的不同能够做出不同的反应，其行为模式称为多态。 在go里, 天然就是多态的: 只要实现了interface定义的方法, 就隐含了是该interface类型. 比如: NewCTR是counter mode (CTR) stream, 功能是把block cipher转换成stream cipher. // NewCTR returns a Stream that encrypts/decrypts using the given Block in // counter mode. The length of iv must be the same as the Block's block size. func NewCTR(block Block, iv []byte) Stream 这两个cipher都是通用格式, 比如只要实现了Block接口的三个函数, 都可以作为NewCTR的输入. 只要实现了Stream 接口, 就能作为输出. type Block interface { BlockSize() int Encrypt(dst, src []byte) Decrypt(dst, src []byte) } type Stream interface { XORKeyStream(dst, src []byte) } 接口和类型断言 fmt.Printf接受各种类型的入参, 它怎么知道怎么打印呢? Linux Mint 19.1 Tessa $ go doc fmt.Printf func Printf(format string, a ...interface{}) (n int, err error) Printf formats according to a format specifier and writes to standard output. It returns the number of bytes written and any write error encountered. 答案是类型断言 类型断言是对interface{}来说的, 对fmt.Printf来说, 它判断如果入参是string, 就直接打印. 如果有String方法, 那就是Stringer类型, 就调用它的String方法. type Stringer interface { String() string } var value interface{} // Value provided by caller. switch str := value.(type) { case string: return str case Stringer: return str.String() } 方法 方法的接收Type不限于结构体 在前面, 有个append方法: type ByteSlice []byte func (slice ByteSlice) Append(data []byte) []byte { // Body exactly the same as the Append function defined above. } 这个方法需要用return返回一个新的slice, 有点笨 用*Type, 即指针形式, 可以直接改caller的切片; 前面说过, 切片结构体有三个filed, 是对其底层数组的描述. func (p *ByteSlice) Append(data []byte) { slice := *p // Body as above, without the return. *p = slice } 更进一步, 可以写成Write的标准格式: func (p *ByteSlice) Write(data []byte) (n int, err error) { slice := *p // Again as above. *p = slice return len(data), nil } 有了这个方法, 就符合io.Writer接口, 就可以用标准的接口调用: var b ByteSlice //这里一定要用&对b取地址,因为只有*ByteSlice才符合io.Writer的要求 fmt.Fprintf(&b, \"This hour has %d days\\n\", 7) //go doc fmt 看Fprintf原型如下: func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) //继续用go doc io.Writer看详细定义 type Writer interface { Write(p []byte) (n int, err error) } The rule about pointers vs. values for receivers is that value methods can be invoked on pointers and values, but pointer methods can only be invoked on pointers. 这里如果直接传b, 传值会发生slice的拷贝(浅拷贝, 只拷贝slice结构体本身), 那对这个拷贝的修改就没有任何意义了. python是共享传参(不变的拷贝, 可变的相当于传指针), 而go的参数传递都是传值: 其实都是拷贝值 对int string来说, 就是拷贝值 对slice, map, channel来说, 拷贝\"描述\", 但底层数据不拷贝. -- 浅拷贝 有个特殊的地方, 虽然方法被声明为指针形式, func (p *ByteSlice) Write(data []byte) (n int, err error) 但b.Write和(&b).Write效果是一样的, 因为为了更好看, 编译器会把前者转换为后者. 接口 上面说了方法, 这里说接口 比如sort, 任何实现了sort.Interface的东东, 都能被sort包里的函数排序 //go doc sort type Interface interface{ ... } //go doc sort.Interface type Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } 下面这个例子就实现了sort的Interface //这个Sequence是切片, 定义时[]里面没东西的是切片 type Sequence []int // Methods required by sort.Interface. func (s Sequence) Len() int { return len(s) } func (s Sequence) Less(i, j int) bool { return s[i] 0 { str += \" \" } str += fmt.Sprint(elem) } return str + \"]\" } 在上面Sequence的方法String中, 对每个元素(range s)调用fmt.Sprint, 是挺啰嗦的操作, 效率低. 实际上, fmt.Sprint支持直接传入slice, 在调用之前Sequence强转成slice func (s Sequence) String() string { s = s.Copy() sort.Sort(s) return fmt.Sprint([]int(s)) } 强制转换[]int(s)并没有创建新的值, 只是把s当做int切片使用; 在有些情况下, 强制转换会创建新的值, 比如把int转成float sort包提供了对int切片的排序: IntSlice 除了实现了sort的Interface方法, IntSlice 还包装了自己的Sort方法, 这样可以用 p.Sort() 的形式调用. Linux Mint 19.1 Tessa $ go doc -src sort.IntSlice // IntSlice attaches the methods of Interface to []int, sorting in increasing order. type IntSlice []int func (p IntSlice) Len() int func (p IntSlice) Less(i, j int) bool func (p IntSlice) Search(x int) int func (p IntSlice) Sort() func (p IntSlice) Swap(i, j int) yingjieb@yingjieb-VirtualBox ~ Linux Mint 19.1 Tessa $ go doc -src sort.IntSlice.Sort // Sort is a convenience method. func (p IntSlice) Sort() { Sort(p) } 最后我们的Sequence可以简化成这样: type Sequence []int // Method for printing - sorts the elements before printing func (s Sequence) String() string { s = s.Copy() //这里是把s强转成IntSlice sort.IntSlice(s).Sort() return fmt.Sprint([]int(s)) } 一个东西可以实现多个接口, 比如这个Sequence类型的东东, 既实现了sort的接口, 又实现了fmt包里的Stringer接口 type Stringer interface { String() string } 使用时 package main import \"fmt\" type Person struct { Name string Age int } func (p Person) String() string { return fmt.Sprintf(\"%v (%v years)\", p.Name, p.Age) } func main() { a := Person{\"Arthur Dent\", 42} z := Person{\"Zaphod Beeblebrox\", 9001} fmt.Println(a, z) } gofmt gofmt是编译器自带的格式化代码工具 写代码的时候不需要手动对齐, 用gofmt会自动对齐 不需要关心行宽, go没有限制; gofmt全部搞定 注释即文档 godoc会自动提取下面的注释为package的文档 top level的注释是doc commet if可以有初始化语句 go的if允许和for类似的语法, 有个初始化语句 if err := file.Chmod(0664); err != nil { log.Print(err) return err } for是三种C循环的统一 // Like a C for for init; condition; post { } // Like a C while for condition { } // Like a C for(;;) for { } // Reverse a for i, j := 0, len(a)-1; i switch接受非常量 从上到下依次对case求值, 直到为ture. 空的case是ture. func unhex(c byte) byte { switch { case '0' switch和类型断言联用: var t interface{} t = functionOfSomeType() switch t := t.(type) { default: fmt.Printf(\"unexpected type %T\\n\", t) // %T prints whatever type t has case bool: fmt.Printf(\"boolean %t\\n\", t) // t has type bool case int: fmt.Printf(\"integer %d\\n\", t) // t has type int case *bool: fmt.Printf(\"pointer to boolean %t\\n\", *t) // t has type *bool case *int: fmt.Printf(\"pointer to integer %d\\n\", *t) // t has type *int } 多返回值 C语言只有一个返回值, 有的时候只能用指针作为参数获取 //C语言版本, 出错时, 返回-1, 然后还要用errno来看具体错误. ssize_t write(int fd, const void *buf, size_t count); //go语言版本, 同时返回已经写入的个数和错误, func (file *File) Write(b []byte) (n int, err error) 正如上面的例子, go的返回值可以有名字, 初始值为\"零值\"; 不带参数的return, 就返回它们的当前值. 这样程序可读性更好. defer defer关键词, 声明一个函数, 在defer return时调用(我理解就是函数返回前). 比如函数return someValue, defer的函数在someValue被计算之后, 在return之前被调用. // Contents returns the file's contents as a string. func Contents(filename string) (string, error) { f, err := os.Open(filename) if err != nil { return \"\", err } defer f.Close() // f.Close will run when we're finished. var result []byte buf := make([]byte, 100) for { n, err := f.Read(buf[0:]) result = append(result, buf[0:n]...) // append is discussed later. if err != nil { if err == io.EOF { break } return \"\", err // f will be closed if we return here. } } return string(result), nil // f will be closed if we return here. } defer声明时对参数求值, 而不是在退出时再求值; 执行是LIFO顺序的 for i := 0; i 用defer做函数trace func trace(s string) { fmt.Println(\"entering:\", s) } func untrace(s string) { fmt.Println(\"leaving:\", s) } // Use them like this: func a() { trace(\"a\") defer untrace(\"a\") // do something.... } 因为defer语句是在声明的时候求值的, 所以先求值\"trace\"函数, 打印\"entering\"; 然后在defer return的时候, 执行\"un\"函数 func trace(s string) string { fmt.Println(\"entering:\", s) return s } func un(s string) { fmt.Println(\"leaving:\", s) } func a() { defer un(trace(\"a\")) fmt.Println(\"in a\") } func b() { defer un(trace(\"b\")) fmt.Println(\"in b\") a() } func main() { b() } 结果: entering: b in b entering: a in a leaving: a leaving: b 在panic场景下, defer的最大好处是panic链上的defer都会被调用到 比如RunCompiled中的错误处理, 如果v.run()中出现panic, 这个defer的函数还是会被调用到, 做错误处理. // RunCompiled run the VM with user supplied function fn. func (v *VM) RunCompiled(fn *CompiledFunction, args ...Object) (val Object, err error) { ... defer func() { v.childCtl.Wait() // waits for all child VMs to exit if err = v.postRun(); err != nil { fmt.Println(err) return } if fn != nil && atomic.LoadInt64(&v.aborting) == 0 { val = v.stack[v.sp-1] } }() val = UndefinedValue v.run() return } new和make分配数据 new new的数据会被初始化为0, 返回指针. 这个方式虽然没有调用构造函数或这init之类的函数来初始化结构体, 但new保证这块数据都是0. 很多时候, 0可以直接使用. 比如下面的sync.Mutex初值为0, 就表示是unlock状态, 可以直接用; bytes.Buffer也是全0, 是空的buffer, 可以直接用. type SyncedBuffer struct { lock sync.Mutex buffer bytes.Buffer } p := new(SyncedBuffer) // type *SyncedBuffer var v SyncedBuffer // type SyncedBuffer 有时候结构体初始化需要非0值, 可以new一个结构体, 然后对每个filed单独赋值 func NewFile(fd int, name string) *File { if fd 但这样显得很啰嗦, \"There's a lot of boilerplate in there\", 有很多样板 此时可以用 func NewFile(fd int, name string) *File { if fd 数组, 切片, map都可以这样赋值 //这里Enone Eio Einval应该是int类型 a := [...]string {Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"} s := []string {Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"} m := map[int]string{Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"} 数组和切片的区别 定义不一样 //数组定义 var a1 [3]int var a2 [...]int{1,2,3} //切片定义 var b1 []int b2 := make([]int, 3, 5) 初始化不同 //数组 a1 := [...]int{1,2,3} a2 := [5]int{1,2,3} //切片 b1 := make([]int,3,5) make make用于slice map 和channel, 返回初始化后的type T, 而非*T; 这里的初始化不是指0值, 而是初始化其内部表达. 比如slice的内部结构包括一个指针(指向内部数组), 还有长度和容量; 这些就不是填0值. 比如 make([]int, 10, 100) 创建一个100大小的int数组, 然后创建一个切片结构体, 指向int数组, 长度为10, 容量为100. new([]int) 创建一个0值切片, 也就是nil切片, 这样一个空切片没啥实际作用. var p *[]int = new([]int) // allocates slice structure; *p == nil; rarely useful var v []int = make([]int, 100) // the slice v now refers to a new array of 100 ints // Unnecessarily complex: var p *[]int = new([]int) *p = make([]int, 100, 100) // Idiomatic: v := make([]int, 100) 数组 和C的数组相比, go的array有如下特点: array是值, 数组赋值会拷贝数组所有元素; 所以, 如果数组作为函数参数传参, 会造成数组拷贝 数组的大小也是其类型的一部分; 所以[10]int和[20]int是不同的类型 在go里, 数组是切片的底层承载; 能用slice就不要用数组 切片 切片是对数组的包装和引用 对切片的赋值不会复制数组, 只会引用同一个数组 传入切片到函数, 是传引用. 对数组的改变会被caller看到; 和传数组的指针效果差不多. 因为切片本身就有大小, 所以这个Read原型不需要C里面的nbyte参数. //go版本 func (f *File) Read(buf []byte) (n int, err error) //只readbuf的前32字节, 数组的切片buf[i:j]从0开始编号, 表示从i到(j-1)的元素, 不包括j; 所以这里是0到31的元素 n, err := f.Read(buf[0:32]) //C版本 ssize_t read(int fildes, void *buf, size_t nbyte); map map里面没有的key, 返回0值. attended := map[string]bool{ \"Ann\": true, \"Joe\": true, ... } if attended[person] { // will be false if person is not in the map fmt.Println(person, \"was at the meeting\") } 因为没有的元素也返回0值, 但有的时候map里存在的元素的值就是0值, 那怎么区分? 可以这样, if支持初始化语句: if seconds, ok := timeZone[tz]; ok 打印 fmt.Printf(\"Hello %d\\n\", 23) fmt.Fprint(os.Stdout, \"Hello \", 23, \"\\n\") fmt.Println(\"Hello\", 23) fmt.Println(fmt.Sprint(\"Hello \", 23)) append和...扩展 //原型 func append(slice []T, elements ...T) []T //append接受变长参数 x := []int{1,2,3} x = append(x, 4, 5, 6) fmt.Println(x) //append另外一个slice, 用...扩展 x := []int{1,2,3} y := []int{4,5,6} //没有...的话, y的类型错误 x = append(x, y...) fmt.Println(x) 全局变量初始化和init const变量是编译时初始化的, 只能是常量 而普通变量在运行时初始化, 比C更方便的是, 可以在声明的时候就调用函数来初始化. var ( home = os.Getenv(\"HOME\") user = os.Getenv(\"USER\") gopath = os.Getenv(\"GOPATH\") ) 每个文件都可以有一个或多个init函数, 它在全局变量初始化后被调用 一个常见的场景是, 在main执行之前, 用init来检查运行环境: func init() { if user == \"\" { log.Fatal(\"$USER not set\") } if home == \"\" { home = \"/home/\" + user } if gopath == \"\" { gopath = home + \"/go\" } // gopath may be overridden by --gopath flag on command line. flag.StringVar(&gopath, \"gopath\", gopath, \"override default GOPATH\") } "},"notes/golang_lib选型.html":{"url":"notes/golang_lib选型.html","title":"lib选型","keywords":"","body":" 编解码 性能汇总 排名 bson msgpack go解释器 python装饰器 protobuf cli选型 需求 新增备选 备选 Survey grumble liner readline 我的代码: ishell go-prompt cobra 教程 urfave/cli 简单例子 子命令 其他 go micro的cli 方案1 -- go-prompt 方案2 -- promptui + cobra 方案3 -- readline + cobra 方案4 -- 自己写REPL循环 + cobra 编解码 性能汇总 https://golangrepo.com/repo/alecthomas-go_serialization_benchmarks-go-benchmarks 排名 https://kokizzu.blogspot.com/2020/12/golang-serialization-benchmark-2020.html Format type ns/op bytes/op allocs/op ns/alloc Mum ser 97 48 0 0.00 GencodeUnsafe ser 98 46 48 2.05 Gotiny ser 130 48 0 0.00 GotinyNoTime ser 136 48 0 0.00 Gogoprotobuf ser 147 53 64 2.30 Msgp ser 174 97 128 1.36 Gencode ser 186 53 80 2.33 FlatBuffers ser 298 95 0 0.00 Goprotobuf ser 317 53 64 4.95 Protobuf ser 801 52 152 5.27 ShamatonMapMsgpack ser 819 92 208 3.94 Gob ser 834 63 48 17.38 Format type ns/op bytes/op allocs/op ns/alloc Gencode des 222 53 112 1.98 Gogoprotobuf des 230 53 96 2.40 GotinyNoTime des 241 48 96 2.51 FlatBuffers des 265 95 112 2.37 Gotiny des 267 48 112 2.38 Msgp des 314 97 112 2.80 CapNProto des 443 96 200 2.21 Goprotobuf des 481 53 168 2.86 Protobuf des 790 52 192 4.11 Ikea des 871 55 160 5.44 Gob des 900 63 112 8.04 GoAvro2Binary des 1092 47 560 1.95 Hprose des 1195 85 319 3.75 UgorjiCodecMsgpack des 1398 91 496 2.82 Binary des 1511 61 320 4.72 UgorjiCodecBinc des 1587 95 656 2.42 Bson des 1694 110 232 7.30 Format ns/op bytes Bebop 228 110 GencodeUnsafe 259 92 XDR2 290 120 Mum 313 96 Colfer 321 101 GotinyNoTime 377 96 Gogoprotobuf 377 106 Gotiny 397 96 Gencode 408 106 Msgp 488 194 FlatBuffers 563 190 Goprotobuf 798 106 CapNProto 829 192 Hprose2 1,213 170 ShamatonArrayMsgpack 1,241 100 CapNProto2 1,364 192 Ikea 1,541 110 ShamatonMapMsgpack 1,557 184 Protobuf 1,591 104 Gob 1,734 126 GoAvro2Binary 2,042 94 Hprose 2,110 170 UgorjiCodecMsgpack 2,820 182 VmihailencoMsgpack 2,838 200 Bson 2,865 220 Binary 2,875 122 UgorjiCodecBinc 3,055 190 EasyJson 3,513 299 XDR 4,091 182 JsonIter 4,266 278 GoAvro2Text 5,801 268 Sereal 6,313 264 Json 6,786 299 GoAvro 9,790 94 SSZNoTimeNoStringNoFloatA 12,616 110 bson https://github.com/mongodb/mongo-go-driver/tree/master/bson 对应的文档: https://pkg.go.dev/go.mongodb.org/mongo-driver/bson 还有一个实现: https://pkg.go.dev/labix.org/v2/mgo/bson 实现比较简单, 2014年更新的. msgpack github.com/vmihailenco/msgpack/v4 go解释器 库地址: https://github.com/traefik/yaegi 背景: https://traefik.io/blog/announcing-yaegi-263a1e2d070a/ 看起来很好 Complete support of Go specification Written in pure Go, using only the standard library Simple interpreter API: New(), Eval(), Use() Works everywhere Go works All Go & runtime resources accessible from script (with control) Security: unsafe and syscall packages neither used nor exported by default Support Go 1.13 and Go 1.14 (the latest 2 major releases) python装饰器 本质上是函数闭包: 把返回的函数赋值给原始函数名 @a_new_decorator def a_function_requiring_decoration(): \"\"\"Hey you! Decorate me!\"\"\" print(\"I am the function which needs some decoration to \" \"remove my foul smell\") a_function_requiring_decoration() #outputs: I am doing some boring work before executing a_func() # I am the function which needs some decoration to remove my foul smell # I am doing some boring work after executing a_func() #the @a_new_decorator is just a short way of saying: a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration) 参考这里 其中第一篇笔记很赞 protobuf protobuf项目的go版本现在转到: https://github.com/protocolbuffers/protobuf-go 之前是golang team维护的 https://github.com/golang/protobuf cli选型 需求 自动完成 命令层级 交互式(REPL): The name REPL stands for Read-Eval-Print-Loop - an interactive, typically console-based, programming environment. 命令式 新增备选 https://pkg.go.dev/golang.org/x/term 看起来有点官方 备选 从readline grumble liner里面选一个. 对abs来说, 不需要grumble这样的\"集成\"cli. readline/liner应该够了. 但grumble的思路可以借鉴. 最后选择readline Survey https://github.com/AlecAivazis/survey 感觉不是普通的shell思路, 应该说加了比如check box等功能 grumble https://github.com/desertbit/grumble 本身代码量很少, 但集成了readline等库; 但使用了较新维护的版本https://github.com/desertbit/readline 思路是cobra式的子命令, 但默认加了交互式命令行 更新不多, 但比较稳定? 作者自称受ishell启发 There are a handful of powerful go CLI libraries available (spf13/cobra, urfave/cli). However sometimes an integrated shell interface is a great and useful extension for the actual application. This library offers a simple API to create powerful CLI applications and automatically starts an integrated interactive shell, if the application is started without any command arguments. liner https://github.com/peterh/liner 看起来不错. 类VT100 支持go.mod 支持常规快捷键 支持历史命令 readline https://github.com/chzyer/readline 和c版本的readline套路一样. 有个库包装了readline, 成为一个简单的迭代器, 看起来不错 https://github.com/knieriem/readlineutil func (t *Term) Scan() bool { line, err := t.inst.Readline() if err != nil { t.err = err return false } t.line = line if t.prevPrompt != \"\" && line != \"\" { t.inst.SaveHistory(line) } return true } 我的代码: func repl() { completer := readline.NewPrefixCompleter() liner, err := readline.NewEx(&readline.Config{ Prompt: \"> \", AutoComplete: completer, EOFPrompt: \"exit\", }) if err != nil { panic(err) } defer liner.Close() for { l, err := liner.Readline() if errors.Is(err, io.EOF) { break } if errors.Is(err, readline.ErrInterrupt) { continue } if len(l) != 0 { fmt.Println(l) } } } ishell https://github.com/abiosoft/ishell 看着有点简陋... Sample Interactive Shell >>> help Commands: clear clear the screen greet greet user exit exit the program help display help >>> greet Someone Somewhere Hello Someone Somewhere >>> exit $ go-prompt https://github.com/c-bata/go-prompt 还在更新, 主打交互式, 命令联想, 快捷键, 历史记录上下翻. 好像目标是提供kubectl兼容的kube-prompt go.libhunt上对比 termui 主打文本的图形显示 gocui 主打文本布局, 有点像调试器界面 tview 也是主打界面的 tcell 文本控制台库, 似乎很有用. cobra https://github.com/spf13/cobra 使用广泛 Cobra is used in many Go projects such as Kubernetes, Hugo, and Github CLI to name a few. This list contains a more extensive list of projects using Cobra. cobra是个框架, 典型布局 ▾ appName/ ▾ cmd/ add.go your.go commands.go here.go main.go main.go package main import ( \"{pathToYourApp}/cmd\" ) func main() { cmd.Execute() } 教程 这个教程写的不错 用Cobra的几个好处: Easy to create subcommand-based CLIs and use nested subcommands. Automatic help generation for commands and flags. Increased productivity because of commands such as cobra init appname & cobra add cmdname. Helpful, intelligent suggestions (app srver… did you mean app server?). 这篇文章写的更好 Cobra比标准库flag的功能更丰富 支持-abc -e --example等传统的参数输入 支持子命令. 这个是主要原因. golang标准库里本来有, 但在internal下面, 外部用不了 子命令举例: package main import ( \"github.com/spf13/cobra\" ) func main() { cmd := newCommand() cmd.AddCommand(newNestedCommand()) rootCmd := &cobra.Command{} rootCmd.AddCommand(cmd) if err := rootCmd.Execute(); err != nil { println(err.Error()) } } func newCommand() *cobra.Command { cmd := &cobra.Command{ Run: func (cmd *cobra.Command, args []string) { println(`Foo`) }, Use: `foo`, Short: \"Command foo\", Long: \"This is a command\", } return cmd } func newNestedCommand() *cobra.Command { cmd := &cobra.Command{ Run: func (cmd *cobra.Command, args []string) { println(`Bar`) }, Use: `bar`, Short: \"Command bar\", Long: \"This is a nested command\", } return cmd } urfave/cli https://github.com/urfave/cli 主打轻量化.在积极维护 简单例子 package main import ( \"fmt\" \"log\" \"os\" \"github.com/urfave/cli/v2\" ) func main() { app := &cli.App{ Name: \"greet\", Usage: \"fight the loneliness!\", Action: func(c *cli.Context) error { fmt.Println(\"Hello friend!\") return nil }, } err := app.Run(os.Args) if err != nil { log.Fatal(err) } } 子命令 package main import ( \"fmt\" \"log\" \"os\" \"github.com/urfave/cli/v2\" ) func main() { app := cli.NewApp() app.EnableBashCompletion = true app.Commands = []*cli.Command{ { Name: \"add\", Aliases: []string{\"a\"}, Usage: \"add a task to the list\", Action: func(c *cli.Context) error { fmt.Println(\"added task: \", c.Args().First()) return nil }, }, { Name: \"complete\", Aliases: []string{\"c\"}, Usage: \"complete a task on the list\", Action: func(c *cli.Context) error { fmt.Println(\"completed task: \", c.Args().First()) return nil }, }, { Name: \"template\", Aliases: []string{\"t\"}, Usage: \"options for task templates\", Subcommands: []*cli.Command{ { Name: \"add\", Usage: \"add a new template\", Action: func(c *cli.Context) error { fmt.Println(\"new task template: \", c.Args().First()) return nil }, }, { Name: \"remove\", Usage: \"remove an existing template\", Action: func(c *cli.Context) error { fmt.Println(\"removed task template: \", c.Args().First()) return nil }, }, }, }, } err := app.Run(os.Args) if err != nil { log.Fatal(err) } } 其他 kingpin 似乎不怎么维护了 go micro的cli micro命令似乎进入了一个命令行界面, 有提示符. 但里面的命令和在shell中敲的一样. cli命令对应的Action是Run. 这个Run是个典型的Read-Eval-Print-Loop, 基本上是 for { //先readline() args, err := r.Readline() //准备参数 args = strings.TrimSpace(args) parts := strings.Split(args, \" \") //找到cmd cmd, ok := commands[name] //执行cmd rsp, err := cmd.exec(c, parts[1:]) println(string(rsp)) } micro的交互式cli很简单, 就是在顶层有个循环来readline, 执行cmd. 没有其他功能. 方案1 -- go-prompt 方案2 -- promptui + cobra 讨论在此 看下来感觉不好... 方案3 -- readline + cobra 方案4 -- 自己写REPL循环 + cobra 比如这篇文章里, 就只用了reader.ReadString('\\n') func main() { reader := bufio.NewReader(os.Stdin) for { fmt.Print(\"$ \") cmdString, err := reader.ReadString('\\n') if err != nil { fmt.Fprintln(os.Stderr, err) } err = runCommand(cmdString) if err != nil { fmt.Fprintln(os.Stderr, err) } } } func runCommand(commandStr string) error { commandStr = strings.TrimSuffix(commandStr, \"\\n\") arrCommandStr := strings.Fields(commandStr) switch arrCommandStr[0] { case \"exit\": os.Exit(0) // add another case here for custom commands. } cmd := exec.Command(arrCommandStr[0], arrCommandStr[1:]...) cmd.Stderr = os.Stderr cmd.Stdout = os.Stdout return cmd.Run() } "},"notes/golang_mod_proxy.html":{"url":"notes/golang_mod_proxy.html","title":"go mod和go proxy","keywords":"","body":" go get 和 replace gocenter已经停止维护了 go center使用心得 gitlab ci clone私有库 go mode 使用私有repo 使用ssh方式clone GOPROXY问题和解决 go clean go mod 使用replace指定私有repo artifactory和goproxy的问题汇总 godevsig-gocenter-remote获取不到新版本 gitlab默认不支持goproxy artifactory的repository概念 一个repository只对应一个类型 generic类型 local repository remote repository Virtual Repositories GOPROXY和artifactory 私有repo 私有GOPROXY setup私有GOPROXY go list package模式 module模式 国内可用的proxy go mod模式和普通模式的go get区别 普通模式下 go mod模式下 go mode模式下的help go mod使用记录 go.mod 本地import和外部repo import sum DB审查 go mod机制 定义go module 创建一个go module go.mod文件维护 版本格式 兼容性公约 Using v2 releases Using v1 releases go get 和 replace 有replace的时候, 比如: module github.com/godevsig/gshellos go 1.13 require ( github.com/d5/tengo/v2 v2.7.0 github.com/peterh/liner v1.2.1 ) replace github.com/d5/tengo/v2 => github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 直接go get github.com/godevsig/tengo/v2会报错: go get: github.com/godevsig/tengo/v2@v2.7.0: parsing go.mod: module declares its path as: github.com/d5/tengo/v2 but was required as: github.com/godevsig/tengo/v2 那么怎么更新replace的版本呢? 要先改go.mod, 最后一行指定branch是dev replace github.com/d5/tengo/v2 => github.com/godevsig/tengo/v2 dev 然后执行go get $ go get go: finding github.com/godevsig/tengo/v2 dev go: downloading github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 go: extracting github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 会自动更新go.mod文件, 最后一行变为: replace github.com/d5/tengo/v2 => github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 gocenter已经停止维护了 访问https://search.gocenter.io/, 显示gocenter服务已经终止了. 最后一句 You’ve arrived at this page because the era of Bintray, JCenter, GoCenter, and ChartCenter has ended – as newer and better options have emerged. We’re proud of the benefits they provided, as they helped spur software innovation and bolstered the work of brilliant developers. But you know what they say. Don’t overstay your welcome. Know when it’s time to bow out. Make a graceful exit. The Go team has built a module repository for Go developers called Pkg.go.dev. 所以, 之前的 GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" 要改成默认的: GOPROXY=\"https://proxy.golang.org,direct\" 如果没有你的package, 要自己添加以下: https://go.dev/about#adding-a-package Data for the site is downloaded from proxy.golang.org. We monitor the Go Module Index regularly for new packages to add to pkg.go.dev. If you don’t see a package on pkg.go.dev, you can add it by doing one of the following: Visiting that page on pkg.go.dev, and clicking the “Request” button. For example: https://pkg.go.dev/example.com/my/module Making a request to proxy.golang.org for the module version, to any endpoint specified by the Module proxy protocol. For example: https://proxy.golang.org/example.com/my/module/@v/v1.0.0.info Downloading the package via the go command. For example: GOPROXY=https://proxy.golang.org GO111MODULE=on go get example.com/my/module@v1.0.0 go center使用心得 使用export GOPROXY=https://gocenter.io时, 默认是不包括你的github项目的. 需要在主页https://search.gocenter.io/ 点添加module按钮来手动添加 似乎gocenter不会主动持续的对你的库更新版本, 比如通过gocenter来go get时, latest版本不会更新 直接go get github.com/godevsig/gshellos不会拿到最新版本 对于Pseudo-Versions来说, 需要用户指定版本号, 比如 go get github.com/godevsig/gshellos@6d66a9c 这样才会触发gocenter进行一次缓存 tag规范:https://jfrog.com/blog/go-big-with-pseudo-versions-and-gocenter/ 如果不是proxy管理的, 是可以直接更新的: $ go get gitlab.com/godevsig/system go: finding gitlab.com/godevsig/system latest go: downloading gitlab.com/godevsig/system v0.0.0-20210115023458-e89ec0eae327 go: extracting gitlab.com/godevsig/system v0.0.0-20210115023458-e89ec0eae327 gitlab ci clone私有库 参考网上的经验, 在.gitlab-ci.yml中加入before_script, 这样在每个script执行之前, 都会跑这个git配置, 意思是用git的url替换功能, \"加工\"url地址. default: image: name: godevsig-docker-local.artifactory.com/godevsig/devtool:godevsig-ee82473 entrypoint: [\"\"] before_script: - git config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com\".insteadOf \"https://gitlab.com\" 因为go默认使用https方式get代码, 这里被替换的url字符串为https://gitlab.com, 将其前面加上https://gitlab-ci-token:${CI_JOB_TOKEN} 使用gitlab内置的CI_JOB_TOKEN变量, 可以绕过私有库不能clone的限制, 把私有库clone下来. go mode 使用私有repo 比如https://gitlab.com/godev/system.git不是public, 不能直接clone go build等命令没法获取到这个库. 我用replace关键词暂时解决了本地编译的问题 replace ( github.com/d5/tengo/v2 => /repo/yingjieb/godevsig/tengo gitlab.com/godevsig/system => /repo/yingjieb/godevsig/system ) require ( github.com/d5/tengo/v2 v2.6.2 github.com/peterh/liner v1.2.1 gitlab.com/godevsig/system v0.0.0-00010101000000-000000000000 ) 但这里的system版本号似乎很怪异:v0.0.0-00010101000000-00000000000 这个大概是个特殊的版本号, 因为go 命令其实没有办法获取到 因为go命令默认使用https去clone. 对于私有仓库来说, 对外不可见, 当然不能用https去get. 使用ssh方式clone 用git config命令, 把https方式clone改成git方式, 这样如果你本地有ssh权限clone这个私有库, go命令也能成功, 因为go命令底层也是调用git命令clone的. $ git config --global url.\"git@mygitlab.com:\".insteadOf \"http://mygitlab.com/\" // 其实就是在 .gitconfig 增加了配置 $ cat ~/.gitconfig [url \"git@mygitlab.com:\"] insteadOf = http://mygitlab.com/ //注意： git@mygitlab.com: 后面有个冒号 :, 且 http://mygitlab.com 后面有 / 我的成功例子: git config --global url.\"git@gitlab.com:godevsig\".insteadOf \"https://gitlab.com/godevsig\" 会在~/.gitconfig中增加: [url \"git@gitlab.com:godevsig\"] insteadOf = https://gitlab.com/godevsig GOPROXY问题和解决 设置git的ssh方式替换https方式后, 把go.mod里面的特殊行删除: gitlab.com/godevsig/system v0.0.0-00010101000000-000000000000 然后使用go get命令更新go.mod 发现go命令能正确发现这个私有库的版本号v0.0.0-20201225044511-46ec8cf4b75c, 但下载失败, 看起来和GOPROXY的设置有关 yingjieb@73e57632f306 /repo/yingjieb/godevsig/gshell $ go get go: finding gitlab.com/godevsig/system/pidinfo latest go: finding gitlab.com/godevsig/system latest go: downloading gitlab.com/godevsig/system v0.0.0-20201225044511-46ec8cf4b75c build gitlab.com/godevsig/gshell: cannot load gitlab.com/godevsig/system/pidinfo: gitlab.com/godevsig/system@v0.0.0-20201225044511-46ec8cf4b75c: reading https://artifactory.com/artifactory/api/go/godevsig-go-virtual/gitlab.com/godevsig/system/@v/v0.0.0-20201225044511-46ec8cf4b75c.zip: 500 Internal Server Error 修改私有库不经过GOPROXY是可以的: GONOPROXY=\"*.net.com\" go get go clean 下面的命令会把所有的cache都清除, 导致go get下次会全新下载 go clean -cache -modcache -i -r 不加参数的go clean好像都不删除cache的. go mod 使用replace指定私有repo 在gshell中, 引用了库github.com/abs-lang/abs, 但我想修改这个package, 但依旧保留import \"github.com/abs-lang/abs\" 怎么做? -- go.mod中使用replace关键词 $ cat go.mod module gitlab.com/godev/gshell go 1.13 replace github.com/abs-lang/abs => /repo/yingjieb/godev/abs require ( github.com/abs-lang/abs v0.0.0-20190921150801-05c699c0415e github.com/peterh/liner v1.2.1 } 上面replace的意思是用本地路径替换目标package, 但源代码不用修改. 如果希望用私有repo, replace要求私有repo要有版本号. artifactory和goproxy的问题汇总 godevsig-gocenter-remote获取不到新版本 现象: $ GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/godevsig-gocenter-remote,direct\" GO111MODULE=on go get -v golang.org/x/tools/gopls go: golang.org/x/tools/gopls upgrade => v0.5.1 问题: 应该获取到新版本v0.5.3 解决: 使用virtual repo, 而且必须加api/go前缀就能下载最新的tag GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" GO111MODULE=on go get -v golang.org/x/tools/gopls go: golang.org/x/tools/gopls upgrade => v0.5.3 注: 对godevsig-gocenter-remote加api/go是不行的. 原因: 不是virtual的repo, 好像只能当cache用. gitlab默认不支持goproxy 现象: godevsig-go-virtual包括godevsig-gocenter-remote和godevsig-gogitlab-remote后者proxy https://gitlab.com 但get gitlab.com/godevsig/compatible失败 GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" GO111MODULE=on go get -v gitlab.com/godevsig/compatible go get gitlab.com/godevsig/compatible: no matching versions for query \"upgrade\" 而不加proxy能成功. GO111MODULE=on go get -v gitlab.com/godevsig/compatible get \"gitlab.com/godevsig/compatible\": found meta tag get.metaImport{Prefix:\"gitlab.com/godevsig/compatible\", VCS:\"git\", RepoRoot:\"https://gitlab.com/godevsig/compatible.git\"} at //gitlab.com/godevsig/compatible?go-get=1 go: downloading gitlab.com/godevsig/compatible v0.1.0 go: gitlab.com/godevsig/compatible upgrade => v0.1.0 原因: https://docs.gitlab.com/ee/user/packages/go_proxy/ 需要管理员手动打开, 在gitlab rails控制台 可以全部打开 Feature.enable(:go_proxy) 可以按project打开 Feature.enable(:go_proxy, Project.find(1)) Feature.disable(:go_proxy, Project.find(2)) 进展: gitlab 13.3才有这个功能 临时方案: 从virtual中去掉gitlab的汇聚. 待gitlab go proxy使能后再加 临时只virtual gocenter的. GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" GO111MODULE=on go get -v gitlab.com/godevsig/compatible get \"gitlab.com/godevsig/compatible\": found meta tag get.metaImport{Prefix:\"gitlab.com/godevsig/compatible\", VCS:\"git\", RepoRoot:\"https://gitlab.com/godevsig/compatible.git\"} at //gitlab.com/godevsig/compatible?go-get=1 go: gitlab.com/godevsig/compatible upgrade => v0.1.0 添加写申请: https://nsnsi.service-now.com/ess?id=create_ticket&sys_id=cdb84691db3d8f80012570600f96196a&returnPage=request_services&returnPage2=browse_it_services artifactory的repository概念 https://www.jfrog.com/confluence/display/JFROG/Repository+Management repository包括: Local Remote Virtual Distribution Release Bundle Repository Bintray Distribution Repository 一个repository只对应一个类型 特别的, virtual的repository只能汇聚同一类型的实体repository. 虽然没有强制要求不能上传不同类型的artifact, 但不推荐这样. generic类型 generic类型的repository能放任何东西, 没有特殊的包管理. local repository 访问路径: http://:/artifactory// remote repository 实际上是个proxy和cache 访问格式 http://:/artifactory// 如果确定artifact已经被cache了, 可以直接访问: http://:/artifactory/-cache/ Virtual Repositories 虚拟的repository是汇聚同类repository用的. 搜索的顺序是先local的, 再remote的. 同类的需要看list顺序, 可以改的. GOPROXY和artifactory JFrog Artifactory推出了https://gocenter.io 使用只需要 export GOPROXY=https://gocenter.io 这个代理完全能取代go1.13开始的默认GOPROXY设置. 注意: GOPROXY只在go mod模式下才有用. 使能go mod模式, 要么目录下有go.mod文件, 要么需要强制指定GO111MODULE=on 使用GoCenter比直接从github上下载更快, GoCenter网页也能显示更详细的信息. 私有repo 使用公共repo时, GOSUMDB要去默认的公共校验中心sum.golang.org校验文件安全性. 而私有库显然没有入这个\"sum DB\", 拉取私有库会报错. 通常使用GOPRIVATE环境变量传入需要bypass sum db的私有库 GoCenter提供了同时使用公共gocenter.io和私有库的方法: export GOPROXY=https://gocenter.io,direct export GOPRIVATE=*.internal.mycompany.com 这样能解决问题, 但没法防止私有库的owner去改tag, 改了tag, 就不能重复构建同样的版本了. 私有GOPROXY 私有GOPROXY能解决上面的问题. 私有GOPROXY能同时cache公共GOPROXY和内部私有repo In Artifactory, a combination of a remote repository for GoCenter, a remote Go module repository that points to private GitHub repos (for private modules) and a local Go module repository can be combined into a single virtual repository, to access as a single unit. 使用私有GOPROXY, GONOSUMDB来完成任务: $ export GOPROXY=\"https://:@my.artifactory.server/artifactory/api/go/go\" $ export GONOSUMDB=\"github.com/mycompany/*,github.com/mypersonal/*\" setup私有GOPROXY 官方参考 这里看起来我需要: go remote repo: proxy gocenter go remote repo: proxy gitlab go vitual repo general local repo: 参考: artifactory的go registry说明 经验文档1 经验文档2 go list package模式 go list 用于显示当前目录下的package的import path yingjieb@f8530ea27843 /repo/yingjieb/3rdparty/delve/pkg/proc $ go list github.com/go-delve/delve/pkg/proc -f选项其实是个模板, 可以显示go tool内部的管理数据, 比如查看package的import了谁, 以及依赖谁(即所有递归的import) % go list -f '{{ .Imports }}' github.com/davecheney/profile [io/ioutil log os os/signal path/filepath runtime runtime/pprof] % go list -f '{{ .Deps }}' github.com/davecheney/profile [bufio bytes errors fmt io io/ioutil log math os os/signal path/filepath reflect runtime runtime/pprof sort strconv strings sync sync/atomic syscall text/tabwriter time unicode unicode/utf8 unsafe] -deps 选项可以递归的list依赖. 也就是说默认不打印依赖. 列出当前目录下的package, 其中...是go tool通用的通配符, 匹配所有. 注意, 不要用go list ..., 意思是列出所有目录下的package yingjieb@f8530ea27843 /repo/yingjieb/3rdparty/delve/pkg/proc $ go list ./... github.com/go-delve/delve/pkg/proc github.com/go-delve/delve/pkg/proc/core github.com/go-delve/delve/pkg/proc/core/minidump github.com/go-delve/delve/pkg/proc/fbsdutil github.com/go-delve/delve/pkg/proc/gdbserial github.com/go-delve/delve/pkg/proc/linutil github.com/go-delve/delve/pkg/proc/native github.com/go-delve/delve/pkg/proc/test github.com/go-delve/delve/pkg/proc/winutil module模式 module对应的是package的自然集合, 通常是一个repo. go list -m all 用于列出所有的import的包(main包和main的依赖包) The arguments to list -m are interpreted as a list of modules, not packages. The main module is the module containing the current directory. The active modules are the main module and its dependencies. With no arguments, list -m shows the main module. With arguments, list -m shows the modules specified by the arguments. Any of the active modules can be specified by its module path. The special pattern \"all\" specifies all the active modules, first the main module and then dependencies sorted by module path. A pattern containing \"...\" specifies the active modules whose module paths match the pattern. 国内可用的proxy https://goproxy.cn/ $ export GO111MODULE=on $ export GOPROXY=https://goproxy.cn go mod模式和普通模式的go get区别 普通模式下 GOPROXY不起作用, go get直接从目标地址下载 go get -v github.com/naoina/go-stringutil # 下载后的代码以src形式保存在GOPATH下的 ./src/github.com/naoina/go-stringutil go mod模式下 # 使用godevsig的proxy GOPROXY=\"https://artifactory.com:443/artifactory/godevsig-go-virtual\" GO111MODULE=on go get -v github.com/naoina/go-stringutil # 下载后的代码以pkg cache的形式保存在GOPATH下的 ./pkg/mod/cache/download/github.com/naoina/go-stringutil 注: GOPROXY生效后, 在 https://artifactory.com/artifactory/webapp/#/artifacts/browse/tree/General/godevsig-gocenter-remote-cache 下, 能找到已经cache的package go mode模式下的help 连help输出也不一样 GO111MODULE=on go help get 第一步解析依赖, 对每个package pattern, 依次做版本检查: 先检查最新的tag, 比如v1.2.3 没有release的tag, 就用pre tag, 比如v0.0.1-pre1 没有tag, 就用最新的commit 可以用@version下载指定版本, @v1会下载v1的最新版本; @commitid也行 对于间接依赖, go get会follow go.mod的指示 go get后面是空的情况下, get当前目录下的依赖 第二步时下载, build, install; 在package下面没有东西可以build的时候, build和install有可能被忽略 可以用...的pattern go mod使用记录 比如库gitlab.com/godevsig/compatible go.mod 使用go mod init gitlab.com/godevsig/compatible 得到如下go.mod: 声明了本库的module名. 官方说法是, 这个名字必须和库地址一致.见cmd/go: Why not separate the module name and the download URL? module gitlab.com/godevsig/compatible go 1.13 本地import和外部repo import 这里的本地引用是说通一个repo下, 不同package之间的引用. 本地引用和外部引用没有任何区别: 在log同一级的目录msg下: main.go package main import \"gitlab.com/godevsig/compatible/log\" func main() { lg := log.DefaultStream.NewLogger(\"msgdriven\") lg.Infolnn(\"hello msg\") } 但本地引用情况下, 本地修改能够立即生效. 比如我在log包里加了一个API, 本地修改不入库, lg.Infolnn(), 本地其他包能够立刻引用新的API. 外部引用的情况下, 只认已经入库的内容. 因为lg.Infolnn()的修改还没有入库, 外部的repo是不知道的. 错误如下: $ go build # main ./hello.go:42:4: lg.Infolnn undefined (type *log.Logger has no field or method Infolnn) sum DB审查 默认配置下, go get/build发现go.mod文件后, 开启go mod模式, 自动拉取依赖的库. 但出现410 Gone错误 $ go build go: finding gitlab.com/godevsig/compatible latest go: finding gitlab.com/godevsig/compatible/log latest go: downloading gitlab.com/godevsig/compatible v0.0.0-20200811070332-66acc8ba0617 verifying gitlab.com/godevsig/compatible@v0.0.0-20200811070332-66acc8ba0617: gitlab.com/godevsig/compatible@v0.0.0-20200811070332-66acc8ba0617: reading htt ps://sum.golang.org/lookup/gitlab.com/godevsig/compatible@v0.0.0-20200811070332-66acc8ba0617: 410 Gone 看过程是它能取到版本, 但verifying checksum出错了. 因为go mod要去sum.golang.org获取校验, 但我们引用的module是私有库, 肯定在golang.org里面没有. 解决: 配置环境变量 GOSUMDB=off 参考: Golang-执行go get私有库提示”410 Gone“ 解决办法 或者使用 GONOSUMDB=\"*.net.com/*\" go mod机制 go help modules go help go.mod go help mod go modules是go的官方包管理机制, 用于替代老的GOPATH环境变量来指定版本依赖的方式. go tools1.13支持go modules. 环境变量GO111MODULE=auto的默认方式下, 如果目录下有go.mod文件, 则使能go modules模式; 否则还是用老的GOPATH模式 GOPATH在go modules模式下, 只用于存放下载的源码: GOPATH/pkg/mod, 和按照后的二进制: GOPATH/bin GO111MODULE=on 强制使用go modules模式 定义go module 一个go module是一个目录, 该目录下有go.mod文件, 该目录也称为module root. 比如下面的go.mod声明了一个module, 它的import path是example.com/m; 它还依赖指定版本的golang.org/x/text和gopkg.in/yaml.v2 module example.com/m require ( golang.org/x/text v0.3.0 gopkg.in/yaml.v2 v2.1.0 ) 创建一个go module 在工程目录下, 执行go mod init example.com/m会创建go.mod go.mod文件创建后, go命令比如go build, go get会自动更新go.mod. go命令会在当前目录找go.mod, 没有再到父目录及其再往上的父目录寻找go.mod 在哪里执行go命令, 那个目录就是main module. 只有main module的go.mod文件的有replace和exclude关键词才有效; 不是main module, 这些关键词被忽略. build list是构建main module的依赖列表 A Go module is a collection of related Go packages that are versioned together as a single unit. go list命令用于查看main module的build list go list -m # print path of main module go list -m -f={{.Dir}} # print root directory of main module go list -m all # print build list go.mod文件维护 go.mod被设计为人和go命令都可读可修改. go命令比如go build, 如果发现源码里面有新增的import example/m关键词, 就会自动添加example/m的最新version到go.mod go mod tidy命令可以整理go.mod文件, 删除不再需要的module. // indirect指示间接依赖 go get命令会更新go.mod的版本. 比如升级一个module, 那其他依赖这个module的modules也会被自动更新到相应版本. 版本格式 版本号的核心思想是版本号是可以比较新旧的. 对没有版本管理的repo, 假的版本号格式是:v0.0.0-yyyymmddhhmmss-abcdefabcdef 其中时间是commit时间, 后面是commit hash. go的命令支持module版本指定: v1.2.3指定了一个具体的版本 v1会被扩展成最新的v1版本 和>=v1.5.6 latest被扩展成最新的tagged版本, 或者, 对于没有版本管理的库, 使用最新的commit upgrade: 和latest差不多 patch: 和latest差不多 其他: commit hash, tag名, 分支名, 会选择源码的指定版本.go get github.com/gorilla/mux@latest # same (@latest is default for 'go get') go get github.com/gorilla/mux@v1.6.2 # records v1.6.2 go get github.com/gorilla/mux@e3702bed2 # records v1.6.2 go get github.com/gorilla/mux@c856192 # records v0.0.0-20180517173623-c85619274f5d go get github.com/gorilla/mux@master # records current meaning of master 兼容性公约 如果一个package的新老版本的import路径一致, 那么新版本必须兼容老版本. 对不兼容的版本, 解决方案是import路径加v2, 比如: go.mod里显式写明: module example.com/m/v2 在引用时也写明引用v2里面的一个package import example.com/m/v2/sub/pkg 比如urfave/cli的v1和v2版本: Using v2 releases $ GO111MODULE=on go get github.com/urfave/cli/v2 ... import ( \"github.com/urfave/cli/v2\" // imports as package \"cli\" ) ... Using v1 releases $ GO111MODULE=on go get github.com/urfave/cli ... import ( \"github.com/urfave/cli\" ) ... "},"notes/golang_汇编_arm64.html":{"url":"notes/golang_汇编_arm64.html","title":"汇编语法和arm64小知识","keywords":"","body":"golang汇编语法参考: https://go.dev/doc/asm pseudo寄存器 函数 arm64汇编 Register mapping rules ARM64异常处理过程 ARM64上下文切换 什么是VHE pseudo寄存器 SB: Static base pointer 全局基地址. 比如foo(SB)就是foo这个symbol的地址 FP: 帧指针. 用来传参的, 比如 first_arg+0(FP): 第一个参数 second_arg+8(FP): 第二个参数(64bit CPU) SP: 栈指针. 指向栈顶. 用于局部变量. CPU都有物理SP, 语法上看前缀来区分: x-8(SP), y-4(SP): 使用pseudo SP -8(SP)使用物理SP PC: 程序指针 函数 格式: TEXT symbol(SB), [flags,] $framesize[-argsize] symbol: 函数名 SB: SB伪寄存器 flags: 可以是 NOSPLIT: 不让编译器插入栈分裂的代码 WRAPPER: 不增加函数帧计数 NEEDCTXT: 需要上下文参数, 一般用于闭包 framesize: 局部变量大小, 包含要传给子函数的参数部分 argsize: 参数+返回值的大小, 可以省略由编译器自己推导 比如 //go:nosplit func swap(a, b int) (int, int) 可以写为: TEXT ·swap(SB), NOSPLIT, $0-32 或者 TEXT ·swap(SB), NOSPLIT, $0 这里-32是4个8字节的int, 即入参a, b和两个出参.注意go并不区分入参和出参 func swap(a, b int) (int, int) 或 func swap(a, b, c, d int) 或 func swap() (a, b, c, d int) 或 func swap() (a, []int, d int) 汇编都一样 arm64汇编 https://pkg.go.dev/cmd/internal/obj/arm64#pkg-overview Register mapping rules All basic register names are written as Rn. Go uses ZR as the zero register and RSP as the stack pointer. Bn, Hn, Dn, Sn and Qn instructions are written as Fn in floating-point instructions and as Vn in SIMD instructions. ARM64异常处理过程 When an event which causes an exception occurs, the processor hardware automatically performs certain actions. The SPSR_ELn is updated, (where n is the Exception level where the exception is taken), to store the PSTATE information required to correctly return at the end of the exception. PSTATE is updated to reflect the new processor status (and this may mean that the Exception level is raised, or it may stay the same). The return address to be used at the end of the exception is stored in ELR_ELn. 异常发生的时候, CPU会自动的实施如下动作: 将PSTATE保存到SPSR_ELn比如异常发生在EL0, 一般会在EL1处理. 那PSTATE会保存在SPSR_EL1 更新PSTATE以反映新的CPU状态, 比如已经进入EL1 硬件会将返回地址保存在ELR_Eln.还是比如异常发生在EL0, 但在EL1处理, 那返回地址保存在ELR_EL1 The processor has to be told when to return from an exception by software. This is done by executing the ERET instruction. This restores the pre-exception PSTATE from SPSR_ELn and returns program execution back to the original location by restoring the PC from ELR_ELn. eret指令用来从异常处理返回: 从SPSR_ELn恢复异常前的PSTATE 从ELR_ELn恢复PC 异常返回, 从恢复的PC和PSTATE继续执行 ELR_ELn contains the return address which is preferred for the specific exception type. For some exceptions, this is the address of the next instruction after the one which generated the exception. For example, when an SVC (system call) instruction is executed, we simply wish to return to the following instruction in the application. In other cases, we may wish to re-execute the instruction that generated the exception. 在发生异常时, 硬件会自动更新ELR, 根据情况, 返回地址有几种可能: 比如SVC指令触发的同步异常, ELR里保存的是其下一条指令 比如异步异常(即外部中断), ELR里保存的是下一个没被执行(或完全执行)的指令 ELR可以在异常处理程序里面被更改. In addition to the SPSR and ELR registers, each Exception level has its own dedicated Stack Pointer register. These are named SP_EL0, SP_EL1, SP_EL2 and SP_EL3. These registers are used to point to a dedicated stack that can, for example, be used to store registers which are corrupted by the exception handler, so that they can be restored to their original value before returning to the original code. Handler code may switch from using SP_ELn to SP_EL0. For example, it may be that SP_EL1 points to a piece of memory which holds a small stack that the kernel can guarantee to always be valid. SP_EL0 might point to a kernel task stack which is larger, but not guaranteed to be safe from overflow. This switching is controlled by writing to the [SPSel] bit, as shown in the following code: MSR SPSel, #0 // switch to SP_EL0 MSR SPSel, #1 // switch to SP_ELn 每个EL都有独立的SP, 并且异常处理程序可以切换使用SP_EL0和SP_ELn. ARM64上下文切换 Processors that implement the ARMv8-A Architecture are typically used in systems running a complex operating system with many applications or tasks that run concurrently. Each process has its own unique translation tables residing in physical memory. When an application starts, the operating system allocates it a set of translation table entries that map both the code and data used by the application to physical memory. These tables can subsequently be modified by the kernel, for example, to map in extra space, and are removed when the application is no longer running. There might therefore be multiple tasks present in the memory system. The kernel scheduler periodically transfers execution from one task to another. This is called a context switch and requires the kernel to save all execution state associated with the process and to restore the state of the process to be run next. The kernel also switches translation table entries to those of the next process to be run. The memory of the tasks that are not currently running is completely protected from the task that is running. 每个进程都有自己的translation table, 这个table是kernel分配的, 把其物理地址配置到ttbr0寄存器. 上下文切换的时候, kernel会保存/恢复如下上下文: general-purpose registers X0-X30. Advanced SIMD and Floating-point registers V0 - V31. Some status registers. TTBR0_EL1 and TTBR0. Thread Process ID (TPIDxxx) Registers. Address Space ID (ASID). For EL0 and EL1, there are two translation tables. TTBR0_EL1 provides translations for the bottom of Virtual Address space, which is typically application space and TTBR1_EL1 covers the top of Virtual Address space, typically kernel space. This split means that the OS mappings do not have to be replicated in the translation tables of each task. EL0和EL1有两个translation table, TTBR0_EL1负责bottom空间(用户空间), TTBR1_EL1负责top空间(kernel空间). 大家都用TTBR1_EL1做kernel空间, 所以进程切换的时候, TTBR1_EL1不用变, 所以kernel的映射不用变. Translation table entries contain a non-global (nG) bit. If the nG bit is set for a particular page, it is associated with a specific task or application. If the bit is marked as 0, then the entry is global and applies to all tasks. 页表entry里有个nG位, 用来表示non-global, 为0的时候, 这个页表entry就是全局的, 对所有task都有效. For non-global entries, when the TLB is updated and the entry is marked as non-global, a value is stored in the TLB entry in addition to the normal translation information. This value is called the Address Space ID (ASID), which is a number assigned by the OS to each individual task. Subsequent TLB look-ups only match on that entry if the current ASID matches with the ASID that is stored in the entry. This permits multiple valid TLB entries to be present for a particular page marked as non-global, but with different ASID values. In other words, we do not necessarily need to flush the TLBs when we context switch. ASID(Address Space ID)寄存器用来标记页表entry所属的task, 由kernel分配. 当TLB更新的时候, TLB entry除了保存地址翻译信息, 还会包括这个ASID. TLB查询的时候, 只有当前的ASID和TLB entry保存的ASID匹配的时候, 才算TLB命中. 所以上下文切换的时候不需要flush TLB. In AArch64, this ASID value can be specified as either an 8-bit or 16-bit value, controlled by the TCR_EL1.AS bit. The current ASID value is specified in either TTBR0_EL1 or TTBR1_EL1. TCR_EL1 controls which TTBR holds the ASID, but it is normally TTBR0_EL1, as this corresponds to application space. ASID可以8位或16位. 一般配置在TTBR0_EL1中. Having the current value of the ASID stored in the translation table register means that you can atomically modify both the translation tables as well as the ASID in a single instruction. This simplifies the process of changing the table and ASID when compared with the ARMv7-A Architecture. 把ASID值放在TTBR0_EL1里的好处是, 一个指令就可以原子的更改ASID和页表. Additionally, the ARMv8-A Architecture provides Thread ID registers for use by operating system software. These have no hardware significance and are typically used by threading libraries as a base pointer to per-thread data. This is often referred to as Thread Local Storage (TLS). For example, the pthreads library uses this feature and includes the following registers: User Read and Write Thread ID Register (TPIDR_EL0). User Read-Only Thread ID Register (TPIDRRO_EL0). Thread ID Register, privileged accesses only (TPIDR_EL1). TPIDR(Thread ID registers)是给系统软件保存Thread Local Storage (TLS)用的. EL0可以用TPIDR_EL0 EL1还有TPIDR_EL1 什么是VHE Note: The DynamIQ processors (Cortex-A55, Cortex-A75 and Cortex-A76) support Virtualization Host Extensions (VHEs). 通常kernel运行在EL1, 一个同样的kernel, 如果运行在VHE使能了, 硬件会重定向寄存器访问: We saw in the section on Virtualizing generic timers that enabling VHE changes the layout of the EL2 virtual address space. However, we still have a problem with the configuration of the MMU. This is because our kernel will try to access _EL1 registers, such as TTBR0_EL1, rather than _EL2 registers such as TTBR0_EL2. To run the same binary at EL2, we need to redirect the accesses from the EL1 registers to the EL2 equivalents. Setting E2H will do this, so that accesses to _EL1 system registers are redirected to their EL2 equivalents. This redirection illustrated in the following diagram: "},"notes/rust_入门_brief.html":{"url":"notes/rust_入门_brief.html","title":"入门系列","keywords":"","body":"我在学习rust语法过程中的笔记, 大部分来自于网上摘录, 略有更改. "},"notes/rust_books.html":{"url":"notes/rust_books.html","title":"reference books","keywords":"","body":"参考书目: 文档汇总: https://www.rust-lang.org/learn 语法: https://doc.rust-lang.org/book 语法参考: https://doc.rust-lang.org/reference 标准库: https://doc.rust-lang.org/std/index.html 例子: https://doc.rust-lang.org/stable/rust-by-example cargo: https://doc.rust-lang.org/stable/cargo rustup: https://rust-lang.github.io/rustup 交叉编译: https://rust-lang.github.io/rustup/cross-compilation.html "},"notes/rust_入门1.html":{"url":"notes/rust_入门1.html","title":"安装和基础语法","keywords":"","body":" 安装 组件 rustup hello world 基础语法 格式化输出 语法糖 变量 类型推导 默认只读 变量遮蔽 类型别名 全局变量 基本数据类型 指针 什么是Box 什么是Rc 类型转换 字符串 复合数据类型 tuple 元组 数组 数组切片 字符串切片 非字符串切片 索引和边界检查 struct 部分初始化 输出结构体 tuple struct 元组结构体 举例 结构体方法 结构体关联函数 普遍方法 静态方法 enum enum和match 经常出现的Option就是一种enum if let代替match 表达式 if else if let和while let 循环 函数 发散函数Diverging functions main函数 const_fn trait 默认trait trait做参数 匿名trait Box impl trait for trait 为别人的类型实现trait trait不能做为参数, 返回值, 实例变量 调用trait 方法和函数没有本质不同? trait约束 trait继承 derive 常见trait 带关联类型的trait 模式解构 match ref和mut 知晓变量类型 方案一: 利用编译错误来获取变量类型 方案二: 使用标准库 方案三: 不需要nightly版本 问号操作符 问号操作背后 安装 使用rustup安装: curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh 安装了如下的文件: $ ls /home/yingjieb/.rustup downloads settings.toml tmp toolchains update-hashes $ ls /home/yingjieb/.cargo bin env $ ls /home/yingjieb/.cargo/bin cargo cargo-fmt clippy-driver rustc rustfmt rust-lldb cargo-clippy cargo-miri rls rustdoc rust-gdb rustup 在/home/yingjieb/.profile增加了 . \"$HOME/.cargo/env\" 在/home/yingjieb/.bashrc增加了 . \"$HOME/.cargo/env\" 这个env主要就是干了一件事: export PATH=\"$HOME/.cargo/bin:$PATH\" 组件 默认安装了如下组件: cargo 5.7 MiB clippy rust-docs rust-std 34.9 MiB rustc 74.2 MiB rustfmt 如果是在你的CI环境下只想用rustc来编译, 可以指定profile为minimal 比如 ## install RUST ARG RUST_TOOLCHAIN=\"1.60.0\" RUN mkdir $CARGO_HOME && chmod 777 $CARGO_HOME RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --profile minimal --default-toolchain \"$RUST_TOOLCHAIN\" \\ && rustup target add x86_64-unknown-linux-musl --toolchain \"$RUST_TOOLCHAIN\" \\ && rustup component add rustfmt \\ && rustup component add clippy rustup rustup是管理rust工具链的工具: $ rustup -V rustup 1.24.3 (ce5817a94 2021-05-31) info: This is the version for the rustup toolchain manager, not the rustc compiler. info: The currently active `rustc` version is `rustc 1.59.0 (9d1b2106e 2022-02-23) hello world $ cat hello.rs fn main() { println!(\"hello world!\"); } $ rustc hello.rs yingjieb@godev-server /repo/yingjieb/rust/practice $ ls hello hello.rs yingjieb@godev-server /repo/yingjieb/rust/practice $ ./hello hello world! yingjieb@godev-server /repo/yingjieb/rust/practice $ file hello hello: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=ae53c8a4def1de8266d96cfe6dc8d8074ffa1d2b, with debug_info, not stripped $ llh hello -rwxr-xr-x 1 yingjieb platform 3.5M Mar 23 02:59 hello yingjieb@godev-server /repo/yingjieb/rust/practice $ ldd hello linux-vdso.so.1 (0x00007ffce327e000) libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fe769517000) librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fe76930f000) libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fe7690f0000) libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fe768eec000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fe768afb000) /lib64/ld-linux-x86-64.so.2 (0x00007fe769979000) $ strip hello yingjieb@godev-server /repo/yingjieb/rust/practice $ llh total 300K -rwxr-xr-x 1 yingjieb platform 295K Mar 23 03:05 hello -rw-r--r-- 1 yingjieb platform 44 Mar 23 02:59 hello.rs 可以看到编译出来的hello可执行程序达到3.5M, 而且还动态链接了c库. strip后是295K. 这个大小正常 $ size -A hello hello : section size addr .interp 28 624 .note.ABI-tag 32 652 .note.gnu.build-id 36 684 .gnu.hash 28 720 .dynsym 1800 752 .dynstr 1232 2552 .gnu.version 150 3784 .gnu.version_r 224 3936 .rela.dyn 16776 4160 .rela.plt 96 20936 .init 23 21032 .plt 80 21056 .plt.got 8 21136 .text 217583 21152 .fini 9 238736 .rodata 20335 238752 .eh_frame_hdr 3772 259088 .eh_frame 21392 262864 .gcc_except_table 2972 284256 .tdata 40 2384528 .tbss 57 2384576 .init_array 16 2384576 .fini_array 8 2384592 .data.rel.ro 9280 2384600 .dynamic 576 2393880 .got 1696 2394456 .data 56 2396160 .bss 456 2396216 .comment 41 0 .debug_aranges 37632 0 .debug_pubnames 401408 0 .debug_info 785107 0 .debug_abbrev 3086 0 .debug_line 413191 0 .debug_frame 96 0 .debug_str 1057897 0 .debug_pubtypes 144 0 .debug_ranges 514768 0 Total 3512131 实际上是debug信息占了绝大部分size. 基础语法 用//或/**/来注释 函数声明fn Foo( input1 : i32, input2 : u32) -> i32 { ... } 局部变量声明使用let关键字开头，用双引号包含起来的部分是字符串常量 分号结尾 最简单的标准输出是使用println！宏来完成. println后面的感叹号，它代表这是一个宏，而不是一个函数。 代码组织: crate: 类似项目概念 mod: 类似namespace概念 std: 标准库. 编译器会为用户写的每个crate自动插入一句话 use std::prelude::*; 函数可以在使用的位置后面声明 格式化输出 fn main() { println!(\"{}\", 1); // 打印变量的默认格式 println!(\"{:o}\", 9); // 八进制 println!(\"{:x}\", 255); // 十六进制 小写 println!(\"{:X}\", 255); // 十六进制 大写 println!(\"{:p}\", &0); // 指针 println!(\"{:b}\", 15); // 二进制 println!(\"{:e}\", 10000f32); // 科学计数(小写) println!(\"{:E}\", 10000f32); // 科学计数(大写) println!(\"{:?}\", \"test\"); // 打印Debug println!(\"{:#?}\", (\"test1\", \"test2\")); // 带换行和缩进的Debug打印 println!(\"{a} {b} {b}\", a = \"x\", b = \"y\"); // 命名参数 } 从属于std::fmt模块, 这些是宏可以做编译时检查, 最终是调用std::io里面的函数输出. 语法糖 ..表示rangefn main() { let r = 1..10; // r是一个Range,中间是两个点,代表[1,10)这个区间 for i in r { print!(\"{:?}\\t\", i); } } 两个小数点的语法仅仅是一个“语法糖”而已，用它构造出来的变量 是Range类型use std::ops::Range; fn main() { let r = Range { start: 1, end: 10 }; // r是一个Range for i in r { print!(\"{:?}\\t\", i); } } 这个类型本身实现了Iterator trait，因此它可以直接应用到循环语句中。Range具有迭代器的全部功能，因此它能调用迭代器的成员方法。fn main() { use std::iter::Iterator; // 先用rev方法把这个区间反过来,然后用map方法把每个元素乘以10 let r = (1i32..11).rev().map(|i| i * 10); for i in r { print!(\"{:?}\\t\", i); } } 左闭右开: start..end 左闭右闭: start..=end 变量 Rust的变量必须先声明后使用, 变量必须初始化, 不初始化会报错。对于局部变量，最常见的声明语法为： let variable : i32 = 100; 类型推导 变量类型可以推导: let x = 5; 而且类型推导比较强大: fn main() { // 没有明确标出变量的类型,但是通过字面量的后缀, // 编译器知道elem的类型为u8 let elem = 5u8; // 创建一个动态数组,数组内包含的是什么元素类型可以不写 let mut vec = Vec::new(); vec.push(elem); // 到后面调用了push函数,通过elem变量的类型, // 编译器可以推导出vec的实际类型是 Vec println!(\"{:?}\", vec); } 我们甚至还可以只写一部分类型，剩下的部分让编译器去推导，比如下面的这个程序，我们只知道players变量是Vec动态数组类型，但是里面包含什么元素类型并不清楚，可以在尖括号中用下划线来代替： fn main() { let player_scores = [ (\"Jack\", 20), (\"Jane\", 23), (\"Jill\", 18), (\"John\", 19), ]; // players 是动态数组,内部成员的类型没有指定,交给编译器自动推导 let players : Vec = player_scores .iter() .map(|&(player, _score)| { player }) .collect(); println!(\"{:?}\", players); } 默认只读 默认变量是只读的, 重新赋值会出错: fn main() { let x = 5; x = 10; //编译错误: re-assignment of immutable variable`x` } 加mut关键字才能可写: let mut x = 5; // mut x: i32 x = 10; 按照我的理解, 第一次赋值叫变量绑定, 后面再修改需要加mut fn test(condition: bool) { let x: i32; // 声明 x,不必使用 mut 修饰 if condition { x = 1; // 初始化 x,不需要 x 是 mut 的,因为这是初始化,不是修改 println!(\"{}\", x); } // 如果条件不满足,x 没有被初始化 // 但是没关系,只要这里不使用 x 就没事 } 类型没有“默认构造函数”，变量没有“默认值”。对于let x：i32；如果没有显式赋值，它就没有被初始化，不要想当然地以为它的值是0。编译器会做变量检查, 没有\"绑定\"的使用会报错. 变量遮蔽 比如 fn main() { let x = \"hello\"; println!(\"x is {}\", x); let x = 5; println!(\"x is {}\", x); } 第二个let x中的x把前面的x遮蔽了, 这两个x是两个变量, 类型和在内存里的空间都不一样; 前面的x实际上从此不能再次被访问到 变量遮蔽在类型转换, 改变变量读写属性时很有用: // 注意：这段代码只是演示变量遮蔽功能,并不是Vec类型的最佳初始化方法 fn main() { let mut v = Vec::new(); // v 必须是mut修饰,因为我们需要对它写入数据 v.push(1); v.push(2); v.push(3); let v = v; // 从这里往下,v成了只读变量,可读写变量v已经被遮蔽,无法再访问 for i in &v { println!(\"{}\", i); } } 反过来也行 fn main() { let v = Vec::new(); //v是不可变的 let mut v = v; //这个v可变, 这个v和上面的v已经不是一个v了 v.push(1); println!(\"{:?}\", v); } 类型别名 type Age = u32; fn grow(age: Age, year: u32) -> Age { age + year } fn main() { let x : Age = 20; println!(\"20 years later: {}\", grow(x, 20)); } 或者用在泛型场景里: type Double = (T, Vec); // 小括号包围的是一个 tuple,请参见后文中的复合数据类型 // 那么以后使用Double的时候，就等同于（i32，Vec） 全局变量 比如: static GLOBAL: i32 = 0; 全局变量必须是静态变量 全局变量必须在声明的时候马上初始化 全局变量的初始化必须是编译期可确定的常量，不能包括执行期才能确定的表达式、语句和函数调用// 这样是允许的 static array : [i32; 3] = [1,2,3]; // 这样是不允许的 static vec : Vec = { let mut v = Vec::new(); v.push(1); v }; 但使用const fn是可以的:#![feature(const_fn)] fn main() { use std::sync::atomic::AtomicBool; static FLAG: AtomicBool = AtomicBool::new(true); } 带有mut修饰的全局变量，在使用的时候必须使用unsafe关键字 fn main() { //局部变量声明,可以留待后面初始化,只要保证使用前已经初始化即可 let x; let y = 1_i32; x = 2_i32; println!(\"{} {}\", x, y); //全局变量必须声明的时候初始化,因为全局变量可以写到函数外面,被任意一个函数使用 static G1 : i32 = 3; println!(\"{}\", G1); //可变全局变量无论读写都必须用 unsafe修饰 static mut G2 : i32 = 4; unsafe { G2 = 5; println!(\"{}\", G2); } //全局变量的内存不是分配在当前函数栈上,函数退出的时候,并不会销毁全局变量占用的内存空间,程序退出才会回收 } 基本数据类型 boolfn main() { let x = true; let y: bool = !x; // 取反运算 let z = x && y; // 逻辑与,带短路功能 println!(\"{}\", z); let z = x || y; // 逻辑或,带短路功能 println!(\"{}\", z); let z = x & y; // 按位与,不带短路功能 println!(\"{}\", z); let z = x | y; // 按位或,不带短路功能 println!(\"{}\", z); let z = x ^ y; // 按位异或,不带短路功能 println!(\"{}\", z); } charlet love = '❤'; // 可以直接嵌入任何 unicode 字符 let c1 = '\\n'; // 换行符 let c2 = '\\x7f'; // 8 bit 字符变量 let c3 = '\\u{7FFF}'; // unicode字符 因为char类型的设计目的是描述任意一个unicode字符，因此它占据的内存空间不是1个字节，而是4个字节 用u8或者前面加b前缀来表示1个字节的ASCII字符let x :u8 = 1; let y :u8 = b'A'; let s :&[u8;5] = b\"hello\"; let r :&[u8;14] = br#\"hello \\n world\"#; //这里表示byte的raw string, 好像去掉前后的#也行 注意这里的b\"hello\"和\"hello\"不一样:fn print_type_of(t: &T) { println!(\"{:#?}: {}\", t, std::any::type_name::()) } fn main() { print_type_of(&\"hello\"); print_type_of(&b\"hello\"); } //结果 \"hello\": &str [ 104, 101, 108, 108, 111, ]: &[u8; 5] 整型 用i或者u加位位宽表示, 比如i32 u64 i128等. 指针用isize或者usize表示, 在32位机器上是32位, 在64位机器上是64位.let var1 : i32 = 32; // 十进制表示 let var2 : i32 = 0xFF; // 以0x开头代表十六进制表示 let var3 : i32 = 0o55; // 以0o开头代表八进制表示 let var4 : i32 = 0b1001; // 以0b开头代表二进制表示 let var5 = 0x_1234_ABCD; //使用下划线分割数字,不影响语义,但是极大地提升了阅读体验。 let var6 = 123usize; // i6变量是usize类型 let var7 = 0x_ff_u8; // i7变量是u8类型 let var8 = 32; // 不写类型,默认为 i32 类型 rust可以在整型溢出时panic, 但需要\"debug\"版本编译, 比如rustc test.rs, 而rustc -O test.rs产生的\"release\"版本则不会panic, 而是自动截断. 通过开关rustc -C overflow-checks=no test.rs可以控制这个行为. 浮点let f1 = 123.0f64; // type f64 let f2 = 0.1f64; // type f64 let f3 = 0.1f32; // type f32 let f4 = 12E+99_f64; // type f64 科学计数法 let f5 : f64 = 2.; // type f64 指针 类型名 简介 Box 指向类型T的, 具有所有权的指针, 有权释放内存; T在堆中分配 &T 指向类型T的借用指针, 也称为引用, 无权释放内存, 无权写数据 &mut T 指向类型T的mut借用指针, 无权释放内存, 有权写数据 *const T 指向类型T的只读指针, 没有生命周期信息, 无权写数据 *mut T 指向类型T的读写指针, 没有生命周期信息, 有权写数据 注: &T是借用指针, 而*T实际上也存在的, 叫raw pointer. 但是必须以*mut T或*const T存在. 一般raw pointer不常用. 除此之外，在标准库中还有一种封装起来的可以当作指针使用的类型，叫“智能指针”（smart pointer） 类型名 简介 Rc 指向类型T的引用计数指针, 共享所有权, 线程不安全 Arc 指向类型T的原子引用计数指针, 共享所有权, 线程安全 Cow clone on write, 写时复制指针. 可能是借用指针, 也可能是具有所有权的指针 什么是Box Box是指向堆中类型为T的变量的指针. 这个T可以是unsized的. All values in Rust are stack allocated by default. Values can be boxed (allocated on the heap) by creating a Box. A box is a smart pointer to a heap allocated value of type T. When a box goes out of scope, its destructor is called, the inner object is destroyed, and the memory on the heap is freed. 默认变量是分配在栈上的, 用Box可以指定分配到堆上. 除了在堆上分配内存, Box没有其他的性能损失. 比如下面的代码: fn main() { let b = Box::new(5); //在堆中分配int32类型的5, Box这个\"指针\"是在栈上. 当b离开scope的时候, 堆上的数字5会被回收. println!(\"b = {}\", b); } 这个例子在堆里分配一个i32并没有实际意义, 只是演示Box的分配原理. Box的使用情况: When you have a type whose size can’t be known at compile time and you want to use a value of that type in a context that requires an exact size When you have a large amount of data and you want to transfer ownership but ensure the data won’t be copied when you do so 在堆里分配的数据在转移所有权的时候不拷贝. When you want to own a value and you care only that it’s a type that implements a particular trait rather than being of a specific type 什么是Rc To enable multiple ownership, Rust has a type called Rc, which is an abbreviation for reference counting. The Rc type keeps track of the number of references to a value to determine whether or not the value is still in use. If there are zero references to a value, the value can be cleaned up without any references becoming invalid. We use the Rc type when we want to allocate some data on the heap for multiple parts of our program to read and we can’t determine at compile time which part will finish using the data last. 比如b和c都\"拥有\"a这个链表 如果用Box是不行的: enum List { Cons(i32, Box), Nil, } use crate::List::{Cons, Nil}; fn main() { let a = Cons(5, Box::new(Cons(10, Box::new(Nil)))); let b = Cons(3, Box::new(a)); let c = Cons(4, Box::new(a)); // 当a move进b的时候, 所有权已经转给b了. a就不能再访问了. } The Cons variants own the data they hold, so when we create the b list, a is moved into b and b owns a. Then, when we try to use a again when creating c, we’re not allowed to because a has been moved. 下面的代码把Box换成了Rc Instead, we’ll change our definition of List to use Rc in place of Box, as shown in Listing 15-18. Each Cons variant will now hold a value and an Rc pointing to a List. When we create b, instead of taking ownership of a, we’ll clone the Rc that a is holding, thereby increasing the number of references from one to two and letting a and b share ownership of the data in that Rc. We’ll also clone a when creating c, increasing the number of references from two to three. Every time we call Rc::clone, the reference count to the data within the Rc will increase, and the data won’t be cleaned up unless there are zero references to it. enum List { Cons(i32, Rc), Nil, } use crate::List::{Cons, Nil}; use std::rc::Rc; fn main() { let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); let b = Cons(3, Rc::clone(&a)); //这里是clone应该只是clone包装, 而不是clone里面的数据, 但增加引用计数. let c = Cons(4, Rc::clone(&a)); } 注: 用Rc::clone(&a)和a.clone()是一样的. 前者更隐含了是浅拷贝的意思, 开销非常小. 类型转换 Rust对不同类型之间的转换控制得非常严格。即便是下面这样的程序，也会出现编译错误 fn main() { let var1 : i8 = 41; let var2 : i16 = var1; } Rust提供了一个关键字as，专门用于这样的类型转换 fn main() { let var1 : i8 = 41; let var2 : i16 = var1 as i16; } 类型不能随便转换: let a = \"some string\"; let b = a as u32; // 编译错误 有时必须用多个as转换 fn main() { let i = 42; // 先转为 *const i32,再转为 *mut i32 let p = &i as *const i32 as *mut i32; println!(\"{:p}\", p); } 字符串 Rust的字符串涉及两种类型，一种是&str，另外一种是String.str是Rust的内置类型。&str是对str的借用。Rust的字符串内部默认是使用utf-8编码格式的。而内置的char类型是4字节长度的，存储的内容是Unicode Scalar Value。所以，Rust里面的字符串不能视为char类型的数组，而更接近u8类型的数组. [T]是DST类型，对应的str是DST类型。 &[T]是数组切片类型，对应的&str是字符串切片类型.下面的代码能编过 &str是个胖指针, 它对指向的字符串没有所有权. let greeting : &str = \"Hello\"; fn main() { let greeting: &str = \"Hello\"; let substr: &str = &greeting[2..]; println!(\"{}\", substr); } &greeting[2..]去掉&就编译不过 我们没办法扩大greeting所引用的范围，在它后面增加内容。但是String类型可以: fn main() { let mut s = String::from(\"Hello\"); s.push(' '); s.push_str(\"World.\"); println!(\"{}\", s); } &String类型可以被编译器自动转换为&str类型: fn capitalize(substr: &mut str) { substr.make_ascii_uppercase(); } fn main() { let mut s = String::from(\"Hello World\"); capitalize(&mut s); println!(\"{}\", s); } 在这个例子中，capitalize函数调用的时候，形式参数要求是&mut str类型，而实际参数是&mut String类型，这里编译器给我们做了自动类型转换。在capitalize函数内部，它有权修改&mut str所指向的内容，但是无权给这个字符串扩容或者释放内存。 复合数据类型 tuple 元组 用一对 () 包括的一组数据，可以包含不同种类的数据 let a = (1i32, false); // 元组中包含两个元素,第一个是i32类型,第二个是bool类型 let b = (\"a\", (1i32, 2i32)); // 元组中包含两个元素,第二个元素本身也是元组,它又包含了两个元素 只有一个元素要加逗号 let a = (0,); // a是一个元组,它有一个元素 let b = (0); // b是一个括号表达式,它是i32类型 访问tuple可以用模式匹配 let p = (1i32, 2i32); let (a, b) = p; //模式匹配 let x = p.0; //数字索引 let y = p.1; //数字索引 println!(\"{} {} {} {}\", a, b, x, y); 空元组占用0内存空间: let empty : () = (); fn main() { println!(\"size of i8 {}\" , std::mem::size_of::()); println!(\"size of char {}\" , std::mem::size_of::()); println!(\"size of '()' {}\" , std::mem::size_of::()); } 注: size_of的原型是 pub const fn size_of() -> usize 这个函数没有入参, 但需要实例化类型参数T 本例中这样调用: std::mem::size_of::() 用了双冒号实例化类型参数的方式. 数组 用一对 [] 包括的同类型数据数组是一个容器，它在一块连续空间内存中，存储了一系列的同样类型的数据。数组中元素的占用空间大小必须是编译期确定的。数组本身所容纳的元素个数也必须是编译期确定的，执行阶段不可变。如果需要使用变长的容器，可以使用标准库中的Vec/LinkedList等。数组类型的表示方式为[T;n]。其中T代表元素类型；n代表元素个数；它必须是编译期常量整数；中间用分号隔开。 let a = [1, 2, 3, 4, 5]; // a 是一个长度为 5 的整型数组 let b = [\"January\", \"February\", \"March\"]; // b 是一个长度为 3 的字符串数组 let c: [i32; 5] = [1, 2, 3, 4, 5]; // c 是一个长度为 5 的 i32 数组 let d = [3; 5]; // 等同于 let d = [3, 3, 3, 3, 3]; let first = a[0]; let second = a[1]; // 数组访问 a[0] = 123; // 错误：数组 a 不可变 let mut a = [1, 2, 3]; a[0] = 4; // 正确 只有元素类型和元素个数都完全相同，这两个数组才是同类型的。数组与指针之间不能隐式转换。同类型的数组之间可以互相赋值 fn main() { let mut xs: [i32; 5] = [1, 2, 3, 4, 5]; let ys: [i32; 5] = [6, 7, 8, 9, 10]; xs = ys; xs[0] = 111; println!(\"new array {:?}\", xs); println!(\"old array {:?}\", ys); } //output new array [111, 7, 8, 9, 10] old array [6, 7, 8, 9, 10] 把数组xs作为参数传给一个函数，这个数组并不会退化成一个指针。而是会将这个数组完整复制进这个函数。函数体内对数组的改动不会影响到外面的数组。 这里再解释一下, rust的数组赋值(或者说是move), 是拷贝完整数组. rust默认在栈上分配变量, 如果想在退出作用域的时候继续使用数据, 用Box来声明变量. 数组可以直接比较: fn main() { let v1 = [1, 2, 3]; let v2 = [1, 2, 4]; println!(\"{:?}\", v1 数组支持for in fn main() { let v = [0_i32; 10]; for i in &v { println!(\"{:?}\", i); } } 数组切片 对数组取借用borrow操作，可以生成一个“数组切片”（Slice）。数组切片对数组没有“所有权”，我们可以把数组切片看作专门用于指向数组的指针，是对数组的另外一个“视图”。比如，我们有一个数组[T; n]，它的借用指针的类型就是&[T; n]。它可以通过编译器内部魔法转换为数组切片类型&[T]。数组切片实质上还是指针，它不过是在类型系统中丢弃了编译阶段定长数组类型的长度信息，而将此长度信息存储为运行期的值。示例如下: fn main() { fn mut_array(a: &mut [i32]) { a[2] = 5; } println!(\"size of &[i32; 3] : {:?}\", std::mem::size_of::()); println!(\"size of &[i32] : {:?}\", std::mem::size_of::()); let mut v: [i32; 3] = [1, 2, 3]; { let s: &mut [i32; 3] = &mut v; mut_array(s); } println!(\"{:?}\", v); } 变量v是[i32; 3]类型；变量s是&mut[i32; 3]类型，占用的空间大小与指针相同。它可以自动转换为&mut[i32]数组切片类型传入函数 mut_array，占用的空间大小等于两个指针的空间大小。通过这个指针，在函数内部，修改了外部的数组v的值。 数组切片是指向一个数组的指针，而它比指针又多了一点东西——它不止包含有一个指向数组的指针，切片本身还含带长度信息。又叫胖指针.由于不定长数组类型[T]在编译阶段是无法判断该类型占用空间的大小的，目前我们不能在栈上声明一个不定长大小数组的变量实例，也不能用它作为函数的参数、返回值。但是，指向不定长数组的胖指针的大小是确定的，&[T]类型可以用做变量实例、函数参数、返回值。 字符串切片 fn main() { let s = String::from(\"broadcast\"); let part1 = &s[0..5]; let part2 = &s[5..9]; println!(\"{}={}+{}\", s, part1, part2); } // broadcast=broad+cast 非字符串切片 fn main() { let arr = [1, 3, 5, 7, 9]; let part = &arr[0..3]; for i in part.iter() { println!(\"{}\", i); } } 索引和边界检查 rust的索引是会边界检查的. 如果越界会panic 数组的index操做执行的是下面的代码: impl ops::Index for [T] { type Output = T; fn index(&self, index: usize) -> &T { assert!(index 实际上, 自己也可以定义index操做, 只要满足 std::ops::Index trait //索引读操做 std::ops::IndexMut trait //索引写操做 一般情况下，Rust不鼓励大量使用“索引”操作。正常的“索引”操作 都会执行一次“边界检查”。从执行效率上来说，Rust比C/C++的数组索引效率低一点，因为C/C++的索引操作是不执行任何安全性检查的，它们对应的Rust代码相当于调用get_unchecked()函数更推荐使用迭代器 fn main() { use std::iter::Iterator; let v = &[10i32, 20, 30, 40, 50]; // 如果我们同时需要index和内部元素的值,调用enumerate()方法 for (index, value) in v.iter().enumerate() { println!(\"{} {}\", index, value); } // filter方法可以执行过滤,nth函数可以获取第n个元素 let item = v.iter().filter(|&x| *x % 2 == 0).nth(2); println!(\"{:?}\", item); } 注: filter的原型如下, 可以看到闭包的入参是引用&Self::Item fn filter(self, predicate: P) -> Filter where Self: Sized, P: FnMut(&Self::Item) -> bool, { Filter::new(self, predicate) } FnMut原型如下, 闭包都会自动实现FnMut. pub trait FnMut: FnOnce { extern \"rust-call\" fn call_mut( &mut self, args: Args ) -> Self::Output; } struct 普通结构体定义: struct Site { domain: String, name: String, nation: String, found: u32 } 普通结构体实例化: let runoob = Site { domain: String::from(\"www.runoob.com\"), name: String::from(\"RUNOOB\"), nation: String::from(\"China\"), found: 2013 }; 举例: struct Point { x: i32, y: i32, } fn main() { let p = Point { x: 0, y: 0}; println!(\"Point is at {} {}\", p.x, p.y); } fn main() { // 刚好局部变量名字和结构体成员名字一致 let x = 10; let y = 20; // 下面是简略写法,等同于 Point { x: x, y: y },同名字的相对应 let p = Point { x, y }; println!(\"Point is at {} {}\", p.x, p.y); } 访问struct内部的元素: fn main() { let p = Point { x: 0, y: 0}; // 声明了px 和 py,分别绑定到成员 x 和成员 y let Point { x : px, y : py } = p; println!(\"Point is at {} {}\", px, py); // 同理,在模式匹配的时候,如果新的变量名刚好和成员名字相同,可以使用简写方式 let Point { x, y } = p; println!(\"Point is at {} {}\", x, y); } 部分初始化 Rust设计了一个语法糖，允许用一种简化的语法赋值使用另外一个 struct的部分成员。比如： struct Point3d { x: i32, y: i32, z: i32, } fn default() -> Point3d { Point3d { x: 0, y: 0, z: 0 } } // 可以使用default()函数初始化其他的元素 // ..expr 这样的语法,只能放在初始化表达式中,所有成员的最后最多只能有一个 let origin = Point3d { x: 5, ..default()}; let point = Point3d { z: 1, x: 2, ..origin }; 输出结构体 调试中，完整地显示出一个结构体实例是非常有用的。但如果我们手动的书写一个格式会非常的不方便。所以 Rust 提供了一个方便地输出一整个结构体的方法： #[derive(Debug)] struct Rectangle { width: u32, height: u32, } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\"rect1 is {:?}\", rect1); } 如第一行所示：一定要导入调试库 #[derive(Debug)] ，之后在 println 和 print 宏中就可以用 {:?} 占位符输出一整个结构体： rect1 is Rectangle { width: 30, height: 50 } 如果属性较多的话可以使用另一个占位符 {:#?} rect1 is Rectangle { width: 30, height: 50 } tuple struct 元组结构体 有一种更简单的定义和使用结构体的方式：元组结构体。 元组结构体是一种形式是元组的结构体。 与元组的区别是它有名字和固定的类型格式。它存在的意义是为了处理那些需要定义类型（经常使用）又不想太复杂的简单数据： struct Color(u8, u8, u8); struct Point(f64, f64); let black = Color(0, 0, 0); let origin = Point(0.0, 0.0); \"颜色\"和\"点坐标\"是常用的两种数据类型，但如果实例化时写个大括号再写上两个名字就为了可读性牺牲了便捷性，Rust不会遗留这个问题。元组结构体对象的使用方式和元组一样，通过. 和下标来进行访问： fn main() { struct Color(u8, u8, u8); struct Point(f64, f64); let black = Color(0, 0, 0); let origin = Point(0.0, 0.0); println!(\"black = ({}, {}, {})\", black.0, black.1, black.2); println!(\"origin = ({}, {})\", origin.0, origin.1); } 举例 //以下三种都可以,内部可以没有成员: 空struct struct Foo1; struct Foo2(); struct Foo3{} // struct有名字, 但成员不用名字, 这种类型的叫tuple struct struct Color(i32, i32, i32); struct Point(i32, i32, i32); // 可以类似下面的结构体: struct Color{ 0: i32, 1: i32, 2: i32, } struct Point { 0: i32, 1: i32, 2: i32, } 举例: // define struct struct T1 { v: i32 } // define tuple struct struct T2(i32); fn main() { let v1 = T1 { v: 1 }; let v2 = T2(1); // init tuple struct let v3 = T2 { 0: 1 }; // init tuple struct let i1 = v1.v; let i2 = v2.0; let i3 = v3.0; } fn main() { struct Inches(i32); fn f1(value : Inches) {} fn f2(value : i32) {} let v : i32 = 0; f1(v); // 编译不通过,'mismatched types' f2(v); } fn type_alias() { type I = i32; fn f1(v : I) {} fn f2(v : i32) {} let v : i32 = 0; f1(v); //可以编译过, 因为type只是别名 f2(v); } 结构体方法 第一个入参是&self的函数就是这个结构体方法, 用impl块包住: struct Rectangle { width: u32, height: u32, } impl Rectangle { fn area(&self) -> u32 { self.width * self.height } } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\"rect1's area is {}\", rect1.area()); } //结果 //rect1's area is 1500 请注意，在调用结构体方法的时候不需要填写 self ，这是出于对使用方便性的考虑。 结构体关联函数 impl块里面的没有用&self的函数就是关联函数, 使用的时候要加这个结构体的前缀:: #[derive(Debug)] struct Rectangle { width: u32, height: u32, } impl Rectangle { fn create(width: u32, height: u32) -> Rectangle { Rectangle { width, height } } } fn main() { let rect = Rectangle::create(30, 50); println!(\"{:?}\", rect); } //结果 //Rectangle { width: 30, height: 50 } 普遍方法 在Rust中，我们可以为任何一个类型添加方法，整型也不例外。比如在标准库中，整数类型有一个方法是pow，它可以计算n次幂，于是我们可以这么使用： let x : i32 = 9; println!(\"9 power 3 = {}\", x.pow(3)); println!(\"9 power 3 = {}\", 9_i32.pow(3)); //也可以直接使用字面量来调用方法 静态方法 没有receiver参数的方法（第一个参数不是self参数的方法）称作“静态方法”。静态方法可以通过Type::FunctionName()的方式调用。 需要注意的是，即便我们的第一个参数是Self相关类型，只要变量名字不是self，就不能使用小数点的语法调用函数。 struct T(i32); impl T { // 这是一个静态方法 fn func(this: &Self) { println!{\"value {}\", this.0}; } } fn main() { let x = T(42); // x.func(); 小数点方式调用是不合法的 T::func(&x); } trait也可以定义静态函数: pub trait Default { fn default() -> Self; } Default trait实际上可以看作一个针对无参数构造函数的统一抽象 impl Default for Vec { fn default() -> Vec { Vec::new() } } enum 枚举类在 Rust 中并不像其他编程语言中的概念那样简单，但依然可以十分简单的使用： #[derive(Debug)] enum Book { Papery, Electronic } fn main() { let book = Book::Papery; println!(\"{:?}\", book); } // 结果 // Papery 书分为纸质书（Papery book）和电子书（Electronic book）。 如果你现在正在开发一个图书管理系统，你需要描述两种书的不同属性（纸质书有索书号，电子书只有 URL），你可以为枚举类成员添加元组属性描述： enum Book { Papery(u32), Electronic(String), } let book = Book::Papery(1001); let ebook = Book::Electronic(String::from(\"url://...\")); 如果你想为属性命名，可以用结构体语法： enum Book { Papery { index: u32 }, Electronic { url: String }, } let book = Book::Papery{index: 1001}; 虽然可以如此命名，但请注意，并不能像访问结构体字段一样访问枚举类绑定的属性。访问的方法在 match 语法中。 enum有或的意思, 下面的Number就是或者是Int, 或者是Float enum Number { Int(i32), Float(f32), } fn read_num(num: &Number) { match num { // 如果匹配到了 Number::Int 这个成员,那么value的类型就是 i32 &Number::Int(value) => println!(\"Integer {}\", value), // 如果匹配到了 Number::Float 这个成员,那么value的类型就是 f32 &Number::Float(value) => println!(\"Float {}\", value), } } fn main() { let n: Number = Number::Int(10); read_num(&n); } 在Rust中，enum和struct为内部成员创建了新的名字空间。如果要访问内部成员，可以使用::符号 enum Message { Quit, ChangeColor(i32, i32, i32), Move { x: i32, y: i32 }, Write(String), } let x: Message = Message::Move { x: 3, y: 4 }; enum BoardGameTurn { Move { squares: i32 }, Pass, } let y: BoardGameTurn = BoardGameTurn::Move { squares: 1 }; enum和match Rust 通过 match 语句来实现分支结构。先认识一下如何用 match 处理枚举类： fn main() { enum Book { Papery {index: u32}, Electronic {url: String}, } let book = Book::Papery{index: 1001}; let ebook = Book::Electronic{url: String::from(\"url...\")}; match book { Book::Papery { index } => { println!(\"Papery book {}\", index); }, Book::Electronic { url } => { println!(\"E-book {}\", url); } } } // 结果 //Papery book 1001 match 块也可以当作函数表达式来对待，它也是可以有返回值的： match 枚举类实例 { 分类1 => 返回值表达式, 分类2 => 返回值表达式, ... } 但是所有返回值表达式的类型必须一样！ 如果把枚举类附加属性定义成元组，在 match 块中需要临时指定一个名字： enum Book { Papery(u32), Electronic {url: String}, } let book = Book::Papery(1001); match book { Book::Papery(i) => { println!(\"{}\", i); }, Book::Electronic { url } => { println!(\"{}\", url); } } 经常出现的Option就是一种enum enum Option是个标准库里经常用到的类型, 已经被preclude了, 不用use能直接用: enum Option { None, Some(T), } 它表示的含义是“要么存在、要么不存在”。比如Option表达的意思 就是“可以是一个i32类型的值，或者没有任何值”。 Rust引入Option是为了解决Null指针问题 如果你想定义一个可以为空值的类，你可以这样： let opt = Option::Some(\"Hello\"); // 这个opt的类型是core::option::Option 如果你想针对 opt 执行某些操作，你必须先判断它是否是 Option::None： fn main() { let opt = Option::Some(\"Hello\"); match opt { Option::Some(something) => { println!(\"{}\", something); }, Option::None => { println!(\"opt is nothing\"); } } } //结果 //Hello 由于 Option 是 Rust 编译器默认引入的，在使用时可以省略 Option:: 直接写 None 或者 Some()。 fn main() { let t = Some(64); match t { Some(64) => println!(\"Yes\"), _ => println!(\"No\"), } } 总结一下: 如果从逻辑上说，我们需要一个变量确实是可空的，那么就应该显式标明其类型为Option，否则应该直接声明为T类型。从类型系 统的角度来说，这二者有本质区别，切不可混为一谈 不要轻易使用unwrap方法。这个方法可能会导致程序发生 panic。对于小工具来说无所谓，在正式项目中，最好是使用lint工具强制禁止调用这个方法 相对于裸指针，使用Option包装的指针类型的执行效率不会降低，这是“零开销抽象” 不必担心这样的设计会导致大量的match语句，使得程序可读性变差。因为Option类型有许多方便的成员函数，再配合上闭包功能，实际上在表达能力和可读性上要更胜一筹 if let代替match match需要强制做全匹配, 否则会编译报错. 用下划线可以解决编译错误, 但有点笨. 用if let可以更好的表达只关心一部分匹配的情况: if let 匹配值 = 源变量 { 语句块 } 比如 let i = 0; if let 0 = i { println!(\"zero\"); } 更完整的例子: fn main() { enum Book { Papery(u32), Electronic(String) } let book = Book::Electronic(String::from(\"url\")); if let Book::Papery(index) = book { println!(\"Papery {}\", index); } else { println!(\"Not papery book\"); } } 表达式 小知识: ! 按位取反或者逻辑取反, 按照operand类型决定Rust不支持++、--运算符，请使用+=1、-=1替代 rust里面每个表达式都是有类型的, 比如赋值表达式的类型为空的tuple (), 也叫unit fn main() { let x = 1; let mut y = 2; // 注意这里专门用括号括起来了 let z = (y = x); println!(\"{:?}\", z); //编译有警告, 但能运行, 结果为() } 连续语句块的类型是最后一个表达式的类型: // 语句块可以是表达式,注意后面有分号结尾,x的类型是() let x : () = { println!(\"Hello.\"); }; // Rust将按顺序执行语句块内的语句,并将最后一个表达式类型返回,y的类型是 i32 let y : i32 = { println!(\"Hello.\"); 5 }; 利用这个特点, 函数的返回可以不写return fn my_func() -> i32 { // ... blablabla 各种语句 100 //最后一个表达式是100, 是i32. 注意没有分号 } if else fn func(i : i32) { if n 0 { print!(\"{} is positive\", n); } else { print!(\"{} is zero\", n); } } if else也可以当作表达式: let x : i32 = if condition { 1 } else { 10 }; //注意1和10后面不加分号. 因为加了分号表达式的整体类型就变了 if let和while let while-let与if-let一样，提供了在while语句中使用“模式解构”的能力 if let Some(x) = optVal { doSomethingWith(x); } 相当于: match optVal { Some(x) => { doSomethingWith(x); } _ => {} } 也相当于: if optVal.is_some() { // 首先判断它一定是 Some(_) let x = optVal.unwrap(); // 然后取出内部的数据 doSomethingWith(x); } 循环 loop 没条件注意break和continue都可以跳转到外层 我们可以在loop while for循环前面加上“生命周期标识符”。该标识符以单引号开头，在内部的循环中可以使用break语句选择跳出到哪一层。 fn main() { // A counter variable let mut m = 1; let n = 1; 'a: loop { if m 50 { println!(\"break\"); break 'a; } else { continue 'a; } } } } } loop表达式也可以做右值: fn main() { let v = loop { break 10; }; println!(\"{}\", v); } 在loop内部break的后面可以跟一个表达式，这个表达式就是最终的 loop表达式的值。如果一个loop永远不返回，那么它的类型就是“发散类型”。示例如下： fn main() { let v = loop {}; println!(\"{}\", v); //永远到不了这里 } while是带条件的循环 for in是迭代器循环. 没有三段式的语法 函数 fn add1(t : (i32,i32)) -> i32 { t.0 + t.1 } // 模式解构传参 fn add2((x,y) : (i32,i32)) -> i32 { x + y //也可以用return x+y } 函数不写返回类型默认是unit () 函数是一等公民 函数内部可以定义函数, 类型, trait等 虽然add1和add2的入参和出参都一样, 但每个函数都有自己的类型fn main() { // 先让 func 指向 add1 let mut func = add1; // 再重新赋值,让 func 指向 add2 func = add2; //这样不行, 会编译报错. 原因就是函数名也是类型的一部分 } 上面的func声明改成下面的写法就不会出错了:// 写法一,用 as 类型转换 let mut func = add1 as fn((i32,i32))->i32; // 写法二,用显式类型标记 let mut func : fn((i32,i32))->i32 = add1; 但只有add1和add2形式一样的时候才行. 形式不同不能转换. 发散函数Diverging functions 返回类型是!的函数是发散函数, 比如: fn diverges() -> ! { panic!(\"This function never returns!\"); } !可以转换为任何类型 let x : i32 = diverges(); let y : String = diverges(); 比如下面的情况就很有用: let p = if x { panic!(\"error\"); } else { 100 }; 上面的代码能编译通过, 因为!也可以赋值给p 内置发散函数: panic! 以及基于它实现的各种函数/宏，比如unimplemented! unreachable! 死循环loop{} 进程退出函数std::process::exit以及类似的libc中的exec一类函数 main函数 main函数没有入参和返回值, 命令行参数用std::env::args() fn main() { for arg in std::env::args() { println!(\"Arg: {}\", arg); } std::process::exit(0); } const_fn 函数可以用const关键字修饰，这样的函数可以在编译阶段被编译器执行，返回值也被视为编译期常量 #![feature(const_fn)] const fn cube(num: usize) -> usize { num * num * num } fn main() { const DIM : usize = cube(2); const ARR : [i32; DIM] = [0; DIM]; println!(\"{:?}\", ARR); } trait trait的意思是特性 初看和go的interface差不多. trait Shape { fn area(&self) -> f64; } Rust中Self（大写S）和self（小写s）都是关键字，大写S的是类型名，小写s的是变量名 所有的trait中都有一个隐藏的类型Self（大写S），代表当前这个实现了此trait的具体类型 trait T { fn method1(self: Self); fn method2(self: &Self); fn method3(self: &mut Self); } // 上下两种写法是完全一样的 trait T { fn method1(self); fn method2(&self); fn method3(&mut self); } 上面定义的这个area方法的参数的名字为self，它的类型是&Self类型。我们可以把上面这个方法的声明看成： trait Shape { fn area(self: &Self) -> f64; } 假如我们有一个结构体类型Circle，它实现了这个trait，代码如下: struct Circle { radius: f64, } impl Shape for Circle { // Self 类型就是 Circle // self 的类型是 &Self,即 &Circle fn area(&self) -> f64 { // 访问成员变量,需要用 self.radius std::f64::consts::PI * self.radius * self.radius } } fn main() { let c = Circle { radius : 2f64}; // 第一个参数名字是 self,可以使用小数点语法调用 println!(\"The area is {}\", c.area()); } 默认trait 这是特性与接口的不同点：接口只能规范方法而不能定义方法，但特性可以定义方法作为默认方法，因为是\"默认\"，所以对象既可以重新定义方法，也可以不重新定义方法使用默认的方法 trait中可以包含方法的默认实现。如果这个方法在trait中已经有了方法体，那么在针对具体类型实现的时候，就可以选择不用重写 trait Descriptive { fn describe(&self) -> String { String::from(\"[Object]\") } } struct Person { name: String, age: u8 } impl Descriptive for Person { fn describe(&self) -> String { format!(\"{} {}\", self.name, self.age) } } fn main() { let cali = Person { name: String::from(\"Cali\"), age: 24 }; println!(\"{}\", cali.describe()); } //结果 //Cali 24 如果Person不实现describe, 则最后打印 [Object] trait做参数 fn output(object: impl Descriptive) { println!(\"{}\", object.describe()); } 任何实现了 Descriptive 特性的对象都可以作为这个函数的参数，这个函数没必要了解传入对象有没有其他属性或方法，只需要了解它一定有 Descriptive 特性规范的方法就可以了。当然，此函数内也无法使用其他的属性与方法。 特性参数还可以用这种等效语法实现： fn output(object: T) { println!(\"{}\", object.describe()); } 这是一种风格类似泛型的语法糖，这种语法糖在有多个参数类型均是特性的情况下十分实用： fn output_two(arg1: T, arg2: T) { println!(\"{}\", arg1.describe()); println!(\"{}\", arg2.describe()); } 特性作类型表示时如果涉及多个特性，可以用 + 符号表示，例如： fn notify(item: impl Summary + Display) fn notify(item: T) 复杂的实现关系可以使用 where 关键字简化，例如： fn some_function(t: T, u: U) 可以简化成: fn some_function(t: T, u: U) -> i32 where T: Display + Clone, U: Clone + Debug 匿名trait 针对一个类型，我们可以直接对它impl来增加成员方法，无须trait名字。比如： impl Circle { fn get_radius(&self) -> f64 { self.radius } } 我们可以把这段代码看作是为Circle类型impl了一个匿名的trait。用这种方式定义的方法叫作这个类型的“内在方法”（inherent methods）。 Box trait Shape { fn area(self: Box) -> f64; } struct Circle { radius: f64, } impl Shape for Circle { // Self 类型就是 Circle // self 的类型是 Box,即 Box fn area(self : Box) -> f64 { // 访问成员变量,需要用 self.radius std::f64::consts::PI * self.radius * self.radius } } fn main() { let c = Circle { radius : 2f64}; // 编译错误 // c.area(); let b = Box::new(Circle {radius : 4f64}); // 编译正确 b.area(); } impl trait for trait 语法: impl for Rust 同一个类可以实现多个特性，每个 impl 块只能实现一个。 trait Shape { fn area(&self) -> f64; } trait Round { fn get_radius(&self) -> f64; } struct Circle { radius: f64, } impl Round for Circle { fn get_radius(&self) -> f64 { self.radius } } // 注意这里是 impl Trait for Trait impl Shape for dyn Round { fn area(&self) -> f64 { std::f64::consts::PI * self.get_radius() * self.get_radius() } } fn main() { let c = Circle { radius : 2f64}; // 编译错误 // c.area(); // let b = Circle { radius : 2f64} as dyn Round; //这样也不行, error[E0620]: cast to unsized type: `Circle` as `dyn Round` let b = Box::new(Circle {radius : 4f64}) as Box; // 编译正确 b.area(); } 注: 以上代码在edition2021编译不过, 需要在Round前面加dyn关键词(已加)加了以后上面代码能编过, 但有个变量c没有使用的警告. 为别人的类型实现trait 比如下面的代码就给内置类型i32实现了Double方法: trait Double { fn double(&self) -> Self; } impl Double for i32 { fn double(&self) -> i32 { *self * 2 } } fn main() { // 可以像成员方法一样调用 let x : i32 = 10.double(); println!(\"{}\", x); } 要给别人的类型添加方法, 需要满足下面的条件:impl块要么与trait的声明在同一个的crate中，要么与类型的声明在同一个crate中 trait不能做为参数, 返回值, 实例变量 参数, 返回值, 实例变量等需要明确知道size的地方不能直接用trait.Rust是一种用户可以对内存有精确控制能力的强类型语言。我们可以自由指定一个变量是在栈里面，还是在堆里面，变量和指针也是不同的类型。类型是有大小（Size）的。有些类型的大小是在编译阶段可以确定的，有些类型的大小是编译阶段无法确定的。目前版本的Rust规定，在函数参数传递、返回值传递等地方，都要求这个类型在编译阶段有确定的大小。否则，编译器就不知道该如何生成代码了。 而trait本身既不是具体类型，也不是指针类型，它只是定义了针对类型的、抽象的“约束”。不同的类型可以实现同一个trait，满足同一个trait的类型可能具有不同的大小。因此，trait在编译阶段没有固定大小，目前我们不能直接使用trait作为实例变量、参数、返回值。 下面的代码是不对的: let x: Shape = Circle::new(); // Shape 不能做局部变量的类型 fn use_shape(arg : Shape) {} // Shape 不能直接做参数的类型 fn ret_shape() -> Shape {} // Shape 不能直接做返回值的类型 调用trait trait Cook { fn start(&self); } trait Wash { fn start(&self); } struct Chef; impl Cook for Chef { fn start(&self) { println!(\"Cook::start\"); } } impl Wash for Chef { fn start(&self) { println!(\"Wash::start\"); } } fn main() { let me = Chef; me.start(); //这里编不过, 因为两个trait都有start方法 } //应该用下面的格式来调用: fn main() { let me = Chef; // 函数名字使用更完整的path来指定,同时,self参数需要显式传递 // 下面两种格式都可以 ::start(&me); ::start(&me); } 方法的点引用是语法糖: 和go一样, 通过小数点语法调用方法调用，有一个“隐藏着”的“取引用”步骤。虽然我们看起来源代码长的是这个样子 me.start()，但是大家心里要清楚，真正传递给start()方法的参数是 &me而不是me，这一步是编译器自动帮我们做的。不论这个方法接受的self参数究竟是Self、&Self还是&mut Self，最终在源码上，我们都是统一的写法：variable.method() 方法和函数没有本质不同? struct T(usize); impl T { fn get1(&self) -> usize { self.0 } fn get2(&self) -> usize { self.0 } } fn get3(t: &T) -> usize { t.0 } fn check_type(_: fn(&T) -> usize) {} fn main() { check_type(T::get1); check_type(T::get2); check_type(get3); } 可以看到，get1、get2和get3都可以自动转成fn（&T）-> usize类型 trait约束 use std::fmt::Debug; fn my_print(x: T) { println!(\"The value is {:?}.\", x); } fn main() { my_print(\"China\"); my_print(41_i32); my_print(true); my_print(['a', 'b', 'c']) } 上面的代码能编过, 是因为my_print需要泛型T满足Debug约束(因为使用了{:?}), 而字符串, i32, bool, 数组都实现了Debug trait. 如果一个自定义类型没有实现Debug trait, 编译就会报错. 上面的约束还可以写成: fn my_print(x: T) where T: Debug { println!(\"The value is {:?}.\", x); } trait继承 实现Derived trait的struct也被要求实现Base trait trait Base {} trait Derived : Base {} //等同于trait Derived where Self：Base{} struct T; impl Derived for T {} impl Base for T {} //需要再加上这句 fn main() { ... } derive derive是个特殊的编译指示: #[derive(Copy, Clone, Default, Debug, Hash, PartialEq, Eq, PartialOrd, Ord)] struct Foo { data: i32, } fn main() { let v1 = Foo { data: 0 }; let v2 = v1; println!(\"{:?}\", v2); } 意思是编译器会自动生成如下的代码: impl Copy for Foo { ... } impl Clone for Foo { ... } impl Default for Foo { ... } impl Debug for Foo { ... } impl Hash for Foo { ... } impl PartialEq for Foo { ... } ... 从而让Foo能够继承列表里的trait. 能够被derive的trait有: Debug Clone Copy Hash RustcEncodable RustcDecodable PartialEq Eq ParialOrd Ord Default FromPrimitive Send Sync 常见trait 只有实现了Display trait的类型，才能用{}格式控制打印出来；只有实现了Debug trait的类型，才能用{:?} {:#?}格式控制打印出来 // std::fmt::Display pub trait Display { fn fmt(&self, f: &mut Formatter) -> Result; } // std::fmt::Debug pub trait Debug { fn fmt(&self, f: &mut Formatter) -> Result; } 带关联类型的trait 标准库中有一个trait叫FromStr，它有一个关联类型代表错误： pub trait FromStr { type Err; fn from_str(s: &str) -> Result; } 如果某些类型调用from_str方法永远不会出错，那么这个Err类型可以指定为! use std::mem::{size_of, size_of_val}; use std::str::FromStr; struct T(String); impl FromStr for T { type Err = !; fn from_str(s: &str) -> Result { Ok(T(String::from(s))) } } fn main() { let r: Result = T::from_str(\"hello\"); println!(\"Size of T: {}\", size_of::()); println!(\"Size of Result: {}\", size_of_val(&r)); // 将来甚至应该可以直接用 let 语句进行模式匹配而不发生编译错误 // 因为编译器有能力推理出 Err 分支没必要存在 // let Ok(T(ref s)) = r; // println!(\"{}\", s); } 模式解构 struct T1(i32, char); struct T2 { item1: T1, item2: bool, } fn main() { let x = T2 { item1: T1(0, 'A'), item2: false, }; let T2 { item1: T1(value1, value2), item2: value3, } = x; //从x解构出value1, value2, value3; 后者直接就当变量用了 println!(\"{} {} {}\", value1, value2, value3); } 下划线用来占位: struct P(f32, f32, f32); fn calc(arg: P) -> f32 { // 匹配 tuple struct,但是忽略第二个成员的值 let P(x, _, y) = arg; x * x + y * y } fn main() { let t = P(1.0, 2.0, 3.0); println!(\"{}\", calc(t)); } match rust的match初看和switch case意思差不多: enum Direction { East, West, South, North, } fn print(x: Direction) { match x { Direction::East => { println!(\"East\"); } Direction::West => { println!(\"West\"); } Direction::South => { println!(\"South\"); } Direction::North => { println!(\"North\"); } } } fn main() { let x = Direction::East; print(x); } 但match更严格, 比如我们删除North分支, 编译会报错. 解决办法就是把不需要的分支用_覆盖: fn print(x: Direction) { match x { Direction::East => { println!(\"East\"); } Direction::West => { println!(\"West\"); } Direction::South => { println!(\"South\"); } _ => { println!(\"Other\"); } } } 类似的, 下面的match如果没有下划线那个分支, 也是编译不过的: fn category(x: i32) { match x { -1 => println!(\"negative\"), 0 => println!(\"zero\"), 1 => println!(\"positive\"), _ => println!(\"error\"), } } fn main() { let x = 1; category(x); } match还支持|操做和..范围操做: fn category(x: i32) { match x { -1 | 1 => println!(\"true\"), 0 => println!(\"false\"), _ => println!(\"error\"), } } fn main() { let x = 1; category(x); } let x = 'X'; match x { 'a' ..= 'z' => println!(\"lowercase\"), 'A' ..= 'Z' => println!(\"uppercase\"), _ => println!(\"something else\"), } match还支持在分支内加if判断: match x { OptionalInt::Value(i) if i > 5 => println!(\"Got an int bigger than five!\"), OptionalInt::Value(..) => println!(\"Got an int!\"), OptionalInt::Missing => println!(\"No such luck.\"), } fn intersect(arg: i32) { match arg { i if i println!(\"case 1\"), i if i println!(\"case 2\"), i if i * i println!(\"case 3\"), _ => println!(\"default case\"), } } 还可以用@绑定变量. @符号前面是新声明的变量，后面是需要匹配的模式： let x = 1; match x { e @ 1 ..= 5 => println!(\"got a range element {}\", e), _ => println!(\"anything\"), } ref和mut ref: 引用, 避免出现所有权转移 mut: 借用 let mut x: &mut i32; 以上两处的mut含义是不同的。第1处mut，代表这个变量x本身可变，因此它能够重新绑定到另外一个变量上去，具体到这个示例来说，就是指针的指向可以变化。第2处mut，修饰的是指针，代表这个指针对于所指向的内存具有修改能力，因此我们可以用*x=1;这样的语句，改变它所指向的内存的值。 知晓变量类型 方案一: 利用编译错误来获取变量类型 // 这个函数接受一个 unit 类型作为参数 fn type_id(_: ()) {} fn main() { let ref x = 5_i32; // 实际参数的类型肯定不是 unit,此处必定有编译错误,通过编译错误,我们可以看到实参的具体类型 type_id(x); } 方案二: 使用标准库 #![feature(core_intrinsics)] fn print_type_name(_arg: &T) { unsafe { println!(\"{}\", std::intrinsics::type_name::()); } } fn main() { let ref x = 5_i32; print_type_name(&x); } 比如要知道下面的变量类型: let x = 5_i32; // i32 let x = &5_i32; // &i32 let ref x = 5_i32; // ??? let ref x = &5_i32; // ??? 代码: #![feature(core_intrinsics)] fn print_type_name(_arg: &T) { println!(\"{}\", std::intrinsics::type_name::()); } fn main() { let x = 5_i32; print_type_name(&x); //i32 let x = &5_i32; print_type_name(&x); //&i32 let ref x = 5_i32; print_type_name(&x); //&i32 let ref x = &5_i32; print_type_name(&x); //&&i32 } 注: 上面代码只能在debug优化模式和nightly channel下编译通过 方案三: 不需要nightly版本 fn print_type_of(_: &T) { println!(\"{}\", std::any::type_name::()) } 问号操作符 用在Result或Option后面, 用于提前返回或者unwrap value用在Result上, 可以提前返回Err(From::from(e)); 没有Error时则unwrap返回T fn try_to_parse() -> Result { let x: i32 = \"123\".parse()?; // x = 123 let y: i32 = \"24a\".parse()?; // returns an Err() immediately Ok(x + y) // Doesn't run. } let res = try_to_parse(); println!(\"{:?}\", res); 用在Option上, 可以提前返回None; 有值则unwrap返回T: fn try_option_some() -> Option { let val = Some(1)?; Some(val) } assert_eq!(try_option_some(), Some(1)); fn try_option_none() -> Option { let val = None?; Some(val) } assert_eq!(try_option_none(), None); 问号操作背后 代码rust/library/core/src/ops/try_trait.rs 问号operator背后是Try这个trait pub trait Try: FromResidual { type Output; type Residual; fn from_output(output: Self::Output) -> Self; fn branch(self) -> ControlFlow; } "},"notes/rust_入门2.html":{"url":"notes/rust_入门2.html","title":"泛型和内存所有权","keywords":"","body":" 宏 泛型 结构体的泛型 结构体泛型的具化 枚举的泛型 泛型参数可以有默认值 函数中的泛型 泛型实现重载 重载需要判断类型 impl块中的泛型 泛型的约束 关联类型 trait for trait 泛型的方法 内存安全 生命周期 生命周期标记 类型的生命周期标记 省略生命周期标记 所有权 所有权规则 数据赋值和拷贝 所有权与函数 返回值与作用域 println不会发生所有权转移(move) Rc允许多个所有权拥有者 引用和借用 copy和clone 析构函数 mut和&mut 借用指针 为什么rust是内存安全的? 解引用 自定义解引用 常见指针类型 自动解引用 Rc的自动解引用 引用计数 cow 智能指针 其他 在方法里定义struct是可以的 文件打开 unsafe unsafe可以操作裸指针 不用unsafe的swap例子 标准库的swap Vec代码 宏 比如打印当前文件和行号: fn main() { println!(\"file {} line {} \", file!(), line!()); } 比如避免重复: add_impl! { usize u8 u16 u32 u64 isize i8 i16 i32 i64 f32 f64 } 比如初始化一个动态数组: let v = vec![1, 2, 3, 4, 5]; 泛型 max函数的入参是泛型T的数组 fn max(array: &[T]) -> T { let mut max_index = 0; let mut i = 1; while i array[max_index] { max_index = i; } i += 1; } array[max_index] } 结构体的泛型 struct Point { x: T, y: T } 可以这样用: let p1 = Point {x: 1, y: 2}; let p2 = Point {x: 1.0, y: 2.0}; 但这样不行: let p = Point {x: 1, y: 2.0}; x 与 1 绑定时就已经将 T 设定为 i32，所以不允许再出现 f64 的类型。如果我们想让 x 与 y 用不同的数据类型表示，可以使用两个泛型标识符： struct Point { x: T1, y: T2 } 结构体泛型的具化 可以让编译器自动推断, 也可以指定类型, 在左侧和右侧都可以, 但在右侧不支持S的语法: fn print_type_of(_: &T) { println!(\"{}\", std::any::type_name::()) } struct S { data: T, } fn main() { //let four: u32 = \"4\".parse(); //println!(\"{:?}\", four); let x = S { data: 6 }; //编译器自动推断 let y = S { data: 5.5 }; //编译器自动推断 let y1: S = S { data: 5.5 }; //声明y1是S let y2: S:: = S { data: 5.5 }; //声明y2是S:: //let y3 = S {data: 5.5}; //NOK, 编译不过, 编译器认为<>是大于小于号. 据说是编译器图简单 let y3 = S:: { data: 5.5 }; //显式实例化y3, 在右侧只能用双冒号 print_type_of(&x); print_type_of(&y); print_type_of(&y1); print_type_of(&y2); print_type_of(&y3); print_type_of(&\"4\".parse::()); } //结果 playground::S playground::S playground::S playground::S playground::S core::result::Result 枚举的泛型 比如 enum Option { Some(T), None, } 这里的实际上是声明了一个“类型”参数。在这个Option内部，Some(T)是一个tuple struct，包含一个元素类型为T。这个泛型参数类型T，可以在使用时指定具体类型。 使用的时候: let x: Option = Some(42); let y: Option = None; 泛型参数可以有默认值 比如下面的泛型T默认是i32 struct S { data: T } fn main() { let v1 = S { data: 0}; let v2 = S:: { data: false}; println!(\"{} {}\", v1.data, v2.data); } 函数中的泛型 比如: fn compare_option(first: Option, second: Option) -> bool { match(first, second) { (Some(..), Some(..)) => true, (None, None) => true, _ => false } } 注:Some(..)中的双点表示ignore全部, Some(_)表示ignore第一个参数. 再举例: fn largest(list: &[T]) -> &T { let mut largest = &list[0]; for item in list.iter() { if item > largest { largest = item; } } largest } fn main() { let number_list = vec![34, 50, 25, 100, 65]; let result = largest(&number_list); println!(\"The largest number is {}\", result); let char_list = vec!['y', 'm', 'a', 'q']; let result = largest(&char_list); println!(\"The largest char is {}\", result); } //结果 The largest number is 100 The largest char is y 泛型实现重载 比如str的contains方法就接受不同类型的参数: fn main() { let s = \"hello\"; println!(\"{}\", s.contains('a')); println!(\"{}\", s.contains(\"abc\")); println!(\"{}\", s.contains(&['H'] as &[char])); println!(\"{}\", s.contains(|c : char| c.len_utf8() > 2)); } 这个contains的签名是: fn contains>(&'a self, pat: P) -> bool 第二个参数pat是个泛型P, 只要满足Pattern trait, 就能被contains所用. 重载需要判断类型 下面的代码编译不过, 因为let f = i.convert();中, 编译器无法知道f的类型, 于是无法推断出应该调用哪个. trait ConvertTo { fn convert(&self) -> T; } impl ConvertTo for i32 { fn convert(&self) -> f32 { *self as f32 } } impl ConvertTo for i32 { fn convert(&self) -> f64 { *self as f64 } } fn main() { let i = 1_i32; let f = i.convert(); // 这里编译不过 println!(\"{:?}\", f); } 要这样改: let f : f32 = i.convert(); // 或者 let f = ConvertTo::::convert(&i); impl块中的泛型 可以impl 某个trait for type, 也可以为trait impl trait. 即trait for trait. 这个impl trait for trait比如: impl Into for T where U: From, { fn into(self) -> U { U::from(self) } } 泛型的约束 下面的代码编译不通过: fn max(a: T, b: T) -> T { if a 因为并不是所有类型都实现了比较操作, 那么泛型T没有约束的话, 是编译不过的. 加约束有两个写法: 冒号方式 use std::cmp::PartialOrd; // 第一种写法：在泛型参数后面用冒号约束 fn max(a: T, b: T) -> T { where语法 // 第二种写法,在后面单独用 where 子句指定 fn max(a: T, b: T) -> T where T: PartialOrd where语法灵活性更好: trait Iterator { type Item; // Item 是一个关联类型 // 此处的where子句没办法在声明泛型参数的时候写出来 fn max(self) -> Option where Self: Sized, Self::Item: Ord, { ... } ... } 它要求Self类型满足Sized约束，同时关联类型Self::Item要满足Ord约束，这是用冒号语法写不出来的。 比较泛型的完整代码: use std::cmp::Ordering; use std::cmp::PartialOrd; fn max(a: T, b: T) -> T where T: PartialOrd, { if a Option { self.value.partial_cmp(&other.value) } } impl PartialEq for T { fn eq(&self, other: &T) -> bool { self.value == other.value } } fn main() { let t1 = T { value: 1 }; let t2 = T { value: 2 }; let m = max(t1, t2); } 注意由于标准库中的PartialOrd继承了PartialEq，因此单独实现PartialOrd 还是会产生编译错误，必须同时实现PartialEq才能编译通过。 关联类型 trait中不仅可以包含方法（包括静态方法）、常量，还可以包含“类型”。 比如迭代器中的Item就是个关联类型, 关联类型也必须指定才能实例化. pub trait Iterator { type Item; ... } 可以看到，我们希望参数是一个泛型迭代器，可以在约束条件中写Iterator。跟普通泛型参数比起来，关联类型参数必须使用名字赋值的方式。 use std::fmt::Debug; use std::iter::Iterator; fn use_iter(mut iter: ITER) where ITER: Iterator, ITEM: Debug, { while let Some(i) = iter.next() { println!(\"{:?}\", i); } } fn main() { let v: Vec = vec![1, 2, 3, 4, 5]; use_iter(v.iter()); } 也可以将ITEM ITER简化为一个, 因为满足ITER: Iterator, 就可以继续声明其关联类型需要满足的约束ITER::Item: Debug use std::fmt::Debug; use std::iter::Iterator; fn use_iter(mut iter: ITER) where ITER: Iterator, ITER::Item: Debug, { while let Some(i) = iter.next() { println!(\"{:?}\", i); } } fn main() { let v: Vec = vec![1, 2, 3, 4, 5]; use_iter(v.iter()); } trait for trait 下面的例子中, 为一个泛型T, 实现了ToString trait pub trait ToString { fn to_string(&self) -> String; } impl ToString for T { #[inline] fn to_string(&self) -> String { use core::fmt::Write; let mut buf = String::new(); let _ = buf.write_fmt(format_args!(\"{}\", self)); buf.shrink_to_fit(); buf } } 凡是实现了这个trait的类型，都可以调用to_string来得到一个String 类型的结果。同时，标准库中还存在一个std::fmt::Display trait， 也可以做到类似的事情。而且Display是可以通过#[derive（Display）]由 编译器自动实现的。所以，我们可以想到，针对所有满足T: Display的类型，我们可以为它们提供一个统一的实现. 泛型的方法 struct Point { x: T, y: T, } //注意下面的第一个是类型声明, 第二个是\"实例化\"这个Point, 虽然是用泛型来\"实例化\" //所以写成这样也可以的: impl Point:: { impl Point { fn x(&self) -> &T { &self.x } } fn main() { let p = Point { x: 1, y: 2 }; println!(\"p.x = {}\", p.x()); } 内存安全 生命周期 fn main() { let v = vec![1, 2, 3, 4, 5]; // --> v 的生命周期开始 { let center = v[2]; // --> center 的生命周期开始 println!(\"{}\", center); } // 生命周期标记 引用往往导致极其复杂的资源管理问题，首先认识一下垂悬引用： { let r; { let x = 5; r = &x; } println!(\"r: {}\", r); } 这段代码是不会通过 Rust 编译器的，原因是 r 所引用的值已经在使用之前被释放。上图中的绿色范围 'a 表示 r 的生命周期，蓝色范围 'b 表示 x 的生命周期。很显然，'b 比 'a 小得多，引用必须在值的生命周期以内才有效 下面的例子中 longer函数不能编译通过 fn longer(s1: &str, s2: &str) -> &str { if s2.len() > s1.len() { s2 } else { s1 } } 原因是返回值引用可能会返回过期的引用, 一般情况下, 编译器可以推导出返回值的生命周期标记, 比如函数只有唯一入参的时候; 但这里编译器不知道到底返回的引用是s1还是s2 fn main() { let r; { let s1 = \"rust\"; let s2 = \"ecmascript\"; r = longer(s1, s2); } println!(\"{} is longer\", r); } 把longer函数改成带生命周期声明的方式, 就可以成功运行了: fn longer(s1: &'a str, s2: &'a str) -> &'a str { if s2.len() > s1.len() { s2 } else { s1 } } fn main() { let r; { let s1 = \"rust\"; let s2 = \"ecmascript\"; r = longer(s1, s2); } println!(\"{} is longer\", r); //println!(\"s2: {}\", s2); } //ecmascript is longer 可以看到, r实际引用的s2, s2的内容在出了scope后还能被r引用. 但直接打印s2是不行的, 会报错误:cannot find value s2 in this scope 生命周期注释用单引号开头，跟着一个小写字母单词： &i32 // 常规引用 &'a i32 // 含有生命周期注释的引用 &'a mut i32 // 可变型含有生命周期注释的引用 'static // 特殊的生命周期标记, 表示静态, 好像是全局的意思 下面的写法是一样的: fn test(arg: &'a T) -> &'a i32 fn test(arg: &'a T) -> &'b i32 where 'a:'b //'a:'b表示'a比'b“活”得长 类型的生命周期标记 如果自定义类型中有成员包含生命周期参数，那么这个自定义类型 也必须有生命周期参数: struct Test { member: &'a str } 在使用impl的时候，也需要先声明再使用: impl Test { fn test(&self, s: &'a str) { } } 如果在泛型约束中有where T: 'a之类的条件，其意思是，类型T的所有生命周期参数必须大于等于'a。要特别说明的是，若是有where T: 'static的约束，意思则是，类型T里面不包含任何指向短生命周期的借用指针，意思是要么完全不包含任何借用，要么可以有指向'static的借用指针。 省略生命周期标记 fn get_str(s: &String) -> &str { s.as_ref() } 等同于 fn get_str(s: &'a String) -> &'a str { s.as_ref() } 所有权 下面的代码编译不过: fn main() { let s = String::from(\"hello\"); let s1 = s; println!(\"{}\", s); } 出现错误的原因是let s1 = s;导致了所有权转移, 转移后s就不能再访问了. 每个值只有一个所有者。变量s的生命周期从声明开始，到move给s1就结束了。变量s1的生命周期则是从它声明开始， 到函数结束。而字符串本身，由String::from函数创建出来，到函数结束的时候就会销毁。中间所有权的转换，并不会将这个字符串本身重新销毁再创建。在任意时刻，这个字符串只有一个所有者，要么是s， 要么是s1。 一个变量可以把它拥有的值转移给另外一个变量，称为“所有权转移”。赋值语句、函数调用、函数返回等，都有可能导致所有权转移。 Rust中的变量绑定操作，默认是move语义，执行了新的变量绑定后，原来的变量就不能再被使用！一定要记住！ 就是说rust里面的赋值语句实际上是移动语义.但是有例外: 比如下面的代码就可以编译通过: fn main() { let v1 : isize = 0; let v2 = v1; println!(\"{}\", v1); } 因为在Rust中有一部分“特殊照顾”的类型，其变量绑定操作是copy语义。实现了copy trait的类型就会在assign的时候使用copy. 所谓的copy语义，是指在执行变量绑定操作的时候，v2是对v1所属数据的一份复制。v1所管理的这块内存依然存在，并未失效，而v2是新开辟了一块内存，它的内容是从v1管理的内存中复制而来的。和手动调用clone方法效果一样，let v2=v1；等效于let v2=v1.clone() Rust中，在普通变量绑定、函数传参、模式匹配等场景下，凡是实 现了std::marker::Copy trait的类型，都会执行copy语义。基本类型，比如数字、字符、bool等，都实现了Copy trait，因此具备copy语 义。 对于自定义类型，默认是没有实现Copy trait的，但是我们可以手动添上。 要实现这个copy trait: #[derive(Copy, Clone)] struct Foo { data : i32 } fn main() { let v1 = Foo { data : 0 }; let v2 = v1; println!(\"{:?}\", v1.data); } Rust中的copy语义就是浅复制 所有权规则 Rust中的每一个值都有一个对应的变量作为它的所有者 。 在同一时间内，值有且仅有一个所有者。 Rc允许多个所有权的owner 当所有者离开自己的作用域时，它持有的值就会被释放掉。 数据赋值和拷贝 Rust永远不会自动地创 建数据的深度拷贝。因此在Rust中，任何自动的赋值操作都可以被视为高效的。 let s1 = String::from(\"hello\"); //s1在堆里 let s2 = s1; // s2是s1的浅拷贝, 同时s1失效 println!(\"{}, world!\", s1); //这里会报错, 因为所有权已经move了 //后面s2拥有对应的数据, s2退出作用域的时候, drop函数被自动调用以释放空间 但下面的代码也是对的, 因为i32有Copy trait let x = 5; let y = x; println!(\"x = {}, y = {}\", x, y); 有copy trait的类型有: 所有的整数类型，诸如u32 仅拥有两种值（true和false）的布尔类型：bool 字符类型：char 所有的浮点类型，诸如f64 如果元组包含的所有字段的类型都是Copy的，那么这个元组也 是Copy的。例如，(i32, i32)是Copy的，但(i32, String)则不是 所有权与函数 将值传递给函数在语义上类似于对变量进行赋值。将变量传递给 函数将会触发移动或复制，就像是赋值语句一样。 fn main() { let s = String::from(\"hello\"); // 变量s进入作用域 take_ownership(s); // s的值被移动进了函数 // 所以它从这里开始不再有效 let x = 5; // 变量x进入作用域 make_copy(x); // 变量x同样被传递进了函数 //但由于i32是copy的, 所以我们依然可以在这之后使用x } // x首先离开作用域, 随后是s. 但由于s的值已经发生了移动, 所以没什么特别的事情发生. fn take_ownership(some_string: String) { // some_string进入作用域 println!(\"{}\", some_string); } // some_string在这里离开作用域, 它的drop函数被自动调用, 其所占的内存也随之被释放了 fn make_copy(some_integer: i32) { // some_integer进入作用域 println!(\"{}\", some_integer); } // some_integer在这里离开了作用域, 没有什么特别的事情发生 返回值与作用域 函数在返回值的过程中也会发生所有权的转移。 fn main() { let s1 = give_ownership(); // 返回值移动至s1中 let s2 = String::from(\"hello\"); // s2进入作用域 let s3 = take_and_giveback(s2); // s2被移动进函数, 而这个函数的返回值又被移动到了s3上 } // s3在这里离开作用域并被销毁. 由于s2已经移动了, 所以它不会在离开作用域的时候发生任何事情. s1最后离开作用域并被销毁. // give_ownership 会将它的返回值移动至调用它的函数内 fn give_ownership() -> String { let some_string = String::from(\"hello\"); // some_string进入作用域 some_string // some_string做为返回值移动到调用函数 } // take_and_giveback 将取得一个String的所有权并将它做为结果返回 fn take_and_giveback(a_string: String) -> String { // a_string进入作用域 a_string // a_string做为返回值移动至调用函数 } println不会发生所有权转移(move) 因为println是宏, 比如下面的代码: fn main() { let x = 5; println!(\"{}\", x); } 用这个命令rustc -Z unstable-options --pretty expanded得到下面宏展开的代码: #![feature(prelude_import)] #[prelude_import] use std::prelude::v1::*; #[macro_use] extern crate std; fn main() { let x = 5; { ::std::io::_print(::core::fmt::Arguments::new_v1( &[\"\", \"\\n\"], &match (&x,) { (arg0,) => [::core::fmt::ArgumentV1::new( arg0, ::core::fmt::Display::fmt, )], }, )); }; } 化简后是借用传参的. use std::{fmt, io}; fn main() { let x = 5; io::_print(fmt::Arguments::new_v1( &[\"\", \"\\n\"], &[fmt::ArgumentV1::new(&x, fmt::Display::fmt)], // ^^ )); } Rc允许多个所有权拥有者 To enable multiple ownership, Rust has a type called Rc, which is an abbreviation for reference counting. The Rc type keeps track of the number of references to a value to determine whether or not the value is still in use. enum List { Cons(i32, Box), Nil, } use crate::List::{Cons, Nil}; fn main() { let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); println!(\"count after creating a = {}\", Rc::strong_count(&a)); let b = Cons(3, Rc::clone(&a)); println!(\"count after creating b = {}\", Rc::strong_count(&a)); { let c = Cons(4, Rc::clone(&a)); println!(\"count after creating c = {}\", Rc::strong_count(&a)); } println!(\"count after c goes out of scope = {}\", Rc::strong_count(&a)); } //结果 $ cargo run Compiling cons-list v0.1.0 (file:///projects/cons-list) Finished dev [unoptimized + debuginfo] target(s) in 0.45s Running `target/debug/cons-list` count after creating a = 1 count after creating b = 2 count after creating c = 3 count after c goes out of scope = 2 注: 用Rc::clone(&a)和a.clone()是一样的. 前者更隐含了是浅拷贝的意思, 开销非常小. 引用和借用 引用方式传递也叫借用, 所有权不转移. 在任何一段给定的时间里，你要么只能拥有一个可变引用，要么只能拥有任意数量的不可变引用。 引用总是有效的。 fn dangle() -> &String{ // dangle会返回一个指向String的引用 let s = String::from(\"hello\"); // s被绑定到新的String上 &s // 我们将指向s的引用返回给调用者 } // 变量s在这里离开作用域并随之被销毁, 它指向的内存自然也不再有效. // 危险! copy和clone copy是std::marker::Copy 带marker的都是特殊的trait, 编译器会有特殊处理一旦一个类型实现了Copy trait，那么它在变量绑定、函数参数传递、函数返回值传递等场景下，都是copy语义，而不再是默认的move语义。并不是所有的类型都可以实现Copy trait。Rust规定，对于自定义类型，只有所有成员都实现了Copy trait，这个类型才有资格实现Copy trait。常见的数字类型、bool类型、共享借用指针&，都是具有Copy属性的类型。而Box、Vec、可写借用指针&mut等类型都是不具备Copy属性的类型。 对于数组类型，如果它内部的元素类型是Copy，那么这个数组也是 Copy类型。 对于元组tuple类型，如果它的每一个元素都是Copy类型，那么这个 tuple也是Copy类型。 clone是std::clone::Clone pub trait Clone: Sized { fn clone(&self) -> Self; fn clone_from(&mut self, source: &Self) { *self = source.clone() } } 即使实现了clone trait的对象, 在赋值的时候也是move语义. 举例: // A unit struct without resources #[derive(Debug, Clone, Copy)] struct Unit; // A tuple struct with resources that implements the `Clone` trait #[derive(Clone, Debug)] struct Pair(Box, Box); fn main() { // Instantiate `Unit` let unit = Unit; // Copy `Unit`, there are no resources to move let copied_unit = unit; // Both `Unit`s can be used independently println!(\"original: {:?}\", unit); println!(\"copy: {:?}\", copied_unit); // Instantiate `Pair` let pair = Pair(Box::new(1), Box::new(2)); println!(\"original: {:?}\", pair); // Move `pair` into `moved_pair`, moves resources let moved_pair = pair; println!(\"moved: {:?}\", moved_pair); // Error! `pair` has lost its resources //println!(\"original: {:?}\", pair); // TODO ^ Try uncommenting this line // Clone `moved_pair` into `cloned_pair` (resources are included) let cloned_pair = moved_pair.clone(); // Drop the original pair using std::mem::drop drop(moved_pair); // Error! `moved_pair` has been dropped //println!(\"copy: {:?}\", moved_pair); // TODO ^ Try uncommenting this line // The result from .clone() can still be used! println!(\"clone: {:?}\", cloned_pair); } 总结: Copy内部没有方法，Clone内部有两个方法。 Copy trait是给编译器用的，告诉编译器这个类型默认采用copy语 义，而不是move语义。 Clone trait是给程序员用的，赋值操作还是move语义. 我们必须手动调用 clone方法，它才能发挥作用。 Copy trait不是想实现就能实现的，它对类型是有要求的，有些类型不可能impl Copy。而Clone trait则没有什么前提条件，任何类型都可以实现（unsized类型除外，因为无法使用unsized类型作为返回值） Copy trait规定了这个类型在执行变量绑定、函数参数传递、函数返回等场景下的操作方式。即这个类型在这种场景下，必然执行的 是“简单内存复制”操作，这是由编译器保证的，程序员无法控制。 Clone trait里面的clone方法究竟会执行什么操作，则是取决于程序员自己写的逻辑。一般情况下，clone方法应该执行一个“深复制”操作，但这不是强制性的，如果你愿意，在里面启动一个人工智能程序都是有可能的。 析构函数 rust没有构造函数, 但允许析构函数: 用户可以自己写满足std::ops::Drop的trait trait Drop { fn drop(&mut self); } 这个Drop会在变量声明周期结束的时候被调用. 自己调用Drop是非法的, 但可以间接调用标准库的drop函数: use std::mem::drop; fn main() { let mut v = vec![1, 2, 3]; // v的生命周期结束 v.push(4); // 错误的调用 } 其实, 标准库的drop就是入参是值传递的空函数: #[inline] pub fn drop(_x: T) { } 这里入参是值传递非常重要, 将对象的所有权移入函数中，什么都不用做，编译器就会自动释放掉这个对象了。 因为这个drop函数的关键在于使用move语义把参数传进来，使得变量的所有权从调用方移动到drop函数体内，参数类型一定要是T，而不是&T或者其他引用类型。函数体本身其实根本不重要，重要的是把变量的所有权move进入这个函数体中，函数调用结束的时候该变量的生命周期结束，变量的析构函数会自动调用，管理的内存空间也会自然释放。这个过程完全符合前面讲的生命周期、move语义，无须编译器做特殊处理。事实上，我们完全可以自己写一个类似的函数来实现同样的效果，只要保证参数传递是move语义即可。 因此, 有copy()语义的变量, 对其drop()是没有作用的, 因为这些变量是复制不是move. mut和&mut mut可以出现在绑定(=)的左右两侧 fn main() { let mut var = 0_i32; { let p1 = &mut var; // p1 指针本身不能被重新绑定,我们可以通过p1改变变量var的值 *p1 = 1; } { let temp = 2_i32; let mut p2 = &var; // 我们不能通过p2改变变量var的值,但p2指针本身指向的位置可以被改变 p2 = &temp; } { let mut temp = 3_i32; let mut p3 = &mut var; // 我们既可以通过p3改变变量var的值,而且p3指针本身指向的位置也可以改变 *p3 = 3; p3 = &mut temp; } } 借用指针 借用指针不能比它指向的变量存在的时间更长 &mut型借用只能指向本身具有mut修饰的变量，对于只读变量，不可以有&mut型借用 &mut型借用指针存在的时候，被借用的变量本身会处于“冻结”状态 如果只有&型借用指针，那么能同时存在多个；如果存在&mut型借用指针，那么只能存在一个；如果同时有其他的&或者&mut型借用指针存在，那么会出现编译错误 // 这里的参数采用的“引用传递”,意味着实参本身并未丢失对内存的管理权 fn borrow_semantics(v: &Vec) { // 打印参数占用空间的大小,在64位系统上,结果为8,表明该指针与普通裸指针的内部表示方法相同 println!(\"size of param: {}\", std::mem::size_of::>()); for item in v { print!(\"{} \", item); } println!(\"\"); } // 这里的参数采用的“值传递”,而Vec没有实现Copy trait,意味着它将执行move语义 fn move_semantics(v: Vec) { // 打印参数占用空间的大小,结果为24,表明实参中栈上分配的内存空间复制到了函数的形参中 println!(\"size of param: {}\", std::mem::size_of::>()); for item in v { print!(\"{} \", item); } println!(\"\"); } fn main() { let array = vec![1, 2, 3]; // 需要注意的是,如果使用引用传递,不仅在函数声明的地方需要使用&标记 // 函数调用的地方同样需要使用&标记,否则会出现语法错误 // 这样设计主要是为了显眼,不用去阅读该函数的签名就知道这个函数调用的时候发生了什么 // 而小数点方式的成员函数调用,对于self参数,会“自动转换”,不必显式借用,这里有个区别 borrow_semantics(&array); // 在使用引用传递给上面的函数后,array本身依然有效,我们还能在下面的函数中使用 move_semantics(array); // 在使用move语义传递后,array在这个函数调用后,它的生命周期已经完结 } 任何借用指针的存在，都会导致原来的变量被“冻结”（Frozen）: fn main() { let mut x = 1_i32; let p = &mut x; x = 2; // 因为p的存在，此时对x的改变被认为是非法的 println!(\"value of pointed : {}\", p); } 为什么rust是内存安全的? 比如c语言在迭代vector的时候, 改变vector自身, 编译的时候没问题, 但运行时会崩溃; 而rust在编译时就会报错, 因为rust的原则是: 共享不可变，可变不共享 首先我们介绍一下这两个概念Alias和Mutation。 Alias的意思是“别名”。如果一个变量可以通过多种Path来访问，那它们就可以互相看作alias。Alias意味着“共享”，我们可以通过多个入口访问同一块内存。 Mutation的意思是“改变”。如果我们通过某个变量修改了一块内存，就是发生了mutation。Mutation意味着拥有“修改”权限，我们可以写入数据。 Rust保证内存安全的一个重要原则就是，如果能保证alias和 mutation不同时出现，那么代码就一定是安全的. 为什么在Rust中永远不会出现迭代器失效这样的错误？因为通 过“mutation+alias”规则，就可以完全杜绝这样的现象，这个规则是Rust 内存安全的根，是解决内存安全问题的灵魂。 Rust防范“内存不安全”代码的原则极其清晰明了。如果你对同一块内存存在多个引用，就不要试图对这块内存做修改；如果你需要对一块内存做修改，就不要同时保留多个引用。只要保证了这个原则，我们就可以保证内存安全。它在实践中发挥了强大的作用，可以帮助我们尽早发现问题。这个原则是Rust的立身之本、生命之基、活力之源。 注: std::cell::Cell可以\"突破\"这个“唯一修改权”的原则. 但实际上, Cell被小心的设计成一个包裹, 支持多个共享引用, 可以内部可变. 解引用 和c一样, 用*解引用 自定义解引用 实现std::ops::Deref或者std::ops::DerefMut这两个trait就能自定义解引用 pub trait Deref { type Target: ?Sized; fn deref(&self) -> &Self::Target; } pub trait DerefMut: Deref { fn deref_mut(&mut self) -> &mut Self::Target; } *expr的类型是Target，而 deref()方法返回的类型却是&Target 常见指针类型 Box是“指针”，指向一个在堆上分配的对象 Vec是“指针”，指向一组同类型的顺序排列的堆上分配的对象，且携带有当前缓存空间总大小和元素个数大小的元数据 String是“指针”，指向的是一个堆上分配的字节数组，其中保存的内容是合法的utf8字符序列。且携带有当前缓存空间总大小和字符串实际长度的元数据 以上几个类型都对所指向的内容拥有所有权，管理着它们所指向的内存空间的分配和释放 Rc和Arc也是某种形式的、携带了额外元数据的“指针”，它们提供的是一种“共享”的所有权，当所有的引用计数指针都销毁之后，它们所指向的内存空间才会被释放 自动解引用 len的函数签名是:fn len(&self) -> usize 按理说只有形式是&str的参数才行, 但下面的代码都正确: fn main() { let s = \"hello\"; println!(\"length: {}\", str::len(&s)); println!(\"length: {}\", str::len(s)); println!(\"length: {}\", s.len()); println!(\"length: {}\", (&s).len()); println!(\"length: {}\", (&&&&&&&&&&&&&s).len()); } 这是因为Rust编译器帮我们做了隐式的deref调用，当它找不到这个成员方法的时候，会自动尝试使用deref方法后再找该方法，一 直循环下去。所以&&&&&&&&&&str会被正确解引用 自动deref的规则是，如果类型T可以解引用为U，即T：Deref， 则&T可以转为&U Rc的自动解引用 Rc是带引用计数的智能指针, 它实现了Deref trait impl Deref for Rc { type Target = T; #[inline(always)] fn deref(&self) -> &T { &self.inner().value } } 它的Target类型是它的泛型参数T。这么设计有什么好处呢？我们 看下面的用法： use std::rc::Rc; fn main() { let s = Rc::new(String::from(\"hello\")); println!(\"{:?}\", s.bytes()); } 我们创建了一个指向String类型的Rc指针，并调用了bytes()方 法。这里是不是有点奇怪？这里的机制是这样的：Rc类型本身并没有bytes()方法，所以编译器会尝试自动deref，试试s.deref().bytes()。 String类型其实也没有bytes()方法，但是String可以继续deref，于是再试试s.deref().deref().bytes()。 这次在str类型中找到了bytes()方法，于是编译通过。 我们实际上通过Rc类型的变量调用了str类型的方法，让这个智能指针透明。这就是自动Deref的意义。 这就是为什么String需要实现Deref trait，是为了让&String类型的变量可以在必要的时候自动转换为&str类型。所以String类型的变量可以直接调用str类型的方法。比如： let s = String::from(\"hello\"); let len = s.bytes(); 虽然s的类型是String，但它在调用bytes()方法的时候，编译器会自动查找并转换为s.deref().bytes()调用。所以String类型的变量就可以直接调用str类型的方法了。 同理：Vec类型也实现了Deref trait，目标类型是[T]，&Vec类型的变量就可以在必要的时候自动转换为&[T]数组切片类型；Rc类型也实现了Deref trait，目标类型是T，Rc类型的变量就可以直接调用T类型的方法。 引用计数 普通变量绑定自身消亡的时候，这块内存就会被释放。引用计数智能指针给我们提供了另外一种选择：一块不可变内存可以有多个所有者，当所有的所有者消亡后，这块内存才会被释放。 std：：rc：：Rc: Rc是普通的引用计数, 只能单线程使用 std：：sync：：Arc: Arc是atomic Rc, 多线程安全 一般Rust不允许多owner, 但Rc可以突破这个限制: use std::rc::Rc; struct SharedValue { value: i32, } fn main() { let shared_value: Rc = Rc::new(SharedValue { value: 42 }); let owner1 = shared_value.clone(); let owner2 = shared_value.clone(); //shared_value.value = 88; 这句编译不过, 因为Rc就被设计成引用计数, 而不是共享变量. 用Cell来解决变量共享问题. println!(\"value : {} {}\", owner1.value, owner2.value); println!(\"address : {:p} {:p}\", &owner1.value, &owner2.value); } 运行结果: $ ./test value : 42 42 address : 0x13958abdf20 0x13958abdf20 这说明，owner1 owner2里面包含的数据不仅值是相同的，而且地址也是相同的。这正是Rc的意义所在。 如果要创建指向同样 内存区域的多个Rc指针，需要显式调用clone函数。请注意，Rc指针是 没有实现Copy trait的。如果使用直接赋值方式，会执行move语义，导致前一个指针失效，后一个指针开始起作用，而且引用计数值不变。如果需要创造新的Rc指针，必须手工调用clone()函数，此时引用计数值才会加1。当某个Rc指针失效，会导致引用计数值减1。当引用计数值减到0的时候，共享内存空间才会被释放。 cow 写时拷贝. 它对指向的数据可能“拥有所有权”，或者 可能“不拥有所有权”。 当它只需要对所指向的数据进行只读访问的时候，它就只是一个借用指针；当它需要写数据功能时，它会先分配内存，执行复制操作，再对自己拥有所有权的内存进行写入操作。 在标准库里: pub enum Cow where B: ToOwned { /// Borrowed data. Borrowed(&'a B), /// Owned data. Owned(::Owned) } 它可以是Borrowed或者Owned两种状态。如果是Borrowed状态，可以通过调用to_mut()函数获取所有权。在这个过程中，它实际上会分配一块新的内存，并将原来Borrowed状态的数据通过调用to_owned()方法 构造出一个新的拥有所有权的对象，然后对这块拥有所有权的内存执行操作。 比如下面的remove_spaces()函数, 如果入参没有空格, 就只返回借用; 如果有空格, 就返回一个新申请的有所有权的对象buf. use std::borrow::Cow; fn remove_spaces(input: &'a str) -> Cow { if input.contains(' ') { let mut buf = String::with_capacity(input.len()); for c in input.chars() { if c != ' ' { buf.push(c); } } return Cow::Owned(buf); } return Cow::Borrowed(input); } fn main() { let s1 = \"no_spaces_in_string\"; let result1 = remove_spaces(s1); let s2 = \"spaces in string\"; let result2 = remove_spaces(s2); println!(\"{}\\n{}\", result1, result2); } 为什么这里要用Cow呢? 因为这个函数的返回值类型用&str类 型和String类型都不大合适。 如果返回类型指定为&str类型，那么需要新分配内存的时候，会出现生命周期编译错误。因为函数内部新分配的字符串的引用不能在函数调用结束后继续存在。 如果返回类型指定为String类型，那么对于那种不需要对输入参数做修改的情况，有一些性能损失。因为输入参数&str类型转为String类 型需要分配新的内存空间并执行复制，性能开销较大。这种时候使用Cow类型就是不二之选。既能满足编译器的生命周期要求，也避免了无谓的数据复制。Cow类型，就是优秀的“零性能损失抽象”的设计范例。 Cow类型还实现了Deref trait，所以当我们需要调用类型T的成员函数的时候，可以直接调用，完全无须考虑后面具体是“借用指针”还是“拥有所有权的指针”。所以我们也可以把它当成是一种“智能指针”。 智能指针 上面提到的Rc和Cow都是智能指针.Rust中允许一部分运算符可以由用户自定义行为，即“操作符重载”。其中“解引用”是一个非常重要的操作符，它允许重载。 而需要提醒大家注意的是，“取引用”操作符，如&、&mut，是不允许重载的。因此，“取引用”和“解引用”并非对称互补关系。*&T的类型 一定是T，而&*T的类型未必就是T。 更重要的是，读者需要理解，在某些情况下，编译器帮我们插入了自动deref的调用，简化代码。 在Deref的基础上，我们可以封装出一种自定义类型，它可以直接调用其内部的其他类型的成员方法，我们可以把这种类型称为智能指针类型 其他 在方法里定义struct是可以的 impl Clone for Box { fn clone(&self) -> Self { let mut new = BoxBuilder { data: RawVec::with_capacity(self.len()), len: 0, }; let mut target = new.data.ptr(); for item in self.iter() { unsafe { ptr::write(target, item.clone()); target = target.offset(1); }; new.len += 1; } return unsafe { new.into_box() }; // Helper type for responding to panics correctly. struct BoxBuilder { data: RawVec, len: usize, } impl BoxBuilder { unsafe fn into_box(self) -> Box { let raw = ptr::read(&self.data); mem::forget(self); raw.into_box() } } impl Drop for BoxBuilder { fn drop(&mut self) { let mut data = self.data.ptr(); let max = unsafe { data.offset(self.len as isize) }; while data != max { unsafe { ptr::read(data); data = data.offset(1); } } } } } } 为什么明明可以直接在一个方法里写完的代码，还要引入一个新的类型呢？原因就在于panic safety问题。注意我们这里调用了T类型的 clone方法。T是一个泛型参数，谁能保证clone方法不会产生panic？没有谁能保证，我们只能尽可能让clone发生panic的时候，RawVec的状态不会乱掉。 所以，标准库的实现利用了RAII机制，即便在clone的时候发生了 panic，这个BoxBuilder类型的局部变量的析构函数依然会正确执行，并在析构函数中做好清理工作。上面这段代码之所以搞这么复杂，就是为了保证在发生panic的时候逻辑依然是正确的。大家可以去翻一下标准库中的代码，有大量类似的模式存在，都是因为需要考虑panic safety问题。Rust的标准库在编写的时候有这样一个目标：即便发生了panic，也不会产生“内存不安全”和“线程不安全”的情况。 文件打开 use std::fs::File; use std::io::Read; fn main() { let f = File::open(\"/target/file/path\"); if f.is_err() { println!(\"file is not exist.\"); return; } let mut f = f.unwrap(); let mut content = String::new(); let result = f.read_to_string(&mut content); if result.is_err() { println!(\"read file error.\"); return; } println!(\"{}\", result.unwrap()); } unsafe unsafe可以修饰fn, 代码块, trait, impl等 unsafe有传递性, 比如使用unsafe的fn的代码块也必须用unsafe来修饰. unsafe可以操作裸指针 fn main() { let x = 1_i32; let mut y: u32 = 1; let raw_mut = &mut y as *mut u32 as *mut i32 as *mut i64; // 这是安全的 unsafe { *raw_mut = -1; // 这是不安全的,必须在 unsafe 块中才能通过编译 } println!(\"{:X} {:X}\", x, y); } 上面的例子中: 首先raw_mut必须经过三个as as as的转换才能从u32的指针转为i64的指针 对raw_mut的直接修改是unsafe的 修改了raw_mut, 也就是y, 但也\"一起\"修改了x, 因为x和y两个变量地址是挨着的. 又比如下面的例子: fn raw_to_ref(p: *const i32) -> &'a i32 { unsafe { &*p } } fn main() { let p: &i32 = raw_to_ref(std::ptr::null::()); println!(\"{}\", p); } 这个例子会运行错误, 因为传入了一个空指针, 而在unsafe里面对空指针解引用出现错误. 不加unsafe是不能对裸指针解引用的 在unsafe里, 用户要自己避免空指针问题, 编译器是不管的 要修复这个错误, 改成这样就好了: fn raw_to_ref(p: *const i32) -> Option { if p.is_null() { None } else { unsafe { Some(&*p) } } } fn main() { let p: Option = raw_to_ref(std::ptr::null::()); println!(\"{:?}\", p); } 不用unsafe的swap例子 下面的例子是我自己写的, 能正常工作, 没用unsafe. fn swap(x: &mut i32, y: &mut i32) { let z = *x; *x = *y; *y = z; } fn main() { let mut a = 5; let mut b = 8; swap(&mut a, &mut b); println!(\"a: {}, b: {}\", a, b) } 但如果用泛型, 就会出现编译错误: fn swap(x: &mut T, y: &mut T) { let z = *x; *x = *y; *y = z; } fn main() { let mut a = 5; let mut b = 8; swap(&mut a, &mut b); println!(\"a: {}, b: {}\", a, b) } 错误是:cannot move out of *x which is behind a mutable reference 编译器还提示move occurs because *x has type T, which does not implement the Copy trait 意思是assign的时候, 默认执行的是move语义, 但这里因为x只是借用, 但没有权限解引用. 但如果实现了Copy trait, 也可以调用Copy 那么添加T的约束为Copy, 也就好了: fn swap(x: &mut T, y: &mut T) { let z = *x; //这里用了copy语义 *x = *y; *y = z; } fn main() { let mut a = 5; let mut b = 8; swap(&mut a, &mut b); println!(\"a: {}, b: {}\", a, b) } 标准库的swap 标准的swap并没有要求copy, 而是直接操作指针 fn swap(x: &mut T, y: &mut T) { unsafe { let mut t: T = mem::uninitialized(); ptr::copy_nonoverlapping(&*x, &mut t, 1); ptr::copy_nonoverlapping(&*y, x, 1); ptr::copy_nonoverlapping(&t, y, 1); mem::forget(t); } } 首先，我们依然需要一个作为中转的局部变量。这个局部变量该怎么初始化呢？其实我们不希望它执行初始化，因为我们只需要这部分内存空间而已，它里面的内容马上就会被覆盖掉，做初始化是浪费性能。况且，我们也不知道用什么通用的办法初始化一个泛型类型，它连Default约束都未必满足。所以我们要用mem::uninitialized函数。接下来，我们可以直接通过内存复制来交换两个变量。因为在Rust中，所有的类型、所有的move操作，都是简单的内存复制，不涉及其他的语义。Rust语言已经假定任何一个类型的实例，随时都可以被move到另外的地方，不会产生任何问题。所以，我们可以直接使用ptr::copy系列函数来完成。再加上在safe代码中，&mut型指针具有排他性， 我们可以确信，x和y一定指向不同的变量。所以可以使用ptr::copy_nonoverlapping函数，比ptr::copy要快一点。 最后，一定要记得，要阻止临时的局部变量t执行析构函数。因为t本身并未被合理地初始化，它内部的值是直接通过内存复制获得的。在复制完成后，它内部的指针（如果有的话）会和y指向的变量是相同的。如果我们不阻止它，那么在函数结束的时候它的析构函数就会被自动调用，这样y指向的变量就变成非法的了。 这样我们才能正确地完成这个功能。虽然源代码看起来比较长，但是实际生成的代码并不多，就是3次内存块的复制。 Vec代码 下面的代码中, 用Vec的new创建出来的变量v1, 开始的capacity是0, length也是0, 增长的倍数也是2倍速. fn main() { let mut v1 = Vec::::new(); println!(\"Start: length {} capacity {}\", v1.len(), v1.capacity()); for i in 1..10 { v1.push(i); println!( \"[Pushed {}] length {} capacity {}\", i, v1.len(), v1.capacity() ); } let mut v2 = Vec::::with_capacity(1); println!(\"Start: length {} capacity {}\", v2.len(), v2.capacity()); v2.reserve(10); for i in 1..10 { v2.push(i); println!( \"[Pushed {}] length {} capacity {}\", i, v2.len(), v2.capacity() ); } } //结果 Start: length 0 capacity 0 [Pushed 1] length 1 capacity 4 [Pushed 2] length 2 capacity 4 [Pushed 3] length 3 capacity 4 [Pushed 4] length 4 capacity 4 [Pushed 5] length 5 capacity 8 [Pushed 6] length 6 capacity 8 [Pushed 7] length 7 capacity 8 [Pushed 8] length 8 capacity 8 [Pushed 9] length 9 capacity 16 Start: length 0 capacity 1 [Pushed 1] length 1 capacity 10 [Pushed 2] length 2 capacity 10 [Pushed 3] length 3 capacity 10 [Pushed 4] length 4 capacity 10 [Pushed 5] length 5 capacity 10 [Pushed 6] length 6 capacity 10 [Pushed 7] length 7 capacity 10 [Pushed 8] length 8 capacity 10 [Pushed 9] length 9 capacity 10 用with_capacity()创建的容量一开始就分配了. Vec的特点是空间会自动扩展, 并且当变量生命周 期结束的时候，它会自动释放它管理的内存空间 为什么Vec能够自动回收空间呢? 因为Vec实现了Drop: unsafe impl Drop for Vec { fn drop(&mut self) { unsafe { // use drop for [T] ptr::drop_in_place(&mut self[..]); } // RawVec handles deallocation } } "},"notes/rust_入门3.html":{"url":"notes/rust_入门3.html","title":"闭包 容器 迭代器 生成器 线程","keywords":"","body":" 静态分派和动态分派 trait不能用作入参或者返回值 impl Trait做为入参 impl trait只是语法糖 trait object impl trait 闭包 普通的函数不能捕获局部变量 闭包和函数 闭包如何捕获变量? move关键字 闭包和泛型 可以用Box封装闭包 容器 Vec VecDeque HashMap BTreeMap 迭代器 从容器创造迭代器 迭代器组合 for in 生成器 协程 标准库 类型转换 AsRef/AsMut borrow From/Into ToOwned ToString/FromStr 运算符重载 complex加法重载 IO OsString和OsStr 文件和路径 标准输入输出 进程启动参数 Any和反射 线程安全 创建线程 更多线程参数 rust怎么保证线程安全 Send & Sync 什么是Send类型 什么是Sync类型 保证线程安全的类型 Arc Mutex RwLock Atomic Barrier Condvar 全局变量 线程局部存储 异步管道 同步管道 相当于go channel 第三方线程库 静态分派和动态分派 trait不能用作入参或者返回值 比如下面的Bird这个trait, 有两个实现, Duck和Swan trait Bird { fn fly(&self); } struct Duck; struct Swan; impl Bird for Duck { fn fly(&self) { println!(\"duck duck\"); } } impl Bird for Swan { fn fly(&self) { println!(\"swan swan\"); } } 但Bird不能直接用作入参和出参, 因为trait是一种DST类型，它的大小在编译阶段是不固定的. 这点和go的interface是不同的. // 以下代码不能编译 fn test(arg: Bird) {} fn test() -> Bird {} 有两个办法: 用泛型传参, 即静态分派fn test(arg: T) { arg.fly(); } 用trait object, 即自己给trait穿个Box的马甲, 做到动态分派 // 根据不同需求,可以用不同的指针类型,如 Box/&/&mut 等 fn test(arg: Box) { arg.fly(); } 似乎还有个办法是加dyn关键词, dyn是比较新的关键词 trait Bird { fn fly(&self); } struct Duck; struct Swan; impl Bird for Duck { fn fly(&self) { println!(\"duck duck\"); } } impl Bird for Swan { fn fly(&self) { println!(\"swan swan\"); } } fn call_fly(f: &dyn Bird) { f.fly() } fn main() { let duck = Duck; call_fly(&duck); call_fly(&Swan{}); } //输出 duck duck swan swan impl Trait做为入参 比如下面的函数 fn parse_csv_document(src: R) -> std::io::Result>> { src.lines() .map(|line| { // For each line in the source line.map(|line| { // If the line was read successfully, process it, if not, return the error line.split(',') // Split the line separated by commas .map(|entry| String::from(entry.trim())) // Remove leading and trailing whitespace .collect() // Collect all strings in a row into a Vec }) }) .collect() // Collect all lines into a Vec> } 可以由泛型约束改成impl trait, 即声明src必须实现std::io::BufRead这个trait. 这点和golang传入interface有点像. fn parse_csv_document(src: impl std::io::BufRead) -> std::io::Result>> { src.lines() .map(|line| { // For each line in the source line.map(|line| { // If the line was read successfully, process it, if not, return the error line.split(',') // Split the line separated by commas .map(|entry| String::from(entry.trim())) // Remove leading and trailing whitespace .collect() // Collect all strings in a row into a Vec }) }) .collect() // Collect all lines into a Vec> } impl trait只是语法糖 比如下面的代码用了impl trait形式的入参: pub fn notify(item: &impl Summary) { println!(\"Breaking news! {}\", item.summarize()); } 它实际上是下面显式声明泛型约束的方法一样: pub fn notify(item: &T) { println!(\"Breaking news! {}\", item.summarize()); } trait object 指向trait的指针就是trait object。假如Bird是一个trait的名称，那么dyn Bird就是一个DST动态大小类型。&dyn Bird、&mut dyn Bird、Box、*const dyn Bird、*mut dyn Bird以及Rc等等都是Trait Object。 A trait object points to both an instance of a type implementing our specified trait as well as a table used to look up trait methods on that type at runtime. We create a trait object by specifying some sort of pointer, such as a & reference or a Box smart pointer, then the dyn keyword, and then specifying the relevant trait. impl trait 还有个impl trait语法, 比如: fn foo(n: u32) -> impl Iterator { (0..n).map(|x| x * 100) } 返回一个函数也可以用类似的语法: fn multiply(m: i32) -> impl Fn(i32) -> i32 { move |x| x * m } fn main() { let f = multiply(5); println!(\"{}\", f(2)); } //结果 10 闭包 闭包(closure)是一种匿名函数，具有“捕获”外部变量的能力。闭包有时候也被称作lambda表达式。它有两个特点: 可以像函数一 样被调用； 可以捕获当前环境中的变量。 语法如下: fn main() { let add = |a: i32, b: i32| -> i32 { return a + b; }; let x = add(1, 2); println!(\"result is {}\", x); } 以上闭包有两个参数，以两个|包围。执行语句包含在{}中。闭包的参数和返回值类型的指定与普通函数的语法相同。闭包的参 数和返回值类型都是可以省略的，因此以上闭包可省略为: let add = |a, b| a + b; //省略了类型, 括号, 和return 普通的函数不能捕获局部变量 rust支持函数中定义函数, 但不支持内部函数引用外部函数的局部变量. 比如下面的代码编译不过 fn main() { let x = 1_i32; fn inner_add() -> i32 { x + 1 } let x2 = inner_add(); println!(\"result is {}\", x2); } 要改为闭包: fn main() { let x = 1_i32; let inner_add = || x + 1; let x2 = inner_add(); println!(\"result is {}\", x2); } 闭包和函数 闭包的实现: fn main() { let x = 1_i32; let add_x = | a | x + a; let result = add_x( 5 ); println!(\"result is {}\", result); } 如果改为非闭包的普通实现: struct Closure { inner1: i32, } impl Closure { fn call(&self, a: i32) -> i32 { self.inner1 + a } } fn main() { let x = 1_i32; let add_x = Closure { inner1: x }; let result = add_x.call(5); println!(\"result is {}\", result); } 可以看到闭包的方式更简洁. 闭包如何捕获变量? Rust主要是通过分析外部变量在闭包中的使用方式，通过一系列的规则自动推导出来的。主要规则如下: 如果一个外部变量在闭包中，只通过借用指针&使用，那么这个变量就可通过引用&的方式捕获； 如果一个外部变量在闭包中，通过&mut指针使用过，那么这个变量就需要使用&mut的方式捕获； 如果一个外部变量在闭包中，通过所有权转移的方式使用过，那么这个变量就需要使用“by value”的方式捕获。 简单点总结规则是，在保证能编译通过的情况下，编译器会自动选择一种对外部影响最小的类型存储。对于被捕获的类型为T的外部变量，在匿名结构体中的存储方式选择为: 尽可能先选择&T类型，其次选择&mut T类型，最后选择T类型。 move关键字 闭包的捕获默认是引用捕获, 即捕获&T. 下面的例子编译不通过 fn make_adder(x: i32) -> Box i32> { Box::new(|y| x + y) } fn main() { let f = make_adder(3); println!(\"{}\", f(1)); // 4 println!(\"{}\", f(10)); // 13 } 函数make_adder中有一个局部变量x，按照前面所述的规则，它被闭包所捕获，而且可以使用引用&的方式完成闭包内部的逻辑，因此它是被引用捕获的。而闭包则作为函数返回值被传递出去了。于是，闭包被调用的时候，它内部的引用所指向的内容已经被释放了。 这个时候就要用move关键字了, 表示后面语句块的所有变量都强制使用\"值传递\": fn make_adder(x: i32) -> Box i32> { Box::new(move |y| x + y) // 使用move来强制使用值传递 } 闭包和泛型 下面的例子是传入一个闭包函数到泛型函数: fn call_with_closure(some_closure: F) -> i32 where F: Fn(i32) -> i32, { some_closure(1) } fn main() { let answer = call_with_closure(|x| x + 2); println!(\"{}\", answer); } 每个闭包，编译器都会为它生成一个匿名结构体类型；即使两个闭包的参数和返回值一致，它们也是完全不同的两个类 型，只是都实现了同一个trait而已。 可以用Box封装闭包 fn test() -> Box i32> { let c = |i: i32| i * 2; Box::new(c) } fn main() { let closure = test(); let r = closure(2); println!(\"{}\", r); } 容器 容器 描述 Vec 可变长数组, 连续存储 VecDeque 双向队列, 适用于从头部和尾部插入删除数据 LinkedList 双向链表, 非连续存储 HashMap 基于Hash算法存储key value HashSet 只有key没有value的HashMap BTreeMap 基于B树存储key value BTreeSet 只有key没有value的BtreeMap BinaryHeap 基于二叉堆的优先级队列 Vec 它就是一个可以自动扩展容量的动态数组。它重载了Index运算符，可以通过中括号取下标的形式访问内部成员。它还重载了Deref/DerefMut运算符，因此可 以自动被解引用为数组切片。 用法示例: fn main() { // 常见的几种构造Vec的方式 // 1. new() 方法与 default() 方法一样,构造一个空的Vec let v1 = Vec::::new(); // 2. with_capacity() 方法可以预先分配一个较大空间,避免插入数据的时候动态扩容 let v2: Vec = Vec::with_capacity(1000); // 3. 利用宏来初始化,语法跟数组初始化类似 let v3 = vec![1, 2, 3]; // 插入数据 let mut v4 = Vec::new(); // 多种插入数据的方式 v4.push(1); v4.extend_from_slice(&[10, 20, 30, 40, 50]); v4.insert(2, 100); println!(\"capacity: {} length: {}\", v4.capacity(), v4.len()); // 访问数据 // 调用 IndexMut 运算符,可以写入数据 v4[5] = 5; let i = v4[5]; println!(\"{}\", i); // Index 运算符直接访问,如果越界则会造成 panic,而 get 方法不会,因为它返回一个 Option if let Some(i) = v4.get(6) { println!(\"{}\", i); } // Index 运算符支持使用各种 Range 作为索引 let slice = &v4[4..]; println!(\"{:?}\", slice); } VecDeque A double-ended queue implemented with a growable ring buffer VecDeque是一个双向队列。在它的头部或者尾部执行添加或者删除操作，都是效率很高的。它的用法和Vec非常相似，主要是多了pop_front()和push_front()等方法 use std::collections::VecDeque; fn main() { let mut queue = VecDeque::with_capacity(64); // 向尾部按顺序插入一堆数据 for i in 1..10 { queue.push_back(i); } // 从头部按顺序一个个取出来 while let Some(i) = queue.pop_front() { println!(\"{}\", i); } } HashMap HashMap泛型参数K是键的类型，V是值的类型，S是哈希算法的类型。S这个泛型参数有一个默认值. Hash trait就是这个算法: trait Hash { fn hash(&self, state: &mut H); ... } trait Hasher { fn finish(&self) -> u64; fn write(&mut self, bytes: &[u8]); ... } 如果一个类型，实现了Hash，给定了一种哈希算法Hasher，就能计算出一个u64类型的哈希值, 比如类似下面的: struct Person { first_name: String, last_name: String, } impl Hash for Person { fn hash(&self, state: &mut H) { self.first_name.hash(state); self.last_name.hash(state); } } 但通常写作: #[derive(Hash)] struct Person { first_name: String, last_name: String, } 完整的写法如下: use std::collections::HashMap; #[derive(Hash, Eq, PartialEq, Debug)] struct Person { first_name: String, last_name: String, } impl Person { fn new(first: &str, last: &str) -> Self { Person { first_name: first.to_string(), last_name: last.to_string(), } } } fn main() { let mut book = HashMap::new(); book.insert(Person::new(\"John\", \"Smith\"), \"521-8976\"); book.insert(Person::new(\"Sandra\", \"Dee\"), \"521-9655\"); book.insert(Person::new(\"Ted\", \"Baker\"), \"418-4165\"); let p = Person::new(\"John\", \"Smith\"); // 查找键对应的值 if let Some(phone) = book.get(&p) { println!(\"Phone number found: {}\", phone); } // 删除 book.remove(&p); // 查询是否存在 println!(\"Find key: {}\", book.contains_key(&p)); } HashMap对查询和insert/delete这种组合, 提供了entry API, 可以节省一次hash运算. 比如下面的代码: if map.contains_key(key) { // 执行了一遍hash查找的工作 map.insert(key, value); // 又执行了一遍hash查找的工作 } 使用entry API可以写成: map.entry(key).or_insert(value); BTreeMap 和HashMap用起来类似, 但使用B树来存储key value. 和hash不同, 这个解构是有序的. BTreeMap对key的要求是满足Ord约束，即具备“全序”特征. BTreeMap使用起来和Hashap类似, 但多了一个range功能如下: use std::collections::BTreeMap; fn main() { let mut map = BTreeMap::new(); map.insert(3, \"a\"); map.insert(5, \"b\"); map.insert(8, \"c\"); for (k, v) in map.range(2..6) { println!(\"{} : {}\", k, v); } } 迭代器 迭代器的trait: trait Iterator { type Item; fn next(&mut self) -> Option; } 它最主要的一个方法就是next()，返回一个Option。一般情况返回Some(Item)；如果迭代完成，就返回None。 一个迭代器需要自己记录内部状态, 比如下面Seq结构体里的current: use std::iter::Iterator; struct Seq { current: i32, } impl Seq { fn new() -> Self { Seq { current: 0 } } } impl Iterator for Seq { type Item = i32; //指定关联类型 fn next(&mut self) -> Option { if self.current 从容器创造迭代器 从容器创造迭代器: iter()创造一个Item是&T类型的迭代器； iter_mut()创造一个Item是&mut T类型的迭代器； into_iter()创造一个Item是T类型的迭代器。--这里有问题, 不一定是T 比如Vec等容器创造迭代器: fn main() { let v = vec![1, 2, 3, 4, 5]; let mut iter = v.iter(); while let Some(i) = iter.next() { println!(\"{}\", i); } } 这个和用for in是一样的: fn main() { let v = vec![1, 2, 3, 4, 5]; for i in v { println!(\"{}\", i) } } 迭代器组合 比如下面的例子: fn main() { let v = vec![1, 2, 3, 4, 5, 6, 7, 8, 9]; let mut iter = v .iter() .take(5) .filter(|&x| x % 2 == 0) .map(|&x| x * x) .enumerate(); while let Some((i, v)) = iter.next() { println!(\"{} {}\", i, v); } } 直到执行iter.next()前, 创造iter使用的\"组合\"模式的代价很小, 它只是按照用户定义的组合, 初始化了一个迭代器对象, 并没有真正干活. 比如下面的代码只是构造了一个迭代器示例, 不会打印, 因为没有调用next()方法. let v = vec![1, 2, 3, 4, 5]; v.iter().map(|x| println!(\"{}\", x)); for in for in就是给迭代器设计的语法糖 use std::collections::HashMap; fn main() { let v = vec![1, 2, 3, 4, 5, 6, 7, 8, 9]; for i in v { println!(\"{}\", i); } //从array生成一个hashmap let map: HashMap = [(1, 'a'), (2, 'b'), (3, 'c')].iter().cloned().collect(); //比较新的版本>1.56, 可以用from函数 let map = HashMap::from([(1, 'a'), (2, 'b'), (3, 'c')]); for (k, v) in &map { println!(\"{} : {}\", k, v); } } 因为for调用的是 trait IntoIterator { type Item; type IntoIter: Iterator; //感觉这行是约束的意思 fn into_iter(self) -> Self::IntoIter; } 只要某个类型实现了IntoIterator，那么调用into_iter()方法就可以得到对应的迭代器。这个into_iter()方法的receiver是self，而不是&self，执行的是move语义。这么做，可以同时支持Item类型为T、&T 或者&mut T，用户有选择的权力。 那么如何实现这个trait呢? 需要三个版本一起实现: impl IntoIterator for BTreeMap { type Item = (K, V); type IntoIter = IntoIter; } impl IntoIterator for &'a BTreeMap { type Item = (&'a K, &'a V); type IntoIter = Iter; } impl IntoIterator for &'a mut BTreeMap { type Item = (&'a K, &'a mut V); type IntoIter = IterMut; } 对于一个容器类型，标准库里面对它impl了三次IntoIterator。当Self类型为BTreeMap的时候，Item类型为(K，V)，这意味着，每次next()方法都是把内部的元素move出来了；当Self类型为&BTreeMap的时候，Item类型为(&K，&V)，每次next()方法返回的是借用； 当Self类型为&mut BTreeMap的时候，Item类型为(&K，&mut V)，每次next()方法返回的key是只读的，value是可读写的。 所以，如果有个变量m，其类型为BTreeMap，那么用户可以选择使用m.into_iter()或者(&m).into_iter()或者(&mut m).into_iter()，分别达到不同的目的。 for in循环用了into_iter()方法, 对应上面三种实现, 使用方法如下: // container在循环之后生命周期就结束了,循环过程中的每个item是从container中move出来的 for item in container {} // 迭代器中只包含container的&型引用,循环过程中的每个item都是container中元素的借用 for item in &container {} // 迭代器中包含container的&mut型引用,循环过程中的每个item都是指向container中元素的可变借用 for item in &mut container {} 可以看到, 实现了IntoIterator, 就可以被for in所使用. 生成器 生成器的语法像闭包, 区别是在语句块中有yield关键词, 比如: // 方案一 #![feature(generators, generator_trait)] use std::ops::{Generator, GeneratorState}; fn main() { let mut g = || { let mut curr: u64 = 1; let mut next: u64 = 1; loop { let new_next = curr.checked_add(next); if let Some(new_next) = new_next { curr = next; next = new_next; yield curr; // println!(\"{}\", v), GeneratorState::Complete(_) => return, } } } } 注意以上代码编译不过, 但可以看看其中原理: 生成器最大的特点就是，程序的执行流程可以在生成器和调用者之间来回切换。当我们需要暂时从生成器中返回的时候，就使用yield关键字；当调用者希望再次进入生成器的时候，就调用resume()方法，这时程序执行的流程是从上次yield返回的那个点继续执行。 回想迭代器, next方法就很像resume. 迭代器需要自己维护内部状态, 生成器也是类似的, 感觉生成器能自动维护其内部状态. 协程 用户态调度的协程.Rust的协程设计，核心是async和await两个关键字，以及Future这个 trait: pub trait Future { type Output; fn poll(self: PinMut, cx: &mut Context) -> Poll; ...... } 比如下面的代码: async fn async_fn(x: u8) -> u8 { let msg = await!(read_from_network()); let result = await!(calculate(msg, x)); result } 在这个示例中，假设read_from_network()以及calculate()函数都是异步的。最外层的async_fn()函数当然也是异步的。当代码执行到 await！(read_from_network())里面的时候，发现异步操作还没有完成，它会直接退出当前这个函数，把CPU让给其他任务执行。当这个数据从网络上传输完成了，调度器会再次调用这个函数，它会从上次中断的地方恢复执行。所以用async/await的语法写代码，异步代码的逻辑在源码组织上跟同步代码的逻辑差别并不大。这里面状态保存和恢复这些琐碎的事情，都由编译器帮我们完成了。 async关键字可以修饰函数、闭包以及代码块。对于函数: async fn f1(arg: u8) -> u8 {} 实际上等同于: fn f1(arg: u8) -> impl Future {} rust和go不同的, rust需要显式的手动指定调度点, 比如上面的await宏就埋了调度的代码; 而go的调度代码是\"隐藏\"的, 表面上让人感觉不到发生了用户态调度. 标准库 类型转换 常用的类型转换已经被preclude 包括AsRef、AsMut、Into、From、ToOwned等 AsRef/AsMut AsRef这个trait代表的意思是，这个类型可以通过调用as_ref方法，得到另外一个类型的共享引用: pub trait AsRef { fn as_ref(&self) -> &T; } 这里的?Sized约束指T可以是Sized也可以不是Sized, 如果没有, 则默认T是Sized. 类似的, 还有AsMut有一个as_mut方法，可以得到另外一个类型的可读写 引用: pub trait AsMut { fn as_mut(&mut self) -> &mut T; } 比如标准库的String类型, 就针对好几个类型参数实现了 AsRef trait: impl AsRef for String impl AsRef for String impl AsRef for String impl AsRef for String AsRef这样的trait很适合用在泛型代码中，为一系列类型做统一抽 象。比如，我们可以写一个泛型函数，它接受各种类型，只要可以被转 换为&[u8]即可: fn iter_bytes>(arg: T) { for i in arg.as_ref() { println!(\"{}\", i); } } fn main() { let s: String = String::from(\"this is a string\"); let v: Vec = vec![1, 2, 3]; let c: &str = \"hello\"; // 相当于函数重载。只不过基于泛型实现的重载,一定需要重载的参数类型满足某种共同的约束 iter_bytes(s); iter_bytes(v); iter_bytes(c); } borrow pub trait Borrow { fn borrow(&self) -> &Borrowed; } From/Into AsRef/Borrow做的类型转换都是从一种引用&T到另一种引用&U的转换。而From/Into做的则是从任意类型T到U的类型转换: pub trait From { fn from(T) -> Self; } pub trait Into { fn into(self) -> T; } Into和From是逆操作, 如果存在U: From，则实现T: Into impl Into for T where U: From { fn into(self) -> U { U::from(self) } } 比如标准库的String就实现了From impl From for String 可以使用&str.into()或者String::from(s)调用 fn main() { let s: &'static str = \"hello\"; let str1: String = s.into(); let str2: String = String::from(s); } ToOwned ToOwned trait提供的是一种更“泛化”的Clone的功能。Clone一般是从&T类型变量创造一个新的T类型变量，而ToOwned一般是从一个&T类型变量创造一个新的U类型变量。 impl ToOwned for T where T: Clone, { type Owned = T; fn to_owned(&self) -> T { self.clone() } fn clone_into(&self, target: &mut T) { target.clone_from(self); } } ToString/FromStr ToString trait提供了其他类型转换为String类型的能力 pub trait ToString { fn to_string(&self) -> String; } 一般情况下，我们不需要自己为自定义类型实现ToString trait。因为标准库中已经提供了一个默认实现: impl ToString for T { #[inline] default fn to_string(&self) -> String { use core::fmt::Write; let mut buf = String::new(); buf.write_fmt(format_args!(\"{}\", self)) .expect(\"a Display implementation return an error unexpectedly\"); buf.shrink_to_fit(); buf } } 这意味着，任何一个实现了Display trait的类型，都自动实现了ToString trait。而Display trait是可以自动derive的，我们只需要为类型添加一个attribute即可。 FromStr则提供了从字符串切片&str向其他类型转换的能力: pub trait FromStr { type Err; fn from_str(s: &str) -> Result; } str类型有个方法是parse pub fn parse(&self) -> Result { … } 可以这样用: fn print_type_of(_: &T) { println!(\"{}\", std::any::type_name::()) } fn main() { print_type_of(&\"4\".parse::()); let four1 = \"4\".parse::(); //和结构体一样, 函数的泛型参数也可以用双冒号指定 let four2: Result = \"4\".parse(); println!(\"{:?}\", four1); println!(\"{:?}\", four2); } 运算符重载 Rust允许一部分运算符重载，用户可以让这些运算符支持自定义类型。运算符重载的方式是: 针对自定义类型，impl一些在标准库中预定 义好的trait，这些trait都存在于std::ops模块中。比如前面已经讲过了的Deref trait就属于运算符重载 比如加法运算符重载需要满足下面的trait: trait Add { type Output; fn add(self, rhs: RHS) -> Self::Output; } 基本库为i32实现的加法trait: impl Add for i32 type Output = i32; impl Add for &'a i32 type Output = >::Output; impl Add for i32 type Output = >::Output; impl Add for &'b i32 type Output = >::Output; 这意味着，不仅i32+i32是允许的，而且i32+&i32、&i32+i32、&i32+&i32这几种形式也都是允许的。它们的返回类型都是i32 complex加法重载 use std::ops::Add; #[derive(Copy, Clone, Debug, PartialEq)] struct Complex { real: i32, imaginary: i32, } impl Add for Complex { type Output = Complex; fn add(self, other: Complex) -> Complex { Complex { real: self.real + other.real, imaginary: self.imaginary + other.imaginary, } } } fn main() { let c1 = Complex { real: 1, imaginary: 2, }; let c2 = Complex { real: 2, imaginary: 4, }; println!(\"{:?}\", c1 + c2); } 可以实现多个类型的add: use std::ops::Add; #[derive(Copy, Clone, Debug, PartialEq)] struct Complex { real: i32, imaginary: i32, } impl Add for Complex { type Output = Complex; fn add(self, other: &'a Complex) -> Complex { Complex { real: self.real + other.real, imaginary: self.imaginary + other.imaginary, } } } impl Add for Complex { type Output = Complex; fn add(self, other: i32) -> Complex { Complex { real: self.real + other, imaginary: self.imaginary, } } } IO OsString和OsStr Rust的String和Str是utf-8编码的, 但操作系统的字符串不一定用什么格式. 所以rust设计了OsString和OsStr来屏蔽差异. 使用场景如下: use std::path::PathBuf; fn main() { let mut buf = PathBuf::from(\"/\"); buf.set_file_name(\"bar\"); if let Some(s) = buf.to_str() { println!(\"{}\", s); } else { println!(\"invalid path\"); } } 这里的set_file_name方法声明如下: fn set_file_name>(&mut self, file_name: S) 因为&str满足这个约束: impl AsRef for str 文件和路径 rust对文件的实现在std::fs::File. 对文件的读写，则需要用到std::io模块了. 这个模块内部定义了几个重要的trait，比如Read/Write。File类型也实现了Read和Write两个 trait，因此它拥有一系列方便读写文件的方法. use std::fs::File; use std::io::prelude::*; use std::io::BufReader; fn test_read_file() -> Result { let mut path = std::env::home_dir().unwrap(); path.push(\".rustup\"); path.push(\"settings\"); path.set_extension(\"toml\"); let file = File::open(&path)?; let reader = BufReader::new(file); for line in reader.lines() { println!(\"Read a line: {}\", line?); } Ok(()) } fn main() { match test_read_file() { Ok(_) => {} Err(e) => { println!(\"Error occured: {}\", e); } } } 标准输入输出 use std::io::prelude::*; use std::io::BufReader; fn test_stdin() -> Result { let stdin = std::io::stdin(); let handle = stdin.lock(); let reader = BufReader::new(handle); for line in reader.lines() { let line = line?; if line.is_empty() { return Ok(()); } println!(\"Read a line: {}\", line); } Ok(()) } fn main() { match test_stdin() { Ok(_) => {} Err(e) => { println!(\"Error occured: {}\", e); } } } 进程启动参数 在Rust中，进程启动参数是调用独立的函数std::env::args()来得到的，或者使用std::env::args_os()来得到，进程返回值也是调用独立函数std::process::exit()来指定的。 比如: fn main() { if std::env::args().any(|arg| arg == \"-kill\") { std::process::exit(1); } for arg in std::env::args() { println!(\"{}\", arg); } } Any和反射 Rust标准库中提供了一个乞丐版的“反射”功能，那就是std::any模块。这个模块内，有个trait名字叫作Any。所有的类型都自动实现了Any这个trait，因此我们可以把任何一个对象的引用转为&Any这个trait object，然后调用它的方法。 它可以判断这个对象是什么类型，以及强制转换&Any为某个具体类型。另外，成员函数get_type_id()暂时要求'static约束，这个限制条件以后会放宽。 #![feature(get_type_id)] use std::any::Any; use std::fmt::Display; fn log(value: &T) { let value_any = value as &Any; if let Some(s) = value_any.downcast_ref::() { println!(\"String: {}\", s); } else if let Some(i) = value_any.downcast_ref::() { println!(\"i32: {}\", i); } else { let type_id = value_any.get_type_id(); println!(\"unknown type {:?}: {}\", type_id, value); } } fn do_work(value: &T) { log(value); } fn main() { let my_string = \"Hello World\".to_string(); do_work(&my_string); let my_i32: i32 = 100; do_work(&my_i32); let my_char: char = '❤'; do_work(&my_char); } 线程安全 创建线程 use std::thread; thread::spawn(move || { // 这里是新建线程的执行逻辑 }); 如果我们需要等待子线程执行结束，那么可以使用join方法: use std::thread; // child 的类型是 JoinHandle,这个T是闭包的返回类型 let child = thread::spawn(move || { // 子线程的逻辑 }); // 父线程等待子线程结束 let res = child.join(); 更多线程参数 use std::thread; thread::Builder::new().name(\"child1\".to_string()).spawn(move || { println!(\"Hello, world!\"); }); thread的常用API: thread::sleep(dur: Duration) 使得当前线程等待一段时间继续执行。在等待的时间内，线程调度器会调度其他的线程来执行。 thread::yield_now() 放弃当前线程的执行，要求线程调度器执行线程切换。 thread::current() 获得当前的线程。 thread::park() 暂停当前线程，进入等待状态。当thread::Thread::unpark(&self)方法被调用的时候，这个线程可以被恢复执行。 thread::Thread::unpark(&self) 综合例子如下: use std::thread; use std::time::Duration; fn main() { let t = thread::Builder::new() .name(\"child1\".to_string()) .spawn(move || { println!(\"enter child thread.\"); thread::park(); println!(\"resume child thread\"); }) .unwrap(); println!(\"spawn a thread\"); thread::sleep(Duration::new(5, 0)); t.thread().unpark(); t.join(); println!(\"child thread finished\"); } rust怎么保证线程安全 下面的代码编译不过: use std::thread; fn main() { let mut health = 12; thread::spawn(|| { health *= 2; }); println!(\"{}\", health); } spawn函数接受的参数是一个闭包。我们在闭包里面引用了函数体内的局部变量，而这个闭包是运行在另外一个线程上，编译器无法肯定局部变量health的生命周期一定大于闭包的生命周期，于是发生了错误. 如果在闭包前面加move, 虽然能够编译过, 但运行结果是health还是12, 因为move的语义是copy, 导致在闭包里面的health已经不是外面的health了. rust编译器可以识别下面的代码, 带不带move都编译不过. use std::thread; fn main() { let mut v: Vec = vec![]; thread::spawn(|| { v.push(1); }); println!(\"{:?}\", v); } 那么rust能不能让一个变量在不同的线程中共享呢? 答: 不能. 我们没有办法在多线程中直接读写普通的共享变量，除非使用Rust提供的线程安全相关的设施 。 The compiler prevents all data races. “共享不可变，可变不共享” Send & Sync std::marker::Sync: 如果类型T实现了Sync类型，那说明在不同的线程中使用&T访问同一个变量是安全的。 std::marker::Send: 如果类型T实现了Send类型，那说明这个类型的变量在不同的线程中传递所有权是安全的。 在spawn签名中: pub fn spawn(f: F) -> JoinHandle where F: FnOnce() -> T, F: Send + 'static, T: Send + 'static 我们需要注意的是，参数类型F有重要的约束条件F: Send+'static， T: Send+'static。它要求参数满足传递所有权的约束, 但凡在线程之间传递所有权会发生安全问题的类型，都无法在这个参数中出现，否则就是编译错误。另外，Rust对全局变量也有很多限制，你不可能简单地通过全局变量在多线程中随意共享状态。这样，编译器就会禁止掉可能有危险的线程间共享数据的行为。 什么是Send类型 Types that can be transferred across thread boundaries. This trait is automatically implemented when the compiler determines it's appropriate. Send trait由编译器自动判断并实现. 如果一个类型可以安全地从一个线程move进入另一个线程，那它就是Send类型。比如: 普通的数字类型是Send，因为我们把数字move进入另一个线程之后，两个线程同时执行也不会造成什么安全问题. 更进一步，内部不包含引用的类型，都是Send。因为这样的类型跟外界没有什么关联，当它被move进入另一个线程之后，它所有的部分都跟原来的线程没什么关系了，不会出现并发访问的情况。比如String类型。 稍微复杂一点的，具有泛型参数的类型，是否满足Send大多是取决于参数类型是否满足Send。比如Vec，只要我们能保证T: Send，那么Vec肯定也是Send，把它move进入其他线程是没什么问题的。再比如Cell、RefCell、Option、Box，也都是这种情况。 还比如加锁的类型也是Send类型, 比如Mutex就是这种。 Mutex这个类型实际上不关心它内部类型是怎样的，反正要访问内部数据，一定要调用lock()方法上锁，它的所有权在哪个线程中并不重要，所以把它move到其他线程也是没有问题的. 那什么不是send类型呢? 答案是编译器报错的就不是. 比如Rc 什么是Sync类型 Types for which it is safe to share references between threads. This trait is automatically implemented when the compiler determines it's appropriate. Sync trait由编译器自动判断并实现. 如果类型T实现了Sync trait，那说明在不 同的线程中使用&T访问同一个变量是安全的。注意这里是&T是只读的. 显然，基本数字类型肯定是Sync。假如不同线程都拥有指向同一个i32类型的只读引用&i32，这是没什么问题的。因为这个类型引用只能读，不能写。多个线程读同一个整数是安全的。 -- 这里我有疑问, 如果所有权的线程去写呢? 不就不安全了么? 大部分具有泛型参数的类型是否满足Sync，很多都是取决于参数类 型是否满足Sync。像Box、Vec Option 这种也是Sync的，只要其中的参数T是满足Sync的。 也有一些类型，不论泛型参数是否满足Sync，它都是满足Sync的。 这种类型把不满足Sync条件的类型用它包起来，就变成了满足Sync条件 的。Mutex就是这种。多个线程同时拥有&Mutex型引用，指向同一个变量是没问题的。 保证线程安全的类型 Arc Arc是Rc的线程安全版本。它的全称是“Atomic reference counter”。 use std::sync::Arc; use std::thread; fn main() { let numbers: Vec = (0..100u32).collect(); // 引用计数指针,指向一个 Vec let shared_numbers = Arc::new(numbers); // 循环创建 10 个线程 for _ in 0..10 { // 复制引用计数指针,所有的 Arc 都指向同一个 Vec let child_numbers = shared_numbers.clone(); // move修饰闭包,上面这个 Arc 指针被 move 进入了新线程中 thread::spawn(move || { // 我们可以在新线程中使用 Arc,读取共享的那个 Vec let local_numbers = &child_numbers[..]; // 继续使用 Vec 中的数据 }); } } Mutex 下面我们用一个示例来演示一下Arc和Mutex配合。使用多线程修改共享变量: use std::sync::Arc; use std::sync::Mutex; use std::thread; const COUNT: u32 = 1000000; fn main() { let global = Arc::new(Mutex::new(0)); let clone1 = global.clone(); let thread1 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone1.lock().unwrap(); *value += 1; } }); let clone2 = global.clone(); let thread2 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone2.lock().unwrap(); *value -= 1; } }); thread1.join().ok(); thread2.join().ok(); println!(\"final value: {:?}\", global); } 而MutexGuard类型则是一个“智能指针”类型，它实现了DerefMut和Deref这两个trait，所以它可以被当作指向内部数据的普通指针使用。 MutexGuard实现了一个析构函数，通过RAII手法，在析构函数中调用了unlock()方法解锁。因此，用户是不需要手动调用方法解锁的 RwLock use std::sync::Arc; use std::sync::RwLock; use std::thread; const COUNT: u32 = 1000000; fn main() { let global = Arc::new(RwLock::new(0)); let clone1 = global.clone(); let thread1 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone1.write().unwrap(); *value += 1; } }); let clone2 = global.clone(); let thread2 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone2.write().unwrap(); *value -= 1; } }); thread1.join().ok(); thread2.join().ok(); println!(\"final value: {:?}\", global); } Atomic use std::sync::atomic::{AtomicIsize, Ordering}; use std::sync::Arc; use std::thread; const COUNT: u32 = 1000000; fn main() { // Atomic 系列类型同样提供了线程安全版本的内部可变性 let global = Arc::new(AtomicIsize::new(0)); let clone1 = global.clone(); let thread1 = thread::spawn(move || { for _ in 0..COUNT { clone1.fetch_add(1, Ordering::SeqCst); } }); let clone2 = global.clone(); let thread2 = thread::spawn(move || { for _ in 0..COUNT { clone2.fetch_sub(1, Ordering::SeqCst); } }); thread1.join().ok(); thread2.join().ok(); println!(\"final value: {:?}\", global); } Barrier use std::sync::{Arc, Barrier}; use std::thread; fn main() { let barrier = Arc::new(Barrier::new(10)); let mut handlers = vec![]; for _ in 0..10 { let c = barrier.clone(); // The same messages will be printed together. // You will NOT see any interleaving. let t = thread::spawn(move || { println!(\"before wait\"); c.wait(); println!(\"after wait\"); }); handlers.push(t); } for h in handlers { h.join().ok(); } } 这个程序创建了一个多个线程之间共享的Barrier，它的初始值是10。我们创建了10个子线程，每个子线程都有一个Arc指针指向了这个Barrier，并在子线程中调用了Barrier::wait方法。这些子线程执行到 wait方法的时候，就开始进入等待状态，一直到wait方法被调用了10 次，10个子线程都进入等待状态，此时Barrier就通知这些线程可以继续了。然后它们再开始执行下面的逻辑。 Condvar 等待和通知的机制 use std::sync::{Arc, Condvar, Mutex}; use std::thread; use std::time::Duration; fn main() { let pair = Arc::new((Mutex::new(false), Condvar::new())); let pair2 = pair.clone(); thread::spawn(move || { thread::sleep(Duration::from_secs(1)); let &(ref lock, ref cvar) = &*pair2; let mut started = lock.lock().unwrap(); *started = true; cvar.notify_one(); println!(\"child thread {}\", *started); }); // wait for the thread to start up let &(ref lock, ref cvar) = &*pair; let mut started = lock.lock().unwrap(); println!(\"before wait {}\", *started); while !*started { started = cvar.wait(started).unwrap(); } println!(\"after wait {}\", *started); } 全局变量 Rust中允许存在全局变量。在基本语法章节讲过，使用static关键字修饰的变量就是全局变量。全局变量有一个特点: 如果要修改全局变量，必须使用unsafe关键字 线程局部存储 线程局部(Thread Local)的意思是，声明的这个变量看起来是一个变量，但它实际上在每一个线程中分别有自己独立的存储地址，是不同的变量，互不干扰。在不同线程中，只能看到与当前线程相关联的那个副本，因此对它的读写无须考虑线程安全问题。 可以使用#[thread_local]attribute 可以使用thread_local！宏 异步管道 相当于无限扩容的go channel, 但只是多生产单消费异步管道是最常用的一种管道类型。它的特点是: 发送端和接收端之间存在一个缓冲区，发送端发送数据的时候，是先将这个数据扔到缓冲区，再由接收端自己去取。因此，每次发送，立马就返回了，发送端不用管数据什么时候被接收端处理 use std::sync::mpsc::channel; use std::thread; fn main() { let (tx, rx) = channel(); thread::spawn(move || { for i in 0..10 { tx.send(i).unwrap(); //这里依次发送10个数字, 改成tx.send(\"hello\")发字符串也行的. } }); while let Ok(r) = rx.recv() { println!(\"received {}\", r); } } channel是个泛型函数: pub fn channel() -> (Sender, Receiver) Sender和Receiver 都是泛型类型，且一组发送者和接收者必定是同样的类型参数，因此保 证了发送和接收端都是同样的类型。因为Rust中的类型推导功能的存在，使我们可以在调用channel的时候不指定具体类型参数，而通过后续的方法调用，推导出正确的类型参数。 Sender和Receiver的泛型参数必须满足T: Send约束。这个条件是显而易见的: 被发送的消息会从一个线程转移到另外一个线程，这个约束是为了满足线程安全。如果用户指定的泛型参数没有满足条件，在编译的时候会发生错误，提醒我们修复bug。 发送者调用send方法，接收者调用recv方法，返回类型都是Result类型，用于错误处理，因为它们都有可能调用失败。当发送者已经被销毁 的时候，接收者调用recv则会返回错误；同样，当接收者已经销毁的时候，发送者调用send也会返回错误。 在管道的接收端，如果调用recv方法的时候还没有数据，它会进入等待状态阻塞当前线程，直到接收到数据才继续往下执行。 同步管道 相当于go channel 异步管道内部有一个不限长度的缓冲区，可以一直往里面填充数据，直至内存资源耗尽。异步管道的发送端调用send方法不会发生阻塞，只要把消息加入到缓冲区，它就马上返回。 同步管道的特点是: 其内部有一个固定大小的缓冲区，用来缓存消息。如果缓冲区被填满了，继续调用send方法的时候会发生阻塞，等待接收端把缓冲区内的消息拿走才能继续发送。缓冲区的长度可以在建立管道的时候设置，而且0是有效数值。如果缓冲区的长度设置为0，那就 意味着每次的发送操作都会进入等待状态，直到这个消息被接收端取走才能返回。 第三方线程库 threadpool: threadpool是一个基本的线程池实现use std::sync::mpsc::channel; use threadpool::ThreadPool; fn main() { let n_workers = 4; let n_jobs = 8; let pool = ThreadPool::new(n_workers); let (tx, rx) = channel(); for _ in 0..n_jobs { let tx = tx.clone(); pool.execute(move || { tx.send(1) .expect(\"channel will be there waiting for the pool\"); }); } assert_eq!(rx.iter().take(n_jobs).fold(0, |a, b| a + b), 8); } scoped-threadpool在前面的章节中，我们已经知道，如果要在多线程之间共享变量， 必须使用Arc这样的保证线程安全的智能指针。然而，Arc是有运行期开销的(虽然很小)。假如我们有时候需要子线程访问当前调用栈中的局部变量，而且能保证当前函数的生命周期一定大于子线程的生命周期， 子线程一定先于当前函数退出，那我们能不能直接在子线程中使用最简单的借用指针&来访问父线程栈上的局部对象呢？ parking_lotRust标准库帮我们封装了一些基本的操作系统的同步原语，比如 Mutex Condvar等。一般情况下这些够我们使用了。但是还有一些对性能有极致要求的开发者对标准库的实现并不满意，于是社区里又有人开发出来了一套替代品，在性能和易用性方面，都比标准库更好，这就是 parking_lot库。 crossbeam标准库给了一份mpsc(多生产者单消费者)管道的实现， 但是它有许多缺陷。crossbeam-channel这个库给我们提供了另外一套管 道的实现方式。不仅包括mpsc，还包括mpmc(多生产者多消费者)， 而且使用便捷，执行效率也很高。下面是一个双端管道的使用示例。它基本实现了go语言的内置管道 功能，在执行效率上甚至有过之而无不及:extern crate crossbeam; #[macro_use] extern crate crossbeam_channel as channel; use channel::{Receiver, Sender}; fn main() { let people = vec![\"Anna\", \"Bob\", \"Cody\", \"Dave\", \"Eva\"]; let (tx, rx) = channel::bounded(1); // Make room for one unmatched send. let (tx, rx) = (&tx, &rx); crossbeam::scope(|s| { for name in people { s.spawn(move || seek(name, tx, rx)); } }); if let Ok(name) = rx.try_recv() { println!(\"No one received {}’s message.\", name); } } // Either send my name into the channel or receive someone else's, whatever happens first. fn seek(name: &'a str, tx: &Sender, rx: &Receiver) { select_loop! { recv(rx, peer) => println!(\"{} received a message from {}.\", name, peer), send(tx, name) => {}, // Wait for someone to receive my message. } } rayon Rayon是Rust核心组成员Nicholas Matsakis开发的一个并行迭代器项目。它可以把一个按顺序执行的任务轻松变成并行执行。它非常轻量级，效率极高，而且使用非常简单。而且它保证了无数据竞争的线程安全。 "},"notes/rust_工程构建.html":{"url":"notes/rust_工程构建.html","title":"工程构建","keywords":"","body":" 测试和文档测试 详细解释crate和mod的文档 项目和模块 cargo cargo.toml 错误处理 问号运算符 和C的ABI兼容 从C调用Rust库 从Rust调用C库 文档 测试和文档测试 rust原生支持测试, 还支持对文档中的example代码进行测试. https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/testing.html 详细解释crate和mod的文档 https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/crates-and-modules.html cargo build会根据约定俗成的规则来编译bin或者lib, 大体上是通过分析目录结构, 和特殊的文件名, 比如main.rs, lib.rs, mod.rs等. $ tree . . ├── Cargo.lock ├── Cargo.toml ├── src │ ├── english │ │ ├── farewells.rs │ │ ├── greetings.rs │ │ └── mod.rs │ ├── japanese │ │ ├── farewells.rs │ │ ├── greetings.rs │ │ └── mod.rs │ └── lib.rs └── target ├── deps ├── libphrases-a7448e02a0468eaa.rlib └── native 项目和模块 Rust用了两个概念来管理项目：一个是crate，一个是mod。 crate简单理解就是一个项目。crate是Rust中的独立编译单元。每个 crate对应生成一个库或者可执行文件（如.lib .dll .so .exe等）。官方有一 个crate仓库https://crates.io/ ，可以供用户发布各种各样的库，用户也可 以直接使用这里面的开源库。 mod简单理解就是命名空间。mod可以嵌套，还可以控制内部元素的可见性。 crate和mod有一个重要区别是：crate之间不能出现循环引用；而mod是无所谓的，mod1要使用mod2的内容，同时mod2要使用mod1的内容，是完全没问题的。在Rust里面，crate才是一个完整的编译单元 （compile unit）。也就是说，rustc编译器必须把整个crate的内容全部读进去才能执行编译，rustc不是基于单个的.rs文件或者mod来执行编译的。作为对比，C/C++里面的编译单元是单独的.c/.cpp文件以及它们所有的include文件。每个.c/.cpp文件都是单独编译，生成.o文件，再把这些.o文件链接起来。 cargo Cargo是官方的项目管理工具 新建一个hello world工程cargo new hello_world --bin 新建一个hello world库cargo new hello_world --lib 编译cargo build --release cargo.toml 举例: [package] name = \"seccompiler\" version = \"1.1.0\" authors = [\"Amazon Firecracker team \"] edition = \"2018\" build = \"../../build.rs\" description = \"Program that compiles multi-threaded seccomp-bpf filters expressed as JSON into raw BPF programs, serializing them and outputting them to a file.\" homepage = \"https://firecracker-microvm.github.io/\" license = \"Apache-2.0\" [[bin]] name = \"seccompiler-bin\" path = \"src/seccompiler_bin.rs\" [dependencies] bincode = \"1.2.1\" libc = \">=0.2.39\" serde = { version = \">=1.0.27\", features = [\"derive\"] } serde_json = \">=1.0.9\" utils = { path = \"../utils\" } The Cargo.toml file for each package is called its manifest. It is written in the TOML format. Every manifest file consists of the following sections:参考: https://doc.rust-lang.org/cargo/reference/manifest.html cargo-features — Unstable, nightly-only features. [package] — Defines a package. name — The name of the package. version — The version of the package. authors — The authors of the package. edition — The Rust edition. rust-version — The minimal supported Rust version. description — A description of the package. documentation — URL of the package documentation. readme — Path to the package's README file. homepage — URL of the package homepage. repository — URL of the package source repository. license — The package license. license-file — Path to the text of the license. keywords — Keywords for the package. categories — Categories of the package. workspace — Path to the workspace for the package. build — Path to the package build script. links — Name of the native library the package links with. exclude — Files to exclude when publishing. include — Files to include when publishing. publish — Can be used to prevent publishing the package. metadata — Extra settings for external tools. default-run — The default binary to run by cargo run. autobins — Disables binary auto discovery. autoexamples — Disables example auto discovery. autotests — Disables test auto discovery. autobenches — Disables bench auto discovery. resolver — Sets the dependency resolver to use. Target tables: (see configuration for settings) [lib] — Library target settings. [[bin]] — Binary target settings. [[example]] — Example target settings. [[test]] — Test target settings. [[bench]] — Benchmark target settings. Dependency tables: [dependencies] — Package library dependencies. [dev-dependencies] — Dependencies for examples, tests, and benchmarks. [build-dependencies] — Dependencies for build scripts. [target] — Platform-specific dependencies. [badges] — Badges to display on a registry. [features] — Conditional compilation features. [patch] — Override dependencies. [replace] — Override dependencies (deprecated). [profile] — Compiler settings and optimizations. [workspace] — The workspace definition. 错误处理 比如使用Option表示some和none两种可能, 返回Result既有值又有错误 impl str { pub fn find>(&'a self, pat: P) -> Option {} } impl File { pub fn open>(path: P) -> io::Result {} } 比如 use std::mem::{size_of, size_of_val}; use std::str::FromStr; use std::string::ParseError; fn main() { let r: Result = FromStr::from_str(\"hello\"); println!(\"Size of String: {}\", size_of::()); println!(\"Size of `r`: {}\", size_of_val(&r)); } 问号运算符 问号运算符意思是，如果结果是Err，则提前返回一个Result类型，否则继续执行。 标准库的Option、Result实现了问号需要的trait fn file_double>(file_path: P) -> Result { let mut file = File::open(file_path).map_err(|e| e.to_string())?; let mut contents = String::new(); file.read_to_string(&mut contents) .map_err(|err| err.to_string())?; let n = contents .trim() .parse::() .map_err(|err| err.to_string())?; Ok(2 * n) } 进一步简化: use std::fs::File; use std::io::Read; use std::path::Path; fn file_double>(file_path: P) -> Result> { let mut file = File::open(file_path)?; let mut contents = String::new(); file.read_to_string(&mut contents)?; let n = contents.trim().parse::()?; Ok(2 * n) } fn main() { match file_double(\"foobar\") { Ok(n) => println!(\"{}\", n), Err(err) => println!(\"Error: {:?}\", err), } } 跟其他很多运算符一样，问号运算符也对应着标准库中的一个trait std::ops::Try trait Try { type Ok; type Error; fn into_result(self) -> Result; fn from_error(v: Self::Error) -> Self; fn from_ok(v: Self::Ok) -> Self; } 和C的ABI兼容 Rust有一个非常好的特性，就是它支持与C语言的ABI兼容. 所以，我们可以用Rust写一个库，然后直接把它当成C写的库来使用。或者反过来，用C写的库，可以直接在Rust中被调用。而且这个过程是没有额外性能损失的。C语言的ABI是这个世界上最通用的ABI，大部分编程语言都支持与C的ABI兼容。这也意味着，Rust与其他语言之间的交互是没问题的，比如用Rust为Python/Node.js/Ruby写一个模块等。 rust编译选项有--crate-type [bin|lib|rlib|dylib|cdylib|staticlib|proc-macro]其中，cdylib和staticlib就是与C的ABI兼容的 Rust 中有泛型，C语言里面没有，所以泛型这种东西是不可能暴露出来给C语言使用的，这就不是C语言的ABI的一部分。只有符合C语言的调用方式的函数，才能作为FFI的接口。这样的函数有以下基本要求： 使用extern \"C\"修饰，在Rust中extern fn默认等同于extern \"C\" fn； 使用#[no_mangle]修饰函数，避免名字重整； 函数参数、返回值中使用的类型，必须在Rust和C里面具备同样的内存布局。 从C调用Rust库 假设我们要在Rust中实现一个把字符串从小写变大写的函数，然后 由C语言调用这个函数: 在Rust侧: #[no_mangle] pub extern \"C\" fn rust_capitalize(s: *mut c_char) { unsafe { let mut p = s as *mut u8; while *p != 0 { let ch = char::from(*p); if ch.is_ascii() { let upper = ch.to_ascii_uppercase(); *p = upper as u8; } p = p.offset(1); } } } 我们在Rust中实现这个函数，考虑到C语言调用的时候传递的是char*类型，所以在Rust中我们对应的参数类型是*mut std::os:: raw::c_char。这样两边就对应起来了。 用下面的命令生成一个c兼容的静态库: rustc --crate-type=staticlib capitalize.rs 在C里面调用: #include #include // declare extern void rust_capitalize(char *); int main() { char str[] = \"hello world\"; rust_capitalize(str); printf(\"%s\\n\", str); return 0; } 用下面的命令链接: gcc -o main main.c -L. -l:libcapitalize.a -Wl,--gc-sections -lpthread -ldl 从Rust调用C库 比如c的函数 int add_square(int a, int b) { return a * a + b * b; } 在rust里面调用: use std::os::raw::c_int; #[link(name = \"simple_math\")] extern \"C\" { fn add_square(a: c_int, b: c_int) -> c_int; } fn main() { let r = unsafe { add_square(2, 2) }; println!(\"{}\", r); } //编译: //rustc -L . call_math.rs 文档 特殊的文档注释 是///、//！、/**…*/、/*！…*/，它们会被视为文档 mod foo { //! 这块文档是给 `foo` 模块做的说明 /// 这块文档是给函数 `f` 做的说明 fn f() { // 这块注释不是文档的一部分 } } 文档还支持markdown格式 "},"notes/rust_vmm_brief.html":{"url":"notes/rust_vmm_brief.html","title":"VMM(virtual machine monitor)","keywords":"","body":"介绍Firecracker Cloud-hypervisor以及virtio基础概念. 转录自我的PPT VMM brief Virtio devices MMIO based virtio devices PCI based virtio devices Memory Manager in cloud-hypervisor Device Manager Virtio Net example VMM brief Virtio devices Virtio is a protocol that defines how guest drivers talk to virtual devices. See the spec v1.2.Virtio devices can be exposed by PCI or MMIO PCI: a device with PCI vendor ID 0x1AF4 is a virtio device, device configuration structures are mapped to PCI configuration header BAR 0 Common configuration: feature bits, queue num, queue size, queue select, queue address Notifications: driver writes to notification address triggers an event to device ISR Status: not used when msi-x is enabled Device-specific configuration: different virtio types(net, block…) have different layouts PCI configuration access: provide an alternative way to access above registers other than BAR MMIO: a region of predefined register layout starting at base address, with compatible = \"virtio,mmio“ in DTS, which can be “discovered” by guest driver. All registers are little endian MMIO based virtio devices PCI based virtio devices Memory Manager in cloud-hypervisor Defines VM physical memory layout, just like a new SOC Uses BtreeMap to record memory ranges Uses KVM_SET_USER_MEMORY_REGION ioctl to map the layout to VMM virtual memory. (VM_PA to HOST_VA) When guest VM access memory, 2 stages translate happens(e.g. AARCH64): VM_VA -> VM_PA HOST_VA -> HOST_PA Mainly focus on PCI MMIO space PCI MMCONFIG space AARCH64 VM_PA layout Device Manager Manages all PCI devices Virtio PCI devices VFIO PCI devices Normally has 2 PCI segments Segment 0 is default Each PCI segment has PCI root, vendor ID intel, device ID VIRT_PCIE_HOST Uses HashMap to map bdf to PciDevice A pci config mmio BusDevice to route mm config access to corresponding PciDevice A MMIO address Allocator And many VirtioPciDevices Virtio Net example Virtio net has at least 3 virtqueues Transmitq Receiveq Controlq Driver sends and receives packet driver puts a packet into transmitq Notifies device by writing the notification address of the queue Kvm delivers the notification VMM handles the packet, typically by forwarding it to tap VMM receives the reply packet from tap VMM injects interrupt through KVM Guest irq handler receives the packet Guest driver handles the received packet and hands over it to upper network stack. The content in the virtqueue is virtio_net_hdr + packet data "},"notes/rust_vmm_简介.html":{"url":"notes/rust_vmm_简介.html","title":"rust-vmm简介","keywords":"","body":"https://github.com/rust-vmm Rust-Vmm 是一个开源工程，是一个可以自由定制的 VMM（virtual machine monitor）虚拟机管理器，用户可以按照自己的方式订制它。它是基于 Rust 语言实现的 VMM，有着 Rust 语言带来的优点和特性。 首先，Rust 语言一个内存安全的语言，相比于用 C 或者 C++ 会频繁遇到的各种内存的问题，比如内存的溢出、空指针、野指针、越界访问等等，更进一步会造成安全的问题、性能的问题，以及各种崩溃的问题。Rust 语言很好地解决了这一点，从它的语法、编译规则等杜绝了内存级别访问的漏洞以及风险，所以用 Rust 写的 Rust-Vmm 天然的就是内存安全的。 第二，Rust-Vmm 是不易被攻击的，Rust-VMM 是从零开始的，它是从最小的硬件虚拟化出发的，最小的硬件虚拟化意味着它有着最小的攻击面，被攻击的面就非常少，所以它会很安全。 第三，Rust-Vmm 能够很灵活的定制。Rust-VMM 可以灵活定制它的每一个组件，所有的对于设备的模拟或者关键特性的处理都是封装成了一个一个的 Rust-Vmm crates 包，比如有 VCPU，有 linuxloader，vm-virtIO 等等。其中 crates 是 Rust 语言中的包管理工具，可以理解 JAVA 或 golang 里面的 package，它是以发行不同的包或者库的形式对外发布它的 feature。 第四，Rust-Vmm 有非常高的性能，基于 Rust 语言的 without garbage collection 特性，它是没有 GC 回收检查机制的，不像 JAVA 或者其他更高级的语言会有一个 runtime，Rust-Vmm 的性能上会更好，同时基于 KVM 实现的虚拟化方案也是性能的保证。 简单介绍一下 Rust-Vmm 的一个历史，它是由谷歌首先实现的，谷歌首先实现一个 Rust based 的轻量级的 VMM，它叫做 crosVM，大家也可以从链接里面看到，它是一个为 chrome 浏览器做的一个微内核。然后 AWS，亚马逊基于谷歌开源出来的 crosVM，实现了自己的基于 rust 的 VMM 叫 Firecracker。两个项目的开发人员会发现做这两个项目的时候，会有很多重复的重叠的通用的代码，很自然的把可以开源的、通用的部分结合到一块，就有了 Rust-Vmm 的项目。 使用rust vmm crosvm 使用rust vmm 参考https://opensource.com/article/19/3/rust-virtual-machine要自己搭一个vmm, 可以使用rust rmm提供的各种模块, 这些模块都是独立的项目, rust里面叫crate. KVM interface: Creating our VMM on top of KVM requires an interface that can invoke KVM functionality from Rust. The kvm-bindings crate represents the Rust Foreign Function Interface (FFI) to KVM kernel headers. Because headers only include structures and defines, we also have wrappers over the KVM ioctls (kvm-ioctls) that we use for opening dev/kvm, creating a VM, creating vCPUs, and so on. Virtio devices and rate limiting: Virtio has a frontend-backend architecture. Currently in rust-vmm, the frontend is implemented in the virtio-devices crate, and the backend lies in the vhost package. Vhost has support for both user-land and kernel-land drivers, but users can also plug virtio-devices to their custom backend. The virtio-bindings are the bindings for Virtio devices generated using the Virtio Linux headers. All devices in the virtio-devices crate are exported independently as modules using conditional compilation. Some devices, such as block, net, and vsock support rate limiting in terms of I/O per second and bandwidth. This can be achieved by using the functionality provided in the rate-limiter crate. The kernel-loader is responsible for loading the contents of an ELF kernel image in guest memory. rust-vmm的github上, 各个模块是单独成库的: crosvm crosvm是google的为chrome OS上运行的VMM, 安全性好, Rust写的. Rust也是静态binary 每个虚拟设备是个进程,fork出来的, 但不exec. 这个进程用了minijail做沙盒处理, 应该类似seccomp. 基于KVM 使用Rust 支持x86, aarch64 virtual device使用socket和VM通信 设备模型的核心是bus, 一个读/写操做到bus上, bus会按这个读或写的地址, 找到对应的BusDevice, 转发读/写请求到该BusDevice. 一个地址上只能有一个BusDevice BusDevice可能出现在多个地址 每个BusDevice都自带mutex, 所以BusDevice的实现里就不需要再加锁了. "},"notes/rust_firecracker_代码.html":{"url":"notes/rust_firecracker_代码.html","title":"firecracker代码","keywords":"","body":"firecracker是最终的可执行文件: run_without_api流程 build_microvm_from_json event manager aarch64 物理内存layout devices::Bus 底层serial 用法 Serial结构体 三个Trait 自定义Error 用NoEvents的实例化的Serial driver在哪里读写? SerialWrapper 从stdin读输入发给guest流程 实现了BusDevice的按地址读写的trait attach_virtio_device vm.register_ioevent(queue_evt, &io_addr, i as u32) vm.register_irqfd kvm的irq相关API KVM_CREATE_IRQCHIP KVM_SET_GSI_ROUTING KVM_IRQFD KVM_CREATE_DEVICE 都有哪些可以被create ARM gic v3 KVM_DEV_ARM_VGIC_GRP_ADDR MmioTransport impl MmioTransport 实现BusDevice device device的状态有 IrqTrigger VirtioDevice trait VirtIO设备框图 virtIO net Net实现了VirtioDevice Net还实现了MutEventSubscriber run_without_api流程 这里重点考察build/cargo_target/x86_64-unknown-linux-musl/release/firecracker --no-api --config-file myvmconfig.json方式运行的firecrackermyvmconfig.json内容如下: { \"boot-source\": { \"kernel_image_path\": \"build/kernel/linux-5.10/vmlinux-5.10-x86_64.bin\", \"boot_args\": \"console=ttyS0 reboot=k panic=1 pci=off\", \"initrd_path\": null }, \"drives\": [ { \"drive_id\": \"rootfs\", \"path_on_host\": \"build/rootfs/bionic.rootfs.ext4\", \"is_root_device\": true, \"partuuid\": null, \"is_read_only\": false, \"cache_type\": \"Unsafe\", \"io_engine\": \"Sync\", \"rate_limiter\": null } ], \"machine-config\": { \"vcpu_count\": 2, \"mem_size_mib\": 1024, \"smt\": false, \"track_dirty_pages\": false }, \"balloon\": null, \"network-interfaces\": [], \"vsock\": null, \"logger\": null, \"metrics\": null, \"mmds-config\": null } 经过前面的命令行参数解析, 最后调用 run_without_api( &seccomp_filters, //这个是seccomp的bpf代码 vmm_config_json, //这个是配置文件的字符串 instance_info, boot_timer_enabled, mmds_size_limit, metadata_json.as_deref(), ) 这个函数先从json构建vmm, 然后在循环里run: fn run_without_api( seccomp_filters: &BpfThreadMap, config_json: Option, instance_info: InstanceInfo, bool_timer_enabled: bool, mmds_size_limit: usize, metadata_json: Option, ) -> FcExitCode { let mut event_manager = EventManager::new().expect(\"Unable to create EventManager\"); // Create the firecracker metrics object responsible for periodically printing metrics. let firecracker_metrics = Arc::new(Mutex::new(metrics::PeriodicMetrics::new())); event_manager.add_subscriber(firecracker_metrics.clone()); // Build the microVm. We can ignore VmResources since it's not used without api. let (_, vmm) = match build_microvm_from_json( seccomp_filters, &mut event_manager, // Safe to unwrap since '--no-api' requires this to be set. config_json.unwrap(), instance_info, bool_timer_enabled, mmds_size_limit, metadata_json, ) { Ok((res, vmm)) => (res, vmm), Err(exit_code) => return exit_code, }; // Start the metrics. firecracker_metrics .lock() .expect(\"Poisoned lock\") .start(metrics::WRITE_METRICS_PERIOD_MS); // Run the EventManager that drives everything in the microVM. loop { event_manager .run() .expect(\"Failed to start the event manager\"); if let Some(exit_code) = vmm.lock().unwrap().shutdown_exit_code() { return exit_code; } } } build_microvm_from_json就用到了核心模块vmm firecracker/src/vmm/src build_microvm_from_json build_microvm_from_json //根据json填充VmResources结构体并初始化 let mut vm_resources = VmResources::from_json() let vmm = vmm::builder::build_microvm_for_boot(&vm_resources) //建立guest内存, 思路是在host上mmap, 并记录内存region到变量 let guest_memory = create_guest_memory() //在x86上, 0-768M是内存, 768M到4G是MMIO, 4G以上还是内存 let arch_mem_regions = arch::arch_memory_regions(mem_size) vm_memory::create_guest_memory(&arch_mem_regions) 为每个region mmap一个region //先mmap一个大的size, size=原size+2个page, 属性是libc::PROT_NONE // Map the guarded range to PROT_NONE let guard_addr = unsafe { libc::mmap( std::ptr::null_mut(), guarded_size, libc::PROT_NONE, libc::MAP_ANONYMOUS | libc::MAP_PRIVATE | libc::MAP_NORESERVE, -1, 0, ) }; //再在刚刚map的region里面, 用原size map一个读写region // Inside the protected range, starting with guard_addr + PAGE_SIZE, // map the requested range with received protection and flags let region_addr = unsafe { libc::mmap( region_start_addr as *mut libc::c_void, //前面返回的addr加个page size, prot, flags | libc::MAP_FIXED, fd, offset as libc::off_t, ) }; //最后build MmapRegion并返回, 用的是https://github.com/rust-vmm/vm-memory //到这里好像只是生成GuestMemoryMmap数据结果, 并没有实际操作啥 //加载linux 内核, 代码在firecracker/src/vmm/src/builder.rs let entry_addr = load_kernel(boot_config, &guest_memory)?; let kernel_file = 先open kernel文件 //使用了https://github.com/rust-vmm/linux-loader //下面的Loader在x86上是ELF, 在ARM上是PE //把kernel_file加载到guest_memory let entry_addr = Loader::load::( &guest_memory, &kernel_file, arch::get_kernel_start()) //上面这个get_kernel_start()在x86上是1MB, aarch64上是2GB //先读elf header, 解析所有program header到 let mut phdrs: Vec = vec![]; for 每个phdr //写入guest内存, 似乎只是写入host上mmap的内存. 可能后面会用kvm的api把这些内存映射成guest内存 guest_mem.read_exact_from(mem_offset, kernel_image, phdr.p_filesz as usize) //从guest_memory find 一个region, 并写入initrd的内容; //在我们的配置里, initrd是null let initrd = load_initrd_from_config(boot_config, &guest_memory)?; //重写cmdline, 再原基础上增加virtio等配置 //创建VM let (mut vmm, mut vcpus) = create_vmm_and_vcpus( instance_info, event_manager, guest_memory, None, track_dirty_pages, vcpu_config.vcpu_count, )?; // Set up Kvm Vm and register memory regions. //调用kvm-ioctls let mut vm = setup_kvm_vm(&guest_memory, track_dirty_pages)?; //open /dev/kvm, 然后ioctl KVM_CREATE_VM let mut vm = Vm::new() vm.memory_init() //每个region调用 ioctl KVM_SET_USER_MEMORY_REGION //MMIO_MEM_START在x86上是(4G-768M), 在aarch64上是1G //IRQ_BASE到IRQ_MAX在x86上是5到23, 在aarch64上是32到128 //这里说的是virtio设备用的irq号范围 //mmio_device_manager包括mmio_base, irq, 和bus let mmio_device_manager = MMIODeviceManager::new(arch::MMIO_MEM_START, (arch::IRQ_BASE, arch::IRQ_MAX)); //IrqManager是管理(first..last)irq范围的简单结构体 IrqManager::new() //device的bus是个BtreeMap组织的按地址空间划分的设备的集合 devices::Bus::new() //创建中断控制器 setup_interrupt_controller(&mut vm)?; //x86上是ioctl KVM_CREATE_IRQCHIP //aarch64上是GICv2::create(vm, vcpu_count) vm.setup_irqchip() //新建个eventfd let vcpus_exit_evt = EventFd::new(libc::EFD_NONBLOCK) vcpus = create_vcpus(&vm, vcpu_count, &vcpus_exit_evt) //for里创建n个vCPU, ioctl KVM_CREATE_VCPU let vcpu = Vcpu::new() vcpu.kvm_vcpu.init(vm.fd()) set_stdout_nonblocking(); // servial device是pio设备, 在x86上有, aarch64上没有 let serial_device = setup_serial_device(event_manager, stdin, stdout) //由Serial device写1产生event let interrupt_evt = EventFdTrigger::new(EventFd::new(EFD_NONBLOCK)) //表示in buffer ready let kick_stdin_read_evt = EventFdTrigger::new(EventFd::new(EFD_NONBLOCK)) //SerialWrapper是event和Servial的桥梁 let serial = SerialWrapper { serial: Serial::with_events( interrupt_evt, SerialEventsWrapper { metrics: METRICS.uart.clone(), buffer_ready_event_fd: Some(kick_stdin_read_evt), }, out, ), input: Some(input), } //加入event manager, 最后的event loop里面会监听stdin和kick_stdin_read_evt fd event_manager.add_subscriber(serial.clone()); //只有x86有pio device, 把上面的serial_device加入到pio_device_manager let pio_device_manager = create_pio_dev_manager_with_legacy_devices(&vm, serial_device, reset_evt) let vmm = Vmm { events_observer: Some(Box::new(SerialStdin::get())), instance_info: instance_info.clone(), shutdown_exit_code: None, vm, guest_memory, uffd, vcpus_handles: Vec::new(), vcpus_exit_evt, mmio_device_manager, #[cfg(target_arch = \"x86_64\")] pio_device_manager, }; //最后返回vmm, vcpus Ok((vmm, vcpus)) //这个是给测试用的, kernel启动完成后, test版本的init会直接写/dev/mem某个地址魔术字(123) attach_boot_timer_device(&mu vmm, request_ts)?; let boot_timer = devices::pseudo::BootTimer::new(request_ts); //在mmio里面分配地址空间, 所谓的注册就是按地址空间assign设备, 设备有读写函数 vmm.mmio_device_manager.register_mmio_boot_timer(boot_timer) //目前balloon设备没使能 attach_balloon_device(&mut vmm, &mut boot_cmdline, balloon, event_manager)?; attach_virtio_device(event_manager, vmm, id, balloon.clone(), cmdline) event_manager.add_subscriber(device.clone()); let device = MmioTransport::new(vmm.guest_memory().clone(), device); //分配mmio地址范围, 注册到mmio manager; 并修改cmdline vmm.mmio_device_manager.register_mmio_virtio_for_boot(vmm.vm.fd(), id, device, cmdline) //可能有多个virtio块设备 attach_block_devices( &mut vmm, &mut boot_cmdline, vm_resources.block.list.iter(), event_manager, )?; for 每个 block //如果是root device, 就增加cmdline \"root=/dev/vda\"或\"root=PARTUUID=partuuid\" //见下面的函数分析 attach_virtio_device(event_manager, vmm, id, block.clone(), cmdline)?; //可能有多个virtio net设备 attach_net_devices( &mut vmm, &mut boot_cmdline, vm_resources.net_builder.iter(), event_manager, )?; //对应virtio socket device //guest可以通过AF_VSOCK通过vsock device和host的AF_UNIX socket通信 attach_unixsock_vsock_device(&mut vmm, &mut boot_cmdline, unix_vsock, event_manager)?; configure_system_for_boot( &vmm, vcpus.as_mut(), vcpu_config, entry_addr, &initrd, boot_cmdline, )?; //启动vcpu到pause状态 // Move vcpus to their own threads and start their state machine in the 'Paused' state. vmm.start_vcpus( vcpus, seccomp_filters .get(\"vcpu\") .ok_or_else(|| MissingSeccompFilters(\"vcpu\".to_string()))? .clone(), ) //给每个vcpu起个thread thread::Builder::new().spawn(move || { //Runs the vCPU in KVM context in a loop. Handles KVM_EXITs then goes back in. //run的逻辑是执行StateMachine循环 //state machine从paused开始 self.run(filter); //状态机循环 while let Some(state_fn) = state_machine.function { // Run the current state handler, and get the next one. state_machine = state_fn(machine); } }) //使能seccomp seccompiler::apply_filter() // The vcpus start off in the `Paused` state, let them run. vmm.resume_vm().map_err(Internal)?; self.mmio_device_manager.kick_devices(); //对每个vCPU send event let vmm = Arc::new(Mutex::new(vmm)); event_manager.add_subscriber(vmm.clone()); VmResources定义如下: 一个VMM就由block vsock balloon net等builder构成 #[derive(Default)] pub struct VmResources { /// The vCpu and memory configuration for this microVM. vm_config: VmConfig, /// The boot configuration for this microVM. boot_config: Option, /// The block devices. pub block: BlockBuilder, /// The vsock device. pub vsock: VsockBuilder, /// The balloon device. pub balloon: BalloonBuilder, /// The network devices builder. pub net_builder: NetBuilder, /// The optional Mmds data store. // This is initialised on demand (if ever used), so that we don't allocate it unless it's // actually used. pub mmds: Option>>, /// Data store limit for the mmds. pub mmds_size_limit: usize, /// Whether or not to load boot timer device. pub boot_timer: bool, } event manager https://github.com/rust-vmm/event-manager 使用了epoll机制的事件驱动库 基本上是个epoll的event loop, event subscriber注册的时候掉哟init, 在loop里有对应的event就调用process. aarch64 物理内存layout // ==== Address map in use in ARM development systems today ==== // // - 32-bit - - 36-bit - - 40-bit - //1024GB + + +-------------------+ devices::Bus 一个device都对应一段地址空间, 一个bus包括多个device, 按BtreeMap组织, key是device的地址范围, value是BusDevice /// A device container for routing reads and writes over some address space. /// /// This doesn't have any restrictions on what kind of device or address space this applies to. The /// only restriction is that no two devices can overlap in this address space. #[derive(Clone, Default)] pub struct Bus { //bus下面是BtreeMap管理的device devices: BTreeMap>>, } Bus有get_device, insert, read, write方法. read和write的基本逻辑是通过地址来判断是哪个device, 然后lock这个设备, 然后read/write 比如: /// Reads data from the device that owns the range containing `addr` and puts it into `data`. /// /// Returns true on success, otherwise `data` is untouched. pub fn read(&self, addr: u64, data: &mut [u8]) -> bool { //self.get_device(addr)返回(offset,dev), offset就是\"设备内\"偏移地址 if let Some((offset, dev)) = self.get_device(addr) { // OK to unwrap as lock() failing is a serious error condition and should panic. dev.lock() .expect(\"Failed to acquire device lock\") .read(offset, data); true } else { false } } 底层serial vm-superio-0.5.0/src/serial.rs serial是个泛型的结构体: The serial console emulation is done by emulating a serial COM port. Each serial COM port (COM1-4) has an associated Port I/O address base and 12 registers mapped into 8 consecutive Port I/O locations (with the first one being the base). This structure emulates the registers that make sense for UART 16550 (and below) and helps in the interaction between the driver and device by using a Trigger object for notifications. It also writes the guest's output to an out Write object. serial模拟了UART的16550的12个寄存器 用法 use std::io::{sink, Error, Result}; use std::ops::Deref; use vm_superio::Trigger; use vm_superio::Serial; use vmm_sys_util::eventfd::EventFd; struct EventFdTrigger(EventFd); impl Trigger for EventFdTrigger { type E = Error; fn trigger(&self) -> Result { self.write(1) } } impl Deref for EventFdTrigger { type Target = EventFd; fn deref(&self) -> &Self::Target { &self.0 } } impl EventFdTrigger { pub fn new(flag: i32) -> Self { EventFdTrigger(EventFd::new(flag).unwrap()) } pub fn try_clone(&self) -> Self { EventFdTrigger((**self).try_clone().unwrap()) } } let intr_evt = EventFdTrigger::new(libc::EFD_NONBLOCK); let mut serial = Serial::new(intr_evt.try_clone(), Vec::new()); // std::io::Sink can be used if user is not interested in guest's output. let serial_with_sink = Serial::new(intr_evt, sink()); // Write 0x01 to THR register. serial.write(0, 0x01).unwrap(); // Read from RBR register. let value = serial.read(0); // Send more bytes to the guest in one shot. let input = &[b'a', b'b', b'c']; // Before enqueuing bytes we first check if there is enough free space // in the FIFO. if serial.fifo_capacity() >= input.len() { serial.enqueue_raw_bytes(input).unwrap(); } Serial结构体 这是个泛型, 需要用三个trait: Trigger, SerialEvents, Write来实例化. pub struct Serial { // Some UART registers. baud_divisor_low: u8, baud_divisor_high: u8, interrupt_enable: u8, interrupt_identification: u8, line_control: u8, line_status: u8, modem_control: u8, modem_status: u8, scratch: u8, // This is the buffer that is used for achieving the Receiver register // functionality in FIFO mode. Reading from RBR will return the oldest // unread byte from the RX FIFO. in_buffer: VecDeque, // Used for notifying the driver about some in/out events. interrupt_evt: T, events: EV, out: W, } 三个Trait pub trait SerialEvents { /// The driver reads data from the input buffer. fn buffer_read(&self); /// The driver successfully wrote one byte to serial output. fn out_byte(&self); /// An error occurred while writing a byte to serial output resulting in a lost byte. fn tx_lost_byte(&self); /// This event can be used by the consumer to re-enable events coming from /// the serial input. fn in_buffer_empty(&self); } //一般都是EventFD, 用于trigger通知guest driver? pub trait Trigger { /// Underlying type for the potential error conditions returned by `Self::trigger`. type E; /// Trigger an event. fn trigger(&self) -> Result; } //Write就是io哪个Write 自定义Error /// Errors encountered while handling serial console operations. #[derive(Debug)] pub enum Error { /// Failed to trigger interrupt. Trigger(E), /// Couldn't write/flush to the given destination. IOError(io::Error), /// No space left in FIFO. FullFifo, } 用NoEvents的实例化的Serial NoEvents结构体就是实现了一个啥也不干的SerialEvents pub struct NoEvents; impl SerialEvents for NoEvents { fn buffer_read(&self) {} fn out_byte(&self) {} fn tx_lost_byte(&self) {} fn in_buffer_empty(&self) {} } 一个更具体的实例化: impl Serial { /// Creates a new `Serial` instance which writes the guest's output to /// `out` and uses `trigger` object to notify the driver about new /// events. /// /// # Arguments /// * `trigger` - The Trigger object that will be used to notify the driver /// about events. /// * `out` - An object for writing guest's output to. In case the output /// is not of interest, /// [std::io::Sink](https://doc.rust-lang.org/std/io/struct.Sink.html) /// can be used here. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn new(trigger: T, out: W) -> Serial { Self::with_events(trigger, NoEvents, out) } } 同样的Serial是范围更大的泛型: impl Serial { /// Creates a new `Serial` instance which writes the guest's output to /// `out`, uses `trigger` object to notify the driver about new /// events, and invokes the `serial_evts` implementation of `SerialEvents` /// during operation. /// /// # Arguments /// * `trigger` - The `Trigger` object that will be used to notify the driver /// about events. /// * `serial_evts` - The `SerialEvents` implementation used to track the occurrence /// of significant events in the serial operation logic. /// * `out` - An object for writing guest's output to. In case the output /// is not of interest, /// [std::io::Sink](https://doc.rust-lang.org/std/io/struct.Sink.html) /// can be used here. pub fn with_events(trigger: T, serial_evts: EV, out: W) -> Self { //用了很多const定义个u8的常量, 比如DEFAULT_BAUD_DIVISOR_LOW是0x0C Serial { baud_divisor_low: DEFAULT_BAUD_DIVISOR_LOW, baud_divisor_high: DEFAULT_BAUD_DIVISOR_HIGH, interrupt_enable: DEFAULT_INTERRUPT_ENABLE, interrupt_identification: DEFAULT_INTERRUPT_IDENTIFICATION, line_control: DEFAULT_LINE_CONTROL, line_status: DEFAULT_LINE_STATUS, modem_control: DEFAULT_MODEM_CONTROL, modem_status: DEFAULT_MODEM_STATUS, scratch: DEFAULT_SCRATCH, in_buffer: VecDeque::new(), interrupt_evt: trigger, events: serial_evts, out, } } /// Provides a reference to the interrupt event object. pub fn interrupt_evt(&self) -> &T { &self.interrupt_evt } /// Provides a reference to the serial events object. pub fn events(&self) -> &EV { &self.events } //具体操作, 私有方法, 基本上是对结构体的各field进行操作 fn is_dlab_set(&self) -> bool { (self.line_control & LCR_DLAB_BIT) != 0 } //还有很多, 省略 //读写函数, 谁来读写? driver //write不是io Write的格式, offset是预定义的常量表中的常量 /// Handles a write request from the driver at `offset` offset from the /// base Port I/O address. /// /// # Arguments /// * `offset` - The offset that will be added to the base PIO address /// for writing to a specific register. /// * `value` - The byte that should be written. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn write(&mut self, offset: u8, value: u8) -> Result> { match offset { DLAB_LOW_OFFSET if self.is_dlab_set() => self.baud_divisor_low = value, DLAB_HIGH_OFFSET if self.is_dlab_set() => self.baud_divisor_high = value, //关键路径, 每次写入一个字节; 写到stdout DATA_OFFSET => { let res = self .out //重点是这里, 这个out一般是stdout, guest driver的write, 通过这里的Serial Device(Self), 写到stdout .write_all(&[value]) .map_err(Error::IOError) .and_then(|_| self.out.flush().map_err(Error::IOError)) .map(|_| self.events.out_byte()) .map_err(|err| { self.events.tx_lost_byte(); err }); // Because we cannot block the driver, the THRE interrupt is sent // irrespective of whether we are able to write the byte or not self.thr_empty_interrupt().map_err(Error::Trigger)?; return res; } _ => {} } Ok(()) } //读的逻辑是从self.in_buffer pop出一个字节, 返回给调用者. /// Handles a read request from the driver at `offset` offset from the /// base Port I/O address. /// /// Returns the read value. /// /// # Arguments /// * `offset` - The offset that will be added to the base PIO address /// for reading from a specific register. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn read(&mut self, offset: u8) -> u8 { match offset { DLAB_LOW_OFFSET if self.is_dlab_set() => self.baud_divisor_low, DLAB_HIGH_OFFSET if self.is_dlab_set() => self.baud_divisor_high, DATA_OFFSET => { // Here we emulate the reset method for when RDA interrupt // was raised (i.e. read the receive buffer and clear the // interrupt identification register and RDA bit when no // more data is available). self.del_interrupt(IIR_RDA_BIT); let byte = self.in_buffer.pop_front().unwrap_or_default(); if self.in_buffer.is_empty() { self.clear_lsr_rda_bit(); self.events.in_buffer_empty(); } self.events.buffer_read(); byte } LCR_OFFSET => self.line_control, MCR_OFFSET => self.modem_control, LSR_OFFSET => self.line_status, _ => 0, } } /// Returns how much space is still available in the FIFO. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). #[inline] pub fn fifo_capacity(&self) -> usize { FIFO_SIZE - self.in_buffer.len() } /// Helps in sending more bytes to the guest in one shot, by storing /// `input` bytes in UART buffer and letting the driver know there is /// some pending data to be read by setting RDA bit and its corresponding /// interrupt when not already triggered. /// /// # Arguments /// * `input` - The data to be sent to the guest. /// /// # Returns /// /// The function returns the number of bytes it was able to write to the fifo, /// or `FullFifo` error when the fifo is full. Users can use /// [`fifo_capacity`](#method.fifo_capacity) before calling this function /// to check the available space. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn enqueue_raw_bytes(&mut self, input: &[u8]) -> Result> { let mut write_count = 0; if !self.is_in_loop_mode() { if self.fifo_capacity() == 0 { return Err(Error::FullFifo); } write_count = std::cmp::min(self.fifo_capacity(), input.len()); if write_count > 0 { self.in_buffer.extend(&input[0..write_count]); self.set_lsr_rda_bit(); //就是给Self.interrupt_evt这个eventfd写1 self.received_data_interrupt().map_err(Error::Trigger)?; } } Ok(write_count) } } driver在哪里读写? 待续 SerialWrapper SerialWrapper包括了底层Serial设备和input SerialWrapper: firecracker/src/devices/src/legacy/serial.rs 底层Serial: vm-superio-0.5.0/src/serial.rs pub struct SerialWrapper { pub serial: Serial, pub input: Option>, } 这个结构体是Serial device和event loop之间的桥梁. 之间用eventfd来通知 Host VMM Guest stdin/stdout Serial设备 read/write driver 具体来讲, guest driver通过BusDevice向Serial设备发出读写请求, VMM调用Serial设备的read/write函数来完成响应并在某些情况下触发中断通知(可能是给PioManager), 比如在给in_buffer读到data后产生received_data_interrupt. Serial结构体来维护UART16550的硬件的寄存器level的行为. 从stdin读输入发给guest流程 SerialWrapper的的实例实现了recv_bytes impl SerialWrapper { fn recv_bytes(&mut self) -> io::Result { let avail_cap = self.serial.fifo_capacity(); if let Some(input) = self.input.as_mut() { let mut out = vec![0u8; avail_cap]; //指定cap的vec //从stdin读 let count = input.read(&mut out)?; //看来&mut Vec能当作&mut [u8] if count > 0 { self.serial //这个有点讲究了, raw_input并不是底层Serial的方法, 而是本文件定义的trait //底层调用的是Servial设备的enqueue_raw_bytes方法, 往底层Servial的in_buffer填数据 .raw_input(&out[..count]) .map_err(|_| io::Error::from_raw_os_error(libc::ENOBUFS))?; } return Ok(count); } Err(io::Error::from_raw_os_error(libc::ENOTTY)) } } 这个recv_bytes被MutEventSubscriber trait调用, SerialWrapper也实现了MutEventSubscriber 里面的process就调用了recv_bytes 具体没怎么看懂 impl MutEventSubscriber for SerialWrapper { //process会在发生event的时候被调用, 传入event和ops用来表示event类型和维护event //可能有多个fd的源头, 但都共用这一个process函数. /// Handle events on the serial input fd. fn process(&mut self, event: Events, ops: &mut EventOps) { #[inline] fn unregister_source(ops: &mut EventOps, source: &T) { match ops.remove(Events::new(source, EventSet::IN)) { Ok(_) => (), Err(_) => error!(\"Could not unregister source fd: {}\", source.as_raw_fd()), } } let input_fd = self.serial_input_fd(); let buffer_ready_fd = self.buffer_ready_evt_fd(); if input_fd (), Err(err) => { error!(\"Detach serial device input source due to error in consuming the buffer ready event: {:?}\", err); unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); return; } } } // We expect to receive: `EventSet::IN`, `EventSet::HANG_UP` or // `EventSet::ERROR`. To process all these events we just have to // read from the serial input. match self.recv_bytes() { Ok(count) => { // Handle EOF if the event came from the input source. if input_fd == event.fd() && count == 0 { unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); warn!(\"Detached the serial input due to peer close/error.\"); } } Err(e) => { match e.raw_os_error() { Some(errno) if errno == libc::ENOBUFS => { unregister_source(ops, &input_fd); } //这里是none-block read没东西的时候会返回EAGAIN或者EWOULDBLOCK, 都差不多 Some(errno) if errno == libc::EWOULDBLOCK => { self.handle_ewouldblock(ops); } Some(errno) if errno == libc::ENOTTY => { error!(\"The serial device does not have the input source attached.\"); unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); } Some(_) | None => { // Unknown error, detach the serial input source. unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); warn!(\"Detached the serial input due to peer close/error.\"); } } } } } /// Initial registration of pollable objects. /// If serial input is present, register the serial input FD as readable. fn init(&mut self, ops: &mut EventOps) { //input就是stdin, buffer_ready_event_fd就是前面的kick_stdin_read_evt这个eventfd if self.input.is_some() && self.serial.events().buffer_ready_event_fd.is_some() { let serial_fd = self.serial_input_fd(); let buf_ready_evt = self.buffer_ready_evt_fd(); if serial_fd != -1 { //实际上是把stdin加到epoll if let Err(e) = ops.add(Events::new(&serial_fd, EventSet::IN)) { warn!(\"Failed to register serial input fd: {}\", e); } } //这个实际上是kick_stdin_read_evt这个eventfd if let Err(e) = ops.add(Events::new(&buf_ready_evt, EventSet::IN)) { warn!(\"Failed to register serial buffer ready event: {}\", e); } } } } 实现了BusDevice的按地址读写的trait 按总线地址读写, 最终转化为设备内偏移地址读写 impl BusDevice for SerialWrapper { //读是从内部in_buffer读 fn read(&mut self, offset: u64, data: &mut [u8]) { if data.len() != 1 { self.serial.events().metrics.missed_read_count.inc(); return; } data[0] = self.serial.read(offset as u8); } //写是写到stdout fn write(&mut self, offset: u64, data: &[u8]) { if data.len() != 1 { self.serial.events().metrics.missed_write_count.inc(); return; } if let Err(e) = self.serial.write(offset as u8, data[0]) { // Counter incremented for any handle_write() error. error!(\"Failed the write to serial: {:?}\", e); self.serial.events().metrics.error_count.inc(); } } } attach_virtio_device /// Attaches a VirtioDevice device to the device manager and event manager. fn attach_virtio_device( event_manager: &mut EventManager, vmm: &mut Vmm, id: String, device: Arc>, cmdline: &mut LoaderKernelCmdline, ) -> std::result::Result { use self::StartMicrovmError::*; //注册事件订阅 event_manager.add_subscriber(device.clone()); let device = MmioTransport::new(vmm.guest_memory().clone(), device); vmm.mmio_device_manager .register_mmio_virtio_for_boot(vmm.vm.fd(), id, device, cmdline) //分配mmio的addr len和irq资源, 策略是依次顺序分配 let mmio_slot = self.allocate_new_slot(1)?; self.register_mmio_virtio(vm, device_id, mmio_device, &mmio_slot)?; let locked_device = mmio_device.locked_device(); identifier = (DeviceType::Virtio(locked_device.device_type()), device_id); //对每个queue for (i, queue_evt) in locked_device.queue_events().iter().enumerate() //NOTIFY_REG_OFFSET是0x50, 加上slot.addr这个mmio device的base地址 //注意, 并不是所有的mmio设备的地址空间访问都会触发event, 这个io_addr只是特定地址, 用来notify device的. let io_addr = IoEventAddress::Mmio(slot.addr + u64::from(devices::virtio::NOTIFY_REG_OFFSET)); //这个queue_evt是每个queue的eventfd, 写io_addr就会触发event, 说明guest driver要通知device来干活了 //调用了kvm的ioctl vm.register_ioevent(queue_evt, &io_addr, i as u32) //写这指定地址的时候发event到queue_evt vm.register_irqfd() //注册中断注入guest的eventfd和irq号, 调用kvm ioctl KVM_IRQFD; 意思是只要这个eventfd被写入, 内核的kvm模块就会给guest发指定的irq号中断. register_mmio_device() } vm.register_ioevent(queue_evt, &io_addr, i as u32) 三个参数如下: fd - EventFd which will be signaled. When signaling, the usual vmexit to userspace is prevented.addr - Address being written to.datamatch - Limits signaling fd to only the cases where the value being written is equal to this parameter. The size of datamatch is important and it must match the expected size of the guest's write. guest驱动需要某种方法来通知device, kvm的ioeventfd就是干这个用的. 用eventfd的好处是这个guest driver到device的通知不需要vmexit. Registers an event to be signaled whenever a certain address is written to. When signaling, the usual vmexit to userspace is prevented. 对应KVM的KVM_IOEVENTFD This ioctl attaches or detaches an ioeventfd to a legal pio/mmio address within the guest. A guest write in the registered address will signal the provided event instead of triggering an exit. If datamatch flag is set, the event will be signaled only if the written value to the registered address is equal to datamatch in struct kvm_ioeventfd. 注意: 这个对每个queue都调用了vm.register_ioevent(queue_evt, &io_addr, i as u32), 作用是给io_addr地址绑定一个queue_evt, 当driver写i到这个io_aadr地址的时候, signal给queue_evt. 但问题是, 如果是多个queue, 多个queue_evt都\"绑定\"到同一个io_addr.我猜测这个API是支持多个一个地址对应多个eventfd的, 可能由datamatch的值来区分这个signal发送到哪个eventfd vm.register_irqfd vm.register_irqfd(locked_device.interrupt_evt(), slot.irqs[0]) 调用kvm的ioctl的KVM_IRQFD(见下面) IRQFD是device写eventfd, 通过kvm触发guest中断的机制. kvm的irq相关API https://www.kernel.org/doc/html/latest/virt/kvm/api.html KVM_CREATE_IRQCHIP Creates an interrupt controller model in the kernel. On x86, creates a virtual ioapic, a virtual PIC (two PICs, nested), and sets up future vcpus to have a local APIC. IRQ routing for GSIs 0-15 is set to both PIC and IOAPIC; GSI 16-23 only go to the IOAPIC. On arm64, a GICv2 is created. Any other GIC versions require the usage of KVM_CREATE_DEVICE, which also supports creating a GICv2. Using KVM_CREATE_DEVICE is preferred over KVM_CREATE_IRQCHIP for GICv2. On s390, a dummy irq routing table is created. KVM_SET_GSI_ROUTING Sets the GSI routing table entries, overwriting any previously set entries. KVM_IRQFD Allows setting an eventfd to directly trigger a guest interrupt. kvm_irqfd.fd specifies the file descriptor to use as the eventfd and kvm_irqfd.gsi specifies the irqchip pin toggled by this event. When an event is triggered on the eventfd, an interrupt is injected into the guest using the specified gsi pin. The irqfd is removed using the KVM_IRQFD_FLAG_DEASSIGN flag, specifying both kvm_irqfd.fd and kvm_irqfd.gsi. With KVM_CAP_IRQFD_RESAMPLE, KVM_IRQFD supports a de-assert and notify mechanism allowing emulation of level-triggered, irqfd-based interrupts. When KVM_IRQFD_FLAG_RESAMPLE is set the user must pass an additional eventfd in the kvm_irqfd.resamplefd field. When operating in resample mode, posting of an interrupt through kvm_irq.fd asserts the specified gsi in the irqchip. When the irqchip is resampled, such as from an EOI, the gsi is de-asserted and the user is notified via kvm_irqfd.resamplefd. It is the user’s responsibility to re-queue the interrupt if the device making use of it still requires service. Note that closing the resamplefd is not sufficient to disable the irqfd. The KVM_IRQFD_FLAG_RESAMPLE is only necessary on assignment and need not be specified with KVM_IRQFD_FLAG_DEASSIGN. On arm64, gsi routing being supported, the following can happen: in case no routing entry is associated to this gsi, injection fails in case the gsi is associated to an irqchip routing entry, irqchip.pin + 32 corresponds to the injected SPI ID. in case the gsi is associated to an MSI routing entry, the MSI message and device ID are translated into an LPI (support restricted to GICv3 ITS in-kernel emulation). KVM_CREATE_DEVICE Creates an emulated device in the kernel. The file descriptor returned in fd can be used with KVM_SET/GET/HAS_DEVICE_ATTR. If the KVM_CREATE_DEVICE_TEST flag is set, only test whether the device type is supported (not necessarily whether it can be created in the current vm). Individual devices should not define flags. Attributes should be used for specifying any behavior that is not implied by the device type number. 都有哪些可以被create Devices ARM Virtual Interrupt Translation Service (ITS) ARM Virtual Generic Interrupt Controller v2 (VGIC) ARM Virtual Generic Interrupt Controller v3 and later (VGICv3) MPIC interrupt controller FLIC (floating interrupt controller) Generic vcpu interface VFIO virtual device Generic vm interface XICS interrupt controller POWER9 eXternal Interrupt Virtualization Engine (XIVE Gen1) ARM gic v3 Only one VGIC instance may be instantiated through this API. The created VGIC will act as the VM interrupt controller, requiring emulated user-space devices to inject interrupts to the VGIC instead of directly to CPUs. It is not possible to create both a GICv3 and GICv2 on the same VM. Creating a guest GICv3 device requires a host GICv3 as well. KVM_DEV_ARM_VGIC_GRP_ADDR 定义了vgic寄存器在guest物理地址空间的基地址 KVM_VGIC_V3_ADDR_TYPE_DIST (rw, 64-bit) Base address in the guest physical address space of the GICv3 distributor register mappings. Only valid for KVM_DEV_TYPE_ARM_VGIC_V3. This address needs to be 64K aligned and the region covers 64 KByte. KVM_VGIC_V3_ADDR_TYPE_REDIST (rw, 64-bit) Base address in the guest physical address space of the GICv3 redistributor register mappings. There are two 64K pages for each VCPU and all of the redistributor pages are contiguous. Only valid for KVM_DEV_TYPE_ARM_VGIC_V3. This address needs to be 64K aligned. MmioTransport mplements the MMIO transport for virtio devices. This requires 3 points of installation to work with a VM: Mmio reads and writes must be sent to this device at what is referred to here as MMIO base. Mmio::queue_evts must be installed at virtio::NOTIFY_REG_OFFSET offset from the MMIO base. Each event in the array must be signaled if the index is written at that offset. Mmio::interrupt_evt must signal an interrupt that the guest driver is listening to when it is written to. Typically one page (4096 bytes) of MMIO address space is sufficient to handle this transport and inner virtio device. 对应的结构体: pub struct MmioTransport { device: Arc>, // The register where feature bits are stored. pub(crate) features_select: u32, // The register where features page is selected. pub(crate) acked_features_select: u32, pub(crate) queue_select: u32, pub(crate) device_status: u32, pub(crate) config_generation: u32, mem: GuestMemoryMmap, pub(crate) interrupt_status: Arc, } impl MmioTransport impl MmioTransport { /// Constructs a new MMIO transport for the given virtio device. pub fn new(mem: GuestMemoryMmap, device: Arc>) -> MmioTransport { //这里小知识点: device.lock()返回的是mutextGuard, 它会在生命周期结束后自动调用unlock. //不用担心一直会lock, 因为device.lock()的声明周期只有下面一行 //这行结束了其实就已经unlock了. let interrupt_status = device.lock().expect(\"Poisoned lock\").interrupt_status(); //new这个结构体 MmioTransport { device, features_select: 0, acked_features_select: 0, queue_select: 0, device_status: device_status::INIT, config_generation: 0, mem, interrupt_status, } } pub fn locked_device(&self) -> MutexGuard { self.device.lock().expect(\"Poisoned lock\") } // Gets the encapsulated VirtioDevice. pub fn device(&self) -> Arc> { self.device.clone() } fn check_device_status(&self, set: u32, clr: u32) -> bool { self.device_status & (set | clr) == set } fn are_queues_valid(&self) -> bool { self.locked_device() .queues() .iter() .all(|q| q.is_valid(&self.mem)) } //注意到泛型U, 并没有约束; //这里的意思是入参d的类型是U, 表示默认值. fn with_queue(&self, d: U, f: F) -> U where F: FnOnce(&Queue) -> U, { match self .locked_device() .queues() .get(self.queue_select as usize) { Some(queue) => f(queue), None => d, } } fn with_queue_mut(&mut self, f: F) -> bool { if let Some(queue) = self .locked_device() .queues_mut() .get_mut(self.queue_select as usize) { f(queue); true } else { false } } fn update_queue_field(&mut self, f: F) { if self.check_device_status( device_status::FEATURES_OK, device_status::DRIVER_OK | device_status::FAILED, ) { self.with_queue_mut(f); } else { warn!( \"update virtio queue in invalid state 0x{:x}\", self.device_status ); } } fn reset(&mut self) { 重置结构体\"寄存器\" } //根据VirtIO Spec 1.0, section 2.1.1 and 3.1.1 //在device的write里面调用, 实际上是给guest的driver用的 fn set_device_status(&mut self, status: u32) { } } 实现BusDevice 根据virtIO规范MMIO transport方式:https://docs.oasis-open.org/virtio/virtio/v1.2/csd01/virtio-v1.2-csd01.html#x1-1650002 impl BusDevice for MmioTransport { fn read(&mut self, offset: u64, data: &mut [u8]) { match offset { 0x00..=0xff if data.len() == 4 => { let v = match offset { 0x0 => MMIO_MAGIC_VALUE, 0x04 => MMIO_VERSION, 0x08 => self.locked_device().device_type(), 0x0c => VENDOR_ID, // vendor id 0x10 => { //32bit的feature flag let mut features = self .locked_device() .avail_features_by_page(self.features_select); if self.features_select == 1 { features |= 0x1; // enable support of VirtIO Version 1 } features } //对已经选中的queue(QueueSel), 读出queue内元素个数; Reading from the register returns the maximum size (number of elements) of the queue the device is ready to process or zero (0x0) if the queue is not available. 0x34 => self.with_queue(0, |q| u32::from(q.get_max_size())), //对已经选中的queue, 写1表示ready. 读是读上一次的值 0x44 => self.with_queue(0, |q| q.ready as u32), //中断状态寄存器, 要么是Used Buffer Notification(bit 0), 要么是Configuration Change Notification(bit 1) 0x60 => self.interrupt_status.load(Ordering::SeqCst) as u32, //设备状态寄存器. 0x70 => self.device_status, //配置空间原子性寄存器, 两次读的一样就是原子的? 0xfc => self.config_generation, _ => { warn!(\"unknown virtio mmio register read: 0x{:x}\", offset); return; } }; byte_order::write_le_u32(data, v); //注意这里, 使用byte_order的小端写 } 0x100..=0xfff => self.locked_device().read_config(offset - 0x100, data), _ => { warn!( \"invalid virtio mmio read: 0x{:x}:0x{:x}\", offset, data.len() ); } }; } fn write(&mut self, offset: u64, data: &[u8]) { fn hi(v: &mut GuestAddress, x: u32) { *v = (*v & 0xffff_ffff) | (u64::from(x) { let v = byte_order::read_le_u32(data); //按小端方式理解data match offset { //Device (host) features word selection. 写这个寄存器选择feature flag 0x14 => self.features_select = v, //Flags representing device features understood and activated by the driver 0x20 => { if self.check_device_status( device_status::DRIVER, device_status::FEATURES_OK | device_status::FAILED, ) { self.locked_device() .ack_features_by_page(self.acked_features_select, v); } else { warn!( \"ack virtio features in invalid state 0x{:x}\", self.device_status ); } } //Activated (guest) features word selection 0x24 => self.acked_features_select = v, //这个就是QueueSel, 也叫Virtual queue index, 从0开始 0x30 => self.queue_select = v, //Virtual queue size 0x38 => self.update_queue_field(|q| q.size = v as u16), //queue read //Writing one (0x1) to this register notifies the device that it can execute requests from this virtual queue. 0x44 => self.update_queue_field(|q| q.ready = v == 1), //中断应答 0x64 => { if self.check_device_status(device_status::DRIVER_OK, 0) { self.interrupt_status .fetch_and(!(v as usize), Ordering::SeqCst); } } //Device status: Writing non-zero values to this register sets the status flags, indicating the driver progress 0x70 => self.set_device_status(v), //Virtual queue’s Descriptor Area 64 bit long physical address 0x80 => self.update_queue_field(|q| lo(&mut q.desc_table, v)), 0x84 => self.update_queue_field(|q| hi(&mut q.desc_table, v)), //Virtual queue’s Driver Area 64 bit long physical address 0x90 => self.update_queue_field(|q| lo(&mut q.avail_ring, v)), 0x94 => self.update_queue_field(|q| hi(&mut q.avail_ring, v)), //Virtual queue’s Device Area 64 bit long physical address 0xa0 => self.update_queue_field(|q| lo(&mut q.used_ring, v)), 0xa4 => self.update_queue_field(|q| hi(&mut q.used_ring, v)), _ => { warn!(\"unknown virtio mmio register write: 0x{:x}\", offset); } } } 0x100..=0xfff => { if self.check_device_status(device_status::DRIVER, device_status::FAILED) { self.locked_device().write_config(offset - 0x100, data) } else { warn!(\"can not write to device config data area before driver is ready\"); } } _ => { warn!( \"invalid virtio mmio write: 0x{:x}:0x{:x}\", offset, data.len() ); } } } } device device的状态有 /// Enum that indicates if a VirtioDevice is inactive or has been activated /// and memory attached to it. pub enum DeviceState { Inactive, Activated(GuestMemoryMmap), } 这个enum也有方法, 其中mem()方法返回GuestmemoryMmap impl DeviceState { /// Checks if the device is activated. pub fn is_activated(&self) -> bool { match self { DeviceState::Inactive => false, DeviceState::Activated(_) => true, } } /// Gets the memory attached to the device if it is activated. pub fn mem(&self) -> Option { match self { DeviceState::Activated(ref mem) => Some(mem), DeviceState::Inactive => None, } } } IrqTrigger IrqTrigger包含一个eventFd叫irq_evt, trigger_irq方法就是写这个eventFd. /// Helper struct that is responsible for triggering guest IRQs pub struct IrqTrigger { pub(crate) irq_status: Arc, pub(crate) irq_evt: EventFd, } impl IrqTrigger { pub fn new() -> std::io::Result { Ok(Self { irq_status: Arc::new(AtomicUsize::new(0)), irq_evt: EventFd::new(libc::EFD_NONBLOCK)?, }) } pub fn trigger_irq(&self, irq_type: IrqType) -> std::result::Result { let irq = match irq_type { IrqType::Config => VIRTIO_MMIO_INT_CONFIG, IrqType::Vring => VIRTIO_MMIO_INT_VRING, }; //irq状态 self.irq_status.fetch_or(irq as usize, Ordering::SeqCst); //eventfd写1 self.irq_evt.write(1).map_err(|e| { error!(\"Failed to send irq to the guest: {:?}\", e); e })?; Ok(()) } } VirtioDevice trait /// Trait for virtio devices to be driven by a virtio transport. /// /// The lifecycle of a virtio device is to be moved to a virtio transport, which will then query the /// device. The virtio devices needs to create queues, events and event fds for interrupts and expose /// them to the transport via get_queues/get_queue_events/get_interrupt/get_interrupt_status fns. pub trait VirtioDevice: AsAny + Send { /// Get the available features offered by device. fn avail_features(&self) -> u64; /// Get acknowledged features of the driver. fn acked_features(&self) -> u64; /// Set acknowledged features of the driver. /// This function must maintain the following invariant: /// - self.avail_features() & self.acked_features() = self.get_acked_features() fn set_acked_features(&mut self, acked_features: u64); fn has_feature(&self, feature: u64) -> bool { (self.acked_features() & 1 u32; /// Returns the device queues. fn queues(&self) -> &[Queue]; /// Returns a mutable reference to the device queues. fn queues_mut(&mut self) -> &mut [Queue]; /// Returns the device queues event fds. fn queue_events(&self) -> &[EventFd]; /// Returns the device interrupt eventfd. fn interrupt_evt(&self) -> &EventFd; /// Returns the current device interrupt status. fn interrupt_status(&self) -> Arc; /// The set of feature bits shifted by `page * 32`. fn avail_features_by_page(&self, page: u32) -> u32 { let avail_features = self.avail_features(); match page { // Get the lower 32-bits of the features bitfield. 0 => avail_features as u32, // Get the upper 32-bits of the features bitfield. 1 => (avail_features >> 32) as u32, _ => { warn!(\"Received request for unknown features page.\"); 0u32 } } } /// Acknowledges that this set of features should be enabled. fn ack_features_by_page(&mut self, page: u32, value: u32) { let mut v = match page { 0 => u64::from(value), 1 => u64::from(value) { warn!(\"Cannot acknowledge unknown features page: {}\", page); 0u64 } }; // Check if the guest is ACK'ing a feature that we didn't claim to have. let avail_features = self.avail_features(); let unrequested_features = v & !avail_features; if unrequested_features != 0 { warn!(\"Received acknowledge request for unknown feature: {:x}\", v); // Don't count these features as acked. v &= !unrequested_features; } self.set_acked_features(self.acked_features() | v); } /// Reads this device configuration space at `offset`. fn read_config(&self, offset: u64, data: &mut [u8]); /// Writes to this device configuration space at `offset`. fn write_config(&mut self, offset: u64, data: &[u8]); /// Performs the formal activation for a device, which can be verified also with `is_activated`. fn activate(&mut self, mem: GuestMemoryMmap) -> ActivateResult; /// Checks if the resources of this device are activated. fn is_activated(&self) -> bool; /// Optionally deactivates this device and returns ownership of the guest memory map, interrupt /// event, and queue events. fn reset(&mut self) -> Option)> { None } } VirtIO设备框图 virtIO net virtIO net的定义很复杂 pub struct Net { pub(crate) id: String, pub tap: Tap, //对接的tap设备 pub(crate) avail_features: u64, pub(crate) acked_features: u64, pub(crate) queues: Vec, pub(crate) queue_evts: Vec, pub(crate) rx_rate_limiter: RateLimiter, pub(crate) tx_rate_limiter: RateLimiter, pub(crate) rx_deferred_frame: bool, rx_deferred_irqs: bool, rx_bytes_read: usize, rx_frame_buf: [u8; MAX_BUFFER_SIZE], tx_iovec: Vec, tx_frame_buf: [u8; MAX_BUFFER_SIZE], pub(crate) irq_trigger: IrqTrigger, //中断触发, 里面是eventfd pub(crate) config_space: ConfigSpace, pub(crate) guest_mac: Option, pub(crate) device_state: DeviceState, pub(crate) activate_evt: EventFd, pub mmds_ns: Option, #[cfg(test)] pub(crate) mocks: Mocks, } Net实现了很多方法, 比如交换tap设备和queue的数据: impl Net { new_with_tap() id() guest_mac() iface_name() mmds_ns() signal_used_queue() {self.irq_trigger.trigger_irq()} signal_rx_used_queue() do_write_frame_to_guest( write_frame_to_guest() read_from_mmds_or_tap() //处理从tap设备来的数据, 然后给guest发irq: //self.signal_used_queue() -> self.irq_trigger.trigger_irq(IrqType::Vring) 还是写eventfd process_rx() handle_deferred_frame() resume_rx() process_tx() read_tap() process_rx_queue_event() process_tap_rx_event() process_tx_queue_event() process_virtio_queues() } Net实现了VirtioDevice 相对比较薄的一层, 实现了下面的方法: Net还实现了MutEventSubscriber impl MutEventSubscriber for Net { fn process(&mut self, event: Events, ops: &mut EventOps) { let source = event.fd(); let event_set = event.event_set(); // TODO: also check for errors. Pending high level discussions on how we want // to handle errors in devices. let supported_events = EventSet::IN; if !supported_events.contains(event_set) { warn!( \"Received unknown event: {:?} from source: {:?}\", event_set, source ); return; } if self.is_activated() { let virtq_rx_ev_fd = self.queue_evts[RX_INDEX].as_raw_fd(); let virtq_tx_ev_fd = self.queue_evts[TX_INDEX].as_raw_fd(); let rx_rate_limiter_fd = self.rx_rate_limiter.as_raw_fd(); let tx_rate_limiter_fd = self.tx_rate_limiter.as_raw_fd(); let tap_fd = self.tap.as_raw_fd(); let activate_fd = self.activate_evt.as_raw_fd(); // Looks better than C style if/else if/else. match source { _ if source == virtq_rx_ev_fd => self.process_rx_queue_event(), _ if source == tap_fd => self.process_tap_rx_event(), //tap设备来数据了 _ if source == virtq_tx_ev_fd => self.process_tx_queue_event(), _ if source == rx_rate_limiter_fd => self.process_rx_rate_limiter_event(), _ if source == tx_rate_limiter_fd => self.process_tx_rate_limiter_event(), _ if activate_fd == source => self.process_activate_event(ops), _ => { warn!(\"Net: Spurious event received: {:?}\", source); METRICS.net.event_fails.inc(); } } } else { warn!( \"Net: The device is not yet activated. Spurious event received: {:?}\", source ); } } fn init(&mut self, ops: &mut EventOps) { // This function can be called during different points in the device lifetime: // - shortly after device creation, // - on device activation (is-activated already true at this point), // - on device restore from snapshot. if self.is_activated() { self.register_runtime_events(ops); } else { self.register_activate_event(ops); } } } "},"notes/rust_firecracker_使用.html":{"url":"notes/rust_firecracker_使用.html","title":"firecracker使用","keywords":"","body":" 编译 编译firecracker 编译kernel 编译rootfs 运行 配置文件方式运行 rest API方式运行 devctr镜像 顶层cargo firecracker/tools/devtool脚本 cmd_build 先build seccompiler 再build rebase-snap build firecracker build jailer build_kernel build_rootfs firecracker/resources/tests/init.c firecracker/resources/tests/fillmem.c firecracker/resources/tests/readmem.c 做镜像 编译 先clone代码: git clone https://github.com/firecracker-microvm/firecracker 编译firecracker firecracker是rust写的, 但编译不需要本地依赖rust环境, 而是在docker内完成的. 使用了docker imagepublic.ecr.aws/firecracker/fcuvm:v35, 大小3.25G 因为使用了x86_64-unknown-linux-musl做为target, 所以最后的可执行文件是静态链接的 默认debug版本:tools/devtool build生成:build/cargo_target/x86_64-unknown-linux-musl/debug/firecracker 38M, 静态链接, 带符号 指定release版本tools/devtool build --release生成:build/cargo_target/x86_64-unknown-linux-musl/release/firecracker 4.1M, 静态链接, 带符号 编译kernel tools/devtool build_kernel -c resources/guest_configs/microvm-kernel-x86_64-5.10.config -n 8生成:build/kernel/linux-5.10/vmlinux-5.10-x86_64.bin 42M, 带符号的linux elf, 模块全部编入kernel. 编译rootfs tools/devtool build_rootfs -s 300MB生成:build/rootfs/bionic.rootfs.ext4 300M 运行 配置文件方式运行 build/cargo_target/x86_64-unknown-linux-musl/release/firecracker --api-sock /tmp/firecracker.socket --config-file myvmconfig.json会打印kernel启动过程, 并自动以root登陆 myvmconfig.json内容如下: { \"boot-source\": { \"kernel_image_path\": \"build/kernel/linux-5.10/vmlinux-5.10-x86_64.bin\", \"boot_args\": \"console=ttyS0 reboot=k panic=1 pci=off\", \"initrd_path\": null }, \"drives\": [ { \"drive_id\": \"rootfs\", \"path_on_host\": \"build/rootfs/bionic.rootfs.ext4\", \"is_root_device\": true, \"partuuid\": null, \"is_read_only\": false, \"cache_type\": \"Unsafe\", \"io_engine\": \"Sync\", \"rate_limiter\": null } ], \"machine-config\": { \"vcpu_count\": 2, \"mem_size_mib\": 1024, \"smt\": false, \"track_dirty_pages\": false }, \"balloon\": null, \"network-interfaces\": [], \"vsock\": null, \"logger\": null, \"metrics\": null, \"mmds-config\": null } 跑的是ubuntu, 带systemd的 启动迅速 reboot会触发kernel退出, 但并不重启 没有网络接口 根文件系统挂在/dev/vda上 VM配置了1024M内存, 但运行时firecracker进程占用95M, 虚拟内存1032M. rest API方式运行 firecracker启动的时候要指定一个API socket, 每个VM一个. 使用这个socket, 可以用rest API方式来运行和管理VM. devctr镜像 devctr是开发中使用的镜像, 所有的操作都通过这个镜像完成. 基于ubuntu18 安装了常用的开发工具binutils-dev clang cmake gcc 等等 安装了rustcurl https://sh.rustup.rs -sSf | sh -s -- -y rustup target add x86_64-unknown-linux-musl rustup component add rustfmt rustup component add clippy-preview rustup install \"stable\" 使用了开源的init程序, 静态编译版本# Add the tini init binary. ADD https://github.com/krallin/tini/releases/download/${TINI_VERSION_TAG}/tini-static-amd64 /sbin/tini RUN chmod +x /sbin/tini WORKDIR \"$FIRECRACKER_SRC_DIR\" ENTRYPOINT [\"/sbin/tini\", \"--\"] 顶层cargo cargo.toml [workspace] members = [\"src/firecracker\", \"src/jailer\", \"src/seccompiler\", \"src/rebase-snap\"] default-members = [\"src/firecracker\"] [profile.dev] panic = \"abort\" [profile.release] panic = \"abort\" lto = true [patch.crates-io] kvm-bindings = { git = \"https://github.com/firecracker-microvm/kvm-bindings\", tag = \"v0.5.0-1\", features = [\"fam-wrappers\"] } cargo的build系统会自动维护cargo.lock来描述版本信息. 下面的命令可以更新依赖的版本信息: $ cargo update # updates all dependencies $ cargo update -p regex # updates just “regex” firecracker/tools/devtool脚本 # By default, all devtool commands run the container transparently, removing # it after the command completes. Any persisting files will be stored under # build/. # If, for any reason, you want to access the container directly, please use # `devtool shell`. This will perform the initial setup (bind-mounting the # sources dir, setting privileges) and will then drop into a BASH shell inside # the container. # # Building: # Run `./devtool build`. # By default, the debug binaries are built and placed under build/debug/. # To build the release version, run `./devtool build --release` instead. # You can then find the binaries under build/release/. # # Testing: # Run `./devtool test`. # This will run the entire integration test battery. The testing system is # based on pytest (http://pytest.org). # # Opening a shell prompt inside the development container: # Run `./devtool shell`. # # Additional information: # Run `./devtool help`. run_devctr函数写的很好. docker -v的z参数表示可以共享, 参考https://docs.docker.com/storage/bind-mounts/#configure-the-selinux-label # Helper function to run the dev container. # Usage: run_devctr -- # Example: run_devctr --privileged -- bash -c \"echo 'hello world'\" run_devctr() { docker_args=() ctr_args=() docker_args_done=false while [[ $# -gt 0 ]]; do [[ \"$1\" = \"--\" ]] && { docker_args_done=true shift continue } [[ $docker_args_done = true ]] && ctr_args+=(\"$1\") || docker_args+=(\"$1\") shift done # If we're running in a terminal, pass the terminal to Docker and run # the container interactively [[ -t 0 ]] && docker_args+=(\"-i\") [[ -t 1 ]] && docker_args+=(\"-t\") # Try to pass these environments from host into container for network proxies proxies=(http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY) for i in \"${proxies[@]}\"; do if [[ ! -z ${!i} ]]; then docker_args+=(\"--env\") && docker_args+=(\"$i=${!i}\") fi done # Finally, run the dev container # Use 'z' on the --volume parameter for docker to automatically relabel the # content and allow sharing between containers. docker run \"${docker_args[@]}\" \\ --rm \\ --volume /dev:/dev \\ --volume \"$FC_ROOT_DIR:$CTR_FC_ROOT_DIR:z\" \\ --env OPT_LOCAL_IMAGES_PATH=\"$(dirname \"$CTR_MICROVM_IMAGES_DIR\")\" \\ --env PYTHONDONTWRITEBYTECODE=1 \\ \"$DEVCTR_IMAGE\" \"${ctr_args[@]}\" } cmd_build 默认debug版本, 默认libc是musl target是x86_64-unknown-linux-musl 先build seccompiler seccompiler是个单独的binary, 把json转成BPF程序保存到文件中. # Build seccompiler-bin. run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build -p seccompiler --bin seccompiler-bin \\ --target-dir \"$CTR_CARGO_SECCOMPILER_TARGET_DIR\" \\ \"${cargo_args[@]}\" ret=$? 注: -p seccompiler: 只build seccompiler 再build rebase-snap Tool that copies all the non-sparse sections from a diff file onto a base file # Build rebase-snap. run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build -p rebase-snap \\ --target-dir \"$CTR_CARGO_REBASE_SNAP_TARGET_DIR\" \\ \"${cargo_args[@]}\" ret=$? build firecracker # Build Firecracker. run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build \\ --target-dir \"$CTR_CARGO_TARGET_DIR\" \\ \"${cargo_args[@]}\" ret=$? build jailer # Build jailer only in case of musl for compatibility reasons. if [ \"$libc\" == \"musl\" ];then run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build -p jailer \\ --target-dir \"$CTR_CARGO_TARGET_DIR\" \\ \"${cargo_args[@]}\" fi build_kernel 比如:./tools/devtool build_kernel -c resources/guest_configs/microvm-kernel-arm64-4.14.config # arch不同, vmlinux的format也不同 arch=$(uname -m) if [ \"$arch\" = \"x86_64\" ]; then target=\"vmlinux\" cfg_pattern=\"x86\" format=\"elf\" elif [ \"$arch\" = \"aarch64\" ]; then target=\"Image\" cfg_pattern=\"arm64\" format=\"pe\" recipe_url=\"https://raw.githubusercontent.com/rust-vmm/vmm-reference/$recipe_commit/resources/kernel/make_kernel.sh\" # 从自己的github的另一个库rust-vmm/vmm-reference下载 make_kernel.sh run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$kernel_dir_ctr\" \\ -- /bin/bash -c \"curl -LO \"$recipe_url\" && source make_kernel.sh && extract_kernel_srcs \"$KERNEL_VERSION\"\" cp \"$KERNEL_CFG\" \"$kernel_dir_host/linux-$KERNEL_VERSION/.config\" KERNEL_BINARY_NAME=\"vmlinux-$KERNEL_VERSION-$arch.bin\" #真正的make kernel run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$kernel_dir_ctr\" \\ -- /bin/bash -c \"source make_kernel.sh && make_kernel \"$kernel_dir_ctr/linux-$KERNEL_VERSION\" $format $target \"$nprocs\" \"$KERNEL_BINARY_NAME\"\" build_rootfs default rootfs size是300M, 用ubuntu18.04, 目标是$flavour.rootfs.ext4 先编译几个c文件, 用作测试? run_devctr \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ -- /bin/bash -c \"gcc -o $rootfs_dir_ctr/init $resources_dir_ctr/init.c && \\ gcc -o $rootfs_dir_ctr/fillmem $resources_dir_ctr/fillmem.c && \\ gcc -o $rootfs_dir_ctr/readmem $resources_dir_ctr/readmem.c\" firecracker/resources/tests/init.c 在调用/sbin/openrc-init之前, 向/dev/mem的特定地址(比如aarch64的0x40000000 1G)写入数字123 用于通知VMM kernel已经启动完毕 // Base address values are defined in arch/src/lib.rs as arch::MMIO_MEM_START. // Values are computed in arch/src//mod.rs from the architecture layouts. // Position on the bus is defined by MMIO_LEN increments, where MMIO_LEN is // defined as 0x1000 in vmm/src/device_manager/mmio.rs. #ifdef __x86_64__ #define MAGIC_MMIO_SIGNAL_GUEST_BOOT_COMPLETE 0xd0000000 #endif #ifdef __aarch64__ #define MAGIC_MMIO_SIGNAL_GUEST_BOOT_COMPLETE 0x40000000 #endif #define MAGIC_VALUE_SIGNAL_GUEST_BOOT_COMPLETE 123 int main () { int fd = open(\"/dev/mem\", (O_RDWR | O_SYNC | O_CLOEXEC)); int mapped_size = getpagesize(); char *map_base = mmap(NULL, mapped_size, PROT_WRITE, MAP_SHARED, fd, MAGIC_MMIO_SIGNAL_GUEST_BOOT_COMPLETE); *map_base = MAGIC_VALUE_SIGNAL_GUEST_BOOT_COMPLETE; msync(map_base, mapped_size, MS_ASYNC); const char *init = \"/sbin/openrc-init\"; char *const argv[] = { \"/sbin/init\", NULL }; char *const envp[] = { }; execve(init, argv, envp); } firecracker/resources/tests/fillmem.c Usage: ./fillmem mb_count先mmap再memset firecracker/resources/tests/readmem.c Usage: ./readmem mb_count value 做镜像 用ubuntu18.04 container的 truncate -s \"$SIZE\" \"$img_file\" mkfs.ext4 -F \"$img_file\" docker run -v \"$FC_ROOT_DIR:/firecracker\" ubuntu:18.04 bash -s 注: 使用'EOF'格式的heredoc, 其内部的变量不会展开 "},"notes/rust_cloud-hypervisor_代码.html":{"url":"notes/rust_cloud-hypervisor_代码.html","title":"cloud hypervisor代码","keywords":"","body":"cloud hypervisor是一种基于rust-vmm的VMM实现. 它和其他VMM的对比在这里 code walk in single picture 编译 build时可选的feature列表 REST API和CLI 先用cli创建一个empty的实例, 默认1vCPU, 512M内存. 随后用REST API来创建vm 然后boot这个实例 其他命令 cli和REST的关系 http路由 内部channel 代码梳理 main hypervisor的抽象 vm抽象基本上是基于kvm api的 vmops cli create vm代码流程 REST API流程实例 用户发REST API 这个VMM对应的http server响应请求 从http的raw data里(json格式)解析VmConfig vm_create使用内部channel向VMM的API发送请求 内部channel处理请求 处理这次的VmCreate 返回response impl Vmm x86_64和aarch64的mem layout vm_boot DeviceManager DeviceManager结构体 DeviceManager方法 DeviceNode包括id, 资源, 层级, pci信息 PCI segment PciBus PciDevice virtio设备 virtionet Net结构体 impl VirtioDevice for Net activate NetQueuePair 其他trait virtio block IO Bus和MMIO Bus Bus方法 中断 interrupt group 中断控制器 msi中断控制器 MsiInterruptGroup KVM_IRQFD code walk in single picture 编译 git clone https://github.com/cloud-hypervisor/cloud-hypervisor.git cd cloud-hypervisor/ # docker方式编译 -- 推荐 # 如果需要proxy, 在cmd_build函数docker run命令行加--env http_proxy=\"http://10.158.100.6:8080/\" scripts/dev_cli.sh build --release --libc musl # 产生的bin: build/cargo_target/x86_64-unknown-linux-musl/release/cloud-hypervisor # 本地方式编译, 完全静态链接版本要使用x86_64-unknown-linux-musl rustup target add x86_64-unknown-linux-musl # 完全静态版本一定要加--all, 还要安装musl-tools sudo apt install musl-tools cargo build --release --target=x86_64-unknown-linux-musl --all # 产生的bin: target/x86_64-unknown-linux-musl/release/cloud-hypervisor build时可选的feature列表 #[cfg(target_arch = \"x86_64\")] #[cfg(target_arch = \"aarch64\")] #[cfg(feature = \"guest_debug\")] #[cfg(feature = \"fwdebug\")] #[cfg(feature = \"tdx\")] #[cfg(feature = \"kvm\")] #[cfg(all(feature = \"mshv\", target_arch = \"x86_64\"))] #[cfg(feature = \"gdb\")] REST API和CLI cloud hypervisor以cli方式启动, 并启动http服务, 提供REST接口. 如果cli传入vmm的参数, 则http服务会根据后面的REST api来创建VM 先用cli创建一个empty的实例, 默认1vCPU, 512M内存. $ ./target/debug/cloud-hypervisor --api-socket /tmp/cloud-hypervisor.sock Cloud Hypervisor Guest API server: /tmp/cloud-hypervisor.sock vCPUs: 1 Memory: 512 MB Kernel: None Kernel cmdline: Disk(s): None 随后用REST API来创建vm curl --unix-socket /tmp/cloud-hypervisor.sock -i \\ -X PUT 'http://localhost/api/v1/vm.create' \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"cpus\":{\"boot_vcpus\": 4, \"max_vcpus\": 4}, \"kernel\":{\"path\":\"/opt/clh/kernel/vmlinux-virtio-fs-virtio-iommu\"}, \"cmdline\":{\"args\":\"console=ttyS0 console=hvc0 root=/dev/vda1 rw\"}, \"disks\":[{\"path\":\"/opt/clh/images/focal-server-cloudimg-amd64.raw\"}], \"rng\":{\"src\":\"/dev/urandom\"}, \"net\":[{\"ip\":\"192.168.10.10\", \"mask\":\"255.255.255.0\", \"mac\":\"12:34:56:78:90:01\"}] }' 所有的json选项可在vmm/src/config.rs的struct VmConfig里面查看. struct VmConfig用了rust的序列化框架serde, 把结构体直接映射成 然后boot这个实例 curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.boot' 其他命令 # dump vm的config curl --unix-socket /tmp/cloud-hypervisor.sock -i \\ -X GET 'http://localhost/api/v1/vm.info' \\ -H 'Accept: application/json' # reboot vm curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.reboot' # shut down curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.shutdown' cli和REST的关系 http路由 HTTP_ROUTES是个全局变量 lazy_static! { /// HTTP_ROUTES contain all the cloud-hypervisor HTTP routes. pub static ref HTTP_ROUTES: HttpRoutes = { let mut r = HttpRoutes { routes: HashMap::new(), }; r.routes.insert(endpoint!(\"/vm.add-device\"), Box::new(VmActionHandler::new(VmAction::AddDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-user-device\"), Box::new(VmActionHandler::new(VmAction::AddUserDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-disk\"), Box::new(VmActionHandler::new(VmAction::AddDisk(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-fs\"), Box::new(VmActionHandler::new(VmAction::AddFs(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-net\"), Box::new(VmActionHandler::new(VmAction::AddNet(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-pmem\"), Box::new(VmActionHandler::new(VmAction::AddPmem(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vdpa\"), Box::new(VmActionHandler::new(VmAction::AddVdpa(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vsock\"), Box::new(VmActionHandler::new(VmAction::AddVsock(Arc::default())))); r.routes.insert(endpoint!(\"/vm.boot\"), Box::new(VmActionHandler::new(VmAction::Boot))); r.routes.insert(endpoint!(\"/vm.counters\"), Box::new(VmActionHandler::new(VmAction::Counters))); r.routes.insert(endpoint!(\"/vm.create\"), Box::new(VmCreate {})); r.routes.insert(endpoint!(\"/vm.delete\"), Box::new(VmActionHandler::new(VmAction::Delete))); r.routes.insert(endpoint!(\"/vm.info\"), Box::new(VmInfo {})); r.routes.insert(endpoint!(\"/vm.pause\"), Box::new(VmActionHandler::new(VmAction::Pause))); r.routes.insert(endpoint!(\"/vm.power-button\"), Box::new(VmActionHandler::new(VmAction::PowerButton))); r.routes.insert(endpoint!(\"/vm.reboot\"), Box::new(VmActionHandler::new(VmAction::Reboot))); r.routes.insert(endpoint!(\"/vm.receive-migration\"), Box::new(VmActionHandler::new(VmAction::ReceiveMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.remove-device\"), Box::new(VmActionHandler::new(VmAction::RemoveDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize\"), Box::new(VmActionHandler::new(VmAction::Resize(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize-zone\"), Box::new(VmActionHandler::new(VmAction::ResizeZone(Arc::default())))); r.routes.insert(endpoint!(\"/vm.restore\"), Box::new(VmActionHandler::new(VmAction::Restore(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resume\"), Box::new(VmActionHandler::new(VmAction::Resume))); r.routes.insert(endpoint!(\"/vm.send-migration\"), Box::new(VmActionHandler::new(VmAction::SendMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.shutdown\"), Box::new(VmActionHandler::new(VmAction::Shutdown))); r.routes.insert(endpoint!(\"/vm.snapshot\"), Box::new(VmActionHandler::new(VmAction::Snapshot(Arc::default())))); r.routes.insert(endpoint!(\"/vmm.ping\"), Box::new(VmmPing {})); r.routes.insert(endpoint!(\"/vmm.shutdown\"), Box::new(VmmShutdown {})); r }; } 内部channel rust标准库的channel是mpsc, 创建channel: // 编译器会从下文推断出这个channel传输的是ApiRequest let (api_request_sender, api_request_receiver) = std::sync::mpsc::channel(); 这个ApiRequest是个enum, 所有的http请求都定义在这; 注意这里回复还是一个Sender, 里面是ApiResponse. 这个就是rust版本的channel in channel: 发出http请求的一方, 构造请求和一个专有的Sender句柄给服务方, 并等待在对应的Receiver; 服务方把ApiResponse响应写回到这个Sender里面; #[allow(clippy::large_enum_variant)] #[derive(Debug)] pub enum ApiRequest { /// Create the virtual machine. This request payload is a VM configuration /// (VmConfig). /// If the VMM API server could not create the VM, it will send a VmCreate /// error back. VmCreate(Arc>, Sender), /// Boot the previously created virtual machine. /// If the VM was not previously created, the VMM API server will send a /// VmBoot error back. VmBoot(Sender), /// Delete the previously created virtual machine. /// If the VM was not previously created, the VMM API server will send a /// VmDelete error back. /// If the VM is booted, we shut it down first. VmDelete(Sender), /// Request the VM information. VmInfo(Sender), /// Request the VMM API server status VmmPing(Sender), /// Pause a VM. VmPause(Sender), /// Resume a VM. VmResume(Sender), /// Get counters for a VM. VmCounters(Sender), /// Shut the previously booted virtual machine down. /// If the VM was not previously booted or created, the VMM API server /// will send a VmShutdown error back. VmShutdown(Sender), /// Reboot the previously booted virtual machine. /// If the VM was not previously booted or created, the VMM API server /// will send a VmReboot error back. VmReboot(Sender), /// Shut the VMM down. /// This will shutdown and delete the current VM, if any, and then exit the /// VMM process. VmmShutdown(Sender), /// Resize the VM. VmResize(Arc, Sender), /// Resize the memory zone. VmResizeZone(Arc, Sender), /// Add a device to the VM. VmAddDevice(Arc, Sender), /// Add a user device to the VM. VmAddUserDevice(Arc, Sender), /// Remove a device from the VM. VmRemoveDevice(Arc, Sender), /// Add a disk to the VM. VmAddDisk(Arc, Sender), /// Add a fs to the VM. VmAddFs(Arc, Sender), /// Add a pmem device to the VM. VmAddPmem(Arc, Sender), /// Add a network device to the VM. VmAddNet(Arc, Sender), /// Add a vDPA device to the VM. VmAddVdpa(Arc, Sender), /// Add a vsock device to the VM. VmAddVsock(Arc, Sender), /// Take a VM snapshot VmSnapshot(Arc, Sender), /// Restore from a VM snapshot VmRestore(Arc, Sender), /// Incoming migration VmReceiveMigration(Arc, Sender), /// Outgoing migration VmSendMigration(Arc, Sender), // Trigger power button VmPowerButton(Sender), } 代码梳理 main main函数在cloud-hypervisor/src/main.rs fn main() { // Ensure all created files (.e.g sockets) are only accessible by this user let _ = unsafe { libc::umask(0o077) }; //默认vCPU=1, 物理地址46bit; mem=512M; 使用/dev/urandom let (default_vcpus, default_memory, default_rng) = prepare_default_values(); //使用了流行的cli库clap, 瀑布式的定义args //get_matches就是parse()命令行 let cmd_arguments = create_app(&default_vcpus, &default_memory, &default_rng).get_matches(); let exit_code = match start_vmm(cmd_arguments); //支持kvm或mshv, 编译时选择 let hypervisor = hypervisor::new() let kvm_obj = Kvm::new() Ok(KvmHypervisor { kvm: kvm_obj }) let vmm_thread = vmm::start_vmm_thread( env!(\"CARGO_PKG_VERSION\").to_string(), &api_socket_path, api_socket_fd, api_evt.try_clone().unwrap(), http_sender, api_request_receiver, #[cfg(feature = \"gdb\")] gdb_socket_path, #[cfg(feature = \"gdb\")] debug_evt.try_clone().unwrap(), #[cfg(feature = \"gdb\")] vm_debug_evt.try_clone().unwrap(), &seccomp_action, hypervisor, //这个是上面的kvm实例化的hypervisor ) let thread = { //新建thread做主event处理循环 thread::Builder::new() .name(\"vmm\".to_string()) .spawn(move || { //新建vmm, 主要是注册event, 并没有开始真正干活 let mut vmm = Vmm::new( vmm_version.to_string(), api_event, vmm_seccomp_action, hypervisor, exit_evt, )?; //event循环 vmm.control_loop(Arc::new(api_receiver)) let epoll_fd = self.epoll.as_raw_fd(); //在loop里epoll wait, 并根据注册epoll add的token来分发 for event in events.iter().take(num_events) { let dispatch_event: EpollDispatch = event.data.into(); match dispatch_event { EpollDispatch::Unknown => {} EpollDispatch::Exit => {} EpollDispatch::Reset => {} EpollDispatch::ActivateVirtioDevices => {} EpollDispatch::Api => { //consume 触发内部channel的eventfd self.api_evt.read().map_err(Error::EventFdRead)?; //处理内部channel过来的请求并返回结果 let api_request = api_receiver.recv() match api_request { ApiRequest::VmCreate(config, sender) => {} ApiRequest::VmBoot(sender) => {} ... } } } } } }; // 起http线程, 用的是micro_http的库 api::start_http_path_thread() let server = HttpServer::new_from_fd() start_http_thread(server) hread::Builder::new() //新线程 loop { match server.requests() { Ok(request_vec) => { for server_request in request_vec { server.respond(server_request.process( |request| { handle_http_request(request, &api_notifier, &api_sender) } )) } } } } //带api前缀的都是发http请求到vmm.control_loop的. vmm::api::vm_create() vmm::api::vm_boot() //或者vmm::api::vm_restore() vmm_thread.join() std::process::exit(exit_code); } hypervisor的抽象 能在最顶层抽象一个hypervisor, 同时支持多种虚拟化技术. 用了抽象函数返回另一个抽象的模式, 即create_vm返回一个Vm trait object /// /// Trait to represent a Hypervisor /// /// This crate provides a hypervisor-agnostic interfaces /// pub trait Hypervisor: Send + Sync { /// /// Create a Vm using the underlying hypervisor /// Return a hypervisor-agnostic Vm trait object /// fn create_vm(&self) -> Result>; /// /// Create a Vm of a specific type using the underlying hypervisor /// Return a hypervisor-agnostic Vm trait object /// fn create_vm_with_type(&self, _vm_type: u64) -> Result> { unreachable!() } #[cfg(target_arch = \"x86_64\")] /// /// Get the supported CpuID /// fn get_cpuid(&self) -> Result; /// /// Check particular extensions if any /// fn check_required_extensions(&self) -> Result { Ok(()) } #[cfg(target_arch = \"x86_64\")] /// /// Retrieve the list of MSRs supported by the hypervisor. /// fn get_msr_list(&self) -> Result; #[cfg(target_arch = \"aarch64\")] /// /// Retrieve AArch64 host maximum IPA size supported by KVM. /// fn get_host_ipa_limit(&self) -> i32; /// /// Retrieve TDX capabilities /// #[cfg(feature = \"tdx\")] fn tdx_capabilities(&self) -> Result; } vm抽象基本上是基于kvm api的 /// /// Trait to represent a Vm /// /// This crate provides a hypervisor-agnostic interfaces for Vm /// pub trait Vm: Send + Sync { #[cfg(target_arch = \"x86_64\")] /// Sets the address of the one-page region in the VM's address space. fn set_identity_map_address(&self, address: u64) -> Result; #[cfg(target_arch = \"x86_64\")] /// Sets the address of the three-page region in the VM's address space. fn set_tss_address(&self, offset: usize) -> Result; /// Creates an in-kernel interrupt controller. fn create_irq_chip(&self) -> Result; /// Registers an event that will, when signaled, trigger the `gsi` IRQ. fn register_irqfd(&self, fd: &EventFd, gsi: u32) -> Result; /// Unregister an event that will, when signaled, trigger the `gsi` IRQ. fn unregister_irqfd(&self, fd: &EventFd, gsi: u32) -> Result; /// Creates a new KVM vCPU file descriptor and maps the memory corresponding fn create_vcpu(&self, id: u8, vm_ops: Option>) -> Result>; /// Registers an event to be signaled whenever a certain address is written to. fn register_ioevent( &self, fd: &EventFd, addr: &IoEventAddress, datamatch: Option, ) -> Result; /// Unregister an event from a certain address it has been previously registered to. fn unregister_ioevent(&self, fd: &EventFd, addr: &IoEventAddress) -> Result; // Construct a routing entry fn make_routing_entry(&self, gsi: u32, config: &InterruptSourceConfig) -> IrqRoutingEntry; /// Sets the GSI routing table entries, overwriting any previously set fn set_gsi_routing(&self, entries: &[IrqRoutingEntry]) -> Result; /// Creates a memory region structure that can be used with {create/remove}_user_memory_region fn make_user_memory_region( &self, slot: u32, guest_phys_addr: u64, memory_size: u64, userspace_addr: u64, readonly: bool, log_dirty_pages: bool, ) -> MemoryRegion; /// Creates a guest physical memory slot. fn create_user_memory_region(&self, user_memory_region: MemoryRegion) -> Result; /// Removes a guest physical memory slot. fn remove_user_memory_region(&self, user_memory_region: MemoryRegion) -> Result; /// Creates an emulated device in the kernel. fn create_device(&self, device: &mut CreateDevice) -> Result>; /// Returns the preferred CPU target type which can be emulated by KVM on underlying host. #[cfg(any(target_arch = \"arm\", target_arch = \"aarch64\"))] fn get_preferred_target(&self, kvi: &mut VcpuInit) -> Result; /// Enable split Irq capability #[cfg(target_arch = \"x86_64\")] fn enable_split_irq(&self) -> Result; #[cfg(target_arch = \"x86_64\")] fn enable_sgx_attribute(&self, file: File) -> Result; /// Retrieve guest clock. #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] fn get_clock(&self) -> Result; /// Set guest clock. #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] fn set_clock(&self, data: &ClockData) -> Result; #[cfg(feature = \"kvm\")] /// Checks if a particular `Cap` is available. fn check_extension(&self, c: Cap) -> bool; /// Create a device that is used for passthrough fn create_passthrough_device(&self) -> Result>; /// Get the Vm state. Return VM specific data fn state(&self) -> Result; /// Set the VM state fn set_state(&self, state: VmState) -> Result; /// Start logging dirty pages fn start_dirty_log(&self) -> Result; /// Stop logging dirty pages fn stop_dirty_log(&self) -> Result; /// Get dirty pages bitmap fn get_dirty_log(&self, slot: u32, base_gpa: u64, memory_size: u64) -> Result>; #[cfg(feature = \"tdx\")] /// Initalize TDX on this VM fn tdx_init(&self, cpuid: &CpuId, max_vcpus: u32) -> Result; #[cfg(feature = \"tdx\")] /// Finalize the configuration of TDX on this VM fn tdx_finalize(&self) -> Result; #[cfg(feature = \"tdx\")] /// Initalize a TDX memory region for this VM fn tdx_init_memory_region( &self, host_address: u64, guest_address: u64, size: u64, measure: bool, ) -> Result; } vmops vm的op主要针对gpa, guest physical address pub trait VmOps: Send + Sync { // 对guest dram来说的 fn guest_mem_write(&self, gpa: u64, buf: &[u8]) -> Result; fn guest_mem_read(&self, gpa: u64, buf: &mut [u8]) -> Result; // 对guest mmio来说的 fn mmio_read(&self, gpa: u64, data: &mut [u8]) -> Result; fn mmio_write(&self, gpa: u64, data: &[u8]) -> Result; // 对guest pio来说的 #[cfg(target_arch = \"x86_64\")] fn pio_read(&self, port: u64, data: &mut [u8]) -> Result; #[cfg(target_arch = \"x86_64\")] fn pio_write(&self, port: u64, data: &[u8]) -> Result; } cli create vm代码流程 命令行传入的kernel选项, 会被parse成vm config, 再创建vm let vm_params = config::VmParams::from_arg_matches(&cmd_arguments); let vm_config = config::VmConfig::parse(vm_params) // Create and boot the VM based off the VM config we just built. let sender = api_request_sender.clone(); vmm::api::vm_create( api_evt.try_clone().unwrap(), api_request_sender, Arc::new(Mutex::new(vm_config)), ) 这个vm_create就是给内部http服务发请求: pub fn vm_create( api_evt: EventFd, api_sender: Sender, config: Arc>, ) -> ApiResult { let (response_sender, response_receiver) = channel(); // Send the VM creation request. api_sender .send(ApiRequest::VmCreate(config, response_sender)) .map_err(ApiError::RequestSend)?; api_evt.write(1).map_err(ApiError::EventFdWrite)?; response_receiver.recv().map_err(ApiError::ResponseRecv)??; Ok(()) } REST API流程实例 用户发REST API A user or operator sends an HTTP request to the Cloud Hypervisor REST API in order to creates a virtual machine: #!/bin/bash curl --unix-socket /tmp/cloud-hypervisor.sock -i \\ -X PUT 'http://localhost/api/v1/vm.create' \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"cpus\":{\"boot_vcpus\": 4, \"max_vcpus\": 4}, \"kernel\":{\"path\":\"/opt/clh/kernel/vmlinux-virtio-fs-virtio-iommu\"}, \"cmdline\":{\"args\":\"console=ttyS0 console=hvc0 root=/dev/vda1 rw\"}, \"disks\":[{\"path\":\"/opt/clh/images/focal-server-cloudimg-amd64.raw\"}], \"rng\":{\"src\":\"/dev/urandom\"}, \"net\":[{\"ip\":\"192.168.10.10\", \"mask\":\"255.255.255.0\", \"mac\":\"12:34:56:78:90:01\"}] }' 这个VMM对应的http server响应请求 The Cloud Hypervisor HTTP thread processes the request and de-serializes the HTTP request JSON body into an internal VmConfig structure. micro_http响应这个请求, 调用提前注册好的EndpointHandler: // /api/v1/vm.create handler pub struct VmCreate {} impl EndpointHandler for VmCreate { fn handle_request( &self, req: &Request, api_notifier: EventFd, api_sender: Sender, ) -> Response { match req.method() { Method::Put => { match &req.body { Some(body) => { // Deserialize into a VmConfig let vm_config: VmConfig = match serde_json::from_slice(body.raw()) .map_err(HttpError::SerdeJsonDeserialize) { Ok(config) => config, Err(e) => return error_response(e, StatusCode::BadRequest), }; // Call vm_create() match vm_create(api_notifier, api_sender, Arc::new(Mutex::new(vm_config))) .map_err(HttpError::ApiError) { Ok(_) => Response::new(Version::Http11, StatusCode::NoContent), Err(e) => error_response(e, StatusCode::InternalServerError), } } None => Response::new(Version::Http11, StatusCode::BadRequest), } } _ => error_response(HttpError::BadRequest, StatusCode::BadRequest), } } } 从http的raw data里(json格式)解析VmConfig let vm_config: VmConfig = match serde_json::from_slice(body.raw()) vm_create使用内部channel向VMM的API发送请求 vm_create使用内部channel向VMM的API发送请求, 请求的内容是VmConfig, 并使用channel in channel来等待回复 VmCreate(Arc>, Sender) // 构造内部channel let (response_sender, response_receiver) = std::sync::mpsc::channel(); // Send the VM creation request. api_sender .send(ApiRequest::VmCreate(config, response_sender)) .map_err(ApiError::RequestSend)?; api_evt.write(1).map_err(ApiError::EventFdWrite)?; response_receiver.recv().map_err(ApiError::ResponseRecv)??; 内部channel处理请求 // Read from the API receiver channel let api_request = api_receiver.recv().map_err(Error::ApiRequestRecv)?; 处理这次的VmCreate The Cloud Hypervisor control loop matches the received internal API against the VmCreate payload, and extracts both the VmConfig structure and the Sender from the command payload. It stores the VmConfig structure and replies back to the sender ((The HTTP thread): match api_request { ApiRequest::VmCreate(config, sender) => { // We only store the passed VM config. // The VM will be created when being asked to boot it. let response = if self.vm_config.is_none() { self.vm_config = Some(config); Ok(ApiResponsePayload::Empty) } else { Err(ApiError::VmAlreadyCreated) }; sender.send(response).map_err(Error::ApiResponseSend)?; } 这里create vm并没有真正的create, 而只是保存vmconfig, 待到boot的时候再创建 返回response 可以看到, 用户的curl请求等到动作执行完毕后, 就会收到response impl Vmm 代码在cloud-hypervisor/vmm/src/lib.rsvm_create和vm_boot等真正执行在Vmm的方法里: impl Vmm { new() vm_create() vm_boot() } x86_64和aarch64的mem layout 和firecracker相比, cloudhypervisor重点在pci mmio. vm_boot 前面说过, vm_create只是保存vmconfig, 而vm_boot是真正创建并运行vm的地方 let vm = Vm::new( Arc::clone(vm_config), exit_evt, reset_evt, &self.seccomp_action, self.hypervisor.clone(), activate_evt, None, None, None, )?; //vm代码在cloud-hypervisor/vmm/src/vm.rs let vm = hypervisor.create_vm().unwrap(); //kvm ioctl KVM_CREATE_VM //return Arc::new(KvmVm {fd: vm_fd, state: VmState {}, ...} //下面3个事x86独有 vm.set_identity_map_address(KVM_IDENTITY_MAP_START.0) vm.set_tss_address(KVM_TSS_START.0 as usize) vm.enable_split_irq() //KVM_ENABLE_CAP let memory_manager = MemoryManager::new(vm.clone(), ...) //建立内存region Vec, 这个Vec的元素是(start, size, type) //比如一般内存分2G, [(0,2G,ram), (3G, 640M, SubRegion), (3G+640M, 大概200M, Reserved)] let arch_mem_regions = arch::arch_memory_regions(ram_size); //很复杂 ... let allocator = SystemAllocator::new( io_base:0 io_size: 64K platform_mmio_base: max_mem - 1M platform_mmio_size: 1M mmio_hole_base: 0xc000_0000 mmio_hole_size: 640M X86_64_IRQ_BASE: 5 irq_num: 24-5 ) //acpi在地址空间最后1M的platform mmio区域 acpi_address = allocator.lock().unwrap().allocate_platform_mmio_addresses(MEMORY_MANAGER_ACPI_SIZE) //从0开始到start_of_device_area的区域是ram let ram_allocator = AddressAllocator::new(GuestAddress(0), start_of_device_area.0) let mut memory_manager = MemoryManager { boot_guest_memory, guest_memory, next_memory_slot, start_of_device_area, end_of_device_area, end_of_ram_area, vm, hotplug_slots, selected_slot, mergeable: config.mergeable, allocator, hotplug_method: config.hotplug_method, boot_ram, current_ram, next_hotplug_slot, shared: config.shared, hugepages: config.hugepages, hugepage_size: config.hugepage_size, prefault: config.prefault, user_provided_zones, snapshot_memory_ranges: MemoryRangeTable::default(), memory_zones, guest_ram_mappings: Vec::new(), acpi_address, log_dirty: dynamic, // Cannot log dirty pages on a TD arch_mem_regions, ram_allocator, dynamic, }; memory_manager.allocate_address_space()?; for (zone_id, regions) in list { for (region, virtio_mem) in regions { //ioctl KVM_SET_USER_MEMORY_REGION //记录user memory region和slot的关系到Vec self.guest_ram_mappings.push(GuestRamMapping { gpa: region.start_addr().raw_value(), size: region.len(), slot, zone_id: zone_id.clone(), virtio_mem, file_offset, }); } } for 每个非ram的region self.ram_allocator .allocate(Some(region.start_addr()), region.len(), None) //内部使用BtreeMap来管理内存ranges, 把每个range insert到BtreeMap //应该都是针对guest 物理地址 self.ranges.insert(new_addr, size); let new_vm = Vm::new_from_memory_manager(memory_manager, vm, ...) //1. 起一个后台线程load kernel //支持load ELF 或 firmware, firmware load到4G地址 Self::load_kernel_async(&kernel, &memory_manager, &config)? linux_loader::loader::elf::Elf::load() linux_loader::loader::load_cmdline() //到CMDLINE_START地址 //或者强制load firmware到4G-size地址, 并手动添加映射 //2. create numa node //主要是从vm config里面提取config.memory_zones和config.distances信息填充到BTreeMap let numa_nodes = Self::create_numa_nodes() //3. 创建device manager, 见下面的详解 //cloud-hypervisor/vmm/src/device_manager.rs let device_manager = DeviceManager::new( vm.clone(), config.clone(), memory_manager.clone(), &exit_evt, &reset_evt, seccomp_action.clone(), numa_nodes.clone(), &activate_evt, force_iommu, restoring, boot_id_list, timestamp, ) /* 1. 新建device tree: HashMap 2. num_pci_segments默认为1, 可以配 3. 确定device区域(其实就是PCI设备区域), 见上面layout图 4. 新建address_manager { allocator: memory_manager.lock().unwrap().allocator(), io_bus: Arc::new(Bus::new()), mmio_bus: Arc::new(Bus::new()), vm: vm.clone(), device_tree: Arc::clone(&device_tree), pci_mmio_allocators, } 5. 新建msi_interrupt_manager, IOAPIC需要它, legacy_interrupt_manager需要IOAPIC gsi_msi_routes是个HashMap, 所有pci的device都共享这个gsi RoutingEntry对应kvm_irq_routing_entry 6. 分配acpi_address 7. 为pci预留legacy的中断slot: pci_irq_slots = [0; 32]; 8. 新建默认的pci_segment, id为0, 一个pci segment包括一个pci root桥, 一个PCI bus 9. 构建pci_segments Vec, 目前看包括id 0和id1的pci_segment 10. 用上面的材料构建device_manager结构体 11. 把device_manager insert到address_manager 12. 返回device_manager */ let memory = memory_manager.lock().unwrap().guest_memory(); //只有x86有io bus let io_bus = Arc::clone(device_manager.lock().unwrap().io_bus()); let mmio_bus = Arc::clone(device_manager.lock().unwrap().mmio_bus()); //只有x86有pci io let pci_config_io = device_manager.lock().unwrap().pci_config_io() as Arc>; //4. vm_ops let vm_ops: Arc = Arc::new(VmOpsHandler { memory, #[cfg(target_arch = \"x86_64\")] io_bus, mmio_bus, #[cfg(target_arch = \"x86_64\")] pci_config_io, }); //5. 创建cpu_manager 通过上面的device_manager memory_manager vm_ops来\"操作\"VM cpu::CpuManager::new() //6. 从文件准备initramfs //7. 构建vm结构体并返回 Ok(Vm { #[cfg(any(target_arch = \"aarch64\", feature = \"tdx\"))] kernel, initramfs, device_manager, config, on_tty, threads: Vec::with_capacity(1), signals: None, state: RwLock::new(VmState::Created), cpu_manager, memory_manager, vm, #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] saved_clock: None, numa_nodes, seccomp_action: seccomp_action.clone(), exit_evt, #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] hypervisor, stop_on_boot, #[cfg(target_arch = \"x86_64\")] load_kernel_handle, }) //根据vm config创建设备, 主要是pci的virtio设备, vfio设备等 new_vm.device_manager.create_devices(serial_pty, console_pty, console_resize_pipe) /* 1. 创建interrupt_controller 对x86来说是IOAPIC, 它的上游是self.msi_interrupt_manager 并把这个中断控制器添加到address_manager bus_devices 和device_tree 对aarch64来说是GIC, gic::Gic::new(), 上游也是self.msi_interrupt_manager 2. 创建legacy的interrupt_controller, 基于上面的interrupt_controller 3. add_legacy_devices() 4. add_acpi_devices() 5. add_console_device() 6. make_virtio_devices() let mut virtio_devices: Vec = Vec::new(); make_virtio_block_devices() make_virtio_net_devices() make_virtio_rng_devices() make_virtio_fs_devices() make_virtio_pmem_devices() make_virtio_vsock_devices() make_virtio_mem_devices() make_virtio_balloon_devices() make_virtio_watchdog_devices() make_vdpa_devices() 7. add_pci_devices(上面的virtio设备) 创建iommu_device: virtio_devices::Iommu::new() //对每个virtio设备 for handle in virtio_devices { add_virtio_pci_device() // 默认add到pci segment 0, 没有iommu, 没有dma 1. id为\"xxx_virtio-pci\" 2. 给这个pci device分配pci资源, bdf号等 (pci_segment_id, pci_device_bdf, resources) = self.pci_resources() 3. msi中断个数为queue个数+1 4. 创建virtio_pci_device //Constructs a new PCI transport for the given virtio device. virtio_pci_device = VirtioPciDevice::new( id, memory, virtio_device, msix_num, access_platform, &self.msi_interrupt_manager, pci_device_bdf.into(), self.activate_evt, use_64bit_bar, //除了virtio block都是64位. dma_handler ) 每个queue都配一个eventfd 创建queues, queue有两个泛型参数 根据virtio规范, pci_device_id是0x1040+device_type. 创建interrupt group, 即把下面的每个irq都绑定一个eventfd到irq 配置msix_config 配置class, 比如PciClassCode::NetworkController等 组成configuration space需要的信息: let configuration = PciConfiguration::new( VIRTIO_PCI_VENDOR_ID, pci_device_id, 0x1, // For modern virtio-PCI devices class, subclass, None, PciHeaderType::Device, VIRTIO_PCI_VENDOR_ID, pci_device_id, msix_config_clone, ); 组成virtio pci device let mut virtio_pci_device = VirtioPciDevice { id, configuration, common_config: VirtioPciCommonConfig { access_platform, driver_status: 0, config_generation: 0, device_feature_select: 0, driver_feature_select: 0, queue_select: 0, msix_config: Arc::new(AtomicU16::new(VIRTQ_MSI_NO_VECTOR)), msix_queues: Arc::new(Mutex::new(vec![VIRTQ_MSI_NO_VECTOR; num_queues])), }, msix_config, msix_num, device, device_activated: Arc::new(AtomicBool::new(false)), interrupt_status: Arc::new(AtomicUsize::new(0)), virtio_interrupt: None, queues, queue_evts, memory: Some(memory), settings_bar: 0, use_64bit_bar, interrupt_source_group, cap_pci_cfg_info: VirtioPciCfgCapInfo::default(), bar_regions: vec![], activate_evt, activate_barrier: Arc::new(Barrier::new(2)), dma_handler, }; //设置msix中断控制器 virtio_pci_device.virtio_interrupt = VirtioInterruptMsix::new() return 这个virtio_pci_device 5. add到pci, 返回bar地址信息 new_resources = self.add_pci_device(virtio_pci_device) 分配bar空间, 返回Vec.这是PciDevice本身的方法 pci_bus.add_device() //添加到hashmap 记录这个Bus_device到bus_devices pci_bus.register_mapping() //注册bar地址到device manager的MMIO Bus, 关联本BusDevice到这个bar地址 6. virtio设备的每个queue, 都有个\"通知\"地址 = bar地址base+NOTIFICATION_BAR_OFFSET+queue index*4, 每个通知地址都有一个eventfd self.address_manager.register_ioevent() 调用KVM的KVM_IOEVENTFD ioctl 7. 把本设备加入到device_tree } add_vfio_devices() add_user_devices() self.bus_devices .push(Arc::clone(&segment.pci_config_mmio) as Arc>); 8. done self.virtio_devices = virtio_devices */ vm.boot() //新建thread处理signal: SIGWINCH, SIGTERM, SIGINT self.setup_signal_handler() //stdin设为raw mode self.setup_tty() //load kernel let entry_point = self.entry_point() self.cpu_manager.create_boot_vcpus() for each vcpu kvm create vcpu self.cpu_manager.start_boot_vcpus() for each vcpu 创建新线程, 在里面loop: vcpu.run() VcpuExit::IoIn VcpuExit::IoOut VcpuExit::Shutdown VcpuExit::SystemEvent VcpuExit::MmioRead VcpuExit::MmioWrite VcpuExit::Hyperv DeviceManager DeviceManager结构体 pub struct DeviceManager { // Manage address space related to devices address_manager: Arc, // Console abstraction console: Arc, // console PTY console_pty: Option>>, // serial PTY serial_pty: Option>>, // Serial Manager serial_manager: Option>, // pty foreground status, console_resize_pipe: Option>, // Interrupt controller #[cfg(target_arch = \"x86_64\")] interrupt_controller: Option>>, #[cfg(target_arch = \"aarch64\")] interrupt_controller: Option>>, // Things to be added to the commandline (e.g. aarch64 early console) #[cfg(target_arch = \"aarch64\")] cmdline_additions: Vec, // ACPI GED notification device ged_notification_device: Option>>, // VM configuration config: Arc>, // Memory Manager memory_manager: Arc>, // The virtio devices on the system virtio_devices: Vec, // List of bus devices // Let the DeviceManager keep strong references to the BusDevice devices. // This allows the IO and MMIO buses to be provided with Weak references, // which prevents cyclic dependencies. bus_devices: Vec>>, // Counter to keep track of the consumed device IDs. device_id_cnt: Wrapping, pci_segments: Vec, #[cfg_attr(target_arch = \"aarch64\", allow(dead_code))] // MSI Interrupt Manager msi_interrupt_manager: Arc>, #[cfg_attr(feature = \"mshv\", allow(dead_code))] // Legacy Interrupt Manager legacy_interrupt_manager: Option>>, // Passthrough device handle passthrough_device: Option>, // VFIO container // Only one container can be created, therefore it is stored as part of the // DeviceManager to be reused. vfio_container: Option>, // Paravirtualized IOMMU iommu_device: Option>>, iommu_mapping: Option>, // PCI information about devices attached to the paravirtualized IOMMU // It contains the virtual IOMMU PCI BDF along with the list of PCI BDF // representing the devices attached to the virtual IOMMU. This is useful // information for filling the ACPI VIOT table. iommu_attached_devices: Option)>, // Tree of devices, representing the dependencies between devices. // Useful for introspection, snapshot and restore. device_tree: Arc>, // Exit event exit_evt: EventFd, reset_evt: EventFd, #[cfg(target_arch = \"aarch64\")] id_to_dev_info: HashMap, // seccomp action seccomp_action: SeccompAction, // List of guest NUMA nodes. numa_nodes: NumaNodes, // Possible handle to the virtio-balloon device balloon: Option>>, // Virtio Device activation EventFd to allow the VMM thread to trigger device // activation and thus start the threads from the VMM thread activate_evt: EventFd, acpi_address: GuestAddress, selected_segment: usize, // Possible handle to the virtio-mem device virtio_mem_devices: Vec>>, #[cfg(target_arch = \"aarch64\")] // GPIO device for AArch64 gpio_device: Option>>, #[cfg(target_arch = \"aarch64\")] // Flash device for UEFI on AArch64 uefi_flash: Option>, // Flag to force setting the iommu on virtio devices force_iommu: bool, // Helps identify if the VM is currently being restored restoring: bool, // io_uring availability if detected io_uring_supported: Option, // List of unique identifiers provided at boot through the configuration. boot_id_list: BTreeSet, // Start time of the VM timestamp: Instant, } DeviceManager方法 impl DeviceManager { new() serial_pty() console_pty() console_resize_pipe() create_devices() state() set_state() get_msi_iova_space() get_device_info() add_pci_devices() add_interrupt_controller() get_interrupt_controller() add_acpi_devices() add_legacy_devices() add_serial_device() modify_mode() set_raw_mode() add_virtio_console_device() add_console_device() make_virtio_devices() make_virtio_block_devices() make_virtio_net_devices() make_virtio_rng_devices() make_virtio_fs_devices() make_virtio_pmem_devices() make_virtio_vsock_devices() make_virtio_mem_devices() make_virtio_balloon_devices() make_virtio_watchdog_devices() make_vdpa_devices() next_device_name() add_passthrough_device() create_vfio_container() add_vfio_devices() add_vfio_user_device() add_pci_device() add_virtio_pci_device() pci_resources() io_bus() mmio_bus() allocator() //address_manager.allocator interrupt_controller() pci_config_io() pci_segments() console() cmdline_additions() update_memory() activate_virtio_devices() notify_hotplug() add_device() add_user_device() remove_device() eject_device() hotplug_virtio_pci_device() is_iommu_segment() add_disk() add_fs() add_pmem() add_net() add_vdpa() add_vsock() counters() resize_balloon() device_tree() restore_devices() notify_power_button() iommu_attached_devices() uefi_flash() validate_identifier() } DeviceNode包括id, 资源, 层级, pci信息 尤其是每个Device都是PCI的device #[derive(Clone, Serialize, Deserialize)] pub struct DeviceNode { pub id: String, pub resources: Vec, pub parent: Option, pub children: Vec, #[serde(skip)] pub migratable: Option>>, pub pci_bdf: Option, #[serde(skip)] pub pci_device_handle: Option, } PCI segment pub(crate) struct PciSegment { pub(crate) id: u16, pub(crate) pci_bus: Arc>, pub(crate) pci_config_mmio: Arc>, pub(crate) mmio_config_address: u64, #[cfg(target_arch = \"x86_64\")] pub(crate) pci_config_io: Option>>, // Bitmap of PCI devices to hotplug. pub(crate) pci_devices_up: u32, // Bitmap of PCI devices to hotunplug. pub(crate) pci_devices_down: u32, // List of allocated IRQs for each PCI slot. pub(crate) pci_irq_slots: [u8; 32], // Device memory covered by this segment pub(crate) start_of_device_area: u64, pub(crate) end_of_device_area: u64, pub(crate) allocator: Arc>, } pci的config空间是vmm的一个结构体: /// Contains the configuration space of a PCI node. /// See the [specification](https://en.wikipedia.org/wiki/PCI_configuration_space). /// The configuration space is accessed with DWORD reads and writes from the guest. pub struct PciConfiguration { registers: [u32; NUM_CONFIGURATION_REGISTERS], writable_bits: [u32; NUM_CONFIGURATION_REGISTERS], // writable bits for each register. bars: [PciBar; NUM_BAR_REGS], rom_bar_addr: u32, rom_bar_size: u32, rom_bar_used: bool, // Contains the byte offset and size of the last capability. last_capability: Option, msix_cap_reg_idx: Option, msix_config: Option>>, } new一个segment impl PciSegment { pub(crate) fn new() { 1. 新建一个pci root桥 默认是VENDOR_ID_INTEL(0x8086)和DEVICE_ID_INTEL_VIRT_PCIE_HOST(0xD57) PciClassCode::BridgeDevice &PciBridgeSubclass::HostBridge PciHeaderType::Device 2. 新建PCI bus, PCI bus用hashmap来管理pci 设备: HashMap>> 3. 新建pci_config_mmio, 一个就是一个PciBus实例 4. 把pci_config_mmio insert到address_manager的mmio_bus 5. 组装一个segment并返回 } } PciBus impl PciBus { new() register_mapping() add_device() remove_by_device() next_device_id() get_device_id() put_device_id() } PciDevice pub trait PciDevice: BusDevice { allocate_bars() free_bars() write_config_register() read_config_register() detect_bar_reprogramming() read_bar() write_bar() move_bar() as_any() id() } virtio设备 virtionet 代码cloud-hypervisor/virtio-devices/src/net.rs //主要是创建tap设备, 配置virtio net的属性 make_virtio_net_devices() 1. 生成id, 即xxx_net 2. 支持vhost user, 但一般还是virtio-net对接tap设备 virtio_devices::Net::new() tap设备有名就open有名的, 没名就默认叫vmtap%d tap设备可以配IP 这里为了模拟多queue, 使用了多个tap Self::new_with_tap() 设置feature标记各种offload, tso, 多队列 Ok(Net { common: VirtioCommon { device_type: VirtioDeviceType::Net as u32, avail_features, queue_sizes: vec![queue_size; queue_num], paused_sync: Some(Arc::new(Barrier::new((num_queues / 2) + 1))), min_queues: 2, ..Default::default() }, id, taps, config, ctrl_queue_epoll_thread: None, counters: NetCounters::default(), seccomp_action, rate_limiter_config, exit_evt, }) 3. 插入到设备树 self.device_tree.insert() 4. 返回MetaVirtioDevice Ok(MetaVirtioDevice { virtio_device, iommu: net_cfg.iommu, id, pci_segment: net_cfg.pci_segment, dma_handler: None, }) Net结构体 pub struct Net { common: VirtioCommon, id: String, taps: Vec, config: VirtioNetConfig, ctrl_queue_epoll_thread: Option>, counters: NetCounters, seccomp_action: SeccompAction, rate_limiter_config: Option, exit_evt: EventFd, } impl VirtioDevice for Net impl VirtioDevice for Net { device_type() queue_max_sizes() features() ack_features() read_config() activate() //这里应该是入口 reset() counters() set_access_platform() } activate 在vmm.control_loop的事件循环里, 会有EpollDispatch::ActivateVirtioDevices事件来触发virtio设备的使能: fn activate { 1. self.common.activate() 2. 创建NetCtrlEpollHandler, 起个线程\"_net1_ctrl\", 在里面epoll循环处理ctrl queue的事件 3. 每个q都创建NetEpollHandler, 起个线程\"_net1_qp%i\", 在epoll里循环处理data queue的事件 } data queue的事件: match ev_type { RX_QUEUE_EVENT: self.handle_rx_event() TX_QUEUE_EVENT: self.handle_tx_event() TX_TAP_EVENT: self.handle_tx_event() RX_TAP_EVENT: self.handle_rx_tap_event() 还有rate limit事件... } NetQueuePair cloud-hypervisor/net_util/src/queue_pair.rs 前面的事件, 最后都会落脚到 impl NetQueuePair { process_tx() self.tx.process_desc_chain() 基本上就是在循环里直接操作desc指向的buffer, 最后调用libc::writev把这些buffer写到tap的fd里面. 最后更新used index process_rx() self.rx.process_desc_chain 基本上是从desc链的信息中, 找到guest driver提前准备好的buffer, 组成iovecs, 用libc::readv函数读到这个iovecs里 } 其他trait Net还满足: Drop trait Pausable trait Snapshottable trait Transportable trait Migratable trait virtio block make_virtio_block_device() 1. 生成id, 一般是xxx_disk 2. 支持vhost user对接spdk 3. 打开块设备文件, 支持qcow2, vhd和raw, 返回一个trait object: Box 4. 传入上面的材料, 创建virtio block设备 virtio_devices::Block::new() 设置feature标记, FLUSH, CONFIG_WCE, BLK_SIZE, TOPOLOGY 计算disk参数, 比如block size, sector个数, writeback, 多队列等 返回Block设备 Ok(Block { common: VirtioCommon { device_type: VirtioDeviceType::Block as u32, avail_features, paused_sync: Some(Arc::new(Barrier::new(num_queues + 1))), queue_sizes: vec![queue_size; num_queues], min_queues: 1, ..Default::default() }, id, disk_image, disk_path, disk_nsectors, config, writeback: Arc::new(AtomicBool::new(true)), counters: BlockCounters::default(), seccomp_action, rate_limiter_config, exit_evt, }) 5. 插入到设备树 self.device_tree.insert() 6. 返回MetaVirtioDevice Ok(MetaVirtioDevice { virtio_device, iommu: net_cfg.iommu, id, pci_segment: net_cfg.pci_segment, dma_handler: None, }) IO Bus和MMIO Bus 顶层的device manager包括两个bus: io bus只有x86有io bus mmio busmmio bus是最常用的. io或者mmio的Bus抽象都是一个BtreeMap, 靠地址range来路由读写操作到底指向哪个具体的设备 pub struct Bus { devices: RwLock>>>, } Bus设备必须有offset读写的方法 pub trait BusDevice: Send { /// Reads at `offset` from this device fn read(&mut self, base: u64, offset: u64, data: &mut [u8]) {} /// Writes at `offset` into this device fn write(&mut self, base: u64, offset: u64, data: &[u8]) -> Option> { None } } 注: 对比firecracker的Bus定义, 和这里差不多: pub struct Bus { //bus下面是BtreeMap管理的device devices: BTreeMap>>, } Bus方法 一个BusDevice对应一个地址范围 impl Bus { new() //根据地址找上一个设备 resolve(&self, addr: u64) -> Option>)> //在指定地址范围插入设备 insert(&self, device: Arc>, base: u64, len: u64) //删除指定地址范围的设备 remove(&self, base: u64, len: u64) //读写 read(&self, addr: u64, data: &mut [u8]) write(&self, addr: u64, data: &[u8]) } 中断 和硬件的irq稍有区别, virt irq在这里被叫做Interrupt Source A device may support multiple types of interrupts, and each type of interrupt may support one or multiple interrupt sources. For example, a PCI device may support: Legacy Irq: exactly one interrupt source. PCI MSI Irq: 1,2,4,8,16,32 interrupt sources. PCI MSIx Irq: 2^n(n=0-11) interrupt sources. 一个设备可以有多个中断源, 比如MSI可以有32个源, MSIx可以有4096个源. A distinct Interrupt Source Identifier (ISID) will be assigned to each interrupt source. An ID allocator will be used to allocate and free Interrupt Source Identifiers for devices. To decouple the vm-device crate from the ID allocator, the vm-device crate doesn't take the responsibility to allocate/free Interrupt Source IDs but only makes use of assigned IDs. 每个中断源都被分配一个ID, 即ISID. vm-device只负责使用这些ID The overall flow to deal with interrupts is: The VMM creates an interrupt manager The VMM creates a device manager, passing on an reference to the interrupt manager The device manager passes on an reference to the interrupt manager to all registered devices The guest kernel loads drivers for virtual devices The guest device driver determines the type and number of interrupts needed, and update the device configuration The virtual device backend requests the interrupt manager to create an interrupt group according to guest configuration information 中断并不是在一开始就固定分配好的, 而是需要guest kernel驱动来触发. VMM创建好中断管理器后, 由设备管理器把中断控制器的引用传递给每个具体的设备; guest kernel驱动在初始化虚拟设备的时候, 决定自己的中断类型, 比如MSI, 和中断个数; 对应虚拟设备的backend根据guest驱动提供的信息, 向中断管理器请求创建一个中断group. interrupt group InterruptManager只有两个API, create_group()和destroy_group(), 用于新建/销毁 InterruptSourceGroup /// Trait to manage interrupt sources for virtual device backends. /// /// The InterruptManager implementations should protect itself from concurrent accesses internally, /// so it could be invoked from multi-threaded context. pub trait InterruptManager: Send + Sync { type GroupConfig; /// Create an [InterruptSourceGroup](trait.InterruptSourceGroup.html) object to manage /// interrupt sources for a virtual device /// /// An [InterruptSourceGroup](trait.InterruptSourceGroup.html) object manages all interrupt /// sources of the same type for a virtual device. /// /// # Arguments /// * interrupt_type: type of interrupt source. /// * base: base Interrupt Source ID to be managed by the group object. /// * count: number of Interrupt Sources to be managed by the group object. fn create_group(&self, config: Self::GroupConfig) -> Result>; /// Destroy an [InterruptSourceGroup](trait.InterruptSourceGroup.html) object created by /// [create_group()](trait.InterruptManager.html#tymethod.create_group). /// /// Assume the caller takes the responsibility to disable all interrupt sources of the group /// before calling destroy_group(). This assumption helps to simplify InterruptSourceGroup /// implementations. fn destroy_group(&self, group: Arc) -> Result; } InterruptSourceGroup负责具体中断的维护: 使能/禁止/向guest注入中断/更新中断配置 pub trait InterruptSourceGroup: Send + Sync { /// Enable the interrupt sources in the group to generate interrupts. fn enable(&self) -> Result { // Not all interrupt sources can be enabled. // To accommodate this, we can have a no-op here. Ok(()) } /// Disable the interrupt sources in the group to generate interrupts. fn disable(&self) -> Result { // Not all interrupt sources can be disabled. // To accommodate this, we can have a no-op here. Ok(()) } /// Inject an interrupt from this interrupt source into the guest. fn trigger(&self, index: InterruptIndex) -> Result; /// Returns an interrupt notifier from this interrupt. /// /// An interrupt notifier allows for external components and processes /// to inject interrupts into a guest, by writing to the file returned /// by this method. #[allow(unused_variables)] fn notifier(&self, index: InterruptIndex) -> Option; /// Update the interrupt source group configuration. /// /// # Arguments /// * index: sub-index into the group. /// * config: configuration data for the interrupt source. /// * masked: if the interrupt is masked fn update( &self, index: InterruptIndex, config: InterruptSourceConfig, masked: bool, ) -> Result; } 中断控制器 分为两大类, msi和legacy msi中断控制器 pub struct MsiInterruptManager { allocator: Arc>, vm: Arc, gsi_msi_routes: Arc>>, } MsiInterruptManager实现了InterruptManager trait: impl InterruptManager for MsiInterruptManager { type GroupConfig = MsiIrqGroupConfig; fn create_group(&self, config: Self::GroupConfig) -> Result> { let mut allocator = self.allocator.lock().unwrap(); //把这次group里的所有中断插入到irq_routes, 以hashmap形式索引, key是u32 //每个中断源对应一个eventfd和一个gsi号组成的InterruptRoute let mut irq_routes: HashMap = HashMap::with_capacity(config.count as usize); for i in config.base..config.base + config.count { irq_routes.insert(i, InterruptRoute::new(&mut allocator)?); } Ok(Arc::new(MsiInterruptGroup::new( self.vm.clone(), self.gsi_msi_routes.clone(), irq_routes, ))) } fn destroy_group(&self, _group: Arc) -> Result { Ok(()) } } MsiInterruptGroup impl InterruptSourceGroup for MsiInterruptGroup { //对这个group下面的每个中断源 fn enable(&self) -> Result { for (_, route) in self.irq_routes.iter() { route.enable(&self.vm)?; //调用kvm的ioctl KVM_IRQFD注册eventfd, 绑定到对应的gsi. 写这个eventfd会触发kvm注入中断到irqchip的gsi pin vm.register_irqfd(&self.irq_fd, self.gsi) } } disable() //取消注册 trigger() //就是写对应的eventfd notifier() //返回eventfd的clone } KVM_IRQFD Allows setting an eventfd to directly trigger a guest interrupt. kvm_irqfd.fd specifies the file descriptor to use as the eventfd and kvm_irqfd.gsi specifies the irqchip pin toggled by this event. When an event is triggered on the eventfd, an interrupt is injected into the guest using the specified gsi pin kvm的ioctl KVM_IRQFD注册eventfd, 绑定到对应的gsi. 写这个eventfd会触发kvm注入中断到irqchip的gsi pin "},"notes/rust_cloud-hypervisor_使用.html":{"url":"notes/rust_cloud-hypervisor_使用.html","title":"cloud hypervisor使用","keywords":"","body":" 命令记录 命令行启动 ch-remote启动 启动 可选参数 rest API ping dump vm info reboot shutdown 其他 guest kernel启动打印 gdb调试 rust-gdb 测试场景: vm内virtio-net网口ping对应的tap口 gdb观察 ping是否会触发VM exit -- 否 vmm后端怎么工作 写文件是否会触发VM exit -- 否 lspci是否会触发VM exit -- 是 最小化启动 参考集成 release过程 命令记录 命令行启动 bin/cloud-hypervisor --seccomp false --api-socket clh.sock --cpus boot=2 --memory size=2048M,shared=on --kernel kernel/vmlinux.bin --initramfs rootfs/boot/rootfs.cpio.gz --cmdline \"console=hvc0 config_overlay=linux_shell_only=1 init=/init\" ch-remote启动 # 先启动主程序, 主程序等待命令 bin/cloud-hypervisor --seccomp false --api-socket clh.sock # create bin/ch-remote --api-socket clh.sock create 启动 # virt-customize需要这个 apt install libguestfs-tools # 默认ubuntu的cloud image是没有默认用户的, 也没有root密码 # 用下面的命令配置一个 sudo virt-customize -a focal-server-cloudimg-amd64.img --root-password password:ubuntu wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw wget https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/download/0.4.0/hypervisor-fw 启动示例: $ sudo setcap cap_net_admin+ep ./cloud-hypervisor/target/release/cloud-hypervisor # 如果有权限问题, 把/dev/kvm的other设为读写 # 或者加入kvm组 sudo chmod o+rw /dev/kvm $ ./cloud-hypervisor/target/release/cloud-hypervisor \\ --kernel ./hypervisor-fw \\ --disk path=focal-server-cloudimg-amd64.raw \\ --cpus boot=4 \\ --memory size=1024M \\ --net \"tap=,mac=,ip=,mask=\" 可选参数 cloud-hypervisor -h --api-socket /path/to/uds --kernel --cmdline --console --cpus --device --disk --event-monitor --fs --initramfs --log-file --memory --memory-zone --net --numa --platform --pmem --restore --rng --seccomp --serial --vsock --watchdog rest API ping curl --unix-socket /tmp/clh.sock -i -X GET 'http://localhost/api/v1/vmm.ping' dump vm info 假设使用--api-socket /tmp/clh.sock启动clh curl --unix-socket /tmp/clh.sock -i -X GET 'http://localhost/api/v1/vm.info' -H 'Accept: application/json' | tail -1 | jq . 列表如下: { \"config\": { \"cpus\": { \"boot_vcpus\": 1, \"max_vcpus\": 1, \"topology\": null, \"kvm_hyperv\": false, \"max_phys_bits\": 46, \"affinity\": null, \"features\": {} }, \"memory\": { \"size\": 1073741824, \"mergeable\": false, \"hotplug_method\": \"Acpi\", \"hotplug_size\": null, \"hotplugged_size\": null, \"shared\": false, \"hugepages\": false, \"hugepage_size\": null, \"prefault\": false, \"zones\": null }, \"kernel\": { \"path\": \"./hypervisor-fw\" }, \"initramfs\": null, \"cmdline\": { \"args\": \"\" }, \"disks\": [ { \"path\": \"focal-server-cloudimg-amd64.raw\", \"readonly\": false, \"direct\": false, \"iommu\": false, \"num_queues\": 1, \"queue_size\": 128, \"vhost_user\": false, \"vhost_socket\": null, \"poll_queue\": true, \"rate_limiter_config\": null, \"id\": \"_disk0\", \"disable_io_uring\": false, \"pci_segment\": 0 } \"net\": [ { \"tap\": null, \"ip\": \"192.168.249.1\", \"mask\": \"255.255.255.0\", \"mac\": \"2e:cc:5f:b8:cd:dc\", \"host_mac\": \"82:22:4f:c3:21:da\", \"iommu\": false, \"num_queues\": 2, \"queue_size\": 256, \"vhost_user\": false, \"vhost_socket\": null, \"vhost_mode\": \"Client\", \"id\": \"_net1\", \"fds\": null, \"rate_limiter_config\": null, \"pci_segment\": 0 } ], \"rng\": { \"src\": \"/dev/urandom\", \"iommu\": false }, \"balloon\": null, \"fs\": null, \"pmem\": null, \"serial\": { \"file\": null, \"mode\": \"Null\", \"iommu\": false }, \"console\": { \"file\": null, \"mode\": \"Tty\", \"iommu\": false }, \"devices\": null, \"user_devices\": null, \"vdpa\": null, \"vsock\": null, \"iommu\": false, \"sgx_epc\": null, \"numa\": null, \"watchdog\": false, \"platform\": null }, \"state\": \"Running\", \"memory_actual_size\": 1073741824, \"device_tree\": { \"__rng\": { \"id\": \"__rng\", \"resources\": [], \"parent\": \"_virtio-pci-__rng\", \"children\": [], \"pci_bdf\": null }, \"_disk0\": { \"id\": \"_disk0\", \"resources\": [], \"parent\": \"_virtio-pci-_disk0\", \"children\": [], \"pci_bdf\": null }, \"_net1\": { \"id\": \"_net1\", \"resources\": [], \"parent\": \"_virtio-pci-_net1\", \"children\": [], \"pci_bdf\": null }, \"_virtio-pci-__console\": { \"id\": \"_virtio-pci-__console\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 70364448686080, \"size\": 524288, \"type_\": \"Mmio64\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"__console\" ], \"pci_bdf\": \"0000:00:01.0\" }, \"__serial\": { \"id\": \"__serial\", \"resources\": [], \"parent\": null, \"children\": [], \"pci_bdf\": null }, \"_virtio-pci-_disk0\": { \"id\": \"_virtio-pci-_disk0\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 3891789824, \"size\": 524288, \"type_\": \"Mmio32\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"_disk0\" ], \"pci_bdf\": \"0000:00:02.0\" }, \"_virtio-pci-_net1\": { \"id\": \"_virtio-pci-_net1\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 70364448161792, \"size\": 524288, \"type_\": \"Mmio64\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"_net1\" ], \"pci_bdf\": \"0000:00:03.0\" }, \"__console\": { \"id\": \"__console\", \"resources\": [], \"parent\": \"_virtio-pci-__console\", \"children\": [], \"pci_bdf\": null }, \"__ioapic\": { \"id\": \"__ioapic\", \"resources\": [], \"parent\": null, \"children\": [], \"pci_bdf\": null }, \"_virtio-pci-__rng\": { \"id\": \"_virtio-pci-__rng\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 70364447637504, \"size\": 524288, \"type_\": \"Mmio64\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"__rng\" ], \"pci_bdf\": \"0000:00:04.0\" } } } reboot shutdown curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.reboot' curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.shutdown' 其他 比如暂停, 恢复, add net, add disk, remove device, dump counters等等都支持. 例如: curl --unix-socket /tmp/clh.sock -i -X GET 'http://localhost/api/v1/vm.counters' guest kernel启动打印 以ubuntu的云镜像为例: Command line: BOOT_IMAGE=/boot/vmlinuz-5.4.0-113-generic root=LABEL=cloudimg-rootfs ro console=tty1 console=ttyS0 BIOS-provided physical RAM map efi: EFI v2.80 by Hypervisor detected: KVM clocksource: kvm-clock tsc: Detected 2394.454 MHz processor Zone ranges: DMA [mem 0x0000000000001000-0x0000000000ffffff] DMA32 [mem 0x0000000001000000-0x000000003fffffff] Normal empty Device empty Early memory node ranges node 0: [mem 0x0000000000001000-0x000000000009ffff] node 0: [mem 0x000000000013f000-0x000000003fffffff] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffffff] On node 0 totalpages: 261984 //1G Booting paravirtualized kernel on KVM //guest kernel知道自己是在KVM上启动的 NR_IRQS: 524544, nr_irqs: 256, preallocated irqs: 0 printk: console [tty1] enabled printk: console [ttyS0] enabled LSM: Security Framework initializing Yama: becoming mindful. AppArmor: AppArmor initialized PCI host bridge to bus 0000:00 pci_bus 0000:00: root bus resource [mem 0xe8000000-0xe80fffff] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xe7ffffff window] pci_bus 0000:00: root bus resource [mem 0x100000000-0x3ffeffffffff window] pci_bus 0000:00: root bus resource [io 0x0000-0x0cf7 window] pci_bus 0000:00: root bus resource [io 0x0d00-0xffff window] pci_bus 0000:00: root bus resource [bus 00] pci 0000:00:00.0: [8086:0d57] type 00 class 0x060000 //INTEL pci 0000:00:01.0: [1af4:1043] type 00 class 0xffff00 //virtio pci 0000:00:01.0: reg 0x10: [mem 0x3ffefff80000-0x3ffeffffffff 64bit] //资源已经分配好 pci 0000:00:02.0: [1af4:1042] type 00 class 0x018000 pci 0000:00:02.0: reg 0x10: [mem 0xe7f80000-0xe7ffffff] pci 0000:00:03.0: [1af4:1041] type 00 class 0x020000 pci 0000:00:03.0: reg 0x10: [mem 0x3ffefff00000-0x3ffefff7ffff 64bit] pci 0000:00:04.0: [1af4:1044] type 00 class 0xffff00 pci 0000:00:04.0: reg 0x10: [mem 0x3ffeffe80000-0x3ffeffefffff 64bit] pci_bus 0000:00: on NUMA node 0 iommu: Default domain type: Translated PCI: Using ACPI for IRQ routing PCI: pci_cache_line_size set to 64 bytes tcpip协议栈初始化 virtio-pci 0000:00:01.0: enabling device (0000 -> 0002) virtio-pci 0000:00:02.0: enabling device (0000 -> 0002) virtio-pci 0000:00:03.0: enabling device (0000 -> 0002) virtio-pci 0000:00:04.0: enabling device (0000 -> 0002) Serial: 8250/16550 driver, 32 ports, IRQ sharing enabled loop, tun, vfio, usb, i2c驱动初始化 systemd开始工作 一堆的audit打印... gdb调试 用上面的命令启动hypervisor后, 用gdb调试: gdb cloud-hypervisor -p 18294 Reading symbols from cloud-hypervisor...done (gdb) b mmio_read Breakpoint 1 at 0x7f766eb1d1ee: file vmm/src/vm.rs, line 384. (gdb) b mmio_write Breakpoint 2 at 0x7f766eb1d3a1: file vmm/src/vm.rs, line 391. (gdb) info b Num Type Disp Enb Address What 1 breakpoint keep y 0x00007f766eb1d1ee in ::mmio_read at vmm/src/vm.rs:384 2 breakpoint keep y 0x00007f766eb1d3a1 in ::mmio_write at vmm/src/vm.rs:391 (gdb) b src/kvm/mod.rs:1145 Breakpoint 4 at 0x7f766f2759d7: file hypervisor/src/kvm/mod.rs, line 1145. //只对thread 4打断点 (gdb) b kvm_ioctls::ioctls::vcpu::VcpuFd::run thread 4 rust-gdb 参考https://bitshifter.github.io/rr+rust/index.html#1 需要在root用户下安装rust. 我从普通用户拷贝~/.cargo和~/.rustp好像也能用. # su root ~/.cargo/bin/rust-gdb -p 19507 b kvm_ioctls::ioctls::vcpu::VcpuFd::run 测试场景: vm内virtio-net网口ping对应的tap口 启动hypervisor后, VM内有virtio-net网口: root@ubuntu:~# ethtool -i ens3 driver: virtio_net version: 1.0.0 bus-info: 0000:00:03.0 查看pci拓扑: 注: lspci执行过程中, 会频繁的触发vm exit, 断点表面是VM在做VcpuExit::IoOut root@ubuntu:~# lspci 00:00.0 Host bridge: Intel Corporation Device 0d57 00:01.0 Unassigned class [ffff]: Red Hat, Inc. Virtio console (rev 01) 00:02.0 Mass storage controller: Red Hat, Inc. Virtio block device (rev 01) 00:03.0 Ethernet controller: Red Hat, Inc. Virtio network device (rev 01) 00:04.0 Unassigned class [ffff]: Red Hat, Inc. Virtio RNG (rev 01) 同时, hypervisor会在host上创建一个网口vmtap0, 并配置IP192.168.249.1/24 默认vm的ens3是down的, 下面配置其为up, ip为192.168.249.2 ip link set up dev ens3 ip addr add 192.168.249.2/24 dev ens3 此时可以ping通vmtap0: ping 192.168.249.1 gdb观察 设断点: # su root ~/.cargo/bin/rust-gdb -p 19507 b kvm_ioctls::ioctls::vcpu::VcpuFd::run 这里的kvm_ioctls::ioctls::vcpu::VcpuFd::run是下面代码:是KVM_RUN的循环主体. ping是否会触发VM exit -- 否 一直ping, 同时做gdb观察 gdb设置上面的断点后, continue执行, 除了第一次continue后会触发断点, 后面不管怎么ping, 都没有触发断点. 说明: virtio-net在ping的过程中, VM并没有exit, VM一直\"全速\"运行 因为VM没有exit, 也就没有mmio_read, mmio_write等触发VMM后端的动作; 就是说guest driver在收发报文的时候, 对vring的操作, 对bar寄存器的操作, 统统没有触发mmio exit. vmm后端怎么工作 前面看到, ping的过程中没有观察到VM exit, 那VMM后端如何响应guest driver的读写寄存器请求的呢? 会不会在其他代码路径下面调用了寄存器访问的函数呢? 先看看有没有人调用mmio_write和mmio_read (gdb) b mmio_read (gdb) b mmio_write 注: 用b vmm::vm::VmOpsHandler::mmio_read是不认的. 用这样的语法gdb可以认: (gdb) b ::mmio_read 继续在VM里ping, 没有触发断点. 再增加 (gdb) b vm_device::bus::Bus::read (gdb) b vm_device::bus::Bus::write 依旧没触发. 看看有没有认调用VirtioPciDevice的read: b ::read b ::write 还是没有触发 继续看pci的读写bar操作: b ::read_bar b ::write_bar 还是没有触发 至此, VM exit路径没有触发virtio-net后端的动作. 所以, 到这里很清楚了, virtio-net设备在工作的时候, 完全不需要在VM exit和VM enter之间进行切换. guest driver和vmm device在virtio ring的协议下, 通过ioeventfd和irqfd来互相\"通知\", 在VM不exit的情况下, 完成报文的交互. 见cloud-hypervisor/net_util/src/queue_pair.rs的process_tx()和process_rx()函数. 再次确认, pci::device::PciDevice::read_bar/write_bar并没有在virtio-net报文交换的过程中被调用. 写文件是否会触发VM exit -- 否 echo abc > abc.txt sync //执行的很快 dd if=/dev/zero of=out.dd bs=1M count=4 4194304 bytes (4.2 MB, 4.0 MiB) copied, 0.0129554 s, 324 MB/s lspci是否会触发VM exit -- 是 在vm里面执行lspci, 可以看到断点被触发: (gdb) bt #0 kvm_ioctls::ioctls::vcpu::VcpuFd::run #1 0x00007fee2b19b9c5 in ::run #2 0x00007fee2aca1b45 in vmm::cpu::Vcpu::run #3 0x00007fee2ac7f5cb in vmm::cpu::CpuManager::start_vcpu::{{closure}}::{{closure}} () #4 0x00007fee2acd51bb in std::panicking::try::do_call #5 0x00007fee2acd5c5b in __rust_try #6 0x00007fee2acd46e1 in std::panicking::try #7 0x00007fee2ab64211 in std::panic::catch_unwind #8 0x00007fee2ac7eaf4 in vmm::cpu::CpuManager::start_vcpu::{{closure}} #9 0x00007fee2aa607c3 in std::sys_common::backtrace::__rust_begin_short_backtrace #10 0x00007fee2a9cbde0 in std::thread::Builder::spawn_unchecked_::{{closure}}::{{closure}} #11 0x00007fee2acdc7c4 in #12 0x00007fee2acd50a2 in std::panicking::try::do_call #13 0x00007fee2acd5c5b in __rust_try #14 0x00007fee2acd44e7 in std::panicking::try #15 0x00007fee2ab64254 in std::panic::catch_unwind #16 0x00007fee2a9cafb3 in std::thread::Builder::spawn_unchecked_::{{closure}} #17 0x00007fee2a82f74f in core::ops::function::FnOnce::call_once{{vtable-shim}} #18 0x00007fee2b423ff3 in as core::ops::function::FnOnce>::call_once #19 as core::ops::function::FnOnce>::call_once #20 std::sys::unix::thread::Thread::new::thread_start #21 0x00007fee2b44c2e5 in start #22 0x00007fee2b44d3d9 in __clone (gdb) n (gdb) n (gdb) finish (gdb) n 1147 VcpuExit::IoIn(addr, data) => { 最后跟下来vm在做VcpuExit::IoIn和VcpuExit::IoOut, vmm调用对应的pio_read和pio_write来响应. 注: lspci没有触发mmio相关的调用, 只有pio. 最小化启动 https://bl.ocks.org/gdamjan/1f260b58eb9fb1ba62d2234958582405 https://alpinelinux.org/downloads/ 参考集成 见: cloud-hypervisor/scripts/run_integration_tests_x86_64.sh release过程 jobs: steps: - name: Code checkout uses: actions/checkout@v2 - name: Install musl-gcc run: sudo apt install -y musl-tools //需要musl-tools - name: Install Rust toolchain (x86_64-unknown-linux-gnu) //gnu target是动态链接 uses: actions-rs/toolchain@v1 with: toolchain: \"1.60\" target: x86_64-unknown-linux-gnu - name: Install Rust toolchain (x86_64-unknown-linux-musl) //musl target是静态链接 uses: actions-rs/toolchain@v1 with: toolchain: \"1.60\" target: x86_64-unknown-linux-musl - name: Build uses: actions-rs/cargo@v1 with: toolchain: \"1.60\" command: build args: --all --release --target=x86_64-unknown-linux-gnu - name: Static Build uses: actions-rs/cargo@v1 with: toolchain: \"1.60\" command: build args: --all --release --target=x86_64-unknown-linux-musl - name: Strip cloud-hypervisor binaries run: strip target/*/release/cloud-hypervisor //strip - name: Install Rust toolchain (aarch64-unknown-linux-musl) //aarch64 musl uses: actions-rs/toolchain@v1 with: toolchain: \"1.60\" target: aarch64-unknown-linux-musl override: true - name: Static Build (AArch64) uses: actions-rs/cargo@v1 with: use-cross: true command: build args: --all --release --target=aarch64-unknown-linux-musl - name: Upload static cloud-hypervisor //上传asset id: upload-release-static-cloud-hypervisor uses: actions/upload-release-asset@v1 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: upload_url: ${{ steps.create_release.outputs.upload_url }} asset_path: target/x86_64-unknown-linux-musl/release/cloud-hypervisor asset_name: cloud-hypervisor-static asset_content_type: application/octet-stream "},"notes/rust_cloud-hypervisor_问题与解决.html":{"url":"notes/rust_cloud-hypervisor_问题与解决.html","title":"cloud hypervisor问题与解决","keywords":"","body":" cloud hypervisor无法启动 会是什么原因 检查kvm是否nested enable nested KVM 不是nested没开 升级kernel 编译virtiofsd target是musl也不总是完全的静态链接 如何静态链接virtiofsd cloud hypervisor无法启动 直接启动会报错:看提示已经能够显示出错的具体代码位置了. 加上RUST_BACKTRACE=1会更具体: 又提示RUST_BACKTRACE=full会更详细: 可以看到: rust的调用层级很多, 和go有的一拼 RUST_BACKTRACE=1会过滤掉最近的0到12层调用栈, 这些都是rust_begin_unwind的内部流程, 一般用户不需要关心 真正出问题的是vmm::vm::Vm::new, 即RUST_BACKTRACE=full时的第16层调用栈, 很奇怪的是在调用栈里没提示是哪一行. 但调用栈打印之前就有打印提示出错文件和行号:vmm/src/vm.rs:729:48 unwrap出错会直接panic 用环境变量RUST_BACKTRACE=这招和go很像GOTRACEBACK= 会是什么原因 突然想到这个机器本来就是kvm的虚拟机, 是否是kvm嵌套没打开呢? 参考:https://docs.fedoraproject.org/en-US/quick-docs/using-nested-virtualization-in-kvm/ 检查kvm是否nested cat /sys/module/kvm_intel/parameters/nested 果然这个机器显示N enable nested KVM To enable nested virtualization for Intel processors: Shut down all running VMs and unload the kvm_probe module:sudo modprobe -r kvm_intel Activate the nesting feature:sudo modprobe kvm_intel nested=1 Nested virtualization is enabled until the host is rebooted. To enable it permanently, add the following line to the /etc/modprobe.d/kvm.conf file:options kvm_intel nested=1 AMD的CPU把上面的kvm_intel改成kvm_amd 不是nested没开 按照上面的方法, 重新加载kvm_intel并使能nested=1, 也成功了. 但问题依旧.那估计就是kernel版本太低了:Linux spine.novalocal 3.10.0-1160.2.2.el7.x86_64 不支持KVM_CAP_IMMEDIATE_EXIT功能 https://github.com/rust-vmm/kvm-ioctls/src/cap.rs ImmediateExit = KVM_CAP_IMMEDIATE_EXIT, 升级kernel centos 7的kernel比较老, 直接用标准方式升级版本还是3.10. 下面用epel升级kernel yum --enablerepo=elrepo-kernel install kernel-lt 改grub默认从新kernel启动, 启动后版本是: $ uname -a Linux spine.novalocal 5.4.207-1.el7.elrepo.x86_64 #1 SMP Tue Jul 19 10:40:55 EDT 2022 x86_64 x86_64 x86_64 GNU/Linux 使用新kernel问题解决! 编译virtiofsd virtiofsd是rust版本的daemon进程, 用来通过viriofs协议和VM共享host目录. git clone https://gitlab.com/virtio-fs/virtiofsd cargo build --release 错误: /usr/bin/ld: cannot find -lseccomp /usr/bin/ld: cannot find -lcap-ng collect2: error: ld returned 1 exit status 解决: sudo apt install libseccomp-dev libcap-ng-dev target是musl也不总是完全的静态链接 比如这个virtiofsd, 用了musl libc之后, libc的部分是静态链接的. 但还是引用了libseccomp和libcap 如何静态链接virtiofsd virtiofsd的官方repo就可以编译出完全静态的二进制, 它是如何做到的? 见https://gitlab.com/virtio-fs/virtiofsd/-/blob/main/.gitlab-ci.yml apk add libcap-ng-static libseccomp-static musl-dev RUSTFLAGS='-C target-feature=+crt-static -C link-self-contained=yes' LIBSECCOMP_LINK_TYPE=static LIBSECCOMP_LIB_PATH=/usr/lib LIBCAPNG_LINK_TYPE=static LIBCAPNG_LIB_PATH=/usr/lib cargo build --release --target x86_64-unknown-linux-musl "},"notes/rust_coding_brief.html":{"url":"notes/rust_coding_brief.html","title":"代码积累","keywords":"","body":"记录平时积累的rust知识. "},"notes/rust_序列化.html":{"url":"notes/rust_序列化.html","title":"序列化原理","keywords":"","body":" 主流的serde框架 简单例子 serde_json 理论 untype的例子 Index操作符重载 反序列化自定义struct json!宏构建json 序列化结构体 性能 依赖 理论 29种类型 derive 属性 自己实现序列化 序列化 反序列化 反序列化的zero copy和生命周期标记 主流的serde框架 Serde is a framework for _ser_ializing and _de_serializing Rust data structures efficiently and generically. 简单例子 use serde::{Serialize, Deserialize}; extern crate serde_json; // 1.0.82 #[derive(Serialize, Deserialize, Debug)] struct Point { x: i32, y: i32, } fn main() { let point = Point { x: 1, y: 2 }; // Convert the Point to a JSON string. let serialized = serde_json::to_string(&point).unwrap(); // Prints serialized = {\"x\":1,\"y\":2} println!(\"serialized = {}\", serialized); // Convert the JSON string back to a Point. let deserialized: Point = serde_json::from_str(&serialized).unwrap(); // Prints deserialized = Point { x: 1, y: 2 } println!(\"deserialized = {:?}\", deserialized); } serde_json 理论 比如下面的json { \"name\": \"John Doe\", \"age\": 43, \"address\": { \"street\": \"10 Downing Street\", \"city\": \"London\" }, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] } json中的每个\"value\", 都是一个serde_json::Value enum Value { Null, Bool(bool), Number(Number), String(String), Array(Vec), Object(Map), } 用serde_json::from_str从string里反序列化json 用from_slice从&[u8]反序列化json 用from_reader从文件或者TCP的socket的io::Read反序列化json untype的例子 所谓的untype就是说没有预定义好一个struct, 而是直接从JSON字符串里反序列化出一个对象, 这个对象的类型永远是serde_json::Value use serde_json::{Result, Value}; fn untyped_example() -> Result { // Some JSON input data as a &str. Maybe this comes from the user. let data = r#\" { \"name\": \"John Doe\", \"age\": 43, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] }\"#; // Parse the string of data into serde_json::Value. let v: Value = serde_json::from_str(data)?; // Access parts of the data by indexing with square brackets. println!(\"Please call {} at the number {}\", v[\"name\"], v[\"phones\"][0]); Ok(()) } fn main() { untyped_example(); } //结果 Please call \"John Doe\" at the number \"+44 1234567\" rust的enum真是强大, 可以对serde_json::Value在运行时做各种操作, 比如v[\"name\"], 甚至v[\"phones\"][0]都是合法的. -- 是因为serde_json::Value自己实现了Index操作符. 显然我们知道这些是合理的, 那如果故意用\"不可能\"的key去访问呢? 比如: println!(\"Please call {} at the number {}\", v[\"nnnnnnnnnnnn\"], v[\"phones\"][0][0][0]); //能正常运行, 没有崩溃, 没有index越界, 结果为null Please call null at the number null 如果最后整个打印v, 会得到: println!(\"{:?}\", v); //结果 Object({\"age\": Number(43), \"name\": String(\"John Doe\"), \"phones\": Array([String(\"+44 1234567\"), String(\"+44 2345678\")])}) Index操作符重载 看起来v支持用index来访问, 是这个库有特殊的实现: https://github.com/serde-rs/json/blob/master/src/value/index.rs impl ops::Index for Value where I: Index, { ... } 这个Index是下面: 关键先match v的类型, 再操作. 相当于操作符重载, 应该是rust比较高阶的用法. impl Index for str { fn index_into(&self, v: &'v Value) -> Option { match v { Value::Object(map) => map.get(self), _ => None, } } fn index_into_mut(&self, v: &'v mut Value) -> Option { match v { Value::Object(map) => map.get_mut(self), _ => None, } } fn index_or_insert(&self, v: &'v mut Value) -> &'v mut Value { if let Value::Null = v { *v = Value::Object(Map::new()); } match v { Value::Object(map) => map.entry(self.to_owned()).or_insert(Value::Null), _ => panic!(\"cannot access key {:?} in JSON {}\", self, Type(v)), } } } 自己实现的Index逻辑: The result of square bracket indexing like v[\"name\"] is a borrow of the data at that index, so the type is &Value. A JSON map can be indexed with string keys, while a JSON array can be indexed with integer keys. If the type of the data is not right for the type with which it is being indexed, or if a map does not contain the key being indexed, or if the index into a vector is out of bounds, the returned element is Value::Null. 反序列化自定义struct 上面untype的例子中, 反序列化出来的对象只能是serde_json::Value, 虽然也可以按照json对号入座的访问里面的filed, 但实际是走的\"通用\"代码. 下面的例子可以直接返回一个strongly typed结构体: use serde::{Deserialize, Serialize}; use serde_json::Result; #[derive(Serialize, Deserialize)] struct Person { name: String, age: u8, phones: Vec, } fn typed_example() -> Result { // Some JSON input data as a &str. Maybe this comes from the user. let data = r#\" { \"name\": \"John Doe\", \"age\": 43, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] }\"#; // Parse the string of data into a Person object. This is exactly the // same function as the one that produced serde_json::Value above, but // now we are asking it for a Person as output. let p: Person = serde_json::from_str(data)?; //同样是from_str这个API, 会根据左侧变量的type来适配, 强大! // Do things just like with any other Rust data structure. println!(\"Please call {} at the number {}\", p.name, p.phones[0]); //这里对name的访问也变成了p.name Ok(()) } This is the same serde_json::from_str function as before, but this time we assign the return value to a variable of type Person so Serde will automatically interpret the input data as a Person and produce informative error messages if the layout does not conform to what a Person is expected to look like. Any type that implements Serde's Deserialize trait can be deserialized this way. This includes built-in Rust standard library types like Vec and HashMap, as well as any structs or enums annotated with #[derive(Deserialize)]. from_str()会返回不同的类型, 是因为它是个泛型函数: pub fn from_str(s: &'a str) -> Result where T: de::Deserialize, { //这里实际上是return from_trait(read::StrRead::new(s)) //伴随着return, 返回类型T被传递进from_trait from_trait(read::StrRead::new(s)) } 这个泛型函数实例化类型T的传入是从返回值Result推断出来的. 而这个返回值从变量类型而来:let p: Person = serde_json::from_str(data)?编译器推断出T就是Person from_str继续把这个类型传递给from_trait. fn from_trait(read: R) -> Result where R: Read, T: de::Deserialize, { let mut de = Deserializer::new(read); let value = tri!(de::Deserialize::deserialize(&mut de)); // Make sure the whole stream has been consumed. tri!(de.end()); Ok(value) } json!宏构建json serde_json提供了json!宏来在代码里定义原始json文本数据. use serde_json::json; fn main() { // The type of `john` is `serde_json::Value` let john = json!({ \"name\": \"John Doe\", \"age\": 43, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] }); println!(\"first phone number: {}\", john[\"phones\"][0]); // Convert to a string of JSON and print it out println!(\"{}\", john.to_string()); } json宏还提供更高级的功能: 引用变量 let full_name = \"John Doe\"; let age_last_year = 42; // The type of `john` is `serde_json::Value` let john = json!({ \"name\": full_name, \"age\": age_last_year + 1, //这里可以引用上面的变量 \"phones\": [ format!(\"+44 {}\", random_phone()) //也可以调用其他宏和函数 ] }); One neat thing about the json! macro is that variables and expressions can be interpolated directly into the JSON value as you are building it. Serde will check at compile time that the value you are interpolating is able to be represented as JSON. 序列化结构体 serde_json::to_string 序列化到string serde_json::to_vec序列化到Vec serde_json::to_writer序列化到文件或者TCP stream Any type that implements Serde's Serialize trait can be serialized this way. This includes built-in Rust standard library types like Vec and HashMap, as well as any structs or enums annotated with #[derive(Serialize)]. 性能 性能很好. 比最快的C实现还快 It is fast. You should expect in the ballpark of 500 to 1000 megabytes per second deserialization and 600 to 900 megabytes per second serialization, depending on the characteristics of your data. This is competitive with the fastest C and C++ JSON libraries or even 30% faster for many use cases. Benchmarks live in the serde-rs/json-benchmark repo. 依赖 只依赖内存allocator. 可以禁止其他default的feature, 只保留alloc Disable the default \"std\" feature and enable the \"alloc\" feature: [dependencies] serde_json = { version = \"1.0\", default-features = false, features = [\"alloc\"] } 理论 不同于其他使用发射来实现序列化的语言, serde用的是rust的trait. 实现了Serde's Serialize and Deserialize的struct都可以被序列化/反序列化. 29种类型 serde归纳了29种基础类型: 注意没有指针! 这点和tinygo不一样, tinygo用了反射, 而反射是支持指针的. 14 primitive types bool i8, i16, i32, i64, i128 u8, u16, u32, u64, u128 f32, f64 char string UTF-8 bytes with a length and no null terminator. May contain 0-bytes. When serializing, all strings are handled equally. When deserializing, there are three flavors of strings: transient, owned, and borrowed. This distinction is explained in Understanding deserializer lifetimes and is a key way that Serde enabled efficient zero-copy deserialization. byte array - [u8] Similar to strings, during deserialization byte arrays can be transient, owned, or borrowed. option Either none or some value. unit The type of () in Rust. It represents an anonymous value containing no data. unit_struct For example struct Unit or PhantomData. It represents a named value containing no data. unit_variant For example the E::A and E::B in enum E { A, B }. newtype_struct For example struct Millimeters(u8). newtype_variant For example the E::N in enum E { N(u8) }. seq A variably sized heterogeneous sequence of values, for example Vec or HashSet. When serializing, the length may or may not be known before iterating through all the data. When deserializing, the length is determined by looking at the serialized data. Note that a homogeneous Rust collection like vec![Value::Bool(true), Value::Char('c')] may serialize as a heterogeneous Serde seq, in this case containing a Serde bool followed by a Serde char. tuple A statically sized heterogeneous sequence of values for which the length will be known at deserialization time without looking at the serialized data, for example (u8,) or (String, u64, Vec) or [u64; 10]. tuple_struct A named tuple, for example struct Rgb(u8, u8, u8). tuple_variant For example the E::T in enum E { T(u8, u8) }. map A variably sized heterogeneous key-value pairing, for example BTreeMap. When serializing, the length may or may not be known before iterating through all the entries. When deserializing, the length is determined by looking at the serialized data. struct A statically sized heterogeneous key-value pairing in which the keys are compile-time constant strings and will be known at deserialization time without looking at the serialized data, for example struct S { r: u8, g: u8, b: u8 }. struct_variant For example the E::S in enum E { S { r: u8, g: u8, b: u8 } }. 大多数的rust类型, 都能映射到serde类型: rust bool --> serde bool rust Rgb(u8,u8,u8) --> serde tuple struct ... derive 用#[derive(Serialize, Deserialize)]给每个结构体生成一对Serialize and Deserialize traits. 属性 有很多实用的属性, 比如: #[serde(rename = \"name\")] #[serde(rename_all = \"...\")] //比如UPPERCASE, camelCase...等等 #[serde(default)] #[serde(alias = \"name\")] #[serde(flatten)] ...很多... 自己实现序列化 一般用#[derive(Serialize, Deserialize)]配合attributes就够了. 但特殊case如果想自定义序列化, 可以自己实现Serialize and Deserialize这两个trait 每个trait都只有一个方法 pub trait Serialize { fn serialize(&self, serializer: S) -> Result where S: Serializer; } pub trait Deserialize: Sized { fn deserialize(deserializer: D) -> Result where D: Deserializer; } 序列化 pub trait Serialize { fn serialize(&self, serializer: S) -> Result where S: Serializer; } This method's job is to take your type (&self) and map it into the Serde data model by invoking exactly one of the methods on the given Serializer. Serializer也是个trait, 这个trait是不同类型的format(比如json, Bincode等). 并不是所有的序列化输出都是text或者bin的, 比如serde_json::value::Serializer(注意, 不是serde_json::serializer)就序列化到内存. serde把结构体的到29种内部数据类型抽象成trait Serialize, 而把29种数据类型到输出format, 抽象成trait Serializer, 让二者解耦: 从结构体到29种数据类型OK, 就和最后的output格式无关. 这是个很巧妙的设计. Serialize ==> 29种内部数据类型 ==> Serializer 比如序列化一个Map impl Serialize for MyMap where K: Serialize, V: Serialize, { fn serialize(&self, serializer: S) -> Result where S: Serializer, { let mut map = serializer.serialize_map(Some(self.len()))?; for (k, v) in self { //因为知道self就是个map, 所以能用for in map.serialize_entry(k, v)?; } map.end() } } 结构体有4类: 普通结构体, tuple结构体, newtype, unit结构体 // An ordinary struct. Use three-step process: // 1. serialize_struct // 2. serialize_field // 3. end struct Color { r: u8, g: u8, b: u8, } // A tuple struct. Use three-step process: // 1. serialize_tuple_struct // 2. serialize_field // 3. end struct Point2D(f64, f64); // A newtype struct. Use serialize_newtype_struct. struct Inches(u64); // A unit struct. Use serialize_unit_struct. struct Instance; 反序列化 pub trait Deserialize: Sized { fn deserialize(deserializer: D) -> Result where D: Deserializer; } This method's job is to map the type into the Serde data model by providing the Deserializer with a Visitor that can be driven by the Deserializer to construct an instance of your type. Deserializer需要deserialize传入visitor trait. 反序列化比序列化更复杂点. 大体上根据序列化的format不同, 可以分为: 自解释的文本. 比如json, 序列化后的文本就能看出来对应的结构体. 这个情况可以用通用的反序列化apideserialize_any, 产生的对象是serde_json::Value 非自解释的bincode. 比如二进制的序列化方式, 只看output是不可能知道原始结构体的layout的. 这个情况需要编程时明确目标结构体的类型, 产生的对象是非serde_json::Value 反序列化的zero copy和生命周期标记 rust能做到zero copy是因为生成的目标结构体, 能引用原始buffer里面的比如string等类型, 不用拷贝. 因为有生命周期标记. 比如: #[derive(Deserialize)] struct User { id: u32, name: &'a str, screen_name: &'a str, location: &'a str, } Zero-copy deserialization means deserializing into a data structure, like the User struct above, that borrows string or byte array data from the string or byte array holding the input. This avoids allocating memory to store a string for each individual field and then copying string data out of the input over to the newly allocated field. Rust guarantees that the input data outlives the period during which the output data structure is in scope, meaning it is impossible to have dangling pointer errors as a result of losing the input data while the output data structure still refers to it. 上面的User结构体有多个对str的引用, 这些引用直接引用到原始buffer, 没有拷贝. rust保证原始buffer会一直有效直到这个结构体的生命周期结束. 注: User结构体本身不用生命周期标记, 它的标记'a是给里面的成员用的, 表示所有成员都有同样的生命周期. 反序列化的复杂点在于, 目标结构体要分配内存: where T: Deserialize 其引用的内存可能来自原始input的buffer中, 比如serde_json::from_str中, 原始str的生命周期也是caller提供的, 带生命周期标记的, 就可以被最终的目标结构体引用. This means \"T can be deserialized from some lifetime.\" The caller gets to decide what lifetime that is. Typically this is used when the caller also provides the data that is being deserialized from, for example in a function like serde_json::from_str. In that case the input data must also have lifetime 'de, for example it could be &'de str. where T: DeserializeOwned 原始的input, 以及其伴随的buffer, 在反序列化之后会被free. 此时不能引用. 比如io的reader This means \"T can be deserialized from any lifetime.\" The callee gets to decide what lifetime. Usually this is because the data that is being deserialized from is going to be thrown away before the function returns, so T must not be allowed to borrow from it. For example a function that accepts base64-encoded data as input, decodes it from base64, deserializes a value of type T, then throws away the result of base64 decoding. Another common use of this bound is functions that deserialize from an IO stream, such as serde_json::from_reader. "},"notes/rust_知识点积累.html":{"url":"notes/rust_知识点积累.html","title":"知识点更新","keywords":"","body":" 生命周期标记 线程 宏 简单例子 例子1 例子2 迭代器 闭包 rust指针cheatsheet ownership 方法和瀑布式设计 小知识点 std库的catch_unwind catch_unwind和FnOnce 什么是FnOnce catch_unwind 代码解释 std库的同步功能 u32可以调用checked_add做溢出检查 tuple返回值 宏调用使用()或{}都行? 该传值的时候传借用也行? 方法impl块里面的Self 条件编译 static变量 trait object 可以在函数定义里干任何事? 结构体定义和C对比 crate和mod bin文件的例子 lib的例子 firecracker/src/utils/src/arg_parser.rs代码走读 use 使用了BTreeMap 重定义了Result ArgParser对象 ArgParser对象方法 new这个对象: 从命令行parse 增加arg项 格式化help output Argument对象 test std collections Sequences性能 Maps性能 BTreeMap iter() keys()和values() 生命周期标记 只有引用才有生命周期标记的说法, 其他都没有: 没有结构体生命周期标记的说法. 看见一个struct带标记, 实际上是对其内部的field的引用的标记 编译器会自动推导一般的生命标记. 比如: fn announce(value: &impl Display) { println!(\"Behold! {}!\", value); } fn main() { let num = 42; let num_ref = &num; announce(num_ref); } 去掉编译器语法糖的版本fn announce(value: &'a T) where T: Display { println!(\"Behold! {}!\", value); } fn main() { 'x: { let num = 42; 'y: { let num_ref = &'y num; 'z: { announce(num_ref); } } } } 线程 use std::thread; fn main() { let guard = thread::scoped(|| { println!(\"Hello from a thread!\"); }); // guard goes out of scope here. 就是说在这里会等着上面的线程结束 } scoped原型是 fn scoped(self, f: F) -> JoinGuard where T: Send + 'a, F: FnOnce() -> T, F: Send + 'a Specifically, F, the closure that we pass to execute in the new thread. It has two restrictions: It must be a FnOnce from () to T. Using FnOnce allows the closure to take ownership of any data it mentions from the parent thread. The other restriction is that F must be Send. We aren't allowed to transfer this ownership unless the type thinks that's okay. 如果用spawn就不会卡住了, main退出会强制退出线程. fn main() { thread::spawn(|| { println!(\"Hello from a thread!\"); }); timer::sleep(Duration::milliseconds(50)); } 宏 比如Vec!宏: let x: Vec = vec![1, 2, 3]; 展开后是: let x: Vec = { let mut temp_vec = Vec::new(); temp_vec.push(1); temp_vec.push(2); temp_vec.push(3); temp_vec }; 对应的宏实现是: macro_rules! vec { ( $( $x:expr ),* ) => { { let mut temp_vec = Vec::new(); $( temp_vec.push($x); )* temp_vec } }; } ( $( $x:expr ),* ) => {...}里, $x:expr是类似match的语法, $(...),*是类似正则的语法, 表示match expr 0次或多次; $x是个临时变量. =>右边的$()*表示重复每个匹配 简单例子 macro_rules! five_times { ($x:expr) => (5 * $x); } fn main() { assert_eq!(25, five_times!(2 + 3)); } 例子1 macro_rules! foo { (x => $e:expr) => (println!(\"mode X: {}\", $e)); (y => $e:expr) => (println!(\"mode Y: {}\", $e)); } fn main() { foo!(y => 3); //这里的y => 3被宏做匹配 //foo!(z => 3);这样调用不行, 会报错. error: no rules expected the token `z` } //输出 mode Y: 3 例子2 macro_rules! o_O { ( $( $x:expr; [ $( $y:expr ),* ] );* ) => { &[ $($( $x + $y ),*),* ] } } fn main() { let a: &[i32] = o_O!(10; [1, 2, 3]; 20; [4, 5, 6]); assert_eq!(a, [11, 12, 13, 24, 25, 26]); 迭代器 for x in 0..10 { println!(\"{}\", x); } for相当于在loop里不断的调用range这个迭代器的next方法. let mut range = 0..10; loop { match range.next() { Some(x) => { println!(\"{}\", x); }, None => { break } } } vec的iter方法返回一个迭代器: let nums = vec![1, 2, 3]; for num in nums.iter() { //这里的num是个引用, println默认会解引用. println!(\"{}\", num); //下面的写法也行 println!(\"{}\", *num); } Now we're explicitly dereferencing num. Why does iter() give us references? Well, if it gave us the data itself, we would have to be its owner, which would involve making a copy of the data and giving us the copy. With references, we're just borrowing a reference to the data, and so it's just passing a reference, without needing to do the copy. 见: https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/iterators.html 有些概念挺有用的: Iterator adapters, 比如map, filter等API Consumers, 比如collect等 闭包 let add_one = |x| { 1 + x }; println!(\"The sum of 5 plus 1 is {}.\", add_one(5)); fn main() { let x: i32 = 5; let printer = || { println!(\"x is: {}\", x); }; printer(); // prints \"x is: 5\" } 带move关键词的闭包的语义是take ownership: a moving closure always takes ownership of all variables that it uses. Ordinary closures, in contrast, just create a reference into the enclosing stack frame. 每个闭包的type都是独特的, 下面的例子用了F和G两个fn, 虽然签名是一模一样的, 但F和G是两个不同的type, 对应了两个不同的闭包. fn compose(x: i32, f: F, g: G) -> i32 where F: Fn(i32) -> i32, G: Fn(i32) -> i32 { g(f(x)) } fn main() { compose(5, |n: i32| { n + 42 }, |n: i32| { n * 2 }); // evaluates to 94 } rust指针cheatsheet Type Name Summary &T Reference Allows one or more references to read T &mut T Mutable Reference Allows a single reference to read and write T Box Box Heap allocated T with a single owner that may read and write T. Rc \"arr cee\" pointer Heap allocated T with many readers Arc Arc pointer Same as above, but safe sharing across threads *const T Raw pointer Unsafe read access to T *mut T Mutable raw pointer Unsafe read and write access to T ownership 说的很细 https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/ownership.html 方法和瀑布式设计 https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/method-syntax.html 小知识点 std库的catch_unwind panic::catch_unwind可以捕获rust运行时的panic use std::panic; let result = panic::catch_unwind(|| { println!(\"hello!\"); }); assert!(result.is_ok()); let result = panic::catch_unwind(|| { panic!(\"oh no!\"); }); assert!(result.is_err()); catch_unwind和FnOnce std::panic::catch_unwind(AssertUnwindSafe(f)) 上面的代码是ok的, 只要F满足约束: where F: FnOnce(), F: Send + 'static, 什么是FnOnce pub trait FnOnce { type Output; extern \"rust-call\" fn call_once(self, args: Args) -> Self::Output; } Instances of FnOnce can be called, but might not be callable multiple times. Because of this, if the only thing known about a type is that it implements FnOnce, it can only be called once. FnOnce只能被调用一次. FnOnce is implemented automatically by closure that might consume captured variables, as well as all types that implement FnMut, e.g. (safe) function pointers (since FnOnce is a supertrait of FnMut). 闭包自动实现了FnOnce, Fn, FnMut中的一个. Since both Fn and FnMut are subtraits of FnOnce, any instance of Fn or FnMut can be used where a FnOnce is expected. Fn和FnMut是FnOnce的子trait Use FnOnce as a bound when you want to accept a parameter of function-like type and only need to call it once. If you need to call the parameter repeatedly, use FnMut as a bound; if you also need it to not mutate state, use Fn. Also of note is the special syntax for Fn traits (e.g. Fn(usize, bool) -> usize). FnOnce是个函数形式的trait, 和Fn一样拥有特殊语法:Fn(usize, bool) -> usize 详见: Closures: Anonymous Functions catch_unwind std::panic::catch_unwind()的入参类型是FnOnce() -> R + UnwindSafe这个特殊语法的Fn trait pub fn catch_unwind R + UnwindSafe, R>(f: F) -> Result { unsafe { panicking::r#try(f) } } 代码解释 std::panic::catch_unwind(AssertUnwindSafe(f)) AssertUnwindSafe是个元组结构体: pub struct AssertUnwindSafe(pub T); 它实现了FnOnce: impl R> FnOnce for AssertUnwindSafe { type Output = R; extern \"rust-call\" fn call_once(self, _args: ()) -> R { (self.0)() } } 所以: FnOnce不一定非要是个闭包, 也可以是个结构体, 比如struct AssertUnwindSafe 记住Fn这个特殊的trait std库的同步功能 在多线程的情况下, 希望所有线程在某个点\"集合\": use std::sync::{Arc, Barrier}; use std::thread; let mut handles = Vec::with_capacity(10); let barrier = Arc::new(Barrier::new(10)); for _ in 0..10 { let c = Arc::clone(&barrier); // The same messages will be printed together. // You will NOT see any interleaving. handles.push(thread::spawn(move|| { println!(\"before wait\"); c.wait(); println!(\"after wait\"); })); } // Wait for other threads to finish. for handle in handles { handle.join().unwrap(); } u32可以调用checked_add做溢出检查 //self.next_gsi类型是u32 self.next_gsi = self.next_gsi.checked_add(1).ok_or(Error::Overflow)?; tuple返回值 一个函数如果想返回多个返回值, 可以这样: fn prepare_default_values() -> (String, String, String) { let default_vcpus = format! {\"boot={},max_phys_bits={}\", config::DEFAULT_VCPUS,config::DEFAULT_MAX_PHYS_BITS}; let default_memory = format! {\"size={}M\", config::DEFAULT_MEMORY_MB}; let default_rng = format! {\"src={}\", config::DEFAULT_RNG_SOURCE}; (default_vcpus, default_memory, default_rng) } 使用的时候用模式匹配: let (default_vcpus, default_memory, default_rng) = prepare_default_values(); 宏调用使用()或{}都行? 比如下面的代码, format和println宏, 用小括号和大括号调用, 作用一模一样. let default_vcpus = format! {\"boot={},max_phys_bits={}\", 8, 6.78}; let default_vcpus2 = format!(\"boot={},max_phys_bits={}\", 8, 6.78); println!(\"{}\", default_vcpus); println! {\"{}\", default_vcpus2}; 该传值的时候传借用也行? 比如这个函数, 第二个参数guest_mem的类型要求是&GuestMemoryMmap pub fn memory_init( &mut self, guest_mem: &GuestMemoryMmap, kvm_max_memslots: usize, track_dirty_pages: bool, ) -> Result 调用的时候: //已知guest_memory是&GuestMemoryMmap类型 guest_memory: &GuestMemoryMmap let mut vm = Vm::new() //这样可以编译, guest_memory的借用传入 vm.memory_init(&guest_memory, kvm.max_memslots(), track_dirty_pages) //这样也可以, 直接传入guest_memory, 这个应该是更符合函数signature vm.memory_init(guest_memory, kvm.max_memslots(), track_dirty_pages) //这样竟然也行 vm.memory_init(&&&&&&&&&guest_memory, kvm.max_memslots(), track_dirty_pages) 可能GuestMemoryMmap实现了Dref trait? 还是这种形式的传参都是被rust支持的????? 方法impl块里面的Self 一个结构体的方法, 并不都是入参一定是Self, 比如类似new()方法, 返回值才是Self(或者&Self等) 比如: pub struct VmResources { ... } impl VmResources { //new函数 pub fn from_json() -> std::result::Result { ...实例化Self } //其他方法 pub fn set_vsock_device(&mut self, config: VsockDeviceConfig) -> Result //等等 } 调用\"new\"方法的时候, 用的是VmResources::from_json(), 调用其他方法的时候, 用的是对象.xxx(). 而且, 一般的方法第一个入参是&mut self或者&self 它们都在一个impl块里. 条件编译 比如只有再cfg的target_arch是aarch64时才编译: #[cfg(target_arch = \"aarch64\")] enable_ssbd_mitigation(); static变量 比如下面的代码: use lazy_static::lazy_static; lazy_static! { static ref _LOGGER_INNER: Logger = Logger::new(); /// Static instance used for handling human-readable logs. pub static ref LOGGER: &'static Logger = { set_logger(_LOGGER_INNER.deref()).expect(\"Failed to set logger\"); _LOGGER_INNER.deref() }; } static说的是被static标记的变量在整个程序的周期内都有效 ref说的是后面的变量在被match做pattern匹配的时候, 使用借用方式.注: match默认采用move方式, 比如下面的maybe_name变量被match后就没法用了.let maybe_name = Some(String::from(\"Alice\")); // The variable 'maybe_name' is consumed here ... match maybe_name { Some(n) => println!(\"Hello, {}\", n), _ => println!(\"Hello, world\"), } // ... and is now unavailable. println!(\"Hello again, {}\", maybe_name.unwrap_or(\"world\".into())); 用ref就可以: 注意Some(ref n)那句let maybe_name = Some(String::from(\"Alice\")); // Using `ref`, the value is borrowed, not moved ... match maybe_name { Some(ref n) => println!(\"Hello, {}\", n), _ => println!(\"Hello, world\"), } // ... so it's available here! println!(\"Hello again, {}\", maybe_name.unwrap_or(\"world\".into())); _LOGGER_INNER.deref()这种神奇操作来自lazy_static!宏, 这是github上实现的第三方库, 用来在运行时声明static变量, 比如:lazy_static! { static ref NAME: TYPE = EXPR; } 大义是自动实现了Deref trait, 在第一次deref的时候, 执行后面的EXPR, 后面再解引用的时候, 就直接返回第一次的值的引用. trait object 比如下面的代码中, 返回值Arc是个trait object, 和golang的iface差不多的意思. 编译时选择虚拟化平台, 比如选了kvm, kvm的那个new函数返回具体的结构体. pub fn new() -> std::result::Result, HypervisorError> { #[cfg(feature = \"kvm\")] let hv = kvm::KvmHypervisor::new()?; #[cfg(feature = \"mshv\")] let hv = mshv::MshvHypervisor::new()?; Ok(Arc::new(hv)) } 可以在函数定义里干任何事? 比如可以在函数定义里定义结构体, 并实现一个trait fn write_fmt(&mut self, fmt: fmt::Arguments) -> Result { // Create a shim which translates a Write to a fmt::Write and saves // off I/O errors. instead of discarding them struct Adapter { inner: &'a mut T, error: Result, } impl fmt::Write for Adapter { fn write_str(&mut self, s: &str) -> fmt::Result { match self.inner.write_all(s.as_bytes()) { Ok(()) => Ok(()), Err(e) => { self.error = Err(e); Err(fmt::Error) } } } } let mut output = Adapter { inner: self, error: Ok(()) }; match fmt::write(&mut output, fmt) { Ok(()) => Ok(()), Err(..) => { // check if the error came from the underlying `Write` or not if output.error.is_err() { output.error } else { Err(error::const_io_error!(ErrorKind::Uncategorized, \"formatter error\")) } } } } 结构体定义和C对比 同样的结构体, C的定义和rust定义分别如下: struct sock_fprog { unsigned short len; /* Number of BPF instructions */ struct sock_filter *filter; /* Pointer to array of BPF instructions */ }; struct sock_filter { /* Filter block */ __u16 code; /* Actual filter code */ __u8 jt; /* Jump true */ __u8 jf; /* Jump false */ __u32 k; /* Generic multiuse field */ }; rust对应的定义更严谨(啰嗦): /// BPF instruction structure definition. /// See /usr/include/linux/filter.h . #[repr(C)] #[derive(Clone, Debug, PartialEq, Deserialize, Serialize)] #[doc(hidden)] pub struct sock_filter { pub code: ::std::os::raw::c_ushort, pub jt: ::std::os::raw::c_uchar, pub jf: ::std::os::raw::c_uchar, pub k: ::std::os::raw::c_uint, } /// Program made up of a sequence of BPF instructions. pub type BpfProgram = Vec; crate和mod bin文件的例子 firecracker工程下, 有个seccompiler目录: 上面的图中: toml文件里的关键字都是规范定的, 见https://doc.rust-lang.org/cargo/reference/manifest.html Cargo.toml里面说这个seccompiler目录是个crate, 会产生一个seccompiler-bin文件, 产生这个bin的源文件是src/seccompiler_bin.rs; [[bin]]是个表数组, 表示可能会有多个bin. src里面每个文件名都是个mod 在主文件seccompiler_bin.rs里要声明这些mod lib的例子 比如下面这个utils, 是多个工具库的集合. 因为都是库, 就没有一个叫utils.rs的文件 外部crate要引用其中某个库的时候, 用use utils::arg_parser::{ArgParser, Argument, Arguments as ArgumentsBag}; firecracker/src/utils/src/arg_parser.rs代码走读 use 使用了BTreeMap use std::collections::BTreeMap; use std::env; use std::fmt; use std::result; 重定义了Result std::result::Result是个泛型, 是对函数返回值的\"标准\"抽象 pub type Result = result::Result; //这个Error就是下面的Error arg_parser自己的Error定义: 其中每个field基本上都是\"元组结构体\"的形式: /// Errors associated with parsing and validating arguments. #[derive(Debug, PartialEq)] pub enum Error { /// The argument B cannot be used together with argument A. ForbiddenArgument(String, String), /// The required argument was not provided. MissingArgument(String), /// A value for the argument was not provided. MissingValue(String), /// The provided argument was not expected. UnexpectedArgument(String), /// The argument was provided more than once. DuplicateArgument(String), } Error这个enum实现了fmt::Display impl fmt::Display for Error { fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result { use self::Error::*; match *self { ForbiddenArgument(ref arg1, ref arg2) => write!( f, \"Argument '{}' cannot be used together with argument '{}'.\", arg2, arg1 ), MissingArgument(ref arg) => write!(f, \"Argument '{}' required, but not found.\", arg), MissingValue(ref arg) => write!( f, \"The argument '{}' requires a value, but none was supplied.\", arg ), UnexpectedArgument(ref arg) => write!( f, \"Found argument '{}' which wasn't expected, or isn't valid in this context.\", arg ), DuplicateArgument(ref arg) => { write!(f, \"The argument '{}' was provided more than once.\", arg) } } } } 这里面用了write!这个宏, 把一个formated文本写入f. ArgParser对象 ArgParser对象是程序的命令行对象: 这里面一直都带着生命周期标记'a /// Keep information about the argument parser. #[derive(Clone, Default)] pub struct ArgParser { arguments: Arguments, } arguments是个BTree /// Stores the arguments of the parser. #[derive(Clone, Default)] pub struct Arguments { // A BTreeMap in which the key is an argument and the value is its associated `Argument`. args: BTreeMap>, // The arguments specified after `--` (i.e. end of command options). extra_args: Vec, } 再里面的Argument是命令行的option的抽象: /// Stores the characteristics of the `name` command line argument. #[derive(Clone, Debug, PartialEq)] pub struct Argument { name: &'a str, required: bool, requires: Option, forbids: Vec, takes_value: bool, allow_multiple: bool, default_value: Option, help: Option, user_value: Option, } ArgParser对象方法 所有对象方法都包在impl块中: impl ArgParser { } new这个对象: new返回Self本身, 而不能返回借用(&Self), 因为这个函数结束后, 所有local的东西都会被drop, 那显然就没有什么可以借用的. /// Create a new ArgParser instance. pub fn new() -> Self { ArgParser::default() } 从命令行parse 从下面的函数能看到, ArgParser对象虽然只包括Arguments, 但明显没有继承. 所以这里还要显式的转一把: /// Parse the command line arguments. pub fn parse_from_cmdline(&mut self) -> Result { self.arguments.parse_from_cmdline() } 增加arg项 这里用了\"瀑布式\"的函数形式, 入参和出参都是Self类型: 这个过程发生了所有权转移, 这里的mut self入参会导致Self move, 但最后返回的时候又move出去了. /// Add an argument with its associated `Argument` in `arguments`. pub fn arg(mut self, argument: Argument) -> Self { self.arguments.insert_arg(argument); self } 调用形式, 在其他的模块中: 下面的连续.arg()调用, 我理解没有发生Self的拷贝. fn build_arg_parser() -> ArgParser { ArgParser::new() .arg( Argument::new(\"input-file\") .required(true) .takes_value(true) .help(\"File path of the JSON input.\"), ) .arg( Argument::new(\"output-file\") .required(false) .takes_value(true) .default_value(DEFAULT_OUTPUT_FILENAME) .help(\"Optional path of the output file.\"), ) .arg( Argument::new(\"target-arch\") .required(true) .takes_value(true) .help(\"The computer architecture where the BPF program runs. Supported architectures: x86_64, aarch64.\"), ) .arg( Argument::new(\"basic\") .takes_value(false) .help(\"Deprecated! Transforms the filters into basic filters. Drops all argument checks \\ and rule-level actions. Not recommended.\"), ) } 格式化help output // Filter arguments by whether or not it is required. // Align arguments by setting width to length of the longest argument. fn format_arguments(&self, is_required: bool) -> String { let filtered_arguments = self .arguments .args .values() //这是个实体的Values, 实现了Iterator; //但它声明了自己实现了Iterator, 能编译过, 那就\"继承\"了Iterator的其他N多方法 //比如就继承了下面的filter .filter(|arg| is_required == arg.required) .collect::>(); //编译器会自动推导出返回类型是Vec let max_arg_width = filtered_arguments .iter() .map(|arg| arg.format_name().len()) .max() .unwrap_or(0); //因为上面的max函数返回Option类型, 这里unwrap Some层, 取得raw数据. filtered_arguments .into_iter() .map(|arg| arg.format_help(max_arg_width)) .collect::>() .join(\"\\n\") //Vec并没有join方法, 这里自动解引用了, 调用了[String]的join } 上面的Values是stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/alloc/src/collections/btree/map.rs定义的结构体 pub struct Values { inner: Iter, } 而且它还实现了Iterator impl Iterator for Values { } 在这里这个泛型结构体被实例化成了struct Values 那么这个struct Values对象就能享受Iterator的一系列方法 那么接下来的filter方法, 返回的Filter依旧是个Iterator fn filter(self, predicate: P) -> Filter where Self: Sized, P: FnMut(&Self::Item) -> bool, { Filter::new(self, predicate) } 这里的Self就是struct Values对象本身, filter函数需要一个predicate(谓语)函数来执行filter的具体动作, 而它的入参是&Self::Item, 那么struct Values的Iterator关联类型是什么呢? 见下面, 是&'a V, 这里实例化后是&Argument impl Iterator for Values { type Item = &'a V; fn next(&mut self) -> Option { self.inner.next().map(|(_, v)| v) } fn size_hint(&self) -> (usize, Option) { self.inner.size_hint() } fn last(mut self) -> Option { self.next_back() } } 那么就能得出: .filter(|arg| is_required == arg.required) 其中: arg是struct Values的关联类型&Argument的借用, 即&&Argument rust有自动解引用机制, 所以arg.required可以直接用 Argument对象 这里全程都带生命周期标记, 怎么看着挺啰嗦的. #[derive(Clone, Debug, PartialEq)] pub struct Argument { name: &'a str, required: bool, requires: Option, forbids: Vec, takes_value: bool, allow_multiple: bool, default_value: Option, help: Option, user_value: Option, } test 这个文件1k多行, 有一般都是test test从#[cfg(test)]开始 包在mod里面: #[cfg(test)] mod tests { use super::*; use crate::arg_parser::Value; //即使在同一个文件, 也要显式引用 } 测试项以#[test]标记, 函数以test_开头 fn test_value() { //Test `as_string()` and `as_flag()` functions behaviour. let mut value = Value::Flag; assert!(Value::as_single_value(&value).is_none()); value = Value::Single(\"arg\".to_string()); assert_eq!(Value::as_single_value(&value).unwrap(), \"arg\"); value = Value::Single(\"arg\".to_string()); assert!(!Value::as_flag(&value)); value = Value::Flag; assert!(Value::as_flag(&value)); } 使用了大量的assert_eq!宏, 比如: assert_eq!( arg_parser.formatted_help(), \"optional arguments:\\n \\ --config-file 'config-file' info.\\n \\ --id 'id' info.\\n \\ --seccomp-filter 'seccomp-filter' info.\" ); 判断Result是否ok assert!(arguments.parse(&args).is_ok()); 没有看到golang类似的benchmark测试 std collections 代码在.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/collections/mod.rs 主要是对其他crate的重新引用: pub use alloc_crate::collections::{binary_heap, btree_map, btree_set}; pub use alloc_crate::collections::{linked_list, vec_deque}; pub use alloc_crate::collections::{BTreeMap, BTreeSet, BinaryHeap}; pub use alloc_crate::collections::{LinkedList, VecDeque}; pub use self::hash_map::HashMap; pub use self::hash_set::HashSet; Rust's collections can be grouped into four major categories: Sequences: Vec, VecDeque, LinkedList Maps: HashMap, BTreeMap Sets: HashSet, BTreeSet Misc: BinaryHeap Sequences性能 get(i) insert(i) remove(i) append split_off(i) Vec O(1) O(n-i) O(n-i) O(m) O(n-i) VecDeque O(1) O(min(i, n-i)) O(min(i, n-i)) O(m) O(min(i, n-i)) LinkedList O(min(i, n-i)) O(min(i, n-i)) O(min(i, n-i)) O(1) O(min(i, n-i)) Maps性能 get insert remove range append HashMap O(1)~ O(1)~ O(1)~ N/A N/A BTreeMap O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n+m) BTreeMap iter() BTreeMap的iter()方法返回Iter结构体 这是个 pub struct Iter { range: LazyLeafRange, K, V>, length: usize, } 它实现了Iterator: #[stable(feature = \"rust1\", since = \"1.0.0\")] impl Iterator for Iter { type Item = (&'a K, &'a V); fn next(&mut self) -> Option { if self.length == 0 { None } else { self.length -= 1; Some(unsafe { self.range.next_unchecked() }) } } fn size_hint(&self) -> (usize, Option) { (self.length, Some(self.length)) } fn last(mut self) -> Option { self.next_back() } fn min(mut self) -> Option { self.next() } fn max(mut self) -> Option { self.next_back() } } BTreeMap的iter使用举例: use std::collections::BTreeMap; let mut map = BTreeMap::new(); map.insert(3, \"c\"); map.insert(2, \"b\"); map.insert(1, \"a\"); for (key, value) in map.iter() { println!(\"{}: {}\", key, value); } let (first_key, first_value) = map.iter().next().unwrap(); assert_eq!((*first_key, *first_value), (1, \"a\")); keys()和values() BTreeMap还有keys()和values()方法, 分别返回keys和values. 比如: let mut a = BTreeMap::new(); a.insert(2, \"b\"); a.insert(1, \"a\"); let keys = a.keys(); let values = a.values(); println!(\"{:?}\", keys); println!(\"{:?}\", values); 结果: [1, 2] [\"a\", \"b\"] key就是key, value就只有value, 很通顺. 但实际上, keys()和values()方法分别返回Keys和Values结构体, 而他们的内部都是inner: Iter pub struct Keys { inner: Iter, } pub struct Values { inner: Iter, } 区别在于它们各自实现的迭代器不同, 比如: impl Iterator for Values { type Item = &'a V; fn next(&mut self) -> Option { self.inner.next().map(|(_, v)| v) //把(k,v)map成v } fn size_hint(&self) -> (usize, Option) { self.inner.size_hint() } fn last(mut self) -> Option { self.next_back() } } "},"notes/rust_adaptiveservice.html":{"url":"notes/rust_adaptiveservice.html","title":"rust版本的adaptiveservice探索","keywords":"","body":" 5种\"动态\"类型 rust的泛型是静态的 静态分发 动态分发 即trait objects 从指针获取trait objects adaptiveservice是我用go写的微服务消息框架, 其核心之一是用了go的反射来给每个数据struct绑定一个handler方法. if st.svc.canHandle(tm.msg) { mm := &metaKnownMsg{ stream: ss, msg: tm.msg.(KnownMessage), } mq.putMetaMsg(mm) } else { ss.privateChan 在rust里面没有反射, 如何实现从字节流数据(stream buffer)到具体结构体的生成? 生成的数据结构体能否\"断言\"成实现了KnownMessage的trait? 先看看rust从类型上提供了什么语义, 这些语义能干什么. 5种\"动态\"类型 use std::any::Any; struct Header { uuid: u64, protocol: String } // 第一种, 静态类型, 泛型是静态分发的, 即在编译的时候就生成好了\"类型化\"的代码. // statically typed, no pointer dereference struct GenericPacket { header: Header, data: T } // 第二种, 用Any，任何类型都实现了Any // uses the \"Any\" type to have dynamic typing struct AnyPacket { header: Header, data: Any, } // 第三种，用enum穷尽所有可能的类型 // uses an enum to capture the differnet possible types enum DataEnum { Integer(i32), Float(f32) } struct EnumPacket { header: Header, data: DataEnum, } // 第四种: 用trait object trait DataTrait { // interface your data conforms to } struct TraitPacket { header: Header, data: &'a dyn DataTrait, // uses a pointer dereference to something that implements DataTrait } // 第五种: 和第一种类型类似, 但是带具体方法的trait // statically typed, but will accept any type that conforms to DataTrait struct StaticTraitPacket { header: Header, data: T, } rust的泛型是静态的 参考: https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/static-and-dynamic-dispatch.html 比如下面的trait: trait Foo { fn method(&self) -> String; } impl Foo for u8 { fn method(&self) -> String { format!(\"u8: {}\", *self) } } impl Foo for String { fn method(&self) -> String { format!(\"string: {}\", *self) } } 静态分发 比如下面的代码: fn do_something(x: T) { x.method(); } fn main() { let x = 5u8; let y = \"Hello\".to_string(); do_something(x); do_something(y); } rust会在编译阶段就知道do_something()的入参类型, 会静态的生成类型下面的静态代码: fn do_something_u8(x: u8) { x.method(); } fn do_something_string(x: String) { x.method(); } fn main() { let x = 5u8; let y = \"Hello\".to_string(); do_something_u8(x); do_something_string(y); } 虽然\"静态分发\"会有一定的代码\"重复\"带来代码段的膨胀, 但一般问题不大, 直接函数调用的性能会好点, 比如可以被inline优化 动态分发 即trait objects Rust provides dynamic dispatch through a feature called trait objects. Trait objects, like &Foo or Box, are normal values that store a value of any type that implements the given trait, where the precise type can only be known at runtime. The methods of the trait can be called on a trait object via a special record of function pointers (created and managed by the compiler). A function that takes a trait object is not specialised to each of the types that implements Foo: only one copy is generated, often (but not always) resulting in less code bloat. However, this comes at the cost of requiring slower virtual function calls, and effectively inhibiting any chance of inlining and related optimisations from occurring. Trait objects are both simple and complicated: their core representation and layout is quite straight-forward, but there are some curly error messages and surprising behaviours to discover. 从指针获取trait objects There's two similar ways to get a trait object value: casts and coercions. If T is a type that implements a trait Foo (e.g. u8 for the Foo above), then the two ways to get a Foo trait object out of a pointer to T look like: let ref_to_t: &T = ...; // `as` keyword for casting let cast = ref_to_t as &Foo; // using a `&T` in a place that has a known type of `&Foo` will implicitly coerce: let coerce: &Foo = ref_to_t; fn also_coerce(_unused: &Foo) {} also_coerce(ref_to_t); These trait object coercions and casts also work for pointers like &mut T to &mut Foo and Box to Box, but that's all at the moment. Coercions and casts are identical. This operation can be seen as \"erasing\" the compiler's knowledge about the specific type of the pointer, and hence trait objects are sometimes referred to \"type erasure\" "},"notes/rust_常用设施.html":{"url":"notes/rust_常用设施.html","title":"常用设施","keywords":"","body":" structopt log env_logger 常用宏1 常用宏2 由编译器实现的builtin宏 trait Iterator 比较常用的Iterator方法 collect IntoIterator 数组泛型的方法impl [T] Vec Option Result Result的方法: Result的方法 其他Result Result实现了如下的trait env 取消impl trait 文件 使用举例 写文件 读文件到String 更有效率的读文件 不同选项open &File也能modify 文件 File对象 常用函数 File的方法 其他impl的trait 实现Read trait 实现Write trait 实现Seek trait Read Write Seek for &File又来一遍!!!!! open最后调用 IO 常用函数 Read trait Write trait Seek trait BufRead是Read的派生trait structopt structopt用来把命令行参数转成结构体 定义结构体的时候, 用structopt来\"标记\", 比如: #[derive(Clone, Debug, StructOpt)] #[structopt(name = \"virtiofsd backend\", about = \"Launch a virtiofsd backend.\")] struct Opt { /// Shared directory path #[structopt(long)] shared_dir: Option, /// vhost-user socket path [deprecated] #[structopt(long, required_unless_one = &[\"fd\", \"socket-path\", \"print-capabilities\"])] socket: Option, /// vhost-user socket path #[structopt(long = \"socket-path\", required_unless_one = &[\"fd\", \"socket\", \"print-capabilities\"])] socket_path: Option, ... } 注: structopt已经停止开发, 建议使用clap: Command Line Argument Parser for Rust log https://crates.io/crates/log 要在cargo.toml里面声明依赖: [dependencies] log = \"0.4\" 这个库设计的很合理. 对用户提供几个log的宏: error!, warn!, info!, debug! and trace! lib里面, 只使用这几个输出宏 bin里面, 负责初始化后端的logging实现, 如果没有初始化, 那上面的几个输出宏就类似noop 使用set_boxed_logger Sets the global logger to a Box. 或set_logger Sets the global logger to a &'static Log. 可选的logging实现有: Simple minimal loggers: env_logger simple_logger simplelog pretty_env_logger stderrlog flexi_logger Complex configurable frameworks: log4rs fern Adaptors for other facilities: syslog slog-stdlog systemd-journal-logger android_log win_dbg_logger [db_logger] For WebAssembly binaries: console_log For dynamic libraries: You may need to construct an FFI-safe wrapper over log to initialize in your libraries env_logger 比如这样在代码里: use log::{debug, error, log_enabled, info, Level}; env_logger::init(); debug!(\"this is a debug {}\", \"message\"); error!(\"this is printed by default\"); if log_enabled!(Level::Info) { let x = 3 * 4; // expensive computation info!(\"the answer was: {}\", x); } 使用时: $ RUST_LOG=debug ./main [2017-11-09T02:12:24Z DEBUG main] this is a debug message [2017-11-09T02:12:24Z ERROR main] this is printed by default [2017-11-09T02:12:24Z INFO main] the answer was: 12 可以按module来指定level $ RUST_LOG=main=info ./main [2017-11-09T02:12:24Z ERROR main] this is printed by default [2017-11-09T02:12:24Z INFO main] the answer was: 12 又比如在virtiofsd里面是这样用的: fn set_default_logger(log_level: LevelFilter) { if env::var(\"RUST_LOG\").is_err() { env::set_var(\"RUST_LOG\", log_level.to_string()); } env_logger::init(); } 常用宏1 代码在lib/rustlib/src/rust/library/std/src/macros.rs panic print println eprint eprintln dbg 常用宏2 代码在lib/rustlib/src/rust/library/core/src/macros/mod.rs panic!panic!(); panic!(\"this is a {} {message}\", \"fancy\", message = \"message\"); assert_eq! assert_ne!assert_eq!(a, b); // a b是两个表达式 assert_ne!(a, b); assert_matches!assert_matches!(a, Some(_)); assert_matches!(b, None); let c = Ok(\"abc\".to_string()); assert_matches!(c, Ok(x) | Err(x) if x.len() debug_assert! debug_assert_eq! debug_assert_ne! 只有在debug版本里才使能debug_assert!(true); matches!let foo = 'f'; assert!(matches!(foo, 'A'..='Z' | 'a'..='z')); let bar = Some(4); assert!(matches!(bar, Some(x) if x > 2)); ?和r#try!try!是个宏, 但需要用raw方式来调用, r#try. 现在可以用?来代替enum MyError { FileWriteError } impl From for MyError { fn from(e: io::Error) -> MyError { MyError::FileWriteError } } // The preferred method of quick returning Errors fn write_to_file_question() -> Result { let mut file = File::create(\"my_best_friends.txt\")?; file.write_all(b\"This is a list of my best friends.\")?; Ok(()) } // The previous method of quick returning Errors fn write_to_file_using_try() -> Result { let mut file = r#try!(File::create(\"my_best_friends.txt\")); r#try!(file.write_all(b\"This is a list of my best friends.\")); Ok(()) } write! writeln! 写入bufferfn main() -> std::io::Result { let mut w = Vec::new(); write!(&mut w, \"test\")?; write!(&mut w, \"formatted {}\", \"arguments\")?; assert_eq!(w, b\"testformatted arguments\"); Ok(()) } let mut s = String::new(); writeln!(&mut s, \"{} {}\", \"abc\", 123)?; // uses fmt::Write::write_fmt unreachable! unimplemented! todo! 代码实现阶段用到的宏 由编译器实现的builtin宏 compile_error!#[cfg(not(any(feature = \"foo\", feature = \"bar\")))] compile_error!(\"Either feature \\\"foo\\\" or \\\"bar\\\" must be enabled for this crate.\"); format_args! const_format_args! format_args_nl! 格式化宏, 用于format!宏 env! option_env! 在编译时获取env, 注意不是运行时let path: &'static str = env!(\"PATH\"); let key: Option = option_env!(\"SECRET_KEY\"); concat_idents! 多个标识符连起来成为一个fn foobar() -> u32 { 23 } let f = concat_idents!(foo, bar); println!(\"{}\", f()); concat_bytes! 连接字符 concat!let s = concat!(\"test\", 10, 'b', true); assert_eq!(s, \"test10btrue\"); line! column! file! 编译的文件, 行号等; module_path! module路径let current_line = line!(); println!(\"defined on line: {}\", current_line); stringify!let one_plus_one = stringify!(1 + 1); assert_eq!(one_plus_one, \"1 + 1\"); include_str! 编译时从文件读入string; include_bytes! 编译时从文件读入bytes; 文件是相对当前编译文件的路径.//spanish.in里面是adiós let my_str = include_str!(\"spanish.in\"); assert_eq!(my_str, \"adiós\\n\"); cfg!let my_directory = if cfg!(windows) { \"windows-specific-directory\" } else { \"unix-directory\" }; include! 把文件导入进来按表达式来编译 assert! derive! test bench global_allocator cfg_accessible trait Iterator 看起来只要实现了next就是个Iterator了... 其他都有默认实现, 真方便 pub trait Iterator { type Item; //需要用户实现的: fn next(&mut self) -> Option; //有默认实现的: fn size_hint(&self) -> (usize, Option) //默认返回0, 用户要自己实现更适合自己的方法. fn count(self) -> usize fn last(self) -> Option fn advance_by(&mut self, n: usize) -> Result fn nth(&mut self, n: usize) -> Option fn step_by(self, step: usize) -> StepBy fn chain(self, other: U) -> Chain fn zip(self, other: U) -> Zip fn intersperse(self, separator: Self::Item) -> Intersperse fn intersperse_with(self, separator: G) -> IntersperseWith fn map(self, f: F) -> Map fn for_each(self, f: F) fn filter(self, predicate: P) -> Filter fn filter_map(self, f: F) -> FilterMap fn enumerate(self) -> Enumerate //还是返回一个Iterator, 元素是(index, value) fn peekable(self) -> Peekable fn skip_while(self, predicate: P) -> SkipWhile fn take_while(self, predicate: P) -> TakeWhile fn map_while(self, predicate: P) -> MapWhile fn skip(self, n: usize) -> Skip fn take(self, n: usize) -> Take fn scan(self, initial_state: St, f: F) -> Scan fn flat_map(self, f: F) -> FlatMap fn flatten(self) -> Flatten fn fuse(self) -> Fuse fn inspect(self, f: F) -> Inspect fn by_ref(&mut self) -> &mut Self fn collect>(self) -> B fn try_collect(&mut self) -> ChangeOutputType fn partition(self, f: F) -> (B, B) fn partition_in_place(mut self, ref mut predicate: P) -> usize fn is_partitioned(mut self, mut predicate: P) -> bool fn try_fold(&mut self, init: B, mut f: F) -> R fn try_for_each(&mut self, f: F) -> R fn fold(mut self, init: B, mut f: F) -> B fn reduce(mut self, f: F) -> Option fn try_reduce(&mut self, f: F) -> ChangeOutputType> fn all(&mut self, f: F) -> bool fn any(&mut self, f: F) -> bool fn find(&mut self, predicate: P) -> Option fn find_map(&mut self, f: F) -> Option fn try_find(&mut self, f: F) -> ChangeOutputType> fn position(&mut self, predicate: P) -> Option fn rposition(&mut self, predicate: P) -> Option fn max(self) -> Option fn min(self) -> Option fn max_by_key(self, f: F) -> Option fn max_by(self, compare: F) -> Option fn min_by_key(self, f: F) -> Option fn min_by(self, compare: F) -> Option fn rev(self) -> Rev fn unzip(self) -> (FromA, FromB) fn copied(self) -> Copied fn cloned(self) -> Cloned fn cycle(self) -> Cycle fn sum(self) -> S fn product(self) -> P fn cmp(self, other: I) -> Ordering fn cmp_by(mut self, other: I, mut cmp: F) -> Ordering fn partial_cmp(self, other: I) -> Option fn partial_cmp_by(mut self, other: I, mut partial_cmp: F) -> Option fn eq(self, other: I) -> bool fn eq_by(mut self, other: I, mut eq: F) -> bool fn ne(self, other: I) -> bool fn lt(self, other: I) -> bool fn le(self, other: I) -> bool fn gt(self, other: I) -> bool fn ge(self, other: I) -> bool fn is_sorted(self) -> bool fn is_sorted_by(mut self, compare: F) -> bool fn is_sorted_by_key(self, f: F) -> bool } 比较常用的Iterator方法 filter: 对Self的关联类型的借用&Self::Item调用闭包函数, 返回另一个Iterator map: 也是返回另一个Iterator 最后collect: 把Iterator\"重组\"成一个collect对象. collect filter在前面讲过. 这里看一下collect: collect基础用法如下: let a = [1, 2, 3]; let doubled: Vec = a.iter() .map(|&x| x * 2) .collect(); assert_eq!(vec![2, 4, 6], doubled); 注意, 目标变量doubled需要显式指定类型, 要不然collect不知道你要\"重组\"成什么样的collect对象. 常用的就是collect成Vec. 下面是Iterator的默认collect实现: //这里面很晦涩, collect返回一个泛型B, 这个B是要满足`FromIterator`即Iterator的关联类型实例化的`FromIterator` //这个B是编译器自己推断的, 或者根据左值(比如上面的let doubled: Vec), 或者用户指定, 比如更上面的.collect::>(); fn collect>(self) -> B where Self: Sized, { //这里trait名称::trait函数这个调用方式看起来无比奇怪, 有点自己调用自己的意思 //但我理解下面的FromIterator已经是个具体的类型, 由编译器自动推导出来的: //比如上面的左值let doubled: Vec, 到这里就应该是调用Vec的from_iter FromIterator::from_iter(self) } //这里是说要想满足FromIterator这个trait, 就必须实现from_iter这个函数; //而from_iter这个函数入参是个满足泛型T约束的iter, 这个T需要是个IntoIterator(一般的容器类型(collect类型)都实现了IntoIterator) pub trait FromIterator: Sized { fn from_iter>(iter: T) -> Self; } 到这里就清楚了, 对左值let doubled: Vec的用.collect方法生成的情况, 最后调用的是Vec的from_iter()函数 impl FromIterator for Vec { #[inline] fn from_iter>(iter: I) -> Vec { >::from_iter(iter.into_iter()) } } 这里把Self转换成了SpecFromIter, 实例化后是SpecFromIter 而这里的I::IntoIter其实就是变量a的类型vec的IntoIter SpecFromIter说的是要干一件从IntoIter I到Self的事. pub(super) trait SpecFromIter { fn from_iter(iter: I) -> Self; } impl SpecFromIter for Vec where I: Iterator, { default fn from_iter(iterator: I) -> Self { SpecFromIterNested::from_iter(iterator) } } 最后调用到: pub(super) trait SpecFromIterNested { fn from_iter(iter: I) -> Self; } impl SpecFromIterNested for Vec where I: Iterator, { default fn from_iter(mut iterator: I) -> Self { // Unroll the first iteration, as the vector is going to be // expanded on this iteration in every case when the iterable is not // empty, but the loop in extend_desugared() is not going to see the // vector being full in the few subsequent loop iterations. // So we get better branch prediction. let mut vector = match iterator.next() { None => return Vec::new(), Some(element) => { let (lower, _) = iterator.size_hint(); let initial_capacity = cmp::max(RawVec::::MIN_NON_ZERO_CAP, lower.saturating_add(1)); let mut vector = Vec::with_capacity(initial_capacity); unsafe { // SAFETY: We requested capacity at least 1 ptr::write(vector.as_mut_ptr(), element); vector.set_len(1); } vector } }; // must delegate to spec_extend() since extend() itself delegates // to spec_from for empty Vecs as SpecExtend>::spec_extend(&mut vector, iterator); vector } } IntoIterator IntoIterator的关联类型type IntoIter是个trait, 即这个关联类型的具体类型要符合Iterator约束. pub trait IntoIterator { /// The type of the elements being iterated over. type Item; /// Which kind of iterator are we turning this into? type IntoIter: Iterator; fn into_iter(self) -> Self::IntoIter; } 自己实现IntoIterator // A sample collection, that's just a wrapper over Vec #[derive(Debug)] struct MyCollection(Vec); // Let's give it some methods so we can create one and add things // to it. impl MyCollection { fn new() -> MyCollection { MyCollection(Vec::new()) } fn add(&mut self, elem: i32) { self.0.push(elem); } } // and we'll implement IntoIterator impl IntoIterator for MyCollection { type Item = i32; type IntoIter = std::vec::IntoIter; //注意这里实例化了IntoIter类型 fn into_iter(self) -> Self::IntoIter { self.0.into_iter() } } // Now we can make a new collection... let mut c = MyCollection::new(); // ... add some stuff to it ... c.add(0); c.add(1); c.add(2); // ... and then turn it into an Iterator: for (i, n) in c.into_iter().enumerate() { assert_eq!(i as i32, n); } 比如BTreeMap就实现了into_iter的方法 impl IntoIterator for &'a BTreeMap { type Item = (&'a K, &'a V); type IntoIter = Iter; fn into_iter(self) -> Iter { self.iter() } } 可以看到BTreeMap的into_iter其实就是self.iter(), 反回的都是Iter这个结构体(这个结构体实现了Iterator). 数组泛型的方法impl [T] 数组泛型实现了多种方法, 比如join. impl [T] { pub fn sort(&mut self) where T: Ord, pub fn sort_by(&mut self, mut compare: F) where F: FnMut(&T, &T) -> Ordering, pub fn sort_by_key(&mut self, mut f: F) where F: FnMut(&T) -> K, K: Ord, pub fn sort_by_cached_key(&mut self, f: F) where F: FnMut(&T) -> K, K: Ord, pub fn to_vec(&self) -> Vec where T: Clone, pub fn to_vec_in(&self, alloc: A) -> Vec where T: Clone, pub fn into_vec(self: Box) -> Vec pub fn repeat(&self, n: usize) -> Vec where T: Copy, pub fn concat(&self) -> >::Output where Self: Concat, pub fn join(&self, sep: Separator) -> >::Output where Self: Join, //这里首先约束Self是Join { Join::join(self, sep) //这里调用了约束的join函数. } pub fn connect(&self, sep: Separator) -> >::Output where Self: Join, } 但因为T是泛型, 要实现有用的方法, 比如对T进行约束. 比如join就要求[T]满足:Self: Join pub trait Join { /// The resulting type after concatenation type Output; /// Implementation of [`[T]::join`](slice::join) fn join(slice: &Self, sep: Separator) -> Self::Output; } 注意上面的Separator是泛型的类型指示符, 指代具体类型. 上面的例子非常有趣, 泛型[T]实现了join方法, 而这个join方法看起来又调用了\"Self\"的join. 是Self有两套join实现吗? -- 是. [T]有join方法, 没毛病. 而[V]实现了Join trait, 也实现了join函数. 如下: impl> Join for [V] { type Output = Vec; fn join(slice: &Self, sep: &T) -> Vec { let mut iter = slice.iter(); let first = match iter.next() { Some(first) => first, None => return vec![], }; let size = slice.iter().map(|v| v.borrow().len()).sum::() + slice.len() - 1; let mut result = Vec::with_capacity(size); result.extend_from_slice(first.borrow()); for v in iter { result.push(sep.clone()); result.extend_from_slice(v.borrow()) } result } } 这是两套语义, rust并没有因为看见Self有join方法, 就像go一样, 自动推断Self实现了Join trait; 相反的, 用户需要明确声明, 我实现了Join trait(for 关键词). 这种情况下, 会同时存在两套join. 在本例中, 前者还调用了后者. 这不是多此一举吗? 一个同名的join调来调去有意思吗? --不是. 有意思. 因为Separator不同, 实际调用的Join trait也不同. 比如如果Separator是&T, 就需要实现Join的trait. 代码见上面 如果Separator是&[T], 就需要实现Join的trait, 如下: impl> Join for [V] { type Output = Vec; fn join(slice: &Self, sep: &[T]) -> Vec { let mut iter = slice.iter(); let first = match iter.next() { Some(first) => first, None => return vec![], }; let size = slice.iter().map(|v| v.borrow().len()).sum::() + sep.len() * (slice.len() - 1); let mut result = Vec::with_capacity(size); result.extend_from_slice(first.borrow()); for v in iter { result.extend_from_slice(sep); result.extend_from_slice(v.borrow()) } result } } 比如字符串的: impl> Join for [S] { type Output = String; fn join(slice: &Self, sep: &str) -> String { unsafe { String::from_utf8_unchecked(join_generic_copy(slice, sep.as_bytes())) } } } Vec Vec结构体: pub struct Vec { buf: RawVec, len: usize, } 方法: impl Vec { pub const fn new() -> Self pub fn with_capacity(capacity: usize) -> Self pub unsafe fn from_raw_parts(ptr: *mut T, length: usize, capacity: usize) -> Self } 带allocator的Vec有更多的方法: impl Vec { pub const fn new_in(alloc: A) -> Self pub fn with_capacity_in(capacity: usize, alloc: A) -> Self pub fn capacity(&self) -> usize pub fn reserve(&mut self, additional: usize) pub fn try_reserve(&mut self, additional: usize) -> Result pub fn shrink_to_fit(&mut self) pub fn shrink_to(&mut self, min_capacity: usize) pub fn into_boxed_slice(mut self) -> Box pub fn truncate(&mut self, len: usize) pub fn as_slice(&self) -> &[T] pub fn as_mut_slice(&mut self) -> &mut [T] pub fn as_ptr(&self) -> *const T pub fn allocator(&self) -> &A pub unsafe fn set_len(&mut self, new_len: usize) pub fn swap_remove(&mut self, index: usize) -> T pub fn insert(&mut self, index: usize, element: T) pub fn remove(&mut self, index: usize) -> T pub fn retain(&mut self, mut f: F) pub fn dedup_by(&mut self, mut same_bucket: F) pub fn push(&mut self, value: T) pub fn pop(&mut self) -> Option pub fn append(&mut self, other: &mut Self) pub fn drain(&mut self, range: R) -> Drain //返回一个iterator, 包括range内的所有元素 pub fn clear(&mut self) //移出所有元素 pub fn len(&self) -> usize pub fn is_empty(&self) -> bool pub fn split_off(&mut self, at: usize) -> Self pub fn resize_with(&mut self, new_len: usize, f: F) pub fn leak(self) -> &'a mut [T] } 更具化的泛型 impl Vec { pub fn resize(&mut self, new_len: usize, value: T) pub fn extend_from_slice(&mut self, other: &[T]) pub fn extend_from_within(&mut self, src: R) } Vec实现了解引用 impl ops::Deref for Vec { type Target = [T]; fn deref(&self) -> &[T] { unsafe { slice::from_raw_parts(self.as_ptr(), self.len) } } } Option Option的方法如下: impl Option { pub const fn is_some(&self) -> bool pub fn is_some_with(&self, f: impl FnOnce(&T) -> bool) -> bool pub const fn is_none(&self) -> bool pub const fn as_ref(&self) -> Option pub const fn as_mut(&mut self) -> Option pub const fn as_pin_ref(self: Pin) -> Option> pub const fn as_pin_mut(self: Pin) -> Option> pub const fn expect(self, msg: &str) -> T pub const fn unwrap(self) -> T pub const fn unwrap_or(self, default: T) -> T pub const fn map(self, f: F) -> Option pub const fn filter(self, predicate: P) -> Self pub const fn inspect(self, f: F) -> Self pub const fn ok_or(self, err: E) -> Result pub const fn iter(&self) -> Iter pub const fn and_then(self, f: F) -> Option pub const fn and(self, optb: Option) -> Option pub const fn or(self, optb: Option) -> Option pub const fn or_else(self, f: F) -> Option pub const fn xor(self, optb: Option) -> Option pub const fn insert(&mut self, value: T) -> &mut T pub const fn get_or_insert(&mut self, value: T) -> &mut T pub const fn take(&mut self) -> Option pub const fn replace(&mut self, value: T) -> Option pub const fn contains(&self, x: &U) -> bool pub const fn zip(self, other: Option) -> Option } Result Result是经常用的rust抽象, 用于返回值的处理, 很优雅. 代码在lib/rustlib/src/rust/library/core/src/result.rs #[derive(Copy, PartialEq, PartialOrd, Eq, Ord, Debug, Hash)] pub enum Result { /// Contains the success value #[lang = \"Ok\"] Ok(#[stable(feature = \"rust1\", since = \"1.0.0\")] T), /// Contains the error value #[lang = \"Err\"] Err(#[stable(feature = \"rust1\", since = \"1.0.0\")] E), } Result的方法: impl Result { pub const fn is_ok(&self) -> bool /// let x: Result = Ok(2); /// assert_eq!(x.is_ok_with(|&x| x > 1), true); /// /// let x: Result = Ok(0); /// assert_eq!(x.is_ok_with(|&x| x > 1), false); /// /// let x: Result = Err(\"hey\"); /// assert_eq!(x.is_ok_with(|&x| x > 1), false); pub fn is_ok_with(&self, f: impl FnOnce(&T) -> bool) -> bool pub const fn is_err(&self) -> bool /// let x: Result = Err(Error::new(ErrorKind::NotFound, \"!\")); /// assert_eq!(x.is_err_with(|x| x.kind() == ErrorKind::NotFound), true); /// /// let x: Result = Err(Error::new(ErrorKind::PermissionDenied, \"!\")); /// assert_eq!(x.is_err_with(|x| x.kind() == ErrorKind::NotFound), false); /// /// let x: Result = Ok(123); /// assert_eq!(x.is_err_with(|x| x.kind() == ErrorKind::NotFound), false); pub fn is_err_with(&self, f: impl FnOnce(&E) -> bool) -> bool pub fn ok(self) -> Option //把Result转换为Option pub fn err(self) -> Option pub const fn as_ref(&self) -> Result pub const fn as_mut(&mut self) -> Result //调用F把Result转为Result pub fn map U>(self, op: F) -> Result pub fn map_or U>(self, default: U, f: F) -> U pub fn map_or_else U, F: FnOnce(T) -> U>(self, default: D, f: F) -> U pub fn map_err F>(self, op: O) -> Result pub fn inspect(self, f: F) -> Self pub fn inspect_err(self, f: F) -> Self /// let x: Result = Ok(\"hello\".to_string()); /// let y: Result = Ok(\"hello\"); /// assert_eq!(x.as_deref(), y); /// /// let x: Result = Err(42); /// let y: Result = Err(&42); pub fn as_deref(&self) -> Result where T: Deref, pub fn iter(&self) -> Iter pub fn iter_mut(&mut self) -> IterMut //返回Ok里面的T, 如果Error就panic pub fn expect(self, msg: &str) -> T where E: fmt::Debug, // unwrap也返回T, 也可能panic, 但似乎就没有panic message pub fn unwrap(self) -> T where E: fmt::Debug, // 也是unwrap, 但不panic, 不Ok就返回default pub fn unwrap_or_default(self) -> T where T: Default, //unwrap不panic, 不ok则返回指定的default pub fn unwrap_or(self, default: T) -> T pub fn unwrap_or_else T>(self, op: F) -> T // 实际上是unwrap E pub fn expect_err(self, msg: &str) -> E where T: fmt::Debug, pub fn unwrap_err(self) -> E where T: fmt::Debug, pub fn into_ok(self) -> T where E: Into, pub fn into_err(self) -> E where T: Into, // and表示检测x, y中只要有Error, 就返回Error /// let x: Result = Ok(2); /// let y: Result = Err(\"late error\"); /// assert_eq!(x.and(y), Err(\"late error\")); pub fn and(self, res: Result) -> Result /// assert_eq!(Ok(2).and_then(sq_then_to_string), Ok(4.to_string())); /// assert_eq!(Err(\"not a number\").and_then(sq_then_to_string), Err(\"not a number\")); pub fn and_then Result>(self, op: F) -> Result pub fn or(self, res: Result) -> Result pub fn or_else Result>(self, op: O) -> Result /// let x: Result = Ok(2); /// assert_eq!(x.contains(&2), true); /// /// let x: Result = Ok(3); /// assert_eq!(x.contains(&2), false); /// /// let x: Result = Err(\"Some error message\"); /// assert_eq!(x.contains(&2), false); pub fn contains(&self, x: &U) -> bool where U: PartialEq, } 注: const fn表示这个fn可以用在const上下文中 Result的方法 Result也能调用Result的方法, 比如下面copied函数中, 直接用了self.map, 因为Result是个范围很广的泛型, 自然也就包括了Result, 这里要把T看成是&T' impl Result { pub fn copied(self) -> Result where T: Copy, { self.map(|&t| t) //注意这里, map的F是FnOnce(T), 是针对Result来说的; 这里应该传入\"&T\", 那么形式上&t就是T, 然后返回t就是返回T. 看起来挺难理解的... } pub fn cloned(self) -> Result where T: Clone, { self.map(|t| t.clone()) //这里就没有那么绕, t就是&T } } 其他Result impl Result impl Result, E> impl Result, E> impl Result Result实现了如下的trait impl Clone for Result impl IntoIterator for Result impl IntoIterator for &'a Result impl IntoIterator for &'a mut Result env // 这个就是golang的os.args let args: Vec = env::args().collect(); 取消impl trait 就是取消 取消 取消! impl !Send for Args {} impl !Sync for Args {} 文件 lib/rustlib/src/rust/library/std/src/fs.rs 使用举例 写文件 use std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut file = File::create(\"foo.txt\")?; file.write_all(b\"Hello, world!\")?; Ok(()) } 读文件到String use std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut file = File::open(\"foo.txt\")?; let mut contents = String::new(); file.read_to_string(&mut contents)?; assert_eq!(contents, \"Hello, world!\"); Ok(()) } 注意这里, file.read_to_string(), file对象impl Read, 有read_to_string()方法, 就在本文件; 而vscode点击进去, 却是lib/rustlib/src/rust/library/std/src/io/mod.rs中io:Read这个trait的默认实现. 更有效率的读文件 use std::fs::File; use std::io::BufReader; use std::io::prelude::*; fn main() -> std::io::Result { let file = File::open(\"foo.txt\")?; let mut buf_reader = BufReader::new(file); let mut contents = String::new(); buf_reader.read_to_string(&mut contents)?; assert_eq!(contents, \"Hello, world!\"); Ok(()) } 不同选项open let file = OpenOptions::new() .read(true) .write(true) .create(true) .open(\"foo.txt\"); &File也能modify 文件 Note that, although read and write methods require a &mut File, because of the interfaces for [Read] and [Write], the holder of a &File can still modify the file, either through methods that take &File or by retrieving the underlying OS object and modifying the file that way. Additionally, many operating systems allow concurrent modification of files by different processes. Avoid assuming that holding a &File means that the file will not change. 这里是说read和write方法都要求&mut File, 但实际上, &File的持有者也可以修改文件. 这里提醒大家不要认为持有&File的人就\"没危险\"了, 他们也可以修改你的文件, 因为文件系统允许多进程打开一个文件. File对象 pub struct File { inner: fs_imp::File, } 还有几个\"辅助\"元组对象定义: pub struct Metadata(fs_imp::FileAttr); pub struct ReadDir(fs_imp::ReadDir); pub struct DirEntry(fs_imp::DirEntry); pub struct OpenOptions(fs_imp::OpenOptions); pub struct Permissions(fs_imp::FilePermissions); pub struct FileType(fs_imp::FileType); pub struct DirBuilder { inner: fs_imp::DirBuilder, recursive: bool, } 常用函数 读所有文件内容到Vec pub fn read>(path: P) -> io::Result>use std::fs; use std::net::SocketAddr; fn main() -> Result> { let foo: SocketAddr = String::from_utf8_lossy(&fs::read(\"address.txt\")?).parse()?; Ok(()) } 读所有文件内容到String pub fn read_to_string>(path: P) -> io::Resultuse std::fs; use std::net::SocketAddr; use std::error::Error; fn main() -> Result> { let foo: SocketAddr = fs::read_to_string(\"address.txt\")?.parse()?; Ok(()) } 简单的写slice到文件 pub fn write, C: AsRef>(path: P, contents: C) -> io::Resultuse std::fs; fn main() -> std::io::Result { fs::write(\"foo.txt\", b\"Lorem ipsum\")?; //&str可以被认为是AsRef fs::write(\"bar.txt\", \"dolor sit\")?; Ok(()) } remove文件 pub fn remove_file>(path: P) -> io::Resultuse std::fs; fn main() -> std::io::Result { fs::remove_file(\"a.txt\")?; Ok(()) } metadatafn main() -> std::io::Result { let attr = fs::metadata(\"/some/file/path.txt\")?; // inspect attr ... Ok(()) } symlink_metadata rename copy hard_link soft_link read_link canonicalize 可能和abs path差不多 create_dir create_dir_all remove_dir remove_dir_all read_dir 例子1use std::io; use std::fs::{self, DirEntry}; use std::path::Path; // one possible implementation of walking a directory only visiting files fn visit_dirs(dir: &Path, cb: &dyn Fn(&DirEntry)) -> io::Result { if dir.is_dir() { for entry in fs::read_dir(dir)? { let entry = entry?; let path = entry.path(); if path.is_dir() { visit_dirs(&path, cb)?; } else { cb(&entry); } } } Ok(()) } 例子2use std::{fs, io}; fn main() -> io::Result { let mut entries = fs::read_dir(\".\")? .map(|res| res.map(|e| e.path())) .collect::, io::Error>>()?; // The order in which `read_dir` returns entries is not guaranteed. If reproducible // ordering is required the entries should be explicitly sorted. entries.sort(); // The entries have now been sorted by their path. Ok(()) } set_permissionsuse std::fs; fn main() -> std::io::Result { let mut perms = fs::metadata(\"foo.txt\")?.permissions(); perms.set_readonly(true); fs::set_permissions(\"foo.txt\", perms)?; Ok(()) } File的方法 impl File { } open pub fn open>(path: P) -> io::Resultuse std::fs::File; fn main() -> std::io::Result { let mut f = File::open(\"foo.txt\")?; Ok(()) } create pub fn create>(path: P) -> io::Resultuse std::fs::File; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; Ok(()) } options pub fn options() -> OpenOptionsuse std::fs::File; fn main() -> std::io::Result { let mut f = File::options().append(true).open(\"example.log\")?; Ok(()) } sync_all 就是fsync pub fn sync_all(&self) -> io::Resultuse std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; f.write_all(b\"Hello, world!\")?; f.sync_all()?; Ok(()) } sync_data 比sync_all少一些disk操作 pub fn sync_data(&self) -> io::Resultuse std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; f.write_all(b\"Hello, world!\")?; f.sync_data()?; Ok(()) } set_len 设文件大小, 若原本size小, 就shrink文件到新size; 如果原size小, 则剩下的都填0use std::fs::File; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; f.set_len(10)?; Ok(()) } metadata try_clone set_permissions 其他impl的trait impl AsInner for File impl FromInner for File impl IntoInner for File impl fmt::Debug for File 根据注释, 还实现了比如AsFd等trait. 但不知道藏在哪里实现的??? // In addition to the `impl`s here, `File` also has `impl`s for // `AsFd`/`From`/`Into` and // `AsRawFd`/`IntoRawFd`/`FromRawFd`, on Unix and WASI, and // `AsHandle`/`From`/`Into` and // `AsRawHandle`/`IntoRawHandle`/`FromRawHandle` on Windows. 实现Read trait pub struct File { inner: fs_imp::File, } 这里显得很啰嗦, 基本都是调用inner的对应函数. 因为File包括了inner. 因为rust没有继承就要再写一遍wrapper吗??? impl Read for File { fn read(&mut self, buf: &mut [u8]) -> io::Result { self.inner.read(buf) } fn read_vectored(&mut self, bufs: &mut [IoSliceMut]) -> io::Result { self.inner.read_vectored(bufs) } fn read_buf(&mut self, buf: &mut ReadBuf) -> io::Result { self.inner.read_buf(buf) } #[inline] fn is_read_vectored(&self) -> bool { self.inner.is_read_vectored() } // Reserves space in the buffer based on the file size when available. fn read_to_end(&mut self, buf: &mut Vec) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_end(self, buf) } // Reserves space in the buffer based on the file size when available. fn read_to_string(&mut self, buf: &mut String) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_string(self, buf) } } 实现Write trait impl Write for File { fn write(&mut self, buf: &[u8]) -> io::Result { self.inner.write(buf) } fn write_vectored(&mut self, bufs: &[IoSlice]) -> io::Result { self.inner.write_vectored(bufs) } #[inline] fn is_write_vectored(&self) -> bool { self.inner.is_write_vectored() } fn flush(&mut self) -> io::Result { self.inner.flush() } } 实现Seek trait impl Seek for File { fn seek(&mut self, pos: SeekFrom) -> io::Result { self.inner.seek(pos) } } Read Write Seek for &File又来一遍!!!!! 有意思吗? impl Read for &File { fn read(&mut self, buf: &mut [u8]) -> io::Result { self.inner.read(buf) } fn read_buf(&mut self, buf: &mut ReadBuf) -> io::Result { self.inner.read_buf(buf) } fn read_vectored(&mut self, bufs: &mut [IoSliceMut]) -> io::Result { self.inner.read_vectored(bufs) } #[inline] fn is_read_vectored(&self) -> bool { self.inner.is_read_vectored() } // Reserves space in the buffer based on the file size when available. fn read_to_end(&mut self, buf: &mut Vec) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_end(self, buf) } // Reserves space in the buffer based on the file size when available. fn read_to_string(&mut self, buf: &mut String) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_string(self, buf) } } open最后调用 use crate::sys::fs as fs_imp; fn _open(&self, path: &Path) -> io::Result { fs_imp::File::open(path, &self.0).map(|inner| File { inner }) } fs_imp::File::open代码在lib/rustlib/src/rust/library/std/src/sys/unix/fs.rs 里面调用了很多libc的函数. IO 常用函数 pub fn read_to_string(mut reader: R) -> Result //这个是内部使用的函数 fn read_until(r: &mut R, delim: u8, buf: &mut Vec) -> Result Read trait pub trait Read { /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = [0; 10]; /// /// // read up to 10 bytes /// let n = f.read(&mut buffer[..])?; /// /// println!(\"The bytes: {:?}\", &buffer[..n]); /// Ok(()) /// } //也是传入一个[u8]的数组, 返回大小 fn read(&mut self, buf: &mut [u8]) -> Result; //vector方式读 fn read_vectored(&mut self, bufs: &mut [IoSliceMut]) -> Result { default_read_vectored(|b| self.read(b), bufs) } //有没有vector读, 默认false fn is_read_vectored(&self) -> bool { false } /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = Vec::new(); /// /// // read the whole file /// f.read_to_end(&mut buffer)?; /// Ok(()) /// } //读完所有byte fn read_to_end(&mut self, buf: &mut Vec) -> Result { default_read_to_end(self, buf) } /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = String::new(); /// /// f.read_to_string(&mut buffer)?; /// Ok(()) /// } //读完所有string fn read_to_string(&mut self, buf: &mut String) -> Result { default_read_to_string(self, buf) } /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = [0; 10]; /// /// // read exactly 10 bytes /// f.read_exact(&mut buffer)?; /// Ok(()) /// } //一直读到size fn read_exact(&mut self, buf: &mut [u8]) -> Result { default_read_exact(self, buf) } //read到ReadBuf fn read_buf(&mut self, buf: &mut ReadBuf) -> Result { default_read_buf(|b| self.read(b), buf) } fn read_buf_exact(&mut self, buf: &mut ReadBuf) -> Result //借用 fn by_ref(&mut self) -> &mut Self //把这个Read转换为byte iterator fn bytes(self) -> Bytes /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f1 = File::open(\"foo.txt\")?; /// let mut f2 = File::open(\"bar.txt\")?; /// /// let mut handle = f1.chain(f2); /// let mut buffer = String::new(); /// /// // read the value into a String. We could use any Read method here, /// // this is just one example. /// handle.read_to_string(&mut buffer)?; /// Ok(()) /// } //和next Read成链, 先读Self, 接着读next fn chain(self, next: R) -> Chain /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = [0; 5]; /// /// // read at most five bytes /// let mut handle = f.take(5); /// /// handle.read(&mut buffer)?; /// Ok(()) /// } //返回一个新的Read, 但只读limit字节 fn take(self, limit: u64) -> Take } Write trait pub trait Write { //很自然的, 这里的buf是个借用 //和read一样, write也可以部分写 fn write(&mut self, buf: &[u8]) -> Result; fn write_vectored(&mut self, bufs: &[IoSlice]) -> Result fn is_write_vectored(&self) -> bool //这个flush是write独有的 fn flush(&mut self) -> Result; //全写 fn write_all(&mut self, mut buf: &[u8]) -> Result fn write_all_vectored(&mut self, mut bufs: &mut [IoSlice]) -> Result //写格式化string到Write fn write_fmt(&mut self, fmt: fmt::Arguments) -> Result fn by_ref(&mut self) -> &mut Self } Seek trait pub trait Seek { fn seek(&mut self, pos: SeekFrom) -> Result; //从头开始 fn rewind(&mut self) -> Result //返回这个stream的字节数 fn stream_len(&mut self) -> Result //stream的当前位置 fn stream_position(&mut self) -> Result } BufRead是Read的派生trait BufRead自带内部buffer 比如stdin.lock()就实现了BufRead use std::io; use std::io::prelude::*; let stdin = io::stdin(); for line in stdin.lock().lines() { println!(\"{}\", line.unwrap()); } 比如可以用BufReader::new(r)把Reader r转换为BufReader use std::io::{self, BufReader}; use std::io::prelude::*; use std::fs::File; fn main() -> io::Result { let f = File::open(\"foo.txt\")?; let f = BufReader::new(f); for line in f.lines() { println!(\"{}\", line.unwrap()); } Ok(()) } 下面是BufRead的定义: pub trait BufRead: Read { //读出内部buffer, 并从内部reader填入新数据 fn fill_buf(&mut self) -> Result; //amt数量的字节已经被consume了 fn consume(&mut self, amt: usize); fn has_data_left(&mut self) -> Result fn read_until(&mut self, byte: u8, buf: &mut Vec) -> Result fn read_line(&mut self, buf: &mut String) -> Result //返回一个按照分隔符byte分割的iterator fn split(self, byte: u8) -> Split //返回按行分隔的iterator fn lines(self) -> Lines } "},"notes/rust_代码小段.html":{"url":"notes/rust_代码小段.html","title":"代码小段","keywords":"","body":" micro_http channel in channel epoll 反序列化到结构体 match语句块做为值 命令行参数拿到文件名并读出其中字符串 从Vec到Vec 从&str返回任意类型 map_err(Error::Arch)? json文件 compile 序列化 Err的使用方法 micro_http 用的是 micro_http = { git = \"https://github.com/firecracker-microvm/micro-http\", branch = \"main\" } // 起http线程, 用的是micro_http的库 api::start_http_path_thread() let server = HttpServer::new_from_fd() start_http_thread(server) hread::Builder::new() //新线程 loop { match server.requests() { Ok(request_vec) => { for server_request in request_vec { server.respond(server_request.process( |request| { handle_http_request(request, &api_notifier, &api_sender) } )) } } } } 处理就是从全局url路由表中get route 即HTTP_ROUTES.routes.get(&path), 然后调用route的handle_request函数, 即调用route.handle_request(): fn handle_http_request( request: &Request, api_notifier: &EventFd, api_sender: &Sender, ) -> Response { let path = request.uri().get_abs_path().to_string(); let mut response = match HTTP_ROUTES.routes.get(&path) { Some(route) => match api_notifier.try_clone() { Ok(notifier) => route.handle_request(request, notifier, api_sender.clone()), Err(_) => error_response( HttpError::InternalServerError, StatusCode::InternalServerError, ), }, None => error_response(HttpError::NotFound, StatusCode::NotFound), }; response.set_server(\"Cloud Hypervisor API\"); response.set_content_type(MediaType::ApplicationJson); response } 全局变量route是提前静态注册好的: HTTP_ROUTES是个全局变量 lazy_static! { /// HTTP_ROUTES contain all the cloud-hypervisor HTTP routes. pub static ref HTTP_ROUTES: HttpRoutes = { let mut r = HttpRoutes { routes: HashMap::new(), }; r.routes.insert(endpoint!(\"/vm.add-device\"), Box::new(VmActionHandler::new(VmAction::AddDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-user-device\"), Box::new(VmActionHandler::new(VmAction::AddUserDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-disk\"), Box::new(VmActionHandler::new(VmAction::AddDisk(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-fs\"), Box::new(VmActionHandler::new(VmAction::AddFs(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-net\"), Box::new(VmActionHandler::new(VmAction::AddNet(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-pmem\"), Box::new(VmActionHandler::new(VmAction::AddPmem(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vdpa\"), Box::new(VmActionHandler::new(VmAction::AddVdpa(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vsock\"), Box::new(VmActionHandler::new(VmAction::AddVsock(Arc::default())))); r.routes.insert(endpoint!(\"/vm.boot\"), Box::new(VmActionHandler::new(VmAction::Boot))); r.routes.insert(endpoint!(\"/vm.counters\"), Box::new(VmActionHandler::new(VmAction::Counters))); r.routes.insert(endpoint!(\"/vm.create\"), Box::new(VmCreate {})); r.routes.insert(endpoint!(\"/vm.delete\"), Box::new(VmActionHandler::new(VmAction::Delete))); r.routes.insert(endpoint!(\"/vm.info\"), Box::new(VmInfo {})); r.routes.insert(endpoint!(\"/vm.pause\"), Box::new(VmActionHandler::new(VmAction::Pause))); r.routes.insert(endpoint!(\"/vm.power-button\"), Box::new(VmActionHandler::new(VmAction::PowerButton))); r.routes.insert(endpoint!(\"/vm.reboot\"), Box::new(VmActionHandler::new(VmAction::Reboot))); r.routes.insert(endpoint!(\"/vm.receive-migration\"), Box::new(VmActionHandler::new(VmAction::ReceiveMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.remove-device\"), Box::new(VmActionHandler::new(VmAction::RemoveDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize\"), Box::new(VmActionHandler::new(VmAction::Resize(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize-zone\"), Box::new(VmActionHandler::new(VmAction::ResizeZone(Arc::default())))); r.routes.insert(endpoint!(\"/vm.restore\"), Box::new(VmActionHandler::new(VmAction::Restore(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resume\"), Box::new(VmActionHandler::new(VmAction::Resume))); r.routes.insert(endpoint!(\"/vm.send-migration\"), Box::new(VmActionHandler::new(VmAction::SendMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.shutdown\"), Box::new(VmActionHandler::new(VmAction::Shutdown))); r.routes.insert(endpoint!(\"/vm.snapshot\"), Box::new(VmActionHandler::new(VmAction::Snapshot(Arc::default())))); r.routes.insert(endpoint!(\"/vmm.ping\"), Box::new(VmmPing {})); r.routes.insert(endpoint!(\"/vmm.shutdown\"), Box::new(VmmShutdown {})); r }; } 比如create的处理是这样的: // /api/v1/vm.create handler pub struct VmCreate {} impl EndpointHandler for VmCreate { fn handle_request( &self, req: &Request, api_notifier: EventFd, api_sender: Sender, ) -> Response { match req.method() { Method::Put => { match &req.body { Some(body) => { // Deserialize into a VmConfig let vm_config: VmConfig = match serde_json::from_slice(body.raw()) .map_err(HttpError::SerdeJsonDeserialize) { Ok(config) => config, Err(e) => return error_response(e, StatusCode::BadRequest), }; // Call vm_create() match vm_create(api_notifier, api_sender, Arc::new(Mutex::new(vm_config))) .map_err(HttpError::ApiError) { Ok(_) => Response::new(Version::Http11, StatusCode::NoContent), Err(e) => error_response(e, StatusCode::InternalServerError), } } None => Response::new(Version::Http11, StatusCode::BadRequest), } } _ => error_response(HttpError::BadRequest, StatusCode::BadRequest), } } } channel in channel 使用标准库的channel方法 pub fn channel() -> (Sender, Receiver) 发送方: // 编译器会从下文推断出这个channel传输的是ApiRequest let (api_request_sender, api_request_receiver) = std::sync::mpsc::channel(); // 构造内部channel let (response_sender, response_receiver) = std::sync::mpsc::channel(); api_request_sender .send(ApiRequest::VmCreate(config, response_sender)) .map_err(ApiError::RequestSend)?; //send也会出错, 一般都是对端链接断了 response_receiver.recv().map_err(ApiError::ResponseRecv)??; //这里有两个?, 解开2层Result, 因为外层的Result是recv加的. 上面的ApiRequest是类型下面的enum: pub enum ApiRequest { /// Create the virtual machine. This request payload is a VM configuration /// (VmConfig). /// If the VMM API server could not create the VM, it will send a VmCreate /// error back. VmCreate(Arc>, Sender), /// Boot the previously created virtual machine. /// If the VM was not previously created, the VMM API server will send a /// VmBoot error back. VmBoot(Sender), ... } ApiResponse是: /// This is the response sent by the VMM API server through the mpsc channel. pub type ApiResponse = std::result::Result; epoll 用的是rust的epoll // 新建epoll let mut epoll = EpollContext::new().map_err(Error::Epoll)?; // 底层是epoll create let epoll_fd = epoll::create(true) //增加event. 第一个参数是fd, 第二个是关联的dispatch时候用的token epoll.add_event(&exit_evt, EpollDispatch::Exit) // 底层是epoll ctl, 和c版本一样, ctl add可以给fd绑定一个data // wait let num_events = match epoll::wait(epoll_fd, -1, &mut events[..]) //处理 for event in events.iter().take(num_events) { //这个就是当时add event的时候关联的data let dispatch_event: EpollDispatch = event.data.into(); //根据dispatch_event来分发 // 这样的好处是看到这个token, 就知道是哪个事件了, 就知道用哪个fd match dispatch_event { EpollDispatch::Unknown => { } EpollDispatch::Exit => { } EpollDispatch::Api => { } } } 反序列化到结构体 VmmConfig是个结构体: /// Used for configuring a vmm from one single json passed to the Firecracker process. #[derive(Debug, Default, Deserialize, PartialEq, Serialize)] pub struct VmmConfig { #[serde(rename = \"balloon\")] balloon_device: Option, #[serde(rename = \"drives\")] block_devices: Vec, #[serde(rename = \"boot-source\")] boot_source: BootSourceConfig, #[serde(rename = \"logger\")] logger: Option, #[serde(rename = \"machine-config\")] machine_config: Option, #[serde(rename = \"metrics\")] metrics: Option, #[serde(rename = \"mmds-config\")] mmds_config: Option, #[serde(rename = \"network-interfaces\", default)] net_devices: Vec, #[serde(rename = \"vsock\")] vsock_device: Option, } 用第三方库serde_json来反序列化, 得到结构体 let vmm_config: VmmConfig = serde_json::from_slice::(config_json.as_bytes()) .map_err(Error::InvalidJson)?; from_slice::是实例化泛型函数中T的意思 pub fn from_slice(v: &'a [u8]) -> Result match语句块做为值 // let后面pattern匹配, 匹配的是match语句块的值, 即最后的(res, vmm) let (_, vmm) = match build_microvm_from_json( seccomp_filters, &mut event_manager, // Safe to unwrap since '--no-api' requires this to be set. config_json.unwrap(), instance_info, bool_timer_enabled, mmds_size_limit, metadata_json, ) { Ok((res, vmm)) => (res, vmm), Err(exit_code) => return exit_code, }; 命令行参数拿到文件名并读出其中字符串 两个map搞定: 第一个map传入的函数fs::read_to_string就已经把文件内容读出来了. 第二个map把上面的Option>转换成Option, 出错就panic let vmm_config_json = arguments .single_value(\"config-file\") .map(fs::read_to_string) .map(|x| x.expect(\"Unable to open or read from the configuration file\")); 从Vec到Vec let args = vec![\"binary-name\", \"--exec-file\", \"foo\", \"--help\"] .into_iter() .map(String::from) //这里并没有自己写闭包,而是用了现成的函数 .collect::>(); 从&str返回任意类型 比如要从字符串转换为如下enum /// Supported target architectures. #[allow(non_camel_case_types)] #[derive(Debug, PartialEq, Clone, Copy)] pub(crate) enum TargetArch { /// x86_64 arch x86_64, /// aarch64 arch aarch64, } 代码如下 let target_arch: TargetArch = \"x86_64\".try_into().map_err(Error::Arch)?; try_info是个trait方法, 实现了TryInfo, 而后者是个泛型 pub trait TryInto: Sized { /// The type returned in the event of a conversion error. type Error; /// Performs the conversion. fn try_into(self) -> Result; } 实际上, &str有很多种try_into的实现, 它们都和目标类型有关. 这里的目标类型是自己定义的enum TargetArch 因为TryInfo是个泛型, 所以, 这里自己给&str实现了针对性的try_into: impl TryInto for &str { type Error = TargetArchError; fn try_into(self) -> std::result::Result { match self.to_lowercase().as_str() { \"x86_64\" => Ok(TargetArch::x86_64), \"aarch64\" => Ok(TargetArch::aarch64), _ => Err(TargetArchError::InvalidString(self.to_string())), } } } 这也说明, 在rust里, 可以在自己模块给\"别人\"的类型实现某个trait. 注意这里, 原始trait要求try_into的签名是 fn try_into(self) -> Result 而我们实现的时候, 可以实例化: fn try_into(self) -> std::result::Result map_err(Error::Arch)? 有点奇怪, map_err的入参应该是个函数, 但Error::Arch只是个enum, 这样竟然也行? #[derive(Debug)] enum Error { Bincode(BincodeError), FileOpen(PathBuf, io::Error), FileFormat(FilterFormatError), Json(JSONError), MissingInputFile, MissingTargetArch, Arch(TargetArchError), } json文件 compile 序列化 // &mut dyn Read时trait object吗 fn parse_json(reader: &mut dyn Read) -> Result { //用了serde_json库, 在本crate的cargo.toml里面dependencies有 // 从reader读json, 返回JsonFile // 如果有错误, 转换为本模块的Json错误 serde_json::from_reader(reader).map_err(Error::Json) } fn compile(args: &Arguments) -> Result { //一句话打开文件 let input_file = File::open(&args.input_file) .map_err(|err| Error::FileOpen(PathBuf::from(&args.input_file), err))?; // new一个BufReader let mut input_reader = BufReader::new(input_file); // 从这个input_reader读 let filters = parse_json(&mut input_reader)?; // new一个compiler let compiler = Compiler::new(args.target_arch); // transform the IR into a Map of BPFPrograms let bpf_data: HashMap = compiler .compile_blob(filters.0, args.is_basic) //filters.0是元组tuple的数字下标访问方式 .map_err(Error::FileFormat)?; // serialize the BPF programs & output them to a file let output_file = File::create(&args.output_file) .map_err(|err| Error::FileOpen(PathBuf::from(&args.output_file), err))?; bincode::serialize_into(output_file, &bpf_data).map_err(Error::Bincode)?; Ok(()) } 注: Open以后没有Close, 因为input_file会被move进BufReader::new, 再被move出来, 所有权在这个函数结束的时候会被清理. Err的使用方法 fn main() { let mut arg_parser = build_arg_parser(); //这里和golang的if err := xxx(); err != nil {}意思一样 if let Err(err) = arg_parser.parse_from_cmdline() { eprintln!( \"Arguments parsing error: {} \\n\\n\\ For more information try --help.\", err ); process::exit(EXIT_CODE_ERROR); } if arg_parser.arguments().flag_present(\"help\") { println!(\"Seccompiler-bin v{}\\n\", SECCOMPILER_VERSION); println!(\"{}\", arg_parser.formatted_help()); return; } if arg_parser.arguments().flag_present(\"version\") { println!(\"Seccompiler-bin v{}\\n\", SECCOMPILER_VERSION); return; } let args = get_argument_values(arg_parser.arguments()).unwrap_or_else(|err| { eprintln!( \"{} \\n\\n\\ For more information try --help.\", err ); process::exit(EXIT_CODE_ERROR); }); if let Err(err) = compile(&args) { eprintln!(\"Seccompiler error: {}\", err); process::exit(EXIT_CODE_ERROR); } println!(\"Filter successfully compiled into: {}\", args.output_file); } "},"notes/others.html":{"url":"notes/others.html","title":"其他","keywords":"","body":"其他杂项. "},"notes/rust_mdbook_使用.html":{"url":"notes/rust_mdbook_使用.html","title":"使用mdbook","keywords":"","body":"mdBook是rust写的一个工具, 用来把md文档转成html book.guide: https://rust-lang.github.io/mdBook mdBook本身也是个git repo: https://github.com/rust-lang/mdBook 更新 2022.08 安装 book组织 mdbook使用 book.toml SUMMARY.md build book 更新 2022.08 mdbook不支持中文搜索, 故弃用. 使用gitbook代替gitbook参考:https://github.com/zhangjikai/gitbook-usehttps://github.com/snowdreams1006/snowdreams1006.github.io/blob/master/book.jsonhttps://snowdreams1006.github.io/ 安装 可以直接去github页面下载: https://github.com/rust-lang/mdBook/releases也可以自己编译, 但需要先安装rust编译器 cargo install mdbook cargo命令会自动从crates.io下载mdbook, 编译, 然后安装到cargo的bin目录(默认是~/.cargo/bin/). crates.io上的版本会比github代码稍微滞后一点, 可以指定用github代码编译: cargo install --git https://github.com/rust-lang/mdBook.git mdbook book组织 book由chapter组成, 每个chapter是一个独立的page, chapter可以有子chapter. mdbook使用 # 新建一个book mdbook init my-first-book cd my-first-book # 开启一个webserver, 修改的内容可以自动刷新到web page mdbook serve book.toml 一个book需要几个特殊文件来定义排版和布局. 根目录下的book.toml就是其中一个: 最常用的, 最简单的: [book] title = \"My First Book\" mdbook自己的实例:https://github.com/rust-lang/mdBook/blob/master/guide/book.toml SUMMARY.md 这个文件在src目录下, 定义了chapter结构: # Summary [Introduction](README.md) - [My First Chapter](my-first-chapter.md) - [Nested example](nested/README.md) - [Sub-chapter](nested/sub-chapter.md) 实例: https://github.com/rust-lang/mdBook/blob/master/guide/src/SUMMARY.md build book mdbook build 这个命令会根据md文件在本地book目录下生成html. "},"notes/system_原理杂记.html":{"url":"notes/system_原理杂记.html","title":"原理杂记","keywords":"","body":" seccomp系统调用 系统权限 smaps解析性能 打开smaps文件本身 加上字符串操做 结论 使用其他用户启动进程 改变文件的owner为nobody:nogroup, 设置setuid属性 ruid euid 什么是uid euid? 补充 实验 然后用普通user启动 用root启动 进程的权限是看ruid, 而不是euid golang权限降级 什么是defunct进程? cgroup v2 进程 线程 控制器使能 不推荐动态迁移pid 资源限制类型 控制器类型 CPU 内存 IO PID Cpuset 配置文件交互 和V1的对比 系统内存占用分析 其他统计 vm参数 文件缓存 CPU占用率分析 per CPU统计 user + sys + softirq + idle + iowait = 100 softirq现象 结论 补充 系统调用都会触发调度吗? Preemption and Context Switching User Preemption Kernel Preemption 调度代码 一些系统调用, 可能会阻塞, 此时会触发调度 调度器的参考文章 signal的默认行为和打断系统调用 默认行为 signal和系统调用 内核收报文的时间片算在哪里? 背景: 驱动中断在哪里执行? 中断线程化后的CPU load 到底什么是中断上下文? 软中断上下文 softirq激活 ksoftirqd线程 上下文分类 收报的时间算在哪里? socket什么情况下会发生短读short read/partial read? socket通信的时候, 要在应用侧做字节序转换吗? socket的stream模式和datagram模式有什么不同? socket基础 SOCK_STREAM SOCK_SEQPACKET SOCK_DGRAM man 7 ip man 7 tcp man 7 udp man 7 unix 什么是message boundires? TCP的stream模式怎么定界? cgroup配置 写入pid rt调度域的配额 一些命令 linux调度方式有哪些? 非实时调度 实时调度 preemptive kernel是什么意思? 为什么一直说内核抢占? 嵌入式设备需要抢占吗? 用户态上下文切换和ucontex.h 用户态上下文 例子 使用ucontext.h的api实现用户态协程 多线程的情况下, signal被deliver到哪个线程? 信号处理函数执行的上下文是什么? 为什么能打印当前进程的调用栈? sighandler执行的上下文 sigaltstack函数用于指定sighandler栈 回答 信号处理原理 sigaction pending和blocked向量 signal的产生和投递 signal和系统调用 siglongjmp futex系统调用 libevent主循环处理timer 再议rm 普通用户可以rm root用户的文件 关于热升级, 正在使用的文件可以被rm 用户态通过系统调用陷入到内核态, 内存映射会变吗? uboot传mtdpart的时候，名字从哪来的？ 为什么直接考过来的ls不能用？ fork与malloc seccomp系统调用 很多sandbox机制都使用了这个系统调用, 它是个系统调用的filter机制. #include #include #include #include #include int seccomp(unsigned int operation, unsigned int flags, void *args); seccomp设置calling进程的Secure Computing属性,有几种operation: SECCOMP_SET_MODE_STRICT: 只有基本的read, write, exit和sigreturn可以用. 其他的系统调用会触发SIGKILL SECCOMP_SET_MODE_FILTER: args指向sock_fprog, 这是个bpf的指令, 可以设置任意组合的系统调用filter规则struct sock_fprog { unsigned short len; /* Number of BPF instructions */ struct sock_filter *filter; /* Pointer to array of BPF instructions */ }; struct sock_filter { /* Filter block */ __u16 code; /* Actual filter code */ __u8 jt; /* Jump true */ __u8 jf; /* Jump false */ __u32 k; /* Generic multiuse field */ }; SECCOMP_RET_KILL_PROCESS: 导致进程终止 SECCOMP_RET_KILL_THREAD: 导致调用者线程终止, 其他线程不受影响. SECCOMP_RET_TRAP: 系统调用会触发SIGSYS信号 SECCOMP_RET_ERRNO: SECCOMP_RET_TRACE: SECCOMP_RET_LOG: SECCOMP_RET_ALLOW: 系统权限 man capabilities 权限检查是基于thread的, 特权用户(root, euid=0)的thread不用检查, 其他用户会走权限检查流程. linux权限有很多类, 可以单独打开和关闭 比如 CAP_DAC_OVERRIDE: 有这个属性就可以跳过文件或目录的rwx检查 CAP_DAC_READ_SEARCH: 跳过read属性检查 CAP_KILL: 是否有kill权限 CAP_MKNOD: 是否能创建ssh设备文件 CAP_NET_ADMIN: 网络配置 CAP_NET_RAW: 使用raw socket CAP_SYS_ADMIN: 比如mount, setns, clone等 还有其他很多属性, 见man capabilities 子进程继承父进程的属性 smaps解析性能 我要解析/proc/1/smaps, 它的格式如下: ~ # cat /proc/1/smaps 00010000-00013000 r-xp 00000000 00:02 8237 /usr/bin/s6-svscan Size: 12 kB Rss: 12 kB Pss: 12 kB Shared_Clean: 0 kB Shared_Dirty: 0 kB Private_Clean: 0 kB Private_Dirty: 12 kB Referenced: 12 kB Anonymous: 0 kB AnonHugePages: 0 kB ShmemPmdMapped: 0 kB Shared_Hugetlb: 0 kB Private_Hugetlb: 0 kB Swap: 0 kB SwapPss: 0 kB KernelPageSize: 4 kB MMUPageSize: 4 kB Locked: 0 kB VmFlags: rd ex mr mw me dw 00022000-00023000 r--p 00002000 00:02 8237 /usr/bin/s6-svscan Size: 4 kB Rss: 4 kB Pss: 4 kB Shared_Clean: 0 kB Shared_Dirty: 0 kB Private_Clean: 0 kB Private_Dirty: 4 kB Referenced: 4 kB Anonymous: 4 kB AnonHugePages: 0 kB ShmemPmdMapped: 0 kB Shared_Hugetlb: 0 kB Private_Hugetlb: 0 kB Swap: 0 kB SwapPss: 0 kB KernelPageSize: 4 kB MMUPageSize: 4 kB Locked: 0 kB VmFlags: rd mr mw me dw ac ... 我写了代码把所有Pss: xx kB加起来. CPU消耗很高. 这里的消耗包括打开这个文件本身, 和字符串搜索和转换的消耗. 打开smaps文件本身 只是打开这个文件就已经很高了: htop显示CPU在40到70之间, 均值大概在50.perf发现大部分时间在内核的smaps_account()函数, 这个函数在for里计算每个page, 确实比较耗时. 加上字符串操做 buf, err := os.ReadFile(\"/proc/\" + pid + \"/smaps_rollup\") if err == nil { i := bytes.Index(buf, []byte(\"\\nPss:\")) if i != -1 { buf = buf[i+1:] size, _ := strconv.ParseUint(string(bytes.TrimSpace(buf[4:24])), 10, 64) //fmt.Fprintln(os.Stderr, string(bytes.TrimSpace(buf[4:24])), size) pssSize = size return } } 感觉CPU没有升高多少, 平均也在50+%. 结论 打开\"/proc/\" + pid + \"/smaps_rollup\"或\"/proc/\" + pid + \"/smaps\"本身就很消耗CPU. 因为kernel在open的时候才去调用smaps_account()函数. 使用其他用户启动进程 在shell里手动启动一个可执行程序, 其user是当前的登陆用户. 但有的时候, 比如开一个daemon进程, 不想用自己的用户来启动, 下面是方法: 改变文件的owner为nobody:nogroup, 设置setuid属性 这步需要sudo权限 # nobody和nogroup一般的linux系统都有 sudo chown nobody:nogroup gshell # user和group都要设置setuid属性 sudo chmod ugo+ws gshell # ls -l看到gshell程序已经是nobody:nogroup了, 而且u和g都有s属性 # 我专门把o的w属性也加上了 -rwsrwsrwx 1 nobody nogroup 22610134 Sep 26 01:14 gshell ruid euid 什么是uid euid? 最主要是看man setuid和man seteuid The distinction between a real and an effective user id is made because you may have the need to temporarily take another user's identity (most of the time, that would be root, but it could be any user). If you only had one user id, then there would be no way of changing back to your original user id afterwards (other than taking your word for granted, and in case you are root, using root's privileges to change to any user). So, the real user id is who you really are (the one who owns the process), and the effective user id is what the operating system looks at to make a decision whether or not you are allowed to do something (most of the time, there are some exceptions). When you log in, the login shell sets both the real and effective user id to the same value (your real user id) as supplied by the password file. Now, it also happens that you execute a setuid program, and besides running as another user (e.g. root) the setuid program is also supposed to do something on your behalf. How does this work? After executing the setuid program, it will have your real id (since you're the process owner) and the effective user id of the file owner (for example root) since it is setuid. The program does whatever magic it needs to do with superuser privileges and then wants to do something on your behalf. That means, attempting to do something that you shouldn't be able to do should fail. How does it do that? Well, obviously by changing its effective user id to the real user id! Now that setuid program has no way of switching back since all the kernel knows is your id and... your id. Bang, you're dead. This is what the saved set-user id is for. 参考: https://stackoverflow.com/questions/32455684/difference-between-real-user-id-effective-user-id-and-saved-user-id https://mudongliang.github.io/2020/09/17/ruid-euid-suid-usage-in-linux.html https://stackoverflow.com/questions/33982789/difference-between-euid-suid-and-ruid-in-linux-systems 补充 使用ps -eo user,pid,euid,ruid,suid,cmd | grep gshell可以查看各种id euid EUID effective user ID (alias uid). ruid RUID real user ID. suid SUID saved user ID. (alias svuid). 实验 当我sudo chmod ugo+ws bin/gshell后, 看到 -rwsrwsrwx 1 nobody nogroup 23M Oct 22 05:34 gshell 然后用普通user启动 bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 看到: $ ps -eo user,pid,euid,ruid,suid,cmd | grep gshell nobody 27870 65534 1003 65534 bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 yingjieb 27893 1003 1003 1003 grep gshell 很明显: 普通进程grep, 其euid ruid suid都是一致的, 即都是1003(yingjieb) 但bin/gshell带s属性(即setuid属性), 用普通用户运行, euid和suid是65534(nobody), ruid是启动用户 用root启动 sudo bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 看到: $ ps -eo user,pid,euid,ruid,suid,cmd | grep gshell root 27897 0 0 0 sudo bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 nobody 27898 65534 0 65534 bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 yingjieb 27910 1003 1003 1003 grep gshell 可以看到, 先用root启动了该程序, 但会以nobody fork这个进程运行, fork的进程的euid和suid是nobody, 但ruid还是root. 进程的权限是看ruid, 而不是euid 比如上面的例子, root启动的进程27898, 虽然euid变成了nobody, 但实际该进程还是可以有root权限, 创建删除权限都是root的. 那euid有啥用? golang权限降级 思路是先让bin文件的owner是nobody, 带setuid属性. 然后任何用户启动这个文件, euid都是nobody的. 但ruid还是启动用户的. 要在代码里改ruid: euid := os.Geteuid() if err := syscall.Setreuid(euid, euid); err != nil { return err } 改了ruid后, 再用ps -eo user,pid,euid,ruid,suid,cmd | grep gshell看, 所有的UID都是nobody了. 这个进程就只有nobody权限了. 补充, gid也要设置: ps -eo user,pid,euid,ruid,suid,egid,rgid,sgid,cmd | grep gshell 什么是defunct进程? gshell起了一个自己的new version的进程, 但显示: $ ps -ef | grep gshell yingjieb 6762 9291 2 12:18 pts/9 00:00:02 bin/gshell -wd .working -loglevel debug daemon -registry 10.182.105.138:11985 -bcast 9923 -root -repo gitlabe1.ext.net.nokia.com/godevsig/grepo/master -update http://10.182.105.179:8088/gshell/release/latest/%s yingjieb 6777 6762 0 12:18 pts/9 00:00:00 bin/gshell -wd .working -loglevel debug __start -e master.v1.1.3 yingjieb 6799 6762 0 12:20 pts/9 00:00:00 [gshell] 注意这里的[gshell] 是僵尸进程: Processes marked are dead processes (so-called \"zombies\") that remain because their parent has not destroyed them properly. These processes will be destroyed by init(8) if the parent process exits. 僵尸进程不能被kill, 因为它已经死了. 它还在这里显示是因为其父进程还在, 但没有清理这个死掉的子进程. 对应的go代码: 因为Start()并不会等待并清理子进程. if err := exec.Command(cmdArgs[0], cmdArgs[1:]...).Start(); err != nil { lg.Errorf(\"start new gshell failed: %v\", err) } else { lg.Infof(\"new version gshell started\") } 注: 这里子进程死掉的原因可以用下面的代码捕捉 out, err := exec.Command(cmdArgs[0], cmdArgs[1:]...).Output() lg.Debugf(\"out: %s, err: %v\", out, err) 是因为传入的-update选项新的binary不认识. cgroup v2 https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html mount -t cgroup2 none $MOUNT_POINT 和v1不同, cgroup v2只有一个树结构 一个进程只能属于一个cgroup mkdir $CGROUP_NAME创建一个子cgroup 进程 把进程pid写进cgroup.procs会migrate这个进程到该cgroup, 包括其所有线程. 每次只能写一个PID到cgroup.procs文件, 即一次write系统调用移动一个pid 没有子cgroup并且里面没有pid的cgrouup可以删除: rmdir $CGROUP_NAME 如果里面只有zombie进程, 也是可以删除的 /proc/$PID/cgroup可以显式pid所属的cgroup # cat /proc/842/cgroup ... 0::/test-cgroup/test-cgroup-nested 如果这个cgroup被删除了, 会是这样: 这个情况下, 这个进程一定是个僵尸进程 # cat /proc/842/cgroup ... 0::/test-cgroup/test-cgroup-nested (deleted) 线程 官方解释 cgroup v2 supports thread granularity for a subset of controllers to support use cases requiring hierarchical resource distribution across the threads of a group of processes. By default, all threads of a process belong to the same cgroup, which also serves as the resource domain to host resource consumptions which are not specific to a process or thread. The thread mode allows threads to be spread across a subtree while still maintaining the common resource domain for them. 默认所有线程属于同一个cgroup, 但也支持分属于多个subtree. 就是说在同一个tree下面 支持thread模式的controller叫threaded controllers; 不支持的叫domain controllers 默认创建的cgroup是domain模式, 用echo threaded > cgroup.type可以将其改为threaded模式, 但要满足如下条件: As the cgroup will join the parent’s resource domain. The parent must either be a valid (threaded) domain or a threaded cgroup. When the parent is an unthreaded domain, it must not have any domain controllers enabled or populated domain children. The root is exempt from this requirement. threaded cgroup下面新建的cgroup默认是无效的 A (threaded domain) - B (threaded) - C (domain, just created) 这样的cgroup树, 在C刚刚创建的时候, 默认是domain控制器, 但它的父节点上都不是domain控制器. 这样C的cgroup.type文件会报告domain (invalid), 直到配置其为threaded模式. 一个cgroup变为threaded模式会导致其父domain cgroup变为threaded domain 一个进程的线程只能在一个threaded domain下存在. The threaded domain cgroup serves as the resource domain for the whole subtree, and, while the threads can be scattered across the subtree, all the processes are considered to be in the threaded domain cgroup. “cgroup.procs” in a threaded domain cgroup contains the PIDs of all processes in the subtree and is not readable in the subtree proper. However, “cgroup.procs” can be written to from anywhere in the subtree to migrate all threads of the matching process to the cgroup. 这段说的是线程domain组的cgroup.procs包含了子树的所有进程, 因为此时子树里面都是线程ID A (threaded domain) - B (threaded)在这个模式下, 一个线程在B中, 那B只算这个线程的资源. 但B所属的进程所有资源都算在A的头上, 因为A是domain控制器 控制器使能 每个cgroup都支持控制器类型# cat cgroup.controllers cpu io memory 默认全部都是不使能的. 需要显式使能: # echo \"+cpu +memory -io\" > cgroup.subtree_control 只有空的domain cgroup才能使能domain控制器. 但root不受此限制 不推荐动态迁移pid Migrating a process across cgroups is a relatively expensive operation and stateful resources such as memory are not moved together with the process. This is an explicit design decision as there often exist inherent trade-offs between migration and various hot paths in terms of synchronization cost. As such, migrating processes across cgroups frequently as a means to apply different resource restrictions is discouraged. A workload should be assigned to a cgroup according to the system’s logical and resource structure once on start-up. Dynamic adjustments to resource distribution can be made by changing controller configuration through the interface files. 以上说的是动态迁移pid的cost有点大. 动态的配置可以作用在控制器的相关接口文件上. 就是说要静态pid到group, 但group的配置可以改. 资源限制类型 Weights 比例方式. 范围从[1, 10000], 默认100 可以超配 Limits 限额方式, 从[0, max], 默认max. 可以超配(这点和v1不一样?) -- 为什么可以超配? 因为普通模式收CFS调度, 完全公平, CPU 100%忙也受调度限制. Protections 保护方式. 看起来是保护最低限额. Allocations 分配方式. 不能超配. 似乎就是现在的用法? 控制器类型 CPU The “cpu” controllers regulates distribution of CPU cycles. This controller implements weight and absolute bandwidth limit models for normal scheduling policy and absolute bandwidth allocation model for realtime scheduling policy. 说的很清楚, CPU类型的控制器实现了普通调度模式下的限额方式(可以超配)以及实时调度模式下的分配方式(不能超配) WARNING: cgroup2 doesn’t yet support control of realtime processes and the cpu controller can only be enabled when all RT processes are in the root cgroup. Be aware that system management software may already have placed RT processes into nonroot cgroups during the system boot process, and these processes may need to be moved to the root cgroup before the cpu controller can be enabled. 这个warn的意思是cgroup2对RT的支持还不好? 接口文件 cpu.stat 统计信息. 竟然就有利用率和用户态 内核态时间 cpu.weight normal调度用的比例方式 cpu.max 应该是给RT用的 allocation方式 内存 内存控制器是有状态的, 实现了limit方式和protection方式. 目前有三种类型的内存使用能够被统计到: 用户态页表: Userland memory - page cache and anonymous memory. 内核态数据: Kernel data structures such as dentries and inodes. TCP的内存: TCP socket buffers. 如下接口文件: memory.current 目前mem占用, 应是实际值 memory.min 受保护的最小值, 默认是0 memory.low 在low下都不会被kernel回收 memory.high 超过high会被kernel严格回收 memory.max 硬上限. 超过OOM memory.stat 详细统计: 匿名页 有名页 文件 共享内存 slab IO 传统上应该是指disk IO PID 用于限制PID可以fork和clone的次数 Cpuset 指定核. 主要用于NUMA场景. 可以和CPU以及mem联用. 比如在一个cgroup tree下面, 同时限制CPU使用, MEM使用以及指定CPU核 cpuset.cpus 配置文件交互 cgroup.type 控制cgroup是否为threaded模式 cgroup.procs 进程加入cgroup. 所有线程也一起加入 在threaded模式下, 读这个文件返回EOPNOTSUPP, 因为这个cgroup只管线程, 线程所属的进程归这个threaded domain管(在cgroup tree的上游). 但写还是一样的语义. cgroup.threads 线程加入cgroup. 只有在同一个domain的线程才能加入. 即一个进程的线程, 只能在同一个domain的子树上. cgroup.subtree_control 管使能控制器的 cgroup.events 能显示这个cgroup及其子树当前是否有有效的pid. 有效就是指有至少一个非zombine的pid cgroup.freeze 写1就freeze这个cgroup 和V1的对比 v1允许多个树, 而v2只有一个树. 看似v1更灵活, 每个tree里面还可以有任意的控制器. 但过设计了. v1允许进程的线程分属于多个cgroup. 而v2只能是在一个domain; ok, 还是v1过设计了. v1会有父子竞争现象, 因为线程可以任意所属. 系统内存占用分析 参考文章: https://www.cnblogs.com/arnoldlu/p/8568330.html http://linuxperf.com/?p=142cat /proc/meminfo MemTotal: 8054880 kB---------------------物理内存总容量，对应totalram_pages大小。 MemFree: 4004312 kB---------------------空闲内存容量，对应vm_stat[NR_FREE_PAGES]大小。 MemAvailable: 5678888 kB---------------------MemFree减去保留内存，加上部分pagecache和部分SReclaimable。 Buffers: 303016 kB---------------------块设备缓冲区大小. Cached: 2029616 kB---------------------主要是vm_stat[NR_FILE_PAGES],再减去swap出的大小和块设备缓冲区大小。Buffers+Cached=Active(file)+Inactive(file)+Shmem。 SwapCached: 0 kB---------------------交换缓存上的内容容量。 Active: 2123084 kB---------------------Active=Active(anon)+Active(file)。 Inactive: 1476268 kB---------------------Inactive=Inactive(anon)+Inactive(file)。 Active(anon): 1273544 kB---------------------活动匿名内存，匿名指进程中堆上分配的内存，活动指最近被使用的内存。 Inactive(anon): 547988 kB---------------------不活动匿名内存，在内存不足时优先释放。 Active(file): 849540 kB---------------------活动文件缓存，表示内存内容与磁盘上文件相关联。 Inactive(file): 928280 kB---------------------不活动文件缓存。 Unevictable: 17152 kB---------------------不可移动的内存，当然也不可释放，所以不会放在LRU中。 Mlocked: 17152 kB---------------------使用mlocked()处理的页面。 SwapTotal: 7812092 kB---------------------交换空间总容量。 SwapFree: 7812092 kB---------------------交换空间剩余容量。 Dirty: 6796 kB---------------------脏数据，在磁盘缓冲区中尚未写入磁盘的内存大小。 Writeback: 0 kB---------------------待回写的页面大小。 AnonPages: 1283984 kB---------------------内核中存在一个rmap(Reverse Mapping)机制，负责管理匿名内存中每一个物理页面映射到哪个进程的那个逻辑地址等信息。rmap中记录的内存页综合就是AnonPages值。 Mapped: 455248 kB---------------------映射的文件占用内存大小。 Shmem: 550260 kB---------------------vm_stat[NR_SHMEM]，tmpfs所使用的内存，tmpfs即利用物理内存来提供RAM磁盘功能。在tmpfa上保存文件时，文件系统暂时将他们保存到RAM中。 Slab: 268208 kB---------------------slab分配器总量，通过slabinfo工具或者/proc/slabinfo来查看更详细的信息。 SReclaimable: 206964 kB---------------------不存在活跃对象，可回收的slab缓存vm_stat[NR_SLAB_RECLAIMABLE]。 SUnreclaim: 61244 kB---------------------对象处于活跃状态，不能被回收的slab容量。 KernelStack: 12736 kB---------------------内核代码使用的堆栈区。 PageTables: 50376 kB---------------------PageTables就是页表，用于存储各个用户进程的逻辑地址和物理地址的变化关系，本身也是一个内存区域。 NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 11839532 kB Committed_AS: 7934688 kB VmallocTotal: 34359738367 kB------------------理论上内核可以用来映射的逻辑地址范围。 VmallocUsed: 0 kB---------------------内核将空闲内存页。 VmallocChunk: 0 kB HardwareCorrupted: 0 kB AnonHugePages: 0 kB ShmemHugePages: 0 kB ShmemPmdMapped: 0 kB CmaTotal: 0 kB CmaFree: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB DirectMap4k: 226256 kB DirectMap2M: 5953536 kB DirectMap1G: 3145728 kB /proc/meminfo和free的对应关系如下： free /proc/meminfo total =MemTotal used =MemTotal - MemFree - (Cached + SReclaimable) - Buffers free =MemFree shared =Shmem buffers =Buffers cache =Cached + SReclaimable available =MemAvailable 其他统计 /proc/buddyinfo /proc/pagetypeinfo /proc/vmstat /proc/vmallocinfo /proc/self/statm /proc/self/maps /proc/zoneinfo /proc/slabinfo /sys/kernel/mm/ksm /proc/sys/vm/compact_memory /proc/sys/vm/panic_on_oom /proc/sys/vm/oom_kill_allocating_task /proc/sys/vm/oom_dump_tasks vm参数 /proc/sys/vm/highmem_is_dirtyable /proc/sys/vm/legacy_va_layout /proc/sys/vm/lowmem_reserve_ratio /proc/sys/vm/max_map_count /proc/sys/vm/mmap_min_addr /proc/sys/vm/min_free_kbytes /proc/sys/vm/stat_interval /proc/sys/vm/vfs_cache_pressure /proc/sys/vm/page-cluster 文件缓存 /proc/sys/vm/dirty_background_bytes /proc/sys/vm/dirty_background_ratio /proc/sys/vm/dirty_bytes /proc/sys/vm/dirty_ratio /proc/sys/vm/dirty_expire_centisecs /proc/sys/vm/drop_caches CPU占用率分析 下面的数据全部都是从proc文件系统里读出来的. per CPU统计 user + sys + softirq + idle + iowait = 100 看到图中core1的这几个值加起来是绝对的100 core0也一样, 绝对的100 softirq现象 系统在打流的时候, 大约每2分钟就有10秒的冲高, 2个核加起来刚好100. 从上面的图看, 在softirq高的时候, 有100的CPU占用. 按理说2核的CPU共200, 那么应该只剩下100的CPU了. 也就是说, 如果softirq也算是\"独立\"的统计的话, 按进程的叠加不应该超过剩下的100. 是吗? 不是. 见下图: 在蓝色尖峰的时候, 按进程的统计已经超过了150. 结论 按CPU视角来统计, softirq是独立的 按进程视角来统计, softirq被统计进了sys. 因为proc文件系统只提供user和sys的占用, 目前我的结论是softirq在这个进程的占比(或者说\"抢占了\"这个进程的占比)会被加到这个进程的sys占比中. 当softirq高发生时, 通常都是burst的网络报文的处理导致的. 如果只看进程的CPU占用, 要注意里面已经包括了softirq的占用. 补充 上图显示了cpu1的softirq + idle + system + irq + user = 100注意softirq和irq不是一个.有个进程ksoftirqd也占了十几个点的CPU. 如果把它加到sys类里, 就超了100.又因为CPU1的system + user都只有不到5个点, 所以ksoftirqd内核线程的时间是算在softirq里面的. 系统调用都会触发调度吗? 不是. 虽然内核会在返回到用户态之前, 检查是否调度, 但是有条件的: 它检查任务描述符里need_resched字段以判断是否需要调度. 这个字段在进程时间片用尽的时候, 由函数scheduler_tick()来置位, 或者是高优先级任务来的时候, 也要置位这个flag. Preemption and Context Switching Context switching, the switching from one runnable task to another, is handled by the context_switch() function defined in kernel/sched.c. It is called by schedule() when a new process has been selected to run. It does two basic jobs: Calls switch_mm(), which is defined in include/asm/mmu_context.h, to switch the virtual memory mapping from the previous process's to that of the new process. Calls switch_to(), defined in include/asm/system.h, to switch the processor state from the previous process's to the current's. This involves saving and restoring stack information and the processor registers. The kernel, however, must know when to call schedule(). If it only called schedule() when code explicitly did so, user-space programs could run indefinitely. Instead, the kernel provides the need_resched flag to signify whether a reschedule should be performed (See Table 3.2). This flag is set by scheduler_tick() when a process runs out of timeslice and by try_to_wake_up() when a process that has a higher priority than the currently running process is awakened. The kernel will check the flag, see that it is set, and call schedule() to switch to a new process. The flag is a message to the kernel that the scheduler should be invoked as soon as possible because another process deserves to run. Functions for Accessing and Manipulating need_resched Function Purpose set_tsk_need_resched(task) Set the need_resched flag in the given process clear_tsk_need_resched(task) Clear the need_resched flag in the given process need_resched() Test the value of the need_resched flag; return true if set and false otherwise Upon returning to user-space or returning from an interrupt, the need_resched flag is checked. If it is set, the kernel invokes the scheduler before continuing. The flag is per-process, and not simply global, because it is faster to access a value in the process descriptor (because of the speed of current and because it might be in a cache line) than a global variable. Historically, the flag was global before the 2.2 kernel. In 2.2 and 2.4, the flag was an int inside the task_struct. In 2.6, it was moved into a single bit of a special flag variable inside the thread_info structure. As you can see, the kernel developers are never satisfied. User Preemption User preemption occurs when the kernel is about to return to user-space, need_resched is set, and therefore, the scheduler is invoked. If the kernel is returning to user-space, it knows it is in a safe quiescent state. In other words, if it is safe to continue executing the current task, it is also safe to pick a new task to execute. Consequently, whenever the kernel is preparing to return to user-space, either on return from an interrupt or after a system call, the value of need_resched is checked. If it is set, the scheduler is invoked to select a new (more fit) process to execute. Both the return paths for return from interrupt and return from system call are architecture-dependent and typically implemented in assembly in entry.S (which, aside from kernel entry code, also contains kernel exit code). In short, user preemption can occur When returning to user-space from a system call When returning to user-space from an interrupt handler Kernel Preemption The Linux kernel, unlike most other Unix variants and many other operating systems, is a fully preemptive kernel. In non-preemptive kernels, kernel code runs until completion. That is, the scheduler is not capable of rescheduling a task while it is in the kernel—kernel code is scheduled cooperatively, not preemptively. Kernel code runs until it finishes (returns to user-space) or explicitly blocks. In the 2.6 kernel, however, the Linux kernel became preemptive; it is now possible to preempt a task at any point, so long as the kernel is in a state in which it is safe to reschedule. So when is it safe to reschedule? The kernel is capable of preempting a task running in the kernel so long as it does not hold a lock. That is, locks are used as markers of regions of non-preemptibility. Because the kernel is SMP-safe, if a lock is not held, the current code is reentrant and capable of being preempted. The first change in supporting kernel preemption was the addition of a preemption counter, preempt_count, to each process's task_struct. This counter begins at zero and increments for each lock that is acquired and decrements for each lock that is released. When the counter is zero, the kernel is preemptible. Upon return from interrupt, if returning to kernel-space, the kernel checks the values of need_resched and preempt_count. If need_resched is set and preempt_count is zero, then a more important task is runnable and it is safe to preempt. Thus, the scheduler is invoked. If preempt_count is nonzero, a lock is held and it is unsafe to reschedule. In that case, the interrupt returns as usual to the currently executing task. When all the locks that the current task is holding are released, preempt_count returns to zero. At that time, the unlock code checks if need_resched is set. If so, the scheduler will be invoked. Enabling and disabling kernel preemption is sometimes required in kernel code and will be discussed in Chapter 8. Kernel preemption can also occur explicitly, when a task in the kernel blocks or explicitly calls schedule(). This form of kernel preemption has always been supported because no additional logic is required to ensure the kernel is in a state that is safe to preempt. It is assumed that the code that explicitly calls schedule() knows it is safe to reschedule. Kernel preemption can occur When returning to kernel-space from an interrupt handler When kernel code becomes preemptible again If a task in the kernel explicitly calls schedule() If a task in the kernel blocks (which results in a call to schedule()) 调度代码 调度发生时, schedule()调用context_switch()完成调度 一些系统调用, 可能会阻塞, 此时会触发调度 基本上大部分IO相关的系统调用都可能阻塞, 比如 open() read() write()等. 这里列出了常见的可能阻塞的系统调用 调度器的参考文章 https://www.cs.montana.edu/~chandrima.sarkar/AdvancedOS/SchedulingLinux/index.html https://www.cs.columbia.edu/~smb/classes/s06-4118/l13.pdf http://lass.cs.umass.edu/~shenoy/courses/spring20/lectures/Lec09.pdf https://medium.com/@bundetcom/understanding-linux-scheduler-5c683ff482d0 signal的默认行为和打断系统调用 man 7 signal 默认行为 Signal Value Action Comment ────────────────────────────────────────────────────────────────────── SIGHUP 1 Term Hangup detected on controlling terminal or death of controlling process SIGINT 2 Term Interrupt from keyboard SIGQUIT 3 Core Quit from keyboard SIGILL 4 Core Illegal Instruction SIGABRT 6 Core Abort signal from abort(3) SIGFPE 8 Core Floating-point exception SIGKILL 9 Term Kill signal SIGSEGV 11 Core Invalid memory reference SIGPIPE 13 Term Broken pipe: write to pipe with no readers; see pipe(7) SIGALRM 14 Term Timer signal from alarm(2) SIGTERM 15 Term Termination signal SIGUSR1 30,10,16 Term User-defined signal 1 SIGUSR2 31,12,17 Term User-defined signal 2 SIGCHLD 20,17,18 Ign Child stopped or terminated SIGCONT 19,18,25 Cont Continue if stopped SIGSTOP 17,19,23 Stop Stop process SIGTSTP 18,20,24 Stop Stop typed at terminal SIGTTIN 21,21,26 Stop Terminal input for background process SIGTTOU 22,22,27 Stop Terminal output for background process 注: 有的signal是发给整个group的, 比如SIGINT, 会发给整个PGRP, 也就是说, 如果一个前台父进程A起了子进程B, 那么在前台Ctrl+C掉进程A, 那么除了进程A会收到SIGINT, 进程B也会收到SIGINT 但如果是用kill命令, 比如kill -SIGINT 进程A, 那么只有进程A会收到SIGINT, 其子进程B不会收到SIGINT. 进程A的退出也不会导致其子进程B退出 用setpgid 或 setsid来改变子进程的进程组, 可以避免子进程收到前台的SIGINT 详见https://stackoverflow.com/questions/6803395/child-process-receives-parents-sigint signal和系统调用 signal打断系统调用的行为有几种, 和系统调用的类型以及注册sigaction的时候有没有SA_RESTART标记有关 下面的系统调用, 如果有SA_RESTART标记一般会被内核自动重新启动这个调用. 否则返回error EINTR * read(2), readv(2), write(2), writev(2), and ioctl(2) calls on \"slow\" devices. A \"slow\" device is one where the I/O call may block for an indefinite time, for example, a terminal, pipe, or socket. If an I/O call on a slow device has already transferred some data by the time it is interrupted by a signal handler, then the call will return a success status (normally, the number of bytes transferred). Note that a (local) disk is not a slow device according to this definition; I/O operations on disk devices are not interrupted by signals. * open(2), if it can block (e.g., when opening a FIFO; see fifo(7)). * wait(2), wait3(2), wait4(2), waitid(2), and waitpid(2). * Socket interfaces: accept(2), connect(2), recv(2), recvfrom(2), recvmmsg(2), recvmsg(2), send(2), sendto(2), and sendmsg(2), unless a timeout has been set on the socket (see below). * File locking interfaces: flock(2) and the F_SETLKW and F_OFD_SETLKW operations of fcntl(2) * POSIX message queue interfaces: mq_receive(3), mq_timedreceive(3), mq_send(3), and mq_timedsend(3). * futex(2) FUTEX_WAIT (since Linux 2.6.22; beforehand, always failed with EINTR). * getrandom(2). * pthread_mutex_lock(3), pthread_cond_wait(3), and related APIs. * futex(2) FUTEX_WAIT_BITSET. * POSIX semaphore interfaces: sem_wait(3) and sem_timedwait(3) (since Linux 2.6.22; beforehand, always failed with EINTR). * read(2) from an inotify(7) file descriptor (since Linux 3.8; beforehand, always failed with EINTR). 下面的系统调用直接返回EINTR, 不管是否有SA_RESTART * \"Input\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): accept(2), recv(2), recvfrom(2), recvmmsg(2) (also with a non-NULL timeout argument), and recvmsg(2). * \"Output\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): connect(2), send(2), sendto(2), and sendmsg(2). * Interfaces used to wait for signals: pause(2), sigsuspend(2), sigtimedwait(2), and sigwaitinfo(2). * File descriptor multiplexing interfaces: epoll_wait(2), epoll_pwait(2), poll(2), ppoll(2), select(2), and pselect(2). * System V IPC interfaces: msgrcv(2), msgsnd(2), semop(2), and semtimedop(2). * Sleep interfaces: clock_nanosleep(2), nanosleep(2), and usleep(3). * io_getevents(2). 内核收报文的时间片算在哪里? 背景: 驱动中断在哪里执行? 驱动收报要注册irq handler, 一般的, 使用: int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id) 其中: handler: 在中断上下文执行 thread_fn: 不为NULL就会新建一个内核线程\"irq/%irq-%irq_name\"来处理中断下半部. 当kernel启动参数包括threadirqs时, 即使thread_fn为null, 也会强制新建一个内核线程, 在该内核线程内处理中断. threadirqs只有在CONFIG_IRQ_FORCED_THREADING=y的时候才生效. 在板子上实验, 不加threadirqs, fglt-b上没有irq/xxx等进程. 加了threadirqs, 多了十几个irq/xxx进程, 每个中断一个. 一般的系统不会配置threadirqs强制把中断线程化. 所以, 根据驱动中断注册中断处理函数request_threaded_irq()是否有thread_fn, 决定中断是在内核线程上下文还是中断上下文 中断线程化后的CPU load 下面是打开threadirqs后, irq/24-eth0就是板子eth0网口收报的中断被强制线程化后的线程名. 可以看到, 在打流的时候, 这个线程load挺高的. 默认的eth0驱动并没有使用线程化中断, 这里面大概15%的CPU load可能被均摊到其他进程中(看起来是的). 打1000/2000/4000/6000pps 上行dhcpv4 discovery 打开threadirqs功能:topid: http://10.182.105.138:9888/switchPerf/152917918 关闭threadirqs功能:topid：http://10.182.105.138:9888/fgltb_dhcpv4/3501403790 对比两组数据, 基本上可以得到, 每个app的CPU load里, 都包含了中断处理时间, 比较均匀, 大概都是在2%左右. 中断线程化了之后, 每个app的cpu占用统计都稍微降了一点, 这些CPU都被算到irq/24-eth0上了. 另外, 这里面没有看到ksoftirqd等软中断进程, 说明softirq大部分都在\"中断\"中处理了. 到底什么是中断上下文? interrupt context : it specifies that the kernel is currently executing either an interrupt handler or a deferrable function 根据上面的定义, softirq是中断上下文. 从属性上说, 是的. 但严格从CPU角度来讲, softirq并不总是在硬件中断上下文中执行的. 下文会讲到, softirq并不是硬件上的某种\"软件触发中断\", 而是kernel的一种延迟执行的机制, 这些执行可能在硬件中断上下文中, 也可能是在普通的内核态上下文, 但其环境还是类似\"中断\"环境的, 比如抢占级别很高(只能被硬件中断抢占), 单独的softirq栈等等. 软中断上下文 一般硬中断会关中断(比如关闭eth的中断), 而软中断虽然也是在中断上下文执行(这点并不是always true), 但软中断是在使能中断的状态下执行的; 并且, 软中断可以多核同时执行. >中, 把软中断和tasklet叫做延迟执行. 原文 对硬件中断来说, 是关中断情况下串行执行的, 速度越快越好. softirq和tasklet和workqueue就是用来跑下半部的. softirq和tasklet又叫deferrable functions tasklet是基于softirq的 中断上下问的意思是kernel在执行interrupt handler, 或者在执行deferrable functions mpstat可以看软中断统计, 实际上也是从/proc/softirqs得到的数据 下面是个4核A53的ARM板子上的统计 ~ # mpstat -I SCPU Linux 4.9.199-Arm-Cortex_a53 (fglt-b) 03/08/70 _aarch64_ (4 CPU) 01:47:49 CPU HI/s TIMER/s NET_TX/s NET_RX/s BLOCK/s IRQ_POLL/s TASKLET/s SCHED/s HRTIMER/s RCU/s 01:47:49 0 0.00 100.00 0.00 3.58 0.00 0.00 0.14 98.45 0.00 48.13 01:47:49 1 0.00 87.55 0.00 8.61 0.00 0.00 0.00 98.95 0.00 38.53 01:47:49 2 0.00 79.42 0.00 6.46 0.00 0.00 3.09 98.73 0.00 47.22 01:47:49 3 0.00 65.90 0.00 2.41 0.00 0.00 0.00 97.61 0.00 39.11 softirq是静态分配的 tasklet可以动态分配, 比如加载一个内核模块时 同类型的softirq也可以同时运行在多核上, 必须可重入, 用锁保护关键区. 同类tasklet同时只能一个核运行, 不用担心竞争问题. deferrable functions在使用上, 类似中断, 都有如下操作: 初始化(Initialization): 定义一个延迟函数, 一般在kernel初始化时候确定或者在module load的时候做 激活(Activation): 标记为pending, pending的延迟函数会在下次调度到的时候执行. 在中断里也可以标记. 屏蔽(Masking): 临时禁止执行 执行(Execution): 执行pending的deferrable functions, 如果pending的很多, 只执行预定义的一部分. 激活和执行操作是同一个CPU, 这么设计主要是考虑到cache的利用率会高一点. softirq激活 在用open_softirq()注册softirq后, raise_softirq()函数用来激活softirq, 执行流程: 关本地中断 给这个softirq标记为pending 调用wakeup_softirqd()唤醒ksoftirqd进程 开本地中断 kernel会在关键点上检查softirq的pending状态, 这些关键点(checkpoints)包括: kernel调用local_bh_enable 当中断处理函数do_IRQ()完成硬中断处理, 最后调用irq_exit()时 apic timersmp_apic_timer_interrupt()结束时 核间中断处理完成时 ksoftirqd 内核进程运行时 可以看到, 这里面既有中断上下文, 又有进程上下文. 即软中断函数可能在不同的上下文中执行. 当以上checkpoint检查得知有softirq要处理时, 就会调用do_softirq(), 其执行流程如下: in_interrupt()如果是1, 表示已经在中断里调用过了do_softirq(), 或者这个softirq被禁止了. 直接return local_irq_save()关中断 切换到softirq自己的栈 执行_ _do_softirq( ) 这里应该把所有pending的事情都做完, 但这个函数可能是在中断上下文中, 执行太久会有问题. 所以只能执行固定数量的work, 剩下的交给ksoftirqd线程处理. 默认处理10个work local_bh_disable()禁止并发的_ _do_softirq( )执行? why? 不是说好了softirq支持并发吗? local_irq_enable()开中断 执行对应的softirq_vec[n]->action wakeup_softirqd( )唤醒ksoftirqd处理这里剩下的work softirq counter减一, 再次使能 切换回之前的栈 local_irq_restore()开中断 ksoftirqd线程 这个线程是用来做剩下来的工作的. for(;;) { set_current_state(TASK_INTERRUPTIBLE ); schedule( ); /* now in TASK_RUNNING state */ while (local_softirq_pending( )) { preempt_disable(); do_softirq( ); preempt_enable(); cond_resched( ); } } 这个线程是为了解决softirq过快产生的时候, 占用中断时间太长的问题的. 因为softirq可以被自己, 或者被外部事件激活. Softirq functions may reactivate themselves; in fact, both the networking softirqs and the tasklet softirqs do this. Moreover, external events, such as packet flooding on a network card, may activate softirqs at very high frequency. 上下文分类 前面分析了, 软中断上下文可以在硬中断中, 也可能是kernel checkpoints, 但都不是用户进程上下文(可能也不是绝对的, 比如用户态的系统调用里面, 调用的driver函数里有local_bh_enable()调用, 那么softirq就是在这个进程上下文处理的) 用户上下文永远可能被抢占 纯内核线程没有MM softirq是在预定义的kernel \"checkpoint\"里执行的 中断里不能sleep 收报的时间算在哪里? 从用户态调用recv开始, 用户态等待packet 网卡收报, 中断上下文驱动处理, 激活softirq 这个图有点片面. 大概率是在中断上下文处理10个, 剩下的叫给ksoftirqd 唤醒用户进程 补充: kernel的一些api用于判断当前上下文 实际上, 网卡驱动收报, IP层处理, 都不会算在进程上下文上. 但到TCP阶段, 已经绑定到socket了, tcp_v4_do_rcv()有可能在进程上下执行, 也有可能在softirq上下文执行. 结合>的分析, 如果正好用户进程在run, 但还没有调用recv(), 就会在softirq上下文执行tcp_v4_do_rcv() 那么收报的时间算在进程头上吗?答: 应该说大部分时间不会. 比如驱动收报和IP层处理. socket什么情况下会发生短读short read/partial read? 答: 应该主要是和syscall的被打断有关; 或者当时receive queue里面确实没有那么多的字节. A characteristic of earlier UNIX systems was that if a process caught a signal while the process was blocked in a ‘‘slow’’ system call, the system call was interrupted. The system call returned an error and errno was set to EINTR. This was done under the assumption that since a signal occurred and the process caught it, there is a good chance that something has happened that should wake up the blocked system call. To prevent applications from having to handle interrupted system calls, 4.2BSD introduced the automatic restarting of certain interrupted system calls. The system calls that were automatically restarted are ioctl, read, readv, write, writev, wait, and waitpid. As we’ve mentioned, the first five of these functions are interrupted by a signal only if they are operating on a slow device; wait and waitpid are always interrupted when a signal is caught. Since this caused a problem for some applications that didn’t want the operation restarted if it was interrupted, 4.3BSD allowed the process to disable this feature on a per-signal basis. stackoverflow的回答: Interruption of a system call by a signal handler occurs only in the case of various blocking system calls, and happens when the system call is interrupted by a signal handler that was explicitly established by the programmer. Furthermore, in the case where a blocking system call is interrupted by a signal handler, automatic system call restarting is an optional feature. You elect to automatically restart system calls by specifying the SA_RESTART flag when establishing the signal handler. As stated in (for example) the Linux signal(7) manual page: If a signal handler is invoked while a system call or library function call is blocked, then either: * the call is automatically restarted after the signal handler returns; or * the call fails with the error EINTR. Which of these two behaviors occurs depends on the interface and whether or not the signal handler was established using the SA_RESTART flag (see sigaction(2)). As hinted by the last sentence quoted above, even when you elect to use this feature, it does not work for all system calls, and the set of system calls for which it does work varies across UNIX implementations. The Linux signal(7) manual page notes a number of system calls that are automatically restarted when using the SA_RESTART flag, but also goes on to note various system calls that are never restarted, even if you specify that flag when establishing a handler, including: * \"Input\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): accept(2), recv(2), recvfrom(2), recvmmsg(2) (also with a non-NULL timeout argu‐ ment), and recvmsg(2). * \"Output\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): connect(2), send(2), sendto(2), and sendmsg(2). * File descriptor multiplexing interfaces: epoll_wait(2), epoll_pwait(2), poll(2), ppoll(2), select(2), and pselect(2). * System V IPC interfaces: msgrcv(2), msgsnd(2), semop(2), and semtimedop(2). For these system calls, manual restarting using a loop of the form described in APUE is essential, something like: while ((ret = some_syscall(...)) == -1 && errno == EINTR) continue; if (ret == -1) /* Handle error */ ; socket通信的时候, 要在应用侧做字节序转换吗? 答: 要. 尤其是binary编码情况下. 一般类似GPB的codec已经做了. socket的stream模式和datagram模式有什么不同? socket基础 man socket #include /* See NOTES */ #include int socket(int domain, int type, int protocol); domain有如下方式 Name Purpose Man page AF_UNIX, AF_LOCAL Local communication unix(7) AF_INET IPv4 Internet protocols ip(7) AF_INET6 IPv6 Internet protocols ipv6(7) AF_IPX IPX - Novell protocols AF_NETLINK Kernel user interface device netlink(7) AF_X25 ITU-T X.25 / ISO-8208 protocol x25(7) AF_AX25 Amateur radio AX.25 protocol AF_ATMPVC Access to raw ATM PVCs AF_APPLETALK AppleTalk ddp(7) AF_PACKET Low level packet interface packet(7) AF_ALG Interface to kernel crypto API type有 SOCK_STREAM Provides sequenced, reliable, two-way, connection-based byte streams. An out-of-band data transmission mechanism may be supported. SOCK_DGRAM Supports datagrams (connectionless, unreliable messages of a fixed maximum length). SOCK_SEQPACKET Provides a sequenced, reliable, two-way connection-based data transmission path for datagrams of fixed maximum length; a consumer is required to read an entire packet with each input system call. SOCK_RAW Provides raw network protocol access. SOCK_RDM Provides a reliable datagram layer that does not guarantee ordering. SOCK_PACKET Obsolete and should not be used in new programs; see packet(7). type还支持OR标记 SOCK_NONBLOCK Set the O_NONBLOCK file status flag on the new open file description. Using this flag saves extra calls to fcntl(2) to achieve the same result. SOCK_CLOEXEC Set the close-on-exec (FD_CLOEXEC) flag on the new file descriptor. See the description of the O_CLOEXEC flag in open(2) for reasons why this may be useful. socket的选项是SO_xxxx形式的, 用setsockopt(2)来设置. 用getsockopt(2) 来获取. SO_SNDBUF Sets or gets the maximum socket send buffer in bytes. The kernel doubles this value (to allow space for bookkeeping overhead) when it is set using setsockopt(2), and this doubled value is returned by getsockopt(2). The default value is set by the /proc/sys/net/core/wmem_default file and the maximum allowed value is set by the /proc/sys/net/core/wmem_max file. The minimum (doubled) value for this option is 2048. 我这里显示, 默认的发送buf是229K ~ # cat /proc/sys/net/core/wmem_default 229376 ~ # cat /proc/sys/net/core/wmem_max 229376 SOCK_STREAM AF_INET domain里面对应TCP, 有链接, 可靠, 保序. 没有记录边界. 这就是字节流的核心要义. 通俗来讲, 发送方发2次5字节, 接收方可以一次读到10个字节. 并且, 接收方并不知道这10个字节是两次发送的还是一次发送的. send()和recv()API, 支持带外数据发送 如果超时后还是有段数据没有收到, 则这个连接就是broken了. 对broken的连接读写会产生SIGPIPE信号 SOCK_SEQPACKET 底层和SOCK_STREAM一致, 有链接, 可靠, 保序 是packet模式, 有界. 一次读会把这个packet的所有数据读出, 超出的数据会被丢弃. all message boundaries in incoming datagrams are preserved SOCK_DGRAM 无连接, 有size限制的数据报模式 使用sendto()和recvfrom() API. recvfrom()返回下一个数据报. Datagrams are generally received with recvfrom(2), which returns the next datagram along with the address of its sender. 天然有界: 所有的收报都是一个packet. 小报直接收, 大包被截断, 剩余部分丢弃. All receive operations return only one packet. When the packet is smaller than the passed buffer, only that much data is returned; when it is bigger, the packet is truncated and the MSG_TRUNC flag is set. 发送端的sendto()和接收端的recvfrom()永远是1:1的, 一个对一个. 比如sendto()两次, 也必须recvfrom()两次才能收完报文. 这点和TCP不一样. 这也是data gram的含义. 有个api, 支持一次系统调用, 收多个datagram: recvmmsg() 估计是在内核态多次recv收报. man 7 ip #include #include #include /* superset of previous */ tcp_socket = socket(AF_INET, SOCK_STREAM, 0); udp_socket = socket(AF_INET, SOCK_DGRAM, 0); raw_socket = socket(AF_INET, SOCK_RAW, protocol); proc下面有些全局的配置: /proc/sys/net/ipv4/ man 7 tcp #include #include #include tcp_socket = socket(AF_INET, SOCK_STREAM, 0); 一些全局的配置~ # cat /proc/sys/net/ipv4/tcp_wmem 4096 16384 4194304 ~ # cat /proc/sys/net/ipv4/tcp_rmem 4096 87380 6291456 /proc/sys/net/core/rmem_max /proc/sys/net/core/wmem_max 支持urgent data, 用send的MSG_OOB选项发送 支持ioctl man 7 udp #include #include #include udp_socket = socket(AF_INET, SOCK_DGRAM, 0); 默认最大MTU, 写报文超过MTU会有EMSG‐SIZE错误. man 7 unix #include #include unix_socket = socket(AF_UNIX, type, 0); error = socketpair(AF_UNIX, type, 0, int *sv); 同时支持SOCK_STREAM和SOCK_DGRAM, 并且SOCK_DGRAM是可靠和保序的 也支持SOCK_SEQPACKET 不支持out-of-band数据 支持fd传递到其他进程, 见SCM_RIGHTS Send or receive a set of open file descriptors from another process. The data portion contains an integer array of the file descriptors. The passed file descriptors behave as though they have been created with dup(2). datagram模式时, SO_SNDBUF起作用, 这个是send()数据报的上限. 上限是: 2*SO_SNDBUF-32 SO_RCVBUF没有作用 什么是message boundires? UDP preserves message boundaries. If you send \"FOO\" and then \"BAR\" over UDP, the other end will receive two datagrams, one containing \"FOO\" and the other containing \"BAR\". If you send \"FOO\" and then \"BAR\" over TCP, no message boundary is preserved. The other end might get \"FOO\" and then \"BAR\". Or it might get \"FOOBAR\". Or it might get \"F\" and then \"OOB\" and then \"AR\". TCP does not make any attempt to preserve application message boundaries -- it's just a stream of bytes in each direction. 对于datagram类型的报文接收, 用 ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); The recvfrom function reads one packet from the socket socket into the buffer buffer. The size argument specifies the maximum number of bytes to be read. UDP operates on messages, not streams like TCP does. There is a 1-to-1 relationship between sendto() and recvfrom() when using UDP If the packet is longer than size bytes, then you get the first size bytes of the packet and the rest of the packet is lost. There’s no way to read the rest of the packet. Thus, when you use a packet protocol, you must always know how long a packet to expect. The arguments to this call are basically the same as the standard socket call. The Recvfrom() call reads one packet at a time. It returns the length of the message written to the buffer pointed to by the buf argument (the second argument). Even if one packet worth of message does not fill up the buffer, Recvfrom() will return immediately and will not read the second packet. However, if a message in a packet is too long to fit in the supplied buffer, the excess bytes are discarded. By default, Recvfrom() is blocking: when a process issues a Recvfrom() that cannot be completed immediately (because there is no packet), the process is put to sleep waiting for a packet to arrive at the socket. Therefore, a call to Recvfrom() will return immediately only if a packet is available on the socket. When the argument flags of Recvfrom() is set to MSG_NOBLOCK, Recvfrom() does not block if there is no data to be read, but returns immediately with a return value of 0 bytes. MSG_NOBLOCK is defined in $PDIR/include/systm.h. In an actual UNIX system, socket descriptors are set to be non-blocking using fcntl() with type O_NONBLOCK, and Recvfrom() returns errno EWOULDBLOCK when there is no data to be read on the non-blocking socket. TCP的stream模式怎么定界? stream流, 接收方并不知道发送放分多少次发送的. 接收方只看到一个字节流. 这就需要在应用层定界, 即双方约定如何分割和理解这个字节流. 通常的方法有: 加固定size的头. 这个头里有size信息 So you first receive the header (fixed size), extract the message size information and then receive in a second loop the real user data. 加delimiter, 即特殊符号标记 Alternatively some protocols are using delimiters to mark message boundaries. cgroup配置 写入pid /sys/fs/cgroup/cpu的cgroups树下面, 有两个文件 cgroup.procs : 将pid写入这个文件, 这个pid下面的所有线程都受cgroups控制 tasks : 只有这个pid的线程受cgroups控制 rt调度域的配额 /mnt/cgroups/cpu # cat cpu.rt_runtime_us 950000 一些命令 # 查看cgBase组里的进程 cat /mnt/cgroups/cpu/cgBase/cgroup.procs | xargs -i cat /proc/{}/comm # 查看cgBase组里的线程 cat /mnt/cgroups/cpu/cgBase/tasks | xargs -i cat /proc/{}/comm # 查看cgNonDelayCrit组里的进程 cat /mnt/cgroups/cpu/cgBase/cgNonDelayCrit/cgroup.procs | xargs -i cat /proc/{}/comm # 查看cgNonDelayCrit组里的线程 cat /mnt/cgroups/cpu/cgBase/cgNonDelayCrit/tasks | xargs -i cat /proc/{}/comm # 查看onu_engine group cat /mnt/cgroups/cpu/cgBase/cgNonDelayCrit/onu_engine/cgroup.procs | xargs -i cat /proc/{}/comm # 查看所有不在cgroup组的进程 cat /mnt/cgroups/cpu/cgroup.procs | xargs -i cat /proc/{}/comm linux调度方式有哪些? man sched 所有的调度策略是对同一个优先级下面的runnable队列而言的; 高优先级抢占低优先级是宇宙法则, 所有调度策略必须都要遵守. 非实时调度 SCHED_OTHER, SCHED_IDLE, SCHED_BATCH: 静态优先级是0 实时调度 SCHED_FIFO, SCHED_RR: 静态优先级是1 - 99 SCHED_FIFO: 没有时间片, 低优先级随时被高优先级抢占. 同一个优先级按先进先出排队 SCHED_RR: 有时间片, 按时间片轮转. 对于实时调度, 所有的实时优先级组都共享三个配置: sched_rr_timeslice_ms : 管轮转的时间片的 sched_rt_period_us : 实时优先级和普通优先级的总时间. 默认1秒. 对应100% CPU. sched_rt_runtime_us : 可以认为是所有实时优先级占比. 默认0.95秒. 即95% CPU ~ # cat /proc/sys/kernel/sched_rr_timeslice_ms 10 ~ # cat /proc/sys/kernel/sched_rt_period_us 1000000 ~ # cat /proc/sys/kernel/sched_rt_runtime_us 950000 ~ # ls ~ # zcat /proc/config.gz | grep -i empt # CONFIG_PREEMPT_NONE is not set # CONFIG_PREEMPT_VOLUNTARY is not set CONFIG_PREEMPT=y CONFIG_PREEMPT_COUNT=y CONFIG_PREEMPT_RCU=y CONFIG_DEBUG_PREEMPT=y ~ # zcat /proc/config.gz | grep -i hz # CONFIG_HZ_24 is not set # CONFIG_HZ_48 is not set CONFIG_HZ_100=y # CONFIG_HZ_128 is not set # CONFIG_HZ_250 is not set # CONFIG_HZ_256 is not set # CONFIG_HZ_1000 is not set # CONFIG_HZ_1024 is not set CONFIG_SYS_SUPPORTS_ARBIT_HZ=y CONFIG_HZ=100 CONFIG_HZ_PERIODIC=y # CONFIG_NO_HZ_IDLE is not set # CONFIG_NO_HZ_FULL is not set # CONFIG_NO_HZ is not set 解释一下: 几乎所有的moswa app 都是SCHED_RR, 静态分配优先级; 同一个优先级内按时间片轮转. 默认时间片10ms 所有实时优先级进程占CPU比例上限 95% 即有5%的CPU留给了非实时优先级, 目前只有内核线程loop* bio* ubi* spi1等几个线程享用 这个不归cgroup管, 也是为什么cgroup的cg_base最大只能配950000 目前是抢占式调度, 也就是说虽然5%留给了非实时进程, 但这些进程大概率经常被抢占. 应该说系统越忙, 雪崩效应越明显: 有更多的抢占发生 推荐优化思路: 禁止内核抢占CONFIG_PREEMPT=n或者CONFIG_PREEMPT_VOLUNTARY=y 重新整理系统实时进程和非实时进程策略, 一个比较粗糙的想法是业务处理搞SCHED_RR, 并且不那么在内部细分优先级, 比如按业务组定几个就好了, 让调度器去轮转调度; 其他进程, 比如ping, ssh, 各种脚本的衍生进程, 非核心path下的eqpt等进程, 都放到非实时 可以尝试增大SCHED_RR到100ms 调整实时进程组和非实时进程组的比例, 现在是95% : 5% preemptive kernel是什么意思? 内核现在有三个抢占模式: CONFIG_PREEMPT=y的时候, 打开内核抢占; 为n的时候关闭内核抢占 后来又加了CONFIG_PREEMPT_VOLUNTARY, 意思是主动在内核特定点可以抢占. 抢占的意思是低优先级被高优先级抢占. 为什么一直说内核抢占? 答: 因为用户态代码总是可以被抢占的, 无论CONFIG_PREEMPT怎么配置. 例如用户态代码的死循环变量加一, 也是有时间片的, 时间片耗尽也是要被kernel切换出去的. 内核抢占说的是, 当一个进程陷入到内核态, 代表这个进行运行的内核代码能否被抢占. 在古老的kernel版本里面, 内核态代码是不能被抢占的. 后来为了能够即使响应桌面等UI互动等场景, 加入了抢占. CONFIG_PREEMPT的解释如下: This option reduces the latency of the kernel by making all kernel code (that is not executing in a critical section) preemptible. This allows reaction to interactive events by permitting a low priority process to be preempted involuntarily even if it is in kernel mode executing a system call and would otherwise not be about to reach a natural preemption point. This allows applications to run more 'smoothly' even when the system is under load, at the cost of slightly lower throughput and a slight runtime overhead to kernel code. Select this if you are building a kernel for a desktop or embedded system with latency requirements in the milliseconds range. 嵌入式设备需要抢占吗? 抢占主要是给用户体验用的, 比如用户的鼠标键盘希望能响应快一点. 对时延要求高的系统, 比如工业控制系统, 需要打开内核抢占. 而一般的嵌入式系统, 应该更追求处理业务的吞吐量, 此时不抢占更合适. 一般的x86服务器, 都开的是CONFIG_PREEMPT_VOLUNTARY=y, 这是一种介于中间的状态. 这篇文章对比过 CONFIG_PREEMPT_VOLUNTARY有很好的平衡, 所以一般的主流OS(CentOS, Ubuntu, SUSE)都默认此模式(估计是server版本). 用户态上下文切换和ucontex.h 参考: 我所理解的ucontext族函数(主要是概念和使用) 协程：posix::ucontext用户级线程实现原理分析(包括汇编实现原理) posix提供了用户态上下文切换的API #include int getcontext(ucontext_t *ucp); int setcontext(const ucontext_t *ucp); void makecontext(ucontext_t *ucp, void (*func)(), int argc, ...); int swapcontext(ucontext_t *oucp, const ucontext_t *ucp); man getcontext 用户态上下文 ucontext_t描述了用户态上下文: 其中mcontext_t是个硬件相关的结构 typedef struct ucontext_t { struct ucontext_t *uc_link; sigset_t uc_sigmask; stack_t uc_stack; mcontext_t uc_mcontext; ... } ucontext_t; getcontext()函数把当前的上下文保存在ucp指针指向的ucontext_t中 setcontext()函数恢复到ucp指向的上下文, 然后从那个上下文执行. 这个函数不retrun. makecontext()函数新生成一个上下文, 并指定在这个上下文中执行的func sighandler也可以返回一个上下文 例子 下面的程序不断打印\"hello world\" 因为第10行转而在第7行保存的上下文中执行, 效果就像直接goto到第8行一样. #include #include #include int main(int argc, char *argv[]) { ucontext_t context; getcontext(&context); puts(\"Hello world\"); sleep(1); setcontext(&context); return 0; } 使用ucontext.h的api实现用户态协程 基于ucontext.h的轻量级协程库 协程可以理解为一种用户态的轻量级线程, 切换由用户定义 协程上下文切换很快, 因为不会陷入内核态 协程拥有自己的寄存器上下文和栈, 协程调度切换时，将寄存器上下文和栈保存到其他地方，在切换回来的时候，恢复先前保存的寄存器上下文和栈 协程具有极高的执行效率 因为子程序切换不是线程切换，是由程序自身控制，因此协程没有线程切换的开销, 多线程的线程数量越多，协程的性能优势就越明显 访问共享资源不需要多线程的锁机制, 因为只有一个线程, 也不存在同时写变量冲突, 所以在协程中控制共享资源无需加锁, 只需要判断状态就好了，执行效率比多线程高很多, 而且代码编写难度也可以相应降低 以同步代码的方式写异步逻辑 无法利用多核资源, 除非和多进程配合 多线程的情况下, signal被deliver到哪个线程? 问答: https://stackoverflow.com/questions/11679568/signal-handling-with-multiple-threads-in-linux 先准备几个知识: 所有线程都在一个进程空间 signal都是先入queue, 待线程被调度到运行时再执行的. signal是共享的, 但每个thread可以有自己的maskpthread_sigmask(3) 内核里deliver signal的代码: /* * Now find a thread we can wake up to take the signal off the queue. * * If the main thread wants the signal, it gets first crack. * Probably the least surprising to the average bear. */ if (wants_signal(sig, p)) t = p; else if (!group || thread_group_empty(p)) /* * There is just one thread and it does not need to be woken. * It will dequeue unblocked signals before it runs again. */ return; else { /* * Otherwise try to find a suitable thread. */ t = signal->curr_target; while (!wants_signal(sig, t)) { t = next_thread(t); if (t == signal->curr_target) /* * No thread needs to be woken. * Any eligible threads will see * the signal in the queue soon. */ return; } signal->curr_target = t; } /* * Found a killable thread. If the signal will be fatal, * then start taking the whole group down immediately. */ if (sig_fatal(p, sig) && !(signal->flags & SIGNAL_GROUP_EXIT) && !sigismember(&t->real_blocked, sig) && (sig == SIGKILL || !p->ptrace)) { /* * This signal will be fatal to the whole group. */ 结论: 默认是deliver给main thread, 如果main thread不want这个signal, 就尝试下一个thread 用户可以用pthread_sigmask(3)设置thread的mask, 从而让signal被deliver到特定的thread. 可以向指定的thread发signal. 见pthread_kill(3) tgkill(2) 一些同步异常, 比如SIGSEGV和SIGFPE, 是由当前thread的某个指令引起的, 那么signal就直接被deliver到这个线程. 有些signal是以进程为单位产生的, 理论上会被deliver到任意一个线程. 但参考第一条, 通常是deliver到main thread. 信号处理函数执行的上下文是什么? 为什么能打印当前进程的调用栈? 目前已知的知识, 以golang的signal处理为例: SIGKILL and SIGSTOP不能被捕获 同步的signal, 一般是SIGBUS, SIGFPE, and SIGSEGV, 是由正在执行的go程序引起的 在go里, 这些signal被转换为运行时的panic 剩下的signal, 是其他进程异步通知的signal, 用os/signal包来处理 经过实验得到的现象, 还是以golang为例: case 1: 对于一个纯用户态循环, ctrl+c(SIGINT)能够立即终止该进程 for { i++ } 从shell执行kill -SIGQUIT命令发送SIGQUIT信号给目标进程, 目标进程的call stack能精确定位到for循环里的i++那一行 $ ./signal hello ^\\SIGQUIT: quit PC=0x48cfd5 m=0 sigcode=128 goroutine 1 [running]: main.main() /repo/yingjieb/godev/practice/src/signal/main.go:15 +0x75 fp=0xc0000aef60 sp=0xc0000aef00 pc=0x48cfd5 runtime.main() /usr/local/go/src/runtime/proc.go:203 +0x206 fp=0xc0000aefe0 sp=0xc0000aef60 pc=0x42b136 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc0000aefe8 sp=0xc0000aefe0 pc=0x453651 case 2: 对上面的for稍加一句sleep for { i++ time.Sleep(time.Second * 10) } 发送SIGQUIT也一样能够立即打印调用栈; 不意外的, ctrl+c也能够立即终止这个进程. 都不受sleep的干扰. 调用栈显示两个goroutine(实际上, 如果有环境变量GOTRACEBACK=system, 能显示更多goroutine), sleep的调用栈就是main程序当前的代码. 结合代码和现象来看, 这个进程在收到SIGQUIT时, 大概率是在sleep, 没有在运行. 这时操作系统发现有人发送SIGQUIT给该进程, 就执行该进程的sighandler. 在本例中, 这个sighandler就是golang默认的处理. $ ./signal hello ^\\SIGQUIT: quit PC=0x455813 m=0 sigcode=128 goroutine 6 [syscall]: runtime.notetsleepg(0x5613a0, 0x2540bc392, 0x0) /usr/local/go/src/runtime/lock_futex.go:227 +0x34 fp=0xc000064760 sp=0xc000064730 pc=0x409d04 runtime.timerproc(0x561380) /usr/local/go/src/runtime/time.go:311 +0x2f1 fp=0xc0000647d8 sp=0xc000064760 pc=0x4450b1 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc0000647e0 sp=0xc0000647d8 pc=0x453911 created by runtime.(*timersBucket).addtimerLocked /usr/local/go/src/runtime/time.go:169 +0x10e goroutine 1 [sleep]: runtime.goparkunlock(...) /usr/local/go/src/runtime/proc.go:310 time.Sleep(0x2540be400) /usr/local/go/src/runtime/time.go:105 +0x157 main.main() /repo/yingjieb/godev/practice/src/signal/main.go:24 +0x88 golang对于各种signal, 都有默认的sighandler, 那么如标题的问题 sighandler一般被认为是异步的方式执行, 和正常的进程代码是两回事. 那么sighandler究竟是在什么上下文执行的? 以SIGQUIT的handler为例, 为什么一个异步执行的handler, 能够知道正常代码的调用栈? 结合case 1和2, sighandler被调用的时机是怎样的? case 2中, 大概率是在进程没有被执行的时候发生了SIGQUIT. 但case 1中, 进程死循环做i++, 会用尽调度器分给它的时间片. 那么sighandler又是什么时候执行呢? sighandler执行的上下文 程序运行在用户态时->进程由于系统调用或中断进入内核->转向用户态执行信号处理函数->信号处理函数完毕后进入内核->返回用户态继续执行程序首先程序执行在用户态，在进程陷入内核并从内核返回的前夕，会去检查有没有信号没有被处理，如果有且没有被阻塞就会调用相应的信号处理程序去处理。首先，内核在用户栈上创建一个层，该层中将返回地址设置成信号处理函数的地址，这样，从内核返回用户态时，就会执行这个信号处理函数。当信号处理函数执行完，会再次进入内核，主要是检测有没有信号没有处理，以及恢复原先程序中断执行点，恢复内核栈等工作，这样，当从内核返回后便返回到原先程序执行的地方了。 关键点在kernel在收到signal的时候, 会在用户栈上新建一个栈帧, 作用是给sighandler提供运行上下文. 我理解, 如果这个进程正在运行(在另外一个核上), 内核应该会把它调度出去, 再建立sighandler的栈帧. sigaltstack函数用于指定sighandler栈 man sigaltstack解释到: sigaltstack用于显式建立一个栈帧. 默认情况下, kernel会在用户栈上建立这个栈帧, 但对于用户栈溢出造成的SIGSEGV的情况, 在用户栈上的sighandler也就不能执行了. sigaltstack()函数用于这种情况, 在别处指定这个栈帧. #include int sigaltstack(const stack_t *ss, stack_t *old_ss); The most common usage of an alternate signal stack is to handle the SIGSEGV signal that is generated if the space available for the normal process stack is exhausted: in this case, a signal handler for SIGSEGV cannot be invoked on the process stack; if we wish to handle it, we must use an alternate signal stack. Establishing an alternate signal stack is useful if a process expects that it may exhaust its standard stack. This may occur, for example, because the stack grows so large that it encounters the upwardly growing heap, or it reaches a limit established by a call to setrlimit(RLIMIT_STACK, &rlim). If the standard stack is exhausted, the kernel sends the process a SIGSEGV signal. In these circumstances the only way to catch this signal is on an alternate signal stack. 回答 sighandler一般被认为是异步的方式执行, 和正常的进程代码是两回事. 那么sighandler究竟是在什么上下文执行的?答: 默认在用户栈上新建新的栈帧来执行. 可以用sigaltstack改变这个栈帧的位置 以SIGQUIT的handler为例, 为什么一个异步执行的handler, 能够知道正常代码的调用栈?答: handler执行的时候, 是异步的. 此时\"正常\"的进程代码位置应该可以通过上下文的PC指针查到, 那么就可以栈回溯. 结合case 1和2, sighandler被调用的时机是怎样的? case 2中, 大概率是在进程没有被执行的时候发生了SIGQUIT. 但case 1中, 进程死循环做i++, 会用尽调度器分给它的时间片. 那么sighandler又是什么时候执行呢?答: 内核在返回用户态进程的时候, 会执行sighandler. 从实验结果来看, 向进程发送信号会唤醒这个进程. 信号处理原理 signal原理讲义 sigaction sigaction结构体定义了handler的形式: 第三个参数就是ucontext pending和blocked向量 kernel给每个进程维护这两个向量 顾名思义, pending向量是要发给目标进程的向量表; 而blocked向量是不允许发送给进程的向量表. 当一个signal已经被deliver到进程, 该signal会自动被kernel放到blocked向量, 阻止进程在处理singal的时候, 又被同类型signal中断. 类似于关中断. 但不同类型的signal可以打断当前的siganl handler函数. signal的产生和投递 signal产生时, kernel要填的结构体 产生和投递是两个过程 产生signal是填一些结构体, 然后把进程状态转为ready(如果之前是睡眠) 投递signal到进程, 进程必须拥有CPU执行权才能运行其handler 默认的handler由内核执行, 自定义的handler必须等到用户态执行 handler执行完还要回到内核态 signal可以打断系统调用 handler可以调用系统调用, 系统调用返回后还是回到handler上下文 handler可以调用siglongjmp()来跳转到用户态的其他部分代码, 但执行上下文还在handler? SIGCHLD默认是ignore的, handler是SIGIGN也是要被跳过的.![](img/system原理杂记_20220829152133.png) 默认的handler SIG_DFL在内核执行: 不到用户态 不是内核处理的signal, 内核要唤醒这个进程到其用户态处理. 不能简单的把sighandler设为这次返回用户态的入口, 而是要为sighandler建立自己的上下文; 有一部分的上下文是从kernel栈拷到用户栈的. 新建的sighandler栈帧在用户态栈上, 称为uctxt handler返回的时候, 要返回到内核态. 这是通过一个间接的sigreturn系统调用实现的.man sigreturn说的很清楚: 现代linux系统上, 是vdso或libc提供的sigreturn wrapper, 它的作用是利用之前保存在栈上的相关信息, undo所有之前为sig handler运行做的准备工作, 回复进程被signal中断之前的上下文.do_signal是给用户的sighandler设置运行环境, 实际的handler不是在它里面执行的, 而是后面内核态切换到用户态时, 因为eip的改变, 导致用户的sighandler被执行. sighandler可以执行系统调用, 没有任何问题. signal和系统调用 系统调用会被signal打断, 内核需要返回EINTR来指示系统调用被打断了. 被打断的read和write可能会被内核重新执行. 可以配置是返回EINTR还是rerun 进程在系统调用期间收到signal, 那它的之前都在内核态. siglongjmp 调用siglongjmp会导致handler退出, 并把执行上下文交给用户态进程的那部分代码段. siglongjmp和longjmp差不多, 只是多了一些sig mask的操作. siglongjmp并没有破环内核的sig投递 执行 返回的流程. futex系统调用 man futex linux的futex可以当作比较-阻塞的原子操作使用. #include #include int futex(int *uaddr, int futex_op, int val, const struct timespec *timeout, /* or: uint32_t val2 */ int *uaddr2, int val3); Note: There is no glibc wrapper for this system call; see NOTES. int *uaddr是个用户提供的地址, 其值时32位的, 即使在64位机器上, 也是32位. 这个地址可以在共享内存中, 比如用mmap(2) or shmat(2)创建的共享内存, 这样不同的进程也可以使用同一个futex, futex在内核中看的是这个指针的物理地址. futex支持像epoll等系统调用的超时机制. 当futex_op可以是FUTEX_WAIT也可以是FUTEX_WAKE, 即futex有wait和wakeup两种功能. FUTEX_WAIT时, futex比较这个地址指向的32位值, 如果和val相等则休眠; 不等的话, 马上返回, errorno为EAGAIN. FUTEX_WAKE时, 唤醒val个等待在uaddr上的线程. 通常val为1个随机的线程, 或者所有(INT_MAX)的线程. libevent主循环处理timer 在libevent/event.c int event_base_loop(struct event_base *base, int flags) while (!done) { //没有event则退出循环 //从定时器堆里算下次超时时间 timeout_next(base, &tv_p); //调用底层poll, 对linux来说, 是epoll res = evsel->dispatch(base, tv_p); //handle 定时器堆, 把有效的(active)的定时器回调函数加入base的active队列, 带优先级的入队列 timeout_process(base); //真正执行active队列里面的回调; int n = event_process_active(base); } /* Activate every event whose timeout has elapsed. */ static void timeout_process(struct event_base *base) { gettime(base, &now); //获取每个timer while ((ev = min_heap_top_(&base->timeheap))) { if (evutil_timercmp(&ev->ev_timeout, &now, >)) break; /* delete this event from the I/O queues */ event_del_nolock_(ev, EVENT_DEL_NOBLOCK); event_debug((\"timeout_process: event: %p, call %p\", ev, ev->ev_callback)); //正如上面打印的提示一样, 执行每个timer的回调. event_active_nolock_(ev, EV_TIMEOUT, 1); //实际上这里是加入到一个链表: base->activequeues, 由event_process_active()执行这个链表 } } 再议rm rm实际上是unlink调用, 实际上是减小文件的link计数. 如果link减小到0, 而且没有进程open它, 文件会被删除. 如果link减小到0, 但有进程在使用它, 那么文件在进程close它之前都存在. 见man 2 unlink 实验中, 我用vim打开一个文件, 在另外一个窗口rm这个文件, rm没有返回任何错误, 文件已经从文件系统不可见. 但实际上, 这个文件还存在, vim依旧可以访问它.普通用户可以rm root用户的文件 在一次实验中, 我在test文件夹中, 用root账户创建了文件aaa, 但退出root后, 用普通账户就能删除aaa文件.yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ ll total 0 yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ sudo touch aaa yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ ll total 0 -rw-r--r-- 1 root root 0 Mar 4 21:12 aaa yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ rm -f aaa yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ ll total 0 怎么, aaa是-rw-r--r--权限, 理论上不应该能被普通用户删除呀? 有人问了这个问题, 见: https://superuser.com/questions/1336951/user-can-delete-root-owned-files-in-their-home-directory-or-what-are-the-rules其实原理是:目录和文件的关系是, 目录是对其下文件的link, 所以shell命令rm其实是unlink调用, unlink减小对文件的link引用数.如果引用数减到0, 这个文件就没人引用了, 就被删除了.删除一个文件, 并不是作用于这个文件, 而是作用于它的目录, 减小目录对文件的引用.所以, 在本例中, rm作用于目录~/test, 这是个用户有权限访问的目录. rm操作和文件aaa的权限没有关系. 关于热升级, 正在使用的文件可以被rm 比如ubuntu系统在update的时候, 一般是不需要重启的. 但既然要升级, 就必然要替换掉原来的bin或者so之类的文件, 又要app不重启, 怎么做到的呢? 以vim为例, 当前正在打开vim窗口编辑, 同时在另外一个窗口升级vim, 升级成功了, 原来打开的vim还能继续使用. 那打开的vim是新版本还是老版本呢? --是老版本 这主要是文件系统的工作, 每个打开的文件, 都有个文件句柄, 这个句柄是这个文件的一个访问实例; 句柄里保存了文件的实体(inode)在文件系统中的引用. 升级的过程, 是先删除旧文件, 再写入新文件, 虽然文件名相同, 但inode不同. 已经打开的旧文件, 在其句柄里保存的inode, 指向的文件\"看起来\"不存在了, 但实际还在文件系统里. 所有对这个老的inode的引用结束后, 文件系统把这部分在磁盘上的实体空间标记为空闲. #打开vim, 进程是28919 #pmap发现其mmap的文件 Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk 000055683333b000 64K r---- vim.gtk 000055683334b000 104K rw--- vim.gtk #此时, 对vim.gtk的open是不能写的, 因为写是对同一个inode操作. Linux Mint 19.1 Tessa $ sudo dd if=/dev/zero of=/usr/bin/vim.gtk bs=4M count=1 dd: failed to open '/usr/bin/vim.gtk': Text file busy yingjieb@yingjieb-VirtualBox ~ Linux Mint 19.1 Tessa $ sudo cp /usr/bin/x86_64-linux-gnu-gcc-7 /usr/bin/vim.gtk cp: cannot create regular file '/usr/bin/vim.gtk': Text file busy #但是可以删除 Linux Mint 19.1 Tessa $ sudo rm -f /usr/bin/vim.gtk #此时pmap能知道这个文件被删除了 #但28919进程的vim还能继续使用, 因为1. 其文件并没有真正消亡. 2. 文件被装载到内存里了(page). #我估计这两项都为真. 文件被mmap到进程内存空间, 即使只有部分文件被page了, 访问另外的文件部分, 会有page fault, 进而通过文件系统装载文件内容到物理页. #我认为即使page fault, 也会访问到老的inode的文件, 也会成功 -- 未验证 Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk (deleted) 000055683333b000 64K r---- vim.gtk (deleted) 000055683334b000 104K rw--- vim.gtk (deleted) #也可以mv Linux Mint 19.1 Tessa $ sudo mv /usr/bin/vim.gtk /usr/bin/vim.gtk.back #此时pmap知道inode没变, 文件变了. Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk.back 000055683333b000 64K r---- vim.gtk.back 000055683334b000 104K rw--- vim.gtk.back #删除vim.gtk后, 可以新建个同名文件; 但新文件有新的inode Linux Mint 19.1 Tessa $ sudo cp vim.gtk.save /usr/bin/vim.gtk Linux Mint 19.1 Tessa $ llh /usr/bin/vim.gtk -rwxr-xr-x 1 root root 3.1M Jun 13 17:08 /usr/bin/vim.gtk #pmap依然显示vim.gtk是已经删除状态, 因为这里用的老的inode Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk (deleted) 000055683333b000 64K r---- vim.gtk (deleted) 000055683334b000 104K rw--- vim.gtk (deleted) 结论: mv文件不改变文件的inode, 只改变文件名; cp新文件到正在打开的文件是非法的, 因为cp要open这个目的文件, 是对同一个inode操作. 如果合法, 那正在执行的文件, 其内容更改会引发未知错误. rm打开的文件是可以的, 或者说\"看起来\"是马上生效的, 但实际上, 如果老的inode还在被引用, 还是能被文件系统访问到. 升级正在运行的可执行文件, 比如vim.gtk, 要制造新的inode, 具体是: 先rm, 再cp成同名文件 升级后的文件, 只有app重新加载的时候才生效. 用户态通过系统调用陷入到内核态, 内存映射会变吗? 不会 You've got the general idea mostly right, but make this adjustment: there's only one \"kernelspace\" for the whole machine, and all processes share it. When a process is active, it can either be running in \"user mode\" or \"kernel mode\". In user mode, the instructions being executed by the CPU are in the userspace side of the memory map. The program is running its own code, or code from a userspace library. In user mode, a process has limited abilities. There is a flag in the CPU which tells it not to allow the use of privileged instructions, and kernel memory, although it exists in the process's memory map, is inaccessible. (You wouldn't want let any program just read and write the kernel's memory - all security would be gone.) When a process wants to do something other than move data around in its own (userspace) virtual memory, like open a file for example, it must make a syscall. Each CPU architecture has its own unique quirky method of making syscalls, but they all boil down to this: a magic instruction is executed, the CPU turns on the \"privileged mode\" flag, and jumps to a special address in kernelspace, the \"syscall entry point\". Now the process is running in kernel mode. Instructions being executed are located in kernel memory, and they can read and write any memory they want to. The kernel examines the request that the process just made and decides what to do with it. In the open example, the kernel receives 2 or 3 parameters corresponding to the arguments of int open(const char *filename, int flags[, int mode]). The first argument provides an example of when kernelspace needs access to userspace. You said open(\"foo\", O_RDONLY) so the string \"foo\" is part of your program in userspace. The syscall mechanism only passed a pointer, not a string, so the kernel must read the string from user memory. To find the requested file, the kernel may consult with filesystem drivers (to figure out where the file is) and block device drivers (to load the necessary blocks from disk) or network device drivers and protocols (to load the file from a remote source). All of those things are part of the kernel, i.e. in kernelspace, regardless of whether they are built-in or were loaded as modules. If the request can't be satisfied immediately, the kernel may put the process to sleep. That means the process will be taken off the CPU until a response is received from the disk or network. Another process may get a chance to run now. Later, when the response comes in, your process starts running again (still in kernel mode). Now that it's found the file, the open syscall can finish up (check the permissions, create a file descriptor) and return to userspace. Returning to userspace is a simple matter of putting the CPU back in non-privileged mode and restoring the registers to what they were before the user->kernel transition, with the instruction pointer pointing at the instruction after the magic syscall instruction. Besides syscalls, there are other things that can cause a transition from user mode to kernel mode, including: page faults - if your process accesses a virtual memory address that doesn't have a physical address assigned to it, the CPU enters kernel mode and jumps to the page fault handler. The kernel then decides whether the virtual address is valid or not, and it either creates a physical page and resumes the process in userspace where it left off, or sends a SIGSEGV. interrupts - some hardware (network, disk, serial port, etc.) notifies the CPU that it requires attention. The CPU enters kernel mode and jumps to a handler, the kernel responds to it and then resumes the userspace process that was running before the interrupt. Loading a module is done with a syscall that asks the kernel to copy the module's code and data into kernelspace and run its initialization code in kernel mode. This is pretty long, so I'm stopping. I hope the walk-through focusing on user-kernel transitions has provided enough examples to solidify the idea. uboot传mtdpart的时候，名字从哪来的？ 比如uboot会传cmdline给内核 mtdparts=octeon_nand0:0x20000000@0x0(nand);bootflash:0x20000@0x140000(statusA),0x20000@0x160000(statusB),0x140000@0x180000(bootA),0x140000@0x2c0000(bootB),0x1900000@0x400000(linuxA),0x1900000@0x1d00000(linuxB) 那么octeon_nand0和bootflash怎么来的？ 下面是内核的启动记录： [02.11] [ 30.741082] Bootbus flash: Setting flash for 64MB flash at 0x1bc00000 [02.11] [ 30.760360] bootflash: Found 1 x16 devices at 0x0 in 8-bit bank. Manufacturer ID 0x0000c2 Chip ID 0x00007e [02.11] [ 30.782739] Amd/Fujitsu Extended Query Table at 0x0040 [02.11] [ 30.800628] Amd/Fujitsu Extended Query version 1.3. [02.11] [ 30.818400] number of CFI chips: 1 [02.11] [ 30.834545] 6 cmdlinepart partitions found on MTD device bootflash [02.11] [ 30.853523] Creating 6 MTD partitions on \"bootflash\": [02.11] [ 30.871305] 0x000000140000-0x000000160000 : \"statusA\" [02.11] [ 30.889434] 0x000000160000-0x000000180000 : \"statusB\" [02.11] [ 30.907519] 0x000000180000-0x0000002c0000 : \"bootA\" [02.11] [ 30.925437] 0x0000002c0000-0x000000400000 : \"bootB\" [02.11] [ 30.943334] 0x000000400000-0x000001d00000 : \"linuxA\" [02.11] [ 30.961321] 0x000001d00000-0x000003600000 : \"linuxB\" [02.11] [ 30.979710] cvmx_nand_initialize: Setting timing parameter mode to 0 [02.11] [ 30.998826] octeon-nand 1070001000000.nand-flash-interface: NAND using BCH ecc [02.11] [ 31.018967] NAND 1 OOB size: 64, write size: 2048, erase size: 131072 [02.11] [ 31.038133] NAND device: Manufacturer ID: 0x2c, Chip ID: 0xf1 (Micron NAND 128MiB 3,3V 8-bit), 128MiB, page size: 2048, OOB size: 64 [02.11] [ 31.063631] Scanning device for bad blocks [02.11] [ 31.159228] mtd: octeon_nand0: partitioning exceeds flash size, truncating [02.11] [ 31.178825] 1 cmdlinepart partitions found on MTD device octeon_nand0 [02.11] [ 31.197990] Creating 1 MTD partitions on \"octeon_nand0\": [02.11] [ 31.216023] 0x000000000000-0x000008000000 : \"nand\" [02.11] [ 31.238898] Freeing unused kernel memory: 8952K (ffffffff80792000 - ffffffff81050000) 先说bootflash：在arch/mips/cavium-octeon/flash_setup.c中， 是cfi_flash的驱动 在它的probe函数里面，写死了名字：flash_map.name = \"bootflash\";并调用mtd_device_parse_register来解析mtd分区， 传入type cmdlinepart，意思是优先使用cmdlinepart来解析mtd分区 实际上，mtd支持两种，按顺序是\"cmdlinepart\"和\"ofpart\"这个函数里面调用：parse_mtd_partitions会根据以上两种规则创建mtd分区。 另外：uboot里面也有关于mtd的定义，估计是给uboot自己看的。 #define MTDPARTS_DEFAULT \\ \"octeon_nor0:2560k(bootloader)ro,\" \\ \"2m(kernel),\" \\ \"3520k(cramfs),\" \\ \"64k(environment)ro\\0\" #define MTDIDS_DEFAULT \"nor0=octeon_nor0\\0\" 为什么直接考过来的ls不能用？ mount debian的rootfs，从下面考了一个perl但不能直接运行，提示not found。 其实不是这个可执行文件找不到，而是它依赖的动态库不满足。本质上还是个依赖问题。 可以在编译的时候用-static来编成静态链接，这样随便考到哪里都能用了。 fork与malloc 问题: 在fork之前, 父进程malloc了内存, 比如char *p; 那么: 子进程能正常访问p吗? 内容与父进程一样吗? 子进程修改了p内存的内容, 父进程能看到吗? 子进程需要free(p)吗? 回答: #include #include #include #include #include int main(void) { char *something = malloc(256); sprintf(something, \"hello\"); pid_t child_pid = fork(); if (child_pid == 0) //child { /*子进程能够访问这个指针, 并且内容一样*/ printf(\"from child:%s\\n\", something); /*子进程修改这块内存, 但不影响父进程 C-O-W*/ sprintf(something, \"change to 11111\"); printf(\"from child:%s\\n\", something); /*虽然父子进程是独立的进程空间, 但这里指针的地址却是一样的*/ printf(\"from child:addr %p\\n\", something); /*如果不调用exec*函数, 和exit*函数, 那么确实需要在子进程也free, 所以这个例子里free应该写在最后return之前, 这样父子都都要调用*/ free(something); } else //parent { int status; while(wait(&status) != child_pid); printf(\"from parent:%s\\n\", something); printf(\"from parent:addr %p\\n\", something); free(something); } printf(\"dddddddddddddddddd\\n\"); return 0; } 运行结果 $ gcc test_fork_malloc.c ASBLX28:/home/yingjieb/tmp $ ./a.out from child:hello from child:change to 11111 from child:addr 0x84ec010 dddddddddddddddddd from parent:hello from parent:addr 0x84ec010 dddddddddddddddddd "},"notes/system_alpine.html":{"url":"notes/system_alpine.html","title":"Alpine Linux","keywords":"","body":" 现代化的工程系统 使用subgroup来组织repo 组织清爽, 源代码干净 aports bootstrap.sh 现代化的工程系统 alpine linux的全部开发都在 https://gitlab.alpinelinux.org/alpine 自己搭建的gitlab服务器, 允许外部用户注册, fork库, 并提交MR 使用gitlab-ci的CI/CD做build test 用gitlab issue来跟踪bug 文档也是repo管理, 使用Antora Playbook发布, 网页入口是 https://alpinelinux.org/ 使用subgroup来组织repo 比如CI/CD工具库在alpine/infra/docker/alpine-gitlab-ci下面, 先是根alpine, 再是infra, 再是docker, 最后是repo 组织清爽, 源代码干净 比如alpine-gitlab-ci/-/blob/master/overlay/usr/local/bin/build.sh里面的shell 输出代码: : \"${CI_ALPINE_BUILD_OFFSET:=0}\" : \"${CI_ALPINE_BUILD_LIMIT:=9999}\" msg() { local color=${2:-green} case \"$color\" in red) color=\"31\";; green) color=\"32\";; yellow) color=\"33\";; blue) color=\"34\";; *) color=\"32\";; esac printf \"\\033[1;%sm>>>\\033[1;0m %s\\n\" \"$color\" \"$1\" | xargs >&2 } verbose() { echo \"> \" \"$@\" # shellcheck disable=SC2068 $@ } debugging() { [ -n \"$CI_DEBUG_BUILD\" ] } debug() { if debugging; then verbose \"$@\" fi } die() { msg \"$1\" red exit 1 } capture_stderr() { \"$@\" 2>&1 } report() { report=$1 reportsdir=$APORTSDIR/logs/ mkdir -p \"$reportsdir\" tee -a \"$reportsdir/$report.log\" } aports alpine支持的package都放在aports这个库下面. main: alpine core team直接支持的package community: 由社区支持的package 参考: https://wiki.alpinelinux.org/wiki/Repositories /etc/apk/repositories是package的配置 / # cat /etc/apk/repositories https://dl-cdn.alpinelinux.org/alpine/v3.15/main https://dl-cdn.alpinelinux.org/alpine/v3.15/community 比如https://dl-cdn.alpinelinux.org/alpine/v3.15/main目录下包括了所有arch的预编译好的apk点进去看这些apk的修改时间是不一样的, 说明apk是按需编译的. bootstrap.sh 似乎可以用它来生成交叉编译的工具链 "},"notes/system_进程间通信.html":{"url":"notes/system_进程间通信.html","title":"进程间通信","keywords":"","body":" ipcs查看进程间通信的情况, 包括消息队列, 共享内存, semaphore 进程间通信类型 signal 匿名管道 有名管道和FIFO 消息队列 共享内存 信号量 futex Unix domain socket Netlink socket Network socket Inotify机制 FUSE文件系统 D-BUS 参考: http://www.chandrashekar.info/articles/linux-system-programming/introduction-to-linux-ipc-mechanims.html https://tldp.org/LDP/tlk/ipc/ipc.html#:~:text=1%20System%20V%20IPC%20Mechanisms,all%20share%20common%20authentication%20methods. ipcs查看进程间通信的情况, 包括消息队列, 共享内存, semaphore Linux Mint 19 Tara $ ipcs ------ Message Queues -------- key msqid owner perms used-bytes messages ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status 0x00000000 65536 bai 600 524288 2 dest 0x00000000 163841 bai 600 33554432 2 dest 0x00000000 196610 bai 600 33554432 2 dest 0x00000000 294915 bai 600 524288 2 dest 0x00000000 393220 bai 600 524288 2 dest 0x00000000 491525 bai 600 4194304 2 dest 0x00000000 524294 bai 777 2006712 2 0x00000000 622599 bai 777 3035136 2 0x00000000 655368 bai 600 4194304 2 dest 0x00000000 753673 bai 600 524288 2 dest 0x00000000 786442 bai 600 1048576 2 dest 0x00000000 884747 bai 600 524288 2 dest 0x00000000 917516 bai 777 2304 2 0x00000000 950285 bai 600 33554432 2 dest ------ Semaphore Arrays -------- key semid owner perms nsems 进程间通信类型 signal overhead最小, 用来通知进程关于内核和其他进程状态的改变 内核打断进程正常的流程, 调用其注册的handler或者默认的handler Signals are the cheapest forms of IPC provided by Linux. Their primary use is to notify processes of change in states or events that occur within the kernel or other processes. We use signals in real world to convey messages with least overhead - think of hand and body gestures. For example, in a crowded gathering, we raise a hand to gain attention, wave hand at a friend to greet and so on. On Linux, the kernel notifies a process when an event or state change occurs by interrupting the process's normal flow of execution and invoking one of the signal handler functinos registered by the process or by the invoking one of the default signal dispositions supplied by the kernel, for the said event. 匿名管道 生成两个描述符分别用于读和写 用于父子进程, 父进程创建管道, 在folk的时候, 这个管道被dup进子进程的空间 Anonymous pipes (or simply pipes, for short) provide a mechanism for one process to stream data to another. A pipe has two ends associated with a pair of file descriptors - making it a one-to-one messaging or communication mechanism. One end of the pipe is the read-end which is associated with a file-descriptor that can only be read, and the other end is the write-end which is associated with a file descriptor that can only be written. This design means that pipes are essentially half-duplex. Anonymous pipes can be setup and used only between processes that share parent-child relationship. Generally the parent process creates a pipe and then forks child processes. Each child process gets access to the pipe created by the parent process via the file descriptors that get duplicated into their address space. This allows the parent to communicate with its children, or the children to communicate with each other using the shared pipe. Pipes are generally used to implement Producer-Consumer design amongst processes - where one or more processes would produce data and stream them on one end of the pipe, while other processes would consume the data stream from the other end of the pipe. 有名管道和FIFO 在两个独立的进程间, 打开一个特定的FIFO文件来通信 Named pipes (or FIFO) are variants of pipe that allow communication between processes that are not related to each other. The processes communicate using named pipes by opening a special file known as a FIFO file. One process opens the FIFO file from writing while the other process opens the same file for reading. Thus any data written by the former process gets streamed through a pipe to the latter process. The FIFO file on disk acts as the contract between the two processes that wish to communicate. 消息队列 类似于邮箱, 一个进程写消息然后退出, 另一个进程可以从同一个消息队列里读消息 通信双方不需要建立连接, 而作为对比, pipe是需要先建立连接的. 支持多对多 Message queues allow one or more processes to write messages, which will be read by one or more reading processes linux支持两种消息队列 system V: 带message号 posix: 带message优先级 man mq_overview mq_open mq_send mq_receive等函数都是系统调用 Message Queues are synonymous to mailboxes. One process writes a message packet on the message queue and exits. Another process can access the message packet from the same message queue at a latter point in time. The advantage of message queues over pipes/FIFOs are that the sender (or writer) processes do not have to wait for the receiver (or reader) processes to connect. Think of communication using pipes as similar to two people communicating over phone, while message queues are similar to two people communicating using mail or other messaging services. There are two standard specifications for message queues. SysV message queues. The AT&T SysV message queues support message channeling. Each message packet sent by senders carry a message number. The receivers can either choose to receive message that match a particular message number, or receive all other messages excluding a particular message number or all messages. POSIX message queues. The POSIX message queues support message priorities. Each message packet sent by the senders carry a priority number along with the message payload. The messages get ordered based on the priority number in the message queue. When the receiver tries to read a message at a later point in time, the messages with higher priority numbers get delivered first. POSIX message queues also support asynchronous message delivery using threads or signal based notification. 共享内存 一个进程把自己进程空间的一部分共享给另一个. 有两种类型: sysv: 比较古老 posix: 现代的, 使用ram文件系统的文件 As the name implies, this IPC mechanism allows one process to share a region of memory in its address space with another. This allows two or more processes to communicate data more efficiently amongst themselves with minimal kernel intervention. There are two standard specifications for Shared memory. SysV Shared memory. Many applications even today use this mechanism for historical reasons. It follows some of the artifacts of SysV IPC semantics. POSIX Shared memory. The POSIX specifications provide a more elegant approach towards implementing shared memory interface. On Linux, POSIX Shared memory is actually implemented by using files backed by RAM-based filesystem. I recommend using this mechanism over the SysV semantics due to a more elegant file based semantics. 信号量 Semaphores are locking and synchronization mechanism used most widely when processes share resources. Linux supports both SysV semaphores and POSIX semaphores. POSIX semaphores provide a more simpler and elegant implementation and thus is most widely used when compared to SysV semaphores on Linux. futex linux系统调用 Futexes are high-performance low-overhead locking mechanisms provided by the kernel. Direct use of futexes is highly discouraged in system programs. Futexes are used internally by POSIX threading API for condition variables and its mutex implementations. Unix domain socket C-S架构, 全双工, 支持stream和datagram方式 大型软件用的很多 UNIX Domain Sockets provide a mechanism for implementing applications that communicate using the Client-Server architecture. They support both stream and datagram oriented communication, are full-duplex and support a variety of options. They are very widely used for developing many large-scale frameworks. Netlink socket 和socket接口一样, 但主要用于: 内核线程和用户进程通信 用户控件的进程间的广播通信 Netlink sockets are similar to UNIX Domain Sockets in its API semantics - but used mainly for two purposes: For communication between a process in user-space to a thread in kernel-space For communication amongst processes in user-space using broadcast mode. Network socket 网络socket Based on the same API semantics like UNIX Domain Sockets, Network Sockets API provide mechanisms for communication between processes that run on different hosts on a network. Linux has rich support for features and various protocol stacks for using network sockets API. For all kinds of network programming and distributed programming - network socket APIs form the core interface. Inotify机制 监控文件系统改变的, 可以和poll select等联用. inotify是Linux内核2.6.13 (June 18, 2005)版本新增的一个子系统（API），它提供了一种监控文件系统（基于inode的）事件的机制，可以监控文件系统的变化如文件修改、新增、删除等，并可以将相应的事件通知给应用程序。该机制由著名的桌面搜索引擎项目beagle引入用于替代此前具有类似功能但存在诸多缺陷的dnotify。 The Inotify API on Linux provides a method for processes to know of any changes on a monitored file or a directory asynchronously. By adding a file to inotify watch-list, a process will be notified by the kernel on any changes to the file like open, read, write, changes to file stat, deleting a file and so on. FUSE文件系统 FUSE provides a method to implement a fully functional filesystem in user-space. Various operations on the mounted FUSE filesystem would trigger functions registered by the user-space filesystem handler process. This technique can also be used as an IPC mechanism to implement Client-Server architecture without using socket API semantics. D-BUS 桌面系统用的多, 是建立在socket API基础上的多进程通信的系统 D-Bus is a high-level IPC mechanism built generally on top of socket API that provides a mechanism for multiple processes to communicate with each other using various messaging patterns. D-Bus is a standards specification for processes communicating with each other and very widely used today by GUI implementations on Linux following Freedesktop.org specifications. "},"notes/system_特殊功能fd.html":{"url":"notes/system_特殊功能fd.html","title":"特殊功能fd","keywords":"","body":"除了普通文件fd, socket fd, Linux还提供了比较特殊的几种fd, 比如eventfd timerfd signalfd等等. signalfd timerfd timerfd API 注epoll使用简介 边沿触发和电平触发 epoll_wait eventfd概念 用法 进程间共享文件描述符 各种fd是系统调用 用perf看所有带fd的系统调用 perf list | grep syscalls | grep fd | grep enter root@godev-server:/home/yingjieb# perf list | grep syscalls | grep fd | grep enter syscalls:sys_enter_eventfd [Tracepoint event] syscalls:sys_enter_eventfd2 [Tracepoint event] syscalls:sys_enter_fdatasync [Tracepoint event] syscalls:sys_enter_gettimeofday [Tracepoint event] syscalls:sys_enter_memfd_create [Tracepoint event] syscalls:sys_enter_settimeofday [Tracepoint event] syscalls:sys_enter_signalfd [Tracepoint event] syscalls:sys_enter_signalfd4 [Tracepoint event] syscalls:sys_enter_timerfd_create [Tracepoint event] syscalls:sys_enter_timerfd_gettime [Tracepoint event] syscalls:sys_enter_timerfd_settime [Tracepoint event] syscalls:sys_enter_userfaultfd [Tracepoint event] 下面就介绍一下这些fd的使用. signalfd #include #include #include #include #include #define handle_error(msg) \\ do { perror(msg); exit(EXIT_FAILURE); } while (0) int main(int argc, char *argv[]) { sigset_t mask; int sfd; struct signalfd_siginfo fdsi; ssize_t s; sigemptyset(&mask); sigaddset(&mask, SIGINT); sigaddset(&mask, SIGQUIT); /* 阻塞信号以使得它们不被默认的处理试方式处理 */ if (sigprocmask(SIG_BLOCK, &mask, NULL) == -1) handle_error(\"sigprocmask\"); sfd = signalfd(-1, &mask, 0); if (sfd == -1) handle_error(\"signalfd\"); for (;;) { s = read(sfd, &fdsi, sizeof(struct signalfd_siginfo)); if (s != sizeof(struct signalfd_siginfo)) handle_error(\"read\"); if (fdsi.ssi_signo == SIGINT) { printf(\"Got SIGINT\\n\"); } else if (fdsi.ssi_signo == SIGQUIT) { printf(\"Got SIGQUIT\\n\"); exit(EXIT_SUCCESS); } else { printf(\"Read unexpected signal\\n\"); } } } 这个例子只是很简单的说明了使用signalfd的方法，并没有真正发挥它的作用，有了这个API，就可以将信号处理作为IO看待.每一个信号集合（或者某一个对应的信号）就会有对应的文件描述符，这样将信号处理的流程大大简化，将应用程序中的业务作为文件来操作，也体现了linux下的一切皆文件的说法，非常好，假如有很多种信号等待着处理，每一个信号描述符对待一种信号的处理，那么就可以将信号文件描述符设置为非阻塞，同时结合epoll使用，对信号的处理转化为IO复用，和这个有相似之处的API还有timerfd timerfd 使用timerfd的一个例子是libevent. 在linux下面, 默认的libevent使用epoll, epoll有个超时时间.libevent利用这个超时时间来做定时器的触发源, 即在event loop里面, 把定时器堆的时间做为超时时间.更具体一些, 在libevent初始化时:默认情况下, libevent不使用timerfd, epollop->timerfd = -1.但有EVENT_BASE_FLAG_PRECISE_TIMER情况下, if ((base->flags & EVENT_BASE_FLAG_PRECISE_TIMER) && base->monotonic_timer.monotonic_clock == CLOCK_MONOTONIC) { int fd; fd = epollop->timerfd = timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK|TFD_CLOEXEC); if (epollop->timerfd >= 0) { struct epoll_event epev; memset(&epev, 0, sizeof(epev)); epev.data.fd = epollop->timerfd; epev.events = EPOLLIN; //把这个fd加入epoll epoll_ctl(epollop->epfd, EPOLL_CTL_ADD, fd, &epev) 参考: https://blog.csdn.net/KangRoger/article/details/47844443 所以这里的timerfd_create()就是timerfd的使用方法. timerfd API #include int timerfd_create(int clockid, int flags); //这个时间精度应该比ms高. int timerfd_settime(int fd, int flags, const struct itimerspec *new_value, struct itimerspec *old_value); int timerfd_gettime(int fd, struct itimerspec *curr_value); read系统调用会返回超时次数, 如果一次超时都没到, read阻塞. timerfd_create用于创建一个定时器文件，函数返回值是一个文件句柄fd。 timerfd_settime用于设置新的超时时间，并开始计时。flag为0表示相对时间，为1表示绝对时间。new_value为这次设置的新时间，old_value为上次设置的时间。返回0表示设置成功。 timerfd_gettime用于获得定时器距离下次超时还剩下的时间。如果调用时定时器已经到期，并且该定时器处于循环模式（设置超时时间时struct itimerspec::it_interval不为0），那么调用此函数之后定时器重新开始计时。 注epoll使用简介 man epoll可以看到, epoll的API有 epoll_create() : 用于创建epoll对象 epoll_ctl() : 用于管理fd set epoll_wait() : 用于等待IO 边沿触发和电平触发 epoll有类似硬件的触发概念 edge-triggered (ET): 边沿触发, 只有fd的状态有变化才触发. 例如epoll_wait返回一个fd可读, 它实际有2k的数据可以读, 但回调函数里只读了1k. 即使还有1k数据可读, 在ET触发模式下, epoll不会再触发fd可读. 用ET触发的推荐场景是: 这个fd是非阻塞的 并且read或者write返回EAGAIN level-triggered (LT): 电平触发, 这是默认触发方式 epoll_wait #include int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 这里的timeout单位是ms, 是用CLOCK_MONOTONIC度量的. epoll_wait返回有几种可能: 底层driver有数据, event到达 超时, -1表示永久等待. 0表示立即返回 被signal eventfd概念 eventfd()是个系统调用, 生成一个event fd对象, 内核为其维护一个计数器, 用来做用户进程间的wait/nofify机制, 也可以被kernel用来通知用户态进程. 可以用来代替pipe(), 相比于pipe来说，少用了一个文件描述符，而且不必管理缓冲区，单纯的事件通知的话，方便很多在fork()的时候, 子进程继承eventfd, 对应同一个eventfd对象, 并且, 这个fd在execve()后仍然保持, 但如果有close-on-exec选项则不保持. 创建eventfd以后, 可以子进程写, 父进程读; 读的时候, 只要计数器非0, 就返回计数器值, 并reset到0; 计数器为0则block 计数器不溢出就可以写, 写的值加到计数器上. 溢出的话会阻塞. 也可以配合poll(), select()使用 用法 #include int eventfd(unsigned int initval, int flags); read() write() close() //glibc还提供: typedef uint64_t eventfd_t; int eventfd_read(int fd, eventfd_t *value); int eventfd_write(int fd, eventfd_t value); 进程间共享文件描述符 在 OVS架构和代码中, qemu通过unix socket传递eventfd的文件描述符给OVS, 实际上是用了socket的SCM_RIGHTS方法. 实际上, 也可以用pipe之类的进程间通信为载体, 其底层是通过ioctl的I_SENDFD和I_RECVFD完成的. 详见 http://poincare.matf.bg.ac.rs/~ivana/courses/ps/sistemi_knjige/pomocno/apue/APUE/0201433079/ch17lev1sec4.html 出自Advanced Programming in the UNIX® Environment: Second Edition 2005看来这技术有十几年的时间了发送进程: #include \"apue.h\" #include /* * Pass a file descriptor to another process. * If fd= 0) if (ioctl(fd, I_SENDFD, fd_to_send) 接收进程: //接收时, 第三个参数是strrecvfd 结构体 struct strrecvfd { int fd; /* new descriptor */ uid_t uid; /* effective user ID of sender */ gid_t gid; /* effective group ID of sender */ char fill[8]; }; #include \"apue.h\" #include /* * Receive a file descriptor from another process (a server). * In addition, any data received from the server is passed * to (*userfunc)(STDERR_FILENO, buf, nbytes). We have a * 2-byte protocol for receiving the fd from send_fd(). */ int recv_fd(int fd, ssize_t (*userfunc)(int, const void *, size_t)) { int newfd, nread, flag, status; char *ptr; char buf[MAXLINE]; struct strbuf dat; struct strrecvfd recvfd; status = -1; for ( ; ; ) { dat.buf = buf; dat.maxlen = MAXLINE; flag = 0; if (getmsg(fd, NULL, &dat, &flag) 0) if ((*userfunc)(STDERR_FILENO, buf, nread) != nread) return(-1); if (status >= 0) /* final data has arrived */ return(newfd); /* descriptor, or -status */ } } 下面的例子说明, 两个进程想要传递fd, 要先有个通道, 比如pipe, 或者socket, 用来传递fd. #include #include #include #include #include #define TESTFILE \"/dev/null\" main(int argc, char *argv[]) { int fd; int pipefd[2]; struct stat statbuf; stat(TESTFILE, &statbuf); statout(TESTFILE, &statbuf); pipe(pipefd); if (fork() == 0) { close(pipefd[0]); sendfd(pipefd[1]); } else { close(pipefd[1]) recvfd(pipefd[0]); } } sendfd(int p) { int tfd; tfd = open(TESTFILE, O_RDWR); ioctl(p, I_SENDFD, tfd); } recvfd(int p) { struct strrecvfd rfdbuf; struct stat statbuf; char fdbuf[32]; ioctl(p, I_RECVFD, &rfdbuf); fstat(rfdbuf.fd, &statbuf); sprintf(fdbuf, \"recvfd=%d\", rfdbuf.fd); statout(fdbuf, &statbuf); } statout(char *f, struct stat *s) { printf(\"stat: from=%s mode=0%o, ino=%ld, dev=%lx, rdev=%lx\\n\", f, s->st_mode, s->st_ino, s->st_dev, s->st_rdev); fflush(stdout); } "},"notes/gitlab_ci.html":{"url":"notes/gitlab_ci.html","title":"gitlab CI","keywords":"","body":" 安装和注册gitlab runner runner介绍 Group runner Set up a group Runner manually 前置条件:安装docker 安装runner 注册runner runner使用和.gitlab-ci.yml runner管理 image和services docker runner和shell runner job和script 全局配置 stages和workflow include其他yml 可配参数参考 预定义的变量 How to do continuous integration like a boss touble shooting 解决docker内git clone/下载失败问题 merge request gitlab支持pipeline, 官方详细参考, 很全, 很细节 docker方式参考, 实用 快速入门 安装和注册gitlab runner runner介绍 gitlab runner简介是用来执行工程根目录下的.gitlab-ci.yml. 有三种类型的runner Shared (for all projects) Group (for all projects in a group) Specific (for specific projects) 不同的job由不同的runner执行 这里我们实用Group runner Group runner group的admin可以创建group runner. 到gitlab Settings页面 CI/CD下面的Runner配置页面, 找下面的信息 比如这个是https://gitlabe1.ext.net.nokia.com/groups/godevsig 的group runner信息 Set up a group Runner manually Install GitLab Runner Specify the following URL during the Runner setup: https://gitlabe1.ext.net.nokia.com/ Use the following registration token during setup: Aprw1hQ6nuxyra5dzVwQ Start the Runner! 前置条件:安装docker docker安装官方参考 安装完毕后, 如果显示docker ps socket权限问题, 则需要把用户加入到docker组, 特别的, 这里要把gitlab-runner加进去 sudo usermod -a -G docker gitlab-runner 安装runner 增加gitlab源 # For Debian/Ubuntu/Mint curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash # For RHEL/CentOS/Fedora curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash 安装 # For Debian/Ubuntu/Mint export GITLAB_RUNNER_DISABLE_SKEL=true; sudo -E apt-get install gitlab-runner # For RHEL/CentOS/Fedora export GITLAB_RUNNER_DISABLE_SKEL=true; sudo -E yum install gitlab-runner 注册runner 根据上面工程的信息, 注册runner sudo gitlab-runner register \\ --url \"https://gitlabe1.ext.net.nokia.com/\" \\ --description \"docker-godevsig\" \\ --registration-token \"Aprw1hQ6nuxyra5dzVwQ\" \\ --executor \"docker\" \\ --tag-list \"docker-generic\" \\ --docker-image alpine:latest 在ubuntu上, 看runner服务的状态 yingjieb@cloud-server-1:~$ systemctl status gitlab-runner ● gitlab-runner.service - GitLab Runner Loaded: loaded (/etc/systemd/system/gitlab-runner.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2020-09-19 16:11:41 UTC; 2 days ago Main PID: 1944 (gitlab-runner) Tasks: 35 (limit: 4915) CGroup: /system.slice/gitlab-runner.service └─1944 /usr/bin/gitlab-runner run --working-directory /home/gitlab-runner --config /etc/gitlab-runner/config.toml --service gitlab-runner --syslog --user gitlab-runner 工作目录是/home/gitlab-runner config文件/etc/gitlab-runner/config.toml 使用gitlab-runner用户 runner使用和.gitlab-ci.yml runner管理 yingjieb@cloud-server-1:~$ gitlab-runner -h 支持很多命令 start stop restart status register unregister install uninstall 等等 image和services image: 可以放在default里面, 表示runner的基础docker镜像 services: 也是docker镜像, 是给image提供服务的镜像 service的玩法是启动一个service镜像, 可以指定镜像, 可以修改镜像的entrypoint, 可以改默认 docker runner和shell runner runner可以run在docker里面, 也可以是实际host的shell docker runner使用说明 shell runner使用说明 job和script job是runner的基础执行单元, job之间是并行执行的. job是用户定义的, 但不能是保留字 job的script是必须的, 可以有其他可选配置 官方例子for go: image: golang:latest variables: # Please edit to your GitLab project REPO_NAME: gitlab.com/namespace/project # The problem is that to be able to use go get, one needs to put # the repository in the $GOPATH. So for example if your gitlab domain # is gitlab.com, and that your repository is namespace/project, and # the default GOPATH being /go, then you'd need to have your # repository in /go/src/gitlab.com/namespace/project # Thus, making a symbolic link corrects this. before_script: - mkdir -p $GOPATH/src/$(dirname $REPO_NAME) - ln -svf $CI_PROJECT_DIR $GOPATH/src/$REPO_NAME - cd $GOPATH/src/$REPO_NAME stages: - test - build - deploy format: stage: test script: - go fmt $(go list ./... | grep -v /vendor/) - go vet $(go list ./... | grep -v /vendor/) - go test -race $(go list ./... | grep -v /vendor/) compile: stage: build script: - go build -race -ldflags \"-extldflags '-static'\" -o $CI_PROJECT_DIR/mybinary artifacts: paths: - mybinary 全局配置 有几个配置可以配成全局的 stages和workflow stages是顺序执行的 stages: - build - test - deploy workflow是全局的执行条件, 是条件规则集合, 规则依次匹配 workflow: rules: - if: '$CI_PIPELINE_SOURCE == \"schedule\"' when: never - if: '$CI_PIPELINE_SOURCE == \"push\"' when: never - when: always This example never allows pipelines for schedules or push (branches and tags) pipelines, but does allow pipelines in all other cases, including merge request pipelines. workflow有官方模板可以参考 include其他yml 有4种include类型 Method Description local Include a file from the local project repository. file Include a file from a different project repository. remote Include a file from a remote URL. Must be publicly accessible. template Include templates that are provided by GitLab. 可配参数参考 Parameter details 预定义的变量 有些变量是预定义的 比如 CI_PROJECT_DIR CI_BUILDS_DIR CI_PIPELINE_SOURCE CI_COMMIT_TAG CI_COMMIT_BRANCH 其中几个在if条件里挺有用: Example rules Details if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"' Control when merge request pipelines run. if: '$CI_PIPELINE_SOURCE == \"push\"' Control when both branch pipelines and tag pipelines run. if: $CI_COMMIT_TAG Control when tag pipelines run. if: $CI_COMMIT_BRANCH Control when branch pipelines run. How to do continuous integration like a boss 参考gitlab本身的ci配置 和这篇攻略 touble shooting 解决docker内git clone/下载失败问题 原因是docker内的mtu设置比host大. 修改方法如下 增加docker的配置文件, 指定mtu yingjieb@cloud-server-1:~$ cat /etc/docker/daemon.json { \"mtu\": 1400 } 然后重启docker daemon sudo systemctl restart docker merge request 一个forked repo的developer给parent发出merge request, 会在forked repo下面执行gitlab ci的. 过程如下 Fork a parent project. Create a merge request from the forked project that targets the master branch in the parent project. A pipeline runs on the merge request. A maintainer from the parent project checks the pipeline result, and merge into a target branch if the latest pipeline has passed. Currently, those pipelines are created in a forked project, not in the parent project. This means you cannot completely trust the pipeline result, because, technically, external contributors can disguise their pipeline results by tweaking their GitLab Runner in the forked project. There are multiple reasons why GitLab doesn’t allow those pipelines to be created in the parent project, but one of the biggest reasons is security concern. External users could steal secret variables from the parent project by modifying .gitlab-ci.yml, which could be some sort of credentials. This should not happen. 目前的状态是, forked repo发出的merge request不能在parent执行. 有个proposal解决这个问题: Allow fork pipelines to run in parent project 但现在的版本12.7.6还没有这个功能. "}}