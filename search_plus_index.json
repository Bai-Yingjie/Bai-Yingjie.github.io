{"./":{"url":"./","title":"简介","keywords":"","body":"Bai-Yingjie.github.io 个人笔记汇总 https://bai-yingjie.github.io/大部分笔记只是流水账, 毫无章法.我的习惯是越新的内容越在上面, 需要看的话建议倒叙阅读.有部分笔记跨越了好几年, 所以有时候底下的内容看起来略简单. "},"notes/as_title.html":{"url":"notes/as_title.html","title":"Golang","keywords":"","body":"如题 "},"notes/golang_语法基础.html":{"url":"notes/golang_语法基础.html","title":"语法基础","keywords":"","body":" 初始化和空值 结构体 声明空切片 new切片 空切片的实例化 总结 字符串支持比较操作符 空白标识符 空白标识符和err 空白标识符和编译unused检查 空白标识符和类型检查 go 是静态类型语言 interface类型的变量可以重复赋值为任意类型 可以在循环里用:语法糖赋值 连续赋值可以支持重复声明 结构体和json反射 结构体定义里的反射字段 反射 Golang的单引号、双引号与反引号 变长参数 flag包用来解析cmd参数 内置len copy 和cap 字符串 字节数组 符文 常量和iota 格式化和scan print scan 减小go可执行文件的size go doc看说明 go内置pacakge go 环境变量 go test框架 远程包 go 工程布局(layout) 典型的go workspace布局 完整布局参考 go知识点 值传递和指针类型 struct 形式 结构体方法 基于指针对象的方法 继承 结构体可以比较 new分配内存 工厂模式初始化 接口 interface 类型断言 类型断言判断对象是否实现了一个接口 goroutine 通道 带缓冲的通道 通道用close来关闭 切片 切片的append map 集合 delete可以删除元素 range 初始化和空值 结构体 先说结论, 初始化时没有赋值的结构体, 其内容是零值, 但这个对象的地址不是nil; 这个对象也不能和nil比较 type MystructStr struct { s string a int } var ms MystructStr //ms是在地址0xc0000d00e0上的24字节大小的结构体 ({ 0 0}, main.MystructStr)@[*0xc0000d00e0, 24] //&ms不是nil, ms本身也不能和nil比较 声明空切片 对于切片, map等对象来说, 变量名代指切片; 切片的地址可以和nil比较, 切片也可以和nil比较, 这是两码事. 切片和nil可以比较是go语法的规定. var sl []int //判断成立, 会打印 //这里应该理解成, sl的内容为空; 注意sl的内容为空, 不是说它本身的地址是nil. //做为一个变量, sl本身的地址不可能为nil. if sl == nil { fmt.Println(\"nillll\") } new切片 对于new返回的地址, sn是真正的地址类似于sn := &[]int{}, 变量名指切片的地址那么sn就不是nil, 但它指向一个空的切片 sn := new([]int) if sn != nil { fmt.Println(sn) } //结果 &[] 空切片的实例化 //si不为nil si := []int{} 总结 //len(s1)=0;cap(s1)=0;s1==nil var s1 []int //len(s1)=0;cap(s1)=0;s2!=nil s2 := []int{} //len(s3)=0;cap(s3)=0;s3!=nil s3 := make([]int, 0) 指针是否为nil说的是指针是否指向东西. 切片等结构体头也类似于指针. 所以切片是否为nil也说的是切片头是否指向实际的东西 只有var s1 []int形式的声明, 声明了一个切片变量, 只是个声明, 没有给\"指针\"赋值, 所以此时s1为nil new也没有实例化, 但new返回指针, 指向interface对象本身, 所以也不是nil 其他形式, 比如:= make, 都会实例化, 即接口的\"指针\"字段都指向实例. 所以都不是nil 字符串支持比较操作符 原生的比较符可以直接用来比较字符串 ==, !=, >=, . 它们都返回bool值 另外一种写法是func Compare(str1, str2 string) int result1 := \"GFG\" > \"Geeks\" fmt.Println(\"Result 1: \", result1) result2 := \"GFG\" = \"for\" fmt.Println(\"Result 3: \", result3) result4 := \"Geeks\" 空白标识符 空白标识符可以占位任何类型 空白标识符和err if _, err := os.Stat(path); os.IsNotExist(err) { fmt.Printf(\"%s does not exist\\n\", path) } 有时为了省事, 直接把err给\"占位\"了, 这样是不对的. // Bad! This code will crash if path does not exist. fi, _ := os.Stat(path) if fi.IsDir() { fmt.Printf(\"%s is a directory\\n\", path) } 空白标识符和编译unused检查 go会检查代码, 没有用的import和变量会报错误. 用占位符可以让编译器happy: 这里fmt和io以及变量fd没有使用, 一般编译会报错, 用占位符就不会. package main import ( \"fmt\" \"io\" \"log\" \"os\" ) var _ = fmt.Printf // For debugging; delete when done. var _ io.Reader // For debugging; delete when done. func main() { fd, err := os.Open(\"test.go\") if err != nil { log.Fatal(err) } // TODO: use fd. _ = fd } 把import的包赋值给占位符, 相当于不用这个包, 但包里的init会被调用. import _ \"net/http/pprof\" 空白标识符和类型检查 go的类型检查发生在编译时, 传入的对象必须和函数的参数类型一致. 但也可以运行时检查: 下面是json的encoder代码, 它检查如果传入的值实现了json.Marshaler接口, 就调用这个值的MarshalJSON方法, 而不是调用标准的MarshalJSON方法. m, ok := val.(json.Marshaler) 这种运行时检查很常见, 比如判断一个值是否实现了某个接口, 可以这样: 用空白标识符来占位返回的值, 只看ok. if _, ok := val.(json.Marshaler); ok { fmt.Printf(\"value %v of type %T implements json.Marshaler\\n\", val, val) } json.Marshaler和json.RawMessage的定义 Linux Mint 19.1 Tessa $ go doc json.Marshaler type Marshaler interface { MarshalJSON() ([]byte, error) } Marshaler is the interface implemented by types that can marshal themselves into valid JSON. yingjieb@yingjieb-VirtualBox ~/repo/myrepo/try Linux Mint 19.1 Tessa $ go doc json.RawMessage type RawMessage []byte RawMessage is a raw encoded JSON value. It implements Marshaler and Unmarshaler and can be used to delay JSON decoding or precompute a JSON encoding. func (m RawMessage) MarshalJSON() ([]byte, error) func (m *RawMessage) UnmarshalJSON(data []byte) error 如果json.Marshaler的定义变了, 那么一个原本实现了这个接口的类型,就不再有效了. 此时只有等到运行时的类型断言才能知道, 有办法在编译时就知道吗? 可以: 用空白标识符可以进行静态检查: 这里用_代替变量名 //这里是个强制转换, 把nil转换为(*RawMessage) //我认为这里转换为(RawMessage)也行. var _ json.Marshaler = (*RawMessage)(nil) 如果json.Marshaler接口变化了, 这段代码就编不过. go 是静态类型语言 虽然go有语法糖, 可以根据右值来自动解析数据类型. 但不要把它当作动态语言来用了. // 编译器自动知道mys是string mys := \"hhhh\" // 给mys赋值64会报错: cannot use 64 (type int) as type string in assignment mys = 64 动态语言, 变量可以随便赋值为不同种类的. interface类型的变量可以重复赋值为任意类型 The interface{} (empty interface) type describes an interface with zero methods. Every Go type implements at least zero methods and therefore satisfies the empty interface. func describe(i interface{}) { fmt.Printf(\"(%v, %T)\\n\", i, i) } var mi interface{} mi = \"a string\" describe(mi) mi = 2011 describe(mi) mi = 2.777 describe(mi) #输出 (a string, string) (2011, int) (2.777, float64) 可以在循环里用:语法糖赋值 func main() { fmt.Println(\"Hello, playground\") for i := 0; i 连续赋值可以支持重复声明 一般在一个语句块里, 不能对单个变量重复用:=声明; 但可以对连续变量重复声明 Unlike regular variable declarations, a short variable declaration may redeclare variables provided they were originally declared earlier in the same block with the same type, and at least one of the non-blank variables is new. As a consequence, redeclaration can only appear in a multi-variable short declaration. Redeclaration does not introduce a new variable; it just assigns a new value to the original. v := 1 v := 2 fmt.Println(v) // 编译时, 只有v的第二次冒号赋值会报错. ./prog.go:18:4: no new variables on left side of := // 但下面是可以的 func main() { a, b := 1, 2 c, b := 3, 4 fmt.Println(a, b, c) } // 一个经常见的例子是 f, err := os.Open(name) if err != nil { return err } d, err := f.Stat() if err != nil { f.Close() return err } codeUsing(f, d) 注: open等调用返回的error是个内建的类型, 必须用if err != nil来判断; 不能用if err来判断, 因为error类型不是bool类型 ./prog.go:11:2: non-bool err (type error) used as if condition 结构体和json反射 结构体定义里的反射字段 先定义和json对应的struct, 要导出的字段首字母大写. json.Unmarshal()把json转为struct json.Marshal()把struct转为json 这里的反射大概是指//可以选择的控制字段有三种： // -：不要解析这个字段 // omitempty：当字段为空（默认值）时，不要解析这个字段。比如 false、0、nil、长度为 0 的 array，map，slice，string // FieldName：当解析 json 的时候，使用这个名字 type StudentWithOption struct { StudentId string //默认使用原定义中的值 StudentName string `json:\"sname\"` // 解析（encode/decode） 的时候，使用 `sname`，而不是 `Field` StudentClass string `json:\"class,omitempty\"` // 解析的时候使用 `class`，如果struct 中这个值为空，就忽略它 StudentTeacher string `json:\"-\"` // 解析的时候忽略该字段。默认情况下会解析这个字段，因为它是大写字母开头的 } //与json数据对应的结构体 type Server struct { ServerName string ServerIP string } // 数组对应slice type ServerSlice struct { Servers []Server } //将JSON数据解析成结构体 package main import ( \"encoding/json\" \"fmt\" ) func main() { var s ServerSlice str := `{\"servers\":[{\"serverName\":\"TianJin\",\"serverIP\":\"127.0.0.1\"}, {\"serverName\":\"Beijing\",\"serverIP\":\"127.0.0.2\"}]}` json.Unmarshal([]byte(str), &s) fmt.Println(s) } ----output----- {[{TianJin 127.0.0.1} {Beijing 127.0.0.2}]} 反射 Reflection（反射）在计算机中表示 程序能够检查自身结构的能力，尤其是类型 func main() { var x float64 = 3.4 fmt.Println(reflect.TypeOf(x)) //float64 t := reflect.TypeOf(x) fmt.Println(t) //float64 // 注: 我认为其输出也可以叫reflect.Type fmt.Println(reflect.TypeOf(t)) //*reflect.rtype //相关代码在 go/src/reflect/value.go v := reflect.ValueOf(x) fmt.Println(v) //3.4 fmt.Println(reflect.TypeOf(v)) //reflect.Value fmt.Println(v.Interface()) //3.4 fmt.Println(v.Type()) //float64 } 变量包括（type, value）两部分 type 包括 static type和concrete type. 简单来说 static type是你在编码是看见的类型(如int、string)，concrete type是runtime系统看见的类型 类型断言能否成功，取决于变量的concrete type，而不是static type. 因此，一个 reader变量如果它的concrete type也实现了write方法的话，它也可以被类型断言为writer. 只有interface类型才有反射一说 每个interface变量都有一个对应pair，pair中记录了实际变量的值和类型 (value, type) reflect包api //ValueOf用来获取输入参数接口中的数据的值，如果接口为空则返回0 func ValueOf(i interface{}) Value {...} //func TypeOf(i interface{}) Type {...} func TypeOf(i interface{}) Type {...} 反射可以大大提高程序的灵活性，使得interface{}有更大的发挥余地 反射必须结合interface才玩得转 变量的type要是concrete type的（也就是interface变量）才有反射一说 反射可以将“接口类型变量”转换为“反射类型对象” 反射使用 TypeOf 和 ValueOf 函数从接口中获取目标对象信息 反射可以将“反射类型对象”转换为“接口类型变量 reflect.value.Interface().(已知的类型) 遍历reflect.Type的Field获取其Field 反射可以修改反射类型对象，但是其值必须是“addressable” 想要利用反射修改对象状态，前提是 interface.data 是 settable,即 pointer-interface 通过反射可以“动态”调用方法 因为Golang本身不支持模板，因此在以往需要使用模板的场景下往往就需要使用反射(reflect)来实现 Golang的单引号、双引号与反引号 Go语言的字符串类型string在本质上就与其他语言的字符串类型不同： Java的String、C++的std::string以及Python3的str类型都只是定宽字符序列 Go语言的字符串是一个用UTF-8编码的变宽字符序列，它的每一个字符都用一个或多个字节表示 即：一个Go语言字符串是一个任意字节的常量序列。 Golang的双引号和反引号都可用于表示一个常量字符串，不同在于： 双引号用来创建可解析的字符串字面量(支持转义，但不能用来引用多行) 反引号用来创建原生的字符串字面量，这些字符串可能由多行组成(不支持任何转义序列)，原生的字符串字面量多用于书写多行消息、HTML以及正则表达式 而单引号则用于表示Golang的一个特殊类型：rune，类似其他语言的byte但又不完全一样，是指：码点字面量（Unicode code point），不做任何转义的原始内容。 变长参数 func append(slice []Type, elems ...Type) []Type //举例 orig, err := ioutil.ReadFile(file) //这里orig后面的三个点, 是展开orig的意思 in := append([]byte{}, orig...) //举例 func sum(nums ...int) { fmt.Print(nums, \" \") //输出如 [1, 2, 3] 之类的数组 total := 0 for _, num := range nums { //要的是值而不是下标 total += num } fmt.Println(total) } func main() { sum(1, 2) sum(1, 2, 3) //传数组 nums := []int{1, 2, 3, 4} //相当于把nums打散成元素, 依次传入sum sum(nums...) } flag包用来解析cmd参数 import \"flag\" //定义flag, flag.Int返回一个指针: *int var ip = flag.Int(\"flagname\", 1234, \"help message for flagname\") flag.Var(&flagVal, \"name\", \"help message for flagname\") //定义完了调用, 调用完了指针才会有内容 flag.Parse() //代码里使用flag fmt.Println(\"ip has value \", *ip) fmt.Println(\"flagvar has value \", flagvar) //cmd参数形式 --flag -flag -flag=x --flag=x -flag x // non-boolean flags only //integer可以是如下形式, 也可以为负数 1234, 0664, 0x1234 //Bool可以是 1, 0, t, f, T, F, true, false, TRUE, FALSE, True, False 内置len copy 和cap // cap是最大容量, len是实际容量 func cap(v Type) int func len(v Type) int func copy(dst, src []Type) int 字符串 字节数组 符文 []byte: byte数组 b := []byte(\"ABC€\") fmt.Println(b) // [65 66 67 226 130 172] //go的string是unicode编码(变长)的byte数组 s := string([]byte{65, 66, 67, 226, 130, 172}) fmt.Println(s) // ABC€ character € is encoded in UTF-8 using 3 bytes string: 本质上是只读的的byte数组, 对string的index返回对应的byte; 对大于255的字符(character)来说, 占多个byte func main() { const placeOfInterest = `⌘` fmt.Printf(\"plain string: \") fmt.Printf(\"%s\", placeOfInterest) fmt.Printf(\"\\n\") fmt.Printf(\"quoted string: \") fmt.Printf(\"%+q\", placeOfInterest) fmt.Printf(\"\\n\") fmt.Printf(\"hex bytes: \") for i := 0; i UTF-8用1到6个字节编码Unicode字符 rune: 是int32的别名 常量和iota 在常量表达式里面使用iota, 从0开始, 每行加一. type Stereotype int const ( TypicalNoob Stereotype = iota // 0 TypicalHipster // 1 TypicalHipster = iota TypicalUnixWizard // 2 TypicalUnixWizard = iota TypicalStartupFounder // 3 TypicalStartupFounder = iota ) //如果两个const的赋值语句的表达式是一样的，那么可以省略后一个赋值表达式。 type AudioOutput int const ( OutMute AudioOutput = iota // 0 OutMono // 1 OutStereo // 2 _ _ OutSurround // 5 ) type Allergen int const ( IgEggs Allergen = 1 格式化和scan print // 定义示例类型和变量 type Human struct { Name string } var people = Human{Name:\"zhangsan\"} 普通占位符 占位符 说明 举例 输出 %v 相应值的默认格式。 Printf(\"%v\", people) {zhangsan}， %+v 打印结构体时，会添加字段名 Printf(\"%+v\", people) {Name:zhangsan} %#v 相应值的Go语法表示 Printf(\"%#v\", people) main.Human{Name:\"zhangsan\"} %T 相应值的类型的Go语法表示 Printf(\"%T\", people) main.Human %% 字面上的百分号，并非值的占位符 Printf(\"%%\") % func describe(i interface{}) { fmt.Printf(\"(%v, %T)\\n\", i, i) } 整数占位符 占位符 说明 举例 输出 %b 二进制表示 Printf(\"%b\", 5) 101 %c 相应Unicode码点所表示的字符 Printf(\"%c\", 0x4E2D) 中 %d 十进制表示 Printf(\"%d\", 0x12) 18 %o 八进制表示 Printf(\"%d\", 10) 12 %q 单引号围绕的字符字面值，由Go语法安全地转义 Printf(\"%q\", 0x4E2D) '中' %x 十六进制表示，字母形式为小写 a-f Printf(\"%x\", 13) d %X 十六进制表示，字母形式为大写 A-F Printf(\"%x\", 13) D %U Unicode格式：U+1234，等同于 \"U+%04X\" Printf(\"%U\", 0x4E2D) U+4E2D 字符串与字节切片 占位符 说明 举例 输出 %s 输出字符串表示（string类型或[]byte) Printf(\"%s\", []byte(\"Go语言\")) Go语言 %q 双引号围绕的字符串，由Go语法安全地转义 Printf(\"%q\", \"Go语言\") \"Go语言\" %x 十六进制，小写字母，每字节两个字符 Printf(\"%x\", \"golang\") 676f6c616e67 %X 十六进制，大写字母，每字节两个字符 Printf(\"%X\", \"golang\") 676F6C616E67 指针 占位符 说明 举例 输出 %p 十六进制表示，前缀 0x Printf(\"%p\", &people) 0x4f57f0 其它标记 占位符 说明 举例 输出 + 总打印数值的正负号；对于%q（%+q）保证只输出ASCII编码的字符。 Printf(\"%+q\", \"中文\") \"\\u4e2d\\u6587\" - 在右侧而非左侧填充空格（左对齐该区域） # 备用格式：为八进制添加前导 0（%#o） Printf(\"%#U\", '中') U+4E2D 为十六进制添加前导 0x（%#x）或 0X（%#X），为 %p（%#p）去掉前导 0x； 如果可能的话，%q（%#q）会打印原始 （即反引号围绕的）字符串； 如果是可打印字符，%U（%#U）会写出该字符的 Unicode 编码形式（如字符 x 会被打印成 U+0078 'x'）。 ' ' (空格)为数值中省略的正负号留出空白（% d）； 以十六进制（% x, % X）打印字符串或切片时，在字节之间用空格隔开 0 填充前导的0而非空格；对于数字，这会将填充移到正负号之后 scan package main import ( \"fmt\" ) func main() { var name string var age int n, err := fmt.Sscanf(\"Kim is 22 years old\", \"%s is %d years old\", &name, &age) if err != nil { panic(err) } fmt.Printf(\"%d: %s, %d\\n\", n, name, age) } 减小go可执行文件的size #之前是15M, 带符号表 go build -ldflags \"-s -w\" main.go #之后是7.3M, 不带符号表 go tool link -h -s disable symbol table -w disable DWARF generation 不影响panic的打印信息 比如, 在hello.go加入一行panic() # 不要符号表, 不要DWARF go build -ldflags \"-s -w\" hello.go # 还是有panic信息 $ ./hello panic: goroutine 1 [running]: main.main() /repo/yingjieb/godev/practice/src/examples/hello.go:39 +0xa3 注: 如果是gccgo, strip符号表会导致panic的打印没有调用栈信息. go doc看说明 #格式化输出的 go doc fmt #命令行解析的 do doc flag #导出变量的, via HTTP at /debug/vars in JSON format ??? go doc expvar go内置pacakge go的内置package在toolchain的src目录下, 都是go文件. yingjieb@yingjieb-VirtualBox ~/repo/gorepo/go/src Linux Mint 19.1 Tessa $ ls all.bash archive builtin clean.rc container debug flag html io make.bat mime os race.bat run.bat strconv testdata unicode all.bat bootstrap.bash bytes cmd context encoding fmt image iostest.bash Make.dist naclmake.bash path reflect run.rc strings testing unsafe all.rc bufio clean.bash cmp.bash crypto errors go index log make.rc nacltest.bash plugin regexp runtime sync text androidtest.bash buildall.bash clean.bat compress database expvar hash internal make.bash math net race.bash run.bash sort syscall time go 环境变量 $GOROOT : go toolchain的目录, 在编译go toolchain时写入默认值为all.bash的上级目录, 比如/root/go-mips64; 可用来在多个go toolchain间切换; buildroot默认在HOST_GO_ROOT = $(HOST_DIR)/lib/go, 见package/go/go.mk $GOOS and $GOARCH : 目标OS和CPU arch, 比如linux 和mips64. 默认是$GOHOSTOS and $GOHOSTARCH $GOPATH : 所有go程序的工作目录, 默认是用户home/go $GOBIN : go可执行二进制目录, 用go命令安装的bin在此. 默认是$GOPATH/bin 比如go get golang.org/x/tools/cmd/godoc下载, 编译, 安装$GOBIN/godoc 参考: go环境变量 Linux Mint 19.1 Tessa $ go env GOARCH=\"amd64\" GOBIN=\"\" GOCACHE=\"/home/yingjieb/.cache/go-build\" GOEXE=\"\" GOHOSTARCH=\"amd64\" GOHOSTOS=\"linux\" GOOS=\"linux\" GOPATH=\"/home/yingjieb/go\" GORACE=\"\" GOROOT=\"/usr/lib/go-1.10\" GOTMPDIR=\"\" GOTOOLDIR=\"/usr/lib/go-1.10/pkg/tool/linux_amd64\" GCCGO=\"gccgo\" CC=\"gcc\" CXX=\"g++\" CGO_ENABLED=\"1\" CGO_CFLAGS=\"-g -O2\" CGO_CPPFLAGS=\"\" CGO_CXXFLAGS=\"-g -O2\" CGO_FFLAGS=\"-g -O2\" CGO_LDFLAGS=\"-g -O2\" PKG_CONFIG=\"pkg-config\" GOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build439003515=/tmp/go-build -gno-record-gcc-switches\" go test框架 go有个集成的test框架, 包括 go test命令 需包含testing包 被test的package下面, 创建xxx_test.go, 包含func TestXxx(t *testing.T) 比如package stringutil里实现了字符串反转的方法, 那么, 它的test要这么写 package stringutil import \"testing\" func TestReverse(t *testing.T) { cases := []struct { in, want string }{ {\"Hello, world\", \"dlrow ,olleH\"}, {\"Hello, 世界\", \"界世 ,olleH\"}, {\"\", \"\"}, } for _, c := range cases { got := Reverse(c.in) if got != c.want { t.Errorf(\"Reverse(%q) == %q, want %q\", c.in, got, c.want) } } } 测试时, #从任意地方运行 go test github.com/user/stringutil #如果从这个package下面运行 go test 远程包 有的包在github上, 用go get命令可以从远程repo下载 编译 安装指定包. $ go get github.com/golang/example/hello $ $GOPATH/bin/hello Hello, Go examples! 被import的远程包, 本地没有的, 会被自动下载到workspace. go 工程布局(layout) 参考: https://golang.org/doc/code.html go开发约定: go的所有程序都放在一个workspace下面 这个workspace下面放了很多repo, 用git或hg管理起来 package name就是其package路径的basename, 比如crypto/rot13的package name就是rot13 go不要求package name是唯一的, 但要求其路径是唯一的. 一个repo包括一个或多个package 一个package放在一个目录下面, 包括一个或多个go源文件 一个package在workspace的路径, 就是它被import的路径 被import的package可以是remote的repo, go会自动下载到workspace里面 典型的go workspace布局 bin/ hello # command executable outyet # command executable src/ github.com/golang/example/ .git/ # Git repository metadata hello/ hello.go # command source outyet/ main.go # command source main_test.go # test source stringutil/ reverse.go # package source reverse_test.go # test source golang.org/x/image/ .git/ # Git repository metadata bmp/ reader.go # package source writer.go # package source ... (many more repositories and packages omitted) ... $GOPATH就是这个workspaceexport PATH=$PATH:$(go env GOPATH)/bin export GOPATH=$(go env GOPATH) go install就是把编译好的可执行文件拷贝到$GOPATH/bin 比如可以在任意的地方执行go install github.com/user/hello go会去$GOPATH/src找 对你写的go lib(不是以package main开头的是lib)来说, go build会把编译好的package保存在local build cache里 go的package xxx, 这里的xxx是import路径的base name. 在引用的时候, 用相对src的路径引用 package main import ( \"fmt\" \"github.com/user/stringutil\" ) func main() { fmt.Println(stringutil.Reverse(\"!oG ,olleH\")) } 此时源文件布局如下: bin/ hello # command executable src/ github.com/user/ hello/ hello.go # command source stringutil/ reverse.go # package source 完整布局参考 https://github.com/golang-standards/project-layout go知识点 package main import \"fmt\" func main() { /* 这是我的第一个简单的程序 */ fmt.Println(\"Hello, World!\") } #运行 go run hello.go #只编译 go build hello.go package main package关键词表示这个文件属于哪个包, 一般都是多个源文件属于同一个包. import告诉go编译器要使用的包 func main是程序开始执行的函数, 每个可执行的go程序必须包含main函数. 一般情况下, 程序会第一个执行main. 但如果有init()函数, 会先执行init() {不能占单独的一行 每行不必用;结尾 用+可以连接字符串, 比如fmt.Println(\"Google\" + \"Runoob\"), 得到GoogleRunoob 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）。 go的数据类型有bool byte(类似uint8) rune(类似int32) uintptr(无符号整型, 用于存放指针) int(32位或64位, 和体系架构有关) uint8/16/32/64 int8/16/32/64 float float32 float64 string struct channel 指针 数组 func 切片 interface map等 var a string = \"Runoob\" //也可以省略类型, 编译器根据赋值自动推断 var a = \"RUNOOB\" var b, c int = 1, 2 fmt.Println(a, b, c) //没有初始化的变量, 默认为0, 或空字符串\"\", 或nil, 比如: var a *int var a []int var a map[string] int var a chan int var a func(string) int var a error // error 是接口 //也可以省略var, 用v_name := value形式, 但只能在函数体内出现? f := \"Runoob\" //空白标识符_只能写, 不能读, 用于占位, 抛弃不想要的值; 比如下面的值5就被抛弃了 _, b = 5, 7 //取地址&和取值*和C一样 用type_name(expression)做类型转换 Go 没有三目运算符，所以不支持 ?: 形式的条件判断 循环只有forfunc main() { //也可以不要true, 直接一个for就行了 for true { fmt.Printf(\"这是无限循环。\\n\"); } } //一般的for形式都支持, 里面可以有break continue goto for C 函数定义形式, 可以有多个返回值 func function_name( [parameter list] ) [return_types] { 函数体 } /* 函数返回两个数的最大值 */ func max(num1, num2 int) int { /* 声明局部变量 */ var result int if (num1 > num2) { result = num1 } else { result = num2 } return result } 函数可以直接\"赋值\"给变量, 在大部分现代语言中, 函数也可以当作变量 func main(){ /* 声明函数变量 */ getSquareRoot := func(x float64) float64 { return math.Sqrt(x) } /* 使用函数 */ fmt.Println(getSquareRoot(9)) } go的闭包, 在这里就是函数返回值是另一个函数 //Go 语言支持匿名函数，可作为闭包。匿名函数是一个\"内联\"语句或表达式。匿名函数的优越性在于可以直接使用函数内的变量，不必申明。 //以下实例中，我们创建了函数 getSequence() ，返回另外一个函数。该函数的目的是在闭包中递增 i 变量，代码如下： package main import \"fmt\" func getSequence() func() int { i:=0 return func() int { i+=1 return i } } func main(){ /* nextNumber 为一个函数，函数 i 为 0 */ nextNumber := getSequence() /* 调用 nextNumber 函数，i 变量自增 1 并返回 */ fmt.Println(nextNumber()) fmt.Println(nextNumber()) fmt.Println(nextNumber()) /* 创建新的函数 nextNumber1，并查看结果 */ //重新调用getSequence()函数, i是重新申请的变量 nextNumber1 := getSequence() //这里的number会重新开始编号 fmt.Println(nextNumber1()) fmt.Println(nextNumber1()) fmt.Println(nextNumber()) fmt.Println(nextNumber()) } //结果 1 2 3 1 2 //这里是nextNumber继续编号 4 5 //闭包也可以带参数 func main() { add_func := add(1,2) fmt.Println(add_func(1,1)) fmt.Println(add_func(0,0)) fmt.Println(add_func(2,2)) } // 闭包使用方法 //x1 x2是初始化add_func用的, x3 x4是传给add_func的 func add(x1, x2 int) func(x3 int,x4 int)(int,int,int) { i := 0 return func(x3 int,x4 int) (int,int,int){ i++ return i,x1+x2,x3+x4 } } //结果 1 3 2 2 3 0 3 3 4 和C一样, 局部变量在函数内使用; 全局变量在函数体外声明, 在整个包使用, 甚至可以被导出后的外部包使用. 数组变量定义: var variable_name [SIZE] variable_type, 和C一样, 下标从0开始 数组变量赋值var balance = [5]float32{1000.0, 2.0, 3.4, 7.0, 50.0} var balance = [...]float32{1000.0, 2.0, 3.4, 7.0, 50.0} var salary float32 = balance[9] var a = [5][2]int{ {0,0}, {1,2}, {2,4}, {3,6},{4,8}} 指针和引用 func main() { /* 定义局部变量 */ var a int = 100 var b int= 200 fmt.Printf(\"交换前 a 的值 : %d\\n\", a ) fmt.Printf(\"交换前 b 的值 : %d\\n\", b ) /* 调用函数用于交换值 * &a 指向 a 变量的地址 * &b 指向 b 变量的地址 */ swap(&a, &b); fmt.Printf(\"交换后 a 的值 : %d\\n\", a ) fmt.Printf(\"交换后 b 的值 : %d\\n\", b ) } func swap(x *int, y *int) { var temp int temp = *x /* 保存 x 地址的值 */ *x = *y /* 将 y 赋值给 x */ *y = temp /* 将 temp 赋值给 y */ } 结构体, 和c不同的是, 结构体指针访问成员的时候, 也是用. type Books struct { title string author string subject string book_id int } //声明结构体变量并初始化 //variable_name := structure_variable_type {value1, value2...valuen} //或 //variable_name := structure_variable_type { key1: value1, key2: value2..., keyn: valuen} fmt.Println(Books{\"Go 语言\", \"www.runoob.com\", \"Go 语言教程\", 6495407}) Book1.title = \"Go 语言\" Book1.author = \"www.runoob.com\" Book1.subject = \"Go 语言教程\" Book1.book_id = 6495407 切片, 数组的大小是固定的, 而切片大小可以变. \"动态数组\" func main() { /* 创建切片 */ numbers := []int{0,1,2,3,4,5,6,7,8} printSlice(numbers) /* 打印原始切片 */ fmt.Println(\"numbers ==\", numbers) /* 打印子切片从索引1(包含) 到索引4(不包含)*/ fmt.Println(\"numbers[1:4] ==\", numbers[1:4]) /* 默认下限为 0*/ fmt.Println(\"numbers[:3] ==\", numbers[:3]) /* 默认上限为 len(s)*/ fmt.Println(\"numbers[4:] ==\", numbers[4:]) numbers1 := make([]int,0,5) printSlice(numbers1) /* 打印子切片从索引 0(包含) 到索引 2(不包含) */ number2 := numbers[:2] printSlice(number2) /* 打印子切片从索引 2(包含) 到索引 5(不包含) */ number3 := numbers[2:5] printSlice(number3) } func printSlice(x []int){ fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(x),cap(x),x) } range关键字用于 for 循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素 func main() { //这是我们使用range去求一个slice的和。使用数组跟这个很类似 nums := []int{2, 3, 4} sum := 0 for _, num := range nums { sum += num } fmt.Println(\"sum:\", sum) //在数组上使用range将传入index和值两个变量。上面那个例子我们不需要使用该元素的序号，所以我们使用空白符\"_\"省略了。有时侯我们确实需要知道它的索引。 for i, num := range nums { if num == 3 { fmt.Println(\"index:\", i) } } //range也可以用在map的键值对上。 kvs := map[string]string{\"a\": \"apple\", \"b\": \"banana\"} for k, v := range kvs { fmt.Printf(\"%s -> %s\\n\", k, v) } //range也可以用来枚举Unicode字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。 for i, c := range \"go\" { fmt.Println(i, c) } } 值传递和指针类型 有人总结: golang中的传参是值传递, 但因为map channel和slice等内置数据结构本身是指针类型, 所以它们作为参数传递时, 相当于传递了指针. struct 形式 type Books struct { title string author string subject string book_id int } 结构体方法 Go 语言中同时有函数和方法。一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。所有给定类型的方法属于该类型的方法集 形式为: 注意和函数定义的区别 func(receiver type)methodName([参数列表]) [返回值列表]{ } 普通函数定义为: func function_name( [parameter list] ) [return_types] { 函数体 } package main import ( \"fmt\" ) type Student struct{ Name string Age int } func (stu *Student)Set(name string,age int){ stu.Name = name stu.Age = age } func main(){ var s Student s.Set(\"tome\",23) fmt.Println(s) } //注意:方法的访问控制也是通过大小写控制的 //在上面这个例子中需要注意一个地方 //func (stu *Student)Set(name string,age int) //这里使用的是(stu *Student)而不是(stu Student)这里其实是基于指针对象的方法 //当调用一个函数时，会对其每个参数值进行拷贝，如果一个函数需要更新一个变量，或者函数的其中一个参数是在太大 //我们希望能够避免进行这种默认的拷贝，这种情况下我们就需要用到指针了，所以在上一个代码例子中那样我们需要 //func (stu *Student)Set(name string,age int)来声明一个方法 基于指针对象的方法 package main import ( \"fmt\" ) type Point struct{ X float64 Y float64 } func (p *Point) ScaleBy(factor float64){ p.X *= factor p.Y *= factor } func main(){ //两种方法 //方法1 r := &Point{1,2} r.ScaleBy(2) fmt.Println(*r) //方法2 p := Point{1,2} pptr := &p pptr.ScaleBy(2) fmt.Println(p) //方法3 p2 := Point{1,2} (&p2).ScaleBy(2) fmt.Println(p2) //相对来说方法2和方法3有点笨拙 //方法4,go语言这里会自己判断p是一个Point类型的变量， //并且其方法需要一个Point指针作为指针接收器，直接可以用下面简单的方法 p3 := Point{1,2} p3.ScaleBy(2) fmt.Println(p3) } //上面例子中最后一种方法，编译器会隐式的帮我们用&p的方法去调用ScaleBy这个方法 继承 package main import ( \"fmt\" ) type People struct{ Name string Age int } type Student struct{ People Score int } func main(){ var s Student /* s.People.Name = \"tome\" s.People.Age = 23 */ //上面注释的用法可以简写为下面的方法 s.Name = \"tom\" s.Age = 23 s.Score = 100 fmt.Printf(\"%+v\\n\",s) //注意：关于字段冲突的问题，我们在People中定义了一个Name字段，在Student中再次定义Name,这个时候，我们通过s.Name获取的就是Student定义的Name字段 } 结构体可以比较 如果结构体的所有成员变量都是可比较的，那么结构体就可比较 如果结构体中存在不可比较的成员变量，那么结构体就不能比较 map和切片不能比较 package main import ( \"fmt\" ) type Point struct{ x int y int } func main(){ p1 := Point{1,2} p2 := Point{2,3} p3 := Point{1,2} fmt.Println(p1==p2) //false fmt.Println(p1==p3) //true } new分配内存 package main import ( \"fmt\" ) type Student struct { Id int Name string } func main() { s := new(Student) s.Id = 1 s.Name = \"test\" s1 := Student{Id: 2, Name: \"test1\"} fmt.Println(s, s1) } //输出结果: &{1 test} {2 test1} //s 的类型为指针，s1 为一个Student类型; //说明new的返回值是指针, 而用struct_type{}声明的变量是struct_type实例本身. 工厂模式初始化 go没有构造函数, 所以工厂模式很常用 package main import ( \"fmt\" ) type Student struct{ Name string Age int } func NewStudent(name string,age int) *Student{ return &Student { Name:name, Age:age, } } func main(){ s := NewStudent(\"tom\",23) fmt.Println(s.Name) } 接口 interface Go 语言提供了另外一种数据类型即接口，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方法就是实现了这个接口。 /* 定义接口 */ type interface_name interface { method_name1 [return_type] method_name2 [return_type] method_name3 [return_type] ... method_namen [return_type] } /* 定义结构体 */ type struct_name struct { /* variables */ } /* 实现接口方法 */ func (struct_name_variable struct_name) method_name1() [return_type] { /* 方法实现 */ } ... func (struct_name_variable struct_name) method_namen() [return_type] { /* 方法实现*/ } package main import ( \"fmt\" ) type Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\"I am Nokia, I can call you!\") } type IPhone struct { } func (iPhone IPhone) call() { fmt.Println(\"I am iPhone, I can call you!\") } func main() { //这是interface类型的变量 var phone Phone //new返回一个指针, 并对其内存清零; //也可以写成phone = NokiaPhone{}, 或phone = &NokiaPhone{} phone = new(NokiaPhone) phone.call() phone = new(IPhone) phone.call() } //在上面的例子中，我们定义了一个接口Phone，接口里面有一个方法call()。 //然后我们在main函数里面定义了一个Phone类型变量，并分别为之赋#值为NokiaPhone和IPhone。 //然后调用call()方法，输出结果如下： I am Nokia, I can call you! I am iPhone, I can call you! 类型断言 类型断言提供了一个机制找出接口底层对应的实际类型: t := i.(T) 这个语句在断言接口i中实际包含了类型T，然后把底层类型T的值赋值给变量t 如果断言失败，i中没有包含T，这条语句会触发panic 为了测试接口是否包含指定的类型，类型断言会返回2个值，底层类型实际对应的值和一个bool值，来报告断言是否成功 t, ok := i.(T) 如果i中包含T，则t是底层类型的实际值，变量ok是真 如果断言失败，ok变量是假，t是一个零值类型T，不会触发panic，这个语法和对map操作类似 只有interface有类型断言, 因为interface可以指向任何东西, 所以要有办法知道它的运行时类型: https://www.jianshu.com/p/6a46fc7b6e5b x.(T) 检查x的动态类型是否是T，其中x必须是接口值。 switch形式: func main() { var x interface{} x = 17 //fmt包看实际类型, 因为Printf的入参就是接口类型 fmt.Printf(\"type x is %T, value x is %d\\n\", x, x) //这是个特殊的type switch, switch后面是个赋值表达式, 但case的对象是类型 switch v := x.(type) { //case的顺序是有意义的，因为可能同时满足多个接口，不可以用fallthrough, default的位置无所谓。 case nil: fmt.Printf(\" x 的类型 :%T\", v) case int: fmt.Printf(\"x 是 int 型, 值为%v\", v) case float64: fmt.Printf(\"x 是 float64 型, 值为%v\", v) case func(int) float64: fmt.Printf(\"x 是 func(int) 型, 值为%p\", v) case bool, string: fmt.Printf(\"x 是 bool 或 string 型, 值为%v\", v) default: fmt.Printf(\"未知型\") } } //结果: type x is int, value x is 17 x 是 int 型, 值为17 类型断言判断对象是否实现了一个接口 判断val是否实现了json.Marshaler需要的接口, 即val是否为json.Marshaler类型. if _, ok := val.(json.Marshaler); ok { fmt.Printf(\"value %v of type %T implements json.Marshaler\\n\", val, val) } goroutine goroutine 是轻量级线程，goroutine 的调度是由 Golang 运行时进行管理的。 //语法 go 函数名(参数列表) //比如 go f(x, y, z) //并行执行, 就像shell的后台执行一样 package main import ( \"fmt\" \"time\" ) func say(s string) { for i := 0; i 通道 通道（channel）是用来传递数据的一个数据结构, 可用于两个 goroutine 之间通过传递一个指定类型的值来同步运行和通讯。操作符 // 声明一个通道很简单，我们使用chan关键字即可，通道在使用前必须先创建： ch := make(chan int) ch // 也可以不用make来声明channel, 用var也可以; 默认初始化为nil var c chan int fmt.Println(c) select语句形式上类似 switch 语句，但实际上和C里面的select差不多: 用于监听和channel有关的IO操作，当 IO 操作发生时，触发相应的动作. 和switch不同, select会对每个case, 都会对channel求值, 如果有可用的IO, 则随机执行其中一个case的后续指令. 如果没有可用的IO, 则执行default. 如果没有可用IO, 也没有default, 则一直阻塞到IO可用. 比如一个loadbalancer func (b *Banlancer) balance(work chan Request) { for { select { case req := package main import \"fmt\" func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c 带缓冲的通道 // 默认情况下，通道是不带缓冲区的。发送端发送数据，同时必须又接收端相应的接收数据。 // 通道可以设置缓冲区，通过 make 的第二个参数指定缓冲区大小： ch := make(chan int, 100) package main import \"fmt\" func main() { // 这里我们定义了一个可以存储整数类型的带缓冲通道 // 缓冲区大小为2 ch := make(chan int, 2) // 因为 ch 是带缓冲的通道，我们可以同时发送两个数据 // 而不用立刻需要去同步读取数据 ch 通道用close来关闭 //如果通道接收不到数据后 ok 就为 false，这时通道就可以使用 close() 函数来关闭 v, ok := package main import ( \"fmt\" ) func fibonacci(n int, c chan int) { x, y := 0, 1 for i := 0; i 切片 切片是对数组的描述, 一个数组可以有多个描述 用make创建切片的时候, make([]type, length, capacity), 其中, length表示切片的大小, capacity表示切片底层array的大小; capacity容量够的话, append()不会产生新的更大的array 切片的append arr从[0 1 2 3 4 5 6 7]变为[0 1 2 3 4 5 6 10]是因为s3 := append(s2, 10)，s2=[5 6]，再往后添加10的时候，把arr中的7变为了10。而后面再添加11、12时，因为已经超越了arr的cap，所以系统会重新分配更大的底层数组，而不再是对arr进行操作，原来的数组如果有人用就会依旧存在，如果没人用了就会自动垃圾回收 package main import \"fmt\" func main() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(\"arr: \", arr) // output：arr: [0 1 2 3 4 5 6 7] s1 := arr[2:6] s2 := s1[3:5] //其实s1的index只有0 1 2 3, 这里的3:5是3和4, 引用的是原始arr fmt.Println(\"s1: \", s1) // output：s1: [2 3 4 5] //len(s2)为2 fmt.Println(\"s2: \", s2) // output：s2: [5 6] s3 := append(s2, 10) s4 := append(s3, 11) s5 := append(s4, 12) fmt.Println(\"s3: \", s3) // output：s3: [5 6 10] fmt.Println(\"s4: \", s4) // output：s4: [5 6 10 11] fmt.Println(\"s5: \", s5) // output：s5: [5 6 10 11 12] fmt.Println(\"arr: \", arr) // output：arr: [0 1 2 3 4 5 6 10] } 当我们用append追加元素到切片时，如果容量不够，go就会创建一个新的切片变量, 并进行\"深拷贝\", 即把原来的array的元素值, 都拷贝到新的更大的array里面, 再append. 如果用量够用, 就不用\"深拷贝\"了 func main() { var sa []string //用%p可以打印sa的地址, sa本来就是个 fmt.Printf(\"addr:%p \\t\\tlen:%v content:%v\\n\",sa,len(sa),sa); for i:=0;i map 集合 Map 是一种无序的键值对的集合。Map 最重要的一点是通过 key 来快速检索数据，key 类似于索引，指向数据的值。 Map 是一种集合，所以我们可以像迭代数组和切片那样迭代它。不过，Map 是无序的，我们无法决定它的返回顺序，这是因为 Map 是使用 hash 表来实现的。 /* 声明变量，默认 map 是 nil */ var map_variable map[key_data_type]value_data_type /* 使用 make 函数 */ map_variable := make(map[key_data_type]value_data_type) package main import \"fmt\" func main() { var countryCapitalMap map[string]string /*创建集合 */ countryCapitalMap = make(map[string]string) /* map插入key - value对,各个国家对应的首都 */ countryCapitalMap [ \"France\" ] = \"Paris\" countryCapitalMap [ \"Italy\" ] = \"罗马\" countryCapitalMap [ \"Japan\" ] = \"东京\" countryCapitalMap [ \"India \" ] = \"新德里\" /*使用键输出地图值 */ for country := range countryCapitalMap { fmt.Println(country, \"首都是\", countryCapitalMap [country]) } /*查看元素在集合中是否存在 */ captial, ok := countryCapitalMap [ \"美国\" ] /*如果确定是真实的,则存在,否则不存在 */ /*fmt.Println(captial) */ /*fmt.Println(ok) */ if (ok) { fmt.Println(\"美国的首都是\", captial) } else { fmt.Println(\"美国的首都不存在\") } } //运行结果 France 首都是 Paris Italy 首都是 罗马 Japan 首都是 东京 India 首都是 新德里 美国的首都不存在 delete可以删除元素 range 用range可以对数组(array), 切片(slice), 通道(channel), 集合(map)进行遍历 package main import \"fmt\" func main() { //这是我们使用range去求一个slice的和。使用数组跟这个很类似 nums := []int{2, 3, 4} sum := 0 for _, num := range nums { sum += num } fmt.Println(\"sum:\", sum) //在数组上使用range将传入index和值两个变量。上面那个例子我们不需要使用该元素的序号，所以我们使用空白符\"_\"省略了。有时侯我们确实需要知道它的索引。 for i, num := range nums { if num == 3 { fmt.Println(\"index:\", i) } } //range也可以用在map的键值对上。 kvs := map[string]string{\"a\": \"apple\", \"b\": \"banana\"} for k, v := range kvs { fmt.Printf(\"%s -> %s\\n\", k, v) } //range也可以用来枚举Unicode字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。 for i, c := range \"go\" { fmt.Println(i, c) } } // 运行结果: sum: 9 index: 1 a -> apple b -> banana 0 103 1 111 "},"notes/golang_json性能.html":{"url":"notes/golang_json性能.html","title":"json性能比较","keywords":"","body":" json性能之 C vs Go 代码如下: 编译和运行 C Go 编译后大小 测试用的json文件 jq x86 mips 性能结果分析 补充mips测试结果 go工具链test代码 encoding/json encoding/json benchmarking模式 强制单核模式 json benchmarking流程 test2json运行 test2json_test代码 test2json 返回interface类型 github golang example reverse.go reverse test json性能之 C vs Go 思路: 对一个给定的xxxx.json文件, 调用相应的API把json文件load并解析到内部表达, 再调用相应API把内部表达转换回json文件, 输出到控制台. 测试时传入循环次数, 统计消耗时间. Reborn平台上, 用的是C语言实现的libjansson库, 使用json_load_file()load并解析json文件, 使用json_dumpfd()反解析并输出到文件. 对Go来说, toolchain自带json解析库, 用json.Unmarshal()来解析json, 用json.Marshal()来做反解析. 代码如下: C语言版本(使用libjansson库): Go语言版本: 编译和运行 在x86环境下 C #先安装libjansson库 #x86 ubuntu apt install libjansson-dev #mips gentoo taskset -c 1,2,3 emerge -av dev-libs/jansson #编译, 生成a.out gcc -O2 json_load.c -ljansson #运行 time ./a.out test.json 100 > /dev/null Go #编译 go build json_load.go #运行, 默认多进程 time ./json_load -fileName test.json -loopNum 100 > /dev/null #强制单核 taskset -c 1 time ./json_load -fileName test.json -loopNum 100 > /dev/null #gentoo上time不是独立的程序 taskset -c 1 sh -c \"time ./json_load -fileName test.json -loopNum 100 > /dev/null\" 编译后大小 测试用的json文件 example.json test.json1.9M, 190万个字符, 复杂嵌套 jq x86 mips 性能结果分析 C语言json解析运行时 Go语言json解析运行时, 默认多核运行. 注意: 测试代码和运行时命令都并没有显式开启多线程, 多线程是json库函数的行为.纠正: 多线程是go runtime的行为. 详见goroutine解析 Go语言json解析运行时, 强制单核 结果. 运行多次比较稳定: Go toolchain自带的json解析器默认是多进程解析 纠正: 是go runtime起的多线程, go的json解析只是一个goroutine, 被go的runtime调度器调度. 本质上还是单进程. libjansson是单进程解析. C语言版本有大量内核态操作, 估计是load文件操作, 用户态只有一半多一点时间在真正干活. Go语言load文件优化的很好, 强制单进程时, 用户态进程占比99%, 说明所有时间都在做json解析和反解析. 即使除去内核态读文件的差异, Go的json库也比libjansson快一些. 此性能对比无法做到绝对公平, C语言也有更快的json库, Go也可以继续优化; 但从实际使用角度出发, 此对比还是很有参考意义. 补充mips测试结果 go工具链test代码 encoding/json go tool dist test -list | grep -i json cd ~/repo/gorepo/go/src/encoding/json go test -c -o jsontest #help ./jsontest -h #多进程运行 time ./jsontest #单核运行 time taskset -c 1 ./jsontest #所有测试项: ./jsontest -test.list .* ...很多, Test开头的是功能测试, Benchmark开头的是性能测试 encoding/json是多个test的集合: encoding/json benchmarking模式 go test命令族实现了benchmarking的测试, 详见go help test 和 go doc testing 看起来是要加-bench来使能benchmarking模式 对上面的已经编译好的./jsontest来说, ./jsontest -h说要加./jsontest -test.bench .* 默认是多进程模式 强制单核模式 taskset -c 1 ./jsontest -test.bench .* json benchmarking流程 code.json是个复杂的, 多层嵌套的json, 1.9M大小. 测试代码测试code.json到in-memory 结构体的各种操作: Marshal Unmarshal Encode Decode等待 type codeResponse struct { //指针 Tree *codeNode `json:\"tree\"` Username string `json:\"username\"` } type codeNode struct { Name string `json:\"name\"` //数组, 嵌套的codeNode指针 Kids []*codeNode `json:\"kids\"` CLWeight float64 `json:\"cl_weight\"` Touches int `json:\"touches\"` MinT int64 `json:\"min_t\"` MaxT int64 `json:\"max_t\"` MeanT int64 `json:\"mean_t\"` } var codeJSON []byte var codeStruct codeResponse func codeInit() { //os Open f, err := os.Open(\"testdata/code.json.gz\") if err != nil { panic(err) } //defer是先进后出, 也就是说, 离开这个函数的时候, 最后才调用f.Close() defer f.Close() gz, err := gzip.NewReader(f) if err != nil { panic(err) } //data是文件内容 data, err := ioutil.ReadAll(gz) if err != nil { panic(err) } //赋值会深拷贝吗? -- 好像是的 -- 后记: 应该不拷贝 //data是切片, codeJSON也是切片; codeJSON和data同时指向底层文件的数据. 相当于两个指针都指向底层的真正数据 //func ReadAll(r io.Reader) ([]byte, error); 真正的数据保存在这个函数里申请的内存中; codeJSON = data //先Unmarshal, 即转为结构体 if err := Unmarshal(codeJSON, &codeStruct); err != nil { panic(\"unmarshal code.json: \" + err.Error()) } //在把codeStruct Marshal到data; //这么看data变了, 但codeJSON 不变 -- 后记: data只是相当于指针, 指针变了而已 if data, err = Marshal(&codeStruct); err != nil { panic(\"marshal code.json: \" + err.Error()) } //字节比较 if !bytes.Equal(data, codeJSON) { println(\"different lengths\", len(data), len(codeJSON)) for i := 0; i test2json运行 在go/src/cmd/internal/test2json下面运行go test 或者 还是在这个目录下, 编译出可执行文件再运行go test -c -o test2json 这是个多进程程序, 用strace的-f命令可以看出来: strace -f -o log ./test2json 用taskset -c 1执行, 可强制单核跑: taskset -c 1 ./test2json 列出所有测试项: ./test2json -test.list .* TestGolden TestTrimUTF8 test2json特性: 用户态占比接近100% 操作包括 文件open, read json和go结构体互相转换, 调用标准json库 字符串解析和操作 结构体深度比较, 使用go的反射机制 test2json_test代码 测试的思路是: 先调用test2json的converter方法, 把xxx.test转为json, 和已经保存好的正确的xxx.json比对, 一致则测试通过. 如何证明一致: 用json.Unmarshal()把have和want的json都转为结构体event 用反射包里提供的reflect.DeepEqual来深度比较两个结构体. func TestGolden(t *testing.T) { //func Glob(pattern string) (matches []string, err error) //读*.test文件列表 files, err := filepath.Glob(\"testdata/*.test\") if err != nil { t.Fatal(err) } //对每个文件 for _, file := range files { name := strings.TrimSuffix(filepath.Base(file), \".test\") //用testing的Run方法, 注册每个xxx.test 的sub run //用test2json的converter去把test里面的字段, 转换为json //和保存好的对应的xxx.json文件比对, 一致则测试成功. t.Run(name, func(t *testing.T) {......}) } } t.Run是subtest, 由其parent test控制, 可多进程执行. func (t *T) Run(name string, f func(t *T)) bool Run runs f as a subtest of t called name. It runs f in a separate goroutine and blocks until f returns or calls t.Parallel to become a parallel test. Run reports whether f succeeded (or at least did not fail before calling t.Parallel). Run may be called simultaneously from multiple goroutines, but all such calls must return before the outer test function for t returns. test2json go tool dist test -list go tool dist test -rebuild -run test2json 这个程序的思路是: 根据xxx.test文件, 填event结构体; 用json.Marshal()把结构体转为json, 保存到文件xxx.json //`json:\",omitempty\"`是反射字段, 给encoding/json包看的, json.Marshal()会用到 // event is the JSON struct we emit. type event struct { Time *time.Time `json:\",omitempty\"` Action string Package string `json:\",omitempty\"` } 返回interface类型 // io.WriteCloser是个interface类型 type WriteCloser interface { Writer Closer } // 而Writer又是个interface, 包装了Write方法 type Writer interface { Write(p []byte) (n int, err error) } // 同理是Closer type Closer interface { Close() error } // converter实现了Write方法和Close方法 func (c *converter) Write(b []byte) (int, error) { c.input.write(b) return len(b), nil } //这里new(converter)返回指针, converter实现了io.WriteCloser的方法, 符合io.WriteCloser的interface要求 //之所以要先new一个converter, 而不是直接返回&converter, 是因为在给*c赋值的时候, 要用到c.writeOutputEvent; 这是个先又new的c对象, 在给*c赋值的特殊场景;实际上, 是对*c包含的一个结构体赋值. //如果没有上面的特殊场景, 直接返回converter的实例就行. 比如c= converter{....} return &c //把converter当作io.WriteCloser返回 func NewConverter(w io.Writer, pkg string, mode Mode) io.WriteCloser { c := new(converter) *c = converter{ w: w, pkg: pkg, mode: mode, start: time.Now(), input: lineBuffer{ b: make([]byte, 0, inBuffer), line: c.handleInputLine, part: c.output.write, }, output: lineBuffer{ b: make([]byte, 0, outBuffer), line: c.writeOutputEvent, part: c.writeOutputEvent, }, } return c } github golang example reverse.go https://github.com/golang/example/blob/master/stringutil/reverse.go // Package stringutil contains utility functions for working with strings. package stringutil // Reverse returns its argument string reversed rune-wise left to right. func Reverse(s string) string { //rune是int32的别名; 这里是把s转换为int32的数组 r := []rune(s) for i, j := 0, len(r)-1; i reverse test https://github.com/golang/example/blob/master/stringutil/reverse_test.go //package和reverse.go相同, 同一个文件夹下面的惯例都是同一个package //package不是main, 所以这个是个lib package stringutil import \"testing\" //T是个struct: type T struct{ ... } func TestReverse(t *testing.T) { //range遍历, 返回index和value for _, c := range []struct { //in和want写一行, 都是string类型 in, want string }{ {\"Hello, world\", \"dlrow ,olleH\"}, {\"Hello, 世界\", \"界世 ,olleH\"}, {\"\", \"\"}, } { got := Reverse(c.in) if got != c.want { t.Errorf(\"Reverse(%q) == %q, want %q\", c.in, got, c.want) } } } "},"notes/golang_原理.html":{"url":"notes/golang_原理.html","title":"原理相关","keywords":"","body":" go的内存模型 例子1 例子2 业务逻辑上避免调用锁 for循环里的变量 变量每次进入循环都会初始化 变量的地址会变吗? 不会? 会! 结论: 理论解释 -- 表示怀疑 怀疑 合理解释 内置new函数也不是一定分配到堆 总结 修正 再修正 reflect.ValueOf ValueOf流程 什么是ifaceIndir Value的Elem()方法 emptyInterface和nonEmptyInterface ValueOf实例 结论 强制escape 问答 为什么看到value的kind是54? interface赋值给interface 直接赋值: interface只有一层 取地址赋值: interface包interface地址 结论 slice能当作\"出参\"传递 结论 slice和gc 具体例子 Remove all elements Keep allocated memory 结论 float32和data race 使用sync/atomic 再说reflect 什么是unaddressable 不能改变a 能改变a 为什么? 更进一步解释 结论 例子 原理 结论 再议interface interface{}回顾 set get性能损失如何? 结论 标准库的time.Now()如何取得系统时间? time.Now()的实现流程 clock_gettime系统调用 逃逸分析和变量分配 逃逸分析使用 逃逸分析实例 go的值和指针 map 初始化 hashmap结构体 make map变量的时候 遍历 hash算法 常用的hash算法 结论 Gc的演进 interface赋值 更正 interface的内部表达 reflect Type和interface reflect method reflect Value timer timer API 单次timer 周期性timer timer实现原理 add timer 触发timer time.NewTimer()注册了sendTime()回调 timer堆的维护 time包的NewTimer方法调用了runtime.startTimer 性能测试和结果 测试结果 结论 go1.14对timer的优化 go1.13的timer问题 1.14解决思路 系统监控 监控循环 检查timer 检查死锁 轮询网络 抢占处理器 垃圾回收 IO多路复用 golang对epoll的封装 数据结构 初始化 goroutine等待事件 调用epoll 截至日期 GC 垃圾收集器 go runtime调度器 相关的结构体表示 go比较快的5点 go的内存模型 对一个goroutine来说, 编译器和CPU可以合理的乱序, 但必须保证程序顺序的正确性. 即无关的指令才能reorder, 比如a = 1; b = 2;, 在另外一个routine观察可以先看到b = 2 多routine对共享变量的access(重点, 包括读和写), 必须用sync方法 对大于machine word(比如32bit)的值的读写, 是多个machine word size的操做, 它们的顺序未定义 init函数是在特殊的初始化gorotine里执行的, 但init函数可以启动新的goroutine. 被import包的init函数一定先于importer完成. main.main一定是最后执行 例子1 var a, b int func f() { a = 1 b = 2 } func g() { print(b) print(a) } func main() { go f() g() } 可能打印2然后是0. 即f()的b = 2先被g()观察到. 例子2 var a string var done bool func setup() { a = \"hello, world\" done = true } func doprint() { if !done { once.Do(setup) } print(a) } func twoprint() { go doprint() go doprint() } 在doprint()里, 观察到done的写入, 因为乱序执行, 不一定a = \"hello, world\"也完成了. 下面的代码也不对: var a string var done bool func setup() { a = \"hello, world\" done = true } func main() { go setup() for !done { } print(a) } 过了for !done之后, a可能依然是空. 更糟糕的是, 因为没有使用sync, done的写入不能保证一定被main观察到, 以至于main永远不退出. 下面的错误代码更有隐蔽性: type T struct { msg string } var g *T func setup() { t := new(T) t.msg = \"hello, world\" g = t } func main() { go setup() for g == nil { } print(g.msg) } 既是main看到g不是nil了, 也不能保证g.msg就有值了. 业务逻辑上避免调用锁 代码1 func (mq *msgQ) putMsg(mm *metaKnownMsg) { if _, ok := mm.msg.(HighPriorityMessage); ok { if mq.ingressHighChan == nil { mq.Lock() if mq.ingressHighChan == nil { mq.ingressHighChan = make(chan *metaKnownMsg, mq.qsize) } mq.Unlock() } mq.ingressHighChan 代码2 func (mq *msgQ) putMsg(mm *metaKnownMsg) { if _, ok := mm.msg.(HighPriorityMessage); ok { mq.Lock() if mq.ingressHighChan == nil { mq.ingressHighChan = make(chan *metaKnownMsg, mq.qsize) } mq.Unlock() mq.ingressHighChan 在并发场景下, 代码1比代码2理论上性能高非常多. 这里在ingressHighChan为空的时候, 需要新建队列. 这个事情只用做一次. 而代码2在每次进入函数的时候, 都要去获取锁, 那么比如说并发100个函数都走到这里, 就只有一个人能够获取到做, 其他人必须等待锁释放. 而接下来的99个人, 都必须串行的完成这个过程. 总结: 在业务逻辑侧尽量减少lock的调用. 比如这里已知队列为空的时候才调用锁. for循环里的变量 变量每次进入循环都会初始化 比如下面的代码: for { var a, b, c int fmt.Println(\"Hello, playground\", a, b, c) a = 9 fmt.Println(\"Hello, playground\", a, b, c) time.Sleep(time.Second) } 输出: Hello, playground 0 0 0 Hello, playground 9 0 0 Hello, playground 0 0 0 Hello, playground 9 0 0 可以看到: a,b,c都是for里面定义的变量, 初始为零值. 没毛病 循环体里面把a赋值为9, 随后打印a为9, 也没毛病. 本次循环体执行完毕后, 下次循环体执行时, a的值又从零值开始. -- 这里不能用C的思路去理解 变量的地址会变吗? 不会? 看下面的代码: for i := 0; i 输出: Hello, playground 0 824634355464 Hello, playground 9 824634355464 Hello, playground 0 824634355464 Hello, playground 9 824634355464 Hello, playground 0 824634355464 Hello, playground 9 824634355464 看起来变量a的地址并没有变化 会! func main() { for i := 0; i 输出: Hello, playground 0 824634388176 Hello, playground 9 824634388176 Hello, playground 0 824634388176 Hello, playground 9 824634388176 Hello, playground 0 824634388176 Hello, playground 9 824634388176 in main 0 824634499152 in go 9 824634499152 in main 0 824634499176 in go 9 824634499176 in main 0 824634499200 in go 9 824634499200 那么更进一步的问题: 这里go中看到的变量a地址, 和main中每次进入循环体时a的地址一样, 是否是因为它们在时间顺序上前者在后, 后者在前? 改成这样: for i := 0; i 在go函数里面, 先延迟一秒钟. 那么main的for循环会先执行完, goroutine都在后面执行. 结果如下, 说明go函数里面取得到的变量a, 就是本次循环体里面的变量a. in main 0 824634499136 in main 0 824634499152 in main 0 824634499168 in main 0 824634499184 in main 0 824634499200 in main 0 824634499216 in main 0 824634499232 in main 0 824634499248 in main 0 824634499264 in main 0 824634499280 in main 0 824634499296 in main 0 824634499312 in main 0 824634499328 in main 0 824634499344 in main 0 824634499360 in main 0 824634499376 in main 0 824634499392 in main 0 824634499408 in main 0 824634499424 in main 0 824634499440 in main 0 824634499456 in main 0 824634499472 in main 0 824634499488 in main 0 824634499504 in main 0 824634499520 in main 0 824634499536 in main 0 824634499552 in main 0 824634499568 in main 0 824634499584 in main 0 824634499600 in go 9 824634499136 in go 9 824634499600 in go 9 824634499584 in go 9 824634499568 in go 9 824634499552 in go 9 824634499536 in go 9 824634499520 in go 9 824634499504 in go 9 824634499488 in go 9 824634499472 in go 9 824634499456 in go 9 824634499184 in go 9 824634499424 in go 9 824634499408 in go 9 824634499392 in go 9 824634499376 in go 9 824634499360 in go 9 824634499344 in go 9 824634499328 in go 9 824634499312 in go 9 824634499296 in go 9 824634499280 in go 9 824634499264 in go 9 824634499248 in go 9 824634499232 in go 9 824634499216 in go 9 824634499200 in go 9 824634499440 in go 9 824634499168 in go 9 824634499152 结论: for循环体里的变量, 但按照下面的理论来说, 每次进入循环体, 都进入了一个新的scope, 变量地址应该会变化. 少数情况下, 循环体比较简单, 可能变量地址碰巧不变. --结论错误!!!!! for循环体里的变量, 被go函数捕获时, 用的是本次循环体里的变量. 即使循环体在main中异步的改变了该变量, 也不影响已经go出去的routine. --表面正确!!!! 正确结论见下面 理论解释 -- 表示怀疑 参考stackoverflow 有人问为什么在循环里可以: func main() { for i := 0; i 但自己手动写就编译不过: func main() { a := 77 fmt.Println(a) a := 77 fmt.Println(a) } 为啥? 专家的解答是: for循环每次进入循环体大括号块{}, 都是一个新的scope The reason is each time you enter a block of curly braces {} you're creating a new nested scope. When you declare the variable x at the top of the loop it is a new variable and it goes out of scope at the end of the loop. When the program comes back around to the top of the loop again it's another new scope. 有人给出了证据: func main() { for i := 0; i output 0x1040e0f8 0x1040e0fc 可以手动加{}来添加scope: func main() { a := 77 fmt.Println(&a) { a := 77 fmt.Println(&a) } } output 0x1040e0f8 0x1040e0fc 上面的例子就可以\"连续\"定义a两次, 但第二次是个新的变量地址 怀疑 证据例子中, 变量x的地址改变, 不是因为重新进入{}scope的原因. 比如把下面的\"证据\" func main() { for i := 0; i 结果 0x1040e0f8 0x1040e0fc 改成: func main() { for i := 0; i 注意第4行, 用了unsafe.Pointer取x的地址. 结果: 824634150736 824634150736 为什么结果不一样? 上面的证据显示x的地址改变了, 而下面的代码中x的地址没变. 合理解释 因为有fmt.Println(&x), 变量x逃逸到了堆中, 自然每次进入循环其地址都会改变. 而fmt.Println(uintptr(unsafe.Pointer(&x)))不会逃逸, x还是在栈上, 自然地址不变. 内置new函数也不是一定分配到堆 比如下面的代码, 不管是x := 77, 还是x := new(int), 连续两次的地址都是一样的 for i := 0; i 总结 for的循环变量, 比如i++和循环体里面的变量是两码事: for循环同一行的变量作用域在for里面没错, 但更像是在进入循环前定义的一样: for循环里面对循环变量的引用都是指向同一个东西 for循环体里面用var v int或vc := vc定义的变量, 并非同一个地址, 每次循环都是\"临时\"生成的. 所以上面在第13行的修改可以解决问题. 以后检查go出去的函数是否有这个问题, 只检查循环变量就行了 -- 结论正确, 但前面推导过程不对. 见下面 修正 变量地址是否改变, 要看 如果变量在栈上没有逃逸到堆, 那每次for循环里的变量地址是不变的 如果变量逃逸到堆, 那每次for循环里的变量地址不一样 fmt.Println类的函数会导致变量逃逸(大概率) go 函数造成的闭包引用会导致变量逃逸(必然) channel的send应该也会必然导致变量逃逸 不清楚的情况下, 请默认变量是同一个地址. 这样你可以更小心的避免\"无意中\"改变了一个你认为是独立的变量但实际是共享的, 因为你一开始就应该假定这个变量就是共享的. 错误代码示例: for { // fill bufMsg from network socket var tm streamTransportMsg dec.Decode(bufMsg, &tm) streamChan 注意这里取tm地址做为decode的\"出参\", 会实际改变tm底层的数据; 而chan的发送是异步的效果, 真正处理的routine可能看到的tm.msg已经改变. 再修正 上面的错误代码示例不准确 for { // fill bufMsg from network socket var tm streamTransportMsg dec.Decode(bufMsg, &tm) streamChan 另外一个goroutine从streamChan中得到streamTransportMsg的引用, 但看到的tm.msg会在for循环里改变, 不是因为tm的地址没变, 实际上tm的地址会变, 因为channel的发送会导致逃逸. 那错误的原因是tm.msg地址没变, 这是gotiny的Decode问题, 是另外一个故事. reflect.ValueOf ValueOf流程 // ValueOf returns a new Value initialized to the concrete value // stored in the interface i. ValueOf(nil) returns the zero Value. func ValueOf(i interface{}) Value { if i == nil { return Value{} } // TODO: Maybe allow contents of a Value to live on the stack. // For now we make the contents always escape to the heap. It // makes life easier in a few places (see chanrecv/mapassign // comment below). escapes(i) return unpackEface(i) } 从这个函数传进来的i, 不管之前是什么类型, 到这里都是eface, 即empty interface. 这里的escapes(i)我理解i这个interface变量的结构体是在栈上的, 但其\"contents\"要强制分配到heap中, 这里的contents就是i的指针域指向的实体. // unpackEface converts the empty interface i to a Value. func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(&i)) //明确知道i是个emptyInterface // NOTE: don't read e.word until we know whether it is really a pointer or not. t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} } 我们看到: reflect.Value只是unpackEface这个interface, 组成一个Value的结构体, 这中间并没有真正拷贝\"contents\", 而是把\"contents\"做为word返回. 这个word可以是指针, 也可以是值. 这里的Value是如下结构体: // Value is the reflection interface to a Go value. // // Not all methods apply to all kinds of values. Restrictions, // if any, are noted in the documentation for each method. // Use the Kind method to find out the kind of value before // calling kind-specific methods. Calling a method // inappropriate to the kind of type causes a run time panic. // // The zero Value represents no value. // Its IsValid method returns false, its Kind method returns Invalid, // its String method returns \"\", and all other methods panic. // Most functions and methods never return an invalid value. // If one does, its documentation states the conditions explicitly. // // A Value can be used concurrently by multiple goroutines provided that // the underlying Go value can be used concurrently for the equivalent // direct operations. // // To compare two Values, compare the results of the Interface method. // Using == on two Values does not compare the underlying values // they represent. type Value struct { // typ holds the type of the value represented by a Value. typ *rtype // Pointer-valued data or, if flagIndir is set, pointer to data. // Valid when either flagIndir is set or typ.pointers() is true. ptr unsafe.Pointer // flag holds metadata about the value. // The lowest bits are flag bits: // - flagStickyRO: obtained via unexported not embedded field, so read-only // - flagEmbedRO: obtained via unexported embedded field, so read-only // - flagIndir: val holds a pointer to the data // - flagAddr: v.CanAddr is true (implies flagIndir) // - flagMethod: v is a method value. // The next five bits give the Kind of the value. // This repeats typ.Kind() except for method values. // The remaining 23+ bits give a method number for method values. // If flag.kind() != Func, code can assume that flagMethod is unset. // If ifaceIndir(typ), code can assume that flagIndir is set. flag // A method value represents a curried method invocation // like r.Read for some receiver r. The typ+val+flag bits describe // the receiver r, but the flag's Kind bits say Func (methods are // functions), and the top bits of the flag give the method number // in r's type's method table. } 什么是ifaceIndir 在unpackEface中, 调用了函数ifaceIndir(t)来检查是否eface的data域是个指针(一般都是), 但也有时候这个data域直接存的就是值. // unpackEface converts the empty interface i to a Value. func (i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(&i)) //明确知道i是个emptyInterface // NOTE: don't read e.word until we know whether it is really a pointer or not. t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} //这里的e.word就是eface的data. } // ifaceIndir reports whether t is stored indirectly in an interface value. func ifaceIndir(t *rtype) bool { return t.kind&kindDirectIface == 0 } //rtype的kind字段, 第5位表示data指针实际存的是值. const ( kindDirectIface = 1 综上, eface和iface的data域不一定都是指针, 还可能是值. 这可能是个优化, 但其实挺费劲的. 都是指针多好. Value的Elem()方法 Elem()方法用于取得interface或者ptr的\"contents\" // Elem returns the value that the interface v contains // or that the pointer v points to. // It panics if v's Kind is not Interface or Ptr. // It returns the zero Value if v is nil. func (v Value) Elem() Value { k := v.kind() switch k { case Interface: var eface interface{} if v.typ.NumMethod() == 0 { eface = *(*interface{})(v.ptr) //ptr指向empty interface } else { eface = (interface{})(*(*interface { M() //临时构造一个带一个M方法的interface类型, 相当于eface = someOtherInterfaceWithMethod })(v.ptr)) //ptr指向带方法的interface } x := unpackEface(eface) if x.flag != 0 { x.flag |= v.flag.ro() //这里就是unsettable的来源? } return x case Ptr: ptr := v.ptr //默认是data, 只不过保存在ptr里面. 比如就是int 5 if v.flag&flagIndir != 0 { //指针 ptr = *(*unsafe.Pointer)(ptr) //解引用得到data } // The returned value's address is v's value. if ptr == nil { return Value{} } tt := (*ptrType)(unsafe.Pointer(v.typ)) typ := tt.elem fl := v.flag&flagRO | flagIndir | flagAddr //这里我有点困惑, 为什么要设置flagIndir | flagAddr? fl |= flag(typ.Kind()) return Value{typ, ptr, fl} } panic(&ValueError{\"reflect.Value.Elem\", v.kind()}) } 看起来Elem()也是操做ptr, 没有明显的值拷贝. emptyInterface和nonEmptyInterface emptyInterface比较简单 // emptyInterface is the header for an interface{} value. type emptyInterface struct { typ *rtype word unsafe.Pointer } 而nonEmptyInterface就复杂多了, 包括静态interface类型, concrete类型, 和方法表. 方法表容量有100000个之多, 但我判断这部分其实不占那么多内存的. // nonEmptyInterface is the header for an interface value with methods. type nonEmptyInterface struct { // see ../runtime/iface.go:/Itab itab *struct { ityp *rtype // static interface type typ *rtype // dynamic concrete type hash uint32 // copy of typ.hash _ [4]byte fun [100000]unsafe.Pointer // method table } word unsafe.Pointer } 上面是reflect的定义, 相应的runtime表达, 在src/runtime/runtime2.go中, 有: type iface struct { tab *itab data unsafe.Pointer } // layout of Itab known to compilers // allocated in non-garbage-collected memory // Needs to be in sync with // ../cmd/compile/internal/gc/reflect.go:/^func.dumptabs. type itab struct { inter *interfacetype _type *_type hash uint32 // copy of _type.hash. Used for type switches. _ [4]byte fun [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter. } type eface struct { _type *_type data unsafe.Pointer } func efaceOf(ep *interface{}) *eface { return (*eface)(unsafe.Pointer(ep)) } 基本上差不多. ValueOf实例 把一个指向interface类型的指针, 解引用后做ValueOf操做: // p是unsafe.Pointer, 已知指向reflect.Interface类型, rt是这个类型的TypeOf()后的reflect.Type if rt.NumMethod() == 0 { // 没有方法是eface ti := *(*interface{})(p) v := reflect.ValueOf(ti) } 此时p指向eface, 见上面eface定义; 在这个例子中, 这个interface的content是个gotiny.baseTyp结构体: // p是unsafe.Pointer, 已知指向reflect.Interface类型, rt是这个类型的TypeOf()后的reflect.Type if rt.NumMethod() > 0 { // 有方法是iface ti := *(*interface { M() })(p) v := reflect.ValueOf(ti) et := v.Type() } 此时p指向iface, 见上面iface定义; 在这个例子中, 这个interface是: // tint是int, 实现了io.ReadWriteCloser type tint int func (tint) Read([]byte) (int, error) { return 0, nil } func (tint) Write([]byte) (int, error) { return 0, nil } func (tint) Close() error { return nil } v1interface io.ReadWriteCloser = tint(2) 这里我们看到, ti在dlv看来, 其data是2. 我们知道一个interface的\"data\"域是个指针, 但这里的2刚好就是v1interface的值, 那么这个data已经不是指针而是值了, 是否是因为dlv\"自动\"解引用了呢? 在ValueOf(ti)的里面的unpackEface()中, ti被\"值拷贝\"(interface的值拷贝)到i: // unpackEface converts the empty interface i to a Value. func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(&i)) // NOTE: don't read e.word until we know whether it is really a pointer or not. t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} } 因为i在内存中是emptyInterface类型, 强转成e, 我们能借助dlv看到e的typ和word:注意到t的Kind是2(也就是int), 而word是个指针. 这个e就是i, 也就是ti. 所以我们看到v := reflect.ValueOf(ti)执行后, v就是ti的实际内存表达:但从此丢失了ti的method信息??? 结论 当类型的Kind是Interface的时候, 如果只有指向这个变量的指针p, 那么要区分p指向的到底是eface还是iface, 不能混用, 否则会panic. 所以要这样: // p是unsafe.Pointer, 已知指向reflect.Interface类型, rt是这个类型的TypeOf()后的reflect.Type if rt.NumMethod() > 0 { // 有方法是iface ti := *(*interface { M() })(p) v := reflect.ValueOf(ti) et := v.Type() } else { // 没有方法是eface ti := *(*interface{})(p) v := reflect.ValueOf(ti) et := v.Type() } 强制escape /usr/local/go/src/reflect/value.go 定义一个全局变量: var dummy struct { b bool x interface{} } 如果需要强制escape一个变量, 只需要赋值给dummy的x. 因为一个全局变量持有x的引用, 那x必须在heap里面. // Dummy annotation marking that the value x escapes, // for use in cases where the reflect code is so clever that // the compiler cannot follow. func escapes(x interface{}) { if dummy.b { dummy.x = x } } 问答 为什么看到value的kind是54? 如图?答: 这里的kind不是反射那个Kind, 或者说不完全是. 这里的kind是rtype类型的一个field. 真正的kind是这个field在与上kindMask, 相当于t.kind & 31 func (t *rtype) Kind() Kind { return Kind(t.kind & kindMask) } 所以54&31后, 是22. 22对应的Kind是reflect.Ptr interface赋值给interface 直接赋值: interface只有一层 我们知道interface的内部第二个field是个指针 type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 那么如果我把一个interface变量(t1i)赋值给另一个interface变量(t2i), 那么t2i的data是指向t1i的拷贝的吗? 比如 t := 9 var t1i interface{} t1i = t var t2i interface{} t2i = t1i 答: 不是. 首先, interface的赋值也有值拷贝, 前面说过的: 再理解一下 The second word in the interface value points at the actual data, in this case a copy of b. The assignment var s Stringer = b makes a copy of b rather than point at b for the same reason that var c uint64 = b makes a copy: if b later changes, s and c are supposed to have the original value, not the new one. 其次, 这里并不是把t2i这个interface的结构即eface结构拷贝一份, 并用t1i的data域来指向. 而是t2i发现赋值对象也是个interface, 就直接查其concrete类型再赋值. 所以我说interface变量只有一级, 不存在interface里面再包一层interface. 而一定是interface下面就是concrete类型. 注意我说的是运行时, 不是定义时. 定义时可以嵌套interface. 证明: fmt.Println(reflect.TypeOf(t1i).String())结果是int TypeOf(t1i)这步就有t1i赋值给入参的过程, 这个就是interface赋值给interface. 如果允许运行时嵌套interface, 那多层函数传递interface就会嵌套好多层. 用户不会知道里面有多少层interface的. 取地址赋值: interface包interface地址 如果把上面的代码改成 ti := int64(9) var tinterface interface{} tinterface = ti fmt.Println(reflect.TypeOf(tinterface).String()) var t2interface interface{} t2interface = &tinterface ti = 10 fmt.Println(t2interface) 那么t2interface的具体内存表达是什么样的? 答: t2interface的data指针是*interface{}类型, 应该就是指向tinterface 结论 ti := int64(9) var tinterface interface{} tinterface = ti fmt.Println(reflect.TypeOf(tinterface).String()) var t2interface interface{} t2interface = tinterface fmt.Println(reflect.TypeOf(t2interface).String()) var t3interface interface{} t3interface = &tinterface fmt.Println(reflect.TypeOf(t3interface).String()) var t4interface interface{} t4interface = &t3interface fmt.Println(reflect.TypeOf(t4interface).String()) 这段代码打印: int64 int64 *interface {} *interface {} 特别的, t4interface有3层嵌套, 包括&t3interface一层, &tinterface一层, 最后的int64(9)一层. 所以: interface i1值赋值给interface i2, 其concrete类型会传递(或者说短接)到\"第一层\".(t2interface的行为) interface i1值赋值给interface i2, 其i1的concrete的值会拷贝给i2. interface取地址赋值给interface, 并非传递, 而是嵌套.(t4interface的行为) slice能当作\"出参\"传递 比如io.Reader type Reader interface { Read(p []byte) (n int, err error) } 这里说的很清楚, Read reads up to len(p) bytes into p. 注意这里 p做为出参, Read函数内对p的修改是能够被调用者看到的. 但注意up to len(p), 因为p是调用者传入slice的\"浅拷贝\", 大小是不能改变的, append()函数等改变len()的不会体现到调用者看到的\"p\"中. 结论 在slice p被当作参数传递的过程中, 发生了slice的\"浅拷贝\", 浅拷贝共享底层数组, 所以对底层数组的修改能够被调用者看到, 其作用类似\"出参\". 但\"浅拷贝\"对slice本身的改变, 比如改变len, 原slice是看不到的. a := []int{1,2,3} a1 := a a1[2]=100 a1 = append(a1, 4) fmt.Println(a1) fmt.Println(a) //输出 [1 2 100 4] [1 2 100] slice和gc 对一个slice进行切片不会导致底层array被gc. 具体见https://stackoverflow.com/questions/28432658/does-go-garbage-collect-parts-of-slices As mentioned earlier, re-slicing a slice doesn't make a copy of the underlying array. The full array will be kept in memory until it is no longer referenced. Occasionally this can cause the program to hold all the data in memory when only a small piece of it is needed. Since the slice references the original array, as long as the slice is kept around the garbage collector can't release the array. 具体例子 https://yourbasic.org/golang/clear-slice/ Remove all elements To remove all elements, simply set the slice to nil. a := []string{\"A\", \"B\", \"C\", \"D\", \"E\"} a = nil fmt.Println(a, len(a), cap(a)) // [] 0 0 This will release the underlying array to the garbage collector (assuming there are no other references). Keep allocated memory To keep the underlying array, slice the slice to zero length. a := []string{\"A\", \"B\", \"C\", \"D\", \"E\"} a = a[:0] fmt.Println(a, len(a), cap(a)) // [] 0 5 If the slice is extended again, the original data reappears. fmt.Println(a[:2]) // [A B] 结论 对slice进行切片不会导致gc 即a = a[:0]不会把底层的array gc掉. float32和data race 在pidinfo.go中, 我使用了float32类型的变量userHz var userHz float32 = 100 我当时认为一个CPU对齐的32bit变量, 它的load和store操作是原子的. -- 好像理论上是的. 但go test -race还是认为这里有问题: 即同时读写这个变量被认为是数据竞争: WARNING: DATA RACE Read at 0x00000071c34c by goroutine 8: gitlabe1.ext.net.nokia.com/godevsig/system/pidinfo.(*TidInfo).CPUpercent() /builds/godevsig/system/pidinfo/pidinfo.go:480 +0x269 ... Previous write at 0x00000071c34c by goroutine 10: gitlabe1.ext.net.nokia.com/godevsig/system/pidinfo.hzUpdater() /builds/godevsig/system/pidinfo/pidinfo.go:331 +0x22c 使用sync/atomic // AtomicLoadFloat64 loads float64 atomically func AtomicLoadFloat64(addr *float64) float64 { return math.Float64frombits(atomic.LoadUint64((*uint64)(unsafe.Pointer(addr)))) } // AtomicStoreFloat64 stores float64 atomically func AtomicStoreFloat64(addr *float64, val float64) { atomic.StoreUint64((*uint64)(unsafe.Pointer(addr)), math.Float64bits(val)) } 再说reflect 什么是unaddressable 不能改变a package main import ( \"fmt\" \"reflect\" ) func main() { a := 55 fmt.Println(a) rv := reflect.ValueOf(a) fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } 上面的代码输出: 代码13行, 说值不能被寻址 55 55 panic: reflect: reflect.Value.SetInt using unaddressable value goroutine 1 [running]: reflect.flag.mustBeAssignableSlow(0x82) /usr/local/go-faketime/src/reflect/value.go:260 +0x138 reflect.flag.mustBeAssignable(...) /usr/local/go-faketime/src/reflect/value.go:247 reflect.Value.SetInt(0x4a4220, 0x54ab98, 0x82, 0x42) /usr/local/go-faketime/src/reflect/value.go:1633 +0x3b main.main() /tmp/sandbox505010953/prog.go:13 +0x1d9 能改变a 但下面的代码就能够修改变量a的值: package main import ( \"fmt\" \"reflect\" ) func main() { a := 55 fmt.Println(a) rptr := reflect.ValueOf(&a) rv := rptr.Elem() fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } 上面代码输出: 55 55 66 关键在于第11和12行. rptr是&a的值, 也就是a的地址; 而rv是rptr的解引用, 也即rv就是a. 对rv的值的改变, 就是对a的改变. 为什么? 在下面代码中, rv := reflect.ValueOf(a)实际上是得到a的副本的值 而如果rv.SetInt(66)能够成立的话, 也只能是set这个副本的值, 且这个修改也不会反应到a上. func main() { a := 55 fmt.Println(a) rv := reflect.ValueOf(a) fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } 那为什么这样可以? func main() { a := 55 fmt.Println(a) rptr := reflect.ValueOf(&a) rv := rptr.Elem() fmt.Println(rv) rv.SetInt(66) fmt.Println(a) } rptr := reflect.ValueOf(&a)也是得到&a的副本的值. 但&a是个指针, 它的解引用rptr.Elem()就是a, 而不是a的副本. 所以可以修改a.副本发生在指针是没问题的. 更进一步解释 rv.SetInt(66)的源码如下: // SetInt sets v's underlying value to x. // It panics if v's Kind is not Int, Int8, Int16, Int32, or Int64, or if CanSet() is false. func (v Value) SetInt(x int64) { v.mustBeAssignable() switch k := v.kind(); k { default: panic(&ValueError{\"reflect.Value.SetInt\", v.kind()}) case Int: *(*int)(v.ptr) = int(x) case Int8: *(*int8)(v.ptr) = int8(x) case Int16: *(*int16)(v.ptr) = int16(x) case Int32: *(*int32)(v.ptr) = int32(x) case Int64: *(*int64)(v.ptr) = x } } 可以看到, 只有v有ptr才能赋值. 结论 其实很简单, 通过反射赋值, 实际上就是两个过程: 先取地址, 再赋值. ptr = &a *ptr = x 例子 var v interface{} a := 55 v = &a rptr := reflect.ValueOf(v) //unaddressable rptr.Set(reflect.New(rptr.Type().Elem())) //可以赋值, 相当于v = &b reflect.ValueOf(&v).Elem().Set(reflect.New(rptr.Type().Elem())) 原理 https://blog.golang.org/laws-of-reflection 结论 每个类型都对应一个_type结构, 描述了该类型的属性和方法 interface也是类型(也是type声明的), 用interfacetype来描述, 后者内部也包括了_type结构 空interface也是类型, 但没有方法 带方法的interface规定了方法集, 也保存在其_type中 interface的表达可以大概认为是(value, type)对, 更具体的说, 是个16字节的结构, 包括一个指针和实际的(concrete)类型// 没方法的interface type eface struct { _type *_type data unsafe.Pointer } // 有方法的interface type iface struct { tab *itab data unsafe.Pointer } interface变量的静态类型是代码中声明的类型, 这个类型会伴随这个interface变量一生, 不会改变 静态类型在编译阶段用来检查是否赋值成立 -- 即对方是否实现了我规定的方法集 静态类型规定了这个interface变量可以直接调用的方法. concrete类型(有时也称动态类型)是给interface变量赋值的时候, 实际的对象类型 interface变量的concrete类型会随着再次赋值而改变 类型断言的意义在于断言这个concrete类型是否满足断言 -- 用类型断言能够突破静态类型的限制, 调用concrete类型的其他方法 有方法的interface的itable是动态计算的 -- runtime通过匹配该interface类型的方法集和concrete对象类型的方法集, 来生成itable. -- 每个interface变量都有个动态生成的itable. 这个和编译时检查能否赋值不同 -- 但我没想明白, 似乎在编译阶段就能确定下来. 相关的说法是: 就是说可以在编译时搞, 但没必要. Go's dynamic type conversions mean that it isn't reasonable for the compiler or linker to precompute all possible itables: there are too many (interface type, concrete type) pairs, and most won't be needed 反射本质上是一种检测interface变量底层的(value, type)对的方法 -- 这里指concrete类型 reflect.Value类型其实就是这个interface变量的内部表达, 它本身既包含了\"值\", 也包含了类型. 所以reflect.Value有Type()方法得到其concrete类型 所以Value类型的Interface()方法能够再次\"组装(pack)\"一个interface变量, 返回一个空的interface{}类型 reflect.TypeOf()方法其实是个shortcut, 和先ValueOf()再Type()效果一样. reflect.Type类型是go内部的_type的表达 能否对Value类型进行Set()操作, 取决于是否这个Value对象是否是另一个对象的引用type Struct1 struct { A int64 } p := Struct1{} V := reflect.ValueOf(&p).Elem() V.FieldByName(\"A\").SetInt(100) 上面代码能工作, 因为V是对p的引用, 就能修改p的内容. 理解起来, 和f(x)不能改变x, 但f(&x)能改变x是一个道理 再议interface 主要是想考察一下, 我曾经用过的map接口 type intMap struct { ks []int // in insertion order mp map[int]interface{} } 这里面的key是int, value是interface{} 这个interface{}的使用会不会有性能问题? 这里的使用是指: set, 对value赋值, 和普通的map相比, 这里多了对interface{}赋值 get, 获取value func (im *intMap) set(k int, v interface{}) { _, has := im.mp[k] if !has { im.ks = append(im.ks, k) } im.mp[k] = v } func (im *intMap) get(k int) (interface{}, bool) { v, has := im.mp[k] return v, has } interface{}回顾 上图的Binary是uint64, 有两个方法 type Binary uint64 func (i Binary) String() string { return strconv.Uitob64(i.Get(), 2) } func (i Binary) Get() uint64 { return uint64(i) } s是个Stringer的interface{}, 是带方法的. 但它的itable表只有String一个方法. Binary的Get方法不是Stringer的关注点, 不在Stringer的itable里面 itable是运行时动态计算的. 虽然在编译的时候, 编译器是可以知道这些信息的:S := Stringer(b)就包含了所有的关键点, 但在编译阶段就写好itable太粗暴了: interface{}和底层concrete类型的配对可以有非常多种, 很多在运行时可能都不真正需要. 动态itable基于 编译器给每个concrete类型都生成了类型描述, 包括它的方法(函数指针形式)列表 -- 实现表 编译器给每个interface类型也生成类型描述, 它也有方法列表. -- 需求表 运行时按照需求表来查实现表, 完成itable的构建 构建好的itable表会被cache, 同一个interface{}和concrete只会构建一次. set get性能损失如何? type intMap struct { ks []int // in insertion order mp map[int]interface{} } 这里的value是个empty的interface{}, go里面有专门的eface来表达: type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 那么对空interface赋值, 除了data域的值拷贝, 还有个_type *_type指针的赋值, 这里应该就是指向concrete类型的类型描述. 这样, 赋值完成后, 这个interface变量, 就有所有concrete变量的所有信息. 看起来多出来的_type *_type指针赋值, 并没有多少性能损耗. 在get的时候, 直接获取到interface, 通常需要类型断言才能被业务逻辑使用: 比如 //childpi是个空的interface{}类型 childpi, _ := pi.children.get(pid) //断言成*PidInfo才能使用 children = append(children, childpi.(*PidInfo)) 我猜从原理上, 这个类型断言就是看_type *_type是不是*PidInfo 看起来性能也没有多少损失 结论 我目前倾向没有多少性能损失的结论 标准库的time.Now()如何取得系统时间? time.Now()的实现流程 实际的系统时间是汇编代码, 比如mips64是在src/runtime/sys_linux_mips64x.s // func walltime() (sec int64, nsec int32) TEXT runtime·walltime(SB),NOSPLIT,$16 MOVW $0, R4 // CLOCK_REALTIME MOVV $0(R29), R5 MOVV $SYS_clock_gettime, R2 SYSCALL MOVV 0(R29), R3 // sec MOVV 8(R29), R5 // nsec MOVV R3, sec+0(FP) MOVW R5, nsec+8(FP) RET TEXT runtime·nanotime(SB),NOSPLIT,$16 MOVW $1, R4 // CLOCK_MONOTONIC MOVV $0(R29), R5 MOVV $SYS_clock_gettime, R2 SYSCALL MOVV 0(R29), R3 // sec MOVV 8(R29), R5 // nsec // sec is in R3, nsec in R5 // return nsec in R3 MOVV $1000000000, R4 MULVU R4, R3 MOVV LO, R3 ADDVU R5, R3 MOVV R3, ret+0(FP) RET 这里的walltime和nanotime会被time_now()调用. 在src/runtime/timestub.go中 time_now()是time.now的linkname. 即实际上time.now()就是runtime.time_now() package runtime import _ \"unsafe\" // for go:linkname //go:linkname time_now time.now func time_now() (sec int64, nsec int32, mono int64) { sec, nsec = walltime() return sec, nsec, nanotime() } 这里的问题是, 每次获取系统时间, 都有2次系统调用: 第一次是clock_gettime获取CLOCK_REALTIME 第二次是clock_gettime获取CLOCK_MONOTONIC 同时, 我们也看到, 虽然调用了系统调用, 但这个调用路径上没有埋伏runtime的调度等函数. 最后, 标准库time包的Now()调用了now() // Now returns the current local time. func Now() Time { sec, nsec, mono := now() mono -= startNano sec += unixToInternal - minWall if uint64(sec)>>33 != 0 { return Time{uint64(nsec), sec + minWall, Local} } return Time{hasMonotonic | uint64(sec) clock_gettime系统调用 man clock_gettime中说: #include int clock_gettime(clockid_t clk_id, struct timespec *tp); 这里的clk_id可以是从Epoch(1970年?)算起的绝对时间, 这个时间对所有进程都一样. 也可以是按进程角度看起来的时间 CLOCK_REALTIME: 系统时间, 墙上时间. wall clock CLOCK_REALTIME_COARSE: 系统时间, 精度稍差, 但快速的版本 CLOCK_MONOTONIC: 从开机算起的时间, 不能更改 CLOCK_MONOTONIC_COARSE: 精度稍差但快的版本 CLOCK_MONOTONIC_RAW: 硬件返回的时间, 不受NTP影响 CLOCK_PROCESS_CPUTIME_ID: 按进程算的时间 CLOCK_THREAD_CPUTIME_ID: 按线程算的时间 逃逸分析和变量分配 go的程序在编译的时候, 通过逃逸分析来确定变量是分配在栈上, 还是分配到堆上. 一个变量分配在哪里是编译时决定的 如果编译器通过分析得知, 一个变量可能脱离其声明时所在的函数作用域, 就会把这个变量分配到堆上. 否则, 编译器知道这个变量的所有引用都在此函数的生命周期内, 那这个变量就可以被安全的分配到栈上. 在堆上分配的开销相对很大, 编译器会插入CALL runtime.newobject(SB)的汇编代码来实现堆分配. 而栈分配就是简单的通过栈指针SP+偏移的引用. 一个典型的堆分配如图: 下面我们来简单了解一下编译器如何判断一个变量是否可能逃逸 逃逸分析使用 go build, go run, go test都支持-gcflags '-m -l'选项, 打开逃逸分析的输出. -m: 最多4个-m连用, 打开丰富的编译过程的逃逸分析记录 -l: 禁止inline, 让-m的信息更容易阅读 逃逸分析实例 比如下面的代码 package main import ( \"fmt\" \"unsafe\" ) var gr *int func change(r *int) { *r = *r + 1 //gr = r } func sum(a, b int) int { s := a + b change(&s) fmt.Println(s) //fmt.Println(&s) addr := uintptr(unsafe.Pointer(&s)) fmt.Printf(\"0x%x %v\\n\", addr, *(*int)(unsafe.Pointer(addr))) return s } func main() { a, b := 1, 2 c := sum(a, b) fmt.Println(c) } 使用逃逸分析结果如下, $ go run -gcflags '-m -l' hello.go # command-line-arguments ./hello.go:10:13: change r does not escape ./hello.go:18:13: sum ... argument does not escape ./hello.go:18:13: s escapes to heap ./hello.go:21:12: sum ... argument does not escape ./hello.go:21:13: addr escapes to heap ./hello.go:21:32: *(*int)(unsafe.Pointer(addr)) escapes to heap ./hello.go:28:13: main ... argument does not escape ./hello.go:28:13: c escapes to heap 4 0xc000096eb8 4 4 解释: 先看简单点的main函数, a和b两个int变量, 传给sum得到int c, 然后打印c. 首先, go里面都是值传递, main的a和b, 在传给sum的时候, 值已经分别被拷贝进sum的参数, 所以a和b不可能逃逸. c拷贝了sum函数的返回值, 在传递给Println的时候, 又发生了值拷贝, c只是int, 不可能逃逸. 但./hello.go:28:13: c escapes to heap是说c逃逸到堆了吗? 其实不是, 因为Println()的入参是interface{}, 而interface{}是由类型域和指针域组成的, 它的指针域指向底层的数据. 这里的意思是说, c的值被拷贝进一个堆的int变量(应该还是栈上), 被Println的入参interface变量的指针域指向. 所以并不是变量c本身逃逸到堆. 注: 通过反汇编发现, c的值拷贝也不是分配到堆上的. 如果改成fmt.Println(&c), 则c会逃逸. 因为Pringln持有了c的引用, 而没有什么办法能阻止一个函数再次\"传递\"这个引用到channel或者一个全局变量, 从而c的引用会被更广泛的持有. 所以编译器认为c会逃逸, 要分配到堆里, 由运行时GC来负责变量c的释放. 真正的逃逸会在变量声明的那行, 打印moved to heap: 变量名 比如, 如果第19行没有被注释, 则变量s会逃逸到堆. 逃逸分析会打印: ./hello.go:16:2: moved to heap: s 表示s真正的逃逸到堆了. 一般的, 取地址后赋值给interface{}, 则会更可能被编译器判定为逃逸. 注意这里说的是可能, 不是绝对. 有些情况下, 取地址赋值给interface{}不会导致逃逸. 比如下面代码片段: 测试版本go1.13 func changeInterface(r interface{}) { v := r.(*int) *v = *v + 1 } a, b := 1, 2 s := a + b changeInterface(&s) //同样是interface{}赋值, 这句不会导致s逃逸 fmt.Println(s) //值拷贝, 不会导致s逃逸 fmt.Println(&s) //fmt.Print函数族+取变量地址会导致变量逃逸到堆. 个人认为这个设定不是很合理. 编译器应该确切知道fmt.Println()有没有再\"散发\" `&s` 不是所有取地址都会逃逸. 比如sum里面调用了change(&s), 传递的是s的引用; 那s是有可能逃逸的, 但编译器发现change函数, 在没有赋值给全局变量gr的情况下(注释掉12行), 并没有实际上让s继续逃逸. 所以上面的代码, 逃逸分析得出, s还是分配到栈里. 同样是打印地址, addr := uintptr(unsafe.Pointer(&s))然后打印addr不会让s逃逸; 而fmt.Println(&s)则会让s逃逸. uintptr和unsafe.Pointer()的互相强转组合能阻断这种\"引用扩散\", 这可能是unsafe包名字的由来: 其引用的地址由于没有被记录在案, 可能被gc回收掉而不知道. 判断一个变量是否真正被编译器判定为逃逸, 看变量声明的那行是否有moved to heap: 变量名, 注意, 变量名 escapes to heap发生在使用改变量那一行, 个人认为不是说这个变量逃逸了. 还有一个办法来确认是否逃逸: 用go tool compile -S -m -l查看汇编. 比如本例中, 考察sum函数中的变量s, 只有编译器判定s会逃逸并打印moved to heap: s, 其汇编代码里才有CALL runtime.newobject(SB)表示真的调用运行时函数来给改变量分配内存空间. 而平常的s escapes to heap在调用fmt.Print族函数的时候都会出现, 个人理解并不是变量已经逃逸的意思, 也不是变量的拷贝被放到堆中. 下面的截图是本例代码的反汇编go tool objdump -S hello > hello.objdump在调用CALL fmt.Println(SB)之前, sum函数的所有操作的变量看起来都是基于SP的, 都是栈变量. 看起来传递给fmt.Println()的拷贝也并没有分配到堆上. 注: unsafe.Pointer有如下性质: unsafe.Pointer和任意的指针类型能互相转换 unsafe.Pointer和uintptr能互相转换 指针和uintptr不能直接互转 uintptr用于做\"指针\"计算 查看汇编 go tool compile -S -m -l hello.go 反汇编 go tool objdump -S hello > hello.objdump go的值和指针 代码: func Show(i interface{}) { if i == nil { fmt.Printf(\"type: %T, value: %#v\\n\", i, i) return } t := reflect.TypeOf(i) if t.Kind() != reflect.Ptr { fmt.Printf(\"type: %T, size: %d; value: %#v\\n\", i, t.Size(), i) } else { v := reflect.ValueOf(i) fmt.Printf(\"type: %T, size: %d; value: %#v, value size: %d\\n\", i, t.Size(), v.Elem(), t.Elem().Size()) } } 结论: 所有的指针都占8个字节 x86_64 type: int, size: 8; value: 99 type: *int, size: 8; value: 99, value size: 8 type: **int, size: 8; value: (*int)(0xc0000e01d0), value size: 8 type: *int, size: 8; value: 0, value size: 8 type: **int, size: 8; value: (*int)(0xc0000e0228), value size: 8 type: string, size: 16; value: \"hello world\" type: *string, size: 8; value: \"hello world\", value size: 16 type: , value: type: *os.File, size: 8; value: os.File{file:(*os.file)(0xc0000cc060)}, value size: 8 type: **os.File, size: 8; value: &os.File{file:(*os.file)(0xc0000cc060)}, value size: 8 补充: 逃逸分析命令 go build -gcflags '-m -l' go test -gcflags '-m -l' map golang的map底层是hash表实现的. 初始化 hashmap结构体 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } buckets是底层数组的指针, 用unsafe.Pointer来声明的 make map变量的时候 在make(map[k]v, hint)的时候 调用runtime/map.go // makemap implements Go map creation for make(map[k]v, hint). // If the compiler has determined that the map or the first bucket // can be created on the stack, h and/or bucket may be non-nil. // If h != nil, the map can be created directly in h. // If h.buckets != nil, bucket pointed to can be used as the first bucket. func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem > maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint 这个hash表的底层承载是数组(bukets), 最大容量是2^B即, 而B是uint8, 故数组元素最大2^256个, 非常大 每个数组元素叫buket, 能装载8个元素; 相同key的buket用链表链接(拉链式解决冲突) 如果make不指定capacity, 初始化hash表的时候默认使用B=0, 即空的bukets数组; 当后面第一次加数据的时候会扩容. -- Lazy模式 扩容时, 容量是原来的2倍. 因为是在runtime包里的, 这些都是运行时的行为. 遍历 用迭代器来遍历map, 用mapiterinit(t *maptype, h *hmap, it *hiter)来初始化一个迭代器, 编译器生成代码的时候会插入这个调用 / A hash iteration structure. // If you modify hiter, also change cmd/compile/internal/gc/reflect.go to indicate // the layout of this structure. type hiter struct { key unsafe.Pointer // Must be in first position. Write nil to indicate iteration end (see cmd/internal/gc/range.go). elem unsafe.Pointer // Must be in second position (see cmd/internal/gc/range.go). t *maptype h *hmap buckets unsafe.Pointer // bucket ptr at hash_iter initialization time bptr *bmap // current bucket overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // bucket iteration started at offset uint8 // intra-bucket offset to start from during iteration (should be big enough to hold bucketCnt-1) wrapped bool // already wrapped around from end of bucket array to beginning B uint8 i uint8 bucket uintptr checkBucket uintptr } func mapiterinit(t *maptype, h *hmap, it *hiter) { it.t = t it.h = h // grab snapshot of bucket state it.B = h.B it.buckets = h.buckets //起始点随机, 这是为什么range map出来的结果顺序不确定. r := uintptr(fastrand()) if h.B > 31-bucketCntBits { r += uintptr(fastrand()) > h.B & (bucketCnt - 1)) //it.bucket是当前的bucket指针, 指向底层buckets数组的元素, 即key对应的table中的index的元素 it.bucket = it.startBucket mapiternext(it) } mapiternext()是遍历map的执行主体, 编译器会在range语句里面反复调用它, 来得到下一个key, value对 func mapiternext(it *hiter) { h := it.h //不能同时写, 否则直接panic if h.flags&hashWriting != 0 { throw(\"concurrent map iteration and map write\") } //it.t.key里面包括了hash算法 t := it.t alg := t.key.alg //bucket是当前的bucket指针 bucket := it.bucket //b是当前的bucket指向的bmap, bmap是8个元素的结构 b := it.bptr //i是拉链8个元素的编号 i := it.i next: 如果当前bucket为空 如果又回到起始的bucket, 说明遍历结束了 it.key = nil it.elem = nil return //根据是否map在增长中, 来算下个pmap拉链元素的地址, 类似这样 b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) //指针++, 在it.buckets数组里往下移动一个单元 bucket++ //下一个bucket了, i为0 i = 0 //看当前的bucket链表, 一个bucket最多有8个元素 for ; i hash算法 hash算法是key的类型决定的, 详见:src/runtime/alg.go // typeAlg is also copied/used in reflect/type.go. // keep them in sync. type typeAlg struct { // function for hashing objects of this type // (ptr to object, seed) -> hash hash func(unsafe.Pointer, uintptr) uintptr // function for comparing objects of this type // (ptr to object A, ptr to object B) -> ==? equal func(unsafe.Pointer, unsafe.Pointer) bool } 常用的hash算法 实现hash算法的文件在src/runtime/hash64.go和src/runtime/hash32.go 注: 这两个文件有编译限制, 针对CPU类型的. var algarray = [alg_max]typeAlg{ alg_NOEQ: {nil, nil}, alg_MEM0: {memhash0, memequal0}, alg_MEM8: {memhash8, memequal8}, alg_MEM16: {memhash16, memequal16}, alg_MEM32: {memhash32, memequal32}, alg_MEM64: {memhash64, memequal64}, alg_MEM128: {memhash128, memequal128}, alg_STRING: {strhash, strequal}, //这个是interface的hash方法, 内部调用这个interface的hash方法 alg_INTER: {interhash, interequal}, alg_NILINTER: {nilinterhash, nilinterequal}, alg_FLOAT32: {f32hash, f32equal}, alg_FLOAT64: {f64hash, f64equal}, alg_CPLX64: {c64hash, c64equal}, alg_CPLX128: {c128hash, c128equal}, } //内存hash最普遍, 根据指针p的内容和一些素数常量来做操作 const ( // Constants for multiplication: four random odd 64-bit numbers. m1 = 16877499708836156737 m2 = 2820277070424839065 m3 = 9497967016996688599 m4 = 15839092249703872147 ) func memhash64(p unsafe.Pointer, seed uintptr) uintptr { h := uint64(seed + 8*hashkey[0]) h ^= uint64(readUnaligned32(p)) | uint64(readUnaligned32(add(p, 4)))> 29 h *= m3 h ^= h >> 32 return uintptr(h) } func strhash(a unsafe.Pointer, h uintptr) uintptr { x := (*stringStruct)(a) return memhash(x.str, h, uintptr(x.len)) } 有的架构硬件支持aeshash, 就使用这些硬件算法 func memhash(p unsafe.Pointer, seed, s uintptr) uintptr { if (GOARCH == \"amd64\" || GOARCH == \"arm64\") && GOOS != \"nacl\" && useAeshash { return aeshash(p, seed, s) } ... } 结论 golang的map实现是hash表, 拉链式处理冲突 golang在编译时的make(map[k]v, hint), 会被编译器当作makemap()的函数调用插入到目标代码里, 在runtime真正创建map时调用. 对map的range遍历, 会被编译器当作迭代器的函数调用, 供在runtime时调用 对map的遍历, 没有magic, 还是老老实实的对底层数组从头到尾遍历 根据key的类型不同, 用不同的hash函数, 最后一般会调到memhash(), 做内存hash 如果make时不指定capacity, 默认创建底层数组为0的map. 底层数组会在以后put元素时才创建, 而且刚开始不大; 要put的元素越来越多时, 这个底层数组会以2倍的速率随之扩容, 老的元素会被一个个的拷贝到新的2倍大小的数组里. hash函数虽然不变, 但hash出来算index的算法会根据底层数组大小改变. // A map is just a hash table. The data is arranged // into an array of buckets. Each bucket contains up to // 8 key/elem pairs. The low-order bits of the hash are // used to select a bucket. Each bucket contains a few // high-order bits of each hash to distinguish the entries // within a single bucket. // // If more than 8 keys hash to a bucket, we chain on // extra buckets. // // When the hashtable grows, we allocate a new array // of buckets twice as big. Buckets are incrementally // copied from the old bucket array to the new bucket array. // // Map iterators walk through the array of buckets and // return the keys in walk order (bucket #, then overflow // chain order, then bucket index). To maintain iteration // semantics, we never move keys within their bucket (if // we did, keys might be returned 0 or 2 times). When // growing the table, iterators remain iterating through the // old table and must check the new table if the bucket // they are iterating through has been moved (\"evacuated\") // to the new table. Gc的演进 v1.0 — 完全串行的标记和清除过程，需要暂停整个程序； v1.1 — 在多核主机并行执行垃圾收集的标记和清除阶段11； v1.3 — 运行时基于只有指针类型的值包含指针的假设增加了对栈内存的精确扫描支持，实现了真正精确的垃圾收集12； 将 unsafe.Pointer 类型转换成整数类型的值认定为不合法的，可能会造成悬挂指针等严重问题； v1.5 — 实现了基于三色标记清扫的并发垃圾收集器13； 大幅度降低垃圾收集的延迟从几百 ms 降低至 10ms 以下； 计算垃圾收集启动的合适时间并通过并发加速垃圾收集的过程； v1.6 — 实现了去中心化的垃圾收集协调器； 基于显式的状态机使得任意 Goroutine 都能触发垃圾收集的状态迁移； 使用密集的位图替代空闲链表表示的堆内存，降低清除阶段的 CPU 占用14； v1.7 — 通过并行栈收缩将垃圾收集的时间缩短至 2ms 以内15； v1.8 — 使用混合写屏障将垃圾收集的时间缩短至 0.5ms 以内16； v1.9 — 彻底移除暂停程序的重新扫描栈的过程17； v1.10 — 更新了垃圾收集调频器（Pacer）的实现，分离软硬堆大小的目标18； v1.12 — 使用新的标记终止算法简化垃圾收集器的几个阶段19； v1.13 — 通过新的 Scavenger 解决瞬时内存占用过高的应用程序向操作系统归还内存的问题20； v1.14 — 使用全新的页分配器优化内存分配的速度21； interface赋值 接口有两个字段, 一个是类型, 一个是指针. 那对一个空接口赋值, 是传值还是传地址? type Person struct{ name string } type IPerson interface{} func main() { var person Person = Person{\"John\"} var iPerson IPerson fmt.Println(person) // => John fmt.Println(iPerson) // => ...so looks like a pointer iPerson = person // ...this seems to be making a copy fmt.Println(iPerson) // => John person.name = \"Mike\" fmt.Println(person) // => Mike //这里说明, 对数据源的改变, 不会体现到interface里 //说明interface是值拷贝 fmt.Println(iPerson) // => John ...so looks like it wasn't a pointer, // or at least something was definitely copied } The second word in the interface value points at the actual data, in this case a copy of b. The assignment var s Stringer = b makes a copy of b rather than point at b for the same reason that var c uint64 = b makes a copy: if b later changes, s and c are supposed to have the original value, not the new one. 也就是说, 对空接口的赋值, 发生了值拷贝, 空接口的指针字段, 指向新的拷贝. 更正 又过了一段时间, 觉得上面的解释不对对interface的赋值是值拷贝没错. 但对string的值拷贝不拷贝其底层buffer.上面例子第11行, 对空接口iPerson的赋值, 发生了string的\"值拷贝\", 即只拷贝string的结构体, 不拷贝buffer.关键是第14行, 对原始变量person.name的赋值, 也只是把\"Mike\"这个string的结构体赋值给person.name, 并不是把\"Mike\"拷贝到person.name的buffer里. person.name的底层指针, 改为指向\"Mike\"iPerson的name结构体没有变化, 还是指向原\"John\" interface的内部表达 golang中的interface, 有两种表达 iface是有方法的 eface没有方法, 纯空接口 它们都有指向底层数据的指针. type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 参考: https://blog.gopheracademy.com/advent-2018/interfaces-and-reflect/ reflect Type和interface reflect method reflect Value timer 标准库time提供了go语言对时间和定时器的使用接口 timer API 单次timer Timer对象持有channel C. timer超时后, 会发送当前时间到channel C. func NewTimer(d Duration) *Timer 返回一个Timer对象 典型的应用场景是, 从一个管道读数据, 不想永远等下去, 而是设个超时时间. func WaitChannel(conn 周期性timer go里面叫Ticker, 和Timer类似, 但Ticker周期性的往channel发送数据 func NewTicker(d Duration) *Ticker 使用Ticker需要注意的是, 不用的Ticker要调用Stop方法来终止, 否则系统一直会执行这个Ticker. package main import ( \"fmt\" \"time\" ) func main() { ticker := time.NewTicker(time.Second) //不用时stop Ticker defer ticker.Stop() done := make(chan bool) go func() { time.Sleep(10 * time.Second) done timer实现原理 timer的底层实现在runtime里. 在系统监控的循环中，我们通过 runtime.nanotime 和 runtime.timeSleepUntil 获取当前时间和计时器下一次需要唤醒的时间. 其中runtime.timeSleepUntil()函数遍历所有的timer bucket, 返回最小的. func timeSleepUntil() int64 { next := int64(1 timers是个数组, 元素是{timersBucket堆, 和cacheline对齐的pad} const timersLen = 64 // timers contains \"per-P\" timer heaps. // // Timers are queued into timersBucket associated with the current P, // so each P may work with its own timers independently of other P instances. // // Each timersBucket may be associated with multiple P // if GOMAXPROCS > timersLen. var timers [timersLen]struct { timersBucket // The padding should eliminate false sharing // between timersBucket values. pad [cpu.CacheLinePadSize - unsafe.Sizeof(timersBucket{})%cpu.CacheLinePadSize]byte } go1.13里面, 这个数组的大小是64, 是固定的. 按理说应该是per CPU的, 但为了避免动态分配内存, 考虑到主流的CPU核数, 这里就固定了64. 注: 用unsafe.Sizeof可以得到结构体大小 timersBucket是个堆结构, 因为timer的操作都会涉及到排序, 堆的排序和查找性能都不错. type timersBucket struct { lock mutex //goroutine的指针 gp *g created bool sleeping bool rescheduling bool //因为所有timer都是排序的, 这是最小的sleep时间 sleepUntil int64 waitnote note //timer桶下面的所有timer t []*timer } timer结构体, 在timer到时后在timer桶的timerproc协程里执行f type timer struct { tb *timersBucket // the bucket the timer lives in i int // heap index // Timer wakes up at when, and then at when+period, ... (period > 0 only) // each time calling f(arg, now) in the timer goroutine, so f must be // a well-behaved function and not block. when int64 period int64 f func(interface{}, uintptr) arg interface{} seq uintptr } add timer 每个timer的桶都有一个goroutine; 如果add timer的时候, 排好序后该timer是桶里的第一个timer, 会唤醒阻塞的gotoutine; 如果是第一次建立timer桶, 会起goroutine timerproc来执行timer桶里的事件, 因为桶里的timer都是按时间排好序的, 一个goroutine就够了. func addtimer(t *timer) { tb := t.assignBucket() lock(&tb.lock) ok := tb.addtimerLocked(t) unlock(&tb.lock) if !ok { badTimer() } } timer桶的分配 func (t *timer) assignBucket() *timersBucket { //当前g的m的p的id号, 翻译过来就是CPU号 id := uint8(getg().m.p.ptr().id) % timersLen t.tb = &timers[id].timersBucket return t.tb } 真正实现addtimer的函数 func (tb *timersBucket) addtimerLocked(t *timer) bool { // when must never be negative; otherwise timerproc will overflow // during its delta calculation and never expire other runtime timers. if t.when t.when { tb.sleeping = false //这个waitnote是个uintptr, 底层是futex或者是semaphore //每个timer桶一个 notewakeup(&tb.waitnote) } if tb.rescheduling { tb.rescheduling = false goready(tb.gp, 0) } if !tb.created { tb.created = true //起个goroutine, go timerproc(tb) } } return true } 触发timer 按前面所述, add timer时会给每个timer 桶起一个\"守护\"协程timerproc, timer的触发就在这个协程中. 它负责检查桶内的timer, 执行超时后的回调函数, 然后休眠到下个timer到期. //每个timer桶都有一个这个goroutine, 用于到时后执行timer的回调; //大部分回调是time.sendTime()往channel写. func timerproc(tb *timersBucket) { tb.gp = getg() for { lock(&tb.lock) tb.sleeping = false now := nanotime() delta := int64(-1) for { if len(tb.t) == 0 { delta = -1 break } //第一个元素是超时时间最短的 t := tb.t[0] delta = t.when - now //超时时间没到 if delta > 0 { break } //时间到了 ok := true //是周期的timer if t.period > 0 { // leave in heap but adjust next time to fire //这里delta只能是0或负数, delta的偏差越大, 说明系统繁忙来不及响应? 越增大下次的超时时间 t.when += t.period * (1 + -delta/t.period) //重新加入堆排序 if !siftdownTimer(tb.t, 0) { ok = false } } else { //是一次性的timer // remove from heap last := len(tb.t) - 1 if last > 0 { tb.t[0] = tb.t[last] tb.t[0].i = 0 } tb.t[last] = nil tb.t = tb.t[:last] if last > 0 { if !siftdownTimer(tb.t, 0) { ok = false } } t.i = -1 // mark as removed } //f是这个timer的回调 f := t.f arg := t.arg seq := t.seq unlock(&tb.lock) if !ok { badTimer() } if raceenabled { raceacquire(unsafe.Pointer(t)) } //调用这个timer的回调函数, 这个函数必须不能阻塞, 因为这里持有timer桶的锁. //time.NewTimer方法, 传入的是sleep.go里的私有函数sendTime f(arg, seq) lock(&tb.lock) } if delta 0 { // No timers left - put goroutine to sleep. tb.rescheduling = true goparkunlock(&tb.lock, waitReasonTimerGoroutineIdle, traceEvGoBlock, 1) continue } // At least one timer pending. Sleep until then. tb.sleeping = true tb.sleepUntil = now + delta noteclear(&tb.waitnote) unlock(&tb.lock) //这个for循环把那个不是忙等, 而是根据delta时间来sleep. notetsleepg(&tb.waitnote, delta) //底层是futexsleep, 是带超时时间的futex系统调用 //每个timer桶都有个waitnote, 这个应该是futex锁 futexsleep(key32(&n.key), 0, ns) } } time.NewTimer()注册了sendTime()回调 time包的NewTimer()方法, 底层调用的是startTimer(), 向runtime添加timer func NewTimer(d Duration) *Timer { c := make(chan Time, 1) // 创建一个管道 t := &Timer{ // 构造Timer数据结构 C: c, // 新创建的管道 r: runtimeTimer{ when: when(d), // 触发时间 f: sendTime, // 触发后执行函数sendTime arg: c, // 触发后执行函数sendTime时附带的参数 }, } startTimer(&t.r) // 此处启动定时器，只是把runtimeTimer放到系统协程的堆中，由系统协程维护 return t } sendTime()只是向channel发送当前时间 //sleep.go func sendTime(c interface{}, seq uintptr) { // Non-blocking send of time on c. // Used in NewTimer, it cannot block anyway (buffer). // Used in NewTicker, dropping sends on the floor is // the desired behavior when the reader gets behind, // because the sends are periodic. select { //有default是非阻塞发送 case c.(chan Time) timer堆的维护 timer桶里面的所有timer, golang使用了4叉数的顺序存储结构([]*timer切片)来管理. 每次新增 删除 修改timer或者是timer到期, 都会对timer堆重新排序. 上图展示的是二叉堆，实际上Go实现时使用的是四叉堆，使用四叉堆的好处是堆的高度降低，堆调整时更快。 具体算法见: time.go siftupTimer()和siftdownTimer()函数 time包的NewTimer方法调用了runtime.startTimer 在src/time/sleep.go里面, 创建Timer实例的API NewTimer(), 调用了内部函数startTimer() // NewTimer creates a new Timer that will send // the current time on its channel after at least duration d. func NewTimer(d Duration) *Timer { c := make(chan Time, 1) t := &Timer{ C: c, r: runtimeTimer{ when: when(d), f: sendTime, arg: c, }, } startTimer(&t.r) return t } //而startTimer函数竟然在这个文件是个空函数 func startTimer(*runtimeTimer) 但在src/runtime/time.go里面, 有这样的声明: // startTimer adds t to the timer heap. //go:linkname startTimer time.startTimer func startTimer(t *timer) { if raceenabled { racerelease(unsafe.Pointer(t)) } addtimer(t) } 注意同名函数startTimer上面的注释, 似乎是某种链接黑科技: 把本地函数即runtime.startTimer函数, 当作time.startTimer来对待. go:linkname是给编译器看的指示. 详见官方说明 //go:linkname localname [importpath.name] The //go:linkname directive instructs the compiler to use “importpath.name” as the object file symbol name for the variable or function declared as “localname” in the source code. 性能测试和结果 在性能测试程序中, 我们起了N个go routine, 每个go routine起一个周期为1秒的timer, 即有N个timer同时周期性运行. timer超时后的动作非常简单(i++), 所以此测试几乎完全是测试golang timer机制的效率. MIPS板子为4核的CFNT-B golang的版本是1.13 测试程序使用taskset强制跑在单核上. 测试结果 Timer Number Sequential delay time Single core CPU load(MIPS) Single core CPU load(X86) 2000 0 ms 0 ~ 2.6% 0 ~ 0.7% 2000 20 ms 0 ~ 9.9% @ stable ~7.3% 0 ~ 5.9% @ stable ~4.6% 2000 Random in 30 ms Similar as 20 ms Similar as 20 ms 512 20 ms 0 ~ 2.6% @ stable ~2.0% 0 ~ 2.0% @ stable ~1.3% 20000 20 ms 0 ~ 50% @ stable ~43.7% 0 ~ 13.2% @ stable ~12.5% 结论 golang里每个CPU一个timer桶 桶内使用4叉树排序 每个桶有个单独的timer守护routine, 负责睡眠到下次timer到期, 执行timer的回调 timer的回调是time包注册的函数, 负责写channel, 对外不可见. go1.14对timer的优化 go1.13的timer问题 如上面所述, 每个P都有一个timer堆, 每个堆都有一个timerproc goroutine, 在这个routine中, 调用futexsleep是要休眠的; 注意这里的休眠是系统线程M直接休眠了, 这就要求M要和P解绑定, 意味着一次线程级别的上下文切换的开销: G5里面等待timerG5: , 系统把G5放在channel的reveive队列里, 超时时间到期时系统的timer机制会发送数据到这个channel来唤醒G5, 大致可以理解为G5在本地P的timer堆里休眠; 现在假设timer到期, timerproc(TP)被排到下一个被运行的goroutine TP开始执行, 但TP要求M休眠, 即TP\"带走\"了M, 和P分离 独立的P会触发wakep, 新建或寻找新的M并与之绑定; 接下来比如是从别的P里偷取G来运行 timer到期后, M被kernel唤醒, 会acquirep, 这里可能是抢占了当前的M TP里面通过channel唤醒G5, G5被放到本地P队列; 当然这次可能有多个timer同时超时, 它们对应的G都被放到运行队列 TP完成对timer的唤醒, 调用futex继续睡眠, 导致下一轮的M和P的分离. 综上, 1.13的问题在于: timperproc使用了阻塞的方式睡眠等待timer堆到期, 导致其所在的线程阻塞, 导致线程级别的上下文切换. 1.14解决思路 1.14中, 不使用timerproc来触发timer到期, 而是复用调度器的调度时机来检查timer是否超时. 调度器是没有单独goroutine的, 这样复用了以后, timer桶的检查点也没有单独的goroutine了. 少个gotouine不算什么, 关键是少了阻塞式的系统调用, 避免了timerporc里面的M因为要阻塞而与P分离操作. 系统监控 统监控是 Go 语言运行时的重要组成部分，它会每隔一段时间检查 Go 语言运行时，确保程序没有进入异常状态。 Go 语言的系统监控也起到了很重要的作用，它在内部启动了一个不会中止的循环，在循环的内部会轮询网络、抢占长期运行或者处于系统调用的 Goroutine 以及触发垃圾回收，通过这些行为，它能够让系统的运行状态变得更健康。 运行时通过系统监控来触发线程的抢占、网络的轮询和垃圾回收，保证 Go 语言运行时的可用性。系统监控能够很好地解决尾延迟的问题，减少调度器调度 Goroutine 的饥饿问题并保证计时器在尽可能准确的时间触发。 sysmon在独立的M(系统线程)中运行 监控循环 当 Go 语言程序启动时，运行时会在第一个 Goroutine 中调用 runtime.main 启动主程序，该函数会在系统栈中创建新的线程： func main() { ... if GOARCH != \"wasm\" { systemstack(func() { newm(sysmon, nil) }) } ... } runtime.newm 会创建一个存储待执行函数和处理器的新结构体 runtime.m。运行时执行系统监控不需要处理器，系统监控的 Goroutine 会直接在创建的线程上运行： func newm(fn func(), _p_ *p) { mp := allocm(_p_, fn) mp.nextp.set(_p_) mp.sigmask = initSigmask ... newm1(mp) } runtime.newm1 会调用特定平台的 runtime.newsproc 通过系统调用 clone 创建一个新的线程并在新的线程中执行 runtime.mstart： func newosproc(mp *m) { stk := unsafe.Pointer(mp.g0.stack.hi) var oset sigset sigprocmask(_SIG_SETMASK, &sigset_all, &oset) ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart))) sigprocmask(_SIG_SETMASK, &oset, nil) ... } 在新创建的线程中，我们会执行存储在 runtime.m 结构体中的 runtime.sysmon 函数启动系统监控： func sysmon() { sched.nmsys++ checkdead() lasttrace := int64(0) idle := 0 delay := uint32(0) for { if idle == 0 { delay = 20 } else if idle > 50 { delay *= 2 } if delay > 10*1000 { delay = 10 * 1000 } usleep(delay) ... } } 当运行时刚刚调用上述函数时，会先通过 runtime.checkdead 检查是否存在死锁，然后进入核心的监控循环；系统监控在每次循环开始时都会通过 usleep 挂起当前线程，该函数的参数是微秒，运行时会遵循以下的规则决定休眠时间： 初始的休眠时间是 20μs； 最长的休眠时间是 10ms； 当系统监控在 50 个循环中都没有唤醒 Goroutine 时，休眠时间在每个循环都会倍增； 当程序趋于稳定之后，系统监控的触发时间就会稳定在 10ms。它除了会检查死锁之外，还会在循环中完成以下的工作： 运行计时器 — 获取下一个需要被触发的计时器； 轮询网络 — 获取需要处理的到期文件描述符; 非阻塞地调用 runtime.netpoll 检查待执行的文件描述符并通过 runtime.injectglist 将所有处于就绪状态的 Goroutine 加入全局运行队列中 抢占处理器 — 抢占运行时间较长的或者处于系统调用的 Goroutine； 垃圾回收 — 在满足条件时触发垃圾收集回收内存； 检查timer 在系统监控的循环中，我们通过 runtime.nanotime 和 runtime.timeSleepUntil 获取当前时间和计时器下一次需要唤醒的时间. 在runtime/proc.go func sysmon() { for { //这个delay大概是10ms usleep(delay) //处理timer的优先级比较低, 比如只有在idle的时候才检查 if 各种条件 next := timeSleepUntil() now := nanotime() //没到超时时间, 需要Relax一下 osRelax(true) } } 检查死锁 计算系统中正在运行的线程个数, 如果为0, 则可能发生了死锁.进一步需要判断如果goroutine有可运行状态的, 则证明发生了死锁. 轮询网络 如果上一次轮询网络已经过去了 10ms，那么系统监控还会在循环中轮询网络，检查是否有待执行的文件描述符： func sysmon() { ... for { ... lastpoll := int64(atomic.Load64(&sched.lastpoll)) if netpollinited() && lastpoll != 0 && lastpoll+10*1000*1000 调用netpoll(0)非阻塞地检查待执行的文件描述符并通过 runtime.injectglist 将所有处于就绪状态的 Goroutine 加入全局运行队列中;该函数会将所有 Goroutine 的状态从 _Gwaiting 切换至 _Grunnable 并加入全局运行队列等待运行，如果当前程序中存在空闲的处理器，就会通过 runtime.startm 函数启动线程来执行这些任务。 抢占处理器 系统监控通过在循环中抢占处理器来避免同一个 Goroutine 占用线程太长时间造成饥饿问题。 垃圾回收 在最后，系统监控还会决定是否需要触发强制垃圾回收，runtime.sysmon 会构建 runtime.gcTrigger 结构体并调用 runtime.gcTrigger.test 函数判断是否需要触发垃圾回收： func sysmon() { ... for { ... if t := (gcTrigger{kind: gcTriggerTime, now: now}); t.test() && atomic.Load(&forcegc.idle) != 0 { lock(&forcegc.lock) forcegc.idle = 0 var list gList list.push(forcegc.g) injectglist(&list) unlock(&forcegc.lock) } ... } } 如果需要触发垃圾回收，我们会将用于垃圾回收的 Goroutine 加入全局队列，让调度器选择合适的处理器去执行。 参考: https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sysmon/ IO多路复用 golang中的go routine在发生IO调用时(read/write), 不是直接阻塞, 而是使用IO多路复用. goroutine调用read/write时, runtime会把fd加到epoll里等待ready, 同时调用runtime.gopark让出当前线程. Go 语言的运行时会在调度或者系统监控中调用 runtime.netpoll 轮询网络. 网络轮询器并不是由运行时中的某一个线程独立运行的，运行时中的调度和系统调用会通过 runtime.netpoll 与网络轮询器交换消息，获取待执行的 Goroutine 列表，并将待执行的 Goroutine 加入运行队列等待处理。 所有的文件 I/O、网络 I/O 和计时器都是由网络轮询器管理的，它是 Go 语言运行时重要的组成部分。 golang使用多路IO复用, 但没用select, 而是用的效率更高的epoll(在linux平台上), 见src/runtime/netpoll_epoll.go 不同平台使用的系统调用不同 参考: https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-netpoller/ golang对epoll的封装 golang要同时支持epoll, kqueue, windows上的接口, 它们都使用一组接口 //— 初始化网络轮询器，通过 sync.Once 和 netpollInited 变量保证函数只会调用一次； func netpollinit() //监听文件描述符上的边缘触发事件，创建事件并加入监听； func netpollopen(fd uintptr, pd *pollDesc) int32 //轮询网络并返回一组已经准备就绪的 Goroutine，传入的参数会决定它的行为； func netpoll(delta int64) gList //唤醒网络轮询器，例如：计时器向前修改时间时会通过该函数中断网络轮询器； func netpollBreak() // 判断文件描述符是否被轮询器使用； func netpollIsPollDescriptor(fd uintptr) bool 数据结构 type pollDesc struct { //描述符链表 link *pollDesc lock mutex fd uintptr ... rseq uintptr rg uintptr rt timer rd int64 wseq uintptr wg uintptr wt timer wd int64 } 初始化 因为文件 I/O、网络 I/O 以及计时器都依赖网络轮询器，所以 Go 语言会通过以下两条不同路径初始化网络轮询器： internal/poll.pollDesc.init — 通过 net.netFD.init 和 os.newFile 初始化网络 I/O 和文件 I/O 的轮询信息时； runtime.doaddtimer — 向处理器中增加新的计时器时； runtime.netpollinit()做了下面的几个事 调用 epollcreate1 创建一个新的 epoll 文件描述符，这个文件描述符会在整个程序的生命周期中使用； 通过 runtime.nonblockingPipe 创建一个用于通信的管道； 使用 epollctl 将用于读取数据的文件描述符打包成 epollevent 事件加入监听； goroutine等待事件 当我们在文件描述符上执行读写操作时，如果文件描述符不可读或者不可写，当前 Goroutine 就会执行 runtime.poll_runtime_pollWait 检查 runtime.pollDesc 的状态并调用 runtime.netpollblock 等待文件描述符的可读或者可写： func poll_runtime_pollWait(pd *pollDesc, mode int) int { ... for !netpollblock(pd, int32(mode), false) { ... } return 0 } //runtime.netpollblock 是 Goroutine 等待 I/O 事件的关键函数， //它会使用运行时提供的 runtime.gopark 让出当前线程，将 Goroutine 转换到休眠状态并等待运行时的唤醒。 func netpollblock(pd *pollDesc, mode int32, waitio bool) bool { gpp := &pd.rg if mode == 'w' { gpp = &pd.wg } ... if waitio || netpollcheckerr(pd, mode) == 0 { gopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5) } ... } 调用epoll 网络轮询器并不是由运行时中的某一个线程独立运行的，运行时中的调度和系统调用会通过 runtime.netpoll 与网络轮询器交换消息，获取待执行的 Goroutine 列表，并将待执行的 Goroutine 加入运行队列等待处理。 Go 语言的运行时会在调度或者系统监控中调用func netpoll(delay int64) gList轮询网络，该函数的执行过程可以分成以下几个部分： 根据传入的 delay 计算 epoll 系统调用需要等待的时间； 调用系统调用epollwait 等待可读或者可写事件的发生； 在循环中依次处理 epollevent 事件； 返回可读写的的goroutine列表, runtime会将列表中的全部 Goroutine 加入运行队列并等待调度器的调度 截至日期 网络轮询器和计时器的关系非常紧密，这不仅仅是因为网络轮询器负责计时器的唤醒，还因为文件和网络 I/O 的截止日期也由网络轮询器负责处理。截止日期在 I/O 操作中，尤其是网络调用中很关键，网络请求存在很高的不确定因素，我们需要设置一个截止日期保证程序的正常运行，这时就需要用到网络轮询器中的 runtime.poll_runtime_pollSetDeadline 函数 如果截至日期到了, 直接唤醒goroutine;Goroutine 在被唤醒之后就会意识到当前的 I/O 操作已经超时，可以根据需要选择重试请求或者中止调用。 GC 垃圾收集器 https://blog.golang.org/ismmkeynote go runtime调度器 相关的结构体表示 The G Struct : This represents a single go routine with it’s properties such as stack pointer, base of stack, it’s ID, it’s cache and it’s status The M Struct : This represents an OS thread. It also contains a pointer to the global queue of runnable goroutines, the current running goroutine and the reference to the scheduler The Sched Struct : It is a global struct and contains the queues free and waiting goroutines as well as threads. go比较快的5点 参考: https://dave.cheney.net/2014/06/07/five-things-that-make-go-fast go变量占的空间更小, 比如一个int, 和c一样, 占4个字节; 而python等动态语言要占24个字节 -- 他们把int当作一个object go编译器会做自动inline和死代码消除 C有stack变量, 也有malloc到堆上的变量; 而go有escape分析, 用来分析一个变量是否有函数外的引用, 没有的话, 分配在栈里; 此时就不需要GC 有的话, 分配在堆里, 需要GC.上面的代码, c分配在栈里, 因为它没有逃离CenterCursor()函数. goroutine, 更加轻量级的协作每个系统调用都会走这里, entersyscall通知runtime这个线程要阻塞了, runtime就把其他goroutine调度到新线程里去执行. 所以go程序会起几个系统线程, 然后go runtime来管理. goroutine的栈管理 普通进程的栈向下生长, 堆向上生长, 中间用guard page来隔离, guard page是只读的, 在之前调试时遇到过. 如果一个进程有多个线程, 那就有多个栈, 需要多个guard pagegoroutine不用guard page, 栈不够时自动分配go1.2的时候, 如果栈不够, 调用新的函数时, 会给新函数在堆里分配一个栈, 该函数返回就销毁这个栈. go1.3改了方法, 栈不够时, 分配一个新栈, 大小为2倍. 把之前所有的栈拷贝过来运行, 从此都用这个更大的新栈. 空间换时间. "},"notes/golang_interface原理.html":{"url":"notes/golang_interface原理.html","title":"interface原理(网摘)","keywords":"","body":"Go Data Structures: Interfaces Posted on Tuesday, December 1, 2009. Go's interfaces—static, checked at compile time, dynamic when asked for—are, for me, the most exciting part of Go from a language design point of view. If I could export one feature of Go into other languages, it would be interfaces. This post is my take on the implementation of interface values in the “gc” compilers: 6g, 8g, and 5g. Over at Airs, Ian Lance Taylor has written two posts about the implementation of interface values in gccgo. The implementations are more alike than different: the biggest difference is that this post has pictures. Before looking at the implementation, let's get a sense of what it must support. Usage Go's interfaces let you use duck typing like you would in a purely dynamic language like Python but still have the compiler catch obvious mistakes like passing an int where an object with a Read method was expected, or like calling the Read method with the wrong number of arguments. To use interfaces, first define the interface type (say, ReadCloser): type ReadCloser interface { Read(b []byte) (n int, err os.Error) Close() } and then define your new function as taking a ReadCloser. For example, this function calls Read repeatedly to get all the data that was requested and then calls Close: func ReadAndClose(r ReadCloser, buf []byte) (n int, err os.Error) { for len(buf) > 0 && err == nil { var nr int nr, err = r.Read(buf) n += nr buf = buf[nr:] } r.Close() return } The code that calls ReadAndClose can pass a value of any type as long as it has Read and Close methods with the right signatures. And, unlike in languages like Python, if you pass a value with the wrong type, you get an error at compile time, not run time. Interfaces aren't restricted to static checking, though. You can check dynamically whether a particular interface value has an additional method. For example: type Stringer interface { String() string } func ToString(any interface{}) string { if v, ok := any.(Stringer); ok { return v.String() } switch v := any.(type) { case int: return strconv.Itoa(v) case float: return strconv.Ftoa(v, 'g', -1) } return \"???\" } The value any has static type interface{}, meaning no guarantee of any methods at all: it could contain any type. The “comma ok” assignment inside the if statement asks whether it is possible to convert any to an interface value of type Stringer, which has the method String. If so, the body of that statement calls the method to obtain a string to return. Otherwise, the switch picks off a few basic types before giving up. This is basically a stripped down version of what the fmt package does. (The if could be replaced by adding case Stringer: at the top of the switch, but I used a separate statement to draw attention to the check.) As a simple example, let's consider a 64-bit integer type with a String method that prints the value in binary and a trivial Get method: type Binary uint64 func (i Binary) String() string { return strconv.Uitob64(i.Get(), 2) } func (i Binary) Get() uint64 { return uint64(i) } A value of type Binary can be passed to ToString, which will format it using the String method, even though the program never says that Binary intends to implement Stringer. There's no need: the runtime can see that Binary has a String method, so it implements Stringer, even if the author of Binary has never heard of Stringer. These examples show that even though all the implicit conversions are checked at compile time, explicit interface-to-interface conversions can inquire about method sets at run time. “Effective Go” has more details about and examples of how interface values can be used. Interface Values Languages with methods typically fall into one of two camps: prepare tables for all the method calls statically (as in C++ and Java), or do a method lookup at each call (as in Smalltalk and its many imitators, JavaScript and Python included) and add fancy caching to make that call efficient. Go sits halfway between the two: it has method tables but computes them at run time. I don't know whether Go is the first language to use this technique, but it's certainly not a common one. (I'd be interested to hear about earlier examples; leave a comment below.) As a warmup, a value of type Binary is just a 64-bit integer made up of two 32-bit words (like in the last post, we'll assume a 32-bit machine; this time memory grows down instead of to the right): Interface values are represented as a two-word pair giving a pointer to information about the type stored in the interface and a pointer to the associated data. Assigning b to an interface value of type Stringer sets both words of the interface value. (The pointers contained in the interface value are gray to emphasize that they are implicit, not directly exposed to Go programs.) The first word in the interface value points at what I call an interface table or itable (pronounced i-table; in the runtime sources, the C implementation name is Itab). The itable begins with some metadata about the types involved and then becomes a list of function pointers. Note that the itable corresponds to the interface type, not the dynamic type. In terms of our example, the itable for Stringer holding type Binary lists the methods used to satisfy Stringer, which is just String: Binary's other methods (Get) make no appearance in the itable. The second word in the interface value points at the actual data, in this case a copy of b. The assignment var s Stringer = b makes a copy of b rather than point at b for the same reason that var c uint64 = b makes a copy: if b later changes, s and c are supposed to have the original value, not the new one. Values stored in interfaces might be arbitrarily large, but only one word is dedicated to holding the value in the interface structure, so the assignment allocates a chunk of memory on the heap and records the pointer in the one-word slot. (There's an obvious optimization when the value does fit in the slot; we'll get to that later.) To check whether an interface value holds a particular type, as in the type switch above, the Go compiler generates code equivalent to the C expression s.tab->type to obtain the type pointer and check it against the desired type. If the types match, the value can be copied by by dereferencing s.data. To call s.String(), the Go compiler generates code that does the equivalent of the C expression s.tab->fun[0](s.data): it calls the appropriate function pointer from the itable, passing the interface value's data word as the function's first (in this example, only) argument. You can see this code if you run 8g -S x.go (details at the bottom of this post). Note that the function in the itable is being passed the 32-bit pointer from the second word of the interface value, not the 64-bit value it points at. In general, the interface call site doesn't know the meaning of this word nor how much data it points at. Instead, the interface code arranges that the function pointers in the itable expect the 32-bit representation stored in the interface values. Thus the function pointer in this example is (*Binary).String not Binary.String. The example we're considering is an interface with just one method. An interface with more methods would have more entries in the fun list at the bottom of the itable. Computing the Itable Now we know what the itables look like, but where do they come from? Go's dynamic type conversions mean that it isn't reasonable for the compiler or linker to precompute all possible itables: there are too many (interface type, concrete type) pairs, and most won't be needed. Instead, the compiler generates a type description structure for each concrete type like Binary or int or func(map[int]string). Among other metadata, the type description structure contains a list of the methods implemented by that type. Similarly, the compiler generates a (different) type description structure for each interface type like Stringer; it too contains a method list. The interface runtime computes the itable by looking for each method listed in the interface type's method table in the concrete type's method table. The runtime caches the itable after generating it, so that this correspondence need only be computed once. In our simple example, the method table for Stringer has one method, while the table for Binary has two methods. In general there might be ni methods for the interface type and nt methods for the concrete type. The obvious search to find the mapping from interface methods to concrete methods would take O(ni × nt) time, but we can do better. By sorting the two method tables and walking them simultaneously, we can build the mapping in O(ni + nt) time instead. Memory Optimizations The space used by the implementation described above can be optimized in two complementary ways. First, if the interface type involved is empty—it has no methods—then the itable serves no purpose except to hold the pointer to the original type. In this case, the itable can be dropped and the value can point at the type directly: Whether an interface type has methods is a static property—either the type in the source code says interface{} or it says interace{ methods... }—so the compiler knows which representation is in use at each point in the program. Second, if the value associated with the interface value can fit in a single machine word, there's no need to introduce the indirection or the heap allocation. If we define Binary32 to be like Binary but implemented as a uint32, it could be stored in an interface value by keeping the actual value in the second word: Whether the actual value is being pointed at or inlined depends on the size of the type. The compiler arranges for the functions listed in the type's method table (which get copied into the itables) to do the right thing with the word that gets passed in. If the receiver type fits in a word, it is used directly; if not, it is dereferenced. The diagrams show this: in the Binary version far above, the method in the itable is (*Binary).String, while in the Binary32 example, the method in the itable is Binary32.String not (*Binary32).String. Of course, empty interfaces holding word-sized (or smaller) values can take advantage of both optimizations: Method Lookup Performance Smalltalk and the many dynamic systems that have followed it perform a method lookup every time a method gets called. For speed, many implementations use a simple one-entry cache at each call site, often in the instruction stream itself. In a multithreaded program, these caches must be managed carefully, since multiple threads could be at the same call site simultaneously. Even once the races have been avoided, the caches would end up being a source of memory contention. Because Go has the hint of static typing to go along with the dynamic method lookups, it can move the lookups back from the call sites to the point when the value is stored in the interface. For example, consider this code snippet: var any interface{} // initialized elsewhere s := any.(Stringer) // dynamic conversion for i := 0; i In Go, the itable gets computed (or found in a cache) during the assignment on line 2; the dispatch for the s.String() call executed on line 4 is a couple of memory fetches and a single indirect call instruction. In contrast, the implementation of this program in a dynamic language like Smalltalk (or JavaScript, or Python, or ...) would do the method lookup at line 4, which in a loop repeats needless work. The cache mentioned earlier makes this less expensive than it might be, but it's still more expensive than a single indirect call instruction. Of course, this being a blog post, I don't have any numbers to back up this discussion, but it certainly seems like the lack of memory contention would be a big win in a heavily parallel program, as is being able to move the method lookup out of tight loops. Also, I'm talking about the general architecture, not the specifics o the implementation: the latter probably has a few constant factor optimizations still available. More Information The interface runtime support is in [$GOROOT/src/pkg/runtime/iface.c](http://code.google.com/p/go/source/browse/src/pkg/runtime/iface.c). There's much more to say about interfaces (we haven't even seen an example of a pointer receiver yet) and the type descriptors (they power reflection in addition to the interface runtime) but those will have to wait for future posts. Code Supporting code (x.go): package main import ( \"fmt\" \"strconv\" ) type Stringer interface { String() string } type Binary uint64 func (i Binary) String() string { return strconv.Uitob64(i.Get(), 2) } func (i Binary) Get() uint64 { return uint64(i) } func main() { b := Binary(200) s := Stringer(b) fmt.Println(s.String()) } Selected output of 8g -S x.go: 0045 (x.go:25) LEAL s+-24(SP),BX 0046 (x.go:25) MOVL 4(BX),BP 0047 (x.go:25) MOVL BP,(SP) 0048 (x.go:25) MOVL (BX),BX 0049 (x.go:25) MOVL 20(BX),BX 0050 (x.go:25) CALL ,BX The LEAL loads the address of s into the register BX. (The notation _n_(SP) describes the word in memory at SP+_n_. 0(SP) can be shortened to (SP).) The next two MOVL instructions fetch the value from the second word in the interface and store it as the first function call argument, 0(SP). The final two MOVL instructions fetch the itable and then the function pointer from the itable, in preparation for calling that function. "},"notes/golang_内存分配.html":{"url":"notes/golang_内存分配.html","title":"内存分配(网摘)","keywords":"","body":" Go: Memory Management and Allocation Allocation on the heap Small allocation Large allocation Big picture Inspiration go先从本M的buddy系统里分配内存, 再从全局的buddy里面分对于大于32k的大内存, 直接跟os要. 原文链接: https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44 Go: Memory Management and Allocation ℹ️ This article is based on Go 1.13. Go memory management is automatically done by the standard library from the allocation of the memory to its collection when it is not used anymore. Although the developer does not have to deal with it, the underlying management done by Go is well optimized and full of interesting concepts. Allocation on the heap The memory management is designed to be fast in a concurrent environment and integrated with the garbage collector. Let’s start with a simple example: package main type smallStruct **struct** { a, b int64 c, d float64 } func main() { smallAllocation() } //go:noinline func smallAllocation() *smallStruct { return &smallStruct{} } The annotation //go:noinline will disable in-lining that would optimize the code by removing the function and, therefore, end up with no allocation. Running the escape analysis command with go tool compile \"-m\" main.go will confirm the allocation made by Go: Dumping the assembly code for this program, thanks to go tool compile -S main.go, would also explicitly show us the allocation: 0x001d 00029 (main.go:14) LEAQ type.\"\".smallStruct(SB), AX 0x0024 00036 (main.go:14) PCDATA $0, $0 0x0024 00036 (main.go:14) MOVQ AX, (SP) 0x0028 00040 (main.go:14) CALL runtime.newobject(SB) The function newobject is the built-in function for new allocations and proxy mallocgc, a function that manages them on the heap. There are two strategies in Go, one for the small allocations and one for larger ones. Small allocation For the small allocations, under 32kb, Go will try to get the memory from a local cache called mcache. This cache handles a list of span (memory chunk of 32kb), called mspan, that contains the memory available for allocation: Each thread M is assigned to a processor P and handles at most one goroutine at a time. While allocating memory, our current goroutine will use the local cache of its current P to find the first free object available in the span list. Using this local cache does not require lock and makes the allocation more efficient. The span list is divided into ~70 size classes, from 8 bytes to 32k bytes, that can store different object sizes: Each span exists twice: one list for objects that do not contain pointer and another one that contains pointer. This distinction will make the life of the garbage collector easier since it will not have to scan the spans that do not contain any pointer. In our previous example, the size of the structure is 32 bytes and will fit in the 32 bytes span: Now, we may wonder what would happen if the span does not have a free slot during the allocation. Go maintains central lists of spans per size classes, called mcentral, with the spans that contain free objects and the ones that do not: mcentral maintains a double linked list of spans; each of them has a reference to the previous span and next span. A span in the non-empty list — “non-empty” means that at least one slot is free in the list for allocation — could contain some memory in-use already. Indeed, when the garbage collector sweeps the memory, it could clean a part of the span — the part marked as not used anymore — and would put it back in the non-empty list. Our program can now request a span from the central list if it runs out of slots: Go needs a way to get new spans to the central list if none are available in the empty list. New spans will now be allocated from the heap and linked to the central list: The heap pulls the memory from the OS when needed. If it needs more memory, the heap will allocate a large chunk of memory, called arena, of 64Mb for the 64bits architectures and 4Mb for most of the other architectures. The arena also maps the memory page with the spans: Large allocation Go does not manage the large allocations with a local cache. Those allocations, greater than 32kb, are rounded up to the page size and the pages are allocated directly to the heap. Big picture We now have a good view of what is happening at a high level during the memory allocation. Let’s draw all the components together to get the full picture: Inspiration The memory allocator is originally based on TCMalloc, a memory allocator optimized for the concurrent environment created by Google. The documentation of TCMalloc is worth reading; you will also find the concepts explained previously. "},"notes/golang_标准库.html":{"url":"notes/golang_标准库.html","title":"标准库","keywords":"","body":" text/template Execute原型 actions arguments Pipelines Variables 举例 builtin函数 rand unsafe unsafe.Pointer类型 float64转uint64 strconv sync Cond Map Mutex RWMutex Once Pool 重点WaitGroup net ip tcp和udp IP datagrams UDP TCP 代码 TCP UDP raw socket 名字解析 api path filepath encoding 二进制 UTF8 encoding/gob api 简单例子 自定义encode和decode 传输interface对象 encoding/binary varint time Time 时间格式和单位 Duration api Ticker Timer context api 整数发生器 generator 带超时的Context syscall runtime runtime相关的环境变量 api runtime/pprof runtime/debug runtime/trace os os/exec os/signal cgo go作为so 方法 os/user builtin 函数 类型 strings bytes Buffer log/syslog log type logger logger支持多种格式, 用flag来配置 fmt 方法 Stringer类型 格式化标志符 通用 布尔值 整型 浮点 字符串 切片 指针 默认格式化 宽度 精度 对齐 举例 scanf bufio error对象 Reader的方法 Writer的方法 Scanner的方法 Scanner的方法 按行读 统计字符个数 也可以自定义分割函数 io/ioutil io 变量 以Reader为例, 看golang的派生 PipeReader, 派生类 ReadWriter WriterTo ReaderAt 其他基类 Seeker io包的方法 Copy Pipe TeeReader container/ring api 例子: 连接两个ring container/list api 使用举例 container/heap 树的数组表达 min-int树 可以用heap来实现优先级队列 sort 支持对基本类型的排序 对struct排序 通用排序 对外接口 text/template 注: gitbook对模板关键字{{ }}有特殊处理. 下文中为了规避这个问题, 在两个大括号中间都加了空格. { {.var} }: 要被替换的模板变量. \"{ {23 -} } : -用来去掉空格 \"23 传入模板的数据一般是个结构体, 或者map. Templates are executed by applying them to a data structure. Annotations in the template refer to elements of the data structure (typically a field of a struct or a key in a map) to control execution and derive values to be displayed. Execution of the template walks the structure and sets the cursor, represented by a period '.' and called \"dot\", to the value at the current location in the structure as execution proceeds. Execute原型 入参data可以是结构体, map等. 把结果写入io.Writer(这个设计很好, 结果写入接口, 代码的组合性就很强) func (t *Template) Execute(wr io.Writer, data interface{}) error actions { { } }包起来的叫action. { {/* a comment */} } { {- /* a comment with white space trimmed from preceding and following text */ -} } A comment; discarded. May contain newlines. Comments do not nest and must start and end at the delimiters, as shown here. { {pipeline} } The default textual representation (the same as would be printed by fmt.Print) of the value of the pipeline is copied to the output. { {if pipeline} } T1 { {end} } If the value of the pipeline is empty, no output is generated; otherwise, T1 is executed. The empty values are false, 0, any nil pointer or interface value, and any array, slice, map, or string of length zero. Dot is unaffected. { {if pipeline} } T1 { {else} } T0 { {end} } If the value of the pipeline is empty, T0 is executed; otherwise, T1 is executed. Dot is unaffected. { {if pipeline} } T1 { {else if pipeline} } T0 { {end} } To simplify the appearance of if-else chains, the else action of an if may include another if directly; the effect is exactly the same as writing { {if pipeline} } T1 { {else} }{ {if pipeline} } T0 { {end} }{ {end} } { {range pipeline} } T1 { {end} } The value of the pipeline must be an array, slice, map, or channel. If the value of the pipeline has length zero, nothing is output; otherwise, dot is set to the successive elements of the array, slice, or map and T1 is executed. If the value is a map and the keys are of basic type with a defined order (\"comparable\"), the elements will be visited in sorted key order. { {range pipeline} } T1 { {else} } T0 { {end} } The value of the pipeline must be an array, slice, map, or channel. If the value of the pipeline has length zero, dot is unaffected and T0 is executed; otherwise, dot is set to the successive elements of the array, slice, or map and T1 is executed. { {block \"name\" pipeline} } T1 { {end} } A block is shorthand for defining a template { {define \"name\"} } T1 { {end} } and then executing it in place { {template \"name\" pipeline} } The typical use is to define a set of root templates that are then customized by redefining the block templates within. { {with pipeline} } T1 { {end} } If the value of the pipeline is empty, no output is generated; otherwise, dot is set to the value of the pipeline and T1 is executed. { {with pipeline} } T1 { {else} } T0 { {end} } If the value of the pipeline is empty, dot is unaffected and T0 is executed; otherwise, dot is set to the value of the pipeline and T1 is executed. 特别的, 模板可以引用其他命名模板: New模板的时候会给每个模板起个名字, 用这个名字来引用它. -- 关联模板 { {template \"name\"} } The template with the specified name is executed with nil data. { {template \"name\" pipeline} } The template with the specified name is executed with dot set to the value of the pipeline. arguments action里面的概念: argument 模板支持 struct的.Field引用 map的.Key引用 对象的.Method方法引用 -- 即调用dot.Method()函数 也可以是普通函数func - A boolean, string, character, integer, floating-point, imaginary or complex constant in Go syntax. These behave like Go's untyped constants. Note that, as in Go, whether a large integer constant overflows when assigned or passed to a function can depend on whether the host machine's ints are 32 or 64 bits. - The keyword nil, representing an untyped Go nil. - The character '.' (period): . The result is the value of dot. - A variable name, which is a (possibly empty) alphanumeric string preceded by a dollar sign, such as $piOver2 or $ The result is the value of the variable. Variables are described below. - The name of a field of the data, which must be a struct, preceded by a period, such as .Field The result is the value of the field. Field invocations may be chained: .Field1.Field2 Fields can also be evaluated on variables, including chaining: $x.Field1.Field2 - The name of a key of the data, which must be a map, preceded by a period, such as .Key The result is the map element value indexed by the key. Key invocations may be chained and combined with fields to any depth: .Field1.Key1.Field2.Key2 Although the key must be an alphanumeric identifier, unlike with field names they do not need to start with an upper case letter. Keys can also be evaluated on variables, including chaining: $x.key1.key2 - The name of a niladic method of the data, preceded by a period, such as .Method The result is the value of invoking the method with dot as the receiver, dot.Method(). Such a method must have one return value (of any type) or two return values, the second of which is an error. If it has two and the returned error is non-nil, execution terminates and an error is returned to the caller as the value of Execute. Method invocations may be chained and combined with fields and keys to any depth: .Field1.Key1.Method1.Field2.Key2.Method2 Methods can also be evaluated on variables, including chaining: $x.Method1.Field - The name of a niladic function, such as fun The result is the value of invoking the function, fun(). The return types and values behave as in methods. Functions and function names are described below. - A parenthesized instance of one the above, for grouping. The result may be accessed by a field or map key invocation. print (.F1 arg1) (.F2 arg2) (.StructValuedMethod \"arg\").Field Pipelines 顾名思义, 模板支持pipe操作.即多个commands可以用|连接, 最后命令的值是pipeline的值 Argument The result is the value of evaluating the argument. .Method [Argument...] The method can be alone or the last element of a chain but, unlike methods in the middle of a chain, it can take arguments. The result is the value of calling the method with the arguments: dot.Method(Argument1, etc.) functionName [Argument...] The result is the value of calling the function associated with the name: function(Argument1, etc.) Functions and function names are described below. Variables Action里面可以声明变量: #用variable来获取pipeline的输出; 和shell里面一样, pipeline输出到变量里, 而不是展开 $variable := pipeline range $index, $element := pipeline 特别的, $的默认值为传入Execute的值. When execution begins, $ is set to the data argument passed to Execute, that is, to the starting value of dot. 举例 下面所有例子都是一行的模板, 全部生成\"output\"输出. { {\"\\\"output\\\"\"} } A string constant. { {`\"output\"`} } A raw string constant. { {printf \"%q\" \"output\"} } A function call. { {\"output\" | printf \"%q\"} } A function call whose final argument comes from the previous command. { {printf \"%q\" (print \"out\" \"put\")} } A parenthesized argument. { {\"put\" | printf \"%s%s\" \"out\" | printf \"%q\"} } A more elaborate call. { {\"output\" | printf \"%s\" | printf \"%q\"} } A longer chain. { {with \"output\"} }{ {printf \"%q\" .} }{ {end} } A with action using dot. { {with $x := \"output\" | printf \"%q\"} }{ {$x} }{ {end} } A with action that creates and uses a variable. { {with $x := \"output\"} }{ {printf \"%q\" $x} }{ {end} } A with action that uses the variable in another action. { {with $x := \"output\"} }{ {$x | printf \"%q\"} }{ {end} } The same, but pipelined. builtin函数 模板提供了一些预定义的函数: and Returns the boolean AND of its arguments by returning the first empty argument or the last argument, that is, \"and x y\" behaves as \"if x then y else x\". All the arguments are evaluated. call Returns the result of calling the first argument, which must be a function, with the remaining arguments as parameters. Thus \"call .X.Y 1 2\" is, in Go notation, dot.X.Y(1, 2) where Y is a func-valued field, map entry, or the like. The first argument must be the result of an evaluation that yields a value of function type (as distinct from a predefined function such as print). The function must return either one or two result values, the second of which is of type error. If the arguments don't match the function or the returned error value is non-nil, execution stops. html Returns the escaped HTML equivalent of the textual representation of its arguments. This function is unavailable in html/template, with a few exceptions. index Returns the result of indexing its first argument by the following arguments. Thus \"index x 1 2 3\" is, in Go syntax, x[1][2][3]. Each indexed item must be a map, slice, or array. slice slice returns the result of slicing its first argument by the remaining arguments. Thus \"slice x 1 2\" is, in Go syntax, x[1:2], while \"slice x\" is x[:], \"slice x 1\" is x[1:], and \"slice x 1 2 3\" is x[1:2:3]. The first argument must be a string, slice, or array. js Returns the escaped JavaScript equivalent of the textual representation of its arguments. len Returns the integer length of its argument. not Returns the boolean negation of its single argument. or Returns the boolean OR of its arguments by returning the first non-empty argument or the last argument, that is, \"or x y\" behaves as \"if x then x else y\". All the arguments are evaluated. print An alias for fmt.Sprint printf An alias for fmt.Sprintf println An alias for fmt.Sprintln urlquery Returns the escaped value of the textual representation of its arguments in a form suitable for embedding in a URL query. This function is unavailable in html/template, with a few exceptions. eq Returns the boolean truth of arg1 == arg2 ne Returns the boolean truth of arg1 != arg2 lt Returns the boolean truth of arg1 arg2 ge Returns the boolean truth of arg1 >= arg2 bool值是任何类型的0值. 调用函数不用加括号, 举例: { {printf \"%q\" \"output\"} } A function call. { {printf \"%q\" (print \"out\" \"put\")} } A parenthesized argument. rand import \"math/rand\" func main() { rand.Seed(time.Now().UnixNano()) min := 10 max := 30 fmt.Println(rand.Intn(max - min + 1) + min) } unsafe 如包名所指, unsafe不怎么safe, 但它提供了更底层的操作能力 比如timer的实现里, 调用了unsafe.Sizeof获取一个结构体的大小. //返回任意类型的x的字节对齐要求 func Alignof(x ArbitraryType) uintptr //返回x在结构体里的offset常量, x必须是structValue.field格式 func Offsetof(x ArbitraryType) uintptr //比如 dataOffset = unsafe.Offsetof(struct { b bmap v int64 }{}.v) //返回类型的字节数常量 func Sizeof(x ArbitraryType) uintptr unsafe.Pointer类型 unsafe.Pointer uintptr 和任意类型的指针都可以互相转换. 用了Pointer类型, 可以绕过类型系统, 直接读写任意内存. 用Pointer可以实现C的类型强转 几个例子: float64转uint64 package main import ( \"fmt\" \"unsafe\" ) func main() { var v float64 = 1.1 //类型强转 fmt.Println(uint64(v)) //通过指针强转, 结果是不一样的. fmt.Println(*(*uint64)(unsafe.Pointer(&v))) } //结果 1 4607632778762754458 strconv 提供字符串到其他基本类型的转换 比如Atoi, Itoa sync 一般的同步用channel就好. sync包同时也提供了更底层的同步方法. Once和WaitGroup类型应该是用的比较多的. 注意, 包含这个包里定义的类型的数据不能拷贝. Cond Cond是用来保护并发条件下的条件变量x的. 使用时候需要 变量x来表示业务条件 mutex保护这个变量的修改. 并不是用来休眠的 前面两个是程序已经有了的. 那么用Cond的目的是用来等待和通知的. 比如程序要等待x变成比如说100, 就用cond.wait; 到达条件的routine负责通知或者广播等待者. 设计思路和pthread_cond一毛一样 另见并发 任务 事件 和锁.md type Cond struct { // L is held while observing or changing the condition L Locker // contains filtered or unexported fields } // 其中, Locker是个接口 type Locker interface { Lock() Unlock() } //返回一个Cond结构的变量, 需要传入一个Locker func NewCond(l Locker) *Cond //唤醒所有等在这个Cond上的routine, 不需要持有锁 func (c *Cond) Broadcast() //唤醒在c上等待的一个go routine, 不需要持有锁 func (c *Cond) Signal() //调用Wait时, Wait自动unlock c.L, 然后挂起该go routine //恢复的时候, Wait自动lock c.L, 然后return //除非Broadcast或者Signal, Wait不会返回 func (c *Cond) Wait() 没看懂: Because c.L is not locked when Wait first resumes, the caller typically cannot assume that the condition is true when Wait returns. Instead, the caller should Wait in a loop: c.L.Lock() for !condition() { c.Wait() } ... make use of condition ... c.L.Unlock() Map 内置的带锁保护的map. 普通的map不是并发安全的, 需要自己保护临界区. type Map struct { // contains filtered or unexported fields } func (m *Map) Delete(key interface{}) func (m *Map) Load(key interface{}) (value interface{}, ok bool) func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) func (m *Map) Range(f func(key, value interface{}) bool) func (m *Map) Store(key, value interface{}) Mutex 初始状态时unlock态 type Mutex struct { // contains filtered or unexported fields } func (m *Mutex) Lock() func (m *Mutex) Unlock() RWMutex type RWMutex struct { // contains filtered or unexported fields } func (rw *RWMutex) Lock() func (rw *RWMutex) RLock() func (rw *RWMutex) RLocker() Locker func (rw *RWMutex) RUnlock() func (rw *RWMutex) Unlock() Once Once只执行一次 type Once struct { // contains filtered or unexported fields } func (o *Once) Do(f func()) //因为f没有参数, 下面的形式更常见 config.once.Do(func() { config.init(filename) }) Pool Pool是个cache, 是个并发安全的free list. 被put进pool的对象可能没有任何通知的被移除. type Pool struct { // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() interface{} // contains filtered or unexported fields } //随机从pool里选一个对象, 并把该对象从pool里移除. 不保证被put过的对象能够被get //没有对象的时候, 会调用p.New方法. func (p *Pool) Get() interface{} //add对象到pool func (p *Pool) Put(x interface{}) 重点WaitGroup 给main routine来等待所有其他go routine结束用的. 和shell的wait差不多 type WaitGroup struct { // contains filtered or unexported fields } //给counter加delta, delta可以是负值. func (wg *WaitGroup) Add(delta int) //子routine调用done表示自己干完了, counter减一 func (wg *WaitGroup) Done() //main routine调用Wait等待里面的counter减到0 func (wg *WaitGroup) Wait() 例子: package main import ( \"sync\" ) type httpPkg struct{} func (httpPkg) Get(url string) {} var http httpPkg func main() { var wg sync.WaitGroup var urls = []string{ \"http://www.golang.org/\", \"http://www.google.com/\", \"http://www.somestupidname.com/\", } for _, url := range urls { // Increment the WaitGroup counter. wg.Add(1) // Launch a goroutine to fetch the URL. go func(url string) { // Decrement the counter when the goroutine completes. defer wg.Done() // Fetch the URL. http.Get(url) }(url) } // Wait for all HTTP fetches to complete. wg.Wait() } net net提供tcp/ip和unix socket接口 net提供了原始的socket接口, 也提供了一层更简便的接口. 对client来说, 是Dial conn, err := net.Dial(\"tcp\", \"golang.org:80\") if err != nil { // handle error } fmt.Fprintf(conn, \"GET / HTTP/1.0\\r\\n\\r\\n\") status, err := bufio.NewReader(conn).ReadString('\\n') // ... 对server来说, 是Listen ln, err := net.Listen(\"tcp\", \":8080\") if err != nil { // handle error } for { conn, err := ln.Accept() if err != nil { // handle error } go handleConnection(conn) } ip tcp和udp 总的来说, ip是面向报文的, udp也是面向报文的, 只是比ip多加了port.tcp是面向流的.udp有广播. 都有api可以set os的发送接收buffer IP datagrams The IP layer provides a connectionless and unreliable delivery system. It considers each datagram independently of the others. Any association between datagrams must be supplied by the higher layers. The IP layer supplies a checksum that includes its own header. The header includes the source and destination addresses. The IP layer handles routing through an Internet. It is also responsible for breaking up large datagrams into smaller ones for transmission and reassembling them at the other end. UDP UDP is also connectionless and unreliable. What it adds to IP is a checksum for the contents of the datagram and port numbers. These are used to give a client/server model - see later. TCP TCP supplies logic to give a reliable connection-oriented protocol above IP. It provides a virtual circuit that two processes can use to communicate. It also uses port numbers to identify services on a host. 代码 TCP func DialTCP(net string, laddr, raddr *TCPAddr) (c *TCPConn, err os.Error) func (c *TCPConn) Write(b []byte) (n int, err os.Error) func (c *TCPConn) Read(b []byte) (n int, err os.Error) func ListenTCP(net string, laddr *TCPAddr) (l *TCPListener, err os.Error) func (l *TCPListener) Accept() (c Conn, err os.Error) func (c *TCPConn) SetTimeout(nsec int64) os.Error func (c *TCPConn) SetKeepAlive(keepalive bool) os.Error UDP func ResolveUDPAddr(net, addr string) (*UDPAddr, os.Error) func DialUDP(net string, laddr, raddr *UDPAddr) (c *UDPConn, err os.Error) //对client来说, 还是read write: func (c *UDPConn) Read(b []byte) (int, error) func (c *UDPConn) Write(b []byte) (int, error) //对server来说, 有点不一样: 因为UDP的server没有\"连接\"的概念, 只能从每个报文里看到对端的地址. func ListenUDP(net string, laddr *UDPAddr) (c *UDPConn, err os.Error) func (c *UDPConn) ReadFromUDP(b []byte) (n int, addr *UDPAddr, err os.Error func (c *UDPConn) WriteToUDP(b []byte, addr *UDPAddr) (n int, err os.Error) 比如server端的读写是: func handleClient(conn *net.UDPConn) { var buf [512]byte _, addr, err := conn.ReadFromUDP(buf[0:]) if err != nil { return } daytime := time.Now().String() conn.WriteToUDP([]byte(daytime), addr) } raw socket IPConn就是raw socket 比如要写个ping addr, err := net.ResolveIPAddr(\"ip\", os.Args[1]) conn, err := net.DialIP(\"ip4:icmp\", addr, addr) _, err = conn.Write(msg[0:len]) _, err = conn.Read(msg[0:]) 名字解析 名字解析有两个方式: 纯go方式和cgo方式 默认是纯go. 使能了cgo就会用cgo. 环境变量可以选择用哪种方式: export GODEBUG=netdns=go # force pure Go resolver export GODEBUG=netdns=cgo # force cgo resolver api type Buffers func (v *Buffers) Read(p []byte) (n int, err error) func (v *Buffers) WriteTo(w io.Writer) (n int64, err error) //Conn是个interface, 面向流的. 有Read和Write方法. Conn对多个goroutine并发安全 type Conn func Dial(network, address string) (Conn, error) func DialTimeout(network, address string, timeout time.Duration) (Conn, error) //Listener是个接口 type Listener func FileListener(f *os.File) (ln Listener, err error) func Listen(network, address string) (Listener, error) //PacketConn是个接口, 面向datagram的, 有ReadFrom和WriteTo方法. type PacketConn func FilePacketConn(f *os.File) (c PacketConn, err error) func ListenPacket(network, address string) (PacketConn, error) //IPConn is the implementation of the Conn and PacketConn interfaces for IP network connections. //IPConn是Conn的一种实现 type IPConn func DialIP(network string, laddr, raddr *IPAddr) (*IPConn, error) func ListenIP(network string, laddr *IPAddr) (*IPConn, error) func (c *IPConn) Close() error func (c *IPConn) File() (f *os.File, err error) func (c *IPConn) LocalAddr() Addr func (c *IPConn) Read(b []byte) (int, error) func (c *IPConn) ReadFrom(b []byte) (int, Addr, error) func (c *IPConn) ReadFromIP(b []byte) (int, *IPAddr, error) func (c *IPConn) ReadMsgIP(b, oob []byte) (n, oobn, flags int, addr *IPAddr, err error) func (c *IPConn) RemoteAddr() Addr func (c *IPConn) SetDeadline(t time.Time) error func (c *IPConn) SetReadBuffer(bytes int) error func (c *IPConn) SetReadDeadline(t time.Time) error func (c *IPConn) SetWriteBuffer(bytes int) error func (c *IPConn) SetWriteDeadline(t time.Time) error func (c *IPConn) SyscallConn() (syscall.RawConn, error) func (c *IPConn) Write(b []byte) (int, error) func (c *IPConn) WriteMsgIP(b, oob []byte, addr *IPAddr) (n, oobn int, err error) func (c *IPConn) WriteTo(b []byte, addr Addr) (int, error) func (c *IPConn) WriteToIP(b []byte, addr *IPAddr) (int, error) type TCPConn func DialTCP(network string, laddr, raddr *TCPAddr) (*TCPConn, error) func (c *TCPConn) Close() error func (c *TCPConn) CloseRead() error func (c *TCPConn) CloseWrite() error func (c *TCPConn) File() (f *os.File, err error) func (c *TCPConn) LocalAddr() Addr func (c *TCPConn) Read(b []byte) (int, error) func (c *TCPConn) ReadFrom(r io.Reader) (int64, error) func (c *TCPConn) RemoteAddr() Addr func (c *TCPConn) SetDeadline(t time.Time) error func (c *TCPConn) SetKeepAlive(keepalive bool) error func (c *TCPConn) SetKeepAlivePeriod(d time.Duration) error func (c *TCPConn) SetLinger(sec int) error func (c *TCPConn) SetNoDelay(noDelay bool) error func (c *TCPConn) SetReadBuffer(bytes int) error func (c *TCPConn) SetReadDeadline(t time.Time) error func (c *TCPConn) SetWriteBuffer(bytes int) error func (c *TCPConn) SetWriteDeadline(t time.Time) error func (c *TCPConn) SyscallConn() (syscall.RawConn, error) func (c *TCPConn) Write(b []byte) (int, error) type TCPListener func ListenTCP(network string, laddr *TCPAddr) (*TCPListener, error) func (l *TCPListener) Accept() (Conn, error) func (l *TCPListener) AcceptTCP() (*TCPConn, error) func (l *TCPListener) Addr() Addr func (l *TCPListener) Close() error func (l *TCPListener) File() (f *os.File, err error) func (l *TCPListener) SetDeadline(t time.Time) error func (l *TCPListener) SyscallConn() (syscall.RawConn, error) type UDPConn func DialUDP(network string, laddr, raddr *UDPAddr) (*UDPConn, error) func ListenMulticastUDP(network string, ifi *Interface, gaddr *UDPAddr) (*UDPConn, error) func ListenUDP(network string, laddr *UDPAddr) (*UDPConn, error) func (c *UDPConn) Close() error func (c *UDPConn) File() (f *os.File, err error) func (c *UDPConn) LocalAddr() Addr func (c *UDPConn) Read(b []byte) (int, error) func (c *UDPConn) ReadFrom(b []byte) (int, Addr, error) func (c *UDPConn) ReadFromUDP(b []byte) (int, *UDPAddr, error) func (c *UDPConn) ReadMsgUDP(b, oob []byte) (n, oobn, flags int, addr *UDPAddr, err error) func (c *UDPConn) RemoteAddr() Addr func (c *UDPConn) SetDeadline(t time.Time) error func (c *UDPConn) SetReadBuffer(bytes int) error func (c *UDPConn) SetReadDeadline(t time.Time) error func (c *UDPConn) SetWriteBuffer(bytes int) error func (c *UDPConn) SetWriteDeadline(t time.Time) error func (c *UDPConn) SyscallConn() (syscall.RawConn, error) func (c *UDPConn) Write(b []byte) (int, error) func (c *UDPConn) WriteMsgUDP(b, oob []byte, addr *UDPAddr) (n, oobn int, err error) func (c *UDPConn) WriteTo(b []byte, addr Addr) (int, error) func (c *UDPConn) WriteToUDP(b []byte, addr *UDPAddr) (int, error) type UnixConn func DialUnix(network string, laddr, raddr *UnixAddr) (*UnixConn, error) func ListenUnixgram(network string, laddr *UnixAddr) (*UnixConn, error) func (c *UnixConn) Close() error func (c *UnixConn) CloseRead() error func (c *UnixConn) CloseWrite() error func (c *UnixConn) File() (f *os.File, err error) func (c *UnixConn) LocalAddr() Addr func (c *UnixConn) Read(b []byte) (int, error) func (c *UnixConn) ReadFrom(b []byte) (int, Addr, error) func (c *UnixConn) ReadFromUnix(b []byte) (int, *UnixAddr, error) func (c *UnixConn) ReadMsgUnix(b, oob []byte) (n, oobn, flags int, addr *UnixAddr, err error) func (c *UnixConn) RemoteAddr() Addr func (c *UnixConn) SetDeadline(t time.Time) error func (c *UnixConn) SetReadBuffer(bytes int) error func (c *UnixConn) SetReadDeadline(t time.Time) error func (c *UnixConn) SetWriteBuffer(bytes int) error func (c *UnixConn) SetWriteDeadline(t time.Time) error func (c *UnixConn) SyscallConn() (syscall.RawConn, error) func (c *UnixConn) Write(b []byte) (int, error) func (c *UnixConn) WriteMsgUnix(b, oob []byte, addr *UnixAddr) (n, oobn int, err error) func (c *UnixConn) WriteTo(b []byte, addr Addr) (int, error) func (c *UnixConn) WriteToUnix(b []byte, addr *UnixAddr) (int, error) type UnixListener func ListenUnix(network string, laddr *UnixAddr) (*UnixListener, error) func (l *UnixListener) Accept() (Conn, error) func (l *UnixListener) AcceptUnix() (*UnixConn, error) func (l *UnixListener) Addr() Addr func (l *UnixListener) Close() error func (l *UnixListener) File() (f *os.File, err error) func (l *UnixListener) SetDeadline(t time.Time) error func (l *UnixListener) SetUnlinkOnClose(unlink bool) func (l *UnixListener) SyscallConn() (syscall.RawConn, error) path path是个辅助包, 用于解析路径的, 基本上带斜杠的路径常用的方法都有. 针对URL地址的, 对unix路径也有效. windows路径无效. func Base(path string) string func Clean(path string) string func Dir(path string) string func Ext(path string) string func IsAbs(path string) bool func Join(elem ...string) string func Match(pattern, name string) (matched bool, err error) func Split(path string) (dir, file string) filepath filepath提供OS无关的路径, 正斜杠和反斜杠都支持. filepath提供基本的path方法, 还提供了一个很好的目录遍历方法: Walk, 对目录下的所有文件调用WalkFunc func Abs(path string) (string, error) func Base(path string) string func Clean(path string) string func Dir(path string) string func EvalSymlinks(path string) (string, error) func Ext(path string) string func FromSlash(path string) string func Glob(pattern string) (matches []string, err error) func HasPrefix(p, prefix string) bool func IsAbs(path string) bool func Join(elem ...string) string func Match(pattern, name string) (matched bool, err error) func Rel(basepath, targpath string) (string, error) func Split(path string) (dir, file string) func SplitList(path string) []string func ToSlash(path string) string func VolumeName(path string) string func Walk(root string, walkFn WalkFunc) error type WalkFunc encoding encoding下面有好几种encode方法, 但都能用到下面两对接口. 二进制 type BinaryMarshaler interface { MarshalBinary() (data []byte, err error) } type BinaryUnmarshaler interface { UnmarshalBinary(data []byte) error } UTF8 type TextMarshaler interface { MarshalText() (text []byte, err error) } type TextUnmarshaler interface { UnmarshalText(text []byte) error } encoding/gob gob提供在发送和接收双方传输二进制流的方法. 比较常用于rpc gob流是自解释的. 每个gob数据前面都有个类型, 是预定义好的. 在gob流中, 指针会被变成其指向的内容. 使用gob的时候, Encoder把本地变量变成gob流,Decoder把流数据还原到本地变量. 接收端和发送端不一定要完全一样. 结构体的成员按名字来匹配. 比如发送一个结构体: struct { A, B int } 那下面的形式都可以: struct { A, B int } // the same *struct { A, B int } // extra indirection of the struct struct { *A, **B int } // extra indirection of the fields struct { A, B int64 } // different concrete value type; see below 接受方可以是: struct { A, B int } // the same *struct { A, B int } // extra indirection of the struct struct { *A, **B int } // extra indirection of the fields struct { A, B int64 } // different concrete value type; see below 接收下面的形式是错误的: struct { A int; B uint } // change of signedness for B struct { A int; B float } // change of type for B struct { } // no field names in common struct { C, D int } // no field names in common 传输的过程不是很简单, 比如对整形来说, int是以变长方式传输的, 并不区分int32, int64等. string和byte切片, 数组和map, 都可以被Encode然后send. 也可以自定义Encode方法来发送自定义数据. api func Register(value interface{}) func RegisterName(name string, value interface{}) type CommonType type Decoder func NewDecoder(r io.Reader) *Decoder func (dec *Decoder) Decode(e interface{}) error func (dec *Decoder) DecodeValue(v reflect.Value) error type Encoder func NewEncoder(w io.Writer) *Encoder func (enc *Encoder) Encode(e interface{}) error func (enc *Encoder) EncodeValue(value reflect.Value) error type GobDecoder type GobEncoder 注意: type Decoder和type Encoder都是struct, 而不是interface 返回struct, 是要调用这个对象的方法. 而实现interface, 是实现一个派生类 入参都是e interface{}, 这是个万能对象. 可以是指针, 也可以是值. 看怎么用. 简单例子 package main import ( \"bytes\" \"encoding/gob\" \"fmt\" \"log\" ) type P struct { X, Y, Z int Name string } type Q struct { X, Y *int32 Name string } // This example shows the basic usage of the package: Create an encoder, // transmit some values, receive them with a decoder. func main() { // Initialize the encoder and decoder. Normally enc and dec would be // bound to network connections and the encoder and decoder would // run in different processes. var network bytes.Buffer // Stand-in for a network connection enc := gob.NewEncoder(&network) // Will write to network. dec := gob.NewDecoder(&network) // Will read from network. // Encode (send) some values. err := enc.Encode(P{3, 4, 5, \"Pythagoras\"}) if err != nil { log.Fatal(\"encode error:\", err) } err = enc.Encode(P{1782, 1841, 1922, \"Treehouse\"}) if err != nil { log.Fatal(\"encode error:\", err) } // Decode (receive) and print the values. var q Q err = dec.Decode(&q) if err != nil { log.Fatal(\"decode error 1:\", err) } fmt.Printf(\"%q: {%d, %d}\\n\", q.Name, *q.X, *q.Y) err = dec.Decode(&q) if err != nil { log.Fatal(\"decode error 2:\", err) } fmt.Printf(\"%q: {%d, %d}\\n\", q.Name, *q.X, *q.Y) } 结果 \"Pythagoras\": {3, 4} \"Treehouse\": {1782, 1841} 自定义encode和decode Vector里面有私有成员, gob无法直接访问, 必须通过Vector自己的方法. gob会调用encoding的MarshalBinary和UnmarshalBinary来完成这个任务. package main import ( \"bytes\" \"encoding/gob\" \"fmt\" \"log\" ) // The Vector type has unexported fields, which the package cannot access. // We therefore write a BinaryMarshal/BinaryUnmarshal method pair to allow us // to send and receive the type with the gob package. These interfaces are // defined in the \"encoding\" package. // We could equivalently use the locally defined GobEncode/GobDecoder // interfaces. type Vector struct { x, y, z int } func (v Vector) MarshalBinary() ([]byte, error) { // A simple encoding: plain text. var b bytes.Buffer fmt.Fprintln(&b, v.x, v.y, v.z) return b.Bytes(), nil } // UnmarshalBinary modifies the receiver so it must take a pointer receiver. //因为下面Decode()入参是Vector的地址, 所以这里要引用方式. func (v *Vector) UnmarshalBinary(data []byte) error { // A simple encoding: plain text. b := bytes.NewBuffer(data) _, err := fmt.Fscanln(b, &v.x, &v.y, &v.z) return err } // This example transmits a value that implements the custom encoding and decoding methods. func main() { var network bytes.Buffer // Stand-in for the network. // Create an encoder and send a value. enc := gob.NewEncoder(&network) err := enc.Encode(Vector{3, 4, 5}) if err != nil { log.Fatal(\"encode:\", err) } // Create a decoder and receive a value. dec := gob.NewDecoder(&network) var v Vector err = dec.Decode(&v) if err != nil { log.Fatal(\"decode:\", err) } fmt.Println(v) } 结果: {3 4 5} 传输interface对象 interface, channel等默认不能传输. 但可以注册interface的concrete 类型来传输. 比如: Point是个struct, 可以直接gob; 但Pythagoras是interface, 要传输它必须要注册它对应的concrete类型: gob.Register(Point{}) package main import ( \"bytes\" \"encoding/gob\" \"fmt\" \"log\" \"math\" ) type Point struct { X, Y int } func (p Point) Hypotenuse() float64 { return math.Hypot(float64(p.X), float64(p.Y)) } type Pythagoras interface { Hypotenuse() float64 } // This example shows how to encode an interface value. The key // distinction from regular types is to register the concrete type that // implements the interface. func main() { var network bytes.Buffer // Stand-in for the network. // We must register the concrete type for the encoder and decoder (which would // normally be on a separate machine from the encoder). On each end, this tells the // engine which concrete type is being sent that implements the interface. gob.Register(Point{}) // Create an encoder and send some values. enc := gob.NewEncoder(&network) for i := 1; i encoding/binary binary提供对字节序列到任意格式的转换. 比如下面的例子, 把一个字节序列, \"读\"到一个结构体里面. func main() { b := []byte{0x18, 0x2d, 0x44, 0x54, 0xfb, 0x21, 0x09, 0x40, 0xff, 0x01, 0x02, 0x03, 0xbe, 0xef} r := bytes.NewReader(b) var data struct { PI float64 Uate uint8 Mine [3]byte Too uint16 } //对字符数组来说, 大小端没关系. 但对uint16来说, 要知道大小端才知道如何解读. if err := binary.Read(r, binary.LittleEndian, &data); err != nil { fmt.Println(\"binary.Read failed:\", err) } fmt.Println(data.PI) fmt.Println(data.Uate) fmt.Printf(\"% x\\n\", data.Mine) fmt.Println(data.Too) } //输出. 3.141592653589793 255 01 02 03 61374 下面是个写的例子: func main() { buf := new(bytes.Buffer) var data = []interface{}{ uint16(61374), int8(-54), uint8(254), } for _, v := range data { err := binary.Write(buf, binary.LittleEndian, v) if err != nil { fmt.Println(\"binary.Write failed:\", err) } } fmt.Printf(\"%x\", buf.Bytes()) } varint varint是种对int的变长存储策略, 越小的数, 用越少的字节存储. time 底层OS一般提供 墙上(wall clock)时间: 用来报告时间, 表示绝对时间; 墙上时间可能由于设定时间等操作, 造成跳变. 单一(monotonic)时间: 用来测量时间, 表示相对时间 time.Now()返回的就是Time类型的值, 这个值既包括墙上时间, 又包括单一时间. 下面的代码保证即使墙上时间跳变了, 比如时间被校准了, 但相对时间elapsed是实际的delta时间. start := time.Now() ... operation that takes 20 milliseconds ... t := time.Now() elapsed := t.Sub(start) 在api中, 应该说有相对概念的api, 比如Time.sub, Time.before等等, 都用的是单一时间. 相对时间只对当前的进程有效. Time 首先, Time是个结构体; 但其内部结构对外是不可见的. 我们知道的, 只是Time是对绝对时间的表达, 精度是ns Time是值, 不是指针. Time的0值是1年1月1号0点 比较符号==可以比较两个Time, 但推荐用t1.Equal(t2), 后者更精确. type Time struct { // contains filtered or unexported fields } Time有如下方法: func Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time 比如: t := time.Date(2009, time.November, 10, 23, 0, 0, 0, time.UTC), 这样初始化一个time 有Now(), 有从字符串解析时间的Parse()方法. 有Add(), After(), Before() 还有给定Time t, 有解析到Date, Day的方法 比如: d := time.Date(2000, 2, 1, 12, 30, 0, 0, time.UTC) year, month, day := d.Date() fmt.Printf(\"year = %v\\n\", year) fmt.Printf(\"month = %v\\n\", month) fmt.Printf(\"day = %v\\n\", day) 还有把Time转为json格式的方法. 时间格式和单位 const ( ANSIC = \"Mon Jan _2 15:04:05 2006\" UnixDate = \"Mon Jan _2 15:04:05 MST 2006\" RubyDate = \"Mon Jan 02 15:04:05 -0700 2006\" RFC822 = \"02 Jan 06 15:04 MST\" RFC822Z = \"02 Jan 06 15:04 -0700\" // RFC822 with numeric zone RFC850 = \"Monday, 02-Jan-06 15:04:05 MST\" RFC1123 = \"Mon, 02 Jan 2006 15:04:05 MST\" RFC1123Z = \"Mon, 02 Jan 2006 15:04:05 -0700\" // RFC1123 with numeric zone RFC3339 = \"2006-01-02T15:04:05Z07:00\" RFC3339Nano = \"2006-01-02T15:04:05.999999999Z07:00\" Kitchen = \"3:04PM\" // Handy time stamps. Stamp = \"Jan _2 15:04:05\" StampMilli = \"Jan _2 15:04:05.000\" StampMicro = \"Jan _2 15:04:05.000000\" StampNano = \"Jan _2 15:04:05.000000000\" ) //这些时间都是以ns为单位的 const ( Nanosecond Duration = 1 Microsecond = 1000 * Nanosecond Millisecond = 1000 * Microsecond Second = 1000 * Millisecond Minute = 60 * Second Hour = 60 * Minute ) Duration Duration是个时间delta, type Duration int64, 时间单位是ns, 是64位的int, 最大能表示290年. 比如 t0 := time.Now() expensiveCall() t1 := time.Now() fmt.Printf(\"The call took %v to run.\\n\", t1.Sub(t0)) Duration的值有几个方法, 比如 d Duration, d.Hours, d.Senconds等, 把Duration转换为相应的单位.其String方法返回类似的字符串: \"72h3m0.5s\" api func Now() Time : 返回当前local时间 func After(d Duration) : 提供一个简单的超时机制, 它返回一个channel, 超时后可读. 超时后可以被垃圾回收. var c chan int func handle(int) {} func main() { select { case m := time.Sleep(100 * time.Millisecond) : sleep time.Tick 返回一个channel, 这个channel不会close, 一直能读到Time, 它是对NewTicker的封装 比如下面的代码一直会打印, 每5秒一次. 这个是不是和while 1里面sleep差不多. func main() { c := time.Tick(5 * time.Second) for now := range c { fmt.Printf(\"%v %s\\n\", now, statusUpdate()) } } func Since(t Time) Duration : 和time.Now().Sub(t)一样. 从t到现在的Duration Ticker type Ticker struct { //C是给外部用的channel C 使用func NewTicker(d Duration) *Ticker来获得一个Ticker实例 Ticker是周期的tick, 有NewTicker(), Stop()等方法. Timer type Timer struct { //外部可以用C这个channel C 使用func NewTimer(d Duration) *Timer先生成一个Timer对象 和Ticker不同的是, Timer是一次性的事件. 有NewTimer() Stop等方法. context //Context是个interface type Context interface { Deadline() (deadline time.Time, ok bool) //这是个空结构体的channel Done() 顾名思义, 上下文. 提供通用的deadline, cancel等API, 用于多个go routine之间协作的. context不应该被包含在任何struct里, 而是应该直接传入函数, 通常应该是第一个参数, 叫ctx. 一个context可能会被多个go routine使用, context保证并发安全. context对象都有个Done()方法, 返回一个channel. 读这个channel就知道是否有人或有事件通知我们该结束了. 通常在服务端收到一个request时, 会新开一个goroutine来响应这个请求, 我们称其为这个请求的主routine;通常这个主routine会再开其他的goroutine用来访问数据库或者其他RPC服务, 这些子routine都会用到request的相关user的token等身份数据. 当主routine认为超时的时候, 这些子routine应该尽快结束. 所以是主routine创建Context, 设置超时时间, 把Context传入每个子routine; 主routine检测到超时, 会调用Context的Cancel函数, 触发Done的通道关闭; 子routine需要在代码里检测Done通道, 如果关闭了就马上退出. 这是一种主routine\"通知\"子routine退出的方法. api func Background() Context : 返回一个空的ctx变量 整数发生器 generator func WithCancel(parent Context) (ctx Context, cancel CancelFunc) 返回一个Context变量ctx, ctx有个Done的channel 返回的第二个值是CancelFunc函数, 用于关闭ctx.Done 举例: 下面的例子, main调用gen(), 后者返回个channel, 并起个 go routine不断的产生整数, 写入这个channel. 这个go routine还监视ctx.Done(), 这是ctx提供的channel, 能读到东西说明别人告诉他事情做完了. package main import ( \"context\" \"fmt\" ) func main() { // gen generates integers in a separate goroutine and // sends them to the returned channel. // The callers of gen need to cancel the context once // they are done consuming generated integers not to leak // the internal goroutine started by gen. gen := func(ctx context.Context) Context适合用于main通知子routine结束; 而WaitGroup机制是子routine通知main完成, main可以结束等待. 带超时的Context func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) 和WithCancel类似, 返回一个以time.Time为deadline的ctx. 如果时间到了, 或者ctx的CancelFunc被调用了, 或者这个Done channel本身被close了, 那这个ctx的Done channel会close. 举例: 下面的例子设置超时时间d为现在开始后50ms, 并以d初始化ctx. 然后用defer关键词执行cancel(). 注意, 不管哪种情况, 在函数退出的时候执行cancel都是没坏处的. 然后select会阻塞, 等1秒或者是等超时, 很明显, 是超时. package main import ( \"context\" \"fmt\" \"time\" ) func main() { d := time.Now().Add(50 * time.Millisecond) ctx, cancel := context.WithDeadline(context.Background(), d) // Even though ctx will be expired, it is good practice to call its // cancellation function in any case. Failure to do so may keep the // context and its parent alive longer than necessary. defer cancel() select { case 思考: 如果是用c写一个带超时的等待, 该怎么写呢? WithTimeout方法是WithDeadline的简化版: 即WithTimeout = WithDeadline(parent, time.Now().Add(timeout)) syscall syscall包装了很多底层OS系统调用 但只有一部分? 比如没有ioctl? runtime runtime包提供对go的runtime系统访问的功能 runtime相关的环境变量 GOGC: 新分配数据和老数据的比率. 默认是100. 即新老数据一样多的时候, 触发一次垃圾回收.这个比率越大, gc被触发次数越少, 比如说调高到500 SetGCPercent函数和GOGC环境变量作用一样, 但可以在运行时调用. GODEBUG: 里面有控制相关模块的debug的开关, 比如 gc, cgo, 调度, 内存分析等.见笔记go调试 GODEBUG=schedtrace=10000,scheddetail=1 GOMAXPROCS: 控制多少个goroutine可以并行跑 另外还有关于调用栈的, 关于竞争的环境变量 api runtime很强大, 它暴露了很多go的细节. 比如 #执行断点 func Breakpoint() #调用goroutine退出, 其他不受影响 func Goexit() #触发一次调度 func Gosched() #绑定goroutine到底层线程 func LockOSThread() #有MemProfile和CPUProfile等检查性能的函数, 但推荐普通用户使用 runtime/pprof #可用cpu数 func NumCPU() int #还有api可以获得goroutine的个数, 调用cgo的次数等 //...省略一些高端api #返回版本号 func Version() string #调用栈 Callers CallersFrames runtime/pprof 管性能分析的. runtime/debug 顾名思义, 有打印调用栈的, 有调节gc的等等. func FreeOSMemory() func PrintStack() func ReadGCStats(stats *GCStats) func SetGCPercent(percent int) int func SetMaxStack(bytes int) int func SetMaxThreads(threads int) int func SetPanicOnFault(enabled bool) bool func SetTraceback(level string) func Stack() []byte func WriteHeapDump(fd uintptr) type BuildInfo func ReadBuildInfo() (info *BuildInfo, ok bool) type GCStats type Module runtime/trace 和ftrace概念类似, 在关键点上打桩. os os包提供平台无关的接口. 它的错误处理方式是go的经典方式: file, err := os.Open(\"file.go\") // For read access. if err != nil { log.Fatal(err) } 提供的接口包括 Chdir Chmod Link Mkdir Pipe Remove TempDir Rename Expand环境变量等 Getpid, ppid等 IsExist IsTimeout等 文件类 type File Create NewFile Open 用于创建File对象 注意, Open()返回只读的File对象, OpenFile()可以指定打开模式, 和C一样. 读 写 Seek Sync Close 进程类 type Process 按pid查找进程 开始进程 Kill Release Signal Wait等 定义了错误类型 PathError LinkError SyscallError package main import ( \"log\" \"os\" ) func main() { f, err := os.OpenFile(\"notes.txt\", os.O_RDWR|os.O_CREATE, 0755) if err != nil { log.Fatal(err) } if err := f.Close(); err != nil { log.Fatal(err) } } os/exec 用于执行外部程序; 只能在linux上跑 和c里面的system不太一样, exec和c的exec更像, 比system简单. Run和Start的区别是: Run要等待命令返回, 而Start只管开始, 不等待返回, 要和Wait连用. package main import ( \"log\" \"os/exec\" ) func main() { //一般的模式是先生成一个cmd对象. cmd := exec.Command(\"sleep\", \"1\") log.Printf(\"Running command and waiting for it to finish...\") //后面都用这个cmd对象来操作 err := cmd.Run() log.Printf(\"Command finished with error: %v\", err) } os/signal 用来处理go的signal SIGKILL and SIGSTOP不能被捕获, 所以这里的东西都管不了它们 同步的signal, 一般是SIGBUS, SIGFPE, and SIGSEGV, 是由正在执行的go程序引起的 在go里, 这些signal被转换为运行时的panic 剩下的signal, 是其他进程异步通知的signal, 用这里的接口处理 默认行为: By default, a synchronous signal is converted into a run-time panic. A SIGHUP, SIGINT, or SIGTERM signal causes the program to exit. A SIGQUIT, SIGILL, SIGTRAP, SIGABRT, SIGSTKFLT, SIGEMT, or SIGSYS signal causes the program to exit with a stack dump. A SIGTSTP, SIGTTIN, or SIGTTOU signal gets the system default behavior (these signals are used by the shell for job control). The SIGPROF signal is handled directly by the Go runtime to implement runtime.CPUProfile. Other signals will be caught but no action will be taken. cgo 一般go程序在启动的时候, runtime会先安装默认的sighandler, cgo如果自己有处理signal的需求, 要用SA_ONSTACK标记. 否则程序会crash 这种情况要当心, 详见: https://golang.google.cn/pkg/os/signal/#hdr-Go_programs_that_use_cgo_or_SWIG go作为so 当go编译为-buildmode=c-shared时, 一般调用这个so的非go程序, 已经安装了sighandler, 那go runtime有相关处理. https://golang.google.cn/pkg/os/signal/#hdr-Non_Go_programs_that_call_Go_code 方法 func Ignore(sig ...os.Signal) func Ignored(sig os.Signal) bool func Notify(c chan 比如 package main import ( \"fmt\" \"os\" \"os/signal\" ) func main() { // Set up channel on which to send signal notifications. // We must use a buffered channel or risk missing the signal // if we're not ready to receive when the signal is sent. c := make(chan os.Signal, 1) // 在os包中, var Interrupt Signal = syscall.SIGINT signal.Notify(c, os.Interrupt) // Block until a signal is received. s := os/user 提供用户name id等查询的功能. builtin builtin里预定义了golang的常用函数和类型 比如 函数 append cap close copy delete len make new panic recover print 类型 bool byte error int u/int8/16/32/64 float32/64 rune string uintptr strings strings和bytes的方法差不多, 不同在于 strings是UTF8编码, 变长的 bytes是C里的字符数组 举例: Builder是strings包提供的一个struct, 实现了Write方法. 它尽量少copy package main import ( \"fmt\" \"strings\" ) func main() { var b strings.Builder for i := 3; i >= 1; i-- { fmt.Fprintf(&b, \"%d...\", i) } b.WriteString(\"ignition\") fmt.Println(b.String()) } //输出 3...2...1...ignition bytes bytes可以有 两个byte切片可以比较: func Compare(a, b []byte) int 可以判断是否有子串: Contains 子串计数: Count 字串位置: Index 相等: Equal 前后缀: HasPrefix HasSuffix 字符串逐个map: Map 重复N次字符串: Repeat 替换: Replace 分割: Split 大小写转换: ToUpper ToLower 去掉空白: Trim 连接: Join Buffer Buffer是个struct, 是动态大小的byte切片. 有Read和Write方法, 符合io.Reaer和io.Writer NewBuffer返回一个Buffer对象, 但通常new(Buffer)或者var b bytes.Buffer就够实例化一个Buffer了. Buffer的所有方法, 都是引用方式. 比如: func (b *Buffer) Read(p []byte) (n int, err error) func (b *Buffer) Write(p []byte) (n int, err error) log/syslog 虽然这个包已经停止维护, 但它提供了一个参考设计 这个包通过unix socket, 发送记录到syslog守护进程; 只需要调用一次Dial方法来连接到syslog守护进程, 如果有问题, 会自动重连. package main import ( \"fmt\" \"log\" \"log/syslog\" ) func main() { sysLog, err := syslog.Dial(\"tcp\", \"localhost:1234\", syslog.LOG_WARNING|syslog.LOG_DAEMON, \"demotag\") if err != nil { log.Fatal(err) } fmt.Fprintf(sysLog, \"This is a daemon warning with demotag.\") sysLog.Emerg(\"And this is a daemon emergency with demotag.\") } 新的第三方的syslog更好用 log log包实现了一个logger类型, 并提供基础的log功能. log还提供了一个\"标准\"的logger, 用来记录log到stdout log给每个message都加换行. Fatal()会调用os.Exit() Panic()会调用内置函数panic() Print()家族函数用来打印到log type logger logger是个struct, 提供在io.Writer基础上的log功能. 它不是个interface, 并不抽象, 它是实实在在的一个对象. 用func New(out io.Writer, prefix string, flag int) *Logger来实例化一个logger 这个New很精髓, 实例化一个对象来对外提供功能. package main import ( \"bytes\" \"fmt\" \"log\" ) func main() { var ( buf bytes.Buffer logger = log.New(&buf, \"logger: \", log.Lshortfile) ) logger.Print(\"Hello, log file!\") fmt.Print(&buf) } logger支持多种格式, 用flag来配置 比如Ldate | Ltime | Lmicroseconds | Llongfile产生这样的打印 2009/01/23 01:23:23.123123 /a/b/c/d.go:23: message 我们注意到, logger的一个功能就是打印当前的文件名和行数 有个Output()函数, 地一个参数是skip多少级的意思, 因为打印当前行, 也就是打印语句本身所在的行, 并没有什么实际意义. 这和callstack函数会skip几个层级道理一样. fmt 与python不同的是, 字符串格式化不是语言级别的. 在go里, 用fmt包提供这类功能. 方法 比较常用的有 //接受格式化字符串, 返回error对象 func Errorf(format string, a ...interface{}) error //Fprintf/Fprintln家族, 输出到io.Writer func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) //格式化输入, 输入源是io.Reader func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) //去掉F的是 标准输入输出 Printf/Scanf Stringer类型 Stringer类型的String方法是默认的打印方法, 有String方法的类型都能被Print家族打印, 不用显式给出格式化串. type Stringer interface { String() string } package main import ( \"fmt\" ) // Animal has a Name and an Age to represent an animal. type Animal struct { Name string Age uint } // String makes Animal satisfy the Stringer interface. func (a Animal) String() string { return fmt.Sprintf(\"%v (%d)\", a.Name, a.Age) } func main() { a := Animal{ Name: \"Gopher\", Age: 2, } fmt.Println(a) } 格式化标志符 通用 %v the value in a default format when printing structs, the plus flag (%+v) adds field names %#v a Go-syntax representation of the value %T a Go-syntax representation of the type of the value %% a literal percent sign; consumes no value 布尔值 %t the word true or false 整型 %b base 2 %c the character represented by the corresponding Unicode code point %d base 10 %o base 8 %O base 8 with 0o prefix %q a single-quoted character literal safely escaped with Go syntax. %x base 16, with lower-case letters for a-f %X base 16, with upper-case letters for A-F %U Unicode format: U+1234; same as \"U+%04X\" 浮点 %b decimalless scientific notation with exponent a power of two, in the manner of strconv.FormatFloat with the 'b' format, e.g. -123456p-78 %e scientific notation, e.g. -1.234456e+78 %E scientific notation, e.g. -1.234456E+78 %f decimal point but no exponent, e.g. 123.456 %F synonym for %f %g %e for large exponents, %f otherwise. Precision is discussed below. %G %E for large exponents, %F otherwise %x hexadecimal notation (with decimal power of two exponent), e.g. -0x1.23abcp+20 %X upper-case hexadecimal notation, e.g. -0X1.23ABCP+20 字符串 %s the uninterpreted bytes of the string or slice %q a double-quoted string safely escaped with Go syntax %x base 16, lower-case, two characters per byte %X base 16, upper-case, two characters per byte 切片 %p address of 0th element in base 16 notation, with leading 0x 指针 %p base 16 notation, with leading 0x The %b, %d, %o, %x and %X verbs also work with pointers, formatting the value exactly as if it were an integer. 默认格式化 bool: %t int, int8 etc.: %d uint, uint8 etc.: %d, %#x if printed with %#v float32, complex64, etc: %g string: %s chan: %p pointer: %p struct: {field0 field1 ...} array, slice: [elem0 elem1 ...] maps: map[key1:value1 key2:value2 ...] pointer to above: &{}, &[], &map[] 宽度 精度 对齐 %f default width, default precision %9f width 9, default precision %.2f default width, precision 2 %9.2f width 9, precision 2 %9.f width 9, precision 0 + always print a sign for numeric values; guarantee ASCII-only output for %q (%+q) - pad with spaces on the right rather than the left (left-justify the field) # alternate format: add leading 0b for binary (%#b), 0 for octal (%#o), 0x or 0X for hex (%#x or %#X); suppress 0x for %p (%#p); for %q, print a raw (backquoted) string if strconv.CanBackquote returns true; always print a decimal point for %e, %E, %f, %F, %g and %G; do not remove trailing zeros for %g and %G; write e.g. U+0078 'x' if the character is printable for %U (%#U). ' ' (space) leave a space for elided sign in numbers (% d); put spaces between bytes printing strings or slices in hex (% x, % X) 0 pad with leading zeros rather than spaces; for numbers, this moves the padding after the sign 举例 fmt格式的详细例子, 在golang的doc上都有: https://golang.org/pkg/fmt/#example__formats scanf package main import ( \"fmt\" \"os\" \"strings\" ) func main() { var ( i int b bool s string ) r := strings.NewReader(\"5 true gophers\") n, err := fmt.Fscanf(r, \"%d %t %s\", &i, &b, &s) if err != nil { fmt.Fprintf(os.Stderr, \"Fscanf: %v\\n\", err) } fmt.Println(i, b, s) fmt.Println(n) } bufio bufio是在io层之上的, 提供带buffer的io New家族的方法有 使用io.Reader初始化一个bufio.Reader func NewReader(rd io.Reader) *Reader 使用io.Writer初始化一个bufio.Writer func NewWriter(w io.Writer) *Writer 使用bufio的Reader和Writer创建一个ReadWriter func NewReadWriter(r *Reader, w *Writer) *ReadWriter error对象 这个模式在go里很常见: 把错误定义为变量, 错误用error.New创建, 可以被当作error返回. var ( ErrInvalidUnreadByte = errors.New(\"bufio: invalid use of UnreadByte\") ErrInvalidUnreadRune = errors.New(\"bufio: invalid use of UnreadRune\") ErrBufferFull = errors.New(\"bufio: buffer full\") ErrNegativeCount = errors.New(\"bufio: negative count\") ) Reader的方法 bufio的Reader, 可以 看当前buffer的可读取byte数: Buffered 可以丢弃当前buffer的n个字节: Discard 临时读n个byte: Peek 调用底层io.Reader, 读一次: Read 读一个字节: ReadByte 读n个字节, 直到分隔符: func (b *Reader) ReadBytes(delim byte) ([]byte, error) 读一行: ReadLine 读一个符文: ReadRune 读出一个切片, 直到某个字符: ReadSlice 读出一个字符串, 直到某个字符: ReadString 重置buffer: Reset 大小: Size 取消上次读: UnreadByte 写到别处: WriteTo Writer的方法 有多少个字节在buffer里未被使用: Available 已经用了多少: Buffered 从一个Reader里读: ReadFrom 重置buffer: Reset 写字符切片, 写单个字符, 写单个符文, 写utf8字符串 Scanner的方法 bufio提供了对文件遍历的方案: 按行(默认行为), 按空白字符, 按指定的rune, 按制定的byte等方式. Scanner的方法 这里的Scanner是个很好的迭代器的参考 New: func NewScanner(r io.Reader) *Scanner 常用的方法: Scan: 根据split的定义, 内部保存本次token, 返回是否结束. Text或者Bytes : 获取最后一次Scan到的token 我觉得其实Scan可以返回两个值, 第一个是token, 第二个才是表示结束的bool值. 那么for scanner.Scan() {...} 就可以写成for token, finish := scanner.Scan(); finish != ture; token, finish := scanner.Scan(); {...}, 不是省掉了scanner.Text()调用? 似乎人家这么设计是有原因的, 可能和go没有do while结构有关. SplitFunc方法 用来定义分割符的 type SplitFunc func(data []byte, atEOF bool) (advance int, token []byte, err error) 被Scan调用. data是Scan传给SplitFunc的数据, 是剩下未被扫描的字符数组, 和一个底层io.Reader是否已经是EOF的标记. 返回的avance是本次在buffer里前进了多少个字节, token是本次扫描到的token. 按行读 package main import ( \"bufio\" \"fmt\" \"os\" ) func main() { scanner := bufio.NewScanner(os.Stdin) //这里像个迭代器, 实际是每次for都调用一次Scan, Scan返回这次的token, 即被分割后的字符 //用Text或者Bytes方法返回token. for scanner.Scan() { fmt.Println(scanner.Text()) // Println will add back the final '\\n' } if err := scanner.Err(); err != nil { fmt.Fprintln(os.Stderr, \"reading standard input:\", err) } } 统计字符个数 package main import ( \"bufio\" \"fmt\" \"os\" \"strings\" ) func main() { // An artificial input source. const input = \"Now is the winter of our discontent,\\nMade glorious summer by this sun of York.\\n\" scanner := bufio.NewScanner(strings.NewReader(input)) // Set the split function for the scanning operation. scanner.Split(bufio.ScanWords) // Count the words. count := 0 for scanner.Scan() { count++ } if err := scanner.Err(); err != nil { fmt.Fprintln(os.Stderr, \"reading input:\", err) } fmt.Printf(\"%d\\n\", count) } 也可以自定义分割函数 package main import ( \"bufio\" \"fmt\" \"strconv\" \"strings\" ) func main() { // An artificial input source. const input = \"1234 5678 1234567901234567890\" scanner := bufio.NewScanner(strings.NewReader(input)) // Create a custom split function by wrapping the existing ScanWords function. split := func(data []byte, atEOF bool) (advance int, token []byte, err error) { advance, token, err = bufio.ScanWords(data, atEOF) if err == nil && token != nil { _, err = strconv.ParseInt(string(token), 10, 32) } return } // Set the split function for the scanning operation. scanner.Split(split) // Validate the input for scanner.Scan() { fmt.Printf(\"%s\\n\", scanner.Text()) } if err := scanner.Err(); err != nil { fmt.Printf(\"Invalid input: %s\", err) } } io/ioutil 包括了ReadAll ReadDir ReadFile WriteFile等方法. 还包括一个/dev/null对象: var Discard io.Writer = devNull(0) func NopCloser(r io.Reader) io.ReadCloser func ReadAll(r io.Reader) ([]byte, error) func ReadDir(dirname string) ([]os.FileInfo, error) func ReadFile(filename string) ([]byte, error) func TempDir(dir, prefix string) (name string, err error) func TempFile(dir, pattern string) (f *os.File, err error) func WriteFile(filename string, data []byte, perm os.FileMode) error io io包提供底层的io原语, 主要的工作是对os包的一层封装, 提供接口的抽象 变量 io包里, 定义了一些变量. 是io包持有的一些对象. 主要是一些错误的对象, 其他程序可以直接用. 比如: var EOF = errors.New(\"EOF\") var ErrClosedPipe = errors.New(\"io: read/write on closed pipe\") ... 以Reader为例, 看golang的派生 io里面的方法和结构, 充分展示了golang实现基类和派生类的方式. C++的派生是靠血缘方式, 家族式的 Go的派生是党派方式, 只要你的方法和我的一样, 就是自己人. Reader, 可以认为是个基类 比如, 只要实现了Read方法的类型, 都是Reader: //read到p里, 最大len(p) type Reader interface { Read(p []byte) (n int, err error) } 注: Read, 就是从什么地方, 把data读出来, 放到一个buf里. 和C的read一样, 用户要传入一个buf, 在这里是个切片p []byte, go的切片自带大小, 所以不用传size Read不用等到到最大size, 即len(p)才返回. 只要这次的data到位了, 就返回. Read的实现中, 不能持有p, 即不能对p增加引用. PipeReader, 派生类 Reader的派生类, PipeReader实现了Read方法. 所以虽然形式上PipeReader是个struct, 而Reader是interface, 但因为interface可以是任何东西, 有点类似C语言的void * 所以, PipeReader也是Reader. 所有Reader能适用的地方, PipeReader一样适用. type PipeReader struct { // contains filtered or unexported fields } func (r *PipeReader) Read(data []byte) (n int, err error) Writer和Reader类似, 它有派生类: PipeWriter StringWriter ByteWriter等等 ReadWriter ReadWriter是Reader和Writer的组合 type ReadWriter interface { Reader Writer } WriterTo 一个实现了Reader的类型, 也可以实现WriteTo方法, 从而也是WriterTo 定义这个WriterTo类型, 类型断言会用到. type WriterTo interface { WriteTo(w Writer) (n int64, err error) } ReaderAt 带offset的Reader, 是个接口. 其他基类 Closer: 包装了Close方法的interfacetype Closer interface { Close() error } 从C的概念来的, 指定下次的读写从哪里开始 type Seeker interface { Seek(offset int64, whence int) (int64, error) } 等等 Seeker Seeker决定下次读写的offset. whence表示offset的相对位置, 可以相对文件开头, 当前, 和结尾. type Seeker interface { Seek(offset int64, whence int) (int64, error) } io包的方法 Copy func Copy(dst Writer, src Reader) (written int64, err error) 举例, 这里只是演示, 把一段字符串, copy到标准输出. 因为标准输出也是一个Writer package main import ( \"io\" \"log\" \"os\" \"strings\" ) func main() { r := strings.NewReader(\"some io.Reader stream to be read\\n\") if _, err := io.Copy(os.Stdout, r); err != nil { log.Fatal(err) } } Copy的实现: 上面提到过, WriterTo和Reader可以是同一个类型, 在Copy的实现中, 有这样的类型断言 // copyBuffer is the actual implementation of Copy and CopyBuffer. // if buf is nil, one is allocated. func copyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) { // If the reader has a WriteTo method, use it to do the copy. // Avoids an allocation and a copy. if wt, ok := src.(WriterTo); ok { return wt.WriteTo(dst) } // Similarly, if the writer has a ReadFrom method, use it to do the copy. if rt, ok := dst.(ReaderFrom); ok { return rt.ReadFrom(src) } if buf == nil { //默认32K的buf buf = make([]byte, 32*1024) } for { nr, er := src.Read(buf) if nr > 0 { //这里直接传入切片 buf[0:nr] nw, ew := dst.Write(buf[0:nr]) if nw > 0 { written += int64(nw) } if ew != nil { err = ew break } if nr != nw { err = ErrShortWrite break } } if er == EOF { break } if er != nil { err = er break } } return written, err } Pipe Pipe返回一个管道对, 一个用来读, 一个用来写 func Pipe() (*PipeReader, *PipeWriter) 举例, 创建一对读写pipe, 一个go routine写, 主程序读. package main import ( \"bytes\" \"fmt\" \"io\" ) func main() { r, w := io.Pipe() go func() { fmt.Fprint(w, \"some text to be read\\n\") w.Close() }() buf := new(bytes.Buffer) buf.ReadFrom(r) fmt.Print(buf.String()) } TeeReader package main import ( \"bytes\" \"fmt\" \"io\" \"io/ioutil\" \"log\" \"strings\" ) func main() { r := strings.NewReader(\"some io.Reader stream to be read\\n\") var buf bytes.Buffer tee := io.TeeReader(r, &buf) printall := func(r io.Reader) { b, err := ioutil.ReadAll(r) if err != nil { log.Fatal(err) } fmt.Printf(\"%s\", b) } printall(tee) printall(&buf) } //输出: some io.Reader stream to be read some io.Reader stream to be read container/ring ring是个循环链表. 里面的任何一个元素都可以被用来引用这个ring. 所以不像链表有元素和list两个概念, ring只有一个类型: Ring api type Ring struct { Value interface{} // for use by client; untouched by this library // contains filtered or unexported fields } type Ring func New(n int) *Ring //对每个元素执行f, f不能改变ring本身 func (r *Ring) Do(f func(interface{})) func (r *Ring) Len() int //链接连个ring func (r *Ring) Link(s *Ring) *Ring func (r *Ring) Move(n int) *Ring func (r *Ring) Next() *Ring func (r *Ring) Prev() *Ring func (r *Ring) Unlink(n int) *Ring 例子: 连接两个ring package main import ( \"container/ring\" \"fmt\" ) func main() { // Create two rings, r and s, of size 2 r := ring.New(2) s := ring.New(2) // Get the length of the ring lr := r.Len() ls := s.Len() // Initialize r with 0s for i := 0; i container/list 实现了一个双向链表 对这个链表的遍历: for e := l.Front(); e != nil; e = e.Next() { // do something with e.Value } api //这是个struct, Value并不关心具体的数据类型, 只是以万能类型interface存储. type Element struct { // The value stored with this element. Value interface{} // contains filtered or unexported fields } type Element func (e *Element) Next() *Element func (e *Element) Prev() *Element //也是个struct type List func New() *List func (l *List) Back() *Element func (l *List) Front() *Element func (l *List) Init() *List func (l *List) InsertAfter(v interface{}, mark *Element) *Element func (l *List) InsertBefore(v interface{}, mark *Element) *Element func (l *List) Len() int func (l *List) MoveAfter(e, mark *Element) func (l *List) MoveBefore(e, mark *Element) func (l *List) MoveToBack(e *Element) func (l *List) MoveToFront(e *Element) func (l *List) PushBack(v interface{}) *Element func (l *List) PushBackList(other *List) func (l *List) PushFront(v interface{}) *Element func (l *List) PushFrontList(other *List) func (l *List) Remove(e *Element) interface{} 使用举例 package main import ( \"container/list\" \"fmt\" ) func main() { // Create a new list and put some numbers in it. l := list.New() e4 := l.PushBack(4) e1 := l.PushFront(1) l.InsertBefore(3, e4) l.InsertAfter(2, e1) // Iterate through list and print its contents. for e := l.Front(); e != nil; e = e.Next() { fmt.Println(e.Value) } } container/heap 参考: https://golang.org/pkg/container/heap/ heap是个树, 每个node的值都是它的子树的\"最小值\". 所以根节点是最小的. import \"container/heap\" type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() } 注意, 这里的\"最小值\"的英文表述为\"minimum-valued\" node, 何为最小值? 由heap.Interface里面的sort.Interface说了算. 就是说, heap包的逻辑是, 按照sort的方法, 做成一个最小树. 实现了heap.Interface的任何type都可以是heap Push把一个元素排序后放入树中. Pop把树中的一个元素返回. Less()方法决定返回哪个元素. 树的数组表达 节点在数组中的位置对应它在树中的位置,下标为0 的节点为根节点,下标为1是根的左节点,2为根节点的右节点,依次类推,从左到右的顺序存储树的每一层,包括空节点. min-int树 // This example demonstrates an integer heap built using the heap interface. package main import ( \"container/heap\" \"fmt\" ) // An IntHeap is a min-heap of ints. type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i] 0 { fmt.Printf(\"%d \", heap.Pop(h)) } } //结果 minimum: 1 1 2 3 5 可以用heap来实现优先级队列 // This example demonstrates a priority queue built using the heap interface. package main import ( \"container/heap\" \"fmt\" ) // An Item is something we manage in a priority queue. type Item struct { value string // The value of the item; arbitrary. priority int // The priority of the item in the queue. // The index is needed by update and is maintained by the heap.Interface methods. index int // The index of the item in the heap. } //这个heap来存储上是建立在slice上的? // A PriorityQueue implements heap.Interface and holds Items. type PriorityQueue []*Item func (pq PriorityQueue) Len() int { return len(pq) } //原本head是node的值比其子树要小, 这里\"重载\"了Less方法, 返回大的值, 从而实现先pop大的 func (pq PriorityQueue) Less(i, j int) bool { // We want Pop to give us the highest, not lowest, priority so we use greater than here. return pq[i].priority > pq[j].priority } //为什么不是指针传递? 因为pq是slice吗? func (pq PriorityQueue) Swap(i, j int) { pq[i], pq[j] = pq[j], pq[i] pq[i].index = i pq[j].index = j } //实现了Push和Pop就是heap func (pq *PriorityQueue) Push(x interface{}) { n := len(*pq) //类型断言 item := x.(*Item) item.index = n //用append就能push进树结构? *pq = append(*pq, item) } //实现了Push和Pop就是heap func (pq *PriorityQueue) Pop() interface{} { //怎么隐约感觉这里是deep copy old := *pq n := len(old) //这样就行了? item := old[n-1] item.index = -1 // for safety //返回一个切片? *pq = old[0 : n-1] return item } // update modifies the priority and value of an Item in the queue. func (pq *PriorityQueue) update(item *Item, value string, priority int) { item.value = value item.priority = priority heap.Fix(pq, item.index) } // This example creates a PriorityQueue with some items, adds and manipulates an item, // and then removes the items in priority order. func main() { // Some items and their priorities. items := map[string]int{ \"banana\": 3, \"apple\": 2, \"pear\": 4, } // Create a priority queue, put the items in it, and // establish the priority queue (heap) invariants. pq := make(PriorityQueue, len(items)) i := 0 for value, priority := range items { pq[i] = &Item{ value: value, priority: priority, index: i, } i++ } heap.Init(&pq) // Insert a new item and then modify its priority. item := &Item{ value: \"orange\", priority: 1, } heap.Push(&pq, item) pq.update(item, item.value, 5) // Take the items out; they arrive in decreasing priority order. for pq.Len() > 0 { item := heap.Pop(&pq).(*Item) fmt.Printf(\"%.2d:%s \", item.priority, item.value) } } 对上面几个问题的解释: 这里的head用数组slice做底层存储 heap.Push()先调用具体实例的Push()实现, 再调用up()排序 heap.Pop()先调用具体实例的Swap()方法, 再用down方法排序, 再调用具体实例的Pop() up()和down()是src/container/heap/heap.go的排序实现 // Push pushes the element x onto the heap. // The complexity is O(log n) where n = h.Len(). func Push(h Interface, x interface{}) { h.Push(x) up(h, h.Len()-1) } // Pop removes and returns the minimum element (according to Less) from the heap. // The complexity is O(log n) where n = h.Len(). // Pop is equivalent to Remove(h, 0). func Pop(h Interface) interface{} { n := h.Len() - 1 //这里把0号node和len()-1互换了, 正好对应上面的item := old[n-1]直接取 h.Swap(0, n) //头节点没了, 肯定要重新排序 down(h, 0, n) return h.Pop() } sort 提供对切片和自定义的结构的排序. 支持对基本类型的排序 排序是原地排序, 即直接修改底层的数组 func Float64s(a []float64) func Ints(a []int) func IsSorted(data Interface) bool //返回满足条件的下标 func Search(n int, f func(int) bool) int //在已经排好序的slice里search func SearchInts(a []int, x int) int func SearchStrings(a []string, x string) int func Strings(a []string) 比如: package main import ( \"fmt\" \"math\" \"sort\" ) func main() { s := []float64{5.2, -1.3, 0.7, -3.8, 2.6} // unsorted //对s排序, 升序排序 sort.Float64s(s) //排好序后还是s fmt.Println(s) s = []float64{math.Inf(1), math.NaN(), math.Inf(-1), 0.0} // unsorted sort.Float64s(s) fmt.Println(s) } [-3.8 -1.3 0.7 2.6 5.2] [NaN -Inf 0 +Inf] 对struct排序 //传入一个slice, 按照less函数排序 func Slice(slice interface{}, less func(i, j int) bool) //带stable字眼的表示排序是稳定的 func SliceStable(slice interface{}, less func(i, j int) bool) 比如: package main import ( \"fmt\" \"sort\" ) func main() { people := []struct { Name string Age int }{ {\"Gopher\", 7}, {\"Alice\", 55}, {\"Vera\", 24}, {\"Bob\", 75}, } sort.Slice(people, func(i, j int) bool { return people[i].Name 通用排序 //通过调用data.Len, data.Less, data.Swap来进行排序 func Sort(data Interface) func Stable(data Interface) 对外接口 一个用户自定义的数据表达, 要满足sort.Interface要求, 就能被排序. 要求底层承载数据的东西, 是按整数index寻址的. 也就是说, 必须是数组. type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with // index i should sort before the element with index j. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } "},"notes/golang_我的反射代码.html":{"url":"notes/golang_我的反射代码.html","title":"我的反射代码","keywords":"","body":" 背景 ToObject FromObject 测试程序 背景 在早期的gshellos的实现中, 我们用了tengo解释器来在gshell框架下解释运行.tengo代码. tengo使用tengo object来表示对象, 比如int在tengo中是tengo.Int. ToObject ToObject函数的作用是把一个原生的go对象转换为tengo对象, 支持简单的int byte bool等基础value, 以及map slice等复合value的组合. ToObject函数是递归的, 并且设计了fast path和slow path来做value的转换. fast path用类型断言 slow path用reflect 下面我把代码贴出来, 用作后面参考. // ToObject traverses the value v recursively and converts the value to tengo object. // Pointer values encode as the value pointed to. // A nil pointer/interface/slice/map encodes as the tengo.UndefinedValue value. // Struct values encode as tengo map. Only exported field can be encoded with filed names as map keys but with its first letter turned into lower case. // e.g. struct{Field1: 123, AnotherField: 456} will be converted to tengo map{field: 123, anotherField: 456} // int, string, float, bool, Time.time, error encodes as their corresponding tengo object. // slices encode as tengo Array, maps with key as string encode as tengo Map, returns ErrInvalidType if key type in map is not string. // Returns ErrInvalidType on unsupported value type. // Note as ToObject follows pointers, be careful with cyclic pointer references which results in infinite loop. func ToObject(v interface{}) (tengo.Object, error) { // fast path switch v := v.(type) { case nil: return tengo.UndefinedValue, nil case string: if len(v) > tengo.MaxStringLen { return nil, tengo.ErrStringLimit } return &tengo.String{Value: v}, nil case int64: return &tengo.Int{Value: v}, nil case int: return &tengo.Int{Value: int64(v)}, nil case bool: if v { return tengo.TrueValue, nil } return tengo.FalseValue, nil case rune: return &tengo.Char{Value: v}, nil case byte: return &tengo.Char{Value: rune(v)}, nil case float64: return &tengo.Float{Value: v}, nil case *UserFunction: return v, nil case *tengo.UserFunction: return v, nil case tengo.Object: return v, nil case tengo.CallableFunc: if v == nil { return tengo.UndefinedValue, nil } return &tengo.UserFunction{Value: v}, nil case []byte: if v == nil { return tengo.UndefinedValue, nil } if len(v) > tengo.MaxBytesLen { return nil, tengo.ErrBytesLimit } return &tengo.Bytes{Value: v}, nil case error: if v == nil { return tengo.UndefinedValue, nil } return &tengo.Error{Value: &tengo.String{Value: v.Error()}}, nil case map[string]tengo.Object: if v == nil { return tengo.UndefinedValue, nil } return &tengo.Map{Value: v}, nil case map[string]int: if v == nil { return tengo.UndefinedValue, nil } kv := make(map[string]tengo.Object, len(v)) for vk, vv := range v { vo, err := ToObject(vv) if err != nil { return nil, err } kv[vk] = vo } return &tengo.Map{Value: kv}, nil case map[string]int64: if v == nil { return tengo.UndefinedValue, nil } kv := make(map[string]tengo.Object, len(v)) for vk, vv := range v { vo, err := ToObject(vv) if err != nil { return nil, err } kv[vk] = vo } return &tengo.Map{Value: kv}, nil case map[string]float64: if v == nil { return tengo.UndefinedValue, nil } kv := make(map[string]tengo.Object, len(v)) for vk, vv := range v { vo, err := ToObject(vv) if err != nil { return nil, err } kv[vk] = vo } return &tengo.Map{Value: kv}, nil case map[string]string: if v == nil { return tengo.UndefinedValue, nil } kv := make(map[string]tengo.Object, len(v)) for vk, vv := range v { vo, err := ToObject(vv) if err != nil { return nil, err } kv[vk] = vo } return &tengo.Map{Value: kv}, nil case map[string]interface{}: if v == nil { return tengo.UndefinedValue, nil } kv := make(map[string]tengo.Object, len(v)) for vk, vv := range v { vo, err := ToObject(vv) if err != nil { return nil, err } kv[vk] = vo } return &tengo.Map{Value: kv}, nil case []tengo.Object: if v == nil { return tengo.UndefinedValue, nil } return &tengo.Array{Value: v}, nil case []int: if v == nil { return tengo.UndefinedValue, nil } arr := make([]tengo.Object, len(v)) for i, e := range v { vo, err := ToObject(e) if err != nil { return nil, err } arr[i] = vo } return &tengo.Array{Value: arr}, nil case []int64: if v == nil { return tengo.UndefinedValue, nil } arr := make([]tengo.Object, len(v)) for i, e := range v { vo, err := ToObject(e) if err != nil { return nil, err } arr[i] = vo } return &tengo.Array{Value: arr}, nil case []float64: if v == nil { return tengo.UndefinedValue, nil } arr := make([]tengo.Object, len(v)) for i, e := range v { vo, err := ToObject(e) if err != nil { return nil, err } arr[i] = vo } return &tengo.Array{Value: arr}, nil case []string: if v == nil { return tengo.UndefinedValue, nil } arr := make([]tengo.Object, len(v)) for i, e := range v { vo, err := ToObject(e) if err != nil { return nil, err } arr[i] = vo } return &tengo.Array{Value: arr}, nil case []interface{}: if v == nil { return tengo.UndefinedValue, nil } arr := make([]tengo.Object, len(v)) for i, e := range v { vo, err := ToObject(e) if err != nil { return nil, err } arr[i] = vo } return &tengo.Array{Value: arr}, nil case time.Time: return &tengo.Time{Value: v}, nil } // slow path rv := reflect.ValueOf(v) switch rv.Kind() { case reflect.Ptr, reflect.Interface, reflect.Map, reflect.Slice: if rv.IsNil() { return tengo.UndefinedValue, nil } } rv = reflect.Indirect(rv) switch rv.Kind() { case reflect.Bool: if rv.Bool() { return tengo.TrueValue, nil } return tengo.FalseValue, nil case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return &tengo.Int{Value: rv.Int()}, nil case reflect.Uint, reflect.Uintptr, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64: return &tengo.Int{Value: int64(rv.Uint())}, nil case reflect.Float32, reflect.Float64: return &tengo.Float{Value: rv.Float()}, nil case reflect.Array, reflect.Slice: arr := make([]tengo.Object, rv.Len()) for i := 0; i FromObject FromObject是ToObject的反过程. // FromObject parses the tengo object and stores the result in the value pointed to by v. // FromObject uses the inverse of the encodings that ToObject uses, allocating maps, slices, and pointers as necessary. // // FromObject converts tengo Map object into a struct by map look up with field names as keys. // Filed name and tengo map key are matched in a way that the first letter is insensitive. // e.g. both tengo map{name: \"san\"} and map{Name: \"san\"} can be converted to struct{Name: \"san\"} // If v is nil or not a pointer, ObjectToValue returns an ErrInvalidPtr error. // If o is already a tengo object, it is copied to the value that v points to. // If v represents a *tengo.CallableFunc, and o is a tengo UserFunction object, the CallableFunc f will be copied to where v points. // Returns ErrNotConvertibleType if o can not be converted to v, e.g. you are trying to get a map vale from tengo Array object. // Not supported value types: // interface, chan, complex, func // In particular, interface error is not convertible. func FromObject(v interface{}, o tengo.Object) error { if o == tengo.UndefinedValue { return nil // ignore undefined value } // fast path switch ptr := v.(type) { case *int: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToInt(o); ok { *ptr = v return nil } case *int64: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToInt64(o); ok { *ptr = v return nil } case *string: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToString(o); ok { *ptr = v return nil } case *float64: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToFloat64(o); ok { *ptr = v return nil } case *bool: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToBool(o); ok { *ptr = v return nil } case *rune: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToRune(o); ok { *ptr = v return nil } case *[]byte: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToByteSlice(o); ok { *ptr = v return nil } case *time.Time: if ptr == nil { return ErrInvalidPtr } if v, ok := tengo.ToTime(o); ok { *ptr = v return nil } case *[]int: if ptr == nil { return ErrInvalidPtr } toA := func(objArray []tengo.Object) bool { array := make([]int, len(objArray)) for i, o := range objArray { v, ok := tengo.ToInt(o) if !ok { return false } array[i] = v } *ptr = array return true } switch o := o.(type) { case *tengo.Array: if toA(o.Value) { return nil } case *tengo.ImmutableArray: if toA(o.Value) { return nil } } case *[]int64: if ptr == nil { return ErrInvalidPtr } toA := func(objArray []tengo.Object) bool { array := make([]int64, len(objArray)) for i, o := range objArray { v, ok := tengo.ToInt64(o) if !ok { return false } array[i] = v } *ptr = array return true } switch o := o.(type) { case *tengo.Array: if toA(o.Value) { return nil } case *tengo.ImmutableArray: if toA(o.Value) { return nil } } case *[]float64: if ptr == nil { return ErrInvalidPtr } toA := func(objArray []tengo.Object) bool { array := make([]float64, len(objArray)) for i, o := range objArray { v, ok := tengo.ToFloat64(o) if !ok { return false } array[i] = v } *ptr = array return true } switch o := o.(type) { case *tengo.Array: if toA(o.Value) { return nil } case *tengo.ImmutableArray: if toA(o.Value) { return nil } } case *[]string: if ptr == nil { return ErrInvalidPtr } toA := func(objArray []tengo.Object) bool { array := make([]string, len(objArray)) for i, o := range objArray { v, ok := tengo.ToString(o) if !ok { return false } array[i] = v } *ptr = array return true } switch o := o.(type) { case *tengo.Array: if toA(o.Value) { return nil } case *tengo.ImmutableArray: if toA(o.Value) { return nil } } case *map[string]int: if ptr == nil { return ErrInvalidPtr } toM := func(objMap map[string]tengo.Object) bool { mp := make(map[string]int, len(objMap)) for k, o := range objMap { v, ok := tengo.ToInt(o) if !ok { return false } mp[k] = v } *ptr = mp return true } switch o := o.(type) { case *tengo.Map: if toM(o.Value) { return nil } case *tengo.ImmutableMap: if toM(o.Value) { return nil } } case *map[string]int64: if ptr == nil { return ErrInvalidPtr } toM := func(objMap map[string]tengo.Object) bool { mp := make(map[string]int64, len(objMap)) for k, o := range objMap { v, ok := tengo.ToInt64(o) if !ok { return false } mp[k] = v } *ptr = mp return true } switch o := o.(type) { case *tengo.Map: if toM(o.Value) { return nil } case *tengo.ImmutableMap: if toM(o.Value) { return nil } } case *map[string]float64: if ptr == nil { return ErrInvalidPtr } toM := func(objMap map[string]tengo.Object) bool { mp := make(map[string]float64, len(objMap)) for k, o := range objMap { v, ok := tengo.ToFloat64(o) if !ok { return false } mp[k] = v } *ptr = mp return true } switch o := o.(type) { case *tengo.Map: if toM(o.Value) { return nil } case *tengo.ImmutableMap: if toM(o.Value) { return nil } } case *map[string]string: if ptr == nil { return ErrInvalidPtr } toM := func(objMap map[string]tengo.Object) bool { mp := make(map[string]string, len(objMap)) for k, o := range objMap { v, ok := tengo.ToString(o) if !ok { return false } mp[k] = v } *ptr = mp return true } switch o := o.(type) { case *tengo.Map: if toM(o.Value) { return nil } case *tengo.ImmutableMap: if toM(o.Value) { return nil } } case *tengo.Object: if ptr == nil { return ErrInvalidPtr } *ptr = o return nil case *tengo.CallableFunc: if ptr == nil { return ErrInvalidPtr } if f, ok := o.(*tengo.UserFunction); ok { *ptr = f.Value return nil } default: // slow path rptr := reflect.ValueOf(v) if rptr.Kind() != reflect.Ptr || rptr.IsNil() { return ErrInvalidPtr } rv := rptr.Elem() switch rv.Kind() { case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: if v, ok := tengo.ToInt64(o); ok { rv.SetInt(v) return nil } case reflect.Uint, reflect.Uintptr, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64: if v, ok := tengo.ToInt64(o); ok { rv.SetUint(uint64(v)) return nil } case reflect.Float32, reflect.Float64: if v, ok := tengo.ToFloat64(o); ok { rv.SetFloat(v) return nil } case reflect.Ptr: if rv.IsNil() { rv.Set(reflect.New(rv.Type().Elem())) } if err := FromObject(rv.Interface(), o); err == nil { return nil } case reflect.Array, reflect.Slice: toA := func(objArray []tengo.Object) bool { array := reflect.MakeSlice(rv.Type(), len(objArray), len(objArray)) for i, o := range objArray { if o == tengo.UndefinedValue { continue } elem := array.Index(i) if err := FromObject(elem.Addr().Interface(), o); err != nil { return false } } rv.Set(array) return true } switch o := o.(type) { case *tengo.Array: if toA(o.Value) { return nil } case *tengo.ImmutableArray: if toA(o.Value) { return nil } } case reflect.Map: toM := func(objMap map[string]tengo.Object) bool { typ := rv.Type() if typ.Key().Kind() != reflect.String { return false } mp := reflect.MakeMapWithSize(typ, len(objMap)) elemPtr := reflect.New(typ.Elem()) for k, o := range objMap { if o == tengo.UndefinedValue { continue } if err := FromObject(elemPtr.Interface(), o); err != nil { return false } mp.SetMapIndex(reflect.ValueOf(k), elemPtr.Elem()) } rv.Set(mp) return true } switch o := o.(type) { case *tengo.Map: if toM(o.Value) { return nil } case *tengo.ImmutableMap: if toM(o.Value) { return nil } } case reflect.Struct: toStruct := func(objMap map[string]tengo.Object) bool { typ := rv.Type() for i := 0; i 测试程序 package gshellos import ( \"errors\" \"fmt\" \"reflect\" \"regexp\" \"strings\" \"testing\" \"time\" \"github.com/d5/tengo/v2\" ) func TestToObject(t *testing.T) { testb := true var testi uint32 = 88 testf := 33.33 var itf interface{} itf = testf type student struct { Name string Age int Scores map[string]float32 Friends []student } empty := struct { A string B int C float64 D []int E []int64 F []float64 G []tengo.Object H []string I []byte J []interface{} K tengo.CallableFunc L error M map[string]int N map[string]int64 O map[string]float64 P map[string]string Q map[string]interface{} R map[string]tengo.Object S *int }{} cases := []struct { v interface{} want string }{ {&tengo.Int{Value: 123}, `&tengo.Int{ObjectImpl:tengo.ObjectImpl{}, Value:123}`}, {nil, `&tengo.Undefined{ObjectImpl:tengo.ObjectImpl{}}`}, {1, `&tengo.Int{ObjectImpl:tengo.ObjectImpl{}, Value:1}`}, {\"hello world\", `&tengo.String{ObjectImpl:tengo.ObjectImpl{}, Value:\"hello world\", runeStr:[]int32(nil)}`}, {99.99, `&tengo.Float{ObjectImpl:tengo.ObjectImpl{}, Value:99.99}`}, {false, `&tengo.Bool{ObjectImpl:tengo.ObjectImpl{}, value:false}`}, {'@', `&tengo.Char{ObjectImpl:tengo.ObjectImpl{}, Value:64}`}, {byte(56), `&tengo.Char{ObjectImpl:tengo.ObjectImpl{}, Value:56}`}, {[]byte(\"567\"), `&tengo.Bytes{ObjectImpl:tengo.ObjectImpl{}, Value:[]uint8{0x35, 0x36, 0x37}}`}, {errors.New(\"err\"), `&tengo.Error{ObjectImpl:tengo.ObjectImpl{}, Value:\\(\\*tengo.String\\)\\(0x[0-9a-f]+\\)}`}, {map[string]int{\"zhangsan\": 30, \"lisi\": 35}, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{(\"((zhangsan)|(lisi))\":\\(\\*tengo.Int\\)\\(0x[0-9a-f]+\\),? ?){2}}}$`}, {map[string]int64{\"zhangsan\": 30, \"lisi\": 35}, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{(\"((zhangsan)|(lisi))\":\\(\\*tengo.Int\\)\\(0x[0-9a-f]+\\),? ?){2}}}$`}, {map[string]string{\"zhangsan\": \"teacher\", \"lisi\": \"student\"}, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{(\"((zhangsan)|(lisi))\":\\(\\*tengo.String\\)\\(0x[0-9a-f]+\\),? ?){2}}}$`}, {map[string]interface{}{\"zhangsan\": 30, \"lisi\": \"student\"}, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{(\"((zhangsan)|(lisi))\":\\(\\*tengo.((String)|(Int))\\)\\(0x[0-9a-f]+\\),? ?){2}}}$`}, {map[string]float64{\"zhangsan\": 30.1, \"lisi\": 35.2}, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{(\"((zhangsan)|(lisi))\":\\(\\*tengo.Float\\)\\(0x[0-9a-f]+\\),? ?){2}}}$`}, {[2]int{11, 13}, `^&tengo.Array{ObjectImpl:tengo.ObjectImpl{}, Value:\\[\\]tengo.Object{(\\(\\*tengo.Int\\)\\(0x[0-9a-f]+\\),? ?){2}}}$`}, {[]int{101, 103, 105}, `^&tengo.Array{ObjectImpl:tengo.ObjectImpl{}, Value:\\[\\]tengo.Object{(\\(\\*tengo.Int\\)\\(0x[0-9a-f]+\\),? ?){3}}}$`}, {[]int64{101, 103, 105}, `^&tengo.Array{ObjectImpl:tengo.ObjectImpl{}, Value:\\[\\]tengo.Object{(\\(\\*tengo.Int\\)\\(0x[0-9a-f]+\\),? ?){3}}}$`}, {[]float64{101.1, 103.1, 105.1}, `^&tengo.Array{ObjectImpl:tengo.ObjectImpl{}, Value:\\[\\]tengo.Object{(\\(\\*tengo.Float\\)\\(0x[0-9a-f]+\\),? ?){3}}}$`}, {[]string{\"ni\", \"hao\", \"ma\"}, `^&tengo.Array{ObjectImpl:tengo.ObjectImpl{}, Value:\\[\\]tengo.Object{(\\(\\*tengo.String\\)\\(0x[0-9a-f]+\\),? ?){3}}}$`}, {[]interface{}{\"ni\", \"hao\", 123}, `^&tengo.Array{ObjectImpl:tengo.ObjectImpl{}, Value:\\[\\]tengo.Object{(\\(\\*tengo.((String)|(Int))\\)\\(0x[0-9a-f]+\\),? ?){3}}}$`}, {time.Now(), `^&tengo.Time{ObjectImpl:tengo.ObjectImpl{}, Value:time.Time{.*}}$`}, {&testb, `&tengo.Bool{ObjectImpl:tengo.ObjectImpl{}, value:true}`}, {int16(55), `&tengo.Int{ObjectImpl:tengo.ObjectImpl{}, Value:55}`}, {&testi, `&tengo.Int{ObjectImpl:tengo.ObjectImpl{}, Value:88}`}, {&testf, `&tengo.Float{ObjectImpl:tengo.ObjectImpl{}, Value:33.33}`}, {itf, `&tengo.Float{ObjectImpl:tengo.ObjectImpl{}, Value:33.33}`}, {student{\"lisi\", 20, map[string]float32{\"yuwen\": 86.5, \"shuxue\": 83.1}, []student{{Name: \"zhangsan\"}, {Name: \"wangwu\"}}}, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{(\"((age)|(friends)|(name)|(scores))\":\\(\\*tengo.((Int)|Array|String|Map)\\)\\(0x[0-9a-f]+\\),? ?){4}}}$`}, {map[string]student{\"zhangsan\": {Name: \"zhangsan\"}, \"lisi\": {Name: \"lisi\"}}, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{(\"((lisi)|(zhangsan))\":\\(\\*tengo.Map\\)\\(0x[0-9a-f]+\\),? ?){2}}}$`}, {empty, `^&tengo.Map{ObjectImpl:tengo.ObjectImpl{}, Value:map\\[string\\]tengo.Object{\"a\":\\(\\*tengo.String\\)\\(0x[0-9a-f]+\\), \"b\":\\(\\*tengo.Int\\)\\(0x[0-9a-f]+\\), \"c\":\\(\\*tengo.Float\\)\\(0x[0-9a-f]+\\), (\"[d-s]{1}\":\\(\\*tengo.Undefined\\)\\(0x[0-9a-f]+\\),? ?){16}}}$`}, } for _, c := range cases { if len(c.want) == 0 { t.Error(\"empty want\") } obj, err := ToObject(c.v) if err != nil { t.Error(err) continue } got := fmt.Sprintf(\"%#v\", obj) //t.Logf(\"%v\\n\", obj) if got == c.want { continue } re := regexp.MustCompile(c.want) if !re.MatchString(got) { t.Errorf(\"want: %s, got: %s\", c.want, got) } } _, err := ToObject([]complex64{complex(1, -2), complex(1.0, -1.4)}) if err != ErrInvalidType { t.Error(\"complex supported?\") } _, err = ToObject(map[string]interface{}{\"a\": complex(1, -2), \"b\": complex(1.0, -1.4)}) if err != ErrInvalidType { t.Error(\"complex supported?\") } } func TestFromObject(t *testing.T) { obj, _ := ToObject(55) emptyCases := []interface{}{ (*int)(nil), (*int64)(nil), (*string)(nil), (*float64)(nil), (*bool)(nil), (*rune)(nil), (*[]byte)(nil), (*time.Time)(nil), (*[]int)(nil), (*[]int64)(nil), (*[]float64)(nil), (*[]string)(nil), (*map[string]int)(nil), (*map[string]int64)(nil), (*map[string]float64)(nil), (*map[string]string)(nil), (*tengo.Object)(nil), (*tengo.CallableFunc)(nil), (*int32)(nil), nil, } for _, c := range emptyCases { err := FromObject(c, obj) if err != ErrInvalidPtr { t.Fatal(\"empty ptr error expected\") } } var got tengo.Object err := FromObject(&got, obj) if err != nil { t.Error(err) } if !reflect.DeepEqual(got, obj) { t.Errorf(\"want: %#v, got: %#v\", obj, got) } testf := func(args ...tengo.Object) (tengo.Object, error) { return nil, nil } var gotf func(args ...tengo.Object) (tengo.Object, error) fobj, err := ToObject(testf) if err != nil { t.Error(err) } err = FromObject(&gotf, fobj) if err != nil { t.Error(err) } var itf interface{} = gotf gotstring := fmt.Sprintf(\"%#v\", itf) wantstring := `(func(...tengo.Object) (tengo.Object, error))` if !strings.Contains(gotstring, wantstring) { t.Errorf(\"want: %s, got: %s\", wantstring, gotstring) } err = FromObject(&gotf, obj) if !errors.As(err, &ErrNotConvertibleType{}) { t.Error(err) } type student struct { Name string Age int Scores map[string]float32 Classmates []student Deskmate *student Friends map[string]*student } studentA := student{ \"lisi\", 20, map[string]float32{\"yuwen\": 86.5, \"shuxue\": 83.1}, []student{{Name: \"zhangsan\"}, {Name: \"wangwu\"}}, nil, nil, } studentB := student{ \"zhangsan\", 21, map[string]float32{\"yuwen\": 78.5, \"shuxue\": 96.1}, []student{{Name: \"lisi\"}, {Name: \"wangwu\"}}, &studentA, map[string]*student{\"si\": &studentA}, } cases := []interface{}{ \"hello world\", 55, int64(33), 55.77, true, 'U', []byte{1, 2, 3, 4, 5}, time.Now(), []int{22, 33, 44}, []int64{22, 33, 44}, []float64{22.1, 33.2, 44.9}, []string{\"ni\", \"hao\", \"ma\"}, map[string]int{\"A\": 1, \"b\": 15}, map[string]int64{\"A\": 1, \"b\": 15}, map[string]float64{\"a\": 1.54, \"U\": 3.14}, map[string]string{\"a\": \"12345\", \"U\": \"hello world\"}, int16(12), uint16(12), float32(1.2345), studentB, studentA, } for _, c := range cases { t.Logf(\"c: %#v\", c) obj, err := ToObject(c) if err != nil { t.Fatal(err) } t.Logf(\"obj: %#v\", obj) ptr := reflect.New(reflect.TypeOf(c)) err = FromObject(ptr.Interface(), obj) if err != nil { t.Error(err) continue } v := ptr.Elem().Interface() t.Logf(\"v: %#v\", v) if !reflect.DeepEqual(c, v) { t.Errorf(\"want: %#v, got: %#v\", c, v) } } //t.Error(\"err\") } "},"notes/golang_问答.html":{"url":"notes/golang_问答.html","title":"问答","keywords":"","body":" 用range迭代一个map的时候, 删除或者新增key安全吗? net/Conn可以多个goroutine同时读写吗? fmt.Println并发安全吗? write系统调用是原子的吗? System call atomicity 用range迭代一个map的时候, 删除或者新增key安全吗? 比如下面的代码: for key := range m { if key.expired() { delete(m, key) } } 答: 安全. 删除一个还没有被loop到的key, range保证不会这个key不会被loop到; 新增一个key, 则可能会也可能不会被loop到. 因为map是hash桶, loop随机选择一个index然后依次看桶里的元素. The iteration order over maps is not specified and is not guaranteed to be the same from one iteration to the next. If map entries that have not yet been reached are removed during iteration, the corresponding iteration values will not be produced. If map entries are created during iteration, that entry may be produced during the iteration or may be skipped. The choice may vary for each entry created and from one iteration to the next. If the map is nil, the number of iterations is 0. 参考: stackoverflow net/Conn可以多个goroutine同时读写吗? 可以, Conn是并发安全的 Multiple goroutines may invoke methods on a Conn simultaneously. 参考笔记: 网络杂记2.md, 搜多线程能不能同时写同一个socket fmt.Println并发安全吗? 不安全. 见讨论: https://stackoverflow.com/questions/14694088/is-it-safe-for-more-than-one-goroutine-to-print-to-stdout go文档种, 并发安全的api都会说的; 没说的都是并发不安全的. This is an instance of a more universal Go documentation rule: Things are not safe for concurrent access unless specified otherwise or where obvious from context. Everything fmt does falls back to w.Write() as can be seen here. Because there's no locking around it, everything falls back to the implementation of Write(). As there is still no locking (for Stdout at least), there is no guarantee your output will not be mixed. I'd recommend using a global log routine. Furthermore, if you simply want to log data, use the log package, which locks access to the output properly. See the implementation for reference. write系统调用是原子的吗? 答: 好像应该是, 但实际上并不是; 但对于append模式下的文件来说, 实际上也是 https://cs61.seas.harvard.edu/site/2018/Storage4/#:~:text=System%20call%20atomicity,write%20%2C%20should%20have%20atomic%20effect. System call atomicity Unix file system system calls, such as read and write, should have atomic effect. Atomicity is a correctness property that concerns concurrency—the behavior of a system when multiple computations are happening at the same time. (For example, multiple programs have the file open at the same time.) An operation is atomic, or has atomic effect, if it always behaves as if it executes without interruption, at one precise moment in time, with no other operation happening. Atomicity is good because it makes complex behavior much easier to understand. The standards that govern Unix say reads and writes should have atomic effect. It is the operating system kernel’s job to ensure this atomic effect, perhaps by preventing different programs from read or writing to the same file at the same time. Unfortunately for our narrative, experiment shows that on Linux many write system calls do not have atomic effect, meaning Linux has bugs. But writes made in “append mode” (open(… O_APPEND) or fopen(…, \"a\")) do have atomic effect. In this mode, which is frequently used for log files, writes are always placed at the end of the open file, after all other data. "},"notes/golang_高效go.html":{"url":"notes/golang_高效go.html","title":"高效go","keywords":"","body":" 高效go web服务器例子 代码 运行 panic流程和普通执行流程 panic recover recover里面可以改变量值 总结 错误处理 error定义和使用 errors包 自己实现error接口 error和类型断言的例子 进一步看error如何返回的 错误处理化简 channel和并发 channel channel用于同步 channel用于semaphore 一个channel有多个goroutine接收 函数和channel都是first class值: channel in channel 通道in通道的另一个例子 分割和并发 用channel管理message buffer 接口嵌套 结构体嵌套 例子 logger 接口和方法 即使一个int类型也可以带方法 chan带方法 函数也可以带方法!!! 多态 接口和类型断言 方法 接口 gofmt 注释即文档 if可以有初始化语句 for是三种C循环的统一 switch接受非常量 多返回值 defer 用defer做函数trace 在panic场景下, defer的最大好处是panic链上的defer都会被调用到 new和make分配数据 new 数组和切片的区别 make 数组 切片 map 打印 append和...扩展 全局变量初始化和init 高效go https://golang.org/doc/effective_go.html#concurrency web服务器例子 这个web服务器, 利用了chart.apis.google.com提供的api, 把文本转化成二维码. 但你需要把data都放到URL中去做query. 代码 下面的代码, 可以把文本的输入, 通过google的api, 转换成一个QR code. 然后你就可以用手机扫描这个文本类型的QR码, 就能看到对应的文本 package main //这几个库都是标准库 import ( \"flag\" \"html/template\" \"log\" \"net/http\" ) //这里设置默认的http port是1718 var addr = flag.String(\"addr\", \":1718\", \"http service address\") // Q=17, R=18 //根据下面的描述生成模板, 这个模板html被server执行来显示这个页面 var templ = template.Must(template.New(\"qr\").Parse(templateStr)) func main() { flag.Parse() //把函数QR挂到http的根目录 http.Handle(\"/\", http.HandlerFunc(QR)) //开始运行这个server err := http.ListenAndServe(*addr, nil) //QR函数接收到http的request, 里面包含了data if err != nil { log.Fatal(\"ListenAndServe:\", err) } } func QR(w http.ResponseWriter, req *http.Request) { //data从一个叫s的表格而来 templ.Execute(w, req.FormValue(\"s\")) } // html/template很强大, 这里只用了一点点. // 它把req.FormValue(\"s\")返回来的data, 写入下面的模板中 const templateStr = ` QR Link Generator {{if .}} {{.}} {{end}} 具体的template用法在此 运行 #把上面的代码保存为goweb.go #代码格式化 gofmt -w goweb.go #编译 go build goweb.go #直接运行 ./goweb 浏览器打开http://192.168.56.101:1718/, 这个ip就是运行goweb的机器的ip. 会有个很简单的输入框, 输入一些文本后点Show QR就能显示二维码 手机扫描二维码就能还原文本. panic流程和普通执行流程 比如下面的流程: a{ b{ defer c{ recover() }() d{ e{ } f{ } } } g{ } } 比如d()里面panic了 正常的执行流程, 是有上有下的: 先深度执行到f(), 然后return路径沿途返回 panic流程一定是一直向上的, 如果沿途的defer里面没有recover, panic流程向上回溯到这个goroutine的顶层函数停止. 比如在e()里面panic, 它后面的函数就不执行了, 直接向上回溯, 而且只有沿途的defer函数会被执行: While executing a function F, an explicit call to panic or a run-time panic terminates the execution of F. Any functions deferred by F are then executed as usual. Next, any deferred functions run by F's caller are run, and so on up to any deferred by the top-level function in the executing goroutine. At that point, the program is terminated and the error condition is reported, including the value of the argument to panic. This termination sequence is called panicking. recover()阻止了panic的向上的流程, 还是比如e()中panic了, 但在b()的defer列表里, 要执行的c()里面recover, 那么b()正常返回到a(), 接着正常向下执行g() panic panic是go的内建函数, 用于在程序无法运行下去的时候退出 var user = os.Getenv(\"USER\") func init() { if user == \"\" { panic(\"no value for $USER\") } } 那么panic的时候, 执行了什么? panic立即终止执行当前的函数, 向上回溯当前goroutine的调用栈, 依次执行沿途的deferred函数, 然后die. 什么时候隐含有panic? 比如: 类型断言失败, 且没有用ok捕捉第二个返回值 slice越界 recover 可以在panic之后, 用recover恢复go的控制权. 这要求recover要在defer的函数里执行, 因为只有沿途的deferred函数会被panic执行. 在这个例子中: server的一个worker挂了, 调用了panic, 在它的defer函数里, 用recover重新获取执行权. recover函数停止panic发起的unwinding调用栈, 返回当时传给panic的参数. 这里recover停止panic, 效果是干净的关闭失败的goroutine, 其他的goroutien不受影响. recover只在defer的函数里调用才有用. 不是defer的函数, recover什么都不做, 直接返回nil. func server(workChan 注意, 上面的表述中, recover只有在defer的函数里面被调用, 才能生效. 比如下面的代码, recover()什么都不做. 因为它本身就是defer的函数, 而不是被defer的函数调用. package main func main() { defer recover() panic(\"panic\") } 正确的写法是 package main func main() { defer func() { recover() }() panic(\"panic\") } If recover is called outside the deferred function it will not stop a panicking sequence. 所以go的panic加recover的效果, 和C的longjump有点像. 这里补充一下, 如果没有这个recover, 很可能因为这个goroutine调用了panic, 导致整个程序退出. 因为panic会依次回溯defer的函数, 遇到这里的recover, 就停止回溯. 效果就是在safelyDo这一层级停止panic, 程序从此返回, 这个goroutine终结, 但整个程序继续运行. recover里面可以改变量值 // Error is the type of a parse error; it satisfies the error interface. type Error string func (e Error) Error() string { return string(e) } // error is a method of *Regexp that reports parsing errors by // panicking with an Error. func (regexp *Regexp) error(err string) { panic(Error(err)) } // re模块调用error方法时, 就会调用panic // error方法时小写的, 它是个私有方法.和builtin的error重名了, 但没影响? if pos == 0 { re.error(\"'*' illegal at start of expression\") } // Compile returns a parsed representation of the regular expression. func Compile(str string) (regexp *Regexp, err error) { regexp = new(Regexp) // doParse will panic if there is a parse error. defer func() { if e := recover(); e != nil { //recover里面, 依然可以改变量值 regexp = nil // Clear return value. //如果断言失败, 会再次触发panic //这里的作用是, 其他错误情况下, 会继续panic err = e.(Error) // Will re-panic if not a parse error. } }() return regexp.doParse(str), nil } 这里的第二次panic, 和第一次panic一起, 会被crash report记录, 但他们的值不通. 总结 panic和recover常组合用来错误处理, 而不是真正的停止程序运行. 错误处理 先看看C语言版本的open: 成功返回fd, 失败返回-1; 需要单独查errno才能知道失败的原因 Linux Mint 19.1 Tessa $ man 2 open OPEN(2) Linux Programmer's Manual OPEN(2) NAME open, openat, creat - open and possibly create a file SYNOPSIS #include #include #include int open(const char *pathname, int flags); int open(const char *pathname, int flags, mode_t mode); RETURN VALUE open(), openat(), and creat() return the new file descriptor, or -1 if an error occurred (in which case, errno is set appropriately). go的函数支持多返回值, 在错误处理时能返回更多的信息. 比如go的os.Open方法: 失败的时候不仅返回nil, 还返回一个error值 Linux Mint 19.1 Tessa $ go doc os.Open func Open(name string) (*File, error) Open opens the named file for reading. If successful, methods on the returned file can be used for reading; the associated file descriptor has mode O_RDONLY. If there is an error, it will be of type *PathError. error定义和使用 在go传统中, error是个builtin的interface, 即任何实现了Error()方法的类型, 都可以被看作是error对象. src/builtin/builtin.go, 里面还有close(), len()等内建函数. type error interface { Error() string } 在使用时, 一种方式是: 如果open失败, log.Fatal(err)记下log然后程序退出. f, err := os.Open(\"filename.ext\") if err != nil { log.Fatal(err) } // do something with the open *File f errors包 errors包提供了对error简单的封装: 注意errorString是个私有结构, 对外不可见 // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 使用errors.New函数, 可以返回errorString, 但是以error类型返回的. 外部不知道有errorString // New returns an error that formats as the given text. func New(text string) error { return &errorString{text} } 在你的函数里, 你不用自己实现Error()方法, 用errors.New就可以了: func Sqrt(f float64) (float64, error) { if f 在后面, 我们会用fmt.Errorf来代替errors.New 你的函数最终被别人调用, 出错时, 可以调用err.Error()方法返回字符串, 也可以直接print: f, err := Sqrt(-1) if err != nil { fmt.Println(err) } err是个error类型的接口变量, 根据上文, 它又为什么能直接print呢? 见下面, 类型断言. 动态判断类型, 如果是error类型, 调用它的Error()方法. 比如这样: 这段代码在go/src/fmt/print.go具体来说, fmt.Println会先看类型, 先是基础类型, 不是基础类型default是走上面的代码. 前面说过, 用errors.New返回一个error对象, 但New()只接受一个字符串. 用fmt.Errorf可以接受一个带格式化的字符串, 按照Printf的格式打印成字符串, 内部再调用errors.New()返回error. 所以可以这样写: 能带更多的信息 func Sqrt(f float64) (float64, error) { if f 自己实现error接口 通常, 用fmt.Errorf就足够好了, 但还有更高级的写法. 实现了error的Error()方法, 就是error类型 比如json包里, 定义了一个SyntaxError类型, 如果解析json文件出错时, 就把它作为error类型返回. 注意, SyntaxError带一个叫Offset的数据, 后面要用到. type SyntaxError struct { msg string // description of error Offset int64 // error occurred after reading Offset bytes } func (e *SyntaxError) Error() string { return e.msg } 当调用json.Decode的人, 发现出错的时候, 他可以检查这个Offset: 这要用到类型断言 if err := dec.Decode(&val); err != nil { if serr, ok := err.(*json.SyntaxError); ok { line, col := findLine(f, serr.Offset) return fmt.Errorf(\"%s:%d:%d: %v\", f.Name(), line, col, err) } return err } 为啥要在调用函数里搞这些呢? 在SyntaxError的Error()直接写好不就完了吗? error和类型断言的例子 通过类型断言, 可以从err中提取更多的信息: for try := 0; try 进一步看error如何返回的 前面说了, os.Open返回的error会是os.PathError的指针. Linux Mint 19.1 Tessa $ go doc os.PathError type PathError struct { Op string Path string Err error } PathError records an error and the operation and file path that caused it. func (e *PathError) Error() string func (e *PathError) Timeout() bool 解释如下: // PathError records an error and the operation and // file path that caused it. type PathError struct { Op string // \"open\", \"unlink\", etc. Path string // The associated file. Err error // Returned by the system call. } func (e *PathError) Error() string { return e.Op + \" \" + e.Path + \": \" + e.Err.Error() } open失败的meesage像这样: open /etc/passwx: no such file or directory os.Open()最终会调用私有函数:func openFileNolog(name string, flag int, perm FileMode) (*File, error) open失败的时候, 返回return nil, &PathError{\"open\", name, e} 前面说了, PathError实现了Error()方法, 就可以被当做error类型使用. 注: 为什么要对PathError{\"open\", name, e}取地址呢? 答: 对error类型来说, 它是interface, 既可以接受值, 也可以是取地址后的引用. 取决于对应方法的实现方式. 这里PathError实现Error原型是: func (e *PathError) Error() string 它的receiver是pointer receiver, 是指针, 这里要返回PathError取地址; 否则编译不过. 如果receiver的声明是非指针方式, 那么取不取地址都行. type Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\"I am Nokia, I can call you!\") } //这是interface类型的变量 var phone Phone //可以写成phone = NokiaPhone{}, 或phone = &NokiaPhone{} //结果是一样的 phone.call() 参考: https://blog.golang.org/error-handling-and-go 错误处理化简 go的错误处理是类似C的, 在出错时记录, 调用者来检查. 这样的好处是, 错误能被及时的处理; 但相比于python等语言的try catch机制, go的代码会繁琐. 比如http的处理函数里面, 第10行和第14行, 有一样的错误打印. 代码逻辑按步骤, 调用不同的处理函数, 出错时都要给user返回http错误码: 500 (\"Internal Server Error\") 如果后面处理的步骤增多, 会有大量的重复代码. func init() { http.HandleFunc(\"/view\", viewRecord) } func viewRecord(w http.ResponseWriter, r *http.Request) { c := appengine.NewContext(r) key := datastore.NewKey(c, \"Record\", r.FormValue(\"id\"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { http.Error(w, err.Error(), 500) return } if err := viewTemplate.Execute(w, record); err != nil { http.Error(w, err.Error(), 500) } } 在C里面, 可以定义宏函数, 或者wrapper函数, 把要调用的函数包装一下, 统一返回错误码. 在go里, 用函数的方法可以解决这个问题: http的ServeHTTP方法的格式没有返回值 type Handler interface { ServeHTTP(ResponseWriter, *Request) } 通过函数的方法, 可以实际上带上返回值: //定义一个带返回error的函数类型 type appHandler func(http.ResponseWriter, *http.Request) error //实现ServeHTTP方法, 满足http.Handler func (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { if err := fn(w, r); err != nil { http.Error(w, err.Error(), 500) } } //实现具体的viewRecord函数, 从形式上, 它是有error返回值的. func viewRecord(w http.ResponseWriter, r *http.Request) error { c := appengine.NewContext(r) key := datastore.NewKey(c, \"Record\", r.FormValue(\"id\"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { return err } return viewTemplate.Execute(w, record) } 上面实现了带error返回的viewRecord, 它符合appHandler类型的形式, 所以有ServeHTTP方法: 即函数的方法(方法的receiver是函数) 这里的ServeHTTP方法调用了它的receiver函数, 统一处理错误, 通过http发送给user错误码500; ServeHTTP会被http框架调用, 进而receiver函数被调用. 那么如何注册viewRecord函数为http.Handler呢? package http // import \"net/http\" func Handle(pattern string, handler Handler) Handle registers the handler for the given pattern in the DefaultServeMux. The documentation for ServeMux explains how patterns are matched. //按照上面的说明, 注册viewRecord: 强制转换为appHandler即可 func init() { http.Handle(\"/view\", appHandler(viewRecord)) } 注: 此例子充分说明了: go中的函数是一等公民 上面的例子可以更进一步, 不只返回error, 还返回更多的信息: //返回一个专用结构: 包含error接口 type appError struct { Error error Message string Code int } //现在appHandler类型返回appError对象指针 type appHandler func(http.ResponseWriter, *http.Request) *appError func (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { if e := fn(w, r); e != nil { // e is *appError, not os.Error. c := appengine.NewContext(r) c.Errorf(\"%v\", e.Error) http.Error(w, e.Message, e.Code) } } //现在返回的错误信息更丰富了 func viewRecord(w http.ResponseWriter, r *http.Request) *appError { c := appengine.NewContext(r) key := datastore.NewKey(c, \"Record\", r.FormValue(\"id\"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { return &appError{err, \"Record not found\", 404} } if err := viewTemplate.Execute(w, record); err != nil { return &appError{err, \"Can't display record\", 500} } return nil } channel和并发 go处理并发的哲学很简单: 不共享内存, 所有共享走channel 这个哲学能从设计上, 就避免了竞争. Do not communicate by sharing memory; instead, share memory by communicating. 比如: go list.Sort() // run list.Sort concurrently; don't wait for it. 这有点像shell的后台运行& 单独这样除了能在后台跑sort, 没有特别的好处. 一般还要配合某种同步机制, 通知其他相关线程. go里面用channel来通知. 一个func里面, 也可以用go来运行goroutine func Announce(message string, delay time.Duration) { go func() { time.Sleep(delay) fmt.Println(message) }() // Note the parentheses - must call the function. } go的函数, 实际上都是闭包, 它需要的变量, 比如上面的message, 只要在用就会存在. channel 默认的size是0, 表示unbuffered通道 ci := make(chan int) // unbuffered channel of integers cj := make(chan int, 0) // unbuffered channel of integers cs := make(chan *os.File, 100) // buffered channel of pointers to Files unbuffered通道是同步安全的. channel用于同步 接上面sort的例子, sort完成后, 通过channel发送完成的\"通知\". 主程序在某个地方等待这个\"通知\". c := make(chan int) // Allocate a channel. // Start the sort in a goroutine; when it completes, signal on the channel. go func() { list.Sort() c 如果是unbufferd的通道, 发送者阻塞, 直到接收方接收到这个值. 如果是buffered模式, 则发送方只阻塞到值被拷贝进通道. 如果这个buffer满了, 则发送方一直阻塞到接收方收到值. channel用于semaphore 下面的例子中, serve函数把进入的请求, 分发给handle执行. handle是并发执行的. 它们都先写channel, 直到到达最大并发数:MaxOutstanding 这演示了sem这个channel的容量, 决定了这个生产-消费模型的最大并发数. 在到达并发数之前, handle都是并发的; 到达之后, 只有等有的handle退出, 才能执行新的handle. var sem = make(chan int, MaxOutstanding) func handle(r *Request) { //这里并不是和自己互斥; 而是可能会有最多MaxOutstanding个handle同时运行, 它们之间互斥. sem 这个design有个问题, Serve为每个请求起个goroutine来处理, 虽然最大并发被限制为MaxOutstanding, 但新的goroutine还是在被创建. 如果进来的请求太快, 资源消耗会很快. 可以在Serve里面限制goroutine的生成速度: 用range.range遍历通道queue, 如果通道不关闭, 那么range不会结束; 只在没有数据时阻塞. 但这个修改有个bug, 见下文 func Serve(queue chan *Request) { for req := range queue { //并不是range来控制go routine的生成速度 //而是说把sem 这里的bug在于, 作为循环变量, for里的req只有一个地址, 会被所有goroutine共享. 导致最后这些\"handle\"都在处理同一个req. 那么需要把req复制一份, 传给handle 这个req是个Request指针, 每次range得到一个新的req指针. 闭包函数增加个参数, 然后把req传进去: go是值传递, 所以req指针的值对每个goroutine都是unique的. func Serve(queue chan *Request) { for req := range queue { sem 还有一个写法: 在循环体里面: req := req形成一个新的副本. 名字都一样, 作用域不同. 看着有点怪, 但很合法, 也是go的一种常见写法. func Serve(queue chan *Request) { for req := range queue { req := req // Create new instance of req for the goroutine. sem 一个channel有多个goroutine接收 channel应该是天然支持多对多的模型. 对channel做range也支持多个goroutine对同一个channel做range 其实range就是个iterator? 上面的Serve例子, 用一个更省资源的方法来实现: 起固定个数的goroutine, 每个goroutine都直接从req通道读请求. quit是bool类型的通道, 主线程等待这个信号退出. func handle(queue chan *Request) { //每个handle都会对这个queue做range, 如果都等待, 那唤醒谁呢? for r := range queue { process(r) } } func Serve(clientRequests chan *Request, quit chan bool) { // Start handlers for i := 0; i 函数和channel都是first class值: channel in channel first class意思是, 函数和channel级别和int是一样的, 可以在任何地方传递.比如: channels of channels这里的f是个函数变量, resultChan是个chan int类型的变量这个Request被client用来发送请求, 它发一个切片, 一个函数, 和通过chennal传递的结果 type Request struct { args []int f func([]int) int resultChan chan int } 为什么不直接用个int放结果呢? 比如result int 因为client要用通道来等待server返回结果. client提供一个sum方法, 当做f, make(chan int)当做resultChan func sum(a []int) (s int) { for _, v := range a { s += v } return } request := &Request{[]int{3, 4, 5}, sum, make(chan int)} // Send request //这里是go重要的特征: request里面包括了函数变量和channel变量, 它们通过clientRequests 这个channel传递 clientRequests 在server端: 每个handle按照request里面的f方法, 计算出结果, 传递给request内部的通道. 这个结果会\"直达\"给对应的client. 不需要锁. func handle(queue chan *Request) { for req := range queue { req.resultChan 虽然只是演示代码, 但这个是个支持rate限制, 并发, 无锁的RPC框架. 通道in通道的另一个例子 package main import ( \"fmt\" \"math/rand\" \"sync\" \"time\" ) func main() { reqs := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} // 存放结果的channel的channel outs := make(chan chan int, len(reqs)) var wg sync.WaitGroup wg.Add(len(reqs)) for _, x := range reqs { o := handle(&wg, x) outs 分割和并发 比如一个切片, 如果对每个元素的操作都是独立的, 那么这个结构就是很理想的可以多核并行的结构. type Vector []float64 // Apply the operation to v[i], v[i+1] ... up to v[n-1]. func (v Vector) DoSome(i, n int, u Vector, c chan int) { for ; i 这时可以用一个buffered channel来实现并发, channel的size为CPU个数. const numCPU = 4 // number of CPU cores func (v Vector) DoAll(u Vector) { c := make(chan int, numCPU) // Buffering optional but sensible. for i := 0; i 这里的CPU个数是hardcode, 可以动态获取: var numCPU = runtime.NumCPU() //传入0是查询, 传入个正数是设置 var numCPU = runtime.GOMAXPROCS(0) 用channel管理message buffer 虽然go有垃圾回收, 但有时候还是希望能维护一个机制, 可以不用一直alloc buffer, 尽可能的reuse buffer. 用buffered channel可以实现, 把它当做一个free list. 比如: client端, 从freeList取buffer, freeList为空时申请新的buffer. 然后从网络读消息填充buffer, 再通过和server的通道serverChan 传递. //100个room的freeList var freeList = make(chan *Buffer, 100) var serverChan = make(chan *Buffer) func client() { for { var b *Buffer // Grab a buffer if available; allocate if not. //有default的select不会阻塞 select { //从freeList取buffer, 如果有, 就直接用 case b = 结合下面的server代码, server从serverChan 读buffer, 处理完还到freeList里面. func server() { for { b := 仔细想想, 这段代码有几个问题: serverChan 是个unbuffered的通道, 如果只有一个client和一个server, 实际是用不到100个元素的freeList通道的. 因为client和server会串行在通道上.答: 是的. 一个client和一个server是的. 我理解这里可以有多个client和多个server, 虽然通过serverChan 是串行的, 但通过channel很快, 多个server都能得到buffer同时进行处理. 多个client也基本不用等待serverChan, 有请求丢过去就行, 会有server马上响应. 通道的两端是多对多的情况下, 通道本身永远不会是瓶颈; 极端情况下, 100个server都在处理buffer, 这时freeList为空, 此时client需要重新alloc buffer. 这样buffer数会多于100, 这多出来的buffer 在哪里被丢弃? 内存泄漏了吗?答: 在server的select的default分支里丢弃; 内存不会泄漏, 因为go有垃圾回收 有垃圾回收为啥还要这样搞? 全部新申请buffer不行吗?答: 可以. 但这样垃圾回收任务变繁重, 性能差点. 对高吞吐的网络buffer来说, 一般都要reuse buffer. 接口嵌套 比如下面的ReadWriter 就是Reader和Writer的组合. 只有接口才能被嵌套进接口. type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } // ReadWriter is the interface that combines the Reader and Writer interfaces. type ReadWriter interface { Reader Writer } 结构体嵌套 比如bufio的ReadWriter, 包括一个Reader类型的指针, 和一个Writer类型的指针. 但没有名字, 只有类型. 这就叫嵌入. go编译器会默认把类型名当做变量名, 所以可以用ReadWriter.Reader来访问它包含的Reader成员. // ReadWriter stores pointers to a Reader and a Writer. // It implements io.ReadWriter. type ReadWriter struct { *Reader // *bufio.Reader *Writer // *bufio.Writer } 嵌入的好处是, ReadWriter 直接就有了Reader和writer的方法. 注意是, 直接, 即ReadWriter.Read和ReadWriter.Write 这里的Reader和Writer结构体分别实现的Read和Write方法, 是符合io.Reader和io.Writer接口的. 所以ReadWriter符合所有3个接口: io.Reader, io.Writer, 和 io.ReadWriter 需要注意的是, 比如var rw ReadWriter, 虽然调用方法的形式是rw.Read, 但实际的receive对象是 rw.Reader.Read, 也就是说, outer类型(ReadWriter)直接\"拥有\"Read方法, 但实际传入的还是inner类型(Reader) 一个啰嗦的写法是: named方式包含对象, 然后定义一个\"forward\"方法, 比如这样: 效果是一样的. type ReadWriter struct { reader *Reader writer *Writer } func (rw *ReadWriter) Read(p []byte) (n int, err error) { return rw.reader.Read(p) } 例子 logger type Job struct { Command string *log.Logger } 因为嵌入了log.Logger, Job可以直接使用Print, Printf, Println等log.Logger方法 在初始化后, 就可以使用了: job.Println(\"starting now...\") 初始化Job就像一般的初始化一样: 定义一个\"构造\"函数, go没有构造函数机制, 一般都是一个初始化函数. func NewJob(command string, logger *log.Logger) *Job { return &Job{command, logger} } 或者这样初始化: job := &Job{command, log.New(os.Stderr, \"Job: \", log.Ldate)} 如果需要引用其内嵌的域, 前面说过, 直接用job.Logger 注意这里, Job实现了自己的Printf, 所以引用Logger的Printf就要通过Logger func (job *Job) Printf(format string, args ...interface{}) { job.Logger.Printf(\"%q: %s\", job.Command, fmt.Sprintf(format, args...)) } 这里的Job和它的嵌入对象都有Printf方法, 有类似冲突的时候, 看嵌套层级: 层级少的方法会被使用.但有时候同一个层级的嵌套可能有同名的方法, 如果最外层不用这个同名的方法, 也没问题;如果调用, 那通常是错误. 接口和方法 几乎任何东西都可以满足一个interface定义的接口, 比如, 任何实现了Handler接口的对象, 都可以处理http请求. 在http包里: type Handler interface { ServeHTTP(ResponseWriter, *Request) } //调用http.Handle来使用这个interface func Handle(pattern string, handler Handler) ResponseWriter被http handler用来构建http 响应, go doc http.ResponseWriter看到: type ResponseWriter interface { Header() Header Write([]byte) (int, error) WriteHeader(statusCode int) ResponseWriter实现了Write方法, 这个方法满足io.Writer要求, 可以在任何io.Writer可以使用的地方使用. Request是对client的http请求的抽象. 下面是个很简单但完整的http handler实现, 可以统计http请求的次数: // Simple counter server. type Counter struct { n int } func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) { ctr.n++ //注意, 这里Fprintf是向w里面打印, 即直接打印到http的response fmt.Fprintf(w, \"counter = %d\\n\", ctr.n) } 如何attach这个ctr到一个url地址. import \"net/http\" ... ctr := new(Counter) http.Handle(\"/counter\", ctr) 即使一个int类型也可以带方法 // Simpler counter server. type Counter int func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) { *ctr++ fmt.Fprintf(w, \"counter = %d\\n\", *ctr) } chan带方法 有时你希望在url被访问的时候, 得到通知, 可以在chan上挂这个http的handler // A channel that sends a notification on each visit. // (Probably want the channel to be buffered.) type Chan chan *http.Request func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) { ch 函数也可以带方法!!! 比如想访问/args来得到运行这个http server时的参数, 在http包里, 是这样写的: 把func(ResponseWriter, *Request)作为一个type, 可以带方法 // The HandlerFunc type is an adapter to allow the use of // ordinary functions as HTTP handlers. If f is a function // with the appropriate signature, HandlerFunc(f) is a // Handler object that calls f. type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, req). func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) { f(w, req) } 这可能开起来有点奇怪, 在f的方法中, 调用了f本身. 但这和chan作为receiver本质上差不多. 所以, 这么写的好处是, 符合func(ResponseWriter, *Request)形式的函数, 都可以使用ServeHTTP方法 // Argument server. func ArgServer(w http.ResponseWriter, req *http.Request) { fmt.Fprintln(w, os.Args) } //把ArgServer转换为http.HandlerFunc类型, 就有ServeHTTP方法. http.Handle(\"/args\", http.HandlerFunc(ArgServer)) 注: 在使用时, 要把ArgServer转换成HandlerFunc类型才能使用这个类型带的方法. 这是否也可以理解成修饰器? 用type关键字定义一个函数类的类型, 这个类型可以实现别的接口规定的方法, 在这个方法里, 再调用函数自身. 函数还是这个函数, 但可以被不同的人(接口), 用不同的形式(接口方法)来调用. 多态 多态的意思是, 一个通用方法, 在各个子类里面实现, 但对外接口统一, 通常是父类定义好的(虚函数). 在基类中定义了一个虚拟函数，然后在派生类中又定义一个同名，同参数表的函数，这就是多态。多态是这3种情况中唯一采用动态绑定技术的一种情况。也就是说，通过一个基类指针来操作对象，如果对象是基类对象，就会调用基类中的那个函数，如果对象实际是派生类对象，就会调用派声类中的那个函数，调用哪个函数并不由函数的参数表决定，而是由函数的实际类型决定. 一个操作随着所传递或捆绑的对象类型的不同能够做出不同的反应，其行为模式称为多态。 在go里, 天然就是多态的: 只要实现了interface定义的方法, 就隐含了是该interface类型. 比如: NewCTR是counter mode (CTR) stream, 功能是把block cipher转换成stream cipher. // NewCTR returns a Stream that encrypts/decrypts using the given Block in // counter mode. The length of iv must be the same as the Block's block size. func NewCTR(block Block, iv []byte) Stream 这两个cipher都是通用格式, 比如只要实现了Block接口的三个函数, 都可以作为NewCTR的输入. 只要实现了Stream 接口, 就能作为输出. type Block interface { BlockSize() int Encrypt(dst, src []byte) Decrypt(dst, src []byte) } type Stream interface { XORKeyStream(dst, src []byte) } 接口和类型断言 fmt.Printf接受各种类型的入参, 它怎么知道怎么打印呢? Linux Mint 19.1 Tessa $ go doc fmt.Printf func Printf(format string, a ...interface{}) (n int, err error) Printf formats according to a format specifier and writes to standard output. It returns the number of bytes written and any write error encountered. 答案是类型断言 类型断言是对interface{}来说的, 对fmt.Printf来说, 它判断如果入参是string, 就直接打印. 如果有String方法, 那就是Stringer类型, 就调用它的String方法. type Stringer interface { String() string } var value interface{} // Value provided by caller. switch str := value.(type) { case string: return str case Stringer: return str.String() } 方法 方法的接收Type不限于结构体 在前面, 有个append方法: type ByteSlice []byte func (slice ByteSlice) Append(data []byte) []byte { // Body exactly the same as the Append function defined above. } 这个方法需要用return返回一个新的slice, 有点笨 用*Type, 即指针形式, 可以直接改caller的切片; 前面说过, 切片结构体有三个filed, 是对其底层数组的描述. func (p *ByteSlice) Append(data []byte) { slice := *p // Body as above, without the return. *p = slice } 更进一步, 可以写成Write的标准格式: func (p *ByteSlice) Write(data []byte) (n int, err error) { slice := *p // Again as above. *p = slice return len(data), nil } 有了这个方法, 就符合io.Writer接口, 就可以用标准的接口调用: var b ByteSlice //这里一定要用&对b取地址,因为只有*ByteSlice才符合io.Writer的要求 fmt.Fprintf(&b, \"This hour has %d days\\n\", 7) //go doc fmt 看Fprintf原型如下: func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) //继续用go doc io.Writer看详细定义 type Writer interface { Write(p []byte) (n int, err error) } The rule about pointers vs. values for receivers is that value methods can be invoked on pointers and values, but pointer methods can only be invoked on pointers. 这里如果直接传b, 传值会发生slice的拷贝(浅拷贝, 只拷贝slice结构体本身), 那对这个拷贝的修改就没有任何意义了. python是共享传参(不变的拷贝, 可变的相当于传指针), 而go的参数传递都是传值: 其实都是拷贝值 对int string来说, 就是拷贝值 对slice, map, channel来说, 拷贝\"描述\", 但底层数据不拷贝. -- 浅拷贝 有个特殊的地方, 虽然方法被声明为指针形式, func (p *ByteSlice) Write(data []byte) (n int, err error) 但b.Write和(&b).Write效果是一样的, 因为为了更好看, 编译器会把前者转换为后者. 接口 上面说了方法, 这里说接口 比如sort, 任何实现了sort.Interface的东东, 都能被sort包里的函数排序 //go doc sort type Interface interface{ ... } //go doc sort.Interface type Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } 下面这个例子就实现了sort的Interface //这个Sequence是切片, 定义时[]里面没东西的是切片 type Sequence []int // Methods required by sort.Interface. func (s Sequence) Len() int { return len(s) } func (s Sequence) Less(i, j int) bool { return s[i] 0 { str += \" \" } str += fmt.Sprint(elem) } return str + \"]\" } 在上面Sequence的方法String中, 对每个元素(range s)调用fmt.Sprint, 是挺啰嗦的操作, 效率低. 实际上, fmt.Sprint支持直接传入slice, 在调用之前Sequence强转成slice func (s Sequence) String() string { s = s.Copy() sort.Sort(s) return fmt.Sprint([]int(s)) } 强制转换[]int(s)并没有创建新的值, 只是把s当做int切片使用; 在有些情况下, 强制转换会创建新的值, 比如把int转成float sort包提供了对int切片的排序: IntSlice 除了实现了sort的Interface方法, IntSlice 还包装了自己的Sort方法, 这样可以用 p.Sort() 的形式调用. Linux Mint 19.1 Tessa $ go doc -src sort.IntSlice // IntSlice attaches the methods of Interface to []int, sorting in increasing order. type IntSlice []int func (p IntSlice) Len() int func (p IntSlice) Less(i, j int) bool func (p IntSlice) Search(x int) int func (p IntSlice) Sort() func (p IntSlice) Swap(i, j int) yingjieb@yingjieb-VirtualBox ~ Linux Mint 19.1 Tessa $ go doc -src sort.IntSlice.Sort // Sort is a convenience method. func (p IntSlice) Sort() { Sort(p) } 最后我们的Sequence可以简化成这样: type Sequence []int // Method for printing - sorts the elements before printing func (s Sequence) String() string { s = s.Copy() //这里是把s强转成IntSlice sort.IntSlice(s).Sort() return fmt.Sprint([]int(s)) } 一个东西可以实现多个接口, 比如这个Sequence类型的东东, 既实现了sort的接口, 又实现了fmt包里的Stringer接口 type Stringer interface { String() string } 使用时 package main import \"fmt\" type Person struct { Name string Age int } func (p Person) String() string { return fmt.Sprintf(\"%v (%v years)\", p.Name, p.Age) } func main() { a := Person{\"Arthur Dent\", 42} z := Person{\"Zaphod Beeblebrox\", 9001} fmt.Println(a, z) } gofmt gofmt是编译器自带的格式化代码工具 写代码的时候不需要手动对齐, 用gofmt会自动对齐 不需要关心行宽, go没有限制; gofmt全部搞定 注释即文档 godoc会自动提取下面的注释为package的文档 top level的注释是doc commet if可以有初始化语句 go的if允许和for类似的语法, 有个初始化语句 if err := file.Chmod(0664); err != nil { log.Print(err) return err } for是三种C循环的统一 // Like a C for for init; condition; post { } // Like a C while for condition { } // Like a C for(;;) for { } // Reverse a for i, j := 0, len(a)-1; i switch接受非常量 从上到下依次对case求值, 直到为ture. 空的case是ture. func unhex(c byte) byte { switch { case '0' switch和类型断言联用: var t interface{} t = functionOfSomeType() switch t := t.(type) { default: fmt.Printf(\"unexpected type %T\\n\", t) // %T prints whatever type t has case bool: fmt.Printf(\"boolean %t\\n\", t) // t has type bool case int: fmt.Printf(\"integer %d\\n\", t) // t has type int case *bool: fmt.Printf(\"pointer to boolean %t\\n\", *t) // t has type *bool case *int: fmt.Printf(\"pointer to integer %d\\n\", *t) // t has type *int } 多返回值 C语言只有一个返回值, 有的时候只能用指针作为参数获取 //C语言版本, 出错时, 返回-1, 然后还要用errno来看具体错误. ssize_t write(int fd, const void *buf, size_t count); //go语言版本, 同时返回已经写入的个数和错误, func (file *File) Write(b []byte) (n int, err error) 正如上面的例子, go的返回值可以有名字, 初始值为\"零值\"; 不带参数的return, 就返回它们的当前值. 这样程序可读性更好. defer defer关键词, 声明一个函数, 在defer return时调用(我理解就是函数返回前). 比如函数return someValue, defer的函数在someValue被计算之后, 在return之前被调用. // Contents returns the file's contents as a string. func Contents(filename string) (string, error) { f, err := os.Open(filename) if err != nil { return \"\", err } defer f.Close() // f.Close will run when we're finished. var result []byte buf := make([]byte, 100) for { n, err := f.Read(buf[0:]) result = append(result, buf[0:n]...) // append is discussed later. if err != nil { if err == io.EOF { break } return \"\", err // f will be closed if we return here. } } return string(result), nil // f will be closed if we return here. } defer声明时对参数求值, 而不是在退出时再求值; 执行是LIFO顺序的 for i := 0; i 用defer做函数trace func trace(s string) { fmt.Println(\"entering:\", s) } func untrace(s string) { fmt.Println(\"leaving:\", s) } // Use them like this: func a() { trace(\"a\") defer untrace(\"a\") // do something.... } 因为defer语句是在声明的时候求值的, 所以先求值\"trace\"函数, 打印\"entering\"; 然后在defer return的时候, 执行\"un\"函数 func trace(s string) string { fmt.Println(\"entering:\", s) return s } func un(s string) { fmt.Println(\"leaving:\", s) } func a() { defer un(trace(\"a\")) fmt.Println(\"in a\") } func b() { defer un(trace(\"b\")) fmt.Println(\"in b\") a() } func main() { b() } 结果: entering: b in b entering: a in a leaving: a leaving: b 在panic场景下, defer的最大好处是panic链上的defer都会被调用到 比如RunCompiled中的错误处理, 如果v.run()中出现panic, 这个defer的函数还是会被调用到, 做错误处理. // RunCompiled run the VM with user supplied function fn. func (v *VM) RunCompiled(fn *CompiledFunction, args ...Object) (val Object, err error) { ... defer func() { v.childCtl.Wait() // waits for all child VMs to exit if err = v.postRun(); err != nil { fmt.Println(err) return } if fn != nil && atomic.LoadInt64(&v.aborting) == 0 { val = v.stack[v.sp-1] } }() val = UndefinedValue v.run() return } new和make分配数据 new new的数据会被初始化为0, 返回指针. 这个方式虽然没有调用构造函数或这init之类的函数来初始化结构体, 但new保证这块数据都是0. 很多时候, 0可以直接使用. 比如下面的sync.Mutex初值为0, 就表示是unlock状态, 可以直接用; bytes.Buffer也是全0, 是空的buffer, 可以直接用. type SyncedBuffer struct { lock sync.Mutex buffer bytes.Buffer } p := new(SyncedBuffer) // type *SyncedBuffer var v SyncedBuffer // type SyncedBuffer 有时候结构体初始化需要非0值, 可以new一个结构体, 然后对每个filed单独赋值 func NewFile(fd int, name string) *File { if fd 但这样显得很啰嗦, \"There's a lot of boilerplate in there\", 有很多样板 此时可以用 func NewFile(fd int, name string) *File { if fd 数组, 切片, map都可以这样赋值 //这里Enone Eio Einval应该是int类型 a := [...]string {Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"} s := []string {Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"} m := map[int]string{Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"} 数组和切片的区别 定义不一样 //数组定义 var a1 [3]int var a2 [...]int{1,2,3} //切片定义 var b1 []int b2 := make([]int, 3, 5) 初始化不同 //数组 a1 := [...]int{1,2,3} a2 := [5]int{1,2,3} //切片 b1 := make([]int,3,5) make make用于slice map 和channel, 返回初始化后的type T, 而非*T; 这里的初始化不是指0值, 而是初始化其内部表达. 比如slice的内部结构包括一个指针(指向内部数组), 还有长度和容量; 这些就不是填0值. 比如 make([]int, 10, 100) 创建一个100大小的int数组, 然后创建一个切片结构体, 指向int数组, 长度为10, 容量为100. new([]int) 创建一个0值切片, 也就是nil切片, 这样一个空切片没啥实际作用. var p *[]int = new([]int) // allocates slice structure; *p == nil; rarely useful var v []int = make([]int, 100) // the slice v now refers to a new array of 100 ints // Unnecessarily complex: var p *[]int = new([]int) *p = make([]int, 100, 100) // Idiomatic: v := make([]int, 100) 数组 和C的数组相比, go的array有如下特点: array是值, 数组赋值会拷贝数组所有元素; 所以, 如果数组作为函数参数传参, 会造成数组拷贝 数组的大小也是其类型的一部分; 所以[10]int和[20]int是不同的类型 在go里, 数组是切片的底层承载; 能用slice就不要用数组 切片 切片是对数组的包装和引用 对切片的赋值不会复制数组, 只会引用同一个数组 传入切片到函数, 是传引用. 对数组的改变会被caller看到; 和传数组的指针效果差不多. 因为切片本身就有大小, 所以这个Read原型不需要C里面的nbyte参数. //go版本 func (f *File) Read(buf []byte) (n int, err error) //只readbuf的前32字节, 数组的切片buf[i:j]从0开始编号, 表示从i到(j-1)的元素, 不包括j; 所以这里是0到31的元素 n, err := f.Read(buf[0:32]) //C版本 ssize_t read(int fildes, void *buf, size_t nbyte); map map里面没有的key, 返回0值. attended := map[string]bool{ \"Ann\": true, \"Joe\": true, ... } if attended[person] { // will be false if person is not in the map fmt.Println(person, \"was at the meeting\") } 因为没有的元素也返回0值, 但有的时候map里存在的元素的值就是0值, 那怎么区分? 可以这样, if支持初始化语句: if seconds, ok := timeZone[tz]; ok 打印 fmt.Printf(\"Hello %d\\n\", 23) fmt.Fprint(os.Stdout, \"Hello \", 23, \"\\n\") fmt.Println(\"Hello\", 23) fmt.Println(fmt.Sprint(\"Hello \", 23)) append和...扩展 //原型 func append(slice []T, elements ...T) []T //append接受变长参数 x := []int{1,2,3} x = append(x, 4, 5, 6) fmt.Println(x) //append另外一个slice, 用...扩展 x := []int{1,2,3} y := []int{4,5,6} //没有...的话, y的类型错误 x = append(x, y...) fmt.Println(x) 全局变量初始化和init const变量是编译时初始化的, 只能是常量 而普通变量在运行时初始化, 比C更方便的是, 可以在声明的时候就调用函数来初始化. var ( home = os.Getenv(\"HOME\") user = os.Getenv(\"USER\") gopath = os.Getenv(\"GOPATH\") ) 每个文件都可以有一个或多个init函数, 它在全局变量初始化后被调用 一个常见的场景是, 在main执行之前, 用init来检查运行环境: func init() { if user == \"\" { log.Fatal(\"$USER not set\") } if home == \"\" { home = \"/home/\" + user } if gopath == \"\" { gopath = home + \"/go\" } // gopath may be overridden by --gopath flag on command line. flag.StringVar(&gopath, \"gopath\", gopath, \"override default GOPATH\") } "},"notes/golang_进阶.html":{"url":"notes/golang_进阶.html","title":"进阶","keywords":"","body":" 继承, 匿名包含2 实例 StatsConn 总结 继承, 匿名包含 总结 interface的赋值 第一种情况: 如果方法的receiver类型不是引用方式 第二种情况: 方法的receiver是引用方式声明的 总结 go FAQ go1.3是c写的, 后面的编译器是go写的 工具自动把C转成go的 interface的签名必须完全一样 例子1 例子2 nil error不是nil map的元素不能取地址 内置println 空结构体 迭代器样板 scanner样板 range样板 关于copy 函数级并发 顺序版本 goroutine并发版本 channel的广播 close广播 交换机复制式广播 改进 代码心得 再看testing 例子 再议reflect 打印变量信息 测试代码 包初始化 再说切片和数组 数组是值 GO的数组表达和C一样 切片 动态链接 支持动态链接的平台 动态链接支持的架构 交叉编译go 支持交叉编译的平台 一次运行时异常打印 goroutine和共享变量 理论 实践 调试环境变量 举例 GODEBUG GOTRACEBACK 名字冲突和type别名 type定义新类型 type别名 goroutine vs thread 默认的thread数 goroutine介绍 json和万能interface{} 已知结构体 不知道结构体情况下 encoder和decoder 继承, 匿名包含2 我们都知道, 一个结构体匿名包含另一个结构体, 就能继承其方法. 其实, 匿名包含一个interface, 也能继承. 比如: //Fooer是个interface type Fooer interface { Foo() string } //Container匿名包含了Fooer type Container struct { Fooer } // TheRealFoo is a type that implements the Fooer interface. type TheRealFoo struct { } // TheRealFoo真正实现了Fooer func (trf TheRealFoo) Foo() string { return \"TheRealFoo Foo\" } // sink takes a value implementing the Fooer interface. func sink(f Fooer) { fmt.Println(\"sink:\", f.Foo()) } //shilhuaContainer的时候, 初始化Fooer域 co := Container{Fooer: TheRealFoo{}} //下面申请的一幕来了, co也是Fooer //co因为是Container的实例, 后者匿名包含了Fooer(底层实现是TheRealFoo{}) sink(co) //输出: sink: TheRealFoo Foo 由以上得知, 匿名包含interface的效果和匿名包含结构体类似, 但interface变量要正确的初始化. 如果没有正确初始化, 编译是能通过的, 但会运行时错误, 比如下面的错误实例: co := Container{} sink(co) 会打印runtime error: invalid memory address or nil pointer dereference 实例 StatsConn 这里例子里, StatsConn匿名包含了net.Conn, 从而继承了net.Conn的所有函数, 但它重载了Read方法, 目的是增加字节数统计 type StatsConn struct { net.Conn //注意这里的net.Conn是个interface BytesRead uint64 } func (sc *StatsConn) Read(p []byte) (int, error) { n, err := sc.Conn.Read(p) sc.BytesRead += uint64(n) return n, err } 实例化StatsConn的时候, 用tcp的net.Conn实例来初始化. conn, err := net.Dial(\"tcp\", u.Host+\":80\") if err != nil { log.Fatal(err) } sconn := &StatsConn{conn, 0} 从此以后, sconn拥有net.Conn的所有属性, 所有net.Conn能用的地方, 都可以用sconn, 比如: resp, err := ioutil.ReadAll(sconn) if err != nil { log.Fatal(err) } 总结 匿名包含interface和匿名包含struct都能继承 需要注意被包含的interface域应该正确的实例化 参考: https://eli.thegreenplace.net/2020/embedding-in-go-part-3-interfaces-in-structs/ 继承, 匿名包含 package main import \"fmt\" /* 继承 一个结构体嵌到另一个结构体，称作组合 匿名和组合的区别 如果一个struct嵌套了另一个匿名结构体，那么这个结构可以直接访问匿名结构体的方法，从而实现继承 如果一个struct嵌套了另一个【有名】的结构体，那么这个模式叫做组合 如果一个struct嵌套了多个匿名结构体，那么这个结构可以直接访问多个匿名结构体的方法，从而实现多重继承 */ type Car struct { weight int name string } func (p *Car) Run() { fmt.Println(\"running\") } type Bike struct { Car //注意这里, 虽然Car的receiver是引用方式, 而这里Car做为\"值\"被包含, 但是Bike依然继承了Car的方法. lunzi int } type Train struct { Car } func (p *Train) String() string { str := fmt.Sprintf(\"name=[%s] weight=[%d]\", p.name, p.weight) return str } func main() { var a Bike a.weight = 100 a.name = \"bike\" a.lunzi = 2 fmt.Println(a) a.Run() var b Train b.weight = 100 b.name = \"train\" b.Run() fmt.Printf(\"%s\", &b) } 总结 不管一个type是用receiver方式实现的方法, 还是值方式. 我们都说这个type实现了这个方法, 从而满足了某类interface的要求 对引用方式的receiver来说, 只要这个对象是addressable的, 编译器就会自动取地址. 换个说法是, 只要这个\"值\"对象, 在传递的过程中(比如赋值)不被赋值, 对其取地址不会取到其\"拷贝对象\"上去, 就可以搞. interface的赋值 比如最简单的interface type Phone interface { call() } 只要实现了call()方法的类型, 都可以是Phone 声明一个Phone类型的变量 //这是interface类型的变量 var phone Phone 对interface类型的变量赋值, 要看方法的实现情况 第一种情况: 如果方法的receiver类型不是引用方式 type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\"I am Nokia, I can call you!\") } 那么对phone变量的赋值, 地址和值都可以 //new返回一个指针, 并对其内存清零; //以下都对 phone = new(NokiaPhone) phone = &NokiaPhone{} phone = NokiaPhone{} phone.call() 更进一步, 其实取不取引用, 是不一样的. 但都能直接用phone.call(), 因为go对指针也是用点方式调用其方法. func main() { //这是interface类型的变量 var phone Phone var nokiaPhone NokiaPhone fmt.Printf(\"addr: %p, value: %v, type: %T \\n\", &nokiaPhone, nokiaPhone, nokiaPhone) phone = &nokiaPhone fmt.Printf(\"\\naddr: %p, value: %v, type: %T \\n\", phone, phone, phone) phone.call() phone = nokiaPhone fmt.Printf(\"\\naddr: %p, value: %v, type: %T \\n\", phone, phone, phone) phone.call() } //输出 addr: 0x1e529c, value: {}, type: main.NokiaPhone addr: 0x1e529c, value: &{}, type: *main.NokiaPhone I am Nokia, I can call you! addr: %!p(main.NokiaPhone={}), value: {}, type: main.NokiaPhone I am Nokia, I can call you! 第二种情况: 方法的receiver是引用方式声明的 type NokiaPhone struct { } func (nokiaPhone *NokiaPhone) call() { fmt.Println(\"I am Nokia, I can call you!\") } 这种情况下, phone = &nokiaPhone是合法的. 而phone = nokiaPhone不行 错误是: NokiaPhone 没有实现Phone方法. ./prog.go:30:8: cannot use nokiaPhone (type NokiaPhone) as type Phone in assignment: NokiaPhone does not implement Phone (call method has pointer receiver) 注意, 虽然当receiver是引用方式时, 不能phone = nokiaPhone, 但是可以nokiaPhone可以调用call()函数, 即这样写没有任何问题: type NokiaPhone struct { } func (nokiaPhone *NokiaPhone) call() { fmt.Println(\"I am Nokia, I can call you!\") } func main() { var nokiaPhone NokiaPhone //即使receiver是引用方式, 也能直接用\"值\"来调用 nokiaPhone.call() } 不是说NokiaPhone does not implement Phone (call method has pointer receiver)吗? 怎么矛盾了? -- 不矛盾. 编译器做了语法糖, 实际调用的是: (&nokiaPhone).call() 在call()函数看来, receiver还是地址. 那为什么上面的interface赋值phone = nokiaPhone不行呢? -- 因为interface赋值也是值拷贝. 如果这里可以的话, 后面对phone.call()的调用, 实际上最终是(&拷贝后的nokiaPhone).call(), 对拷贝后的对象取地址没有任何意义, 所以编译器禁止这样搞. 总结 方法的receiver是pointer receiver类型时, interface变量只接受引用方式赋值. 方法的receiver是非指针方式, interface变量的赋值既可以是值, 也可以是引用. 即使是receiver方式, \"值\"对象也可以直接调用其方法. go FAQ 官方faq 101FAQ go1.3是c写的, 后面的编译器是go写的 工具自动把C转成go的 go编译器实现背景 工具把gc编译器从C转成go interface的签名必须完全一样 例子1 type Equaler interface { Equal(Equaler) bool } type T int func (t T) Equal(u T) bool { return t == u } // does not satisfy Equaler type T2 int func (t T2) Equal(u Equaler) bool { return t == u.(T2) } // satisfies Equaler 例子2 type Opener interface { Open() Reader } func (t T3) Open() *os.File //T3 does not satisfy Opener nil error不是nil error是个interface{}, 而interface{}是{类型 值}的表达, 两个都是nil的时候, interface才是nil //这里return的error永远不是nil, 因为其类型是*MyError func returnsError() error { var p *MyError = nil if bad() { p = ErrBad } return p // Will always return a non-nil error. } map的元素不能取地址 因为map是hash表, 随着map大小的动态增减, 里面的元素可能会重新算hash, 改变存储位置, 那地址就变了. In Go, a map is designed as a container which can contain unlimited number of entries if memory is available. And, in the official Go runtime implementation, to ensure good map element indexing efficiency, each map value only maintains one continuous memory segment for the entire entries stored in that map. Therefor, Go runtime needs to allocate larger memory segments for a map from time to time when there are more and more entries being put into the map. In the process, the entries stored on older memory segments will be moved to newer memory segments. There might be also some other reasons caausing entry memory movements. In other words, the addresses of map elements will change from time to time on need. If map elements are allowed to be taken addresses, then when some map entries are moved, Go runtime must update all pointers which are storing the addresses of the moved elements, which brings many difficulties in implemnting Go compilers and runtimes and decreases Go program running performance much. So, currently, map elements are disallowed to be taken addresses. 内置println 内置的println是debug时候用的, 输出到stderr 另外, println不会导致变量逃逸 Currently (Go Toolchain 1.15), for the standard Go compiler, calls to the built-in print/println functions will not make the values referenced by the arguments of the calls escape to heap, whereas the print functions in the fmt and log standard packages will. 参考: print-builtin-fmt-log 空结构体 一般来说, 空结构体struct{}是0字节大小的. 但放在另外一个结构体的最后, 编译器会pad一些字节. func main() { type T1 struct { a struct{} x int64 } fmt.Println(unsafe.Sizeof(T1{})) // 8 type T2 struct { x int64 a struct{} } fmt.Println(unsafe.Sizeof(T2{})) // 16 } 解释是: 一个结构体如果可以取地址, 那里面的每个field都应该能被取地址. 而如果T2不pad8个字节, 那对T2的a取地址就是其他对象的地址了, 就超过了T2结构体的范围了. 所以后面要加8字节. 而T1不会有这个越结构体问题. 参考: 空结构体在最后 迭代器样板 scanner样板 bufio的scanner是个很好的迭代器样板. 下面的代码使用scanner扫描一个文件, 比对每一行, 如果不是msg就判定错误. file := \"test/testc.log\" f, err := os.Open(file) if err != nil { t.Fatal(err) } defer f.Close() scanner := bufio.NewScanner(f) var i int pos := len(\"[2020/08/09 14:47:41.769979][testfile][INFO] \") for i = 0; scanner.Scan(); i++ { if scanner.Text()[pos:pos+len(msg)] != msg { break } } if err := scanner.Err(); err != nil { t.Fatal(err) } if i != routineNum*lineNum { t.Fatalf(\"Unexpected line number: got %d, expect %d\", i, routineNum*lineNum) } 关于scanner迭代器: scanner.Scan()返回bool, 利于for判断, 为true继续, 为false则退出for scanner本身是个NewScanner()出来的对象, 在for循环里scanner.xxx()来反应本次迭代的更新的内容 for循环退出, 判断scanner.Err()就能知道是异常终止还是for循环自然结束. range样板 对于自己定义的结构体, 不能用内置的range关键词来迭代; 但可以自己模拟一个, 比如sync/map包, 提供了对map的同步访问API type Map func (m *Map) Delete(key interface{}) func (m *Map) Load(key interface{}) (value interface{}, ok bool) func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) func (m *Map) Range(f func(key, value interface{}) bool) func (m *Map) Store(key, value interface{}) 这里的Range()函数就是一个迭代器. 它接受一个函数f, f返回false则停止迭代. 关于copy 比如对一个slice做copy, 这样的代码能work copy(l[i+1:], l[i:]) 为了把位置i后面的元素都挪一个位置, 代价是把这后面的所有元素都copy一遍 这里的copy实际上是overlap的, copy的时候, 源为l[i:], 目的是l[i+1:], 目的比源向后移动一个位置, 而且目的的元素个数也少了一个. golang的copy允许overlap $ go doc builtin.copy package builtin // import \"builtin\" func copy(dst, src []Type) int The copy built-in function copies elements from a source slice into a destination slice. (As a special case, it also will copy bytes from a string to a slice of bytes.) The source and destination may overlap. Copy returns the number of elements copied, which will be the minimum of len(src) and len(dst). 注意, 如果按照普通的for循环式的copy思路, src和dst重叠时不能正常工作的. 有人讨论说golang的copy语义类似memmove memcpy: 当src和dst重叠时, 结果不确定 memmove: src和dst可以重叠, 结果是正确的拷贝; 可以理解成有个临时缓冲做中转. 实际上并不需要中间buffer, 只需要在开始的时候判断是从前往后拷贝还是从后往前拷贝就行了. 结论: golang的copy支持overlap, 可以正确的拷贝 举例: func main() { l := []int{0,1,2,3,4,5,6,7,8,9} l = append(l, 100) copy(l[4+1:], l[4:]) fmt.Println(l) } 输出: [0 1 2 3 4 4 5 6 7 8 9] 可以看到从i=4开始, 整个slice向右平移了一个位置, 是符合预期的. 函数级并发 顺序版本 piMap := make(map[int]*pidinfo.PidInfo, len(tgtPids)) collect := func() { for _, pid := range tgtPids { pi := piMap[pid] if pi != nil { if err := pi.Update(); err != nil { //fmt.Printf(\"main: %v\\n\", err) piMap[pid] = nil continue } } } } piMap是个全局的map. 现在想把第6行pi.Update()routine化调用, 达到并发执行这个函数的效果. 要解决的问题: piMap全局map的修改不是并发安全的 主程序怎么等待多个pi.Update()完成 参考下面的并发化实现 goroutine并发版本 使用unbuffered channel传递结果 使用计数器控制等待次数 程序的效果是第10行的for代码块可以并发执行, 第22行的for代码块等待上面的routine执行完 并发的版本比顺序版本代码逻辑更复杂点, goroutine的创建 调度和channel的同步都有开销, 但如果并发的收益很大的化还是值得的. piMap := make(map[int]*pidinfo.PidInfo, len(tgtPids)) collect := func() { //可以在函数内部type定义类型 type result struct { pid int err error } resultCh := make(chan result) //计数器, 记录go了多少次 cnt := 0 for _, pid := range tgtPids { pid := pid pi := piMap[pid] if pi != nil { cnt++ go func() { err := pi.Update() //结果写回channel resultCh channel的广播 close广播 close()一个channel, 所有read这个channel的routine都会被唤醒. 注意, 对同一个channel的操作都会有加锁操作, 因而在多核环境下, 锁竞争的开销会变得非常大. 除了这个锁的缺点, close()广播的实现的好处是比较简洁. //代码片段, \"监听\"的goroutine //这样的goroutine可以有很多 //goroutine n for { //update from rootCheck pointer //ti.rootCheck是个指向channel的指针 //关键是用临时变量保存这个channel的一个拷贝 check := *ti.rootCheck select { case 交换机复制式广播 如何让channel做到1对多的广播? 我们知道close一个channel, 那么它的所有reader都会返回一个零值, 这就是广播. 还有别的方法吗? 下面的例子使用订阅模式模仿了广播的api. 详见:stackoverflow github A more elegant solution is a \"broker\", where clients may subscribe and unsubscibe to messages. To also handle subscribing and unsubscribing elegantly, we may utilize channels for this, so the main loop of the broker which receives and distributes the messages can incorporate all these using a single select statement, and synchronization is given from the solution's nature. Another trick is to store the subscribers in a map, mapping from the channel we use to distribute messages to them. So use the channel as the key in the map, and then adding and removing the clients is \"dead\" simple. This is made possible because channel values are comparable, and their comparison is very efficient as channel values are simple pointers to channel descriptors. Without further ado, here's a simple broker implementation: type Broker struct { stopCh chan struct{} publishCh chan interface{} subCh chan chan interface{} unsubCh chan chan interface{} } func NewBroker() *Broker { return &Broker{ stopCh: make(chan struct{}), publishCh: make(chan interface{}, 1), subCh: make(chan chan interface{}, 1), unsubCh: make(chan chan interface{}, 1), } } func (b *Broker) Start() { subs := map[chan interface{}]struct{}{} for { select { case Example using it: func main() { // Create and start a broker: b := NewBroker() go b.Start() // Create and subscribe 3 clients: clientFunc := func(id int) { msgCh := b.Subscribe() for { fmt.Printf(\"Client %d got message: %v\\n\", id, Output of the above will be Client 2 got message: msg#0 Client 0 got message: msg#0 Client 1 got message: msg#0 Client 2 got message: msg#1 Client 0 got message: msg#1 Client 1 got message: msg#1 Client 1 got message: msg#2 Client 2 got message: msg#2 Client 0 got message: msg#2 Client 2 got message: msg#3 Client 0 got message: msg#3 Client 1 got message: msg#3 改进 You may consider the following improvements. These may or may not be useful depending on how / to what you use the broker. Broker.Unsubscribe() may close the message channel, signalling that no more messages will be sent on it: func (b *Broker) Unsubscribe(msgCh chan interface{}) { b.unsubCh This would allow clients to range over the message channel, like this: msgCh := b.Subscribe() for msg := range msgCh { fmt.Printf(\"Client %d got message: %v\\n\", id, msg) } Then if someone unsubscribes this msgCh like this: b.Unsubscribe(msgCh) The above range loop will terminate after processing all messages that were sent before the call to Unsubscribe(). If you want your clients to rely on the message channel being closed, and the broker's lifetime is narrower than your app's lifetime, then you could also close all subscribed clients when the broker is stopped, in the Start() method like this: case 代码心得 go b.Start()起了单独的routine来维护b(即中转线程), 主要是subscribe和unsubscribe的map维护, 和msg的分发; 用单独的goroutine可以避免锁. 订阅和取消订阅实际上是对内部map的添加和删除key, subs[msgCh] = struct{}{}和delete(subs, msgCh). 这里把新make的channel当作map的key, 因为channel是可比较的, 而且比较效率高.关键是插入和删除key非常简单. 中转线程是关键, 类似个交换机; 为了避免在select里面等待, msg都是bufferred模式.而且写都带default, 是非阻塞的. 再看testing 格式go test [build/test flags] [packages] [build/test flags & test binary flags] 帮助文档go help test和go doc testing testdata目录会被go tool忽略, 留给测试case使用 测试case的输出全部走stdout, 即使case里输出到stderr; stderr是留给testing框架用的 默认跑test, 但不跑benchamrk go test除了支持全部go build参数外, 还支持 #基础选项 -args 传个测试case的 -c 只编译不运行, 生成pkg.test -exec xprog 用外部程序xprog来运行test二进制 -i 只安装不运行 -o 输出test二进制 #测试过程控制 -bench regexp 运行正则匹配到的benchmark; -bench .除了会运行test项, 还会运行所有benchmark项 -run regexp 只运行正则的case, 只匹配test项和example项: -benchtime t 默认是1s, 可以指定其他的time.Duration比如1h30s -count n 重复执行所有case n次 -cover 使能coverage 分析 -cpu 1,2,4 指定CPU列表 -parallel n 对调用t.Parallel的case, 指定并发为n; 默认为GOMAXPROCS -short 减小测试时间, 自己在case里判断是否if testing.Short() -timeout d 默认超时时间是10m, 可以改 -list regexp 列出正则匹配的项 #profiling相关 -benchmem: 打印内存使用情况 -blockprofile block.out: 打印goroutine的阻塞情况 -coverprofile cover.out: 打印coverage -memprofile mem.out: mem profile -cpuprofile cpu.out: cpu profile -trace trace.out: 输出trace profile # 命令举例 //不跑test项, 跑所有的benchmark项: go test -run 任意匹配不到的正则 -bench . -benchtime 10s 例子 func TestAbs(t *testing.T) { got := Abs(-1) if got != 1 { t.Errorf(\"Abs(-1) = %d; want 1\", got) } } func BenchmarkHello(b *testing.B) { for i := 0; i t.Run(\"A=1\", func(t *testing.T) { ... }) t.Run(\"A=2\", func(t *testing.T) { ... }) t.Run(\"B=1\", func(t *testing.T) { ... }) // } go test -run '' # Run all tests. go test -run Foo # Run top-level tests matching \"Foo\", such as \"TestFooBar\". go test -run Foo/A= # For top-level tests matching \"Foo\", run subtests matching \"A=\". go test -run /A=1 # For all top-level tests, run subtests matching \"A=1\". // 用TestMain来接管test执行, 必须先做一些复杂的初始化; 然后调用m.Run func TestMain(m *testing.M) { // call flag.Parse() here if TestMain uses flags os.Exit(m.Run()) } 再议reflect reflect.Type是个interface, 而reflect.Value是个结构体. Type更抽象, 而Value是实例. 打印变量信息 func desc(i interface{}) { t := reflect.TypeOf(i) if t.Kind() != reflect.Ptr { //加下面的代码会panic, 提示 panic: reflect.Value.Addr of unaddressable value //我理解是这样的: 传参的时候, 把对象赋值给interface{}, 也是值传递; //reflect.ValueOf(i)其实是有地址的, 但它是个\"临时的拷贝\", 它的地址没有意义 //所以下面的语句不让获取这个临时拷贝的地址; 这个临时的拷贝被认为是unaddressable //fmt.Println(reflect.ValueOf(i).Addr()) fmt.Printf(\"(%v, %T)@\\n\", i, i, t.Size()) } else { //这个case对应desc(&a), 此时i实际上是个指针. //那么v.Elem()和t.Elem()就是解引用 //用v.Elem().UnsafeAddr()代替i, 也能正确打印地址(需换成%x打印) v := reflect.ValueOf(i) fmt.Printf(\"(%v, %v)@[%p]\\n\", v.Elem(), t.Elem(), i, t.Elem().Size()) } } 其中 t是Type类型的对象, t本身是interface类型 t.Kind()是底层实例的类型, 与reflect包里的常量类型可比较 t.Size()返回类型t的大小 v是Value类型的对象, 代表了实际的value v.Elem()指v是指针的时候, 其指向的对象的值 t.Elem()是t是指针的时候, 其指向对象的类型 t.Elem().Size是其指向对象类型的大小 测试代码 func main() { a := 55 fmt.Printf(\"(%v, %T)@(%p, %d)\\n\", a, a, &a, unsafe.Sizeof(a)) desc(a) desc(&a) m := struct { int string }{6, \"hello\"} fmt.Printf(\"(%v, %T)@[%p, %d]\\n\", m, m, &m, unsafe.Sizeof(m)) desc(m) desc(&m) } //结果: (55, int)@(0xc0000c0020, 8) (55, int)@ (55, int)@[0xc0000c0020] ({6 hello}, struct { int; string })@[0xc0000b8040, 24] ({6 hello}, struct { int; string })@ ({6 hello}, struct { int; string })@[0xc0000b8040] 包初始化 再main执行之前, 被依赖的包会递归的包含, 并执行里面的全局变量, init()函数等. 再说切片和数组 数组是值 数组是值类型, 参数里传数组会复制整个数组. Go语言中数组是值语义。一个数组变量即表示整个数组，它并不是隐式的指向第一个元素的指针（比如C语言的数组），而是一个完整的值。当一个数组变量被赋值或者被传递的时候，实际上会复制整个数组。如果数组较大的话，数组的赋值也会有较大的开销。为了避免复制数组带来的开销，可以传递一个指向数组的指针，但是数组指针并不是数组。 var a = [...]int{1, 2, 3} // a 是一个数组 var b = &a // b 是指向数组的指针 fmt.Println(a[0], a[1]) // 打印数组的前2个元素 fmt.Println(b[0], b[1]) // 通过数组指针访问数组元素的方式和数组类似 for i, v := range b { // 通过数组指针迭代数组的元素 fmt.Println(i, v) } GO的数组表达和C一样 注意, go里面数组是数组, 切片是切片; 上面说到切片的表达是个结构体, 包括了数组的指针和大小, 但数组还是和C一样的\"原始\"样子: 指向首元素的指针可以代表这个数组. func main() { // s是个切片 s := []int{1,2,3,4,5,6,7} sp := &s fmt.Println(sp) //&s[0]已经是对底层数组的元素了, 前面说过, go的底层数组和c表达一样 //所以可以强转成*[3]int, 注意这个是个数组; 只能转成数组 sp3 := (*[3]int)(unsafe.Pointer(&s[0])) fmt.Println(sp3) } //结果 &[1 2 3 4 5 6 7] &[1 2 3] 切片 切片是对数组的表达, 带有个header; header里面有底层数组的指针和数组的大小;字符串是只读的int数组, 有个和切片类似的头, 行为和切片有点像. func main() { type MyInt int var a = []int{7, 8, 9} //b也是切片, 但和a共享底层数组 var b = *(*[]MyInt)(unsafe.Pointer(&a)) b[0]= 123 fmt.Println(a) // [123 8 9] fmt.Println(b) // [123 8 9] fmt.Printf(\"%T \\n\", a) // []int fmt.Printf(\"%T \\n\", b) // []main.MyInt } 动态链接 应该是从go1.8左右开始, go支持动态链接 This is possible now using -linkshared flag What you need to do is to first run this command: go install -buildmode=shared -linkshared std (Above code makes all common packages shareable!) then 这个命令在mint下面, 会生成一个36M的libstd.so; 用xz压缩后是8M左右. Linux Mint 19.1 Tessa $ llh ./go/pkg/linux_amd64_dynlink/libstd.so -rw-rw-r-- 1 yingjieb yingjieb 36M Oct 9 09:15 ./go/pkg/linux_amd64_dynlink/libstd.so go install -buildmode=shared -linkshared userownpackage finally when compiling your code you need to run: go build -linkshared yourprogram What the above those is now it rather than statically linking everything only dynamically links them and you will end up with much smaller compiled files. Just to give you an idea my \"hello.go\" file with static linking is 2.3MB while the same code using dynamic linking is just 12KB! 我在mint上, 用共享模式, hello的可执行大小是20K. 静态模式是2M. Linux Mint 19.1 Tessa $ ldd hello linux-vdso.so.1 (0x00007ffea79b8000) libstd.so => /home/yingjieb/repo/gorepo/go/pkg/linux_amd64_dynlink/libstd.so (0x00007f8189201000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8188e10000) libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8188c0c000) libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f81889ed000) /lib64/ld-linux-x86-64.so.2 (0x00007f818bdda000) Linux Mint 19.1 Tessa $ ldd /home/yingjieb/repo/gorepo/go/pkg/linux_amd64_dynlink/libstd.so linux-vdso.so.1 (0x00007fff4b3cb000) libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f065b410000) libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f065b1f1000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f065ae00000) /lib64/ld-linux-x86-64.so.2 (0x00007f065dfe9000) 说明: go程序的静态编译时按需编译. 共享编译std, 会把go的库全部编译, 引入全部依赖, 比如libc 看起来hello依赖libc, 但其实是go的共享库libstd.so依赖libc等动态库. 如果说MIPS上n32不支持cgo的话, 那静态编译用MIPS64的libc.a行吗? 这个东西编译的时候有. buildmode详细说明 go help buildmode -buildmode=shared Combine all the listed non-main packages into a single shared library that will be used when building with the -linkshared option. Packages named main are ignored. 支持动态链接的平台 go1.12只有下面的平台支持: \"linux/386\", \"linux/amd64\", \"linux/arm\", \"linux/arm64\", \"linux/ppc64le\", \"linux/s390x\" 动态链接支持的架构 src/cmd/go/internal/work/init.go 只有case \"linux/386\", \"linux/amd64\", \"linux/arm\", \"linux/arm64\", \"linux/ppc64le\", \"linux/s390x\": MIPS和PPC大端都不支持 交叉编译go go的交叉编译很简单, 只要配置两个环境变量 GOOS GOARCH 比如: //就用x86的gc go编译器 //默认编译出native的go程序, 那这里就是x86-64 go build goweb.go //加环境变量, 就能交叉编译 GOOS=linux GOARCH=mips64 go build goweb.go //编译很顺利, 直接生成mips64的可执行文件 Linux Mint 19.1 Tessa $ file goweb goweb: ELF 64-bit MSB executable, MIPS, MIPS-III version 1 (SYSV), statically linked, not stripped 网上说用gcc go编译器不行:最后一个回复 支持交叉编译的平台 Linux Mint 19.1 Tessa # go tool dist list | grep linux linux/386 linux/amd64 linux/arm linux/arm64 linux/mips linux/mips64 linux/mips64le linux/mipsle linux/ppc64 linux/ppc64le linux/s390x 一次运行时异常打印 func main() { flag.Parse() http.Handle(\"/\", http.HandlerFunc(QR)) err := http.ListenAndServe(*addr, nil) if err != nil { log.Fatal(\"ListenAndServe:\", err) } } 在err := http.ListenAndServe(*addr, nil), 打印出死锁异常 能看出来: go的crash报告很清楚: 有调用链, 行数, 参数 这个http的调用, 大体上经过了net/http, net, poll, syscall, sync等模块的调用, 分层很清楚 fatal error: all goroutines are asleep - deadlock! goroutine 1 [sync.Cond.Wait]: runtime.goparkunlock(...) /usr/local/go/src/runtime/proc.go:310 sync.runtime_notifyListWait(0x8407f0, 0x0) /usr/local/go/src/runtime/sema.go:510 +0x120 sync.(*Cond).Wait(0x8407e8, 0x8407e0) /usr/local/go/src/sync/cond.go:56 +0xe0 syscall.(*queue).waitRead(0x8407e0, 0x1, 0x0, 0x0, 0x8001e0, 0x4b6bb0, 0x864c8c, 0x0) /usr/local/go/src/syscall/net_nacl.go:292 +0xe0 syscall.(*msgq).read(0x8407e0, 0x4296e0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0) /usr/local/go/src/syscall/net_nacl.go:409 +0xc0 syscall.(*netFile).accept(0x832240, 0x0, 0x832240, 0x0, 0x0, 0x4c49, 0x70, 0x4382e0) /usr/local/go/src/syscall/net_nacl.go:571 +0x40 syscall.Accept(0x3, 0x0, 0xff800000, 0x7ff, 0x56f40, 0x4c49, 0xf8ea81ab, 0x850848) /usr/local/go/src/syscall/net_nacl.go:799 +0xa0 internal/poll.accept(0x3, 0x4c01, 0x1, 0x83f000, 0x2, 0x2, 0x8, 0x743800, 0x2, 0x0) /usr/local/go/src/internal/poll/sys_cloexec.go:24 +0x40 internal/poll.(*FD).Accept(0x850840, 0x4c49, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0) /usr/local/go/src/internal/poll/fd_unix.go:377 +0x140 net.(*netFD).accept(0x850840, 0x864e20, 0x7321c0, 0x4c49, 0xfefc0008, 0x0) /usr/local/go/src/net/fd_unix.go:238 +0x40 net.(*TCPListener).accept(0x83efa0, 0x4c49, 0x20, 0x44c9a0, 0x83c201, 0x0) /usr/local/go/src/net/tcpsock_posix.go:139 +0x40 net.(*TCPListener).Accept(0x83efa0, 0x0, 0x83f040, 0x4c49, 0x4242e0, 0x725e08) /usr/local/go/src/net/tcpsock.go:261 +0x40 net/http.(*Server).Serve(0x8526c0, 0x5194d0, 0x83efa0, 0x5, 0x0, 0x0) /usr/local/go/src/net/http/server.go:2896 +0x2e0 net/http.(*Server).ListenAndServe(0x8526c0, 0x469211, 0x8526c0, 0x516bb0) /usr/local/go/src/net/http/server.go:2825 +0xe0 net/http.ListenAndServe(...) /usr/local/go/src/net/http/server.go:3080 main.main() /tmp/sandbox101442177/prog.go:17 +0x160 goroutine和共享变量 理论 在loop里使用goroutine时, 比如 for _, val := range values { go func() { fmt.Println(val) }() } 首先, goroutine是能使用变量val的; 因为goroutine底层也是运行在线程上的, 每个go进程有自己的\"worker\"线程, 一般在启动时和CPU核数相等, 它们的地址空间是一样的. 但goroutine会等待调度执行, 可能在主线程的loop结束后才开始执行. 此时的val被\"捕获\"进goroutine(有时也叫闭包), 但val只有一个值, 在for里改变, 那很可能总是捕获到最后一次的值. 后面的实验也验证了这一点. 一般不这样直接用loop变量, 而是把loop变量当做参数传入goroutine, 这样这个参数在传递的时候, 就保存在goroutine的栈里了, 不用等goroutine被调度执行才evaluate这个值. for _, val := range values { go func(val interface{}) { fmt.Println(val) }(val) } 实践 对比左右两个代码, 左边在循环结束后sleep了, 右边没有. 输出就不一样, 为什么呢? 注: 这个网站提供的环境, 只有一个核.fmt.Println(\"CPU num = \", runtime.NumCPU())打出来是1. 所以goroutine\"并行\"x++, 不存在并发的问题, 结果是对的. x++并不是原子的, 一般C里面要用编译器提供的原子操作宏: __sync_fetch_and_add( &x, 1 );或atomic系列宏 为什么sleep和不sleep结果不同? sleep时, goroutine们先运行 不sleep时, 大概率主线程先运行, 此时goroutine们还没有开始 后面加了打印x的版本看的更清楚: 不sleep时, goroutine都没有开始执行. 我们改一下代码: 注: 在最后是不能打印i的值的, 因为i的作用域只在循环里面, 出了循环就没有了. 这里首先有个警告: 是go vet打印出来的, 大意是说循环变量i被goroutine函数func捕获. 一般这样用容易出问题. 这也说明go提供里vet机制, 能做代码静态检查 每个goroutine的x, 都是同一个x, 没有私有拷贝. 在x++的时候, 从同一个地址取值, 加一, 再放回同一个内存地址. 所以现象上是正常的, 但前提是单核运行才正常. 每个goroutine都打印循环变量i, 但都是5; 因为i在for里改变, 等到goroutine被调度执行时, 这个变量已经是5了. 把i在循环里赋值给ii, 结果又不一样: 注: 区别在于变量ii的位置: 在循环外定义, 则ii只是一个地址. 在循环里面定义, 则ii每次进循环都要重新创建, 地址不一样. 地址不变, 则goroutine取值的时候, 就只能拿到一个值. 地址变了, 则每个goroutine都能取到对应的值. goroutine知道自己要\"捕获\"哪个ii 把17行的go关键词去掉, 只留闭包函数func, 则这个func会在loop里依次被调用, 打印正常的0到4. 调试环境变量 举例 #10s钟打印一次调度信息 GODEBUG=schedtrace=10000,scheddetail=1 GOTRACEBACK=system ./json_load -fileName test.json -loopNum 100000 > /dev/null GODEBUG GODEBUG环境变量包括子变量, 用name=val, name=val的形式, 详见https://golang.org/pkg/runtime/ #GC相关的 allocfreetrace=1 gctrace=1 #cgo cgocheck=1 #调度, 每X ms打印信息 schedtrace=X and scheddetail=1 GOTRACEBACK 默认在程序出错时打印调用栈, #依次加强 GOTRACEBACK=none GOTRACEBACK=single 默认 GOTRACEBACK=all GOTRACEBACK=system GOTRACEBACK=crash 触发coredump 名字冲突和type别名 在匿名继承过程中, 我遇到了一个问题: tengo.String类型, 有String()方法. 如果我想继承这个类型, 通常是这样写: package extension type String struct { tengo.String } 但编译不通过, 大意是String是个field name, 但我们这里需要String()方法. 原因是extension.String, 有String属性, 也有String()方法, 重名了. go编译器不允许field name和method name重名, 否则会冲突. type定义新类型 下面的代码也是不行的, 甚至更糟: package extension type tString tengo.String type String struct { tString } 因为tString是个新的类型, 没有任何方法; 匿名包含tString继承不到任何东西 type别名 这里要用type的别名机制: 定义type的时候用=号 package extension type tString = tengo.String type String struct { tString } 别名保留原名的所有东西. 所以这里tSting就是tengo.String, 只是拼写不一样了. 原始解释 An alias declaration doesn’t create a new distinct type different from the type it’s created from. It just introduces an alias name T1, an alternate spelling, for the type denoted by T2. Type aliases are not meant for everyday use. They were introduced to support gradual code repair while moving a type between packages during large-scale refactoring. Codebase Refactoring (with help from Go) covers this in detail. goroutine vs thread 默认的thread数 一个go进程会起GOMAXPROCS 个线程, 从go1.5之后, 这个值默认是CPU核数. 可以在环境变量改, 也可以用runtime.GOMAXPROCS来在运行时改. GOMAXPROCS=4 goapp 注意GOMAXPROCS 是指同时running的线程数, 不包括被block的线程. go进程对block的线程数没有限制. goroutine介绍 参考 https://codeburst.io/why-goroutines-are-not-lightweight-threads-7c460c1f155f https://medium.com/@riteeksrivastava/a-complete-journey-with-goroutines-8472630c7f5c goroutine并不是linux thread, 但建立在thread上, 受go runtime scheduler调度的任务单位. 对比linux thread, 它更轻量, 表现在如下几个方面: thread的stack比较大, > 1M, 所以如果有1000个thread, 要占1G的内存; goroutine默认stack是2K, 如果有goroutine需要更大的stack, 会分配新的内存区域. goroutine不受OS调度, 而是受go runtime scheduler调度, 所以不需要比如100Hz的中断来调度 基本上, 调度的策略类似linux的非抢占模式, 主动让出或阻塞时让出CPU. goroutine阻塞是阻塞在当前运行它的线程, go scheduler会运行其他thread来运行其他goroutine. 不需要等线程阻塞才调度, 比如goroutine用channel和另一个goroutine通信, 本身并不会导致goroutine所在线程阻塞, 但go scheduler会调度其他goroutine来在当前线程替代之前的goroutine运行. 一个goroutine被调度运行, 只发生在当前的goroutine 调用了channel send, 并阻塞 用go关键词启动一个goroutine 在file access或network相关系统调用上阻塞 被Gc停住后 thread上下文切换的代价偏大, 要保存很多寄存器, 除了常见的通用寄存器, 还包括AVX, SSE, 浮点等. goroutine则不需要保存这么多的寄存器, 因为调度都在特定的点上, 那保存的寄存器也是按需的. json和万能interface{} 普通的结构体和[]byte的转换, 用json.Marshal()和json.Unmarshal() 已知结构体 b := []byte(`{\"Name\":\"Wednesday\",\"Age\":6,\"Parents\":[\"Gomez\",\"Morticia\"]}`) type FamilyMember struct { Name string Age int Parents []string } var m FamilyMember err := json.Unmarshal(b, &m) 注意: 用var声明FamilyMember变量m的时候, Parents还只是个nil 而Unmarshal会再后台申请新的切片来放Parents 同样的, 比如下面, 如果结构体中包括指针, 则Unmarshal会申请Bar的空间.type Foo struct { Bar *Bar } 不知道结构体情况下 那不知道结构体的json, 怎么解析呢? 这就要用到万能的interface{}接口了. The json package uses map[string]interface{} and []interface{} values to store arbitrary JSON objects and arrays; it will happily unmarshal any valid JSON blob into a plain interface{} value. //比如b是json, 但不知道对应的结构体 b := []byte(`{\"Name\":\"Wednesday\",\"Age\":6,\"Parents\":[\"Gomez\",\"Morticia\"]}`) var f interface{} err := json.Unmarshal(b, &f) fmt.Printf(\"%#v\\n\", f) //输出, 可以看到, 这个map的key是string, value是interface{}, 因为只有interface{}可以是任何东西. map[string]interface {}{\"Age\":6, \"Name\":\"Wednesday\", \"Parents\":[]interface {}{\"Gomez\", \"Morticia\"}} //此时用类型断言得到这个类型的\"值\", 也就是这个map m := f.(map[string]interface{}) //然后就可以用range来遍历了 for k, v := range m { switch vv := v.(type) { case string: fmt.Println(k, \"is string\", vv) case float64: fmt.Println(k, \"is float64\", vv) case []interface{}: fmt.Println(k, \"is an array:\") for i, u := range vv { fmt.Println(i, u) } default: fmt.Println(k, \"is of a type I don't know how to handle\") } } 常见的json类型对照: bool for JSON booleans, float64 for JSON numbers, string for JSON strings, and nil for JSON null. encoder和decoder func NewDecoder(r io.Reader) *Decoder func NewEncoder(w io.Writer) *Encoder package main import ( \"encoding/json\" \"log\" \"os\" ) func main() { dec := json.NewDecoder(os.Stdin) enc := json.NewEncoder(os.Stdout) for { var v map[string]interface{} if err := dec.Decode(&v); err != nil { log.Println(err) return } for k := range v { if k != \"Name\" { delete(v, k) } } if err := enc.Encode(&v); err != nil { log.Println(err) } } } "},"notes/golang_杂记1.html":{"url":"notes/golang_杂记1.html","title":"杂记1","keywords":"","body":" 类型断言很慢吗? 结果 zlib压缩 gob编码 gob会缓存 结论 gob的编码规则 decode时使用指针方式避免interface的值拷贝 msg的值拷贝 优化成指针 interface也可以序列化, 但需要Register 输出 如果不Register会怎样? 顶层是interface{}的情况 能直接encode interface{} 使用interface的地址来encode Register()函数 非要Register()吗? 没有特列, append也是值拷贝 要用interface抽象行为, 就不要多一层struct马甲. interface{}变量可以直接和concrete类型的变量比较 Read不能保证全读 用io.ReadFull 没有io.WriteFull string强转 先return再defer, defer里面能看到return的值 包的初始化只执行一次 goroutine与channel 使用channel时一定要判断peer的goroutine是否还在1 问题场景 解决 使用channel时一定要判断peer的goroutine是否还在2 解决 写空的channel不会panic 简单的程序可以检测死锁 复杂的程序检测不出来, 直接卡住 patherror 永久阻塞 selectgo源码杂记 强转成切片指针 突破数组大小限制 切片截取 子切片共享底层数组 go test 测试对象方法 子项 性能测试 不推荐用self或者this指代receiver 范式 在链接阶段对全局变量赋值 使用场景 如何做到的? 链接选项 编译限制Build Constraints 使用-tags参数指定用户自定义constraints 无表达式的switch 无缓冲和缓冲为1的通道不一样 书 go内存模型 解决1: 用channel 解决2: 用sync sync的once 类型断言很慢吗? 答: 不慢, 甚至比直接函数调用还快... 黑科技 package main import ( \"testing\" ) type myint int64 type Inccer interface { inc() } func (i *myint) inc() { *i = *i + 1 } func BenchmarkIntmethod(b *testing.B) { i := new(myint) incnIntmethod(i, b.N) } func BenchmarkInterface(b *testing.B) { i := new(myint) incnInterface(i, b.N) } func BenchmarkTypeSwitch(b *testing.B) { i := new(myint) incnSwitch(i, b.N) } func BenchmarkTypeAssertion(b *testing.B) { i := new(myint) incnAssertion(i, b.N) } func incnIntmethod(i *myint, n int) { for k := 0; k 结果 yingjieb@3a9f377eee5d /repo/yingjieb/godev/practice/src/benchmarks/typeassertion $ go test -bench . goos: linux goarch: amd64 BenchmarkIntmethod-23 465990427 2.55 ns/op BenchmarkInterface-23 269690563 4.46 ns/op BenchmarkTypeSwitch-23 590743738 2.06 ns/op BenchmarkTypeAssertion-23 577222344 2.10 ns/op PASS ok _/repo/yingjieb/godev/practice/src/benchmarks/typeassertion 5.949s BenchmarkInterface: 通过interface直接调用最慢 BenchmarkIntmethod: 直接函数调用做为基准 BenchmarkTypeSwitch/BenchmarkTypeAssertion: 类型断言比直接函数调用还快!!!!! zlib压缩 zlib提供的压缩接口是io.Writer. 即z := zlib.NewWriter(s)是个io.Writer, 往里面写就是压缩写. 但要调用z.Close()接口做flush操作, close后数据才写入底层的io.Writer. 不想close的话, 调用Flush()接口也行. gob编码 json的编码体积偏大, 改用gob的性能和json差不多, 但体积能减小一半. gob专用于go程序之间的数据编码方法, 借鉴并改进了了很多GPB的设计, 应该说是go世界的首选序列化反序列化方法. gob会缓存 比如发送方连续两次发送 conn.enc.Encode(A) conn.enc.Encode(B) 在接收方看起来, 连续两次Decode, 能还原A和B的值 conn.enc.Decode(&A) conn.enc.Decode(&B) 如果两次Encode间隔很短, 比如连续的2次Encode, 在对端Decode的时候, 第一把decode A的时候, 可能已经缓存了部分B的字节, 第二把decode可以用这个缓存. 但如果A的后面是对原始io.Reader的直接操做, 比如: conn.enc.Decode(&A) io.Copy(os.Stdout, conn) 那么可能os.Stdout不会看到B, B缓存在第一把的Decode里面. 比如在发送方发送A和B之间加个sleep 1秒, 实验结果是对A的decode就不缓存. 结论 如果发送方encode间隔很短, gob会预取socket里面的紧跟着上次encode的内容, 那么: 接收方一直用gob去decode的话, 是没问题的. 但如果decode中途去直接操做io读, 是可能读不到数据的. gob的编码规则 以int为基础, size变长 第一次传输一个新的结构体的时候, 先传输这个结构体的定义, 即layout 后面传输的时候, 带结构体标识就可以了 即先描述这个东西长什么样子, 取个名字, 后面直接用名字指代. decode时使用指针方式避免interface的值拷贝 之前我的代码里定义了isMessageOut和messageIn两个接口 // messageOut represents a message to be sent type messageOut interface { isMessageOut() } // messageIn represents an incoming message, a handler is needed to process the message type messageIn interface { // reply(if not nil) is the data that will be sent back to the connection, // the message may be marshaled or compressed. // remember in golang assignment to interface is also value copy, // so return reply as &someStruct whenever possible in your handler implementation. handle() (reply messageOut, err error) } 我有个record类型的结构体要传输. 在接收端, 我定义了handle方法, 接收到messageIn类型的结构体就可以直接handle()了 type record struct { Timestamp int64 Payload recordPayload } func (rcd record) handle() (reply messageOut, err error) { fmt.Println(rcd) return nil, nil } func fakeServer() { ... var msg messageIn for { decoder.Decode(&msg) reply, err := msg.handle() } } 注意decoder.Decode(&msg), 要求msg必须是messageIn, decoder会自动分配concrete类型实例并赋值给msg. 如果对端发过来的消息concrete类型不是messageIn, Decode会返回错误, 类似这样: gob: local interface type *main.messageIn can only be decoded from remote interface type; received concrete type string 意思是对端发过来的是string类型, 我已经收好了; 但是你不是messageIn, 所以不符合用户要求. msg的值拷贝 上面的代码可以工作, 但有个性能问题. 注意到record的handle()接收record的值, 而不是指针. 所以第16行reply, err := msg.handle()时, 对msg发生了一次值拷贝. 在go里面, 值拷贝是浅拷贝, 一般性能开销不大. 因为浅拷贝遇到切片, 字符串, map等等\"引用\"属性的对象, 浅拷贝只拷贝\"指针\", 不拷贝内容. 但这里为了进一步避免浅拷贝, 需要想办法把record的实现改成下面:注意只多了个* func (rcd *record) handle() (reply messageOut, err error) { fmt.Println(rcd) return nil, nil } 编译没问题, 但运行时gob报错: gob: main.record is not assignable to type main.messageIn 熟悉interface的同学应该知道这里的意思其实是: decoder.Decode(&msg) decode出来的\"值\", 不是messageIn, 不能赋值给msg. 那decode出来的\"值\"是什么呢? 这就要提到gob要求interface的具体类型要注册, 我是这样注册的: //在初始化路径上调用一次 gob.Register(record{}) 那么decode出来的\"值\"就是record{}, 而record不是messageIn, *record才是 优化成指针 那么这样改就可以: 把*record注册给gob gob.Register(&record{}) interface也可以序列化, 但需要Register 比如下面的代码中, 要marshal的是record结构体. type record struct { Timestamp int64 // time.Now().Unix() Payload interface{} } 但它的Payload部分是个interface, 可以是 string []processInfo{}type processInfo struct { Pid int Ucpu string //%.2f Scpu string //%.2f Mem uint64 Name string } 一个是内置的字符串, 一个是自定义的结构体数组. 对record类型来说, 这两个类型都是叫Payload 前面说过, 每个新东西都要描述一番, 取个名字. 但对interface来说, 它有很多面孔. 一个描述是不够的. 所以gob规定, interface所指代的具体类型, 要先注册. 下面的Register()调用就注册了这个结构体数组 //把nil强转成目标类型的实例, 因为Register接收实例 //gob.Register([]processInfo{})也是可以的, 只要能得到实例 gob.Register([]processInfo(nil)) var tmp bytes.Buffer enc := gob.NewEncoder(&tmp) dec := gob.NewDecoder(&tmp) //模拟processInfo切片 err := enc.Encode(record{time.Now().Unix(), []processInfo{}}) fmt.Println(\"encoded:\", string(tmp.Bytes())) //模拟一个hello字符串 err := enc.Encode(record{time.Now().Unix(), \"hello\"}) fmt.Println(\"encoded:\", string(tmp.Bytes())) err = dec.Decode(&data) switch v := data.Payload.(type) { case []processInfo: fmt.Println(data.Timestamp, \"====processinfo \", v) case string: fmt.Println(data.Timestamp, \"====string \", v) } 输出 这里用string强转了bytes, 有些不能打印字符. $ ./topid -p 2 -snapshot //从这里可以看出来, 第一次描述了processInfo的layout encoded: .record TimestampPayload)[]main.processInfoD processInfoPidUcpu Scpu MemName .000.0kthreadd //能被decode还原 1590418131 ====processinfo [{2 0.00 0.00 0 kthreadd}] //Payload的string方式第一次出现 描述一下. 有些byte没打印, 但应该第一次的信息是全的. encoded: string hello 1590418131 ====string hello //后面的打印就不带layout信息了 encoded: ;[]main.processInfo.000.0kthreadd 1590418132 ====processinfo [{2 0.00 0.00 0 kthreadd}] encoded: ;[]main.processInfo.000.0kthreadd 1590418133 ====processinfo [{2 0.00 0.00 0 kthreadd}] ... //不知为何, 原始string还是每次有带. encoded: string hello 1590418161 ====string hello 如果不Register会怎样? 不管encode还是decode, 都会打印提示: gob: type not registered for interface: []main.processInfo 顶层是interface{}的情况 上面的例子中, bog可以编码结构体中间的field是interface{}的情况. 那么如果直接encode一个interface{}可以吗? 能decode吗? 先回答: 能; 能, 但需要技巧. 能直接encode interface{} encode的入参就是interface{}类型, 即任何类型都可以被encode. 一个interface{}变量在被赋值的时候, runtime知道它的concrete类型. 参考 神作: interface的运行时的lookup Go Data Structures: Interfaces gob会按照concreate类型传输. 所以这样的代码是可以被encode的. var msg interface{} // msg = anyvariable enc.Encode(msg) 但不能被decode. var msg interface{} dec.Decode(&msg) 报错误: gob: local interface type *interface {} can only be decoded from remote interface type; received concrete type sessionReq = struct { SessionTag string; SysInfo sysInfo = struct { BoardName string; CPUInfo string; KernelInfo string; PackageInfo packageInfo = struct { BuildVersion string; SwID string; BuildServer string; BuildDate string; Repo string; Branch string; }; }; } 这个错误说明两点: gob知道对方传输过来的结构体, 并且能精确解析 但gob不能把它decode给*interface {}, 即&msg; gob还提示, decode给interface必须对端也是interface类型. 使用interface的地址来encode gob支持interface的传输, 比如在再上面的record类型中的interface就可以被传输和decode. 但顶层的interface需要些技巧. 在encode的时候, 传入interface的地址就行. 这样: // encode var msg interface{} // msg = anyvariable enc.Encode(&msg) // decode var msg interface{} dec.Decode(&msg) 很对称, 挺好的. gob会对指针解引用, encode时&msg被赋值给内部interface{}时, gob发现这是个指针类型, 指向interface类型. 所以gob按照interface类型来传输 根据interface的传输规则, encode端和decode端都要提前注册具体类型到gob Register()函数 使用了Type的String方法获得类型的名称 func Register(value interface{}) { rt := reflect.TypeOf(value) name := rt.String() //处理指针的情况, 指针前面加* RegisterName(name, value) gob包默认注册了基础类型 func registerBasics() { Register(int(0)) Register(int8(0)) Register(int16(0)) Register(int32(0)) Register(int64(0)) Register(uint(0)) Register(uint8(0)) Register(uint16(0)) Register(uint32(0)) Register(uint64(0)) Register(float32(0)) Register(float64(0)) Register(complex64(0i)) Register(complex128(0i)) Register(uintptr(0)) Register(false) Register(\"\") Register([]byte(nil)) Register([]int(nil)) Register([]int8(nil)) Register([]int16(nil)) Register([]int32(nil)) Register([]int64(nil)) Register([]uint(nil)) Register([]uint8(nil)) Register([]uint16(nil)) Register([]uint32(nil)) Register([]uint64(nil)) Register([]float32(nil)) Register([]float64(nil)) Register([]complex64(nil)) Register([]complex128(nil)) Register([]uintptr(nil)) Register([]bool(nil)) Register([]string(nil)) } 非要Register()吗? 既然有实例就能注册, 为什么不在encode/decode时自动注册了, 非要搞一个Register()?答: 可能是因为用了反射比较慢的缘故. 注册一次就够了, 每次都\"注册\"反射开销大. 没有特列, append也是值拷贝 那问题是, 做为入参传入append的时候, 是否已经发生了一次值拷贝, 然后再拷贝到[]slice里面去? 要用interface抽象行为, 就不要多一层struct马甲. 少用通用的interface然后再在里面搞类型断言; 而是用具体的interface, 这样在编译阶段就能\"断言\"类型. 比如下面的第45行. package main import ( \"bytes\" \"encoding/json\" \"fmt\" //\"os\" \"bufio\" \"io\" ) type record interface { tag() string doPrint() } type teacher struct { Name string } type student struct { Id int Name string Class int Email string Message string } func (stdt *student) tag() string { return \"student\" } func (stdt *student) doPrint() { fmt.Println(\"do student\", stdt) } func (tc *teacher) tag() string { return \"teacher\" } func (tc *teacher) doPrint() { fmt.Println(\"do teacher\", tc) } func marshalRecord(w io.Writer, rcd record) error { jsn, err := json.Marshal(rcd) if err != nil { return err } w.Write([]byte(rcd.tag() + \": \")) w.Write(jsn) w.Write([]byte{'\\n'}) return nil } func main() { var b bytes.Buffer stdt := student{Id: 9527, Name: \"sam\", Class: 3, Email: \"sam@godev.com\", Message: \"hello\\n world\\n\"} err := marshalRecord(&b, &stdt) if err != nil { fmt.Println(err) } tc := teacher{Name: \"shuxue\"} err = marshalRecord(&b, &tc) if err != nil { fmt.Println(err) } //b.WriteTo(os.Stdout) r := bufio.NewReader(&b) for { line, err := r.ReadBytes('\\n') if err != nil { return } fmt.Printf(\"%s\", line) sep := bytes.Index(line, []byte{':'}) key := string(line[:sep]) value := line[sep+2:] fmt.Printf(\"key: %s\\n\", key) fmt.Printf(\"value: %s\\n\", value) var rcd record switch key { case \"student\": rcd = &student{} case \"teacher\": rcd = &teacher{} } err = json.Unmarshal(value, rcd) if err != nil { fmt.Println(err) return } rcd.doPrint() } } interface{}变量可以直接和concrete类型的变量比较 我实现了一个map, 提供set和get函数. get出来的value是个万能interface{}, func (im *intMap) set(k int, v interface{}) { _, has := im.mp[k] if !has { im.ks = append(im.ks, k) } im.mp[k] = v } func (im *intMap) get(k int) interface{} { v, has := im.mp[k] if has { return v } return nil } func main() { im := newIntMap(10) im.set(1, \"1234\") # v的类型是interface v := im.get(1) show(v) //interface变量可以直接和具体类型的值比较 if v == \"1234\" { fmt.Println(\"interface{} can be compared directly with string\") } im.set(2, &[]int{1, 2, 3}) v = im.get(2) //这里可以比较, 但地址是不一样的 if v == &[]int{1, 2, 3} { fmt.Println(\"should not be\") } show(v) im.set(3, struct{ a, b, c int }{1, 2, 3}) v = im.get(3) //结构体也可以比较, 但前提是结构体里面的元素都可以比较 if v == struct{ a, b, c int }{1, 2, 3} { fmt.Println(\"interface{} can be compared directly with comparable struct\") } show(v) im.set(4, 155) v = im.get(4) show(v) //可以直接和整型比较 if v == 155 { fmt.Println(\"interface{} can be compared directly with int\") } v = im.get(100) // 100不存在, v是nil // nil可以比较, 不会panic; 只是从来不一致. if v == 10086 { fmt.Println(\"nil interface{} can be compared, but never succeed\") } show(v) //切片不能比较 /* if v == []int{5,6,7} { fmt.Println(\"error! operator == not defined on slice\") } */ } //结果: string:(\"1234\") interface{} can be compared directly with string *[]int:([]int{1, 2, 3})@[0xc0000ac040] interface{} can be compared directly with comparable struct struct { a int; b int; c int }:(struct { a int; b int; c int }{a:1, b:2, c:3}) int:(155) interface{} can be compared directly with int :() Read不能保证全读 golang的Reader不保证能read完整的len(buf), 即使没有到EOF, Read也不保证完整的Read. 所以Read会返回已经读的字节数n type Reader interface { Read(p []byte) (n int, err error) } 在C里面, 系统调用read()可能被信号打断而提前返回, 俗称短读. 一般的做法是自己写个包装, 用while一直读, 直到读完为止. 用io.ReadFull 在go里, io包已经提供了这个包装, 就是 func ReadFull(r Reader, buf []byte) (n int, err error) ReadFull保证填满buf, 除非EOF时buf还没填满, 此时返回ErrUnexpectedEOF ReadFull实际上是调用ReadAtLeast func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error) { if len(buf) = min { err = nil } else if n > 0 && err == EOF { err = ErrUnexpectedEOF } return } ReadAtLeast()用一个循环反复Read() 没有io.WriteFull 标准库里面有ReadFull, 但没有WriteFull. 为什么呢? 有人还真实现了WriteFull, 有必要吗? 没必要: 因为read的语义允许short read而不返回error; 但write的语义是要写就都写完, 除非有错误. I would really rather not. ReadFull exists because Read is allowed to return less than was asked without an error. Write is not. I don't want to encourage people to think that buggy Writers are okay by introducing a buggy Writer fixer. string强转 结论: byte强转成string, 会去掉其中的0 buf := make([]byte, 32) buf = append(buf, '1', 0, '2') fmt.Println(buf) fmt.Println(string(buf)) //结果: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 49 0 50] 12 说明byte切片转成string, 每个byte都被扫描, 去掉其中的0. 也说明go里面的类型转换, 是有不小开销的. 先return再defer, defer里面能看到return的值 func checkHierarchy(p int) (err error) { //defer里面可以直接使用returned变量 defer func() { if err != nil { fmt.Println(err) } else { fmt.Println(\"no err returned\") } }() //对返回变量直接赋值是可以的 err = errors.New(\"default err\") if p == 1 { return nil } else if p == 2 || p == 3{ //相当于对err赋值. return fmt.Errorf(\"return: %d\", p) } //空的return会默认返回有名的return变量, 即上面的err return } func main() { checkHierarchy(1) checkHierarchy(2) checkHierarchy(3) checkHierarchy(4) } //输出 no err returned return: 2 return: 3 default err defer里面可以直接使用return变量 空的return会默认返回有名的return变量 程序里可以提前对有名的return变量赋值, 然后用空return返回该值. 带值的return实际上会给有名的return变量赋值, defer的时候看到的是return的指定值. defer在return之后执行 -- 先执行return那一行. 下面的代码会返回\"Change World\"而不是\"Hello World\" func foo() (result string) { defer func() { result = \"Change World\" // change value at the very last moment }() return \"Hello World\" } 包的初始化只执行一次 Package initialization is done only once even if package is imported many times. goroutine与channel goroutine的生命周期和channel要配合, routine的产生与消亡要考虑对channel的影响 使用channel时一定要判断peer的goroutine是否还在1 这个例子中,newPidInfo()函数中, 起了goroutine pi.checkThreads() func newPidInfo(pid int, ppi *PidInfo) (*PidInfo, error) { pi.hierarchyDone = make(chan int) go func() { pi.err = pi.checkThreads() }() pi.triggerAndWaitHierarchy() } func (pi *PidInfo) checkThreads() error { defer func() { pi.hierarchyDone pi.checkThreads()虽然做了异常分支的channel处理, 比如defer那句. 但这里还是出了channel问题. 问题场景 某次进程A要更新hierarchy, A发hierarchyCheck A的checkThreads守护routine收到hierarchyCheck信号, 开始doWork() A的doWork()里, 触发子进程B的hierarchyCheck 子进程B的checkThreads守护routine开始doWork() B的doWork()出错, B的hierarchyDone从异常分支写1, 通知A的doWork()往下走. 对应代码第20行 OK. 到这里还是正常的 下次A要更新hierarchy, A发hierarchyCheck A的checkThreads守护routine收到hierarchyCheck信号, 开始doWork() A的doWork()里, 不知什么原因, A还是认为自己有子进程B. 触发子进程B的hierarchyCheck 子进程B已经没有checkThreads守护routine A永远阻塞在第42行 本质上, 出现问题的原因是: 子进程B的goroutine的异常分支已经完善, 但goroutine异常退出后, 业务逻辑不应该再去用channel和子进程B交互. 即永远判断要交互的goroutine是否存在. 解决 triggerAndWaitHierarchy()加异常判断 func (pi *PidInfo) triggerAndWaitHierarchy() { //for some reason there is no checkThreads routine, thus nowhere we can send to and receive from //this can happen if the children file has the child, but actually the child is dying if pi.err != nil { //fmt.Println(pi.err) return } //trigger once, none blocking pi.hierarchyCheck 使用channel时一定要判断peer的goroutine是否还在2 比如下面的代码, 倒数第二行在写channel的时候, 对应的checkChild协程不一定能到达37行select. 实际上, 只有一个case的select可以只保留channel读部分. for _, tid := range pi.threadIds { tid := tid if pi.childCheckers[tid] == nil { s := childChecker{make(chan int), make(chan []int, 1)} checkChild := func() { f, err := os.Open(\"/proc/\" + pi.pidstr + \"/task/\" + strconv.Itoa(tid) + \"/children\") if err != nil { return } defer f.Close() doWork := func() []int { if _, err := f.Seek(0, 0); err != nil { return nil } buf, err := ioutil.ReadAll(f) if err != nil { return nil } //ToDo: return nil if buf is empty strs := strings.Fields(string(buf)) childrenIds := make([]int, len(strs)) for i := 0; i 实际上, 这里还有一个错误. 在后面的处理里, 下面代码倒数第二行, 会阻塞的从childCheckers[tid].children读出数据, 但如果上面的goroutine异常退出了, //use new refilled map pi.childCheckers = childCheckers //with initial capacity of the previous run pi.childrenIds = make([]int, 0, len(pi.childrenIds)) for _, tid := range pi.threadIds { //concatenate the children slices retrieved from channel to a single one pi.childrenIds = append(pi.childrenIds, 解决 在goroutine刚开始, 加defer函数, 默认退出时读/写channel 这里用的非阻塞读写. checkChild := func() { defer func() { select { case 写空的channel不会panic 简单的程序可以检测死锁 func main() { var c chan int c 复杂的程序检测不出来, 直接卡住 //pi.hierarchyDone是个空的channel for { select { case patherror // requires go1.13 and later func pathError(err error) bool { var perr *os.PathError if errors.As(err, &perr) { return true } return false } 永久阻塞 空的select永远等待 select {} selectgo源码杂记 selectgo()函数是select语句的runtime实现, 由编译器在编译时把select语句块转换为runtime的selectgo()的调用. 强转成切片指针 下面的代码是把一个指针, 强转成指向数组的指针; go里面强转不是万能的, 指针必须转成指针 cas1 := (*[1 和下面的效果类似 func main() { s := []int{1,2,3,4,5,6,7} sp := &s fmt.Println(sp) sp3 := (*[3]int)(unsafe.Pointer(&s[0])) fmt.Println(sp3) } //结果 &[1 2 3 4 5 6 7] &[1 2 3] 突破数组大小限制 func main() { s := [7]int{1,2,3,4,5,6,7} //数组的指针可以当数组用 sp := &s //如果s是切片, 则下面语句报错:(type *[]int does not support indexing) sp[1] = 999 fmt.Println(sp) //强转成指向数组的指针可以突破数组的length限制 //但要注意, 你明确知道在干什么. 否则, segment fault snp := (*[20]int)(unsafe.Pointer(&s[0])) snp[15] = 995 fmt.Println(snp) } 切片截取 比如slice是个切片, 那么slice[ i : j : k ]是截取slice并限制capacity的切片: Length: j - i Capacity: k - i 第三个参数的用法不常见, 但加了可以限制新切片的capacity的能力, 好处是防止越过capacity访问. 下面的代码取自selectgo, 就使用了第二个冒号, scases := cas1[:ncases:ncases] pollorder := order1[:ncases:ncases] lockorder := order1[ncases:][:ncases:ncases] 子切片共享底层数组 子切片的capacity和其主切片的capacity有关, 因为他们都共享底层的数组. 比如下面的例子证明了, 子切片的修改会影响到母切片. func main() { s := []int{1,2,3,4,5,6,7} s1 := s[0:3] fmt.Println(s) fmt.Println(s1) //修改切片s1会影响原切片s s1[1] = 999 fmt.Println(s) fmt.Println(s1) //非法访问, slice越界 //panic: runtime error: index out of range [5] with length 3 s1[5] = 888 } 结果: [1 2 3 4 5 6 7] [1 2 3] [1 999 3 4 5 6 7] [1 999 3] go test 测试对象方法 用Test对象名_方法名. 比如tengo代码中的 func TestScript_Run(t *testing.T) { s := tengo.NewScript([]byte(`a := b`)) err := s.Add(\"b\", 5) require.NoError(t, err) c, err := s.Run() require.NoError(t, err) require.NotNil(t, c) compiledGet(t, c, \"a\", int64(5)) } 子项 Test 函数可以调用t.Run func TestFoo(t *testing.T) { // t.Run(\"A=1\", func(t *testing.T) { ... }) t.Run(\"A=2\", func(t *testing.T) { ... }) t.Run(\"B=1\", func(t *testing.T) { ... }) // } go test可以指定子项: go test -run Foo # Run top-level tests matching \"Foo\", such as \"TestFooBar\" go test -run Foo/A= # For top-level tests matching \"Foo\", run subtests matching \"A=\" go test -run /A=1 # For all top-level tests, run subtests matching \"A=1\" 性能测试 用go test -bench func BenchmarkHello(b *testing.B) { big := NewBig() //开始循环测试之前先reset时间 b.ResetTimer() for i := 0; i 用b.RunParallel()来并发执行, 和-cpu 1,2,4配合, 可以测一个核, 两个核, 四个核的并发性能 go help testflag查看详细的选项 不推荐用self或者this指代receiver https://stackoverflow.com/questions/23482068/in-go-is-naming-the-receiver-variable-self-misleading-or-good-practice receiver有两个作用, 第一, 声明了类型和方法的绑定关系. 第二, 在运行时给方法额外传了这个类型的参数. 对v.Method()的调用时编译器的语法糖, 本质上是(T).Method(v). 参考这里 C++和Python的方法基于具体对象, 所以this和self隐含代指这个具体对象的内存地址, 和方法是紧耦合关系. 而go的方法基于类型, 和具体对象是松耦合关系, 具体的对象只是做为额外的参数传给方法. 以下代码可以运行, 没有错误 package main import \"fmt\" type T struct{} func (t T) Method(msg string) { fmt.Println(msg) } func main() { t := T{} t.Method(\"hello\") // this is valid //使用类型调用方法, 第一个参数是实例 (T).Method(t, \"world\") // this too } 范式 所以实例只是其中的一个参数, 要给个合适的名字, go惯例使用类型的第一个字母小写, 或者更贴切的名字. type MyStruct struct { Name string } //这个更符合go的范式 func (m *MyStruct) MyMethod() error { // do something useful } //self的语义并不贴切 func (self *MyStruct) MyMethod() error { // do something useful } 在链接阶段对全局变量赋值 使用场景 在vonu里面, 编译的时候传入了git commit id和编译时间; 在go build的时候用-ldflags传入 LDFLAGS=-ldflags '-X env.VOnuRevCommitId=$(VONUMGMT_REV_COMMIT_ID) -X \"env.VOnuBuildDate=$(VONUMGMT_BUILD_DATE)\"' go build $(LDFLAGS) -tags static $(APP_MAIN) 这个env.VOnuRevCommitId是env包里的一个全局变量 //定义的时候是nil var VOnuRevCommitId string //直接使用 func VOnuRevCommitIdInfo() string { return VOnuRevCommitId } 如何做到的? go build可以传入的选项有: -a 强制全部重编 -work 不删除临时目录 -race 打开竞争检查 -buildmode 比如共享库方式的选择 -compiler 选gccgo或者gc -gccgoflags -gcflags -ldflags arguments to pass on each go tool link invocation 这是本节的重点 -linkshared 链接共享库 -tags 自定义build constraints -trimpath 不保存绝对路径, 这个功能很好! 链接选项 其中-ldflags里面说到go tool link, 那就要看它的help go tool link -h //go tool link控制很底层的链接行为, 比如链接地址, 共享库路径 -T address 代码段起始地址 -X importpath.name=value 这就是本节用到的点, 定义package.name的变量未value, value是字符串 链接的时候\"初始化\"这个变量 -cpuprofile 写profiling信息到文件 -dumpdep -linkmode -buildmode // 对减小size有好处 -s disable symbol table -w disable DWARF generation 所以这里用了-X选项, 在链接的时候\"初始化\"变量值. 编译限制Build Constraints 详细说明: go doc build 编译限制用来指明一个文件是否要参与编译, 形式上要在文件开始的时候, \"注释\"编译限制, 比如: 只在linux并且使用cgo, 或者OS x并且使用cgo情况下编译该文件 // +build linux,cgo darwin,cgo 只在ignore情况下编译, 即不参与编译. 因为没有东西会匹配ignore. 用其他怪异的tag也行, 但ignore的意思更贴切 // +build ignore 这个注释必须在package语句之前 内置的tag有: During a particular build, the following words are satisfied: - the target operating system, as spelled by runtime.GOOS - the target architecture, as spelled by runtime.GOARCH - the compiler being used, either \"gc\" or \"gccgo\" - \"cgo\", if ctxt.CgoEnabled is true - \"go1.1\", from Go version 1.1 onward - \"go1.2\", from Go version 1.2 onward - \"go1.3\", from Go version 1.3 onward - \"go1.4\", from Go version 1.4 onward - \"go1.5\", from Go version 1.5 onward - \"go1.6\", from Go version 1.6 onward - \"go1.7\", from Go version 1.7 onward - \"go1.8\", from Go version 1.8 onward - \"go1.9\", from Go version 1.9 onward - \"go1.10\", from Go version 1.10 onward - \"go1.11\", from Go version 1.11 onward - \"go1.12\", from Go version 1.12 onward - \"go1.13\", from Go version 1.13 onward - \"go1.14\", from Go version 1.14 onward - any additional words listed in ctxt.BuildTags 另外, 如果文件名有如下形式, 则会被go build认为是隐含了对应tag的build constraint *_GOOS *_GOARCH *_GOOS_GOARCH 使用-tags参数指定用户自定义constraints 比如在kafka.go最开始添加: // +build !device 这里的device就是自定义的tag, 这里的意思是不带device的tag时, kafka.go才参与编译. 或者说有device的tag, kafka.go不编. 下面是测试结果: 带了device tag, $ RUNMODE=cloud go test -tags device --- FAIL: TestMsgCall (0.00s) msgchan_test.go:20: No message channel for kafka FAIL exit status 1 FAIL msgchan 0.002s 无表达式的switch switch 中的表达式是可选的，可以省略。如果省略表达式，则相当于 switch true，这种情况下会将每一个 case 的表达式的求值结果与 true 做比较，如果相等，则执行相应的代码。 func main() { num := 75 switch { // expression is omitted case num >= 0 && num = 51 && num = 101: fmt.Println(\"num is greater than 100\") } } 无缓冲和缓冲为1的通道不一样 无缓冲的通道，写会阻塞，直到有人读。 缓冲为1的通道，写第一个不会阻塞，而写第二个会。 书 https://www.cntofu.com/book/73/readme.html go内存模型 简单来说, 是和C语系一样: 可以编译时乱序, 执行时乱序(CPU特性) 那么, 下面的写法是不对的: 不能保证done在a的赋值之后执行. var a string var done bool func setup() { a = \"hello, world\" done = true } func main() { go setup() for !done { } print(a) } 下面的例子更有隐蔽性: 即使在main看来, g不是nil了, 也不能保证g.msg有值. type T struct { msg string } var g *T func setup() { t := new(T) t.msg = \"hello, world\" g = t } func main() { go setup() for g == nil { } print(g.msg) } 解决1: 用channel var c = make(chan int, 10) var a string func f() { a = \"hello, world\" c 解决2: 用sync var l sync.Mutex var a string func f() { a = \"hello, world\" l.Unlock() } func main() { l.Lock() go f() l.Lock() print(a) } sync的once once 保证之执行一次. var a string var once sync.Once func setup() { a = \"hello, world\" } func doprint() { once.Do(setup) print(a) } func twoprint() { go doprint() go doprint() } "},"notes/golang_杂记2.html":{"url":"notes/golang_杂记2.html","title":"杂记2","keywords":"","body":" 使用reflect的MethodByName调用方法 gob decode零值不赋值 现象 原始数据 代码逻辑 问题现象 解释 验证 结论 setuid 调用小写函数 使用了nohup命令启动gshelld, 还是收到signal退出 SIGHUP Types of signals ¶ 推测 解决 gshell的内存使用 recover不能捕获SIGSEGV类型的panic sigint会发给所有前台进程组 写已经closed的conn 场景 答案 结论 读写nil channel会永远阻塞 流式接口和go 流式函数链的go执行顺序 解读 运行结果和结论 go get和go mod go get go list go mod tidy 总结 go clean 清理编译cache 又犯了经典的goroutine引用闭包变量错误!!!!! 原因 解决 理论解释 总结 if else if 共享一个变量scope 经典的append地址错误 打印指针slice 解决: 给结构体加String方法 关于wait group 反例 从栈上获取变量地址 参考代码 运行时获取函数名 方法1 方法2 continue能返回N层for interface的理解 interface{}是青出于蓝 interface{}是带上下文的方法集合 runtime.Caller获取当前运行目录 An interface holding nil value is not nil net/http导致包变大 现象 解决 原因 结论 Options初始化 总结 空白import不会增加binary size reflect高阶用法 动态构建一个struct byName API -- 神奇的重名API reflect.Value的MethodByName方法 reflect.Type的MethodByName方法 go调用外部程序 text/template代码生成举例 map的重要属性 unaddressable 方法1 整体给map赋值 方法2 让value的类型为指针 结论 go的树状表达 存储data 改进存储 如果用key来存储data会怎样? golang的SIGABRT 关于syscall 标准syscall库的问题 解决 更好的syscall库 使用 ioctl c的ioctl接口 cmd argp go的ioctl接口 ioctl的宏定义在哪里? asm files mmap mmap返回的byte切片是哪里来的? fnctl RWLock死锁 float强转为int go generate go generate常使用的一些工具 godoc安装 godoc使用 package通配符和导入路径 package通配符... 导入路径 obj.function()中obj可以是nil 如何处理? 切片的reslicing 再议目录结构 具体error判断 函数赋值给变量 gob encode和网络io的结合 单步decoder.Decode(&msg) protobuf里面oneof转成go结构体 proto定义 转成的结构体 使用reflect的MethodByName调用方法 下面的代码在Handle()这个方法里面, 调用了同对象的DoHandle()方法. // Handle handles SessionRequest. func (msg *SessionRequest) Handle(stream as.ContextStream) (reply interface{}) { // ONLY use reflect when clients do not have full server functions built-in(aka lite build) handle := reflect.ValueOf(msg).MethodByName(\"DoHandle\") if handle.IsValid() && !handle.IsZero() { ret := handle.Call([]reflect.Value{reflect.ValueOf(stream)})[0] if !ret.IsValid() { return nil } return ret.Interface() } return nil } 被调用的方法必须大写开头. \"DoHandle\"可以, 但是如果这个函数是\"handle\", 就不行 返回值要先检查是否valid, 再检查是否是zero 使用Call()方法调用函数, 传参要自己知道该传什么, 返回值也要知道. 参数和返回值都是reflect.Value类型. gob decode零值不赋值 现象 我有一些cpu使用率的统计数据, 使用gob编码保存在文件中. 但decode出来的数据, 和原始数据不一样. 最典型的特征是, 似乎原值为0的时候, decode出来的数据的值可能\"很随机\" 原始数据 原始数据是如下结构体的切片 type procStat struct { Pid int Name string Ucpu float64 Scpu float64 Mem uint64 } type record struct { Time int64 Procs []procStat } 代码逻辑 在一个routine里, 随机生成record数据, 不断的写入文件; 在另一个routine里, 读这个文件decode. func main() { rand.Seed(time.Now().Unix()) flt := 0.01 fmt.Println(flt) fmt.Printf(\"%x\\n\", *(*uint64)(unsafe.Pointer(&flt))) file := \"gob.data\" records := make(map[int64][]procStat, 1000) go func() { f, _ := os.Create(file) defer f.Close() enc := gob.NewEncoder(f) for i := 0; i 小知识: float在内存中和整形的存储方式很不一样, 比如0.01在内存中是3f847ae147ae147b 问题现象 运行这段程序, 会走到reflect.DeepEqual为假的分支, 说明encode的数据和decode的数据不一样. 但还是很有规律的: $ go run gob.go 0.01 3f847ae147ae147b 2021-10-13 02:44:30 +0000 UTC 2021-10-13 02:44:32 +0000 UTC 2021-10-13 02:44:34 +0000 UTC 2021-10-13 02:44:36 +0000 UTC 2021-10-13 02:44:38 +0000 UTC enc done ---- {1634093070 [{34730 worker 0 0.86 11985} {63668 worker 0.65 0 11985} {54333 worker 0.93 0 11985} {45231 worker 0 0.76 11985} {19332 worker 0.82 0 11985} {51576 worker 0.59 0 11985} {16966 worker 0 0 11985} {17849 worker 0.84 0 11985} {18887 worker 0 0 11985} {36216 worker 0 0.87 11985}]} ---- {1634093072 [{45159 worker 0.79 0.86 11985} {22705 worker 0.94 0 11985} {15938 worker 0. 93 0 11985} {45296 worker 0.71 0.63 11985} {8740 worker 0.82 0.93 11985} {36634 worker 0.94 0 .76 11985} {26329 worker 0 0.99 11985} {1891 worker 0.94 0 11985} {33214 worker 0.7 0 11985} {33629 worker 0.75 0.64 11985}]} 2021-10-13 02:44:32 +0000 UTC Should: [{45159 worker 0.79 0 11985} {22705 worker 0.94 0 11985} {15938 worker 0 0 11985} {45296 wor ker 0.71 0.63 11985} {8740 worker 0 0.93 11985} {36634 worker 0.94 0.76 11985} {26329 worker 0 0.99 11985} {1891 worker 0.94 0 11985} {33214 worker 0.7 0 11985} {33629 worker 0.75 0.64 1 1985}] Got: [{45159 worker 0.79 0.86 11985} {22705 worker 0.94 0 11985} {15938 worker 0.93 0 11985} {452 96 worker 0.71 0.63 11985} {8740 worker 0.82 0.93 11985} {36634 worker 0.94 0.76 11985} {2632 9 worker 0 0.99 11985} {1891 worker 0.94 0 11985} {33214 worker 0.7 0 11985} {33629 worker 0. 75 0.64 11985}] ---- {1634093074 [{1940 worker 0.87 0.62 11985} {59400 worker 0.94 0.57 11985} {10964 worker 0.93 0 11985} {40707 worker 0.67 0.91 11985} {51810 worker 0.74 0.84 11985} {26919 worker 0.5 5 0.53 11985} {62442 worker 0 0.99 11985} {25 worker 0.97 0.78 11985} {4644 worker 0.79 0 119 85} {39752 worker 0.75 0.64 11985}]} 规律: 第一次时间戳时, enc和dec的数据是一致的, 此时还没有错误. 从第二次时间戳开始, dec的数据就开始发生\"跳变\", 表现是结构体中float64类型的两个field(Ucpu和Scpu), 应该是0值的地方, 不是零值, 比如:Should: [{45159 worker 0.79 0 11985} {22705 worker 0.94 0 11985} ... ] Got: [{45159 worker 0.79 0.86 11985} {22705 worker 0.94 0 11985} ...] 上面第一个procStat结构体的Scpu, 应该是0, 却变成了0.86 0.86似乎并不是\"随机\"的值, 经过发现, 正好是上一次recorde的同位置的值. 解释 在结论之前, 先排除几点: 和同时读写文件没有关系. 开始我们怀疑是文件写的同时, 又去文件读, 是否文件的内核态buffer没有\"及时\"写进去, 造成读文件的时候\"部分\"读, 造成数据异常. 但其实不是, 开始的时候我们让写的routine一直写, 后面改成写完close, 然后再读; 问题依旧 和float64的编解码有关吗? 似乎有关, 但如果编解码出错, 应该是全部float64的编解码都有问题. 但这里的现象是\"个别\"数据\"跳变\" 结合以上两点, 特别是第二点, 数据跳变似乎是跳变成了以前出现过的值. 那么这个0.86是哪里来的呢? 正好是上一次record的同位置的值: {34730 worker 0 0.86 11985} 那么现在现象比较明确了: 零值可能跳变 跳变的值是上一次同位置的值. 第49行, 在for之前定义了var rcd record, for里面的dec.Decode(&rcd)都是一直往这个地址decode. 第一次rcd全部是零值的时候, decode没问题; 但第二次rcd已经有了第一次的值了, 又如果gob在decode时候遇到零值, 比如下面Ucpu和Scpu是0, gob并不会给rcd的对应field赋值, 导致rcd的这部分值还是零值. type procStat struct { Pid int Name string Ucpu float64 Scpu float64 Mem uint64 } 验证 把49行换成51行, 即在for内部定义rcd, 结果就ok了. 我猜想是因为dec.Decode(&rcd)因为入参是interface{}, 导致rcd逃逸到堆. 因为是for内部定义的, 每次运行到var rcd record, 都会在堆里新分配rcd, 这样就不受前值影响. 把float64改成int, 按照上面的理论, 0值也会\"跳变\" type procStat struct { Pid int Name string Ucpu int Scpu int Mem uint64 } 经过验证, 确实零值也会跳变. 说明和float64编码没有关系. 结论 dec.Decode(&rcd)gob遇到零值, 不会给rcd相应的field赋值 所以, 需要每一次在使用rcd之前, 都要保证它为零值 要么在for里面定义rcd, 还要观察rcd是否真的逃逸到堆 要么手动给rcd赋值为0 所以, 在go里面, 涉及到解码, 或者对变量指针操做, 要特别注意一个变量在内存里的表达: 这个变量是同一个内存地址时, 通常都有bug 补充: 冒号定义变量var v := ...和new变量都不能保证分配新的变量地址 补充, 改成json编解码不会有这个问题, 估计json在遇到零值依然有赋值动作. setuid https://dustinspecker.com/posts/setuid-elevating-privileges/ 一个文件可以有setuid属性: Setuid, which stands for set user ID on execution, is a special type of file permission in Unix and Unix-like operating systems such as Linux and BSD. It is a security tool that permits users to run certain programs with escalated privileges. When an executable file's setuid permission is set, users may execute that program with a level of access that matches the user who owns the file. For instance, when a user wants to change their password, they run the passwd command. The passwd program is owned by the root account and marked as setuid, so the user is temporarily granted root access for that limited purpose. 命令: chmod u+s myfile chmod u+x myfile chmod g+s myfile2 一般都是谁执行myfile, 这个进程算谁的. 但如果由setuid属性的文件, 执行算这个文件的owner的. 比如这个文件的owner是root, 那普通用户执行这个带s属性的文件, 也有root权限. 调用小写函数 一般的, package的小写函数是没法直接调用的, 但有个办法可以绕过这个限制. 用go:linkname 比如标准库里 package reflect //go:linkname call runtime.reflectcall func call(argtype *rtype, fn, arg unsafe.Pointer, n uint32, retoffset uint32) reflect的call被link成了runtime.reflectcall, 也就是说, 调用reflect.call就是调用小写的runtime.reflectcall. 使用了nohup命令启动gshelld, 还是收到signal退出 nohup bin/gshell -wd rootregistry -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 -root -repo gitlabe1.ext.net.nokia.com/godevsig/grepo/master & 但gshell还是会退出 [2021/09/09 12:23:16.705595][daemon][WARN](adaptiveservice.go:215) signal: hangup [2021/09/09 12:23:16.705762][daemon][INFO](server.go:350) server closing [2021/09/09 12:23:16.705827][daemon][DEBUG](scalamsgq.go:49) msgq closed SIGHUP Types of signals ¶ The signals SIGKILL and SIGSTOP may not be caught by a program, and therefore cannot be affected by this package. Synchronous signals are signals triggered by errors in program execution: SIGBUS, SIGFPE, and SIGSEGV. These are only considered synchronous when caused by program execution, not when sent using os.Process.Kill or the kill program or some similar mechanism. In general, except as discussed below, Go programs will convert a synchronous signal into a run-time panic. The remaining signals are asynchronous signals. They are not triggered by program errors, but are instead sent from the kernel or from some other program. Of the asynchronous signals, the SIGHUP signal is sent when a program loses its controlling terminal. The SIGINT signal is sent when the user at the controlling terminal presses the interrupt character, which by default is ^C (Control-C). The SIGQUIT signal is sent when the user at the controlling terminal presses the quit character, which by default is ^\\ (Control-Backslash). In general you can cause a program to simply exit by pressing ^C, and you can cause it to exit with a stack dump by pressing ^. 注意上面的解释, 当主控制台丢失的时候, 会发SIGHUP给程序. SIGHUP的默认行为是程序退出: man 7 signal 搜索SIGHUP 推测 nohup命令ignore了SIGHUP, 从而其子进程也默认继承了这个irgnore的行为. 而gshell代码里, 显式捕捉了syscall.SIGHUP: func initSigCleaner(lg Logger) { sigOnce.Do(func() { // handle signal sigChan := make(chan os.Signal, 1) signal.Notify(sigChan, syscall.SIGINT, syscall.SIGHUP, syscall.SIGTERM) go func() { sig := 所以明明应该ignore的SIGHUP, 又发挥了作用... 解决 应该去掉这个syscall.SIGHUP的捕捉就好了, 还是用nohup启动. 更好的办法, 是用Ignore API: signal.Ignore(syscall.SIGHUP) gshell的内存使用 用到的可执行文件是bin/gshell, 命令: cat /proc/29961/smaps readelf -a 注: 内存\\场景 单daemon KB daemon + master gre .text RSS 2388 2388 + 2516 .text PSS 2388 1194 + 1322 .rodata RSS 2024 2088 + 2152 .rodata PSS 2024 1044 + 1108 .go.buildinfo RSS 144 144 + 144 .go.buildinfo PSS 144 96 + 96 .bss RSS 84 84 + 72 .bss PSS 84 84 + 72 栈? RSS 2244 2352 + 2772 栈? PSS 2244 2352 + 2772 堆? RSS 1504 1576 + 320 堆? PSS 1504 1576 + 320 n个routine栈 RSS 0/4 0/4 + 0/4 n个routine栈 PSS 0/4 0/4 + 0/4 系统栈1? RSS 68 68 + 68 系统栈1? PSS 68 68 + 68 系统栈2? RSS 12 12 + 12 系统栈2? PSS 12 12 + 12 vdso RSS 4 4 + 4 vdso PSS 0 0 + 0 结论: 同一个go的binary, 多次单独启动的情况下: 代码段.text是共享的 只读数据段.rodata是共享的 vdso等kernel so是共享的 其他好像都不共享 recover不能捕获SIGSEGV类型的panic 比如下面的代码: func() { defer func() { if err := recover(); err != nil { lg.Errorf(\"broken stream chan: %v\", err) } }() streamChan := *(*chan *streamTransportMsg)(unsafe.Pointer(uintptr(tm.dstChan))) // swap src and dst streamChan defer的函数中, recover并不能捕获下面的panic: fatal error: unexpected signal during runtime execution [signal SIGSEGV: segmentation violation code=0x80 addr=0x0 pc=0x40bbee] ... sigint会发给所有前台进程组 gshell daemon起了子进程gre-master, 在前台ctrl+c daemon, gre-master也会收到sigint, 两个进程都会消失. 但如果daemon进程自己panic挂掉, gre-master还会继续运行. 值得注意的是, 如果用kill命令指定向daemon进程发送signit, 那就指定pid才会收到信号, 也不会导致gre-master挂掉. 见system 原理杂记 写已经closed的conn 场景 机器A的进程a和机器B的进程b建立了TCP的conn a一直读, b一直写. a被杀掉, b会怎么样? 会写失败吗? 写会一直阻塞吗? 答案 b会写失败, error信息为: writev tcp 172.17.0.1:40757->172.17.0.4:34458: use of closed network connection 结论 不管是socket读, 还是socket写, 都能感知到connection已经关闭. 但前提是机器A不是突然断电. 在机器A还在但进程a被杀掉的情况下, A的kernel会关闭和B的连接, B的kernel和进程b都是知道对方(也就是A)连接中断了. 读写nil channel会永远阻塞 并且调用栈里面, 会明显的标识: [chan send (nil chan)] 比如: goroutine 34 [chan send (nil chan)]: github.com/godevsig/adaptiveservice.(*streamTransport).receiver.func1(0x5e7c48, 0xc0000c2ba0, 0xc0000a7140) /repo/yingjieb/github/godevsig/adaptiveservice/streamtransport.go:213 +0x49 created by github.com/godevsig/adaptiveservice.(*streamTransport).receiver /repo/yingjieb/github/godevsig/adaptiveservice/streamtransport.go:206 +0x8a 参考go规范: Receiving from a nil channel blocks forever A send on a nil channel blocks forever. 流式接口和go 我们知道流式接口就是说返回其自身的方法. 比如: // NewClient creates a client which discovers services. func NewClient() *Client { return &Client{ base: newBase(), discoverTimeout: -1, } } // WithinScopeOS sets the discover scope in same OS. func (c *Client) WithinScopeOS() *Client { c.withinScopeOS() return c } 这样就可以\"流式\"的初始化: c := NewClient().WithinScopeOS().WithDiscoverTimeout(0) 那么如果我向go这个流式函数链呢? 比如 go NewClient().WithinScopeOS().WithDiscoverTimeout(0) 其执行顺序是怎么样的? 流式函数链的go执行顺序 先看代码: package main import ( \"fmt\" \"time\" ) type test struct { name string } func NewTest(f func() string) *test { fmt.Println(\"in NewTest\") return &test{f()} } func (t *test) fa() *test { fmt.Println(t.name, \"in fa\") return t } func (t *test) fb(f func()) *test { fmt.Println(\"fb\") f() return t } func main() { fmt.Println(\"Hello, playground\") go NewTest( func() func() string { fmt.Println(\"before go? -- YES\") return func() string { return \"San\" } }()). fa(). fb( func() func() { fmt.Println(\"before go? -- NO\") return func() { fmt.Println(\"in go? -- YES\") } }()) time.Sleep(time.Second) } 解读 NewTest函数入参是个函数, 传入的时候返回闭包函数传给它 fa函数是普通的函数链上的一个 fb函数也是函数链上的, 但传入一个闭包函数给它. 大的调用关系是go NewTest(入参).fa().fb(入参) 运行结果和结论 结果: Hello, playground before go? -- YES in NewTest San in fa before go? -- NO fb in go? -- YES 结论是: 只有第一级函数, 即NewTest()的入参, 在这里是个函数, 是在go之前执行, 对应打印before go? -- YES 要注意, fb的入参函数, 是在go里面执行的. 所以说只有第一级的函数的入参才会在go之前被计算 go get和go mod 测试环境 go1.16, go mod模式 go get go get -u: 升级所有依赖, 递归包括依赖的依赖 go get -u all: 首先all会被扩展成main的所有依赖, 然后升级所有依赖. all是关键词, 详见go help packages go list go list -m all能列出当前用的所有的module(包括版本号) go list all能列出当前用的所有的package(import路径) go mod tidy 清理go.mod用的, 但似乎go.sum还是有很多\"历史\"版本, 这些版本并没有使用. 总结 go list -m all查看main的所有递归依赖版本 go的编译系统一般只有一个版本号. 当出现不同版本依赖时, 比如A依赖(X@v0.0.2), 但某个依赖指定了不同的版本号(比如X@v0.0.1), 我猜测根据兼容性公约, go的编译系统会选择新的版本号(v0.0.1)来编译. go clean 清理编译cache go clean -cache -i -r The -cache flag causes clean to remove the entire go build cache. The -i flag causes clean to remove the corresponding installed archive or binary (what 'go install' would create). The -r flag causes clean to be applied recursively to all the dependencies of the packages named by the import paths. The -n flag causes clean to print the remove commands it would execute, but not run them. The -modcache flag causes clean to remove the entire module download cache, including unpacked source code of versioned dependencies. 又犯了经典的goroutine引用闭包变量错误!!!!! 这是个比较隐蔽的先for在switch的结构, 很容易忘记go引用的闭包变量会异步的变化. for _, vc := range vcs { switch cmd.Cmd { case \"restart\": if vc.stat == vmStatExited { vm := vc.VM vm.In = null{} logFile, err := os.Create(vc.outputFile) if err != nil { greLogger.Errorln(errorHere(err)) break } vm.Out = logFile go func() { defer logFile.Close() vc.RestartedNum++ vc.runVM() }() ids = append(ids, vc.ID) } } } 现象是第15和16行, 在10次for循环里, 每次都是对同一个vc对象进行操做. 原因 这里第15和16行引用的是for的循环变量vc, 会被for循环更改. 解决 只在进入goroutine之前, 重新定义局部变量vc := vc, 这样goroutine里面的vc就引用的是局部变量vc.第13行定义的vc每次for循环都是个新的vc. for _, vc := range vcs { switch cmd.Cmd { case \"restart\": if vc.stat == vmStatExited { vm := vc.VM vm.In = null{} logFile, err := os.Create(vc.outputFile) if err != nil { greLogger.Errorln(errorHere(err)) break } vm.Out = logFile vc := vc go func() { defer logFile.Close() vc.RestartedNum++ vc.runVM() }() ids = append(ids, vc.ID) } } } 理论解释 参考https://stackoverflow.com/questions/39208162/why-i-can-redefine-the-same-variable-multiple-times-in-a-for-loop-but-cant-outs 有人问为什么在循环里可以: func main() { for i := 0; i 但自己手动写就编译不过: func main() { a := 77 fmt.Println(a) a := 77 fmt.Println(a) } 为啥? 专家的解答是: for循环每次进入循环体大括号块{}, 都是一个新的scope The reason is each time you enter a block of curly braces {} you're creating a new nested scope. When you declare the variable x at the top of the loop it is a new variable and it goes out of scope at the end of the loop. When the program comes back around to the top of the loop again it's another new scope. 有人给出了证据: func main() { for i := 0; i output 0x1040e0f8 0x1040e0fc 可以手动加{}来添加scope: func main() { a := 77 fmt.Println(&a) { a := 77 fmt.Println(&a) } } output 0x1040e0f8 0x1040e0fc 上面的例子就可以\"连续\"定义a两次, 但第二次是个新的变量地址 总结 for循环同一行的变量作用域在for里面没错, 但更像是在进入循环前定义的一样: for循环里面对循环变量的引用都是指向同一个东西 for循环里面用var v int或vc := vc定义的变量, 并非同一个地址, 每次循环都是\"临时\"生成的. 所以上面在第13行的修改可以解决问题. 以后检查go出去的函数是否有这个问题, 只检查循环变量就行了 if else if 共享一个变量scope 比如 var msg interface{} if ... { } else if msg, ok := msg.(ExclusiveMessage); ok { } else if msg, ok := msg.(Message); ok { } 第二个else if中的msg.(Message)实际上引用的是第一个else if中的msg, ok变量. 解决: 给if的变量取个不同的名字, 不要总叫msg 经典的append地址错误 背景是在vm运行的过程中, 调用callers()保存当下的调用栈所有栈帧. 下面的代码有错误: func (v *VM) callers() (frames []*frame) { curFrame := *v.curFrame curFrame.ip = v.ip - 1 frames = append(frames, &curFrame) for i := v.framesIndex - 1; i >= 1; i-- { //值复制, 避免v.frames变动造成curFrame变动 //v.frames是个数组 curFrame = v.frames[i-1] //注意这里搞错了, 每次都append同一个地址!!! 这个因为curFrame变量只有一个. frames = append(frames, &curFrame) } return frames } 改正: 这种情况下, 返回值的slice, 而不是指针slice. func (v *VM) callers() (frames []frame) { curFrame := *v.curFrame curFrame.ip = v.ip - 1 frames = append(frames, curFrame) for i := v.framesIndex - 1; i >= 1; i-- { curFrame = v.frames[i-1] frames = append(frames, curFrame) } return frames } 打印指针slice 我有个结构体, 现在想打印一个var wants []*want的slice type want struct { content []string unordered bool } 直接fmt.Printf(\"%v\", wants)会输出一个slice, 但元素都是指针. 怎么才能打印这些指针的值呢? 用fmt.Printf(\"%+v\", wants)和fmt.Printf(\"%#v\", wants)都不行. 解决: 给结构体加String方法 func (wt *want) String() string { var sb strings.Builder if wt.unordered { sb.WriteString(\"//unordered output:\\n\") } else { sb.WriteString(\"//output:\\n\") } for _, str := range wt.content { sb.WriteString(str + \"\\n\") } return sb.String() } 这样fmt.Printf(\"%v\", wants)就可以输出我们想要的内容了. 其原理是如果一个类型有自定义String()方法, Printf会调用这个自定义String()方法. 注意, 这里要用引用的receiver方式, 因为我们要打印指针. 关于wait group sync包的wait group用于主routine等待所有子routine退出. 在使用上需要注意: wg.Add(1)需要在go之前. wg.Done()需要在go里面. 即要严格按照官网的例子来写: var wg sync.WaitGroup var urls = []string{ \"http://www.golang.org/\", \"http://www.google.com/\", \"http://www.somestupidname.com/\", } for _, url := range urls { // Increment the WaitGroup counter. wg.Add(1) //注意这里, 在go之前Add() // Launch a goroutine to fetch the URL. go func(url string) { // Decrement the counter when the goroutine completes. defer wg.Done() //注意这里, 在go里面Done() // Fetch the URL. http.Get(url) }(url) } // Wait for all HTTP fetches to complete. wg.Wait() 下面解释一下: 在go之前Add(), 是要这个wg.Add(1) 一定 能被主routine调用到. 在go里面调wg.Done()很好理解, 表示事情在这个异步的goroutine里已经完成. 反例 通常大家容易犯的错误是把wg.Add(1)放到go的里面去做. 比如下面代码: clone一个VM, 然后在新的goroutine中run这个新的VM. 父VM需要记录这个新VM到其childVM map里面. func govm(fn) { newVM := vm.ShallowClone() gvm := &goroutineVM{ VM: newVM, waitChan: make(chan ret, 1), } vm.addChildVM(gvm.VM) go func() { //vm.addChildVM(gvm.VM) //不能在里面Add() val, err := gvm.RunCompiled(fn, args[1:]...) gvm.waitChan 如果第8行放到第10行做, 好像也在干活之前加了1, 干完活减1. 但实际情况是, 比如: 在父VM Abort时, 需要abort其所有的子VM. // Abort aborts the execution of current VM and all its descendant VMs. func (v *VM) Abort() { atomic.StoreInt64(&v.aborting, 1) close(v.abortChan) // broadcast to all receivers v.childCtl.Lock() for cvm := range v.childCtl.vmMap { cvm.Abort() } v.childCtl.Unlock() v.childCtl.Wait() // waits for all child VMs to exit } 现在假设父这样的操做序列: 新起3个VM然后马上abort govm(fn1) govm(fn2) govm(fn3) abort() 3个govm是异步在跑的, 当父VM routine运行到第4行abort()的时候, 在abort()跑到第10行v.childCtl.Wait()等待这个wait group的时候, 不能保证它的3个子VM都跑到了Add(1), 因为子VM的Add()可能还没有运行. 这样会导致在父routine的Wait()得到wait的个数小于实际的VM routine个数, 虽然VM起来以后这个wait个数是能够加到3的, 但已经过了父VM routine 的wait点(Abort()函数第10行), 最后的结果就是父VM routine不能把这3个VM routine都abort()掉. 从栈上获取变量地址 比如我要从下面的栈中, 取传递给github.com/d5/tengo/v2.(*VM).run的地址 goroutine 1 [running]: github.com/d5/tengo/v2.builtinGo(0xc0001360b0, 0x1, 0x1, 0x0, 0x0, 0xc0001360b0, 0x1) /repo/yingjieb/github/godevsig/tengo/builtins.go:409 +0x69 github.com/d5/tengo/v2.(*BuiltinFunction).Call(0x7993b0, 0xc0001360b0, 0x1, 0x1, 0xc000178010, 0x1, 0x7ff, 0x1) /repo/yingjieb/github/godevsig/tengo/objects.go:349 +0x48 github.com/d5/tengo/v2.(*VM).run(0xc00013e0d0) /repo/yingjieb/github/godevsig/tengo/vm.go:652 +0x3323 github.com/d5/tengo/v2.(*VM).Run(0xc00013e0d0, 0xc00013e0d0, 0x400) /repo/yingjieb/github/godevsig/tengo/vm.go:96 +0xc7 github.com/godevsig/gshellos.(*shell).runREPL(0xc000099ec8) /repo/yingjieb/github/godevsig/gshellos/gshellbuilder.go:101 +0x825 github.com/godevsig/gshellos.ShellMain(0x786a60, 0xc00005e750) /repo/yingjieb/github/godevsig/gshellos/gshellbuilder.go:197 +0x660 main.main() /repo/yingjieb/github/godevsig/gshellos/cmd/gshell/gshell.go:12 +0x26 下面是方法 首先在vm.go里面 var stackIdentifierVM string //应该是github.com/d5/tengo/v2.(*VM).run func init() { stackIdentifierVM = runtime.FuncForPC(reflect.ValueOf((*VM).run).Pointer()).Name() } 然后在需要用到VM地址的函数里: func builtinGo(args ...Object) (Object, error) { ... var buf [1024]byte n := runtime.Stack(buf[:], false) //取stack, 看从哪里调的. 本函数离(*VM).Run不远, 1024的buf够了 stk := string(buf[:n]) idx := strings.Index(stk, stackIdentifierVM) //找到stackIdentifierVM字符串, 也就是上面的\"github.com/d5/tengo/v2.(*VM).run\" stk2 := stk[idx+len(stackIdentifierVM)+1:] idx = strings.Index(stk2, \")\") addr, err := strconv.ParseUint(stk2[:idx], 0, 64) //转为int64 vm := (*VM)(unsafe.Pointer(uintptr(addr))) //用unsafe强制转为*VM newVM := vm.ShallowClone() //然后就可以使用这个vm的方法了 } 参考代码 # in vm.go var stackIdentifierVM = runtime.FuncForPC(reflect.ValueOf((*VM).run).Pointer()).Name() # in group.go func getVM() (*VM, error) { var buf [1024]byte n := runtime.Stack(buf[:], false) stk := string(buf[:n]) // find \"github.com/d5/tengo/v2.(*VM).run\" idx := strings.Index(stk, stackIdentifierVM) stk2 := stk[idx+len(stackIdentifierVM)+1:] idx = strings.Index(stk2, \")\") addr, err := strconv.ParseUint(stk2[:idx], 0, 64) if err != nil { return nil, fmt.Errorf(\"failed to get current VM from %s: %w\\n\", stk, err) } vm := (*VM)(unsafe.Pointer(uintptr(addr))) return vm, nil } 运行时获取函数名 比如我有个方法 func (v *VM) run() { } 现在想在另外一个函数里, 打印这个上面这个方法的名字: 方法1 fmt.Println(runtime.FuncForPC(reflect.ValueOf((*VM)(nil).run).Pointer()).Name()) //结果 github.com/d5/tengo/v2.(*VM).run-fm 方法2 fmt.Println(runtime.FuncForPC(reflect.ValueOf((*VM).run).Pointer()).Name()) //结果 github.com/d5/tengo/v2.(*VM).run 注意方法2和方法1的区别只是传入reflect.ValueOf的值不一样: (*VM)(nil).run的意思是先把nil强转成(*VM), 然后这个对象的run方法做为入参 (*VM).run直接就是方法, 说明本质上go把(receiver).method当成一个func定义. continue能返回N层for continue能够指定跳转lable(只能是for的lable) RowLoop: for y, row := range rows { for x, data := range row { if data == endOfRow { continue RowLoop } row[x] = data + bias(x, y) } } interface的理解 interface{}是青出于蓝 一个典型情况是, 底层对象实现了某些方法集合(蓝方法集合), 通过wrapper层, 提供给用户\"扩展\"版本的方法集合(青方法集合). 举例如下: mangos代码中, 底层通道的pipe抽象是transport.Pipe(TranPipe的别名),提供如下方法(蓝色接口): // TranPipe behaves like a full-duplex message-oriented connection between two // peers. Callers may call operations on a Pipe simultaneously from // different goroutines. (These are different from net.Conn because they // provide message oriented semantics.) // // Pipe is only intended for use by transport implementors, and should // not be directly used in applications. type TranPipe interface { // Send sends a complete message. In the event of a partial send, // the Pipe will be closed, and an error is returned. For reasons // of efficiency, we allow the message to be sent in a scatter/gather // list. Send(*Message) error // Recv receives a complete message. In the event that either a // complete message could not be received, an error is returned // to the caller and the Pipe is closed. // // To mitigate Denial-of-Service attacks, we limit the max message // size to 1M. Recv() (*Message, error) // Close closes the underlying transport. Further operations on // the Pipe will result in errors. Note that messages that are // queued in transport buffers may still be received by the remote // peer. Close() error // GetOption returns an arbitrary transport specific option on a // pipe. Options for pipes are read-only and specific to that // particular connection. If the property doesn't exist, then // ErrBadOption should be returned. GetOption(string) (interface{}, error) } 在internal/core/socket.go中, 用一个结构体\"包装\"了底层的transport.Pipe // pipe wraps the Pipe data structure with the stuff we need to keep // for the core. It implements the Pipe interface. type pipe struct { id uint32 p transport.Pipe //这个就是transport.Pipe的接口实例 l *listener d *dialer s *socket closeOnce sync.Once data interface{} // Protocol private added bool closing bool lock sync.Mutex // held across calls to remPipe and addPipe } 这个pipe实现了protocol.ProtocolPipe接口(青色接口): // ProtocolPipe represents the handle that a Protocol implementation has // to the underlying stream transport. It can be thought of as one side // of a TCP, IPC, or other type of connection. type ProtocolPipe interface { // ID returns a unique 31-bit value associated with this. // The value is unique for a given socket, at a given time. ID() uint32 // Close does what you think. Close() error // SendMsg sends a message. On success it returns nil. This is a // blocking call. SendMsg(*Message) error // RecvMsg receives a message. It blocks until the message is // received. On error, the pipe is closed and nil is returned. RecvMsg() *Message // SetPrivate is used to set protocol private data. SetPrivate(interface{}) // GetPrivate returns the previously stored protocol private data. GetPrivate() interface{} } 通过\"青出于蓝\"的操作, pipe struct对外屏蔽了transport.Pipe实例, 但对外提供了该有的函数. 即\"青出于蓝\"的核心不在于暴露蓝的实例, 而是提供青的功能函数. 所以interface{}的本质是提供方法规约, 同时隐藏了实例细节. 这是一个高度接口化(或者说是标准化)的世界, 比如在纺织厂语境下, 你提供的只有纺织工的操作的双手, 你的个性, 比如喜欢王菲的歌, 根本没必要也不值得被外人知道. 相对C++, go的interface概念摒弃了对象的\"数据\"属性, 只保留\"方法\"规约. 对象的\"数据\"自己来cook, 外人不关心; 外人只要你提供方法\"服务\"就行了. 注: 这里的pipe struct是小写, 其内部所有的field都是小写, 这个pipe不能被外部\"直接\"使用. 但可以通过调用核心层的函数, s.proto.AddPipe(p), \"注册\"自己: AddPipe是protocol实例的规定函数, 原型如下: AddPipe(ProtocolPipe) error 上面的p代表一个ProtocolPipe实例, 虽然全部都是小写, 但也不妨碍能被当作ProtocolPipe的interface来赋值. 即这里就把一个完全\"私有\"的实例, 通过满足ProtocolPipe规定的方法, 当作ProtocolPipe的实例被\"导出\"到外部使用. interface{}是带上下文的方法集合 带方法的interface{}的典型的使用场景是: 该interface{}变量是带上下文的函数集合. 比如mangos里面创建REQ的socket: func NewSocket() (protocol.Socket, error) { return protocol.MakeSocket(NewProtocol()), nil } 其中protocol.MakeSocket(proto Protocol) Socket的入参就是一个规定方法的interface{} type ProtocolBase interface { ProtocolContext // Info returns the information describing this protocol. Info() ProtocolInfo // XXX: Revisit these when we can use Pipe natively. // AddPipe is called when a new Pipe is added to the socket. // Typically this is as a result of connect or accept completing. // The pipe ID will be unique for the socket at this time. // The implementation must not call back into the socket, but it // may reject the pipe by returning a non-nil result. AddPipe(ProtocolPipe) error // RemovePipe is called when a Pipe is removed from the socket. // Typically this indicates a disconnected or closed connection. // This is called exactly once, after the underlying transport pipe // is closed. The Pipe ID will still be valid. RemovePipe(ProtocolPipe) // OpenContext is a request to create a unique instance of the // protocol state machine, allowing concurrent use of states on // a given protocol socket. Protocols that don't support this // should return ErrProtoOp. OpenContext() (ProtocolContext, error) } 所以: 核心层(比如这里的protocol层), 给其下辖的模块规定方法集, 满足这些方法集的实现就能享受核心层提供的好处(比如子模块享受核心层的MakeSocket()方法) 核心层是框架, 框架定好规矩(方法集) 子模块是实现, 实现了规定的方法集, 就能融入框架, 享受框架. 这里的例子是, 子模块调用核心层的函数protocol.MakeSocket(自己的接口实例), 传入自己的interface{}实现. 总结: 核心层定义接口, 针对接口做框架 子模块实现接口, 调用核心层的函数来完成任务. runtime.Caller获取当前运行目录 runtime.Caller(0)的第二个返回值是文件名, 对文件名的路径操作得到当前目录, 定位文件等等. _, f, _, _ := runtime.Caller(0) topDir := f[:strings.Index(f, \"extension\")] covFile := filepath.Base(strings.TrimSuffix(file, filepath.Ext(file))) covFileArg := fmt.Sprintf(\"-test.coverprofile=%sl2_%s.cov\", topDir, covFile) An interface holding nil value is not nil func main() { var a interface{} fmt.Printf(\"a == nil is %t\\n\", a == nil) var b interface{} var p *int = nil b = p fmt.Printf(\"b == nil is %t\\n\", b == nil) } 结果: a == nil is true b == nil is false b被赋值为p, p是nil. 但b不是nil 因为interface为nil的条件是2个: 值和类型都必须是nil \"An interface equals nil only if both type and value are nil.\" 这里b的值是nil, 但类型不是nil. 只声明没赋值的接口变量是nil 显式赋值为nil的接口变量是nil. 注意必须是b = nil这样的赋值才行. 补充: nil既是值, 也是一种类型. 另外, 可以对接口进行类型断言来查看其\"值\"是否为nil var v interface{} var a map[string]int v = a //此时v已经不是nil了, 因为v的类型变成了map[string]int //对v断言成mv, 那么mv就又是nil了 mv := v.(map[string]int) if mv == nil { return nil, nil } net/http导致包变大 现象 我import了网上的库, abs. 编译后发现有8.2M. 用nm命令查看二进制, 发现有很多net/http的符号. 但实际上, 我并没有显式引用任何网络相关的函数. 解决 调查发现, abs内部的一个package util中, 有一个文件引用了\"net/http\"包, 提供了一个函数从httpDownload(). 删除这个文件, 二进制的size直接减小了4M! 编译时间也缩短了很多. 而且还不影响功能 原因 那为什么代码里没有实际引用Download()函数, net/http还是被编译进去了呢? 是go的编译器不够聪明, 不能把\"dead code\"删掉吗? -- 不是. 虽然在编译阶段, 是按照packge来编译成.a的, 但这个阶段一般都会缓存到一个cache目录下. 在链接阶段, go的链接器能做到只链接用得到的符号. 但即使只是空引用import _ \"net/http\", 二进制的size就会增加4M, 说明net/http内部一定是有全局变量或者init()函数, 引用了自身的符号. 这个引用进一步把全部符号都拖入泥潭. 结论 不要引用net/http, 初非必须要http功能. 用nm查看二进制, 排查是否有net/http出现. Options初始化 readlineutil.go是github.com/chzyer/readline的一个简单封装, 提供一个类似bufio.Scaner的迭代器. 它的初始化很有设计感. 要点是 入参是变长的 入参的形式是函数 参数在函数里面执行 type Term struct { inst *readline.Instance io.Writer line string err error prevPrompt string } type Option func(*conf) type conf struct { rc *readline.Config } //options是个变长的入参, 格式是Option, 后者是个函数. func NewTerm(options ...Option) (*Term, error) { var c conf c.rc = new(readline.Config) c.rc.DisableAutoSaveHistory = true //执行入参函数 for _, o := range options { o(&c) } inst, err := readline.NewEx(c.rc) t := new(Term) t.inst = inst t.Writer = inst.Stdout() return t, nil } //返回闭包函数 func WithHistoryFile(filename string) Option { return func(c *conf) { c.rc.HistoryFile = filename } } //使用: t := NewTerm(WithHistoryFile(\"history\")) 相对于普通的设计: 多个入参, 类型不同, 显式指定. 比如func NewTerm(history string, prompt string, search bool, 等等) (*Term, error) 这样做的缺点很多: 如果是对外的API, 那这个API可能会经常变化; 比如增加个属性, 调用者要改代码才能编过 -- 即使老用户并不关心这个新增的属性, 也不准备用这个新功能. 参数通过位置传递, 多了不好看 入参是个结构体, 结构体的字段表述不同的属性; 这样入参不需要变长, 靠结构体的定义, 以及不同field的赋值来传入\"变化\" 解决了上面方案的变化问题, 部分解决了API更改的问题. -- 此时API的更改变更为struct{}的更改, 部分解决了老用户希望代码不变的问题 -- 部分赋值的struct是允许的. 但调用者还是要关心这个入参结构体的定义 结构体字段的赋值没有明显的位置感, key: value的形式可读性好点 入参变长, 全部是interface{} 足够灵活, 如果实在是外部需求变化大, 需要适应变化 繁琐: 需要在实现里不断的搞类型断言 对于本例的场景, 并不适合. 传入的参数需要表明目的. 本例范式: func NewTerm(options ...Option) 是对\"结构体\"入参的一种扩展, Option本质上是一个函数, 这个函数对\"cfg入参结构体\"中的一个字段进行配置 这样定义的对外API有良好的扩展性: 用户不必修改代码; cfg结构体对用户不可见. go-micro中, 就大量使用了Options范式: // Service is an interface for a micro service type Service interface { ... // Init initialises options Init(...Option) // Options returns the current options Options() Options ... } type Option func(*Options) type Options struct { A string B int C bool } 总结 设计一个对外的API时, 比较典型的是NewXxx的API, 或者Init()的API, 最好不用1, 简单点的场景用2, 复杂点的框架用4; 特殊情况用3 空白import不会增加binary size 比如一个empty.go, 本来不需要pidinfo包. 但还是引入了这个包 import _ \"pidinfo\" 可以编译, 编译后的binary只包括一点点pidinfo的代码. 整个size并没有变化. 还是2M. 如果调用了有限几个pidinfo里面的函数, 感觉go的编译器会自动remove dead code. reflect高阶用法 动态构建一个struct 用reflect可以创建一个\"任意没有定义过\"的结构体 核心是func StructOf(fields []StructField) Type API typ := reflect.StructOf([]reflect.StructField{ { Name: \"Height\", Type: reflect.TypeOf(float64(0)), Tag: `json:\"height\"`, }, { Name: \"Age\", Type: reflect.TypeOf(int(0)), Tag: `json:\"age\"`, }, }) v := reflect.New(typ).Elem() v.Field(0).SetFloat(0.4) v.Field(1).SetInt(2) s := v.Addr().Interface() w := new(bytes.Buffer) if err := json.NewEncoder(w).Encode(s); err != nil { panic(err) } fmt.Printf(\"value: %+v\\n\", s) fmt.Printf(\"json: %s\", w.Bytes()) r := bytes.NewReader([]byte(`{\"height\":1.5,\"age\":10}`)) if err := json.NewDecoder(r).Decode(s); err != nil { panic(err) } fmt.Printf(\"value: %+v\\n\", s) 结果: value: &{Height:0.4 Age:2} json: {\"height\":0.4,\"age\":2} value: &{Height:1.5 Age:10} byName API -- 神奇的重名API reflect.Value的MethodByName方法 从一个反射对象reflect.Value可以用方法名查到它的方法对象: func (v Value) MethodByName(name string) Value 返回一个\"function value\". 传参给返回的function不能带receiver, 因为它把Value v当作默认的receiver MethodByName returns a function value corresponding to the method of v with the given name. The arguments to a Call on the returned function should not include a receiver; the returned function will always use v as the receiver. It returns the zero Value if no method was found. stack over flow有个讨论, 里面由示例代码. 还有个更简单的 package main import \"fmt\" import \"reflect\" type T struct {} func (t *T) Foo() { fmt.Println(\"foo\") } func main() { var t T reflect.ValueOf(&t).MethodByName(\"Foo\").Call([]reflect.Value{}) } reflect.Type的MethodByName方法 reflect.Type的反射对象也有个同名的方法 reflect.Type是个接口, 它底层的具体类型必须实现一系列的函数 // MethodByName returns the method with that name in the type's // method set and a boolean indicating if the method was found. // // For a non-interface type T or *T, the returned Method's Type and Func // fields describe a function whose first argument is the receiver. // // For an interface type, the returned Method's Type field gives the // method signature, without a receiver, and the Func field is nil. MethodByName(string) (Method, bool) 返回的Method是个结构体 type Method struct { // Name is the method name. // PkgPath is the package path that qualifies a lower case (unexported) // method name. It is empty for upper case (exported) method names. // The combination of PkgPath and Name uniquely identifies a method // in a method set. // See https://golang.org/ref/spec#Uniqueness_of_identifiers Name string PkgPath string Type Type // method type Func Value // func with receiver as first argument Index int // index for Type.Method } 用返回的Method怎么调用函数??? go调用外部程序 这里以go解释器yaegi为例. dotCmd是dot -Tdot -o ast.dot // dotWriter returns an output stream to a dot(1) co-process where to write data in .dot format. func dotWriter(dotCmd string) io.WriteCloser { if dotCmd == \"\" { return nopCloser{ioutil.Discard} } fields := strings.Fields(dotCmd) //构建cmd cmd := exec.Command(fields[0], fields[1:]...) //cmd有StdinPipe函数, 返回 dotin, err := cmd.StdinPipe() if err != nil { log.Fatal(err) } //开始这个cmd, 但还没有输入 if err = cmd.Start(); err != nil { log.Fatal(err) } //返回输入的句柄 return dotin } 外部对dotWriter返回的io.WriteCloser写就可以pipe到cmd的输入. text/template代码生成举例 const model = `// Code generated by 'yaegi extract {{.PkgName}}'. DO NOT EDIT. {{.License}} {{if .BuildTags}}// +build {{.BuildTags}}{{end}} package {{.Dest}} import ( {{- range $key, $value := .Imports }} {{- if $value}} \"{{$key}}\" {{- end}} {{- end}} \"{{.PkgName}}\" \"reflect\" ) func init() { Symbols[\"{{.PkgName}}\"] = map[string]reflect.Value{ {{- if .Val}} // function, constant and variable definitions {{range $key, $value := .Val -}} {{- if $value.Addr -}} \"{{$key}}\": reflect.ValueOf(&{{$value.Name}}).Elem(), {{else -}} \"{{$key}}\": reflect.ValueOf({{$value.Name}}), {{end -}} {{end}} {{- end}} {{- if .Typ}} // type definitions {{range $key, $value := .Typ -}} \"{{$key}}\": reflect.ValueOf((*{{$value}})(nil)), {{end}} {{- end}} {{- if .Wrap}} // interface wrapper definitions {{range $key, $value := .Wrap -}} \"_{{$key}}\": reflect.ValueOf((*{{$value.Name}})(nil)), {{end}} {{- end}} } } {{range $key, $value := .Wrap -}} // {{$value.Name}} is an interface wrapper for {{$key}} type type {{$value.Name}} struct { {{range $m := $value.Method -}} W{{$m.Name}} func{{$m.Param}} {{$m.Result}} {{end}} } {{range $m := $value.Method -}} func (W {{$value.Name}}) {{$m.Name}}{{$m.Param}} {{$m.Result}} { {{$m.Ret}} W.W{{$m.Name}}{{$m.Arg}} } {{end}} {{end}} ` 使用的时候 base := template.New(\"extract\") parse, err := base.Parse(model) b := new(bytes.Buffer) data := map[string]interface{}{ \"Dest\": e.Dest, \"Imports\": imports, //这里的imports是个map \"PkgName\": importPath, \"Val\": val, \"Typ\": typ, \"Wrap\": wrap, \"BuildTags\": buildTags, \"License\": e.License, } err = parse.Execute(b, data) // gofmt source, err := format.Source(b.Bytes()) //此时source里面就是替换后的代码 注: 替换的变量是通过map[string]interface{}传入的, 其值为万能interface 值可以是map, 比如上面的imports; 对应模板里面用range来遍历. map的重要属性 unaddressable 这样操作map是可以的: type User struct { name string } users := make(map[int]User) users[5] = User{\"Steve\"} 但下面这样不行: users[5].name = \"Mark\" //cannot assign to struct field users[5].name in map 为什么呢? 问答在这里 答: map的value是不能被寻址的(by语言设计), 虽然users[5]看起来像是寻找到了一个User, 但在go里面所有的传递都是值传递, users[5].name = \"Mark\"也隐含发生了值拷贝: 从原User拷到了临时的不可见的User. 对后者的赋值= Mmark\"是没有任何意义的, 即使可以, 也不会改变原User的name. 所以在编译阶段, 就会提示错误. 同样的, 这样也会报错: (&users[5]).name = \"Mark\" //cannot take the address of users[5] 那如何更改value呢? 方法1 整体给map赋值 t := users[5] t.name = \"Mark\" users[5] = t 上面的代码中, 首先显式的值拷贝到t, 更改t, 再把t拷贝进users这个map. 这里User类型的实例的拷贝都发生了2次. 方法2 让value的类型为指针 users := make(map[int]*User) 此时users[5]虽然也是值拷贝, 但拷贝出来的指针还是指向底层数据, 就可以更改了. 结论 map的value为值类型时, 不能被寻址; 所以不能\"原地\"修改 可以把map的value设计为指针类型, 支持\"原地\"修改. 但这样会给gc带来压力 也可以用copy-改-copy进map的方式修改 go的树状表达 在C里面, 定义一个node时, next域必须是ListNode的指针 struct ListNode{ int val; ListNode* next; }; 在go里面, 一个tree的最简单, 最天然的表达是map: map的value还是个tree type astTree map[string]astTree 注意到这里, value实际上是它对自己的表达: 自己包括自己(而不是指针), 能行吗? --可以. 下面的例子说明这么写没有任何问题 var ast astTree = nil ast = astTree{\"hello\":nil, \"wolrd\":{\"111\":nil}} fmt.Println(ast) 结果是 map[hello:map[] wolrd:map[111:map[]]] 解释: 实际上, map是个固定size的结构体, 有着类似指针的性质, 比如上面代码中, var ast astTree = nil, map可以赋值为nil. 既然是固定size, 那astTree的value就可以是自身astTree 但是, type astTree map[string]astTree这样树的表达, 语法上可以, 但没有实际意义: 这个树的节点上, 只有做为string的key能存储有意义的数据 -- 一个树, 除了结构表达, 还需要存储data才能发挥实际的作用. 存储data 把ast定义成一个结构体: type astTree struct { data int ast map[string]astTree } 初始化: func main() { fmt.Println(\"Hello, playground\") //var ast astTree = nil ast := astTree{23, map[string]astTree{\"hello\":astTree{}, \"nihao\":astTree{}}} ast.ast[\"world\"] = astTree{} fmt.Println(ast) } //输出 Hello, playground {23 map[hello:{0 map[]} nihao:{0 map[]} world:{0 map[]}]} 但这样有点太丑了. 而且因为map的value元素为值类型的undressable因素, 不能用ast.ast[\"world\"].data =100这样的原地修改方法. 改进存储 按照map的value为指针类型可以寻址的特点, 改进如下: type asTree struct { data int subTrees map[string]*asTree } func main() { fmt.Println(\"Hello, playground\") ast := asTree{23, map[string]*asTree{\"hello\":&asTree{}, \"nihao\":&asTree{}}} ast.subTrees[\"world\"] = &asTree{} ast.subTrees[\"world\"].data =100 ast.subTrees[\"world\"].subTrees = map[string]*asTree{\"shanghai\":&asTree{}} ast.subTrees[\"world\"].subTrees[\"shanghai\"].subTrees = map[string]*asTree{\"pudong\":&asTree{}} fmt.Println(ast) fmt.Println(ast.subTrees[\"world\"]) ast.subTrees[\"world\"].subTrees[\"shanghai\"].data = 2013 fmt.Println(ast.subTrees[\"world\"].subTrees[\"shanghai\"]) } //输出 Hello, playground {23 map[hello:0xc000010200 nihao:0xc000010210 world:0xc000010220]} &{100 map[shanghai:0xc000010230]} &{2013 map[pudong:0xc000010240]} 如果用key来存储data会怎样? type useFullData struct { data1 int data2 string } type asTree map[useFullData]asTree 这样遍历是可以用k, v := range(asTree)来遍历的 但key本质上是种索引, key应该是某种不变的东西. key用来查询并得到数据. 用key来存储数据的问题是, 如果要存储的数据会变化, 那key就变了. golang的SIGABRT 在配置了GOTRACEBACK=crash的情况下, go程序会在panic的时候, 打印所有goroutine的调用栈(这个和GOTRACEBACK=system效果一样), 而且还会发SIGABRT(6号signal)触发core dump. man 7 signal说的很清楚, 每个signal都有默认的性情(disposition): Signal Value Action Comment ────────────────────────────────────────────────────────────────────── SIGHUP 1 Term Hangup detected on controlling terminal or death of controlling process SIGINT 2 Term Interrupt from keyboard SIGQUIT 3 Core Quit from keyboard SIGILL 4 Core Illegal Instruction SIGABRT 6 Core Abort signal from abort(3) SIGFPE 8 Core Floating-point exception SIGKILL 9 Term Kill signal SIGSEGV 11 Core Invalid memory reference SIGPIPE 13 Term Broken pipe: write to pipe with no readers; see pipe(7) SIGALRM 14 Term Timer signal from alarm(2) SIGTERM 15 Term Termination signal SIGUSR1 30,10,16 Term User-defined signal 1 SIGUSR2 31,12,17 Term User-defined signal 2 SIGCHLD 20,17,18 Ign Child stopped or terminated SIGCONT 19,18,25 Cont Continue if stopped SIGSTOP 17,19,23 Stop Stop process SIGTSTP 18,20,24 Stop Stop typed at terminal SIGTTIN 21,21,26 Stop Terminal input for background process SIGTTOU 22,22,27 Stop Terminal output for background process SIGABRT的性情就是触发core dump机制. 内核会走core dump流程. 所以, 在GOTRACEBACK=crash情况下 go程序会先打印panic调用栈(所有go routine) 然后主动调用类似c的abort()函数触发SIGABRT给自己 然后kernel会走core dump流程. 关于syscall syscall提供了对底层os的原始封装. 从go1.4开始 官方推荐使用golang.org/x/sys来代替syscall. 标准库的syscall提供了一些基本的const常量. 比如 EPOLLERR = 0x8 EPOLLET = -0x80000000 EPOLLHUP = 0x10 EPOLLIN = 0x1 EPOLLMSG = 0x400 EPOLLONESHOT = 0x40000000 EPOLLOUT = 0x4 EPOLLPRI = 0x2 EPOLLRDBAND = 0x80 EPOLLRDHUP = 0x2000 EPOLLRDNORM = 0x40 EPOLLWRBAND = 0x200 EPOLLWRNORM = 0x100 EPOLL_CLOEXEC = 0x80000 EPOLL_CTL_ADD = 0x1 EPOLL_CTL_DEL = 0x2 EPOLL_CTL_MOD = 0x3 syscall和CPU arch强相关, 默认显示GOARCH的对应的包. 一般是amd64 用 $GOOS and $GOARCH来切换其他的组合. 实际的代码在对应的组合, 比如/usr/local/go/src/syscall/zerrors_linux_arm64.go 标准syscall库的问题 复杂, 维护的很差, 表现在难于测试, 必须跟随OS的ARCH的改动 缺少文档, 兼容性难以保证 解决 syscall在go1.3code freeze 从go1.4开始, 使用一个新库, 新库分为plan9, unix, windows三个子类 在2014年左右就完成了 Note that we cannot clean up the existing syscall package to any meaningful extent because of the compatibility guarantee. We can freeze and, in effect, deprecate it, however. 更好的syscall库 简介在此, 这个简介在2014年左右 库地址: https://github.com/golang/sys 使用 go get -u golang.org/x/sys ioctl unix/zsyscall_linux.go中 func ioctl(fd int, req uint, arg uintptr) (err error) { _, _, e1 := Syscall(SYS_IOCTL, uintptr(fd), uintptr(req), uintptr(arg)) if e1 != 0 { err = errnoErr(e1) } return } 注意到这里的ioctl是小写的, 外面不能引用. c的ioctl接口 #include int ioctl(int fd, unsigned long request, ...); ioctl是对设备文件用的. 第二个参数是设备相关的request code, 第三个参数是个指针(char *argp). 这个request是个编码, 指示argp是入参还是出参, argp的字节数 ioctl对应驱动的实现: int (*ioctl) (struct inode * node, struct file *filp, unsigned int cmd, unsigned long arg); 这篇文章讲的比较清楚. cmd cmd为32bit, 是个组合, 包括几个部分 分类:8bit 类内序号: 8bit 数据传输方向: 2bit_IOC_NONE _IOC_READ _IOC_WRITE _IOC_READ|_IOC_WRITE 数据大小: 剩下的14bit argp 应用层的ioctl的第三个参数是\"...\"，这个跟printf的\"...\"可不一样，printf中是意味这你可以传任意个数的参数，而ioctl最多也只能传一个，\"...\"的意思是让内核不要检查这个参数的类型。也就是说，从用户层可以传入任何参数，只要你传入的个数是1. 一般会有两种的传参方法： 整数，那可是省力又省心，直接使用就可以了。 指针，通过指针的就传什么类型都可以了，当然用起来就比较烦。在驱动里使用copy_xx_user函数从用户态传输数据 go的ioctl接口 前面说过, go的ioctl是小写的, \"内部专供\" 但在unix/ioctl.go中, 封装了几个对外开放的接口: // ioctl itself should not be exposed directly, but additional get/set // functions for specific types are permissible. // IoctlSetInt performs an ioctl operation which sets an integer value // on fd, using the specified request number. func IoctlSetInt(fd int, req uint, value int) error // IoctlSetPointerInt performs an ioctl operation which sets an // integer value on fd, using the specified request number. The ioctl // argument is called with a pointer to the integer value, rather than // passing the integer value directly. func IoctlSetPointerInt(fd int, req uint, value int) error // IoctlSetWinsize performs an ioctl on fd with a *Winsize argument. // // To change fd's window size, the req argument should be TIOCSWINSZ. func IoctlSetWinsize(fd int, req uint, value *Winsize) error // IoctlSetTermios performs an ioctl on fd with a *Termios. // // The req value will usually be TCSETA or TIOCSETA. func IoctlSetTermios(fd int, req uint, value *Termios) error // IoctlGetInt performs an ioctl operation which gets an integer value // from fd, using the specified request number. // // A few ioctl requests use the return value as an output parameter; // for those, IoctlRetInt should be used instead of this function. func IoctlGetInt(fd int, req uint) (int, error) func IoctlGetWinsize(fd int, req uint) (*Winsize, error) func IoctlGetTermios(fd int, req uint) (*Termios, error) 结合C版本的ioctl分析, 这几个API怕是不够. IoctlSetInt和IoctlSetPointerInt能cover简单的int传输的需求 IoctlGetWinsize和IoctlGetTermios都是传递特殊功能结构体的. unix/syscall_linux.go中, 还有几个API: func IoctlRetInt(fd int, req uint) (int, error) func IoctlSetRTCTime(fd int, value *RTCTime) error func IoctlGetUint32(fd int, req uint) (uint32, error) func IoctlGetRTCTime(fd int) (*RTCTime, error) ioctl的宏定义在哪里? 在unix/zerrors_linux.go和unix/zerrors_linux_amd64.go 不用的OS和ARCH对应不同的文件 比如 //unix/zerrors_linux.go EPOLLIN = 0x1 //unix/zerrors_linux_amd64.go RTC_RD_TIME = 0x80247009 asm files ioctl调用的Syscall是在asm里面手写的 见https://github.com/golang/sys/tree/master/unix The hand-written assembly file at asm_${GOOS}_${GOARCH}.s implements system call dispatch. There are three entry points: func Syscall(trap, a1, a2, a3 uintptr) (r1, r2, err uintptr) func Syscall6(trap, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2, err uintptr) func RawSyscall(trap, a1, a2, a3 uintptr) (r1, r2, err uintptr) The first and second are the standard ones; they differ only in how many arguments can be passed to the kernel. The third is for low-level use by the ForkExec wrapper. Unlike the first two, it does not call into the scheduler to let it know that a system call is running. When porting Go to an new architecture/OS, this file must be implemented for each GOOS/GOARCH pair. mmap unix/syscall_linux.go //返回一个byte切片 func Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error) { return mapper.Mmap(fd, offset, length, prot, flags) } 使用: // +build aix darwin dragonfly freebsd linux netbsd openbsd solaris package unix_test import ( \"runtime\" \"testing\" \"golang.org/x/sys/unix\" ) func TestMmap(t *testing.T) { b, err := unix.Mmap(-1, 0, unix.Getpagesize(), unix.PROT_NONE, unix.MAP_ANON|unix.MAP_PRIVATE) if err != nil { t.Fatalf(\"Mmap: %v\", err) } if err := unix.Mprotect(b, unix.PROT_READ|unix.PROT_WRITE); err != nil { t.Fatalf(\"Mprotect: %v\", err) } //可以直接使用这个byte切片来修改内容 b[0] = 42 if runtime.GOOS == \"aix\" { t.Skip(\"msync returns invalid argument for AIX, skipping msync test\") } else { //msync系统调用是用来flush内容copy到真正的文件, mumap也有这个功能. if err := unix.Msync(b, unix.MS_SYNC); err != nil { t.Fatalf(\"Msync: %v\", err) } } //msync以后, 这块内存就可以\"建议\"内核, 不需要了 if err := unix.Madvise(b, unix.MADV_DONTNEED); err != nil { t.Fatalf(\"Madvise: %v\", err) } //最后使用munmap解除映射 if err := unix.Munmap(b); err != nil { t.Fatalf(\"Munmap: %v\", err) } } 百度上的结论写的不错: 最终被映射文件的内容的长度不会超过文件本身的初始大小，即映射不能改变文件的大小； 可以用于进程通信的有效地址空间大小大体上受限于被映射文件的大小，但不完全受限于文件大小。打开文件被截短为5个people结构大小，而在 map_normalfile1中初始化了10个people数据结构，在恰当时候（map_normalfile1输出initialize over 之后，输出umap ok之前）调用map_normalfile2会发现map_normalfile2将输出全部10个people结构的值，后面将给出详细讨论。 　　注：在linux中，内存的保护是以页为基本单位的，即使被映射文件只有一个字节大小，内核也会为映射分配一个页面大小的内存。当被映射文件小于一个页面大小时，进程可以对从mmap()返回地址开始的一个页面大小进行访问，而不会出错；但是，如果对一个页面以外的地址空间进行访问，则导致错误发生，后面将进一步描述。因此，可用于进程间通信的有效地址空间大小不会超过文件大小及一个页面大小的和。 文件一旦被映射后，调用mmap()的进程对返回地址的访问是对某一内存区域的访问，暂时脱离了磁盘上文件的影响。所有对mmap()返回地址空间的操作只在内存中有意义，只有在调用了munmap()后或者msync()时，才把内存中的相应内容写回磁盘文件，所写内容仍然不能超过文件的大小。 mmap返回的byte切片是哪里来的? unix/syscall_linux.go中, Mmap的实现是 func Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error) { return mapper.Mmap(fd, offset, length, prot, flags) } 而这个mapper的实现在unix/syscall_unix.go func (m *mmapper) Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error) { if length 可以看到 Syscall交互的数据都是uintptr类型 Mmap返回的data []byte, 并不是通常动态申请的buffer, 而是用Syscall返回的地址, 经过黑科技构造成的切片. 注: 复习一下指针转换的知识 unsafe.Pointer有如下性质: unsafe.Pointer和任意的指针类型能互相转换 unsafe.Pointer和uintptr能互相转换 指针和uintptr不能直接互转 fnctl unix/fcntl.go中, 对fnctl也有个简单的封装 RWLock死锁 在持有mtx.Lock()的时候, 在里面再次获取RLock会死锁 比如下面的结构会死锁. mtx.Lock() 调用一个函数() 函数里面再次获取读锁 mtx.RLock() ... mtx.RUnlock() mtx.Unlock() 死锁发生时, goroutine会显示semacquire状态 goroutine 1 [semacquire]: 其调用栈路径上能看到是重复获取锁 官方文档说的很清楚, RLock()不支持重复获取(recursive lock) float强转为int go的强转和C的表现是一致的, 比如把3.1415926强转为int, C和go都是得到3, 即浮点的整数部分. go generate go generate用于执行go代码注释中的动作 中文说明 官方说明 执行go generate时，有一些环境变量可以使用: $GOARCH 体系架构 (arm、amd64等待) $GOOS OS环境(linux、windows等) $GOFILE 当前处理中的文件名 $GOLINE 当前命令在文件中的行号 $GOPACKAGE 当前处理文件的包名 $DOLLAR 固定的\"$\",不清楚用途 假设我们有个main.go文件，内容如下： package main import \"fmt\" //go:generate echo hello //go:generate go run main.go //go:generate echo file=$GOFILE pkg=$GOPACKAGE func main() { fmt.Println(\"main func\") } 执行“go generate”后，输出如下： $ go generate hello main func file=main.go pkg=main 最后的build步骤就两步 all: go generate && go build . go generate常使用的一些工具 在学习go generate的过程中，我还看到了一篇generate的常用工具的wiki，我并没有全部使用过，在此与大家分享，希望能提升开发效率，https://github.com/golang/go/wiki/GoGenerateTools。 go generate仅在您有使用它的工具时才有用！这是生成代码的有用工具的不完整列表。 goyacc – Go的Yacc。 stringer – 实现fmt.Stringer枚举的接口。 gostringer – fmt.GoStringer为枚举实现接口。 jsonenums – 枚举的实现json.Marshaler和json.Unmarshaler接口。 go-syncmap – 使用软件包作为的通用模板生成Go代码sync.Map。 go-syncpool – 使用软件包作为的通用模板生成Go代码sync.Pool。 go-atomicvalue – 使用软件包作为的通用模板生成Go代码atomic.Value。 go-nulljson – 使用包作为实现database/sql.Scanner和的通用模板生成Go代码database/sql/driver.Valuer。 go-enum – 使用包作为实现接口的通用模板生成Go代码fmt.Stringer| binary| json| text| sql| yaml枚举。 go-import – 执行非go文件的自动导入。 gojson – 从示例json文档生成go结构定义。 vfsgen – 生成静态实现给定虚拟文件系统的vfsdata.go文件。 goreuse – 使用包作为通用模板通过替换定义来生成Go代码。 embedfiles – 将文件嵌入Go代码。 ragel – 状态机编译器 peachpy – 嵌入在Python中的x86-64汇编器，生成Go汇编 bundle – Bundle创建适用于包含在特定目标软件包中的源软件包的单一源文件版本。 msgp – MessagePack的Go代码生成器 protobuf – protobuf thriftrw – thrift gogen-avro – avro swagger-gen-types – 从swagger定义中去生成代码 avo – 使用Go生成汇编代码 Wire – Go的编译时依赖注入 sumgen – 从sum-type声明生成接口方法实现 interface-extractor – 生成所需类型的接口，仅在包内使用方法。 deep-copy – 为给定类型创建深度复制方法。 godoc安装 godoc属于golang.org/x/tools/ 根据https://github.com/golang/tools的说法, 最简单的安装: go get -u golang.org/x/tools/... 注意后面的三个点也是要的. 安装完毕后, 在GOPATH的bin下面, 会有很多tools $ ls /repo/yingjieb/go/bin/ authtest callgraph cover findcall gitauth godoc gopackages gotype helper lostcancel present shadow stress toolstash benchcmp compilebench digraph fiximports go-contrib-init goimports gorename goyacc html2article netrcauth present2md splitdwarf stringer unmarshal bundle cookieauth eg getgo godex gomvpkg gostacks guru ifaceassert nilness server ssadump stringintconv 注: go get是先下载后安装packages, 包括依赖的包 godoc使用 在自己的repo下面敲 yingjieb@godev-server /repo/yingjieb/godevsig/compatible $ /repo/yingjieb/go/bin/godoc -http 0.0.0.0:6060 using module mode; GOMOD=/repo/yingjieb/godevsig/compatible/go.mod # 我的repo下面有go.mod, godoc支持gomod yingjieb@godev-server /repo/yingjieb/godevsig/compatible $ ls go.mod LICENSE log msgdriven README.md package通配符和导入路径 package通配符... 比如go get, go install命令最后的packages, 是个import路径. 如果包含特殊的通配格式..., 这个路径就是pattern匹配模式. ...匹配任何字符串, 包括空串. 有两个特例: 结尾的/...匹配任何东西. 比如net/...匹配net net/http ...不匹配vendor. 比如./...不匹配 ./vendor ./mycode/vendor. 想匹配vendor要显式写. 比如./vendor/... 导入路径 支持本地导入路径和远程导入路径 导入路径可以重命名 比如 import \"example.org/pkg/foo\" go get会请求如下的page https://example.org/pkg/foo?go-get=1 (preferred) http://example.org/pkg/foo?go-get=1 (fallback, only with -insecure) 如果取下来的page有如下的元数据 指示example.org实际上是code.org/r/p/exproj, go tool会clone后面这个库, 但路径是example.org the go tool will verify that https://example.org/?go-get=1 contains the same meta tag and then git clone https://code.org/r/p/exproj into GOPATH/src/example.org. go mod模式下, 支持类似的机制: 元数据格式为 obj.function()中obj可以是nil 通常我们会认为如果obj是空指针, 那么这个调用会产生空指针引用, 进而panic. 实际上不是的, obj是nil, 不影响堆function()的调用. 代码如下: type people struct { name string } func (p *people) who() { //注意这一行, 即使p是nil, 这个函数也是会被调用. fmt.Println(\"me\") //访问p.name会panic, 但如果没有下面这一行, 整个程序可以正常执行. //fmt.Println(p.name) } var team map[string]*people = make(map[string]*people) func main() { team[\"wang\"].who() san := people{\"zhang san\"} san.who() } 如何处理? 在C里面, 代码里经常要判断指针是否为空. 那么是不是这里我们也要判断? 答案是不需要. 首先, 如果对象都已经是空了, 说明哪里肯定出了问题. 那不如就让它panic, go会打印调用栈来帮助分析问题. 而为什么在C里面, 我们要判断? 因为C程序只能segmentation fault, 除了coredump没有更多的信息. 而分析coredump成本比较大. 所以C程序员习惯自己来处理空指针错误, 通常也是打印错误. 对于GO程序员, runtime会接管SIGSEGV, 在空指针访问的时候, 自动打印调用栈. 所以, go的理念是: 如果确实有问题, 程序要崩要趁早; 崩在第一现场 切片的reslicing 对于一个切片, 比如ss = [\"stdout\"], 其len为1. 对它进行re slicing的操作ss[1:]是合法的. 即slice[len():len()]是合法的, 比如ss[1:1:1], 本身这样写, 就是矛盾的: 最左边的1要求从1开始, 包括1; 但是中间的1要求到1结束, 不包括1; 最后的1表示只有1个容量. go语法支持这种re slicing, 结果就是len()为0的切片. 再议目录结构 Go 语言项目中的每一个文件目录都代表着一个独立的命名空间，也就是一个单独的包，当我们想要引用其他文件夹的目录时，首先需要使用 import 关键字引入相应的文件目录，再通过 pkg.xxx 的形式引用其他目录定义的结构体、函数或者常量 不要使用src目录 命令行执行程序放在/cmd里: /cmd/server/main.go直接编译出来的文件就是server api定义给外部的接口api └── protobuf-spec └── oceanbookpb ├── oceanbook.pb.go └── oceanbook.proto 参考: 如何写出优雅的 Go 语言代码 具体error判断 下面的代码里, 返回的err不为nil, 但也不好用类型断言来判断err具体类型(可能出错函数直接返回的是errors.New()) 那么还可以通过判断字符串来得到具体的错误, 下面第6行. var err error e.epollFd, err = syscall.EpollCreate(1) switch { case err == nil: break case err.Error() == \"function not implemented\": // Some arch (arm64) do not implement EpollCreate(). if e.epollFd, err = syscall.EpollCreate1(0); err != nil { e.mu.Unlock() return err } default: e.mu.Unlock() return err } 函数赋值给变量 openFileOrig是个函数, 可以直接赋值给变量openFile, 相当于C里面的函数指针. var ( mu sync.Mutex maxSpeed int64 = -1 openFile = openFileOrig ) func openFileOrig(path string, flag int) (io.ReadCloser, error) { f, err := fs.Open(path, flag) if err != nil { return nil, err } return f, nil } gob encode和网络io的结合 goroutine 5 [IO wait]: internal/poll.runtime_pollWait(0x7f1c3dbe3ec8, 0x72, 0xffffffffffffffff) /usr/local/go/src/runtime/netpoll.go:184 +0x55 internal/poll.(*pollDesc).wait(0xc000104218, 0x72, 0x1000, 0x1000, 0xffffffffffffffff) /usr/local/go/src/internal/poll/fd_poll_runtime.go:87 +0x45 internal/poll.(*pollDesc).waitRead(...) /usr/local/go/src/internal/poll/fd_poll_runtime.go:92 internal/poll.(*FD).Read(0xc000104200, 0xc000149000, 0x1000, 0x1000, 0x0, 0x0, 0x0) /usr/local/go/src/internal/poll/fd_unix.go:169 +0x1cf net.(*netFD).Read(0xc000104200, 0xc000149000, 0x1000, 0x1000, 0xc0001c9c50, 0x42e031, 0x5a4478) /usr/local/go/src/net/fd_unix.go:202 +0x4f net.(*conn).Read(0xc000010018, 0xc000149000, 0x1000, 0x1000, 0x0, 0x0, 0x0) /usr/local/go/src/net/net.go:184 +0x68 bufio.(*Reader).Read(0xc0000c86c0, 0xc0000c47d0, 0x1, 0x9, 0x4ad2d8, 0x0, 0x0) /usr/local/go/src/bufio/bufio.go:226 +0x26a io.ReadAtLeast(0x5cb4e0, 0xc0000c86c0, 0xc0000c47d0, 0x1, 0x9, 0x1, 0x6bfea0, 0xc0000fc000, 0x0) /usr/local/go/src/io/io.go:310 +0x87 io.ReadFull(...) /usr/local/go/src/io/io.go:329 encoding/gob.decodeUintReader(0x5cb4e0, 0xc0000c86c0, 0xc0000c47d0, 0x9, 0x9, 0x30, 0x27, 0x0, 0x0) /usr/local/go/src/encoding/gob/decode.go:120 +0x6f encoding/gob.(*Decoder).recvMessage(0xc000104380, 0x0) /usr/local/go/src/encoding/gob/decoder.go:81 +0x57 encoding/gob.(*Decoder).decodeTypeSequence(0xc000104380, 0xc0000c6000, 0x59b95d) /usr/local/go/src/encoding/gob/decoder.go:143 +0x10c encoding/gob.(*Decoder).DecodeValue(0xc000104380, 0x54f1c0, 0xc0000ad900, 0x16, 0x0, 0x0) /usr/local/go/src/encoding/gob/decoder.go:211 +0x10b encoding/gob.(*Decoder).Decode(0xc000104380, 0x54f1c0, 0xc0000ad900, 0x0, 0x0) /usr/local/go/src/encoding/gob/decoder.go:188 +0x16d main.inputDispacher(0x5cdb60, 0xc0000d7840, 0x5cec80, 0xc000010018) /repo/yingjieb/godev/practice/src/tools/topid.go:334 +0x12d created by main.main /repo/yingjieb/godev/practice/src/tools/topid.go:558 +0xe22 单步decoder.Decode(&msg) gob decode使用了反射 gob是二进制编码, 在解码时, 先从io stream读出count, 再根据count读出对应的字节数来解码. var msg messageIn dec.Decode(&msg) // 入参e interface{}被赋值为&msg value := reflect.ValueOf(e) //value.Type().Kind() 必须是reflect.Ptr dec.DecodeValue(value) //入参v reflect.Value被赋值为value dec.mutex.Lock() defer dec.mutex.Unlock() dec.buf.Reset() dec.err = nil id := dec.decodeTypeSequence(false) for dec.err == nil if dec.buf.Len() == 0 if !dec.recvMessage() //先从底层io.Reader读count, 再按照count读具体的字节数 比如典型的:n, err := io.ReadFull(r, buf[0:1]) b := buf[0] // gob编码中, 小于128的用一个字节表示 if b protobuf里面oneof转成go结构体 oneof对应go结构里的interface, 并且自动生成isMessageName_MyField的interface, 和响应格式的签名方法 自动生成GetXxx方法 生成的结构体里面还有些隐藏的字段:XXX_开头的, 可能是protobuf自己用的. 参考: https://developers.google.com/protocol-buffers/docs/reference/go-generated proto定义 // Messages specifically used to retrieve and configure BIP PM counters for GPON message GPONBIPWrapper { string onu_name = 1; // vOnuMgmt -> vProxy uint32 chnl_term_id = 2; // vProxy -> Device (to be changed later to chnl_term_name) uint32 onu_id = 3; // vProxy -> Device oneof msg { ConfigureBERInterval config_ber_interval = 4; // vOnuMgmt -> vProxy -> Device ConfigureBERIntervalResponse config_ber_interval_response = 5; // Device -> vProxy -> vOnuMgmt GetBIPCounters get_bip_counters = 6; // vOnuMgmt -> vProxy -> Device GetBIPCountersResponse get_bip_counters_response = 7; // Device -> vProxy -> vOnuMgmt } } 转成的结构体 // Messages specifically used to retrieve and configure BIP PM counters for GPON type GPONBIPWrapper struct { OnuName string `protobuf:\"bytes,1,opt,name=onu_name,json=onuName,proto3\" json:\"onu_name,omitempty\"` ChnlTermId uint32 `protobuf:\"varint,2,opt,name=chnl_term_id,json=chnlTermId,proto3\" json:\"chnl_term_id,omitempty\"` OnuId uint32 `protobuf:\"varint,3,opt,name=onu_id,json=onuId,proto3\" json:\"onu_id,omitempty\"` // Types that are valid to be assigned to Msg: // *GPONBIPWrapper_ConfigBerInterval // *GPONBIPWrapper_ConfigBerIntervalResponse // *GPONBIPWrapper_GetBipCounters // *GPONBIPWrapper_GetBipCountersResponse Msg isGPONBIPWrapper_Msg `protobuf_oneof:\"msg\"` XXX_NoUnkeyedLiteral struct{} `json:\"-\"` XXX_unrecognized []byte `json:\"-\"` XXX_sizecache int32 `json:\"-\"` } type isGPONBIPWrapper_Msg interface { isGPONBIPWrapper_Msg() } func (*GPONBIPWrapper_ConfigBerInterval) isGPONBIPWrapper_Msg() {} func (*GPONBIPWrapper_ConfigBerIntervalResponse) isGPONBIPWrapper_Msg() {} func (*GPONBIPWrapper_GetBipCounters) isGPONBIPWrapper_Msg() {} func (*GPONBIPWrapper_GetBipCountersResponse) isGPONBIPWrapper_Msg() {} func (m *GPONBIPWrapper) GetMsg() isGPONBIPWrapper_Msg { if m != nil { return m.Msg } return nil } "},"notes/golang_杂记3.html":{"url":"notes/golang_杂记3.html","title":"杂记3","keywords":"","body":" go按位取反(bitwise not) go的相等性(==) 普通类型的比较 指针的相等性 channel的相等性 interface的相等性 结构体的相等性 Array的相等性 string []byte用bytes.Equal比较 reflect.DeepEqual万能比较 cmp包 通过unix socket发送fd 发送 接收 发送2 接收2 创建临时文件并mmap成结构体 memfd_create()系统调用 gvisor中的使用场景 用正则表达式 遍历/proc/self/maps 递归缩进打印error 读go micro cmd cmd.APP() 已经注册的cmd cli相关的cmd cli子命令 client接口 pattern match 读fs_linux.go 善用字符串库函数--strings.Join 切片的插入 匿名函数执行 go按位取反(bitwise not) go没有专用的取反操作符, 但用异或可以取反: func main() { var bitwisenot byte = 0x0F // printing the number in 8-Bit fmt.Printf(\"%08b\\n\", bitwisenot) // 00001111 fmt.Printf(\"%08b\\n\", ^bitwisenot) // 11110000 fmt.Printf(\"%08b\\n\", 1^bitwisenot) // 00001110 和上面结果不一样 fmt.Printf(\"%08b\\n\", ^0x0F) // -0010000 默认数字都是int fmt.Printf(\"%08b\\n\", ^(int)(0x0F)) // -0010000 fmt.Printf(\"%08b\\n\", ^(uint)(0x0F)) // 1111111111111111111111111111111111111111111111111111111111110000 不带符号位 } 结果: 00001111 11110000 00001110 -0010000 -0010000 1111111111111111111111111111111111111111111111111111111111110000 go的相等性(==) 首先, map和slice不能用==比较 function也不能比较. f := func(int) int { return 1 } g := func(int) int { return 2 } f == g //这样比较会编译错误 但function可以跟nil比较. 普通类型的比较 boo, int, float, complex的比较就是普通比较. 但需要注意的是float的NaN不等于NaN nan := math.NaN() pos_inf := math.Inf(1) neg_inf := math.Inf(-1) fmt.Println(nan == nan) // false fmt.Println(pos_inf == pos_inf) // true fmt.Println(neg_inf == neg_inf) // true fmt.Println(pos_inf == neg_inf) // false 指针的相等性 要么两个指针都是nil, 要么两个指针指向同样的地址: var p1, p2 *string name := \"foo\" fmt.Println(p1 == p2) // true p1 = &name p2 = &name fmt.Println(p1) // 0x40c148 fmt.Println(p2) // 0x40c148 fmt.Println(&p1) // 0x40c138 fmt.Println(&p2) // 0x40c140 fmt.Println(*p1) // foo fmt.Println(*p2) // foo fmt.Println(p1 == p2) // true 需要注意的是, 两个不同的empty struct(即空的struct实例)的地址可能相等 A struct or array type has size zero if it contains no fields (or elements, respectively) that have a size greater than zero. Two distinct zero-size variables may have the same address in memory. type S struct{} func main() { var p1, p2 *S s1 := S{} s2 := S{} p1 = &s1 p2 = &s2 fmt.Printf(\"%p\\n\", p1) // 0x1e52bc fmt.Printf(\"%p\\n\", p2) // 0x1e52bc fmt.Println(p1) // &{} fmt.Println(p2) // &{} fmt.Println(&p1) // 0x40c138 fmt.Println(&p2) // 0x40c140 fmt.Println(*p1) // {} fmt.Println(*p2) // {} fmt.Println(p1 == p2) // true 本来s1和s2不是一个东西, 当都是空, 他们的地址相同, 所以相等. } 如果结构体非空, S struct {f int}, p1和p2就不相等了. channel的相等性 满足下面条件之一 两个chnnel都是nil 两个都是从同一个make函数生成的 func f(ch1 chan int, ch2 *chan int) { fmt.Println(ch1 == *ch2) // true } func main() { var ch1, ch2 chan int fmt.Println(ch1 == ch2) // true ch1 = make(chan int) ch2 = make(chan int) fmt.Println(ch1 == ch2) // false ch2 = ch1 fmt.Printf(\"%p\\n\", &ch1) // 0x40c138 fmt.Printf(\"%p\\n\", &ch2) // 0x40c140 fmt.Println(ch1 == ch2) // true f(ch1, &ch1) } interface的相等性 两个interface都是nil(注意动态类型也要是nil)type I interface{ m() } type T []byte func (t T) m() {} func main() { var t T fmt.Println(t == nil) // true var i I = t fmt.Println(i == nil) // false fmt.Println(reflect.TypeOf(i)) // main.T fmt.Println(reflect.ValueOf(i).IsNil()) // true } 动态类型相同, 并且动态值相等type A int type B = A type C int type I interface{ m() } func (a A) m() {} func (c C) m() {} func main() { var a I = A(1) var b I = B(1) var c I = C(1) fmt.Println(a == b) // true 这里A和B是强别名(=号别名), 类型是一样的. fmt.Println(b == c) // false 类型不同不相等 fmt.Println(a == c) // false 类型不同不相等 } 类型I的interface变量i可以和普通类型X的实例x比较, 只要 类型X实现了接口I 类型X可以比较 所以i和x比较, 如果i的动态类型是X, i的动态值又等于x, 那么i和x相等 type I interface{ m() } type X int func (x X) m() {} type Y int func (y Y) m() {} type Z int func main() { var i I = X(1) fmt.Println(i == X(1)) // true fmt.Println(i == Y(1)) // false // fmt.Println(i == Z(1)) // mismatched types I and C // fmt.Println(i == 1) // mismatched types I and int } 如果动态类型相等, 但这个类型不能比较, 则会产生panic: type A []byte func main() { var i interface{} = A{} var j interface{} = A{} fmt.Println(i == j) } panic: runtime error: comparing uncomparable type main.A 如果动态类型不一样, 那就直接不等: type A []byte type B []byte func main() { // A{} == A{} // slice can only be compared to nil var i interface{} = A{} var j interface{} = B{} fmt.Println(i == j) // false } 结构体的相等性 首先, 结构体可以直接用==操作符比较. 如果里面的非_域都相等, 则两个结构体相等. 注意, 结构体里面的大写, 小写域都要相等. type A struct { _ float64 f1 int F2 string } type B struct { _ float64 f1 int F2 string } func main() { fmt.Println(A{1.1, 2, \"x\"} == A{0.1, 2, \"x\"}) // true // fmt.Println(A{} == B{}) // mismatched types A and B } 当判断x==y时, 只有x可以赋值给y或者y可以赋值给x才能用==操做符. 所以下面的判断是不行的, 编译时就会报错. A{} == B{} Array的相等性 注意这里说的是Array, 不是slice. Array里面的每个元素都相等的话, 两个array相等. type T struct { name string age int _ float64 } func main() { x := [...]float64{1.1, 2, 3.14} fmt.Println(x == [...]float64{1.1, 2, 3.14}) // true y := [1]T{{\"foo\", 1, 0}} fmt.Println(y == [1]T{{\"foo\", 1, 1}}) // true } string string的比较按照[]byte按字节比较. fmt.Println(strings.ToUpper(\"ł\") == \"Ł\") // true fmt.Println(\"foo\" == \"foo\") // true fmt.Println(\"foo\" == \"FOO\") // false fmt.Println(\"Michał\" == \"Michal\") // false fmt.Println(\"żondło\" == \"żondło\") // true fmt.Println(\"żondło\" != \"żondło\") // false fmt.Println(strings.EqualFold(\"ąĆź\", \"ĄćŹ\")) // true []byte用bytes.Equal比较 切片不能直接比较. 但bytes.Equal可以比较两个[]byte s1 := []byte{'f', 'o', 'o'} s2 := []byte{'f', 'o', 'o'} fmt.Println(bytes.Equal(s1, s2)) // true s2 = []byte{'b', 'a', 'r'} fmt.Println(bytes.Equal(s1, s2)) // false s2 = []byte{'f', 'O', 'O'} fmt.Println(bytes.EqualFold(s1, s2)) // true s1 = []byte(\"źdźbło\") s2 = []byte(\"źdŹbŁO\") fmt.Println(bytes.EqualFold(s1, s2)) // true s1 = []byte{} s2 = nil fmt.Println(bytes.Equal(s1, s2)) // true reflect.DeepEqual万能比较 func DeepEqual(x, y interface{}) bool可以比较任意两个值. 比如map m1 := map[string]int{\"foo\": 1, \"bar\": 2} m2 := map[string]int{\"foo\": 1, \"bar\": 2} // fmt.Println(m1 == m2) // map can only be compared to nil fmt.Println(reflect.DeepEqual(m1, m2)) // true m2 = map[string]int{\"foo\": 1, \"bar\": 3} fmt.Println(reflect.DeepEqual(m1, m2)) // false m3 := map[string]interface{}{\"foo\": [2]int{1,2}} m4 := map[string]interface{}{\"foo\": [2]int{1,2}} fmt.Println(reflect.DeepEqual(m3, m4)) // true var m5 map[float64]string fmt.Println(reflect.DeepEqual(m5, nil)) // false fmt.Println(m5 == nil) // true 比如slice s := []string{\"foo\"} fmt.Println(reflect.DeepEqual(s, []string{\"foo\"})) // true fmt.Println(reflect.DeepEqual(s, []string{\"bar\"})) // false s = nil fmt.Println(reflect.DeepEqual(s, []string{})) // false s = []string{} fmt.Println(reflect.DeepEqual(s, []string{})) // true 比如结构体 type T struct { name string Age int } func main() { t := T{\"foo\", 10} fmt.Println(reflect.DeepEqual(t, T{\"bar\", 20})) // false fmt.Println(reflect.DeepEqual(t, T{\"bar\", 10})) // false fmt.Println(reflect.DeepEqual(t, T{\"foo\", 10})) // true } cmp包 google提供了cmp包, 可以打印两个值的差异 import ( \"fmt\" \"github.com/google/go-cmp/cmp\" ) type T struct { Name string Age int City string } func main() { x := T{\"Michał\", 99, \"London\"} y := T{\"Adam\", 88, \"London\"} if diff := cmp.Diff(x, y); diff != \"\" { fmt.Println(diff) } } 输出 main.T{ - Name: \"Michał\", + Name: \"Adam\", - Age: 99, + Age: 88, City: \"London\", } 通过unix socket发送fd gvisor的pkg/unet/unet.go里面提供了listen, accept等方法 unet是给server端用的. 比如read和write方法, 先尝试用阻塞式的unix.RawSyscall(unix.SYS_RECVMSG, ...), 不行再用对fd的pollunix.Syscall6(unix.SYS_PPOLL, ...) 还提供了通过unix socket发送/接收fd的方法: // PackFDs packs the given list of FDs in the control message. // // This must be used prior to WriteVec. func (c *ControlMessage) PackFDs(fds ...int) { *c = ControlMessage(unix.UnixRights(fds...)) } // ExtractFDs returns the list of FDs in the control message. // // Either this or CloseFDs should be used after EnableFDs. func (c *ControlMessage) ExtractFDs() ([]int, error) { msgs, err := unix.ParseSocketControlMessage(*c) if err != nil { return nil, err } var fds []int for _, msg := range msgs { thisFds, err := unix.ParseUnixRights(&msg) if err != nil { // Different control message. return nil, err } for _, fd := range thisFds { if fd >= 0 { fds = append(fds, fd) } } } return fds, nil } 被extract出来的fd可以用比如下面的函数来生成一个File对象. //比如调用 os.NewFile(uintptr(fd), \"urpc\") // NewFile returns a new File with the given file descriptor and // name. The returned value will be nil if fd is not a valid file // descriptor. On Unix systems, if the file descriptor is in // non-blocking mode, NewFile will attempt to return a pollable File // (one for which the SetDeadline methods work). // // After passing it to NewFile, fd may become invalid under the same // conditions described in the comments of the Fd method, and the same // constraints apply. func NewFile(fd uintptr, name string) *File 发送 //@pkg/lisafs/sock.go // writeTo writes the passed iovec to the UDS and donates any passed FDs. func writeTo(sock *unet.Socket, iovec [][]byte, dataLen int, fds []int) error { w := sock.Writer(true) //这里的fds是可选的, 会做为control msg来发送 if len(fds) > 0 { w.PackFDs(fds...) } for n := 0; n 接收 //@pkg/lisafs/sock.go // readFrom fills the passed buffer with data from the socket. It also returns // any donated FDs. func readFrom(sock *unet.Socket, buf []byte, wantFDs uint8) ([]int, error) { r := sock.Reader(true) r.EnableFDs(int(wantFDs)) n := len(buf) for got := 0; got 发送2 //@pkg/urpc/urpc.go // marshal sends the given FD and json struct. func marshal(s *unet.Socket, v interface{}, fs []*os.File) error { // Marshal to a buffer. data, err := json.Marshal(v) if err != nil { log.Warningf(\"urpc: error marshalling %s: %s\", fmt.Sprintf(\"%v\", v), err.Error()) return err } // Write to the socket. w := s.Writer(true) if fs != nil { var fds []int for _, f := range fs { fds = append(fds, int(f.Fd())) } w.PackFDs(fds...) } ... } 接收2 //@pkg/urpc/urpc.go // unmarhsal receives an FD (optional) and unmarshals the given struct. func unmarshal(s *unet.Socket, v interface{}) ([]*os.File, error) { // Receive a single byte. r := s.Reader(true) r.EnableFDs(maxFiles) firstByte := make([]byte, 1) // Extract any FDs that may be there. if _, err := r.ReadVec([][]byte{firstByte}); err != nil { return nil, err } fds, err := r.ExtractFDs() ... } 创建临时文件并mmap成结构体 memfd_create()系统调用 #include int memfd_create(const char *name, unsigned int flags); 用tmpfs创建一个临时文件, 这个文件和通常文件系统没关系, 但可以支持所有文件操做. 可以用这个文件来共享内存: 进程A调用memfd_create(), 返回fd 进程B去打开/proc//fd/(pid是进程A的pid, fd是A调用memfd_create()返回的fd号.), 打开后可以mmap, 就看到进程A一样的内容了. gvisor中的使用场景 //RTMemoryStats是要被mmap的结构体 // RTMemoryStatsSize is the size of the RTMemoryStats struct. var RTMemoryStatsSize = unsafe.Sizeof(RTMemoryStats{}) // RTMemoryStatsPointer casts addr to a RTMemoryStats pointer. func RTMemoryStatsPointer(addr uintptr) *RTMemoryStats { return (*RTMemoryStats)(unsafe.Pointer(addr)) } const name = \"memory-usage\" fd, err := memutil.CreateMemFD(name, 0) p, err := unix.BytePtrFromString(name) fd, _, e := unix.Syscall(unix.SYS_MEMFD_CREATE, uintptr(unsafe.Pointer(p)), uintptr(flags), 0) file := os.NewFile(uintptr(fd), name) //设置文件大小为结构体RTMemoryStatsSize的大小 file.Truncate(int64(RTMemoryStatsSize)) //mmap这个文件 mmap, err := memutil.MapFile(0, RTMemoryStatsSize, unix.PROT_READ|unix.PROT_WRITE, unix.MAP_SHARED, file.Fd(), 0) //现在全局变量MemoryAccounting.RTMemoryStats就指向了这个文件. //直接用那个结构体不香吗? MemoryAccounting = &MemoryLocked{ File: file, RTMemoryStats: RTMemoryStatsPointer(mmap), } 用正则表达式 遍历/proc/self/maps 比如一个程序想解析当前进程的进程空间: $ cat /proc/self/maps 55cb9cb6b000-55cb9cb73000 r-xp 00000000 fc:02 396 /bin/cat 55cb9cd72000-55cb9cd73000 r--p 00007000 fc:02 396 /bin/cat 55cb9cd73000-55cb9cd74000 rw-p 00008000 fc:02 396 /bin/cat 55cb9e7a2000-55cb9e7c3000 rw-p 00000000 00:00 0 [heap] 7f3367281000-7f336754d000 r--p 00000000 fc:02 7228 /usr/lib/locale/locale-archive 7f336754d000-7f3367734000 r-xp 00000000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f3367734000-7f3367934000 ---p 001e7000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f3367934000-7f3367938000 r--p 001e7000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f3367938000-7f336793a000 rw-p 001eb000 fc:02 44721 /lib/x86_64-linux-gnu/libc-2.27.so 7f336793a000-7f336793e000 rw-p 00000000 00:00 0 7f336793e000-7f3367967000 r-xp 00000000 fc:02 44717 /lib/x86_64-linux-gnu/ld-2.27.so 7f3367b33000-7f3367b57000 rw-p 00000000 00:00 0 7f3367b67000-7f3367b68000 r--p 00029000 fc:02 44717 /lib/x86_64-linux-gnu/ld-2.27.so 7f3367b68000-7f3367b69000 rw-p 0002a000 fc:02 44717 /lib/x86_64-linux-gnu/ld-2.27.so 7f3367b69000-7f3367b6a000 rw-p 00000000 00:00 0 7fff4ad74000-7fff4ad95000 rw-p 00000000 00:00 0 [stack] 7fff4adda000-7fff4addd000 r--p 00000000 00:00 0 [vvar] 7fff4addd000-7fff4addf000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] 可以用regex // mapsLine matches a single line from /proc/PID/maps. var mapsLine = regexp.MustCompile(\"([0-9a-f]+)-([0-9a-f]+) ([r-][w-][x-][sp]) ([0-9a-f]+) [0-9a-f]{2,3}:[0-9a-f]{2,} [0-9]+\\\\s+(.*)\") func parseMaps() { f, err := os.Open(\"/proc/self/maps\") r := bufio.NewReader(f) for { b, err := r.ReadBytes('\\n') m := mapsLine.FindSubmatch(b) start, err := strconv.ParseUint(string(m[1]), 16, 64) end, err := strconv.ParseUint(string(m[2]), 16, 64) read := m[3][0] == 'r' write := m[3][1] == 'w' execute := m[3][2] == 'x' shared := m[3][3] == 's' offset, err := strconv.ParseUint(string(m[4]), 16, 64) } } 递归缩进打印error type vmError struct { self error children []error } func (vme vmError) Error() string { var b strings.Builder fmt.Fprintf(&b, \"----\\n\") if vme.self != nil { fmt.Fprintf(&b, \"%v\\n\", vme.self) } for _, err := range vme.children { for _, s := range strings.Split(err.Error(), \"\\n\") { if s != \"\\tat -\" { fmt.Fprintf(&b, \"\\t%s\\n\", s) } } } return b.String() } 读go micro cmd micro的入口命令, 只调用了一个函数 这里import中的的v2选择了v2的tag. package main import ( \"github.com/micro/micro/v2/cmd\" ) func main() { cmd.Init() } 这里的Init原型很特别: cmd/cmd.go中, // Init initialised the command line func Init(options ...micro.Option) { Setup(cmd.App(), options...) cmd.Init( cmd.Name(name), cmd.Description(description), cmd.Version(buildVersion()), ) } 这里面的Option是type Option func(*Options), 一个函数签名, 入参是*Options Options是个巨大的结构体, 包含了所有的micro的概念. type Options struct { Auth auth.Auth Broker broker.Broker Cmd cmd.Cmd Config config.Config Client client.Client Server server.Server Store store.Store Registry registry.Registry Runtime runtime.Runtime Transport transport.Transport Profile profile.Profile // Before and After funcs BeforeStart []func() error BeforeStop []func() error AfterStart []func() error AfterStop []func() error // Other options for implementations of the interface // can be stored in a context Context context.Context Signal bool } cmd.APP() func App() *cli.App { //这里的DefaultCmd是个interface, 由newCmd实例化 //即var DefaultCmd = newCmd() return DefaultCmd.App() } type cmd struct { opts Options app *cli.App } //newCmd返回的是Cmd这个interface func newCmd(opts ...Option) Cmd { //实际的cmd是上面的结构体 cmd := new(cmd) cmd.opts = options cmd.app = cli.NewApp() //返回cmd实例, 但从外面看起来是Cmd interface return cmd } //综上, DefaultCmd.App()实际上就是 func (c *cmd) App() *cli.App { return c.app } //那么c.app实际上就是cli.NewApp()的实例化结果. 上面的cli.NewApp()在github.com/micro/cli/v2, 它实际上是urfave/cli的fork. 已经注册的cmd cmd/cmd.go app.Commands = append(app.Commands, new.Commands()...) app.Commands = append(app.Commands, runtime.Commands(options...)...) app.Commands = append(app.Commands, store.Commands(options...)...) app.Commands = append(app.Commands, config.Commands(options...)...) app.Commands = append(app.Commands, api.Commands(options...)...) app.Commands = append(app.Commands, auth.Commands()...) app.Commands = append(app.Commands, bot.Commands()...) app.Commands = append(app.Commands, cli.Commands()...) app.Commands = append(app.Commands, broker.Commands(options...)...) app.Commands = append(app.Commands, health.Commands(options...)...) app.Commands = append(app.Commands, proxy.Commands(options...)...) app.Commands = append(app.Commands, router.Commands(options...)...) app.Commands = append(app.Commands, tunnel.Commands(options...)...) app.Commands = append(app.Commands, network.Commands(options...)...) app.Commands = append(app.Commands, registry.Commands(options...)...) app.Commands = append(app.Commands, debug.Commands(options...)...) app.Commands = append(app.Commands, server.Commands(options...)...) app.Commands = append(app.Commands, service.Commands(options...)...) app.Commands = append(app.Commands, build.Commands()...) app.Commands = append(app.Commands, web.Commands(options...)...) cli相关的cmd cli除了注册了自己的cmd, 还注册了call stream publish等命令. 而且cli.Commands()中, cli命令本身和所有的子命令都是同级的. 只是cli被安排在了第一个 func Commands() []*cli.Command { commands := []*cli.Command{ { Name: \"cli\", Usage: \"Run the interactive CLI\", Action: Run, }, { Name: \"call\", Usage: \"Call a service e.g micro call greeter Say.Hello '{\\\"name\\\": \\\"John\\\"}\", //注意这里的Print是个闭包函数, 返回callService的包装. 类似装饰器 Action: Print(callService), Flags: []cli.Flag{ &cli.StringFlag{ Name: \"address\", Usage: \"Set the address of the service instance to call\", EnvVars: []string{\"MICRO_ADDRESS\"}, }, &cli.StringFlag{ Name: \"output, o\", Usage: \"Set the output format; json (default), raw\", EnvVars: []string{\"MICRO_OUTPUT\"}, }, &cli.StringSliceFlag{ Name: \"metadata\", Usage: \"A list of key-value pairs to be forwarded as metadata\", EnvVars: []string{\"MICRO_METADATA\"}, }, }, }, ... } } cli命令对应的Action是Run. 这个Run是个典型的Read-Eval-Print-Loop, 基本上是 for { //先readline() args, err := r.Readline() //准备参数 args = strings.TrimSpace(args) parts := strings.Split(args, \" \") //找到cmd cmd, ok := commands[name] //执行cmd rsp, err := cmd.exec(c, parts[1:]) println(string(rsp)) } micro的交互式cli很简单, 就是在顶层有个循环来readline, 执行cmd. 没有其他功能. cli子命令 这些子命令, 比如call, publish, 实际调用的是internal/command/cli/command.go中的 func CallService(c *cli.Context, args []string) ([]byte, error) { 参数和返回值都通过json格式编码 d := json.NewDecoder(strings.NewReader(req)) ctx := callContext(c) creq := (*cmd.DefaultOptions().Client).NewRequest(service, endpoint, request, client.WithContentType(\"application/json\")) //实际调用的是client的call接口, 这是个同步调用, 发req, 等rsp err = (*cmd.DefaultOptions().Client).Call(ctx, creq, &rsp, opts...) //等待rsp并打印结果. } client接口 client是micro的核心抽象, 接口定义如下: // Client is the interface used to make requests to services. // It supports Request/Response via Transport and Publishing via the Broker. // It also supports bidirectional streaming of requests. type Client interface { Init(...Option) error Options() Options NewMessage(topic string, msg interface{}, opts ...MessageOption) Message NewRequest(service, endpoint string, req interface{}, reqOpts ...RequestOption) Request Call(ctx context.Context, req Request, rsp interface{}, opts ...CallOption) error Stream(ctx context.Context, req Request, opts ...CallOption) (Stream, error) Publish(ctx context.Context, msg Message, opts ...PublishOption) error String() string } client支持Req/Rsp(通过Transport抽象), 支持Pub/Sub(通过Broker)抽象, 还支持stream模式. pattern match 简单的*通配符匹配 func patternMatchs(str, pattern string) bool { if len(pattern) == 0 { return false } strs := strings.Split(pattern, \"*\") //fmt.Println(strs, len(strs)) var pos, index int if index = strings.Index(str, strs[0]); index != 0 { return false } end := strs[len(strs)-1] if index = strings.LastIndex(str, end); index+len(end) != len(str) { return false } for i, substr := range strs { if i == 0 || i == len(strs)-1 || len(substr) == 0 { continue } index = strings.Index(str[pos:], substr) if index == -1 { return false } pos += index + len(substr) } return true } 读fs_linux.go periph.io/x/periph@v3.6.2+incompatible/host/sysfs/fs_linux.go 善用字符串库函数--strings.Join 比如解析或|关系, 普通的思路是自己组类似flag1|flag2|flag3的字符串. 实际上, 下面的代码片段先把flag1 flag2 flag3分别append到[]string切片, 最后用strings.Join(out, \"|\")加或|操作符. func (e epollEvent) String() string { var out []string for _, b := range bitmaskString { if e&b.e != 0 { out = append(out, b.s) e &^= b.e } } if e != 0 { out = append(out, \"0x\"+strconv.FormatUint(uint64(e), 16)) } if len(out) == 0 { out = []string{\"0\"} } return strings.Join(out, \"|\") } 切片的插入 这个切片是个二叉树的顺序表的表达, 和sort包的思路一致. 先找到r.Name的位置i, 然后用append一个nil的方式把切片扩一个位置出来, 然后用内置的copy函数把i后面的元素往后都挪一个位置; 最后把位置i的元素填上. 为了把位置i后面的元素都挪一个位置, 代价是把这后面的所有元素都copy一遍 这里的copy实际上是overlap的, copy的时候, 源为l[i:], 目的是l[i+1:], 目的比源向后移动一个位置, 而且目的的元素个数也少了一个. 注意, 如果按照普通的for循环式的copy思路, src和dst重叠时不能正常工作的. 有人讨论说golang的copy语义类似memmove memcpy: 当src和dst重叠时, 结果不确定 memmove: src和dst可以重叠, 结果是正确的拷贝; 可以理解成有个临时缓冲做中转. 实际上并不需要中间buffer, 只需要在开始的时候判断是从前往后拷贝还是从后往前拷贝就行了. 结论: golang的copy支持overlap, 可以正确的拷贝 func insertRef(l []*Ref, r *Ref) []*Ref { n := r.Name i := search(len(l), func(i int) bool { return l[i].Name > n }) l = append(l, nil) copy(l[i+1:], l[i:]) l[i] = r return l } 下面是对应的快排 注意在search函数里, 并不需要传入要查找的切片; search调用f的时候, f会比较切片元素, f会访问切片. 在本例中, f能访问insertRef函数的l []*Ref变量, 这也是一种闭包形式? // search implements the same algorithm as sort.Search(). // // It was extracted to to not depend on sort, which depends on reflect. func search(n int, f func(int) bool) int { lo := 0 for hi := n; lo > 1); !f(i) { lo = i + 1 } else { hi = i } } return lo } 匿名函数执行 下面的例子中, 匿名行数在定义后就执行, 就像普通的代码块执行一样: 变量r和err都能直接被匿名函数引用到. 那为什么要用func(){}()这种形式呢? 首先, 匿名函数也是要函数栈的, 多了匿名函数性能上不会更好; 但是, 因为遍历全局的map byName byNumber 有锁操作, 那么使用匿名函数配合defer关键词来加锁和解锁, 代码更优雅. 如果不要这个匿名的壳子, 要么不用defer, 自己找地方加unlock; 还想用defer的话, defer会在r.Open()后执行. 估计这里的逻辑是: 一定要在r.Open()前unlock func Open(name string) (i2c.BusCloser, error) { var r *Ref var err error func() { mu.Lock() defer mu.Unlock() if len(byName) == 0 { err = errors.New(\"i2creg: no bus found; did you forget to call Init()?\") return } if len(name) == 0 { r = getDefault() return } // Try by name, by alias, by number. if r = byName[name]; r == nil { if r = byAlias[name]; r == nil { if i, err2 := strconv.Atoi(name); err2 == nil { r = byNumber[i] } } } }() if err != nil { return nil, err } if r == nil { return nil, errors.New(\"i2creg: can't open unknown bus: \" + strconv.Quote(name)) } return r.Open() } "},"notes/golang_lib选型.html":{"url":"notes/golang_lib选型.html","title":"lib选型","keywords":"","body":" 框架 goframe gf hello Hello World API Service Demo 编解码 性能汇总 排名 bson msgpack go解释器 python装饰器 protobuf cli选型 需求 新增备选 备选 Survey grumble liner readline 我的代码: ishell go-prompt cobra 教程 urfave/cli 简单例子 子命令 其他 go micro的cli 方案1 -- go-prompt 方案2 -- promptui + cobra 方案3 -- readline + cobra 方案4 -- 自己写REPL循环 + cobra 框架 goframe gf 作者是国人 郭强, 应该是某互联网大厂的架构师 https://goframe.org/display/gf 库链接: https://github.com/gogf/gf/issues gf是个go的web应用开发框架, 提供了大一统的企业应用开发的基础库: 封装了常见的基础库: hello 创建一个hello工程 gf init hello 默认就开始编译运行了, 起来之后默认就提供swagger UI的和open api等url. Hello World 视频地址：https://www.bilibili.com/video/BV15R4y1G7hq/ 包含以下内容： 安装GoFrame CLI 使用CLI创建一个Go项目 工程目录介绍 API Service Demo 视频地址：https://www.bilibili.com/video/BV1b44y1M7oL/ 代码地址：https://github.com/gogf/gf-demo-user 我们以一个简单的API Service为例来介绍如何使用GoFrame框架以及相应的CLI工具来开发一个接口项目。 包含以下内容： 包名设计 接口设计 接口文档 配置管理 控制器实现 业务逻辑封装 路由注册 中间件使用 Context及上下文变量 编解码 性能汇总 https://golangrepo.com/repo/alecthomas-go_serialization_benchmarks-go-benchmarks 排名 https://kokizzu.blogspot.com/2020/12/golang-serialization-benchmark-2020.html Format type ns/op bytes/op allocs/op ns/alloc Mum ser 97 48 0 0.00 GencodeUnsafe ser 98 46 48 2.05 Gotiny ser 130 48 0 0.00 GotinyNoTime ser 136 48 0 0.00 Gogoprotobuf ser 147 53 64 2.30 Msgp ser 174 97 128 1.36 Gencode ser 186 53 80 2.33 FlatBuffers ser 298 95 0 0.00 Goprotobuf ser 317 53 64 4.95 Protobuf ser 801 52 152 5.27 ShamatonMapMsgpack ser 819 92 208 3.94 Gob ser 834 63 48 17.38 Format type ns/op bytes/op allocs/op ns/alloc Gencode des 222 53 112 1.98 Gogoprotobuf des 230 53 96 2.40 GotinyNoTime des 241 48 96 2.51 FlatBuffers des 265 95 112 2.37 Gotiny des 267 48 112 2.38 Msgp des 314 97 112 2.80 CapNProto des 443 96 200 2.21 Goprotobuf des 481 53 168 2.86 Protobuf des 790 52 192 4.11 Ikea des 871 55 160 5.44 Gob des 900 63 112 8.04 GoAvro2Binary des 1092 47 560 1.95 Hprose des 1195 85 319 3.75 UgorjiCodecMsgpack des 1398 91 496 2.82 Binary des 1511 61 320 4.72 UgorjiCodecBinc des 1587 95 656 2.42 Bson des 1694 110 232 7.30 Format ns/op bytes Bebop 228 110 GencodeUnsafe 259 92 XDR2 290 120 Mum 313 96 Colfer 321 101 GotinyNoTime 377 96 Gogoprotobuf 377 106 Gotiny 397 96 Gencode 408 106 Msgp 488 194 FlatBuffers 563 190 Goprotobuf 798 106 CapNProto 829 192 Hprose2 1,213 170 ShamatonArrayMsgpack 1,241 100 CapNProto2 1,364 192 Ikea 1,541 110 ShamatonMapMsgpack 1,557 184 Protobuf 1,591 104 Gob 1,734 126 GoAvro2Binary 2,042 94 Hprose 2,110 170 UgorjiCodecMsgpack 2,820 182 VmihailencoMsgpack 2,838 200 Bson 2,865 220 Binary 2,875 122 UgorjiCodecBinc 3,055 190 EasyJson 3,513 299 XDR 4,091 182 JsonIter 4,266 278 GoAvro2Text 5,801 268 Sereal 6,313 264 Json 6,786 299 GoAvro 9,790 94 SSZNoTimeNoStringNoFloatA 12,616 110 bson https://github.com/mongodb/mongo-go-driver/tree/master/bson 对应的文档: https://pkg.go.dev/go.mongodb.org/mongo-driver/bson 还有一个实现: https://pkg.go.dev/labix.org/v2/mgo/bson 实现比较简单, 2014年更新的. msgpack github.com/vmihailenco/msgpack/v4 go解释器 库地址: https://github.com/traefik/yaegi 背景: https://traefik.io/blog/announcing-yaegi-263a1e2d070a/ 看起来很好 Complete support of Go specification Written in pure Go, using only the standard library Simple interpreter API: New(), Eval(), Use() Works everywhere Go works All Go & runtime resources accessible from script (with control) Security: unsafe and syscall packages neither used nor exported by default Support Go 1.13 and Go 1.14 (the latest 2 major releases) python装饰器 本质上是函数闭包: 把返回的函数赋值给原始函数名 @a_new_decorator def a_function_requiring_decoration(): \"\"\"Hey you! Decorate me!\"\"\" print(\"I am the function which needs some decoration to \" \"remove my foul smell\") a_function_requiring_decoration() #outputs: I am doing some boring work before executing a_func() # I am the function which needs some decoration to remove my foul smell # I am doing some boring work after executing a_func() #the @a_new_decorator is just a short way of saying: a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration) 参考这里 其中第一篇笔记很赞 protobuf protobuf项目的go版本现在转到: https://github.com/protocolbuffers/protobuf-go 之前是golang team维护的 https://github.com/golang/protobuf cli选型 需求 自动完成 命令层级 交互式(REPL): The name REPL stands for Read-Eval-Print-Loop - an interactive, typically console-based, programming environment. 命令式 新增备选 https://pkg.go.dev/golang.org/x/term 看起来有点官方 备选 从readline grumble liner里面选一个. 对abs来说, 不需要grumble这样的\"集成\"cli. readline/liner应该够了. 但grumble的思路可以借鉴. 最后选择readline Survey https://github.com/AlecAivazis/survey 感觉不是普通的shell思路, 应该说加了比如check box等功能 grumble https://github.com/desertbit/grumble 本身代码量很少, 但集成了readline等库; 但使用了较新维护的版本https://github.com/desertbit/readline 思路是cobra式的子命令, 但默认加了交互式命令行 更新不多, 但比较稳定? 作者自称受ishell启发 There are a handful of powerful go CLI libraries available (spf13/cobra, urfave/cli). However sometimes an integrated shell interface is a great and useful extension for the actual application. This library offers a simple API to create powerful CLI applications and automatically starts an integrated interactive shell, if the application is started without any command arguments. liner https://github.com/peterh/liner 看起来不错. 类VT100 支持go.mod 支持常规快捷键 支持历史命令 readline https://github.com/chzyer/readline 和c版本的readline套路一样. 有个库包装了readline, 成为一个简单的迭代器, 看起来不错 https://github.com/knieriem/readlineutil func (t *Term) Scan() bool { line, err := t.inst.Readline() if err != nil { t.err = err return false } t.line = line if t.prevPrompt != \"\" && line != \"\" { t.inst.SaveHistory(line) } return true } 我的代码: func repl() { completer := readline.NewPrefixCompleter() liner, err := readline.NewEx(&readline.Config{ Prompt: \"> \", AutoComplete: completer, EOFPrompt: \"exit\", }) if err != nil { panic(err) } defer liner.Close() for { l, err := liner.Readline() if errors.Is(err, io.EOF) { break } if errors.Is(err, readline.ErrInterrupt) { continue } if len(l) != 0 { fmt.Println(l) } } } ishell https://github.com/abiosoft/ishell 看着有点简陋... Sample Interactive Shell >>> help Commands: clear clear the screen greet greet user exit exit the program help display help >>> greet Someone Somewhere Hello Someone Somewhere >>> exit $ go-prompt https://github.com/c-bata/go-prompt 还在更新, 主打交互式, 命令联想, 快捷键, 历史记录上下翻. 好像目标是提供kubectl兼容的kube-prompt go.libhunt上对比 termui 主打文本的图形显示 gocui 主打文本布局, 有点像调试器界面 tview 也是主打界面的 tcell 文本控制台库, 似乎很有用. cobra https://github.com/spf13/cobra 使用广泛 Cobra is used in many Go projects such as Kubernetes, Hugo, and Github CLI to name a few. This list contains a more extensive list of projects using Cobra. cobra是个框架, 典型布局 ▾ appName/ ▾ cmd/ add.go your.go commands.go here.go main.go main.go package main import ( \"{pathToYourApp}/cmd\" ) func main() { cmd.Execute() } 教程 这个教程写的不错 用Cobra的几个好处: Easy to create subcommand-based CLIs and use nested subcommands. Automatic help generation for commands and flags. Increased productivity because of commands such as cobra init appname & cobra add cmdname. Helpful, intelligent suggestions (app srver… did you mean app server?). 这篇文章写的更好 Cobra比标准库flag的功能更丰富 支持-abc -e --example等传统的参数输入 支持子命令. 这个是主要原因. golang标准库里本来有, 但在internal下面, 外部用不了 子命令举例: package main import ( \"github.com/spf13/cobra\" ) func main() { cmd := newCommand() cmd.AddCommand(newNestedCommand()) rootCmd := &cobra.Command{} rootCmd.AddCommand(cmd) if err := rootCmd.Execute(); err != nil { println(err.Error()) } } func newCommand() *cobra.Command { cmd := &cobra.Command{ Run: func (cmd *cobra.Command, args []string) { println(`Foo`) }, Use: `foo`, Short: \"Command foo\", Long: \"This is a command\", } return cmd } func newNestedCommand() *cobra.Command { cmd := &cobra.Command{ Run: func (cmd *cobra.Command, args []string) { println(`Bar`) }, Use: `bar`, Short: \"Command bar\", Long: \"This is a nested command\", } return cmd } urfave/cli https://github.com/urfave/cli 主打轻量化.在积极维护 简单例子 package main import ( \"fmt\" \"log\" \"os\" \"github.com/urfave/cli/v2\" ) func main() { app := &cli.App{ Name: \"greet\", Usage: \"fight the loneliness!\", Action: func(c *cli.Context) error { fmt.Println(\"Hello friend!\") return nil }, } err := app.Run(os.Args) if err != nil { log.Fatal(err) } } 子命令 package main import ( \"fmt\" \"log\" \"os\" \"github.com/urfave/cli/v2\" ) func main() { app := cli.NewApp() app.EnableBashCompletion = true app.Commands = []*cli.Command{ { Name: \"add\", Aliases: []string{\"a\"}, Usage: \"add a task to the list\", Action: func(c *cli.Context) error { fmt.Println(\"added task: \", c.Args().First()) return nil }, }, { Name: \"complete\", Aliases: []string{\"c\"}, Usage: \"complete a task on the list\", Action: func(c *cli.Context) error { fmt.Println(\"completed task: \", c.Args().First()) return nil }, }, { Name: \"template\", Aliases: []string{\"t\"}, Usage: \"options for task templates\", Subcommands: []*cli.Command{ { Name: \"add\", Usage: \"add a new template\", Action: func(c *cli.Context) error { fmt.Println(\"new task template: \", c.Args().First()) return nil }, }, { Name: \"remove\", Usage: \"remove an existing template\", Action: func(c *cli.Context) error { fmt.Println(\"removed task template: \", c.Args().First()) return nil }, }, }, }, } err := app.Run(os.Args) if err != nil { log.Fatal(err) } } 其他 kingpin 似乎不怎么维护了 go micro的cli micro命令似乎进入了一个命令行界面, 有提示符. 但里面的命令和在shell中敲的一样. cli命令对应的Action是Run. 这个Run是个典型的Read-Eval-Print-Loop, 基本上是 for { //先readline() args, err := r.Readline() //准备参数 args = strings.TrimSpace(args) parts := strings.Split(args, \" \") //找到cmd cmd, ok := commands[name] //执行cmd rsp, err := cmd.exec(c, parts[1:]) println(string(rsp)) } micro的交互式cli很简单, 就是在顶层有个循环来readline, 执行cmd. 没有其他功能. 方案1 -- go-prompt 方案2 -- promptui + cobra 讨论在此 看下来感觉不好... 方案3 -- readline + cobra 方案4 -- 自己写REPL循环 + cobra 比如这篇文章里, 就只用了reader.ReadString('\\n') func main() { reader := bufio.NewReader(os.Stdin) for { fmt.Print(\"$ \") cmdString, err := reader.ReadString('\\n') if err != nil { fmt.Fprintln(os.Stderr, err) } err = runCommand(cmdString) if err != nil { fmt.Fprintln(os.Stderr, err) } } } func runCommand(commandStr string) error { commandStr = strings.TrimSuffix(commandStr, \"\\n\") arrCommandStr := strings.Fields(commandStr) switch arrCommandStr[0] { case \"exit\": os.Exit(0) // add another case here for custom commands. } cmd := exec.Command(arrCommandStr[0], arrCommandStr[1:]...) cmd.Stderr = os.Stderr cmd.Stdout = os.Stdout return cmd.Run() } "},"notes/golang_mod_proxy.html":{"url":"notes/golang_mod_proxy.html","title":"go mod和go proxy","keywords":"","body":" go get 和 replace gocenter已经停止维护了 go center使用心得 gitlab ci clone私有库 go mode 使用私有repo 使用ssh方式clone GOPROXY问题和解决 go clean go mod 使用replace指定私有repo artifactory和goproxy的问题汇总 godevsig-gocenter-remote获取不到新版本 gitlab默认不支持goproxy artifactory的repository概念 一个repository只对应一个类型 generic类型 local repository remote repository Virtual Repositories GOPROXY和artifactory 私有repo 私有GOPROXY setup私有GOPROXY go list package模式 module模式 国内可用的proxy go mod模式和普通模式的go get区别 普通模式下 go mod模式下 go mode模式下的help go mod使用记录 go.mod 本地import和外部repo import sum DB审查 go mod机制 定义go module 创建一个go module go.mod文件维护 版本格式 兼容性公约 Using v2 releases Using v1 releases go get 和 replace 有replace的时候, 比如: module github.com/godevsig/gshellos go 1.13 require ( github.com/d5/tengo/v2 v2.7.0 github.com/peterh/liner v1.2.1 ) replace github.com/d5/tengo/v2 => github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 直接go get github.com/godevsig/tengo/v2会报错: go get: github.com/godevsig/tengo/v2@v2.7.0: parsing go.mod: module declares its path as: github.com/d5/tengo/v2 but was required as: github.com/godevsig/tengo/v2 那么怎么更新replace的版本呢? 要先改go.mod, 最后一行指定branch是dev replace github.com/d5/tengo/v2 => github.com/godevsig/tengo/v2 dev 然后执行go get $ go get go: finding github.com/godevsig/tengo/v2 dev go: downloading github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 go: extracting github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 会自动更新go.mod文件, 最后一行变为: replace github.com/d5/tengo/v2 => github.com/godevsig/tengo/v2 v2.7.1-0.20210415163628-cf3fef922971 gocenter已经停止维护了 访问https://search.gocenter.io/, 显示gocenter服务已经终止了. 最后一句 You’ve arrived at this page because the era of Bintray, JCenter, GoCenter, and ChartCenter has ended – as newer and better options have emerged. We’re proud of the benefits they provided, as they helped spur software innovation and bolstered the work of brilliant developers. But you know what they say. Don’t overstay your welcome. Know when it’s time to bow out. Make a graceful exit. The Go team has built a module repository for Go developers called Pkg.go.dev. 所以, 之前的 GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" 要改成默认的: GOPROXY=\"https://proxy.golang.org,direct\" 如果没有你的package, 要自己添加以下: https://go.dev/about#adding-a-package Data for the site is downloaded from proxy.golang.org. We monitor the Go Module Index regularly for new packages to add to pkg.go.dev. If you don’t see a package on pkg.go.dev, you can add it by doing one of the following: Visiting that page on pkg.go.dev, and clicking the “Request” button. For example: https://pkg.go.dev/example.com/my/module Making a request to proxy.golang.org for the module version, to any endpoint specified by the Module proxy protocol. For example: https://proxy.golang.org/example.com/my/module/@v/v1.0.0.info Downloading the package via the go command. For example: GOPROXY=https://proxy.golang.org GO111MODULE=on go get example.com/my/module@v1.0.0 go center使用心得 使用export GOPROXY=https://gocenter.io时, 默认是不包括你的github项目的. 需要在主页https://search.gocenter.io/ 点添加module按钮来手动添加 似乎gocenter不会主动持续的对你的库更新版本, 比如通过gocenter来go get时, latest版本不会更新 直接go get github.com/godevsig/gshellos不会拿到最新版本 对于Pseudo-Versions来说, 需要用户指定版本号, 比如 go get github.com/godevsig/gshellos@6d66a9c 这样才会触发gocenter进行一次缓存 tag规范:https://jfrog.com/blog/go-big-with-pseudo-versions-and-gocenter/ 如果不是proxy管理的, 是可以直接更新的: $ go get gitlab.com/godevsig/system go: finding gitlab.com/godevsig/system latest go: downloading gitlab.com/godevsig/system v0.0.0-20210115023458-e89ec0eae327 go: extracting gitlab.com/godevsig/system v0.0.0-20210115023458-e89ec0eae327 gitlab ci clone私有库 参考网上的经验, 在.gitlab-ci.yml中加入before_script, 这样在每个script执行之前, 都会跑这个git配置, 意思是用git的url替换功能, \"加工\"url地址. default: image: name: godevsig-docker-local.artifactory.com/godevsig/devtool:godevsig-ee82473 entrypoint: [\"\"] before_script: - git config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com\".insteadOf \"https://gitlab.com\" 因为go默认使用https方式get代码, 这里被替换的url字符串为https://gitlab.com, 将其前面加上https://gitlab-ci-token:${CI_JOB_TOKEN} 使用gitlab内置的CI_JOB_TOKEN变量, 可以绕过私有库不能clone的限制, 把私有库clone下来. go mode 使用私有repo 比如https://gitlab.com/godev/system.git不是public, 不能直接clone go build等命令没法获取到这个库. 我用replace关键词暂时解决了本地编译的问题 replace ( github.com/d5/tengo/v2 => /repo/yingjieb/godevsig/tengo gitlab.com/godevsig/system => /repo/yingjieb/godevsig/system ) require ( github.com/d5/tengo/v2 v2.6.2 github.com/peterh/liner v1.2.1 gitlab.com/godevsig/system v0.0.0-00010101000000-000000000000 ) 但这里的system版本号似乎很怪异:v0.0.0-00010101000000-00000000000 这个大概是个特殊的版本号, 因为go 命令其实没有办法获取到 因为go命令默认使用https去clone. 对于私有仓库来说, 对外不可见, 当然不能用https去get. 使用ssh方式clone 用git config命令, 把https方式clone改成git方式, 这样如果你本地有ssh权限clone这个私有库, go命令也能成功, 因为go命令底层也是调用git命令clone的. $ git config --global url.\"git@mygitlab.com:\".insteadOf \"http://mygitlab.com/\" // 其实就是在 .gitconfig 增加了配置 $ cat ~/.gitconfig [url \"git@mygitlab.com:\"] insteadOf = http://mygitlab.com/ //注意： git@mygitlab.com: 后面有个冒号 :, 且 http://mygitlab.com 后面有 / 我的成功例子: git config --global url.\"git@gitlab.com:godevsig\".insteadOf \"https://gitlab.com/godevsig\" 会在~/.gitconfig中增加: [url \"git@gitlab.com:godevsig\"] insteadOf = https://gitlab.com/godevsig GOPROXY问题和解决 设置git的ssh方式替换https方式后, 把go.mod里面的特殊行删除: gitlab.com/godevsig/system v0.0.0-00010101000000-000000000000 然后使用go get命令更新go.mod 发现go命令能正确发现这个私有库的版本号v0.0.0-20201225044511-46ec8cf4b75c, 但下载失败, 看起来和GOPROXY的设置有关 yingjieb@73e57632f306 /repo/yingjieb/godevsig/gshell $ go get go: finding gitlab.com/godevsig/system/pidinfo latest go: finding gitlab.com/godevsig/system latest go: downloading gitlab.com/godevsig/system v0.0.0-20201225044511-46ec8cf4b75c build gitlab.com/godevsig/gshell: cannot load gitlab.com/godevsig/system/pidinfo: gitlab.com/godevsig/system@v0.0.0-20201225044511-46ec8cf4b75c: reading https://artifactory.com/artifactory/api/go/godevsig-go-virtual/gitlab.com/godevsig/system/@v/v0.0.0-20201225044511-46ec8cf4b75c.zip: 500 Internal Server Error 修改私有库不经过GOPROXY是可以的: GONOPROXY=\"*.net.com\" go get go clean 下面的命令会把所有的cache都清除, 导致go get下次会全新下载 go clean -cache -modcache -i -r 不加参数的go clean好像都不删除cache的. go mod 使用replace指定私有repo 在gshell中, 引用了库github.com/abs-lang/abs, 但我想修改这个package, 但依旧保留import \"github.com/abs-lang/abs\" 怎么做? -- go.mod中使用replace关键词 $ cat go.mod module gitlab.com/godev/gshell go 1.13 replace github.com/abs-lang/abs => /repo/yingjieb/godev/abs require ( github.com/abs-lang/abs v0.0.0-20190921150801-05c699c0415e github.com/peterh/liner v1.2.1 } 上面replace的意思是用本地路径替换目标package, 但源代码不用修改. 如果希望用私有repo, replace要求私有repo要有版本号. artifactory和goproxy的问题汇总 godevsig-gocenter-remote获取不到新版本 现象: $ GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/godevsig-gocenter-remote,direct\" GO111MODULE=on go get -v golang.org/x/tools/gopls go: golang.org/x/tools/gopls upgrade => v0.5.1 问题: 应该获取到新版本v0.5.3 解决: 使用virtual repo, 而且必须加api/go前缀就能下载最新的tag GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" GO111MODULE=on go get -v golang.org/x/tools/gopls go: golang.org/x/tools/gopls upgrade => v0.5.3 注: 对godevsig-gocenter-remote加api/go是不行的. 原因: 不是virtual的repo, 好像只能当cache用. gitlab默认不支持goproxy 现象: godevsig-go-virtual包括godevsig-gocenter-remote和godevsig-gogitlab-remote后者proxy https://gitlab.com 但get gitlab.com/godevsig/compatible失败 GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" GO111MODULE=on go get -v gitlab.com/godevsig/compatible go get gitlab.com/godevsig/compatible: no matching versions for query \"upgrade\" 而不加proxy能成功. GO111MODULE=on go get -v gitlab.com/godevsig/compatible get \"gitlab.com/godevsig/compatible\": found meta tag get.metaImport{Prefix:\"gitlab.com/godevsig/compatible\", VCS:\"git\", RepoRoot:\"https://gitlab.com/godevsig/compatible.git\"} at //gitlab.com/godevsig/compatible?go-get=1 go: downloading gitlab.com/godevsig/compatible v0.1.0 go: gitlab.com/godevsig/compatible upgrade => v0.1.0 原因: https://docs.gitlab.com/ee/user/packages/go_proxy/ 需要管理员手动打开, 在gitlab rails控制台 可以全部打开 Feature.enable(:go_proxy) 可以按project打开 Feature.enable(:go_proxy, Project.find(1)) Feature.disable(:go_proxy, Project.find(2)) 进展: gitlab 13.3才有这个功能 临时方案: 从virtual中去掉gitlab的汇聚. 待gitlab go proxy使能后再加 临时只virtual gocenter的. GONOSUMDB=\"gitlab.com/*\" GOPROXY=\"https://artifactory.com/artifactory/api/go/godevsig-go-virtual,direct\" GO111MODULE=on go get -v gitlab.com/godevsig/compatible get \"gitlab.com/godevsig/compatible\": found meta tag get.metaImport{Prefix:\"gitlab.com/godevsig/compatible\", VCS:\"git\", RepoRoot:\"https://gitlab.com/godevsig/compatible.git\"} at //gitlab.com/godevsig/compatible?go-get=1 go: gitlab.com/godevsig/compatible upgrade => v0.1.0 添加写申请: https://nsnsi.service-now.com/ess?id=create_ticket&sys_id=cdb84691db3d8f80012570600f96196a&returnPage=request_services&returnPage2=browse_it_services artifactory的repository概念 https://www.jfrog.com/confluence/display/JFROG/Repository+Management repository包括: Local Remote Virtual Distribution Release Bundle Repository Bintray Distribution Repository 一个repository只对应一个类型 特别的, virtual的repository只能汇聚同一类型的实体repository. 虽然没有强制要求不能上传不同类型的artifact, 但不推荐这样. generic类型 generic类型的repository能放任何东西, 没有特殊的包管理. local repository 访问路径: http://:/artifactory// remote repository 实际上是个proxy和cache 访问格式 http://:/artifactory// 如果确定artifact已经被cache了, 可以直接访问: http://:/artifactory/-cache/ Virtual Repositories 虚拟的repository是汇聚同类repository用的. 搜索的顺序是先local的, 再remote的. 同类的需要看list顺序, 可以改的. GOPROXY和artifactory JFrog Artifactory推出了https://gocenter.io 使用只需要 export GOPROXY=https://gocenter.io 这个代理完全能取代go1.13开始的默认GOPROXY设置. 注意: GOPROXY只在go mod模式下才有用. 使能go mod模式, 要么目录下有go.mod文件, 要么需要强制指定GO111MODULE=on 使用GoCenter比直接从github上下载更快, GoCenter网页也能显示更详细的信息. 私有repo 使用公共repo时, GOSUMDB要去默认的公共校验中心sum.golang.org校验文件安全性. 而私有库显然没有入这个\"sum DB\", 拉取私有库会报错. 通常使用GOPRIVATE环境变量传入需要bypass sum db的私有库 GoCenter提供了同时使用公共gocenter.io和私有库的方法: export GOPROXY=https://gocenter.io,direct export GOPRIVATE=*.internal.mycompany.com 这样能解决问题, 但没法防止私有库的owner去改tag, 改了tag, 就不能重复构建同样的版本了. 私有GOPROXY 私有GOPROXY能解决上面的问题. 私有GOPROXY能同时cache公共GOPROXY和内部私有repo In Artifactory, a combination of a remote repository for GoCenter, a remote Go module repository that points to private GitHub repos (for private modules) and a local Go module repository can be combined into a single virtual repository, to access as a single unit. 使用私有GOPROXY, GONOSUMDB来完成任务: $ export GOPROXY=\"https://:@my.artifactory.server/artifactory/api/go/go\" $ export GONOSUMDB=\"github.com/mycompany/*,github.com/mypersonal/*\" setup私有GOPROXY 官方参考 这里看起来我需要: go remote repo: proxy gocenter go remote repo: proxy gitlab go vitual repo general local repo: 参考: artifactory的go registry说明 经验文档1 经验文档2 go list package模式 go list 用于显示当前目录下的package的import path yingjieb@f8530ea27843 /repo/yingjieb/3rdparty/delve/pkg/proc $ go list github.com/go-delve/delve/pkg/proc -f选项其实是个模板, 可以显示go tool内部的管理数据, 比如查看package的import了谁, 以及依赖谁(即所有递归的import) % go list -f '{{ .Imports }}' github.com/davecheney/profile [io/ioutil log os os/signal path/filepath runtime runtime/pprof] % go list -f '{{ .Deps }}' github.com/davecheney/profile [bufio bytes errors fmt io io/ioutil log math os os/signal path/filepath reflect runtime runtime/pprof sort strconv strings sync sync/atomic syscall text/tabwriter time unicode unicode/utf8 unsafe] -deps 选项可以递归的list依赖. 也就是说默认不打印依赖. 列出当前目录下的package, 其中...是go tool通用的通配符, 匹配所有. 注意, 不要用go list ..., 意思是列出所有目录下的package yingjieb@f8530ea27843 /repo/yingjieb/3rdparty/delve/pkg/proc $ go list ./... github.com/go-delve/delve/pkg/proc github.com/go-delve/delve/pkg/proc/core github.com/go-delve/delve/pkg/proc/core/minidump github.com/go-delve/delve/pkg/proc/fbsdutil github.com/go-delve/delve/pkg/proc/gdbserial github.com/go-delve/delve/pkg/proc/linutil github.com/go-delve/delve/pkg/proc/native github.com/go-delve/delve/pkg/proc/test github.com/go-delve/delve/pkg/proc/winutil module模式 module对应的是package的自然集合, 通常是一个repo. go list -m all 用于列出所有的import的包(main包和main的依赖包) The arguments to list -m are interpreted as a list of modules, not packages. The main module is the module containing the current directory. The active modules are the main module and its dependencies. With no arguments, list -m shows the main module. With arguments, list -m shows the modules specified by the arguments. Any of the active modules can be specified by its module path. The special pattern \"all\" specifies all the active modules, first the main module and then dependencies sorted by module path. A pattern containing \"...\" specifies the active modules whose module paths match the pattern. 国内可用的proxy https://goproxy.cn/ $ export GO111MODULE=on $ export GOPROXY=https://goproxy.cn go mod模式和普通模式的go get区别 普通模式下 GOPROXY不起作用, go get直接从目标地址下载 go get -v github.com/naoina/go-stringutil # 下载后的代码以src形式保存在GOPATH下的 ./src/github.com/naoina/go-stringutil go mod模式下 # 使用godevsig的proxy GOPROXY=\"https://artifactory.com:443/artifactory/godevsig-go-virtual\" GO111MODULE=on go get -v github.com/naoina/go-stringutil # 下载后的代码以pkg cache的形式保存在GOPATH下的 ./pkg/mod/cache/download/github.com/naoina/go-stringutil 注: GOPROXY生效后, 在 https://artifactory.com/artifactory/webapp/#/artifacts/browse/tree/General/godevsig-gocenter-remote-cache 下, 能找到已经cache的package go mode模式下的help 连help输出也不一样 GO111MODULE=on go help get 第一步解析依赖, 对每个package pattern, 依次做版本检查: 先检查最新的tag, 比如v1.2.3 没有release的tag, 就用pre tag, 比如v0.0.1-pre1 没有tag, 就用最新的commit 可以用@version下载指定版本, @v1会下载v1的最新版本; @commitid也行 对于间接依赖, go get会follow go.mod的指示 go get后面是空的情况下, get当前目录下的依赖 第二步时下载, build, install; 在package下面没有东西可以build的时候, build和install有可能被忽略 可以用...的pattern go mod使用记录 比如库gitlab.com/godevsig/compatible go.mod 使用go mod init gitlab.com/godevsig/compatible 得到如下go.mod: 声明了本库的module名. 官方说法是, 这个名字必须和库地址一致.见cmd/go: Why not separate the module name and the download URL? module gitlab.com/godevsig/compatible go 1.13 本地import和外部repo import 这里的本地引用是说通一个repo下, 不同package之间的引用. 本地引用和外部引用没有任何区别: 在log同一级的目录msg下: main.go package main import \"gitlab.com/godevsig/compatible/log\" func main() { lg := log.DefaultStream.NewLogger(\"msgdriven\") lg.Infolnn(\"hello msg\") } 但本地引用情况下, 本地修改能够立即生效. 比如我在log包里加了一个API, 本地修改不入库, lg.Infolnn(), 本地其他包能够立刻引用新的API. 外部引用的情况下, 只认已经入库的内容. 因为lg.Infolnn()的修改还没有入库, 外部的repo是不知道的. 错误如下: $ go build # main ./hello.go:42:4: lg.Infolnn undefined (type *log.Logger has no field or method Infolnn) sum DB审查 默认配置下, go get/build发现go.mod文件后, 开启go mod模式, 自动拉取依赖的库. 但出现410 Gone错误 $ go build go: finding gitlab.com/godevsig/compatible latest go: finding gitlab.com/godevsig/compatible/log latest go: downloading gitlab.com/godevsig/compatible v0.0.0-20200811070332-66acc8ba0617 verifying gitlab.com/godevsig/compatible@v0.0.0-20200811070332-66acc8ba0617: gitlab.com/godevsig/compatible@v0.0.0-20200811070332-66acc8ba0617: reading htt ps://sum.golang.org/lookup/gitlab.com/godevsig/compatible@v0.0.0-20200811070332-66acc8ba0617: 410 Gone 看过程是它能取到版本, 但verifying checksum出错了. 因为go mod要去sum.golang.org获取校验, 但我们引用的module是私有库, 肯定在golang.org里面没有. 解决: 配置环境变量 GOSUMDB=off 参考: Golang-执行go get私有库提示”410 Gone“ 解决办法 或者使用 GONOSUMDB=\"*.net.com/*\" go mod机制 go help modules go help go.mod go help mod go modules是go的官方包管理机制, 用于替代老的GOPATH环境变量来指定版本依赖的方式. go tools1.13支持go modules. 环境变量GO111MODULE=auto的默认方式下, 如果目录下有go.mod文件, 则使能go modules模式; 否则还是用老的GOPATH模式 GOPATH在go modules模式下, 只用于存放下载的源码: GOPATH/pkg/mod, 和按照后的二进制: GOPATH/bin GO111MODULE=on 强制使用go modules模式 定义go module 一个go module是一个目录, 该目录下有go.mod文件, 该目录也称为module root. 比如下面的go.mod声明了一个module, 它的import path是example.com/m; 它还依赖指定版本的golang.org/x/text和gopkg.in/yaml.v2 module example.com/m require ( golang.org/x/text v0.3.0 gopkg.in/yaml.v2 v2.1.0 ) 创建一个go module 在工程目录下, 执行go mod init example.com/m会创建go.mod go.mod文件创建后, go命令比如go build, go get会自动更新go.mod. go命令会在当前目录找go.mod, 没有再到父目录及其再往上的父目录寻找go.mod 在哪里执行go命令, 那个目录就是main module. 只有main module的go.mod文件的有replace和exclude关键词才有效; 不是main module, 这些关键词被忽略. build list是构建main module的依赖列表 A Go module is a collection of related Go packages that are versioned together as a single unit. go list命令用于查看main module的build list go list -m # print path of main module go list -m -f={{.Dir}} # print root directory of main module go list -m all # print build list go.mod文件维护 go.mod被设计为人和go命令都可读可修改. go命令比如go build, 如果发现源码里面有新增的import example/m关键词, 就会自动添加example/m的最新version到go.mod go mod tidy命令可以整理go.mod文件, 删除不再需要的module. // indirect指示间接依赖 go get命令会更新go.mod的版本. 比如升级一个module, 那其他依赖这个module的modules也会被自动更新到相应版本. 版本格式 版本号的核心思想是版本号是可以比较新旧的. 对没有版本管理的repo, 假的版本号格式是:v0.0.0-yyyymmddhhmmss-abcdefabcdef 其中时间是commit时间, 后面是commit hash. go的命令支持module版本指定: v1.2.3指定了一个具体的版本 v1会被扩展成最新的v1版本 和>=v1.5.6 latest被扩展成最新的tagged版本, 或者, 对于没有版本管理的库, 使用最新的commit upgrade: 和latest差不多 patch: 和latest差不多 其他: commit hash, tag名, 分支名, 会选择源码的指定版本.go get github.com/gorilla/mux@latest # same (@latest is default for 'go get') go get github.com/gorilla/mux@v1.6.2 # records v1.6.2 go get github.com/gorilla/mux@e3702bed2 # records v1.6.2 go get github.com/gorilla/mux@c856192 # records v0.0.0-20180517173623-c85619274f5d go get github.com/gorilla/mux@master # records current meaning of master 兼容性公约 如果一个package的新老版本的import路径一致, 那么新版本必须兼容老版本. 对不兼容的版本, 解决方案是import路径加v2, 比如: go.mod里显式写明: module example.com/m/v2 在引用时也写明引用v2里面的一个package import example.com/m/v2/sub/pkg 比如urfave/cli的v1和v2版本: Using v2 releases $ GO111MODULE=on go get github.com/urfave/cli/v2 ... import ( \"github.com/urfave/cli/v2\" // imports as package \"cli\" ) ... Using v1 releases $ GO111MODULE=on go get github.com/urfave/cli ... import ( \"github.com/urfave/cli\" ) ... "},"notes/golang_汇编_arm64.html":{"url":"notes/golang_汇编_arm64.html","title":"汇编语法和arm64小知识","keywords":"","body":"golang汇编语法参考: https://go.dev/doc/asm pseudo寄存器 函数 arm64汇编 Register mapping rules ARM64异常处理过程 ARM64上下文切换 什么是VHE pseudo寄存器 SB: Static base pointer 全局基地址. 比如foo(SB)就是foo这个symbol的地址 FP: 帧指针. 用来传参的, 比如 first_arg+0(FP): 第一个参数 second_arg+8(FP): 第二个参数(64bit CPU) SP: 栈指针. 指向栈顶. 用于局部变量. CPU都有物理SP, 语法上看前缀来区分: x-8(SP), y-4(SP): 使用pseudo SP -8(SP)使用物理SP PC: 程序指针 函数 格式: TEXT symbol(SB), [flags,] $framesize[-argsize] symbol: 函数名 SB: SB伪寄存器 flags: 可以是 NOSPLIT: 不让编译器插入栈分裂的代码 WRAPPER: 不增加函数帧计数 NEEDCTXT: 需要上下文参数, 一般用于闭包 framesize: 局部变量大小, 包含要传给子函数的参数部分 argsize: 参数+返回值的大小, 可以省略由编译器自己推导 比如 //go:nosplit func swap(a, b int) (int, int) 可以写为: TEXT ·swap(SB), NOSPLIT, $0-32 或者 TEXT ·swap(SB), NOSPLIT, $0 这里-32是4个8字节的int, 即入参a, b和两个出参.注意go并不区分入参和出参 func swap(a, b int) (int, int) 或 func swap(a, b, c, d int) 或 func swap() (a, b, c, d int) 或 func swap() (a, []int, d int) 汇编都一样 arm64汇编 https://pkg.go.dev/cmd/internal/obj/arm64#pkg-overview Register mapping rules All basic register names are written as Rn. Go uses ZR as the zero register and RSP as the stack pointer. Bn, Hn, Dn, Sn and Qn instructions are written as Fn in floating-point instructions and as Vn in SIMD instructions. ARM64异常处理过程 When an event which causes an exception occurs, the processor hardware automatically performs certain actions. The SPSR_ELn is updated, (where n is the Exception level where the exception is taken), to store the PSTATE information required to correctly return at the end of the exception. PSTATE is updated to reflect the new processor status (and this may mean that the Exception level is raised, or it may stay the same). The return address to be used at the end of the exception is stored in ELR_ELn. 异常发生的时候, CPU会自动的实施如下动作: 将PSTATE保存到SPSR_ELn比如异常发生在EL0, 一般会在EL1处理. 那PSTATE会保存在SPSR_EL1 更新PSTATE以反映新的CPU状态, 比如已经进入EL1 硬件会将返回地址保存在ELR_Eln.还是比如异常发生在EL0, 但在EL1处理, 那返回地址保存在ELR_EL1 The processor has to be told when to return from an exception by software. This is done by executing the ERET instruction. This restores the pre-exception PSTATE from SPSR_ELn and returns program execution back to the original location by restoring the PC from ELR_ELn. eret指令用来从异常处理返回: 从SPSR_ELn恢复异常前的PSTATE 从ELR_ELn恢复PC 异常返回, 从恢复的PC和PSTATE继续执行 ELR_ELn contains the return address which is preferred for the specific exception type. For some exceptions, this is the address of the next instruction after the one which generated the exception. For example, when an SVC (system call) instruction is executed, we simply wish to return to the following instruction in the application. In other cases, we may wish to re-execute the instruction that generated the exception. 在发生异常时, 硬件会自动更新ELR, 根据情况, 返回地址有几种可能: 比如SVC指令触发的同步异常, ELR里保存的是其下一条指令 比如异步异常(即外部中断), ELR里保存的是下一个没被执行(或完全执行)的指令 ELR可以在异常处理程序里面被更改. In addition to the SPSR and ELR registers, each Exception level has its own dedicated Stack Pointer register. These are named SP_EL0, SP_EL1, SP_EL2 and SP_EL3. These registers are used to point to a dedicated stack that can, for example, be used to store registers which are corrupted by the exception handler, so that they can be restored to their original value before returning to the original code. Handler code may switch from using SP_ELn to SP_EL0. For example, it may be that SP_EL1 points to a piece of memory which holds a small stack that the kernel can guarantee to always be valid. SP_EL0 might point to a kernel task stack which is larger, but not guaranteed to be safe from overflow. This switching is controlled by writing to the [SPSel] bit, as shown in the following code: MSR SPSel, #0 // switch to SP_EL0 MSR SPSel, #1 // switch to SP_ELn 每个EL都有独立的SP, 并且异常处理程序可以切换使用SP_EL0和SP_ELn. ARM64上下文切换 Processors that implement the ARMv8-A Architecture are typically used in systems running a complex operating system with many applications or tasks that run concurrently. Each process has its own unique translation tables residing in physical memory. When an application starts, the operating system allocates it a set of translation table entries that map both the code and data used by the application to physical memory. These tables can subsequently be modified by the kernel, for example, to map in extra space, and are removed when the application is no longer running. There might therefore be multiple tasks present in the memory system. The kernel scheduler periodically transfers execution from one task to another. This is called a context switch and requires the kernel to save all execution state associated with the process and to restore the state of the process to be run next. The kernel also switches translation table entries to those of the next process to be run. The memory of the tasks that are not currently running is completely protected from the task that is running. 每个进程都有自己的translation table, 这个table是kernel分配的, 把其物理地址配置到ttbr0寄存器. 上下文切换的时候, kernel会保存/恢复如下上下文: general-purpose registers X0-X30. Advanced SIMD and Floating-point registers V0 - V31. Some status registers. TTBR0_EL1 and TTBR0. Thread Process ID (TPIDxxx) Registers. Address Space ID (ASID). For EL0 and EL1, there are two translation tables. TTBR0_EL1 provides translations for the bottom of Virtual Address space, which is typically application space and TTBR1_EL1 covers the top of Virtual Address space, typically kernel space. This split means that the OS mappings do not have to be replicated in the translation tables of each task. EL0和EL1有两个translation table, TTBR0_EL1负责bottom空间(用户空间), TTBR1_EL1负责top空间(kernel空间). 大家都用TTBR1_EL1做kernel空间, 所以进程切换的时候, TTBR1_EL1不用变, 所以kernel的映射不用变. Translation table entries contain a non-global (nG) bit. If the nG bit is set for a particular page, it is associated with a specific task or application. If the bit is marked as 0, then the entry is global and applies to all tasks. 页表entry里有个nG位, 用来表示non-global, 为0的时候, 这个页表entry就是全局的, 对所有task都有效. For non-global entries, when the TLB is updated and the entry is marked as non-global, a value is stored in the TLB entry in addition to the normal translation information. This value is called the Address Space ID (ASID), which is a number assigned by the OS to each individual task. Subsequent TLB look-ups only match on that entry if the current ASID matches with the ASID that is stored in the entry. This permits multiple valid TLB entries to be present for a particular page marked as non-global, but with different ASID values. In other words, we do not necessarily need to flush the TLBs when we context switch. ASID(Address Space ID)寄存器用来标记页表entry所属的task, 由kernel分配. 当TLB更新的时候, TLB entry除了保存地址翻译信息, 还会包括这个ASID. TLB查询的时候, 只有当前的ASID和TLB entry保存的ASID匹配的时候, 才算TLB命中. 所以上下文切换的时候不需要flush TLB. In AArch64, this ASID value can be specified as either an 8-bit or 16-bit value, controlled by the TCR_EL1.AS bit. The current ASID value is specified in either TTBR0_EL1 or TTBR1_EL1. TCR_EL1 controls which TTBR holds the ASID, but it is normally TTBR0_EL1, as this corresponds to application space. ASID可以8位或16位. 一般配置在TTBR0_EL1中. Having the current value of the ASID stored in the translation table register means that you can atomically modify both the translation tables as well as the ASID in a single instruction. This simplifies the process of changing the table and ASID when compared with the ARMv7-A Architecture. 把ASID值放在TTBR0_EL1里的好处是, 一个指令就可以原子的更改ASID和页表. Additionally, the ARMv8-A Architecture provides Thread ID registers for use by operating system software. These have no hardware significance and are typically used by threading libraries as a base pointer to per-thread data. This is often referred to as Thread Local Storage (TLS). For example, the pthreads library uses this feature and includes the following registers: User Read and Write Thread ID Register (TPIDR_EL0). User Read-Only Thread ID Register (TPIDRRO_EL0). Thread ID Register, privileged accesses only (TPIDR_EL1). TPIDR(Thread ID registers)是给系统软件保存Thread Local Storage (TLS)用的. EL0可以用TPIDR_EL0 EL1还有TPIDR_EL1 什么是VHE Note: The DynamIQ processors (Cortex-A55, Cortex-A75 and Cortex-A76) support Virtualization Host Extensions (VHEs). 通常kernel运行在EL1, 一个同样的kernel, 如果运行在VHE使能了, 硬件会重定向寄存器访问: We saw in the section on Virtualizing generic timers that enabling VHE changes the layout of the EL2 virtual address space. However, we still have a problem with the configuration of the MMU. This is because our kernel will try to access _EL1 registers, such as TTBR0_EL1, rather than _EL2 registers such as TTBR0_EL2. To run the same binary at EL2, we need to redirect the accesses from the EL1 registers to the EL2 equivalents. Setting E2H will do this, so that accesses to _EL1 system registers are redirected to their EL2 equivalents. This redirection illustrated in the following diagram: "},"notes/golang_cgo_swig.html":{"url":"notes/golang_cgo_swig.html","title":"go调用c可以用swig","keywords":"","body":"首先, swig是 - Simplified Wrapper and Interface Generator The swig command is used to create wrapper code to connect C and C++ code to scripting languages like Perl, Python, Tcl etc swig for go中说到, cgo生成的wrapper能调用c, 但不能直接调用c++. 而且, gcgo和gccgo在调用c的接口时, 是完全不一样的. swig同时支持这两种toolchain, 并且保证类型安全. 从go1.1开始就支持swig了, 并且集成在go build命令中. 使用go build -x -work能看到详细使用swig的过程. 2010年的问答: Can I use shared objects with Go? According to the Go FAQ, you can call into C libraries using a \"foreign function interface\": Do Go programs link with C/C++ programs? There are two Go compiler implementations, 6g and friends, generically called gc, and gccgo. Gc uses a different calling convention and linker and can therefore only be linked with C programs using the same convention. There is such a C compiler but no C++ compiler. Gccgo is a GCC front-end that can, with care, be linked with GCC-compiled C or C++ programs. However, because Go is garbage-collected it will be unwise to do so, at least naively. There is a “foreign function interface” to allow safe calling of C-written libraries from Go code. We expect to use SWIG to extend this capability to C++ libraries. There is no safe way to call Go code from C or C++ yet. 根据说法, gccgo是可以不用cgo的接口, 直接调用c的. 但必须要十分清楚调用convention, 栈大小的限制等细节: You can also use cgo and SWIG with Gccgo and gollvm. Since they use a traditional API, it's also possible, with great care, to link code from these compilers directly with GCC/LLVM-compiled C or C++ programs. However, doing so safely requires an understanding of the calling conventions for all languages concerned, as well as concern for stack limits when calling C or C++ from Go. 见gccgo安装使用文档 "},"notes/golang_toolchain_ppc.html":{"url":"notes/golang_toolchain_ppc.html","title":"go tools增加ppc32支持.md","keywords":"","body":" gccgo工具链不编译c文件 过程 gcc的gccgo官方文档 编译gc go并上传下载 gccgo toolchain准备, 操作命令版本 build toolchain upload the toolchain to artifactory 命令cache go源码编译 原版go源码编译go tools 修改版源码编译 不改变go tools的尝试 使用gccgo 传入GOARCH=ppc64 传入GOARCH=amd64 总结: 尝试成功, 使用ppc32 gccgo的方法 修改go源码, 支持GOARCH=ppc32 编译gccgo crosstool-ng编译gccgo 使用crosstool-ng的gccgo 修改go源码支持ppc32 power ISA背景知识 Power ISA v.2.06 Power ISA v.2.07 Power ISA v.3.0 default ARCH选项 默认编译器参数 要修改的文件 ppc64无法在e6500上运行 这些缺失的符号应该在哪里? 为什么generic-morestack.c没有编译到? crosstool-ng的bug 关于split stack 上面提到的gold linker是什么意思? 相关链接 上传gccgo工具链到artifactory gccgo的hello size过大问题 相关命令 减小libgo.a的体积 使能lto 改动提交到crosstool-ng go_export小节 static和static-libgo 让gcgo支持ppc32 下一步 补充: fant-f运行topid 补充: ppc64 补充: 为什么gc go工具链的支持ppc64, 但不能在e6500上运行? 补充: elf格式 gccgo工具链不编译c文件 参考: https://github.com/golang/go/issues/41758结论: 没有打开CGO_ENABLED=1的情况下, 不会自动编译c文件. CGO_ENABLED=1就好了. 过程 使用gccgo编译MF14Temp时，由于import了fsnotify这个包，而这个包会使用golang.org/x/sys/这个包 这个包里unix/gccgo.go这个go文件里需要调用gccgoRealSyscall和gccgoRealSyscallNoError这两个函数，而这两个函数的实现在unix/gccgo_c.c这个c文件中。 产生下述链接错误的原因是gccgo_c.c这个c文件没有被gccgo编译，因此需要在编译MF14Temp时，加上“CGO_ENABLED=1”这个选项，使能CGO，让GO能够调用C GOARCH=ppc64 go build -o MF14Temp_ppc64 # gitlabe1.ext.net.nokia.com/godevsig/MF14Temp /opt/crosstool/powerpc64-e6500-linux-gnu/bin/../lib/gcc/powerpc64-e6500-linux-gnu/10.2.0/../../../../powerpc64-e6500-linux-gnu/bin/ld: /home/xming/.cache/go-build/16/16ae8d3fbaffd001bb92ecdbfd968c9b2f078bb1bfd38396335cd0a145ce241c-d(_go_.o): in function `golang.x2eorg..z2fx..z2fsys..z2funix.SyscallNoError': /repo/xming/go/pkg/mod/golang.org/x/sys@v0.0.0-20191005200804-aed5e4c7ecf9/unix/gccgo.go:23: undefined reference to `gccgoRealSyscallNoError' /opt/crosstool/powerpc64-e6500-linux-gnu/bin/../lib/gcc/powerpc64-e6500-linux-gnu/10.2.0/../../../../powerpc64-e6500-linux-gnu/bin/ld: /home/xming/.cache/go-build/16/16ae8d3fbaffd001bb92ecdbfd968c9b2f078bb1bfd38396335cd0a145ce241c-d(_go_.o): in function `golang.x2eorg..z2fx..z2fsys..z2funix.Syscall': /repo/xming/go/pkg/mod/golang.org/x/sys@v0.0.0-20191005200804-aed5e4c7ecf9/unix/gccgo.go:30: undefined reference to `gccgoRealSyscall' gcc的gccgo官方文档 https://gcc.gnu.org/onlinedocs/gcc-10.2.0/gccgo/ 编译gc go并上传下载 到https://artifactory-blr1.int.net.nokia.com/artifactory/godevsig-generic-local/toolchain/gccgo/ 查最新的文件夹 找到commit号, 比如 059da3dd98ab7be871a0556dd53fa4057f7dcf09 下载: #编译 cd golang-go git checkout release-branch.go1.16 cd src GOOS=linux GOARCH=amd64 ./bootstrap.bash #上传 curl -H \"X-JFrog-Art-Api:AKCp8hyinctVijrdqGaFc1YAT7e7KDHWJEaackjuv6oCheipkYU9jU5okRj8rnFkVvcZWnTVc\" -X PUT \"https://artifactory-blr1.int.net.nokia.com:443/artifactory/godevsig-generic-local/toolchain/gcgo/`git rev-parse HEAD`/\" -T ../../go-linux-amd64-bootstrap.tbz #下载 curl https://artifactory-blr1.int.net.nokia.com/artifactory/godevsig-generic-local/toolchain/gcgo/1cabb66796f4529afc615dd466b5667fe1509f6c/go-linux-amd64-bootstrap.tbz -O gccgo toolchain准备, 操作命令版本 Steps to prepare gccgo toolchain build toolchain checkout godev branch cd crosstool-ng git checkout godev make crosstool-ng ```sh install dependencies apt install flex help2man texinfo libtool-bin libncurses-dev gawk bison rsync build ./bootstrap ./configure --enable-local make * build gccgo toolchain e.g. to build ppc64 gccgo ```sh ./ct-ng defconfig DEFCONFIG=samples/Nokia/isam-reborn_godev-ppc64-e6500 ./ct-ng build find the toolchain in targets after successfully buildcd targets ls # powerpc64-e6500-linux-gnu upload the toolchain to artifactory compress the toolchain foldertar cJf godev-gccgo-ppc64.tar.xz powerpc64-e6500-linux-gnu upload to artifactorycurl -H \"X-JFrog-Art-Api:AKCp8hyinctVijrdqGaFc1YAT7e7KDHWJEaackjuv6oCheipkYU9jU5okRj8rnFkVvcZWnTVc\" -X PUT \"https://artifactory-blr1.int.net.nokia.com:443/artifactory/godevsig-generic-local/toolchain/gccgo/`git rev-parse HEAD`/\" -T godev-gccgo-ppc64.tar.xz 同时上传ppc和ppc64 proxyoff cd crosstool-ng/targets tar cJf godev-gccgo-ppc.tar.xz powerpc-e500mc-linux-gnu tar cJf godev-gccgo-ppc64.tar.xz powerpc64-e6500-linux-gnu curl -H \"X-JFrog-Art-Api:AKCp8hyinctVijrdqGaFc1YAT7e7KDHWJEaackjuv6oCheipkYU9jU5okRj8rnFkVvcZWnTVc\" -X PUT \"https://artifactory-blr1.int.net.nokia.com:443/artifactory/godevsig-generic-local/toolchain/gccgo/`git rev-parse HEAD`/\" -T \"{godev-gccgo-ppc.tar.xz,godev-gccgo-ppc64.tar.xz}\" 命令cache # hello yingjieb@9102a93a554e /repo/yingjieb/godev/practice/src/examples $ rm -f hello; rm -rf /home/yingjieb/.cache/go-build/; rm -f gccgo.log; PATH=$PATH:/repo/yingjieb/crosstoolng/github/crosstool-ng/targets/powerpc-e500mc-linux-gnu/bin GOARCH=ppc64 /repo/yingjieb/godev/golang-go/bin/go build -compiler gccgo -gccgoflags '-static -Os' hello.go /repo/yingjieb/crosstoolng/github/crosstool-ng/targets/powerpc-e500mc-linux-gnu/bin/powerpc-linux-strip hello scp yingjieb@10.182.105.138:/repo/yingjieb/godev/practice/src/examples/hello . # topid yingjieb@godev-server /repo/yingjieb/godev/practice $ export GOPATH=\"`pwd`:$GOPATH\" yingjieb@godev-server /repo/yingjieb/godev/practice/src/tools $ PATH=$PATH:/repo/yingjieb/crosstoolng/github/crosstool-ng/targets/powerpc-e500mc-linux-gnu/bin GOARCH=ppc64 /repo/yingjieb/godev/golang-go/bin/go build -compiler gccgo -gccgoflags '-static -Os' topid.go /repo/yingjieb/crosstoolng/github/crosstool-ng/targets/powerpc-e500mc-linux-gnu/bin/powerpc-linux-strip topid scp yingjieb@10.182.105.138:/repo/yingjieb/godev/practice/src/tools/topid . ./topid -record -tag fantf -p 1 -child -chartserver 10.182.105.138:9887 -i 3 目标是修改golang go的编译器源码, 使其支持ppc32的gccgo后端 go源码编译 原版go源码编译go tools git clone https://github.com/golang/go.git go build源码在src/cmd/go/internal/work/build.go 第一次编译需要全部编译. cd golang-go/src ./make.bash -a 再编./make.bash --no-clean似乎更快 编译好的go程序在当前工程的bin目录下 cd golang-go/ export GOPATH=\"$GOPATH:`pwd`\" #编译go主程序, 会在当前目录下生成go的可执行程序 cd src/cmd/go go build 注: go tools是指GOTOOLDIR下面的一些可执行文件: $ ls \"/usr/local/go/pkg/tool/linux_amd64\" addr2line asm buildid cgo compile cover dist doc fix link nm objdump pack pprof test2json trace vet 修改版源码编译 我在godevsig分支修改了源码, 支持ppc的gccgo 现在我想基于go1.13 release分支自己编译一套工具链出来 在godev-tool docker里面操作: git checkout release-branch.go1.13 # e164f53422是godevsig分支上我的commit git cherry-pick e164f53422 #在1.15之前, 需要这个commit来支持ppc的cgo git cherry-pick 5d1378143bc #我还想要1.14的-trimpath功能 git cherry-pick eb6ce1cff4 git rm cmd/go/testdata/script/build_trimpath.txt #gccgo不支持go:linkname 指示符, go module要用就出错`//go:linkname is only supported for functions` #需要下面的patch git cherry-pick baf7d95350 git cherry-pick 45873a242d cd golang-go/src GOOS=linux GOARCH=amd64 ./bootstrap.bash 注: bootstrap支持BOOTSTRAP_FORMAT=mintgz意思是生成干净的工具链, 删掉一些不用的文件. 但似乎删的太狠了, 不推荐 不改变go tools的尝试 通常来讲, 用go tools需要传入GOARCH=, 而ppc32是不在列表里面的: $ go tool dist list | grep linux linux/386 linux/amd64 linux/arm linux/arm64 linux/mips linux/mips64 linux/mips64le linux/mipsle linux/ppc64 linux/ppc64le linux/s390x 使用gccgo 一般的, go build的时候, 加-compiler gccgo选项使能gccgo编译器, 需要有gccgo这个可执行文件. 对ppc32来说, 首先要有crosstool-ng编译出来的gccgo, 比如powerpc-e500mc-linux-gnu-gccgo 在/repo/yingjieb/godev/gccgoppc32/powerpc-e500mc-linux-gnu/bin下面 建一个gccgo的可执行脚本, 内容如下: 这会把所有调用到gccgo的参数打印出来 #!/bin/bash ( echo `pwd` echo \"$@\" ) >> gccgo.log exec powerpc-e500mc-linux-gnu-gccgo $@ 注意, go build会使用cache, 要得到完整过程, 需要删掉cache 传入GOARCH=ppc64 yingjieb@9102a93a554e /repo/yingjieb/godev/practice/src/examples $ rm -f hello; rm -rf /home/yingjieb/.cache/go-build/; rm -f gccgo.log; PATH=$PATH:/repo/yingjieb/godev/gccgoppc32/powerpc-e500mc-linux-gnu/bin GOARCH=ppc64 go build -compiler gccgo hello.go yingjieb@9102a93a554e /repo/yingjieb/godev/practice/src/examples $ cat gccgo.log /repo/yingjieb/godev/practice/src/examples -print-search-dirs /repo/yingjieb/godev/practice/src/examples -dumpversion /repo/yingjieb/godev/practice/src/examples -dumpmachine /repo/yingjieb/godev/practice/src/examples -### -x go -c - /repo/yingjieb/godev/practice/src/examples -c -g -fdebug-prefix-map=/tmp/go-build836929485=/tmp/go-build -gno-record-gcc-switches -fgo-relative-import-path=_/repo/yingjieb/godev/practice/src/examples -o /tmp/go-build836929485/b001/_go_.o -I /tmp/go-build836929485/b001/_importcfgroot_ /repo/yingjieb/godev/practice/src/examples/hello.go /repo/yingjieb/godev/practice/src/examples -xassembler-with-cpp -I /tmp/go-build836929485/b001/ -c -o /tmp/go-build836929485/b001/_buildid.o -D GOOS_linux -D GOARCH_ppc64 /tmp/go-build836929485/b001/_buildid.s /repo/yingjieb/godev/practice/src/examples -### -x go -c - /repo/yingjieb/godev/practice/src/examples -o /tmp/go-build836929485/b001/exe/a.out -Wl,-( -Wl,--whole-archive /tmp/go-build836929485/b001/_pkg_.a -Wl,--no-whole-archive -Wl,-) -Wl,--build-id=0x66534c46775162664f44395036684634392d76552f6f79586f4a615778706b5f78586c7852795069492f476e3059334754737349613869696f4b524356432f66534c46775162664f44395036684634392d7655 虽然传入的是GOARCH=ppc64, 但依然成功生成了hello程序: yingjieb@9102a93a554e /repo/yingjieb/godev/practice/src/examples $ file hello hello: ELF 32-bit MSB executable, PowerPC or cisco 4500, version 1 (SYSV), dynamically linked, interpreter /lib/ld.so.1, for GNU/Linux 4.9.156, with debug_info, not stripped 生成的hello和libgo.so.13考到板子上(FANT-F), 可以正常执行: scp yingjieb@10.182.105.138:/repo/yingjieb/godev/practice/src/examples/hello . scp yingjieb@10.182.105.138:/repo/yingjieb/godev/gccgoppc32/powerpc-e500mc-linux-gnu/powerpc-e500mc-linux-gnu/lib/libgo.so.13 . ~ # LD_LIBRARY_PATH=`pwd` ./hello hello world! 4 0x21192008 4 4 传入GOARCH=amd64 yingjieb@9102a93a554e /repo/yingjieb/godev/practice/src/examples $ rm -f hello; rm -rf /home/yingjieb/.cache/go-build/; rm -f gccgo.log; PATH=$PATH:/repo/yingjieb/godev/gccgoppc32/powerpc-e500mc-linux-gnu/bin GOARCH=amd64 go build -compiler gccgo hello.go # command-line-arguments go1: error: '-m64' not supported in this configuration yingjieb@9102a93a554e /repo/yingjieb/godev/practice/src/examples $ cat gccgo.log /repo/yingjieb/godev/practice/src/examples -print-search-dirs /repo/yingjieb/godev/practice/src/examples -dumpversion /repo/yingjieb/godev/practice/src/examples -dumpmachine /repo/yingjieb/godev/practice/src/examples -### -x go -c - /repo/yingjieb/godev/practice/src/examples -c -g -m64 -fdebug-prefix-map=/tmp/go-build246565517=/tmp/go-build -gno-record-gcc-switches -fgo-relative-import-path=_/repo/yingjieb/godev/practice/src/examples -o /tmp/go-build246565517/b001/_go_.o -I /tmp/go-build246565517/b001/_importcfgroot_ /repo/yingjieb/godev/practice/src/examples/hello.go 说明go build确实会默认传入一些编译选项, 比如这里, 因为指定了GOARCH=amd64, 但我们的交叉编译器是powerpc-e500mc-linux-gnu-gccgo, 不认x86的-m64选项, 报错: go1: error: '-m64' not supported in this configuration 总结: 使用gccgo ppc32的交叉toolchain的时候, 后端编译器powerpc-e500mc-linux-gnu-gccgo就默认使用ppc32. 当go build传入GOARCH=ppc64时, 并没有传入\"默认\"的ABI, 所以没有给编译器造成困扰. 但这里有个隐患: -xassembler-with-cpp -I /tmp/go-build836929485/b001/ -c -o /tmp/go-build836929485/b001/_buildid.o -D GOOS_linux -D GOARCH_ppc64 /tmp/go-build836929485/b001/_buildid.s 这里的-D GOARCH_ppc64是不对的. 尝试成功, 使用ppc32 gccgo的方法 其他都一样, 只是要传入GOARCH=ppc64和-compiler gccgo, 并且保证PATH=$PATH:/repo/yingjieb/godev/gccgoppc32/powerpc-e500mc-linux-gnu/bin下面有gccgo链接到同目录下的powerpc-e500mc-linux-gnu-gccgo 修改go源码, 支持GOARCH=ppc32 前面已经证明, 使用GOARCH=ppc64是可以编译成功的, 并且运行也没发现什么问题. 但注意到ppc64会定义-D GOARCH_ppc64, 这个宏是给C和汇编看的, 有什么影响呢? 搜索一下, 下面的文件使用了GOARCH_ppc64 src/internal/bytealg/compare_ppc64x.s src/internal/bytealg/indexbyte_ppc64x.s src/crypto/md5/md5block_ppc64x.s # 这个文件是go运行时的汇编支持, 比如gcWriteBarrier, 和cgo相关的实现 // +build ppc64 ppc64le src/runtime/asm_ppc64x.s # 这个似乎是syscall的汇编实现 // +build linux // +build ppc64 ppc64le src/runtime/sys_linux_ppc64x.s src/runtime/cgo/asm_ppc64x.s 下面我们要修改go源码, 以支持直接传入GOARCH=ppc32 首先需要crosstool-ng编出gccgo. 编译gccgo gcc源码里面包含了go的源码, 在gcc/libgo下面. 不同版本的gcc的go源码版本如下: cat gcc/libgo/VERSION gcc version go version gcc-8.3.0 go1.10.3 gcc-9.3.0 go1.12 gcc-10.1.0 go1.14.2 crosstool-ng编译gccgo 这里我用官方crosstool-ng git clone https://github.com/crosstool-ng/crosstool-ng 需要先安装些依赖: apt install flex help2man texinfo libtool-bin libncurses-dev gawk bison 要生成ct-ng cd crosstool-ng ./bootstrap ./configure --enable-local make 使用cg-ng ./ct-ng help ./ct-ng list-samples ./ct-ng powerpc-e300c3-linux-gnu ./ct-ng defconfig DEFCONFIG=samples/Nokia/isam-reborn-ppc-P40xx ./ct-ng menuconfig ./ct-ng build #保存config ./ct-ng savedefconfig DEFCONFIG=samples/Nokia/isam-reborn-ppc-e6500 完成后, 会在targets下面生成工具链 使用crosstool-ng的gccgo 为了版本一致, 我选用了 gcc-10.2.0, 里面的go版本是go1.14; go源码使用release-branch.go1.14, 编译go tools. 使用新生成的go tools, 指定gccgo编译hello.go PATH=$PATH:/repo/yingjieb/crosstoolng/github/crosstool-ng/targets/powerpc-e500mc-linux-gnu/bin GOARCH=ppc64 /repo/yingjieb/godev/golang-go/bin/go build -compiler gccgo -gccgoflags '-static -Os' hello.go 修改go源码支持ppc32 power ISA背景知识 power ISA Power ISA v.2.06 The specification for Power ISA v.2.06 was released in February 2009, and revised in July 2010. It is based on Power ISA v.2.05 and includes extensions for the POWER7 processor and e500-mc core. One significant new feature is vector-scalar floating-point instructions (VSX \"AltiVec\")). Book III-E also includes significant enhancement for the embedded specification regarding hypervisor and virtualisation on single and multi core implementations. The spec was revised in November 2010 to the Power ISA v.2.06 revision B spec, enhancing virtualization features. Compliant cores All cores that comply with previous versions of the Power ISA POWER7 A2I e500-mc e5500 Power ISA v.2.07 The specification for Power ISA v.2.07 was released in May 2013. It is based on Power ISA v.2.06 and includes major enhancements to logical partition functionality \"Logical partition (virtual computing platform)\"), transactional memory, expanded performance monitoring, new storage control features, additions to the VMX and VSX vector facilities (VSX-2), along with AES> and Galois Counter Mode (GCM), SHA-224, SHA-256, SHA-384 and SHA-512 (SHA-2) cryptographic extensions and cyclic redundancy check (CRC) algorithms. The spec was revised in April 2015 to the Power ISA v.2.07 B spec. Compliant cores All cores that comply with previous versions of the Power ISA POWER8 e6500 core A2O Power ISA v.3.0 The specification for Power ISA v.3.0 was released in November 2015. It is the first to come out after the founding of the OpenPOWER Foundation and includes enhancements for a broad spectrum of workloads and removes the server and embedded categories while retaining backwards compatibility and adds support for VSX-3 instructions. New functions include 128-bit quad-precision floating-point operations, a random number generator, hardware-assisted garbage collection and hardware-enforced trusted computing. The spec was revised in March 2017 to the Power ISA v.3.0 B spec. Compliant cores All cores that comply with previous versions of the Power ISA POWER9 default ARCH选项 每个arch都有个default选项: 这段代码是自动生成的 // Code generated by go tool dist; DO NOT EDIT. package objabi import \"runtime\" const defaultGO386 = `sse2` const defaultGOARM = `5` const defaultGOMIPS = `hardfloat` const defaultGOMIPS64 = `hardfloat` const defaultGOPPC64 = `power8` const defaultGOOS = runtime.GOOS const defaultGOARCH = runtime.GOARCH const defaultGO_EXTLINK_ENABLED = `` const defaultGO_LDSO = `` const version = `go1.14.9` const stackGuardMultiplierDefault = 1 const goexperiment = `` 值得注意的是, PPC64实际上是power8 默认编译器参数 golang-go/src/cmd/go/internal/work/exec.go // gccArchArgs returns arguments to pass to gcc based on the architecture. func (b *Builder) gccArchArgs() []string { switch cfg.Goarch { case \"386\": return []string{\"-m32\"} case \"amd64\": return []string{\"-m64\"} case \"arm\": return []string{\"-marm\"} // not thumb case \"s390x\": return []string{\"-m64\", \"-march=z196\"} case \"mips64\", \"mips64le\": return []string{\"-mabi=64\"} case \"mips\", \"mipsle\": return []string{\"-mabi=32\", \"-march=mips32\"} case \"ppc64\": if cfg.Goos == \"aix\" { return []string{\"-maix64\"} } } return nil } 要修改的文件 modified: src/cmd/dist/build.go modified: src/cmd/dist/buildruntime.go modified: src/cmd/go/internal/cfg/cfg.go modified: src/internal/cfg/cfg.go ppc64无法在e6500上运行 用gcgo编译出来的GOARCH=ppc64的版本无法在fant-g上运行. 用gccgo编出来的32位程序可以执行. 用gccgo编ppc64时, 编译出错, 报link错误: lib/gcc/powerpc-e6500-linux-gnu/10.2.0/libgcc.a(morestack.o): in function `__morestack': src/gcc/libgcc/config/rs6000/morestack.S:159: undefined reference to `__morestack_block_signals' undefined reference to `__generic_morestack' undefined reference to `__morestack_unblock_signals' undefined reference to `__morestack_block_signals' undefined reference to `__generic_releasestack' undefined reference to `__morestack_unblock_signals' undefined reference to `__generic_findstack' undefined reference to `__generic_morestack_set_initial_sp' undefined reference to `__morestack_load_mmap' 对hello.go来说, 加选项-fno-split-stack可以成功编译ppc64, 成功运行 /repo/yingjieb/crosstoolng/github/crosstool-ng/targets/powerpc-e6500-linux-gnu/bin/powerpc-e6500-linux-gnu-gccgo -fno-split-stack -static hello.go PATH=$PATH:/repo/yingjieb/crosstoolng/github/crosstool-ng/targets/powerpc-e6500-linux-gnu/bin GOARCH=ppc64 /repo/yingjieb/godev/golang-go/bin/go build -compiler gccgo -gccgoflags '-static -Os -fno-split-stack' hello.go 但topid.go即使加了-fno-split-stack, 还是报一样的链接错误 这些缺失的符号应该在哪里? 看起来是libgcc.a的__morestack函数需要调用__morestack_block_signals等函数, 但没有定义. $ nm /repo/yingjieb/crosstoolng/github/powerpc-e6500-linux-gnu/lib/gcc/powerpc-e6500-linux-gnu/10.2.0/libgcc.a | grep more morestack.o: U __generic_morestack U __generic_morestack_set_initial_sp 0000000000000018 D __morestack U __morestack_block_signals 0000000000000048 D __morestack_get_guard U __morestack_load_mmap 0000000000000078 D __morestack_make_guard 0000000000000000 D __morestack_non_split 0000000000000060 D __morestack_set_guard U __morestack_unblock_signals U的意思就是undefined 对ppc来说, gcc的代码libgcc/config/rs6000/morestack.S中, 有__morestack的定义, 确实调用了这些函数. 这些函数的定义在:libgcc/generic-morestack.c 根据下面的参考文章, split stack功能是Ian Lance Taylor在x86上实现的; ppc64上的实现的作者是Alan Modra, [Patch 0/4] PowerPC64 Linux split stack support 对照X86机器上: # 先找到gcc的lib目录, 是/usr/lib/gcc/x86_64-linux-gnu/7 gcc -print-search-dirs # 用nm看符号表 $ nm libgcc.a | grep more nm: _trampoline.o: no symbols nm: __main.o: no symbols nm: _mulhc3.o: no symbols nm: _divhc3.o: no symbols generic-morestack.o: 00000000000002b0 T __generic_morestack 0000000000000240 T __generic_morestack_set_initial_sp 0000000000000940 T __morestack_allocate_stack_space 0000000000000880 T __morestack_block_signals 00000000000000b8 B __morestack_current_segment 0000000000000040 T __morestack_fail 0000000000000020 b __morestack_fullmask U __morestack_get_guard 0000000000000000 B __morestack_initial_sp 0000000000000ad0 T __morestack_load_mmap U __morestack_make_guard 0000000000000110 T __morestack_release_segments 00000000000000c0 B __morestack_segments U __morestack_set_guard 00000000000008e0 T __morestack_unblock_signals generic-morestack-thread.o: U __morestack_fail U __morestack_release_segments U __morestack_segments morestack.o: U __generic_morestack U __generic_morestack_set_initial_sp 0000000000000037 T __morestack U __morestack_block_signals 0000000000000155 T __morestack_get_guard 000000000000011c T __morestack_large_model U __morestack_load_mmap 0000000000000169 T __morestack_make_guard 0000000000000000 T __morestack_non_split 000000000000015f T __morestack_set_guard U __morestack_unblock_signals T表示是代码符号. 确实的函数大部分在generic-morestack.o中. 这和libgcc/generic-morestack.c代码分析是一样的. 说明这部分代码没有编译到libgcc.a中. ppc32没有这个问题, 因为ppc32本来就不支持split stack. 为什么generic-morestack.c没有编译到? libgcc/generic-morestack.c中, 主体代码的编译条件是:#if !defined __powerpc__ || defined __powerpc64____powerpc64__确定是有的. 那为什么还是没有编到呢?原来是libgcc/config/t-stack中, enable_threads控制这个文件是否参与编译: ifeq ($(enable_threads),yes) LIB2ADD_ST += $(srcdir)/generic-morestack.c $(srcdir)/generic-morestack-thread.c endif 在gcc安装手册中, 有使用方法: --enable-threads Specify that the target supports threads. This affects the Objective-C compiler and runtime library, and exception handling for other languages like C++. On some systems, this is the default. In general, the best (and, in many cases, the only known) threading model available will be configured for use. Beware that on some systems, GCC has not been taught what threading models are generally available for the system. In this case, --enable-threads is an alias for --enable-threads=single. --enable-threads=lib Specify that lib is the thread support library. This affects the Objective-C compiler and runtime library, and exception handling for other languages like C++. The possibilities for lib are: aix AIX thread support. dce DCE thread support. lynx LynxOS thread support. mipssde MIPS SDE thread support. no This is an alias for ‘single’. posix Generic POSIX/Unix98 thread support. rtems RTEMS thread support. single Disable thread support, should work for all platforms. tpf TPF thread support. vxworks VxWorks thread support. win32 Microsoft Win32 API thread support. 在gcc/config.gcc中, 每个arch和os都会检查 case ${target} in *-*-linux* | frv-*-*linux* | *-*-kfreebsd*-gnu | *-*-gnu* | *-*-kopensolaris*-gnu | *-*-uclinuxfdpiceabi) case ${enable_threads} in \"\" | yes | posix) thread_file='posix' ;; esac ... esac crosstool-ng的bug 经进一步检查, 原版的gcc没有问题. 问题在于crosstool-ng的一个patch: yingjieb@godev-server /repo/yingjieb/crosstoolng/github/crosstool-ng/packages/gcc/10.2.0 $ cat 0008-libgcc-disable-split-stack-nothreads.patch disable split-stack for non-thread builds Signed-off-by: Waldemar Brodkorb --- libgcc/config/t-stack | 2 ++ 1 file changed, 2 insertions(+) --- a/libgcc/config/t-stack +++ b/libgcc/config/t-stack @@ -1,4 +1,6 @@ # Makefile fragment to provide generic support for -fsplit-stack. # This should be used in config.host for any host which supports # -fsplit-stack. +ifeq ($(enable_threads),yes) LIB2ADD_ST += $(srcdir)/generic-morestack.c $(srcdir)/generic-morestack-thread.c +endif 尝试在crosstool-ng的config里面加: CT_CC_GCC_EXTRA_CONFIG_ARRAY=\"--enable-threads=yes\" 但不起作用, 删除掉这个文件0008-libgcc-disable-split-stack-nothreads.patch就好了. 关于split stack gcc的大神Ian Lance Taylor有两篇文章: gccgo中的split stack Gccgo provides the standard, complete Go library. Many of the core features of the Go runtime are the same in both gccgo and gc, including the goroutine scheduler, channels, the memory allocator, and the garbage collector. Gccgo supports splitting goroutine stacks as the gc compiler does, but currently only on x86 (32-bit or 64-bit) and only when using the gold linker (on other processors, each goroutine will have a large stack, and a deep series of function calls may run past the end of the stack and crash the program). Gccgo distributions do not yet include a version of the go command. However, if you install the go command from a standard Go release, it already supports gccgo via the -compiler option: go build -compiler gccgo myprog. The tools used for calls between Go and C/C++, cgo and SWIG, also support gccgo. gcc中的split stack 上面提到的gold linker是什么意思? gold linker是另一种linker, 并不是ld的某种模式. 相关链接 PowerPC64 Linux split stack support https://gcc.gnu.org/legacy-ml/gcc-patches/2015-05/msg01522.html https://groups.google.com/g/golang-codereviews/c/4T_KQys3XM0/m/VWNk2c6JCgAJ 上传gccgo工具链到artifactory proxyoff cd crosstool-ng/targets tar cJf godev-gccgo-ppc.tar.xz powerpc-e500mc-linux-gnu tar cJf godev-gccgo-ppc64.tar.xz powerpc64-e6500-linux-gnu curl -H \"X-JFrog-Art-Api:AKCp8hyinctVijrdqGaFc1YAT7e7KDHWJEaackjuv6oCheipkYU9jU5okRj8rnFkVvcZWnTVc\" -X PUT \"https://artifactory-blr1.int.net.nokia.com:443/artifactory/godevsig-generic-local/toolchain/gccgo/`git rev-parse HEAD`/\" -T \"{godev-gccgo-ppc.tar.xz,godev-gccgo-ppc64.tar.xz}\" 详见笔记云端环境和go实践.md gccgo的hello size过大问题 gccgo编译出来的静态链接的hello是17M 其中有12M左右是debug info. 用gcc -s或者strip --strip-debug都能减小size, 但问题是运行时panic就不能打印调用栈了. 按照gcc-10.2.0/libgo/README的说法: This library should not be stripped when it is installed. Go code relies on being able to look up file/line information, which comes from the debugging info using the libbacktrace library. go需要debug info来查找file line信息. 注: libbacktrace也是ianlancetaylor大神的作品: github 那有没有其他的办法可以减小hello的size呢? 17M也太大了. strip使用说明 GCC的debug选项 gcc的选项中, -g1和-gz看起来比较有用: -glevel Request debugging information and also use level to specify how much information. The default level is 2. Level 0 produces no debug information at all. Thus, -g0 negates -g. Level 1 produces minimal information, enough for making backtraces in parts of the program that you don’t plan to debug. This includes descriptions of functions and external variables, and line number tables, but no information about local variables. Level 3 includes extra information, such as all the macro definitions present in the program. Some debuggers support macro expansion when you use -g3. If you use multiple -g options, with or without level numbers, the last such option is the one that is effective. -gdwarf does not accept a concatenated debug level, to avoid confusion with -gdwarf-level. Instead use an additional -glevel option to change the debug level for DWARF. -gz[=type] Produce compressed debug sections in DWARF format, if that is supported. If type is not given, the default type depends on the capabilities of the assembler and linker used. type may be one of ‘none’ (don’t compress debug sections), ‘zlib’ (use zlib compression in ELF gABI format), or ‘zlib-gnu’ (use zlib compression in traditional GNU format). If the linker doesn’t support writing compressed debug sections, the option is rejected. Otherwise, if the assembler does not support them, -gz is silently ignored when producing object files. -gz能让hello从17M减小到8.7M 相关命令 #看具体那个section的size size -A hello 这篇文章非常详细的介绍了debug节的方方面面的信息. 特别的, objcopy能够去掉任意指定section /repo/yingjieb/godevsig/crosstool-ng/targets/powerpc-e500mc-linux-gnu/bin/powerpc-e500mc-linux-gnu-objcopy -R .debug_info -R .debug_abbrev -R .debug_aranges -R .debug_ranges -R .debug_loc -R .debug_str hello 减小libgo.a的体积 gcc的libgo在编译的时候, 有自己默认的编译选项-O2 -g 用下面的patch diff --git a/Makefile.in b/Makefile.in index 36e369df6..2e183c702 100644 --- a/Makefile.in +++ b/Makefile.in @@ -619,7 +619,7 @@ CXXFLAGS_FOR_TARGET = @CXXFLAGS_FOR_TARGET@ LIBCFLAGS_FOR_TARGET = $(CFLAGS_FOR_TARGET) LIBCXXFLAGS_FOR_TARGET = $(CXXFLAGS_FOR_TARGET) -fno-implicit-templates LDFLAGS_FOR_TARGET = @LDFLAGS_FOR_TARGET@ -GOCFLAGS_FOR_TARGET = -O2 -g +GOCFLAGS_FOR_TARGET = -Os -g1 -gz GDCFLAGS_FOR_TARGET = -O2 -g FLAGS_FOR_TARGET = @FLAGS_FOR_TARGET@ diff --git a/Makefile.tpl b/Makefile.tpl index efed15117..3c0d2e5e2 100644 --- a/Makefile.tpl +++ b/Makefile.tpl @@ -542,7 +542,7 @@ CXXFLAGS_FOR_TARGET = @CXXFLAGS_FOR_TARGET@ LIBCFLAGS_FOR_TARGET = $(CFLAGS_FOR_TARGET) LIBCXXFLAGS_FOR_TARGET = $(CXXFLAGS_FOR_TARGET) -fno-implicit-templates LDFLAGS_FOR_TARGET = @LDFLAGS_FOR_TARGET@ -GOCFLAGS_FOR_TARGET = -O2 -g +GOCFLAGS_FOR_TARGET = -Os -g1 -gz GDCFLAGS_FOR_TARGET = -O2 -g FLAGS_FOR_TARGET = @FLAGS_FOR_TARGET@ 经过测试, 各个选项组合的size如下: GOCFLAGS_FOR_TARGET webhello size -O2 -g(default) 17M -Os -g1 -gz 13M -Os -g1 -gz -fdata-sections -ffunction-sections -Wl,--gc-sections 12M -Os -g1 -gz -fdata-sections -ffunction-sections -Wl,--gc-sections -flto 12M -Os -g1 -gz -fdata-sections -ffunction-sections 12M 使能lto crosstool-ng默认在static gcc模式下(STATIC_TOOLCHAIN=y), 不使能lto. 但可以自己强制使能: CT_CC_GCC_EXTRA_CONFIG_ARRAY=--enable-lto 但经过验证, 似乎打开lto优化, 并没有减小size. 改动提交到crosstool-ng 在gcc库上commit这个改动, 生成patch # -1表示最新的1个改动 git format-patch -1 拷贝这个patch到gcc下面 cp 0001-gccgo-generate-smaller-libgo-when-building-gccgo.patch crosstool-ng/packages/gcc/10.2.0/ go_export小节 用size -A命令看到, gccgo编译出来的executable中, 有.go_export小节, 在webhello中占1.6M 根据这个讨论, gccgo的作者说.go_export是给shared library用的, 最终的可执行文件不需要. 但他不知道怎么告诉linker把这个小节去掉 那可以在最后手动用objcopy -R .go_export file来删除这个小节. /opt/crosstool/powerpc64-e6500-linux-gnu/bin/powerpc64-e6500-linux-gnu-objcopy --remove-section=.go_export hello static和static-libgo 使用gccgo, 可以传入-gccgoflags为-static-libgo, 只把libgo编译到static的目标文件中, 而libc等库还是动态连接的. 详见这个问答 让gcgo支持ppc32 这个issue就是讨论这个话题的. 但截止目前(2020.10)还没有动静. 有人提到了通常支持一个ARCH需要的工作: Quoting this super useful post from Aram Hăvărneanu from https://groups.google.com/d/msg/golang-dev/SRUK7yJVA0c/JeoCRMwzBwAJ \"I've done many ports now, so the strategy I use is this (very simplified): 1\\. Add GOOS/GOARCH support to the toolchain 2\\. Add some support for GOARCH in cmd/internal/obj 3\\. Add some support for GOARCH in cmd/asm 4\\. Add some support for GOOS/GOARCH in cmd/link 5\\. Iterate through 2-3-4 until you can produse some kind of binaries from assembly files. Depending on the specifics of GOOS/GOARCH you might, or might not need to use external linking. 6\\. Once you can produce binaries, thoroughly test them (link just assembly programs, without runtime). Basically make sure the low-level toolchain works. 7\\. Start working on the Go compiler for GOARCH. 8\\. Write a minimal alternative runtime for Go. The runtime is much too complicated as a first test Go program. Basically write your own runtime in assembly that is just stubbed out, but can run a good bulk of the programs in go/test. 9\\. Once that works well enough, start using the real runtime. This requires implementing a lot of assembly, but you can use the lessons learned from #8. 10\\. Make all the tests in go/test work. 11\\. Make all the stdlib tests work. You are still working amd64 now, and executing on GOARCH with go_GOOS_GOARCH_exec. 12\\. Run bootstrap.bash 13\\. Move over the artifacts on GOOS/GOARCH machine. 14\\. Make sure make.bash works. You will still likely have to fix problems to make this N-generation compiler work. 15\\. Make sure all.bash works. 16\\. Done. As you can see, steps 1-14 are done on amd64 (or some other supported platform), and only step 15 is done on the target architecture. 搜索源码大约有5000行包含ppc64字样... 要完整支持ppc32并非易事. 下一步 用crosstool-ng编译go1.13兼容的工具链 最好全部静态链接 高版本 补充: fant-f运行topid ~ # LD_LIBRARY_PATH=`pwd` ./topid -record -tag fantf -p 1 -child -chartserver 10.182.105.138:9887 -i 3 Hello 你好 Hola Hallo Bonjour Ciao Χαίρετε こんにちは 여보세요 Version: 0.1.3 Visit below URL to get the chart: http://10.182.105.138:9888/fantf/538600174 ~ # ls -lh total 38M -rwxr-xr-x 1 root root 89.7K Jul 8 14:22 hello -rwxr-xr-x 1 root root 37.8M Jul 8 14:24 libgo.so.13 -rwxr-xr-x 1 root root 258.3K Jul 8 15:01 topid ~ # cat /isam/slot_default/devs/rip/boardName FANT-F ~ # ~ # 补充: ppc64 yingjieb@godev-server /repo/yingjieb/godevsig/crosstool-ng/samples/Nokia $ git show 0a81bc37 commit 0a81bc37a9e8d44c9d3f13c0b557854425b018db Author: Bai Yingjie Date: Tue Oct 20 08:55:23 2020 +0000 godev: enable the default split-stack for ppc64, gccgo lib uses split-stack feature, which requires toolchain support split-stack. diff --git a/packages/gcc/10.2.0/0008-libgcc-disable-split-stack-nothreads.patch b/packages/gcc/10.2.0/0008-libgcc-disable-split-stack-nothreads.patch deleted file mode 100644 index df91a9ff..00000000 --- a/packages/gcc/10.2.0/0008-libgcc-disable-split-stack-nothreads.patch +++ /dev/null @@ -1,17 +0,0 @@ -disable split-stack for non-thread builds - -Signed-off-by: Waldemar Brodkorb - ---- - libgcc/config/t-stack | 2 ++ - 1 file changed, 2 insertions(+) - ---- a/libgcc/config/t-stack -+++ b/libgcc/config/t-stack -@@ -1,4 +1,6 @@ - # Makefile fragment to provide generic support for -fsplit-stack. - # This should be used in config.host for any host which supports - # -fsplit-stack. -+ifeq ($(enable_threads),yes) - LIB2ADD_ST += $(srcdir)/generic-morestack.c $(srcdir)/generic-morestack-thread.c -+endif 补充: 为什么gc go工具链的支持ppc64, 但不能在e6500上运行? 因为gc go的ppc64特指power8 zte有人支持了e6500 用法是传入GOPPC 但我试了, 官方源码树里还没有. GOPPC64=e6500 GOARCH=ppc64 _go build hello.g 2020/11/03 01:21:57 Invalid GOPPC64 value. Must be power8 or power9. 还有个说法是, 去掉ppc64的支持, 只保留ppc64le 补充: elf格式 https://stevens.netmeister.org/631/elf.html "},"notes/golang_toolchain_compile_gccgo.html":{"url":"notes/golang_toolchain_compile_gccgo.html","title":"编译gccgo","keywords":"","body":" gccgo和go tools 使用go tools和gccgo crosstool ng(我最后用的是这个) 编译gcc的理论基础 # 编译过程for x86_64 下载gcc9.2源码, release版本就可以 安装依赖 解压gcc 编译 编译完成后 会在指定目录下生成 使用 gccgo和go tools gotools目录是编译go tools的. 到时候要自己改build源码, 自己生成tools? go的代码在libgo https://github.com/golang/go/wiki/GccgoCrossCompilation#build-a-cross-gccgo-aware-version-of-the-go-tool https://github.com/golang/go/wiki/GccgoCrossCompilation https://github.com/karalabe/xgo 使用go tools和gccgo https://medium.com/@chrischdi/cross-compiling-go-for-raspberry-pi-dc09892dc745 crosstool ng(我最后用的是这个) https://crosstool-ng.github.io/docs/configuration/ crosstool-ng可以打印shell的调用栈, 比如: [INFO ] Retrieving needed toolchain components' tarballs [EXTRA] Retrieving 'automake-1.16.1' [EXTRA] Verifying SHA512 checksum for 'automake-1.16.1.tar.xz' [EXTRA] Retrieving 'linux-4.9.156' [ERROR] linux: download failed [ERROR] [ERROR] >> [ERROR] >> Build failed in step 'Retrieving needed toolchain components' tarballs' [ERROR] >> called in step '(top-level)' [ERROR] >> [ERROR] >> Error happened in: CT_Abort[scripts/functions@487] [ERROR] >> called from: CT_DoFetch[scripts/functions@2103] [ERROR] >> called from: CT_PackageRun[scripts/functions@2063] [ERROR] >> called from: CT_Fetch[scripts/functions@2174] [ERROR] >> called from: do_kernel_get[scripts/build/kernel/linux.sh@22] [ERROR] >> called from: main[scripts/crosstool-NG.sh@647] [ERROR] >> 是因为使用了trap ... ERR技术.在crosstool-ng-1.24.0/scripts/functions中, trap CT_OnError ERR, 具体见CT_OnError函数. # Install the fault handler trap CT_OnError ERR # Inherit the fault handler in subshells and functions set -E # Make pipes fail on the _first_ failed command # Not supported on bash help trap和help set说的很清楚 上面这个CT_OnError函数用了下面的思路: bash默认有变量FUNCNAME BASH_SOURCE BASH_LINENO, 这些是数组, 保存了调用栈. https://unix.stackexchange.com/questions/462156/how-do-i-find-the-line-number-in-bash-when-an-error-occured 编译gcc的理论基础 https://preshing.com/20141119/how-to-build-a-gcc-cross-compiler/ https://solarianprogrammer.com/2018/05/06/building-gcc-cross-compiler-raspberry-pi/ 编译过程for x86_64 ============================= 下载gcc9.2源码, release版本就可以 axel http://www.netgull.com/gcc/releases/gcc-9.2.0/gcc-9.2.0.tar.xz 安装依赖 apt install build-essential libgmp-dev libmpfr-dev libmpc-dev 解压gcc 编译 cd gcc-9.2.0 mkdir objdir && cd objdir ../configure --prefix=/home/byj/repo/gorepo/gcc --enable-languages=go --disable-multilib # 虽然没有写明要c和c++, 但默认是肯定有的 make -j 编译完成后 make install 会在指定目录下生成 gcc c++ g++ go gofmt gccgo 使用 export LD_LIBRARY_PATH=~/repo/gorepo/gcc/lib64 PATH=~/repo/gorepo/gcc/bin:$PATH go build hello.go 会生成hello可执行文件, 默认动态链接, 大小70K 动态库libgo.so大小48M, strip后26M 压缩后5M $ ldd hello linux-vdso.so.1 => (0x00007ffe35580000) libgo.so.14 => /home/byj/repo/gorepo/gcc/lib64/libgo.so.14 (0x00007f5fae036000) libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f5fadd05000) libgcc_s.so.1 => /home/byj/repo/gorepo/gcc/lib64/libgcc_s.so.1 (0x00007f5fadaee000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5fad723000) /lib64/ld-linux-x86-64.so.2 (0x000055cdd4f10000) libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f5fad506000) "},"notes/golang_go_on_mips.html":{"url":"notes/golang_go_on_mips.html","title":"go on mips boards(not so updated)","keywords":"","body":"记录早期我在mips上跑go的过程.现在看起来走了些弯路, 主要是当时没想到go的交叉编译会那么简单. "},"notes/golang_go_on_mips_part1.html":{"url":"notes/golang_go_on_mips_part1.html","title":"part 1: cross compile go","keywords":"","body":" Background Go toolchains Compile gc go toolchain Compile gc go 1.4 for host Compile gc go cross toolchain Cgo issue Cgo use gcc compiler direct cgo to use N32 ABI How to proceed if cgo is not working? disable cgo support use N64 ABI for MIPS64 hello.go Works next Background In order to run go app on the board, we need to have a go compiler that compiles go sources into go executables. Here we have a simple hello example: hello.go package main import \"fmt\" func main() { fmt.Println(\"Hello, World!\") } For go is a modern programing language, it is pretty straightforward to do this in the cloud/server x86 environment: $ sudo apt install golang-go $ go build hello.go $ ls hello hello.go $ ./hello Hello, World! OK, job is done, you can stop reading if you work on a system that uses Ubuntu/CentOS on X86, or even ARM64. But for people who work in embedded environment like buildroot system on MIPS, please continue. Go toolchains There are two official Go compiler toolchains. gc go toolchain: seems to be more popular, this toolchain itself is written in Go x86/ubuntu reference: sudo apt install golang-go gccgo compiler: the traditional compiler using the GCC back end x86/ubuntu reference: sudo apt install gccgo-go At the moment, for MIPS boards like fglt-b, gcc version is 4.7.0, lower than the minimal gcc prerequisite version 4.7.1, which has support for go 1.0. gcc 8 supports go 1.10. source: https://golang.org/doc/install/gccgo Compile gc go toolchain In order to have go executables runnable on board, a gc go toolchain needs to be compiled first which is a cross toolchain resides on host for embedded world. As mentioned, gc go is written in go, so a go bootstrap compiler is needed to compile gc go toolchain. Actually, the bootstrap compiler is also gc go compiler version 1.4, which was the last distribution in which the toolchain was written in C. Compile gc go 1.4 for host In buildroot, package go-bootstrap is the one does the job. see buildroot/package/go-bootstrap/go-bootstrap.mk buildroot/output/build/host-go-bootstrap-1.4.3/src/make.bash the compiled outputs are installed to: buildroot/output/host/lib/go-1.4.3 Compile gc go cross toolchain In buildroot, package go is the one does the job. Here we need to build a cross compiler, GO_GOARCH is used for this purpose, eg: for fglt-b, GO_GOARCH = mips64 If all things go well, the toolchain will be installed to buildroot/output/host/lib/go. The complete build steps: Building Go cmd/dist using /repo/yingjieb/ms/buildroot/output/host/lib/go-1.4.3. Building Go toolchain1 using /repo/yingjieb/ms/buildroot/output/host/lib/go-1.4.3. Building Go bootstrap cmd/go (go_bootstrap) using Go toolchain1. Building Go toolchain2 using go_bootstrap and Go toolchain1. Building Go toolchain3 using go_bootstrap and Go toolchain2. Building packages and commands for host, linux/amd64. # errors are seen in this step Building packages and commands for target, linux/mips64. Cgo issue cgo is a component of go, which enables the creation of go packages that call C code. In buildroot, package go fails to compile, because go doesn't support CGO linking on MIPS64x platforms. See: https://github.com/karalabe/xgo/issues/46 The consequence is any go app that depends on BR2_PACKAGE_HOST_GO_CGO_LINKING_SUPPORTS is unable to compile, even not selectable by buildroot menuconfig. Nearly all go packages depend on BR2_PACKAGE_HOST_GO_CGO_LINKING_SUPPORTS, they are: docker-proxy, docker-containerd, docker-engine, docker-cli, flannel, mender, runc. For MIPS octeon family specifically, which is used widely by LTs, the error message is: # runtime/cgo /repo/yingjieb/ms/buildroot/output/host/opt/ext-toolchain/bin/../lib/gcc/mips64-octeon-linux-gnu/4.7.0/../../../../mips64-octeon-linux-gnu/bin/ld: skipping incompatible /repo/yingjieb/ms/buildroot/output/host/mips64-buildroot-linux-gnu/sysroot/usr/lib/libpthread.so when searching for -lpthread /repo/yingjieb/ms/buildroot/output/host/mips64-buildroot-linux-gnu/sysroot/usr/lib/libgcc_s.so: could not read symbols: File in wrong format collect2: error: ld returned 1 exit status go tool dist: FAILED: /repo/yingjieb/ms/buildroot/output/build/host-go-1.11.6/pkg/tool/linux_amd64/go_bootstrap install -gcflags=all= -ldflags=all= -v std cmd: exit status 2 Cgo use gcc compiler cgo enables go packages call C code, so it must require a C compiler for the C code part. And we are in embedded world, so here we need a cross C compiler. Gc go make.bash uses CC_FOR_TARGET to specify the C compiler, on my environment, for example: CC_FOR_TARGET=\"/repo/yingjieb/ms/buildroot/output/host/bin/mips64-octeon-linux-gnu-gcc\" In fact, this toolchain is a wrapper executable, which wraps external gcc toolchain to generate n32 ABI objects, like this: ELF 32-bit MSB executable, MIPS, N32 MIPS64 rel2 version 1, dynamically linked (uses shared libs), for GNU/Linux 2.6.32, with unknown capability 0x41000000 = 0xf676e75, with unknown capability 0x10000 = 0x70401, not stripped The 64 bit N64 ABI allows for more arguments in registers for more efficient function calls when there are more than four parameters. There is also the N32 ABI which also allows for more arguments in registers. The return address when a function is called is stored in the $ra register automatically by use of the JAL (jump and link) or JALR (jump and link register) instructions. Basically, N32 uses 64 bit registers in a 32 bit address space, meaning that pointers are 32 bit. However, for some unknown reason, the actual output objects are N64 ABI: #cgo puts its generated C files to /tmp dir: yingjieb@FNSHA190 /tmp/go-build164444988/b032 $ ls _cgo_export.c _cgo_flags _cgo_main.c _x001.o _x003.o _x005.o _x007.o _x009.o cgo.cgo1.go _cgo_export.h _cgo_gotypes.go _cgo_main.o _x002.o _x004.o _x006.o _x008.o _x010.o cgo.cgo2.c # the default ABI is N64 yingjieb@FNSHA190 /tmp/go-build164444988/b032 $ file _cgo_main.o _cgo_main.o: ELF 64-bit MSB relocatable, MIPS, MIPS64 rel2 version 1 (SYSV), with unknown capability 0x410000000f676e75 = 0x1000000070401, not stripped The reason maybe that Gcc toolchain uses N64 ABI by default to generates objects. One can explicitly set -mabi=n32 to CFLAGS, that's how we config buildroot to use N32 ABI for our MIPS octeon family boards. direct cgo to use N32 ABI So, let's get back to the cgo compiling issue, basically, ld complains about the format of the to be linked shared objects are incompatible. We can direct cgo to generate N32 ABI object. Add below to src/runtime/cgo/cgo.go#cgo mips64 CFLAGS: -mabi=n32 #cgo mips64 LDFLAGS: -Wl,-m,elf32btsmipn32 Do export CGO_LDFLAGS_ALLOW=\".*\" before building go package Let's compile it again... This time the previous errors are gone, but we have new errors now: # runtime/cgo In file included from _cgo_export.c:4:0: cgo-gcc-export-header-prolog:25:14: error: size of array '_check_for_64_bit_pointer_matching_GoInt' is negative _cgo_export.c is an generated c file, located in /tmp/go-buildxxxxxxxxx where xxxxxxxxx is a random number generated by the build system, so as _cgo_export.h, which has the assertion: typedef GoInt64 GoInt; /* static assertion to make sure the file is being used on architecture at least with matching size of GoInt. */ typedef char _check_for_64_bit_pointer_matching_GoInt[sizeof(void*)==64/8 ? 1:-1]; src/cmd/cgo/out.go is used to genertate _cgo_export.h: It seems that cgo expects a goInt to be 64 bit, but N32's pointer is 32 bit, that's why we have the error message. Disable the check temporally: //typedef char _check_for_GOINTBITS_bit_pointer_matching_GoInt[sizeof(void*)==GOINTBITS/8 ? 1:-1]; #temporary workaroud this check typedef char _check_for_GOINTBITS_bit_pointer_matching_GoInt[1]; Let's rebuild it... cgo build seems to pass, but after it we have more errors: # plugin /repo/yingjieb/ms/buildroot/output/host/mips64-buildroot-linux-gnu/sysroot/usr/lib/libdl.so: could not read symbols:File in wrong format # os/signal/internal/pty /repo/yingjieb/ms/buildroot/output/host/mips64-buildroot-linux-gnu/sysroot/usr/lib/libgcc_s.so: could not read symbols: File in wrong format # os/user /repo/yingjieb/ms/buildroot/output/host/mips64-buildroot-linux-gnu/sysroot/usr/lib/libgcc_s.so: could not read symbols: File in wrong format # net /repo/yingjieb/ms/buildroot/output/host/mips64-buildroot-linux-gnu/sysroot/usr/lib/libgcc_s.so: could not read symbols: File in wrong format Same issue, apply our changes to these files: src/plugin/plugin_dlopen.go src/os/signal/internal/pty/pty.go src/os/user/cgo_lookup_unix.go src/os/user/getgrouplist_unix.go src/os/user/listgroups_unix.go src/os/user/getgrouplist_darwin.go src/net/cgo_linux.go Rebuild, OK, then the error message leads to: /tmp/go-link-436592583/go.o: In function `runtime.save_g': /repo/yingjieb/ms/buildroot/output/host/lib/go/src/runtime/tls_mips64x.s:20:(.text+0x6d24c): relocation truncated to fit: R_MIPS_TLS_TPREL_LO16 against `runtime.tls_g' It seems to have come to the final stage to build the executable \"go\"(the go compiler), but apparently there is something wrong in tls_mips64x.s. The file is not long, but requires some longer study time to adapt for N32 mode if we still want to go this way... // If !iscgo, this is a no-op. // // NOTE: mcall() assumes this clobbers only R23 (REGTMP). TEXT runtime_save_g(SB),NOSPLIT|NOFRAME,$0-0 MOVB runtime_iscgo(SB), R23 BEQ R23, nocgo MOVV R3, R23 // save R3 MOVV g, runtime_tls_g(SB) // TLS relocation clobbers R3 MOVV R23, R3 // restore R3 nocgo: RET TEXT runtime_load_g(SB),NOSPLIT|NOFRAME,$0-0 MOVV runtime_tls_g(SB), g // TLS relocation clobbers R3 RET GLOBL runtime_tls_g(SB), TLSBSS, $8 There are high possibilities that other .s files need to be adapted. A rough estimation is: there are 505 .s files, with 446 line containing \"cgo\" key word together. yingjieb@FNSHA190 /repo/yingjieb/ms/buildroot/output/build/host-go-1.11.6/src $ find -name \"*.s\" | wc -l 505 yingjieb@FNSHA190 /repo/yingjieb/ms/buildroot/output/build/host-go-1.11.6/src $ find -name \"*.s\" | xargs cat | grep cgo | wc -l 446 So, enabling N32 ABI which is used by all our MIPS boards for Go is not something can be done in a short time. How to proceed if cgo is not working? As analyzed, the effort to resolve cgo problem is not trivial, right now what can be done are: disable cgo support add HOST_GO_CGO_ENABLED = 0 to package/go/go.mk, which means the gc go toolchian will not have cgo support, which further results the libraries that depend on cgo are not available. I am not an export of go, but I did a simple counter, there are 208 lines in the toolchain src use cgo. yingjieb@FNSHA190 /repo/yingjieb/ms/buildroot/output/build/host-go-1.11.6/src $ grep -r 'import \"C\"' | wc -l 208 use N64 ABI for MIPS64 What if cgo is the part of the heart of go toolchain and furthermore, is indispensable for most go apps? The other option we can consider is to use N64 ABI. N64 uses 64 bit registers and 64 bit address space. As said, all our MIPS boards use N32, I don't know exactly the reasons, but a common one would be: the old code are written for 32 bit processor, engineers at 32 bit era had the assumption that pointers are always 32 bit. This option remains to be investigated if decision made to go this way. hello.go Finally, we come to our task, thanks for the complicities of embedded world and weak ecosystem of MIPS. Now that we have the gc go toolchain built, yes, with cgo disabled. In Buildroot, we leverage the make framework to construct go packages, for example, I added below files: M package/Nokia/Config.in M package/go/Config.in.host M package/go/go.mk A package/Nokia/go-prototype/Config.in A package/Nokia/go-prototype/go-prototype.mk And I setup a repo named go-prototype, which has the hello.go src. Here I want to skip the details of how to create a package in Buildroot, which is basically to make a package that depends on package go(the gc go toolchain) OK, build our go-protogype package and all other packages selected in buildroot, make rootfs, and load to our board. Be noted that our hello.go doesn't need cgo, since it does not import \"C\" Then on our board, I am using cfnt-b, which has the same CPU with fglt-b: Type /isam/slot_default/run # hello Hello, World! First go program on cfnt-b! /isam/slot_default/run # which hello /usr/bin/hello /isam/slot_default/run # ls -lh /usr/bin/hello -rwxr-xr-x 1 root root 1.4M Jun 28 2019 /usr/bin/hello OK, we are good to run hello.go Works next run Go simple function with library(with the hope that cgo is not used) Go benchmarking research and selection(with the hope that cgo is not used) Benchmark go(with the hope that cgo is not used) investigate how to enable N64 ABI for MIPS(optional) "},"notes/golang_go_on_mips_part2.html":{"url":"notes/golang_go_on_mips_part2.html","title":"part 2: build native go compiler","keywords":"","body":" Background Native compilation of go src board prerequisites set up Gentoo linux environment build gc go toolchain hello.go and cgotest.go Works next Background In previous article go on mips board part 1, we have set up a go cross compiler and by using of buildroot go package frame work, we added a go-prototype package in buildroot and we are able to generate go \"hello\" executable running on MIPS board cfnt-b. For simple \"hello\" go executable, it is fine. However, Cgo is not supported. The MIPS N32 ABI we are always using for our MIPS board does not seem to support Cgo, see \"Cgo issue\" in go on mips board part 1, hence it prevents us from running go packages that call C code, which is the case that vOnuMgmt expects, according to vOnuMgmt expert. So, What should we do? The errors are link time errors, ld complains about the format of the to be linked shared objects are incompatible. In the end of that article, I proposed to try MIPS N64 ABI. However, in buildroot, one can select \"Target ABI\" to either n32 or n64, but not both. If we use n64 ABI, there will be no lib32 support, for example, no n32 glibc is there which is the corner stone of the 32bit isam applications. The possible options to support N64 ABI: change the whole world from N32 ABI completely to N64 ABI: a fundamental change, big impact, think about Android or ios switching from 32 bit to 64 bit. in buildroot, implement \"multilib\" which supports both N32 and N64, let go packages use n64, everything else use n32: smaller impact, but consuming considerablelly more rootfs size since lib64 will also need to be copied to target rootfs.#toolchain-external-custom/mips64-octeon-linux-gnu/sys-root $ du -sh lib32 lib32-fp lib64 lib64-fp 50M lib32 25M lib32-fp 60M lib64 30M lib64-fp The second option is preferred, but we need more work to investigate the effort. There is indeed another prospect in which we can build go natively on the board, see below... But please note that this approach is for prototype go only for performance evaluation, because it leverages a totally different root filesystem, much larger but has the ability to native build go packages compared to buildroot root filesystem. We will also need to explore more feasible method to build go packages if go performance is accetable on MIPS boards. Native compilation of go src board prerequisites To be able to compile go natively, the board should have: native gcc toolchian: used to compile Cgo go bootstrap: used to build go toolchain It is not the intention of buildroot to have the ablitiy to generate a gcc toolchain for the target board, all it is about is cross compilation. And building a Gcc toolchain is not even an easy task for people working on X86 PC/Server environment, since lots of dependency packages need to install in order to get Gcc toolchain built, let alone we are on a embedded busybox based system. So we need a basic system that can provide minimal development environment, for MIPS in particular. Fortunately, there is one available(maybe one only for MIPS): Gentoo Linux set up Gentoo linux environment I am skipping some details about how to setup the Gentoo Linux environment as it is less relevant to our go topic. So here I just list key points. Gentoo linux base rootfs is a prebuilt rootfs, with size about 2G, so I put it on my PC and let board mount it over nfs. Let board boot to the default Linux environment, and then chroot to Gentoo Linux. chroot let us switch into Gentoo Linux as if it is the root filesystem build gc go toolchain To build a gc go toolchain on the board, following steps are required: build go1.12 toolchain on X86 first on X86, use the go1.12 toolchain to build bootstrap toolchain for MIPS64 copy go bootstrap toolchain for MIPS64 to board use that bootstrap toolchain to build go1.12 toolchain The reason we need 4 steps is go toolchain is written in go, so in order to build go toolchain, we need go bootstrap toolchain, which is go1.4, only X86 can build that toolchain. hello.go and cgotest.go OK, now we have native go toolchain, let's compile and run some go programs: root@yingjieb-VirtualBox ~/work/nfsroot/mipsroot.go.ok/root Linux Mint 19.1 Tessa # cat hello.go package main import \"fmt\" func main() { fmt.Println(\"Hello, World!\") fmt.Println(\"First go program on cfnt-b!\") } root@yingjieb-VirtualBox ~/work/nfsroot/mipsroot.go.ok/root Linux Mint 19.1 Tessa # cat cgotest.go package main //int Add(int a, int b){ // return a+b; //} import \"C\" import \"fmt\" func main() { a := C.int(10) b := C.int(20) c := C.Add(a, b) fmt.Println(c) // 30 } The go programs run as expected. Works next go program with libraries: hello.go is too simple, we need to run a real world go program that uses more libraries, to see if running them on MIPS board has any problems. general benchmarks: for example, lmbench. This is to see how general performance looks like compared to X86. go basic performance compress: tar/zip/bzip2/flate structures: heap/list/ring algorithm: sort/string crypto: aes/des/dsa/md5/sha256 encoding: csv/json/xml image: gif/jpeg/png net: http/socket more complicated go benchmarks. "},"notes/golang_go_on_mips_part3.html":{"url":"notes/golang_go_on_mips_part3.html","title":"part 3: gccgo experiments","keywords":"","body":" What is gccgo Current gcc used by MIPS boards doesn't compile go Build gcc toolchain to support go gcc toolchain needs to be rebuild to support go build gcc toolchain natively on X86 use gccgo C Interoperability Gcc version requirement Conclusion What is gccgo The gccgo compiler is a new frontend for GCC, the widely used GNU compiler. refer to: https://golang.org/doc/install/gccgo Current gcc used by MIPS boards doesn't compile go Build gcc toolchain to support go gcc toolchain needs to be rebuild to support go Building gccgo is just like building GCC with one or two additional options. See the instructions on the gcc web site. When you run configure, add the option --enable-languages=c,c++,go (along with other languages you may want to build). build gcc toolchain natively on X86 gccgo is another branch of gcc, called branches/gccgo: svn checkout svn://gcc.gnu.org/svn/gcc/branches/gccgo gccgo mkdir objdir cd objdir ../gccgo/configure --prefix=/opt/gccgo --enable-languages=c,c++,go --with-ld=/opt/gold/bin/ld make make install use gccgo gccgo -c file.go gccgo -o file file.o C Interoperability When using gccgo there is limited interoperability with C, or with C++ code compiled using extern \"C\". refer to: https://golang.org/doc/install/gccgo#C_Interoperability Gcc version requirement The GCC 4.7.1 release and all later 4.7 releases include a complete Go 1 compiler and libraries. The GCC 4.9 releases include a complete Go 1.2 implementation. The GCC 5 releases include a complete implementation of the Go 1.4 user libraries. The GCC 6 releases include a complete implementation of the Go 1.6.1 user libraries. The GCC 7 releases include a complete implementation of the Go 1.8.1 user libraries. The GCC 8 releases are expected to include a complete implementation of the Go 1.10 release Conclusion Gcc toolchain was compiled and generated by vendors, and by default made without go language support. Current gcc toolchain is provided by Marvell(Cavium), which doesn't support go. gcc version is 4.7.0, which can not support Go 1.0 the toolchain was not compiled with Go language support. To be able to use gcc to compile go code, we need vendor to provide cross gcc toolchain, which must meet 2 prerequisites: with additional go language enabled: add --enable-languages=c,c++,go when compiling the toolchain. better to be Gcc 8, Gcc 7 only supports Go 1.8 "},"notes/golang_go_on_mips_part4.html":{"url":"notes/golang_go_on_mips_part4.html","title":"part 4: json performance","keywords":"","body":" Background Single core performance methodology Multi-core performance methodology Devices under test Take goroutine into account Json performance X86 vs MIPS comparison run official json benchmark the result Writing test code for C vs Go comparision compile and run the benchmark on MIPS board runtime status result Overall observation Background There are many factors that impact the performance of a workload under test: On hardware wise, what is the CPU arch being used(X86, MIPS, ARM…), how is the Cache system like(L1 L2 L3), how many DDR controllers on the system, and how much memory a system has? what is the storage subsystem(SSD, NVME, or distributed storage system), what is the network subsystem(1G, 10G, 25G, which NIC being used?)… On software wise, what is the kernel and root file system? How is the software configured? Is it a single thread app or in multi thread mode? What is the contention model if it is multi-threaded? The factors are too many and any one of them could have big impact on the performance. However, there are indeed methodologies based on experience and practice that could direct the evaluation task of a given workload requirement. Single core performance methodology Generally, unlike multi-thread workloads, single thread app does not involve contentions with other threads that share same resources, which avoids the complicities of lock contention, waiting or sleeping on a resource to be available, or cache coherence issue, etc. A typical example is MySQL, which uses many threads that may access the same row or column of a table. So it is in practice more reliable to use single thread mode to do the benchmark. Multi-core performance methodology As said, multi-core introduces more complicities which are all about contention for shared resources, what resources are shared across multiple cores depends on the given workload. For example, if the target workload has multiple threads that shares a critical memory area, there will be a lock to protect the access to the shared memory, which may result in thread being scheduled out, which will hurt the performance.Even if the target workload is designed to be scale-out, say not using locks, its many threads are running independently sharing nothing from software perspective, that is not often the case in real world, but even it is, the cumulative performance may still not be scaled, that's because the cores actually share hardware buses, like cache bandwidth, ddr bandwidth… So for multi-core performance , we should check the scalability of cores 2 4 6 8…, usually by using taskset to bind the tasks to different cores. Devices under test From hardware perspective, which factor is more important for a given workload? That depends on the nature of the selected test app: For compute intensive workloads, CPU micro architecture(multi-issue, OOO, branch predictor…), frequency(base and turbo), L1 L2 cache are the most important factors. For memory intensive workloads, L3 cache and DDR bandwidth sometimes are more important. For IO intensive workloads, normally CPU is not the problem, but the key is how fast the IO subsystem can be, multi-queue technology is often used to improve the IO performance to make better use of a multi-core system. Most real world workloads are a mix type of the above 3 types, typically a server app waits for network IO to receive requests, the requests go through Kernel TCP/IP stack and then are delivered to app to process, the app invokes \"compute\" functions that normally use in memory data structures, and corresponding algorithm to do the real job. The real job part is often compute and memory intensive, depends on how fast the requests come and wait in queues to be served. Therefor we will further focus on the \"real job\" part. It is usually about how fast the CPU processes the instructions and how fast the data can be retrieved from the cache and memory system. Below is the comparison of the CPU architecture that to be evaluated for json performance: Machine X86-laptop X86-workstation MIPS CPU Intel(R) Core(TM) i5-8350U Intel(R) Xeon(R) E7- 8837 Cavium Octeon III Freq 1.70GHz base/ turbo to 3.58GHz 2.67 GHz/ no turbo 1.2GHz/ no turbo Issue width 4 way 4 way 2 way Execution mode Out of Order Out of Order In Order SIMD AVX SSE SSE NONE Core # 4 32 4 L1 cache dcache 32K, icache 32K dcache 32K, icache 32K dcache 32K, icache 78K L2 cache 256K 256K 512k L3 cache 6M 24M NA DDR Channel # 1 uesd/ 2max ? Typical 4 1 Take goroutine into account We want to focus on single thread single core app, then expands a bit more to multi-thread, however it is fairly hard in Golang to do so, because Go has goroutines. Typically, Go runtime starts several threads on which go routines are scheduled to run by go runtime scheduler, go routines can be started by program by using go key word in your code, or can be started by go runtime like GC routines. For example, in json_load benchmark(detailed in the following sections): there are 6 threads, with 8 goroutines running on top of them. So in the rest of this article, I decide to run go programs in 2 methods: A. run with taskset -c 1 to force it running on 1 core B. free run the program, let go runtime to manage the threads. For X86 vs MIPS comparison, only run A method, as we want to know X86 single core VS MIPS single core. For Go vs C comparison, we focuse on B method, and we also look at A method. Json performance X86 vs MIPS comparison I am using built-in json benchmark. run official json benchmark Gc go toolchain has a test framework that all of its packages have built-in tests, encoding/json as the \"official\" json parser also follows the principle, there are many sub-tests of test and benchmarking.The benchmark takes the input test.json file, and test many operations on the data: encoding, decoding…. The input file test.json is a complicated recursive json file, with 1.9M size. We want ro run it in single core, so: taskset -c 1 ./jsontest -test.bench .* The run time snapshot is something looks like this: 1 core running nearly 100% in user space. The behavior is the same on MIPS, so we can make sure the comparison is apple to apple. the result Writing test code for C vs Go comparision Now that we have a roughly idea of how much slower MIPS than X86 running json in Go, that's may be a reference of the performance loss about running OnuMgmt on the cloud VS on the device. But since we will eventually have our code running on the device, for LT board it is MIPS, regardless what code it is, Go or C/C++… So we got to know what is the performance comparison of Go VS C? There are indeed some programing language comparison data on the internet: some good references are: Go java python lua C/C++ Go vs C++ Go vs python I've got the feeling that Go is a bit slower than C/C++, but much much faster than python. It is all about on X86, then how about on MIPS? So we decided to write a simple json benchmark and run it on our MIPS board. We reuse the input json file test.json, what the simple benchmark does is it opens and reads the json file, parsing json into its internal in memory data structures, and then converts the data structures back to json strings, and outputs back to stdout. For C implementation, we use libjansson which is used by reborn platform widely for json parsing. For Go implementation, we use official encoding/json package in GC go toolchain. When benchmarking, run the program enough times and count the time spent as the performance index. compile and run the benchmark on MIPS board For C implementation, we need libjansson #install libjansson, we are on Gentoo linux, we use emerge #for X86, it is 'apt install libjansson-dev' emerge -av dev-libs/jansson #compile, into a.out gcc -O2 json_load.c -ljansson #benchmark it time ./a.out test.json 100 > /dev/null For Go implementation, no other package needed. #compile go build json_load.go #run, Go run time will automatically starts several threads time ./json_load -fileName test.json -loopNum 100 > /dev/null #force single core taskset -c 1 time ./json_load -fileName test.json -loopNum 100 > /dev/null runtime status There are 6 threads(starts with M), with 8 goroutines(starts with G) running on top of them. P represents Processor on the system. json_load is a simple benchmark that has no awareness that it is multi-threaded, in the above 8 goroutines(sometimes more depends on the runtime), there is only one that does the \"user\" work: encoding and decoding the json file. The runtime resource comparison shows that Go has more memory footprint than C, which is nearly triple in huge json file case, while in the small json file case, C only requires 412K on MIPS, that says the json parsing itself is not memory consuming, but Go requires additional memory for its runtime managed data and thus consumes 6772K. Go also has higher CPU usage, also because Go has runtime scheduler and Gc routines running together with the \"user\" routine. The CPU overhead on MIPS is considerably higher than X86. I would say the extra static size and about 30% of a single core overhead is the Go \"tax\" to use this modern programming language on MIPS. result Overall observation For Go builtin json test, MIPS is roughly 7 times slower than X86 @ real frequency For Go builtin json test, MIPS is roughly 3 times slower than X86 @ 1GHz frequency, by calculation For json parsing test between C and Go X86 go json package is highly optimized, even faster than C implementation libjansson MIPS go json package is less optimized, but still on par with C:libjansson "},"notes/golang_gentoo_on_mips_board_and_build_go.html":{"url":"notes/golang_gentoo_on_mips_board_and_build_go.html","title":"Gentoo on mips board and build go","keywords":"","body":" 准备环境 chroot 更新Gentoo build go toolchain 先在x86上build bootstrap for mips 后在板子上编译go toolchain hello.go 和 cgotest.go go env 截图 准备环境 从以下地址下载stage3: 2014是最后更新的, 说明mips已经5年没人更新了. http://distfiles.gentoo.org/experimental/mips/stages/mips64/2014 git clone portage库 https://anongit.gentoo.org/git/repo/gentoo.git #在mint虚拟机上, 打开相关服务和转发 sudo sysctl -w net.ipv4.ip_forward=1 sudo iptables -t nat -A POSTROUTING -j MASQUERADE -s 192.168.2.12/32 -o enp0s10 cat /etc/exports /home/yingjieb/work 192.168.2.0/24(rw,sync,insecure,no_subtree_check,no_root_squash,fsid=0) sudo systemctl start nfs-kernel-server.service #用root操作 sudo -s cd ~/work/nfsroot mkdir mipsroot tar xvf stage3-mips64_multilib-20140904.tar.bz2 -C mipsroot #把portage库拷到usr/portage, 带.git一起拷, 后面还要操作 cp -a gentoo.git mipsroot/usr/portage #到mipsroot目录下操作, 这也是板子的rootfs cd mipsroot 板子起到linux, 配好网络 #板子上操作, 192.168.2.11是mint的ip, 直连的 ifconfig agl0 192.168.2.12 up ifconfig eth-mgnt 192.168.2.12 up route add default gw 192.168.2.11 /etc/init.d/S50dropbear start #mount nfs4 mkdir -p /root/remote mount -t nfs4 192.168.2.11:nfsroot/mipsroot /root/remote -o nolock //nfsv4 mount 192.168.2.11:/home/yingjieb/work/nfsroot/mipsroot /root/remote -o nolock //nfsv3是这么写 #准备chroot mount /dev/pts -o remount,gid=5 ln -s /proc/self/fd /dev/fd cd /root #mount mount -o bind /dev remote/dev mount -o bind /dev/pts remote/dev/pts mount -o bind /proc remote/proc mount -o bind /sys remote/sys mount -o bind /run remote/run #umount umount remote/dev/pts umount remote/dev umount remote/proc umount remote/sys umount remote/run umount remote chroot #最好ssh到板子操作 ssh root@192.168.2.12 chroot remote /bin/bash #一次性操作 #网络 ping 135.245.48.34 route add default gw 192.168.2.11 echo \"nameserver 172.24.213.251\" > /etc/resolv.conf #时间 date -s 20190705 #profile, 重要 cd /etc/portage ln -sf ../../usr/portage/profiles/default/linux/mips/13.0/multilib/n64 make.profile #一般操作 export http_proxy=\"http://135.245.48.34:8000\" export https_proxy=$http_proxy export ftp_proxy=$http_proxy export rsync_proxy=$http_proxy # gentoo使用 #留core0跑网络 taskset -c 1,2,3 emerge -avtuDN @world 更新Gentoo #etc/portage/make.conf GENTOO_MIRRORS=\"http://distfiles.gentoo.org/ http://bbgentoo.ilb.ru/\" build go toolchain git clone go的源码: git clone https://go.googlesource.com/go go的toolchain编译包括两步: 先用go1.4编bootstrap 用bootstrap再编go高版本的编译器 这么做的原因是, go1.4是c写的, 以后的高版本编译器是go写的. 要编译 >1.4版本的编译器, 先要有go1.4编译器. 先在x86上build bootstrap for mips 在mint机器上, 先编译go1.4 git clone https://go.googlesource.com/go $HOME/go1.4 cd $HOME/go1.4/src git checkout release-branch.go1.4 ./make.bash 再编译go1.12, 这个版本支持生成cross toolchain git clone https://go.googlesource.com/go $HOME/go cd $HOME/go/src git checkout release-branch.go1.12 env GOROOT_BOOTSTRAP=$HOME/go1.4 ./make.bash 用go1.12编译target上的boot strap toolchain #还是go1.12目录 cd $HOME/go/src env GOOS=linux GOARCH=mips64 ./bootstrap.bash #成功后, 会生成一个目录和一个压缩包 go-linux-mips64-bootstrap go-linux-mips64-bootstrap.tbz 后在板子上编译go toolchain 拷贝go-linux-mips64-bootstrap.tbz到板子上, 并解压 注意: cgo默认开启, 但需要板子上有gcc工具链, 以支持cgo #正常应该git clone https://go.googlesource.com/go #但我是在板子上, 没有git; 所以直接用nfs共享的 #cd到go 1.12源码go-mips64 cd go-mips64/src #编译go 1.12 for mips64 #all.bash会做test, 有功能和性能的测试 env GOROOT_BOOTSTRAP=/root/go-linux-mips64-bootstrap ./all.bash isam-reborn src # env GOROOT_BOOTSTRAP=/root/go-linux-mips64-bootstrap ./all.bash Building Go cmd/dist using /root/go-linux-mips64-bootstrap. Building Go toolchain1 using /root/go-linux-mips64-bootstrap. Building Go bootstrap cmd/go (go_bootstrap) using Go toolchain1. Building Go toolchain2 using go_bootstrap and Go toolchain1. Building Go toolchain3 using go_bootstrap and Go toolchain2. Building packages and commands for linux/mips64. hello.go 和 cgotest.go root@yingjieb-VirtualBox ~/work/nfsroot/mipsroot.go.ok/root Linux Mint 19.1 Tessa # cat hello.go package main import \"fmt\" func main() { fmt.Println(\"Hello, World!\") fmt.Println(\"First go program on cfnt-b!\") } root@yingjieb-VirtualBox ~/work/nfsroot/mipsroot.go.ok/root Linux Mint 19.1 Tessa # cat cgotest.go package main //int Add(int a, int b){ // return a+b; //} import \"C\" import \"fmt\" func main() { a := C.int(10) b := C.int(20) c := C.Add(a, b) fmt.Println(c) // 30 } go env Linux Mint 19.1 Tessa # ls bin go-linux-mips64 go-linux-mips64-bootstrap go-linux-mips64-bootstrap.tbz src isam-reborn ~ # go env GOARCH=\"mips64\" GOBIN=\"\" GOCACHE=\"/root/.cache/go-build\" GOEXE=\"\" GOFLAGS=\"\" GOHOSTARCH=\"mips64\" GOHOSTOS=\"linux\" GOOS=\"linux\" GOPATH=\"/root\" GOPROXY=\"\" GORACE=\"\" GOROOT=\"/root/go-linux-mips64\" GOTMPDIR=\"\" GOTOOLDIR=\"/root/go-linux-mips64/pkg/tool/linux_mips64\" GCCGO=\"gccgo\" GOMIPS64=\"hardfloat\" CC=\"gcc\" CXX=\"g++\" CGO_ENABLED=\"1\" GOMOD=\"\" CGO_CFLAGS=\"-g -O2\" CGO_CPPFLAGS=\"\" CGO_CXXFLAGS=\"-g -O2\" CGO_FFLAGS=\"-g -O2\" CGO_LDFLAGS=\"-g -O2\" PKG_CONFIG=\"pkg-config\" GOGCCFLAGS=\"-fPIC -mabi=64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build357009098=/tmp/go-build -gno-record-gcc-switches\" 截图 参考: https://dave.cheney.net/2015/10/16/bootstrapping-go-1-5-on-non-intel-platforms https://golang.org/doc/install/source https://golang.org/cmd/cgo/ "},"notes/golang_micro.html":{"url":"notes/golang_micro.html","title":"go-micro和micro","keywords":"","body":" micro server命令流程 makefile main.go cmd 顶层Action server子命令 log ./micro service api执行流程 service命令入口, 代码在cmd/service/service.go api命令入口 总结 urfave的cli使用 新版micro搭建blog服务 建立运行环境 新建posts 服务 写main.go 写handler.go 增加save功能 新版micro 依赖 要先启动server, 再login上去 micro server会默认启动一些服务 run hello world service 调用hello world服务 cli方式 rest API方式 自己写个client 总结 新建service 使用micro new新建个工程 storage服务 每个service都有自己的table 用update命令重新run一个服务 内置config命令 更新2021.6.18 分叉 v2-to-v3-upgrade-guide v3版本也是搞micro run这一套 go micro的网络设计理念 更新2020.11 介绍 框架 服务发现 异步消息 消息编码 其他接口 使用micro模板 生成工程模板代码 安装依赖 运行工程 micro server命令流程 makefile micro的makefile很简单 build: go build -a -installsuffix cgo -ldflags \"-s -w ${LDFLAGS}\" -o $(NAME) 会展开成 $ make build go build -a -installsuffix cgo -ldflags \"-s -w -X github.com/micro/micro/v3/cmd.BuildDate=1624082635 -X github.com/micro/micro/v3/cmd.GitCommit=870f80e7 -X github.com/micro/micro/v3/cmd.GitTag=v3.3.0\" -o micro 注: -a是强制所有包都重编 -ldflags \"-X ...这一堆是给包的\"全局变量\"赋值 main.go main.go的思路和gshellos building很像 通过import的package的init函数来注册, main里面只调用cmd.Run() package main //go:generate ./scripts/generate.sh import ( \"github.com/micro/micro/v3/cmd\" // load packages so they can register commands _ \"github.com/micro/micro/v3/cmd/cli\" _ \"github.com/micro/micro/v3/cmd/server\" _ \"github.com/micro/micro/v3/cmd/service\" _ \"github.com/micro/micro/v3/cmd/usage\" ) func main() { cmd.Run() } 注: go generate命令是独立的, go build不会默认先调用go generate. 之所以这里在makefile里面没有调用go generate命令, 可能是因为生成代码这个步骤是开发者手动完成的 cmd 使用了urfave的cli框架 urfave的cli框架里, 命令是以树的形式组织的:子命令先注册到上级命令, 然后顶层命令的run函数, 会找到合适的子命令来run; 如果没找到, 就调用本层命令的Action函数. cmd包全局变量DefaultCmd Cmd = New()之后, 就调用DefaultCmd.Run()来开始命令行解析. 顶层Action 上面说过, 没有匹配的子命令的时候, 就调用本次的Action. 那么顶层的Action被调用到的时候, 说明用户输入的不是子命令, 按照micro的设计, 而是个自定义服务名. 这里的基本逻辑是查找这个服务名, 调用服务. server子命令 按照教程, 所有micro都要依赖micro服务. ./micro server 这个server是个子命令, 被注册到DefaultCmd的子命令列表中 command := &cli.Command{ Name: \"server\", Usage: \"Run the micro server\", Description: `Launching the micro server ('micro server') will enable one to connect to it by setting the appropriate Micro environment (see 'micro env' && 'micro env --help') commands.`, Flags: []cli.Flag{ &cli.StringFlag{ Name: \"address\", Usage: \"Set the micro server address :10001\", EnvVars: []string{\"MICRO_SERVER_ADDRESS\"}, }, &cli.StringFlag{ Name: \"image\", Usage: \"Set the micro server image\", EnvVars: []string{\"MICRO_SERVER_IMAGE\"}, Value: \"micro/micro:latest\", }, }, Action: func(ctx *cli.Context) error { Run(ctx) return nil }, } server的Action动作是启动如下服务 services = []string{ \"registry\", // :8000 \"broker\", // :8003 \"network\", // :8443 \"runtime\", // :8088 \"config\", // :8001 \"store\", // :8002 \"events\", // :unset \"auth\", // :8010 \"proxy\", // :8081 \"api\", // :8080 } 按照micro service [name]的形式, 注意这里的命令的关键词是service for 每个在上面services列表中的service { // all things run by the server are `micro service [name]` cmdArgs := []string{\"service\"} cmdArgs = append(cmdArgs, service) // runtime based on environment we run the service in args := []runtime.CreateOption{ runtime.WithCommand(os.Args[0]), runtime.WithArgs(cmdArgs...), runtime.WithEnv(env), runtime.WithPort(port), runtime.WithRetries(10), runtime.WithServiceAccount(\"micro\"), runtime.WithVolume(\"store-pvc\", \"/store\"), runtime.CreateImage(context.String(\"image\")), runtime.CreateNamespace(\"micro\"), runtime.WithSecret(\"MICRO_AUTH_PUBLIC_KEY\", auth.DefaultAuth.Options().PublicKey), runtime.WithSecret(\"MICRO_AUTH_PRIVATE_KEY\", auth.DefaultAuth.Options().PrivateKey), } // NOTE: we use Version right now to check for the latest release muService := &runtime.Service{Name: service, Version: \"latest\"} //真正的启动内置service runtimeServer.Create(muService, args...) } 这里有两种类型的runtime: local kubernetes 我们这里走的是local. local的Create函数在 service/runtime/local/local.go func (r *localRuntime) Create(resource runtime.Resource, opts ...runtime.CreateOption) error { 这个Create是个通用的接口, 可以新建比如namespace, NetworkPolicy, 也可以是Service // create new service service := newService(s, options) // 先建log文件, 一般在 /tmp/micro/logs/runtime.log f, err := os.OpenFile(logFile(service.Name), os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) // start the service err := service.Start() } 注意最后service.Start()是启动一个独立的进程, 这个进程运行了内置的service 这里执行的命令是:./micro service api p, err := s.Process.Fork(s.Exec) cmd := exec.Command(exe.Package.Path, exe.Args...) err := cmd.Start() log micro的log都放在/tmp/micro/logs var ( // The directory for logs to be output LogDir = filepath.Join(os.TempDir(), \"micro\", \"logs\") // The source directory where code lives SourceDir = filepath.Join(os.TempDir(), \"micro\", \"uploads\") ) 比如我的实际例子: $ ls /tmp/micro/logs/ api.log auth.log broker.log config.log events.log network.log proxy.log registry.log runtime.log store.log ./micro service api执行流程 service命令入口, 代码在cmd/service/service.go 命令行入口: 注意这个入口是在下级命令的情况下才会调用的. 所以我看了半天实际是执行不到的. : ( // Run starts a micro service sidecar to encapsulate any app func Run(ctx *ccli.Context) { // new service srv := service.New(opts...) // create new muxer // muxer := mux.New(name, p) // set the router srv.Server().Init( server.WithRouter(p), ) // run service srv.Run() } api命令入口 api命令的入口实际上是 var srvCommands = []srvCommand{ { Name: \"api\", Command: api.Run, Flags: api.Flags, }, ... } 对应代码: service/api/server/server.go 默认值就是这里的8080 var ( Name = \"api\" Address = \":8080\" Handler = \"meta\" Resolver = \"micro\" APIPath = \"/\" ProxyPath = \"/{service:[a-zA-Z0-9]+}\" Namespace = \"\" ACMEProvider = \"autocert\" ACMEChallengeProvider = \"cloudflare\" ACMECA = acme.LetsEncryptProductionCA ) api命令的入口就是: func Run(ctx *cli.Context) error { // initialise service srv := service.New(service.Name(Name)) // create a new api server with wrappers api := httpapi.NewServer(Address) // initialise api.Init(opts...) // register the handler api.Handle(\"/\", h) // Start API if err := api.Start(); err != nil { log.Fatal(err) } // Run server if err := srv.Run(); err != nil { log.Fatal(err) } // Stop API if err := api.Stop(); err != nil { log.Fatal(err) } } 我这里./micro server总是出错, 看log是因为: api这个服务的8080端口被占用了. 2021-06-20 05:20:44 file=server/server.go:341 level=fatal service=api listen tcp :8080: bind: address already in use 这个端口是写死的. 虽然有命令行参数可以改, 但是这个命令行是micro server传入写死的... 这似乎是个死局, 初非直接改代码. 解决办法很简单, 直接改个port: $ git diff diff --git a/service/api/server/server.go b/service/api/server/server.go index 2bcd7651..69f7f31a 100644 --- a/service/api/server/server.go +++ b/service/api/server/server.go @@ -39,7 +39,7 @@ import ( var ( Name = \"api\" - Address = \":8080\" + Address = \":18080\" Handler = \"meta\" Resolver = \"micro\" APIPath = \"/\" 总结 每个service都使用了micro的框架, 都以独立进程的形式存在. urfave的cli使用 注册的action会被调用: 比如 func Run(ctx *cli.Context) error { ... } ctx.String(\"server_name\"): 获取命令行的string类型的flag值 ctx.Bool(\"enable_acme\"): 类似的, 获取Bool类型的值 新版micro搭建blog服务 建立运行环境 先run micro server micro server 看看当前环境 $ micro env * local 127.0.0.1:8081 Local running micro server dev proxy.m3o.dev Cloud hosted development environment platform proxy.m3o.com Cloud hosted production environment 可能需要先运行micro env set local来建立local的环境 新建posts 服务 $ micro new posts $ ls posts Dockerfile Makefile README.md generate.go go.mod handler main.go proto 改proto先 syntax = \"proto3\"; package posts; service Posts { rpc Save(SaveRequest) returns (SaveResponse) {} rpc Query(QueryRequest) returns (QueryResponse) {} rpc Delete(DeleteRequest) returns (DeleteResponse) {} } message SaveRequest { string id = 1; string title = 2; string slug = 3; string content = 4; int64 timestamp = 5; repeated string tags = 6; } message SaveResponse { string id = 1; } message Post { string id = 1; string title = 2; string slug = 3; string content = 4; int64 created = 5; int64 updated = 6; string author = 7; repeated string tags = 8; } proto文件有一定的修改, 目的是让命令访问更简单点 不改的话是这样 micro posts save --post_title=Title --post_content=Content 这里想整成这样: micro posts save --title=Title --content=Content 然后make proto就可以生成代码了 写main.go package main import ( \"posts/handler\" \"github.com/micro/micro/v3/service\" \"github.com/micro/micro/v3/service/logger\" ) func main() { // Create the service srv := service.New( service.Name(\"posts\"), ) // Register Handler srv.Handle(handler.NewPosts()) // Run service if err := srv.Run(); err != nil { logger.Fatal(err) } } 写handler.go package handler import ( \"context\" \"time\" \"github.com/micro/dev/model\" \"github.com/micro/go-micro/errors\" \"github.com/micro/micro/v3/service/logger\" \"github.com/micro/micro/v3/service/store\" proto \"posts/proto\" \"github.com/gosimple/slug\" ) type Posts struct { db model.Model idIndex model.Index createdIndex model.Index slugIndex model.Index } func NewPosts() *Posts { createdIndex := model.ByEquality(\"created\") createdIndex.Order.Type = model.OrderTypeDesc slugIndex := model.ByEquality(\"slug\") idIndex := model.ByEquality(\"id\") idIndex.Order.Type = model.OrderTypeUnordered return &Posts{ db: model.New( store.DefaultStore, \"posts\", model.Indexes(slugIndex, createdIndex), &model.ModelOptions{ IdIndex: idIndex, }, ), createdIndex: createdIndex, slugIndex: slugIndex, idIndex: idIndex, } } 现在run这个服务micro run ., 能得到初步的输出 $ micro logs posts Starting [service] posts Server [grpc] Listening on [::]:53031 Registry [service] Registering node: posts-b36361ae-f2ae-48b0-add5-a8d4797508be 增加save功能 增加save函数 func (p *Posts) Save(ctx context.Context, req *proto.SaveRequest, rsp *proto.SaveResponse) error { logger.Info(\"Received Posts.Save request\") post := &proto.Post{ Id: req.Id, Title: req.Title, Content: req.Content, Slug: req.Slug, Created: time.Now().Unix(), } if req.Slug == \"\" { post.Slug = slug.Make(req.Title) } return p.db.Save(post) } 重新run micro update . micro posts save --id=1 --title=\"Post one\" --content=\"First saved post\" micro posts save --id=2 --title=\"Post two\" --content=\"Second saved post\" 新版micro 依赖 依赖protobuf go版本 # Download latest proto releaes # https://github.com/protocolbuffers/protobuf/releases go get github.com/golang/protobuf/protoc-gen-go go get github.com/micro/micro/v3/cmd/protoc-gen-micro 要先启动server, 再login上去 用户名密码是admin和micro micro server $ micro login Enter username: admin Enter password: Successfully logged in. micro server会默认启动一些服务 $ micro services api auth broker config events network proxy registry runtime server store run hello world service 在github.com/micro/services库中, 有很多\"官方\"写好的服务 比如我们要run个hello world micro run github.com/micro/services/helloworld 现在可以看看状态 $ micro status NAME VERSION SOURCE STATUS BUILD UPDATED METADATA helloworld latest github.com/micro/services/helloworld running n/a 4s ago owner=admin, group=micro 看看log $ micro logs helloworld 2020-10-06 17:52:21 file=service/service.go:195 level=info Starting [service] helloworld 2020-10-06 17:52:21 file=grpc/grpc.go:902 level=info Server [grpc] Listening on [::]:33975 2020-10-06 17:52:21 file=grpc/grpc.go:732 level=info Registry [service] Registering node: helloworld-67627b23-3336-4b92-a032-09d8d13ecf95 调用hello world服务 cli方式 还是使用micro命令来调用, 格式是micro [service] [method], 默认的method是call, 参数可以直接命令行传入 $ micro helloworld --name=Jane { \"msg\": \"Hello Jane\" } 查询这个服务能提供什么服务: $ micro helloworld --help NAME: micro helloworld VERSION: latest USAGE: micro helloworld [command] COMMANDS: call 要看call命令的子命令call的使用 $ micro helloworld call --help NAME: micro helloworld call USAGE: micro helloworld call [flags] FLAGS: --name string rest API方式 curl \"http://localhost:8080/helloworld?name=John\" 自己写个client 是个rpc模式的client 实际上这个client本身也是个\"service\"(使用service.New()得来) package main import ( \"context\" \"fmt\" \"time\" \"github.com/micro/micro/v3/service\" proto \"github.com/micro/services/helloworld/proto\" ) func main() { // create and initialise a new service srv := service.New() // create the proto client for helloworld client := proto.NewHelloworldService(\"helloworld\", srv.Client()) // call an endpoint on the service rsp, err := client.Call(context.Background(), &proto.Request{ Name: \"John\", }) if err != nil { fmt.Println(\"Error calling helloworld: \", err) return } // print the response fmt.Println(\"Response: \", rsp.Msg) // let's delay the process for exiting for reasons you'll see below time.Sleep(time.Second * 5) } run这个client: cd example && go mod init example micro run . run的时候不打印, 用status命令能看到 $ micro status NAME VERSION SOURCE STATUS BUILD UPDATED METADATA example latest example.tar.gz running n/a 2s ago owner=admin, group=micro helloworld latest github.com/micro/services/helloworld running n/a 5m59s ago owner=admin, group=micro 看log能够得到其output $ micro logs example # some go build output here Response: Hello John 总结 使用protobuf来封装message client也是service 新建service 使用micro new新建个工程 配套目录, proto定义, Makefile自动生成 $ micro new helloworld Creating service helloworld . ├── main.go ├── generate.go ├── handler │ └── helloworld.go ├── proto │ └── helloworld.proto ├── Dockerfile ├── Makefile ├── README.md ├── .gitignore └── go.mod download protoc zip packages (protoc-$VERSION-$PLATFORM.zip) and install: visit https://github.com/protocolbuffers/protobuf/releases download protobuf for micro: go get -u github.com/golang/protobuf/proto go get -u github.com/golang/protobuf/protoc-gen-go go get github.com/micro/micro/v3/cmd/protoc-gen-micro compile the proto file helloworld.proto: cd helloworld make proto 根据提示, 改了proto后, make proto来生成go代码 storage服务 没错, 永久存储被内置成了服务, 并配套了专有命令 写key value对$ micro store write key1 value1 读key$ micro store read key1 val1 $ micro store read -v key1 KEY VALUE EXPIRY key1 val1 None pattern读, -p选项$ micro store read --prefix --verbose key KEY VALUE EXPIRY key1 val1 None key2 val2 None 每个service都有自己的table 用--table指定table micro store write --table=example mykey \"Hi there\" 可以在client代码里读key package main import ( \"fmt\" \"time\" \"github.com/micro/micro/v3/service\" \"github.com/micro/micro/v3/service/store\" ) func main() { srv := service.New(service.Name(\"example\")) srv.Init() records, err := store.Read(\"mykey\") if err != nil { fmt.Println(\"Error reading from store: \", err) } if len(records) == 0 { fmt.Println(\"No records\") } for _, record := range records { fmt.Printf(\"key: %v, value: %v\\n\", record.Key, string(record.Value)) } time.Sleep(1 * time.Hour) } 用update命令重新run一个服务 比如之前已经在run的example服务(实际是hello world的client), 改了代码要重新run, 用 micro update . 使用最近代码重run 也可以先kill, 再run micro kill example micro run . 内置config命令 支持类似map式的set $ micro config set key val $ micro config get key val $ micro config set key.subkey val $ micro config get key.subkey val $ micro config get key {\"subkey\":\"val\"} $ micro config set key.othersubkey val2 $ micro config get key {\"othersubkey\":\"val2\",\"subkey\":\"val\"} 用client代码来获取config package main import ( \"fmt\" \"github.com/micro/micro/v3/service\" \"github.com/micro/micro/v3/service/config\" ) func main() { // setup the service srv := service.New(service.Name(\"example\")) srv.Init() // read config value val, _ := config.Get(\"key.subkey\") fmt.Println(\"Value of key.subkey: \", val.String(\"\")) } 更新2021.6.18 分叉 分叉为两个分支: https://github.com/micro/micro: 统一的库, 包括原go-micro(在micro/service目录下, 是原go-micro的拷贝) 这个版本使用了Polyform Shield许可证, 禁止和开源作者竞争 https://github.com/asim/go-micro: 原go-micro, 使用个人地址, 也是v3版本, 使用apache协议 已经没有github.com/micro/go-micro 地址了, 自动跳转到https://github.com/asim/go-micro 创始人(asim)两个库都在维护, 但更多的精力放在了另外一个库中:https://github.com/micro/services 官方的说法是v2-to-v3-upgrade-guide: go-micro已经\"now deprecated\", 由asim个人维护. v2-to-v3-upgrade-guide srv := micro.NewService( micro.Name(\"go.micro.service.foo\") ) 变为 srv := service.New( service.Name(\"foo\") ) v3版本也是搞micro run这一套 要先起个server: 使用命令micro server, 没有server的环境, 可以使用免费的M3O环境: micro env set platform go micro的网络设计理念 从Building a global services network using Go, QUIC and Micro看过来的. 更新2020.11 go micro换了地址 老地址:github.com/micro/go-micro 新地址:https://github.com/asim/nitro 访问老地址会自动跳到新地址 FAQ中说 go-micro重命名为Nitro, 现在由个人维护; 原组织github.com/micro现在加倍下注(doubling down)在Micro项目, 这个项目会集大成 License从Apache 2.0换到了Polyform Noncommercial go-plugins现在地址是github.com/asim/nitro-plugins, 虽然是Apache协议, 但用了Nitro, 所以也不能商用 Nitro的目标是不引入外部依赖, 外部依赖由Nitro Plugins解决. -- 纯框架 defualt的top level services初始化被移出了. 作者认为设置default初始化不好 cmd包也被移出了. 作者认为这部分代码引入了复杂的依赖代码.难于维护. 作者推荐使用google的生成依赖初始化项目wire 介绍见blog 不同于基于reflection的 Uber's dig and Facebook's inject, wire使用代码生成技术, 类似java的 Dagger 2 基本上是代码里声明依赖, 用go generate调用wire生成代码. 作者认为micro和nitro的区别是, 前者现在是大一统的方案, 目标是云; 后者是作者自己维护的框架, 目标是edge, IOT, 嵌入式等. 原来的go-micro开发怎么继续? 答: 使用Micro和m3o.com which starts as a purely free Dev environment in the cloud. go-micro v2还能用吗? 答: 可以. v2还是Apache许可证. import github.com/micro/go-micro/v2 github会自动重定向到https://github.com/asim/nitro 补充: Micro项目的License也换了. 但同样的, 可以用v2版本 介绍 本文介绍go的开源微服务框架https://github.com/micro/go-micro. 原文链接 Micro in Action, Part 2: An Ultimate Guide for Bootstrap Micro In Action, Part 3: Calling a Service Micro In Action, Part 4: Pub/Sub Micro In Action, Part 5: Message Broker Micro In Action, Part 6: Service Discovery Micro In Action, Part 7: Circuit Breaker & Rate Limiter Micro In Action, Coda: Distributed Cron Job The index page of Micro In Action Micro有两个库: go-micro 核心库. 典型的是用gRPC micro 辅助工具集, 比如工程模板生成, 运行状态检查, 微服务调用. 基于go-micro 还有一个重要库: go-plugins 自定义扩展, 比如提供了transport protocols的扩展选择. go-micro是plugin的思路, 不同的扩展可以自由组合. 框架 go-mirco对通用的分布式微服务做了interface抽象.其中service是核心, 负责协调其他interfaces 服务发现 服务发现定义为如下的interface, 只要实现了这些, 就能被框架使用. github.com/micro/go-micro/v2/registry/Registry // The registry provides an interface for service discovery // and an abstraction over varying implementations // {consul, etcd, zookeeper, ...} type Registry interface { Init(...Option) error Options() Options Register(*Service, ...RegisterOption) error Deregister(*Service) error GetService(string) ([]*Service, error) ListServices() ([]*Service, error) Watch(...WatchOption) (Watcher, error) String() string } 实际上, go-plugin库已经有很多实现了, 比如etcd/consul/zookeeper, 默认是多播DNS(mDNS), 不需要配置, 开箱即用. 异步消息 异步消息定义如下: github.com/micro/go-micro/v2/broker/Broker // Broker is an interface used for asynchronous messaging. type Broker interface { Init(...Option) error Options() Options Address() string Connect() error Disconnect() error Publish(topic string, m *Message, opts ...PublishOption) error Subscribe(topic string, h Handler, opts ...SubscribeOption) (Subscriber, error) String() string } 已经实现的broker有: RabbitMQ, Kafka, NSQ, 默认的使用http. 消息编码 github.com/micro/go-micro/v2/codec/Codec // Codec encodes/decodes various types of messages used within go-micro. // ReadHeader and ReadBody are called in pairs to read requests/responses // from the connection. Close is called when finished with the // connection. ReadBody may be called with a nil argument to force the // body to be read and discarded. type Codec interface { Reader Writer Close() error String() string } 目前有json bson msgpack等实现. 其他接口 Server， define the server of microservices Transport， defines the transport protocol Selector，abstracts logic of service selection. you can implement various load balancing strategies with this interface Wrapper，defines middleware which can wrap server/client request go-micro对微服务的抽象很\"正交\"(orthoganal), 比较全面. 使用micro模板 生成工程模板代码 下载micro工具 GO111MODULE=on go get github.com/micro/micro/v2@v2.4.0 创建一个模板工程 micro new --namespace=com.foo --gopath=false hello micro new, create a gRPC service by running the new sub-command of the micro command-line tool hello, specify the service name --namespace=com.foo, provide a namespace to the service --gopath=false, generate code into the current directory instead of $GOPATH (since Golang supports Go Module, new projects should be placed outside of $GOPATH) 命令执行完毕后, 在当前目录会创建工程代码: Creating service com.foo.srv.hello in hello . ├── main.go ├── generate.go ├── plugin.go ├── handler │ └── hello.go ├── subscriber │ └── hello.go ├── proto/hello │ └── hello.proto ├── Dockerfile ├── Makefile ├── README.md ├── .gitignore └── go.mod download protobuf for micro: brew install protobuf go get -u github.com/golang/protobuf/{proto,protoc-gen-go} go get -u github.com/micro/protoc-gen-micro/v2 compile the proto file hello.proto: cd hello protoc --proto_path=.:$GOPATH/src --go_out=. --micro_out=. proto/hello/hello.proto 注意到一个Makefile文件生成了 安装依赖 主要是安装protobuf # install protobuf brew install protobuf # install protoc-gen-go go get -u github.com/golang/protobuf/{proto,protoc-gen-go} # install protoc-gen-micro GO111MODULE=on go get -u github.com/micro/protoc-gen-micro/v2 protoc-gen-micro是protobuf的micro插件 注: protobuf项目的go版本现在转到: https://github.com/protocolbuffers/protobuf-go 之前是golang team维护的 https://github.com/golang/protobuf 运行工程 首先要get go-micro go get github.com/micro/go-micro/v2@v2.4.0 这样go.mod会是 module hello go 1.14 require github.com/micro/go-micro/v2 v2.4.0 运行 make build && ./hello-service 得到如下输出 make build && ./hello-serviceprotoc --proto_path=. --micro_out=Mgithub.com/micro/go-micro/api/proto/api.proto=github.com/micro/go-micro/v2/api/proto:. --go_out=Mgithub.com/micro/go-micro/api/proto/api.proto=github.com/micro/go-micro/v2/api/proto:. proto/hello/hello.protogo build -o hello-service *.go2020-04-02 11:12:47 level=info Starting [service] go.micro.service.hello 2020-04-02 11:12:47 level=info Server [grpc] Listening on [::]:53451 2020-04-02 11:12:47 level=info Broker [eats] Connected to [::]:53453 2020-04-02 11:12:47 level=info Registry [mdns] Registering node: go.micro.service.hello-063d6dae-826b-49f5-9141-df525af8a6b1 2020-04-02 11:12:47 level=info Subscribing to topic: go.micro.service.hello 这里make build会先用protoc编译.proto文件, 然后go build, 生成hello-service可执行程序. "},"notes/golang_微服务概念.html":{"url":"notes/golang_微服务概念.html","title":"微服务概念","keywords":"","body":" 传统的monolithic设计 微服务 微服务通信 API网关 调用service 服务发现 部分失效 微服务IPC 消息格式 微服务API 处理部分失效 本文是2015年5月, Nginx社区的一篇微服务介绍文章的阅读笔记. 原文链接 文章中假设你要从头设计一个打车的系统, 来和uber竞争 传统的monolithic设计 这个框架简单,单一形式部署容易. 绝大部分应用都是这个思路. 但随着软件的长期维护, 这个模式不好维护. 微服务 一个微服务单独开发和部署, 提供独特的功能. 通常使用容器化技术来部署. Each service has a well‑defined boundary in the form of an RPC‑ or message‑driven API. 好处是分而治之, 但加大了通信复杂性 微服务通信 一个client想使用某个服务, 它可以直接访问该微服务 Each microservice would have a public endpoint (https://_serviceName_.api.company.name). 但通常不这样做, 因为client也要关心和不同的微服务打交道, 也难适应变化. API网关 通常client通过API网关来访问微服务. Usually a much better approach is to use what is known as an API Gateway. An API Gateway is a server that is the single entry point into the system. It is similar to the Facade pattern from object‑oriented design. The API Gateway encapsulates the internal system architecture and provides an API that is tailored to each client. It might have other responsibilities such as authentication, monitoring, load balancing, caching, request shaping and management, and static response handling. The API Gateway is responsible for request routing, composition, and protocol translation. All requests from clients first go through the API Gateway. It then routes requests to the appropriate microservice. The API Gateway will often handle a request by invoking multiple microservices and aggregating the results. It can translate between web protocols such as HTTP and WebSocket and web‑unfriendly protocols that are used internally. 关键词: 包装内部服务对外呈现 鉴权 监控 负载均衡 缓存 请求整形 静态响应 请求转发, 响应聚合 调用service 两种风格来调用service: 异步消息. 比如基于massage broker的AMQP, 直接message通信的zeromq 同步调用. 比如RPC HTTP Thrift 通常一个系统中这两个风格都有. 服务发现 API gateway必须能访问Service Registry数据库. 部分失效 The API Gateway should never block indefinitely waiting for a downstream service. 微服务IPC There are the following kinds of one‑to‑one interactions: Request/response – A client makes a request to a service and waits for a response. The client expects the response to arrive in a timely fashion. In a thread‑based application, the thread that makes the request might even block while waiting. Notification (a.k.a. a one‑way request) – A client sends a request to a service but no reply is expected or sent. Request/async response – A client sends a request to a service, which replies asynchronously. The client does not block while waiting and is designed with the assumption that the response might not arrive for a while. There are the following kinds of one‑to‑many interactions: Publish/subscribe – A client publishes a notification message, which is consumed by zero or more interested services. Publish/async responses – A client publishes a request message, and then waits a certain amount of time for responses from interested services. 上面的图例中, trip management发现一个打车请求, 发new trip消息给dispatcher, dispatcher找到一个proposed drvier放到dispatching通道; driver和passenger同时得到通知. REQ-REP模式下, client发送请求, 阻塞等待响应. 在物联网界, 通常用RESTful API(基于HTTP), 这也是阻塞式的. Apache Thrift也是REQ-REP模式. 消息格式 两大类: text类和binery类 前者式json, xml等. 后者是GPB 微服务API API是合同, 但API也注定会变化. 在传统的monolithic模式下, api改了, 每个调用的地方改了就好了. 但微服务场景下, 没有强制手段要求所有的clients都来适配新的API. 所以API要兼容老的, 至少新API和老API都能同时支持. 处理部分失效 一个微服务可能因为故障或维护被down了, 那访问就会不可达. 有时候一个微服务负载太高, 响应很慢. 为了避免一个client因为server的故障而永远等待, 可以: 使用timeout机制 流控, 定义一个limit, 超过limit马上回复 定义一个error比例. 统计成功的请求和error的请求, 大于某个比例就视为服务失效. "},"notes/golang_yeagi.html":{"url":"notes/golang_yeagi.html","title":"解释器yeagi","keywords":"","body":" yeagi执行流程和损耗 先说数据 perf采样 binary topid yaegi topid 优化 interface wrapper 空指针引用panic 解决 reflect出现assignable错误 Methods can not be called by bin go embed和yaegi 嵌入scriptlib.go scriptlib是要解释执行的库 使用时 yaegi如何执行go语句 ast阶段 cfg阶段 run阶段 builtin数组里面, aCall和aCallSlice的action是call case callExpr里面callBin被当作快速路径? yaegi使用 Eval Stop脚本 bin函数执行时不能被cancel 怎么解决呢? 结果 题外 yaegi已知问题 脚本的结构体没有名字 yaegi执行过程 yaegi集成到gshell new 解释器 yaegi使用 编译运行 debug ast和cfg举例图 空敲回车 a := 100 s := \"hello world\" if slice import for range 函数定义 func call 使用例子 动态代码 解释器调用bin符号 -- 代码生成部分 go generate extract包 不用New的对象初始化 Extract方法 go/importer 和 go/types 模板替换 模板 替换结果举例 yaegi 背景知识 AST语法树 1+3*(4-1)+2 xml while for 为什么需要抽象语法树 函数 第一步：词法分析，也叫扫描scanner 第二步：语法分析，也称解析器 main 解释器 解释器调用bin里的符号 使用refect.Value.Call()的例子 查找bin 的method interp/run.go的call()函数 ast的node Eval ast函数 builtin预定义action cfg函数 frame类型 run函数 exec举例 总结 代码生成 REPL循环 EvalWithContext 总结 yeagi执行流程和损耗 同样的go代码topid, 解释执行和编译执行的性能分析和对比如下.原始代码在 https://github.com/godevsig/grepo 先说数据 两个程序做的事情一模一样 跑了一个小时, yaegi的topid实际占用79秒, 平均2.2% 同样一个小时, bin topid实际占用33秒, 平均0.9% 二者大概差两倍, 也就是说对这个case, 解释会增加100%的成本 perf采样 perf record -g -p 18149 -- sleep 60 perf script | /repo/yingjieb/FlameGraph/stackcollapse-perf.pl | /repo/yingjieb/FlameGraph/flamegraph.pl > topid.svg binary topid 实际干活是蓝色框 被pmu中断会算在进程时间里 yaegi topid yaegi的解释执行执行是个递归的过程, 具体来说就是interp.runCfg和interp.call.func6的递归 出现很多fmt.Fprintf和fmt.Sprintf是在递归打印进程信息. 这个过程要不断解释, 递归执行. 真正的printf只占很小比例, 很多时间花在了interp.runCfg和interp.call.func6的递归中, 即: 时间花在了\"解释\"代码而非\"执行\"代码 优化 尽量避免解释, 但又不要把太多\"应用逻辑\"塞到bin里. 目前来看, 如果showPidInfo解释起来成本稍高, 但如果是网络传输, appendProcessInfo函数应该好点. 结论就是保持现状, 不增加bin call api. interface wrapper yaegi对于带方法的iface, 都自动生成了一个interface wrapper 比如stdlib的flag.go: // _flag_Value is an interface wrapper for Value type type _flag_Value struct { IValue interface{} WSet func(a0 string) error WString func() string } func (W _flag_Value) Set(a0 string) error { return W.WSet(a0) } func (W _flag_Value) String() string { return W.WString() } 因为bin call不能直接认识解释模式下的类型定义, yaegi的做法是, 定义一个wrapper 结构体, 例如上面的_flag_Value, 这个结构体实现了规定的方法; 估计yaegi在解释的时候, 把需要满足该接口的类型(flag.Value), 包装成_flag_Value. 这样bin call就可以调用脚本的方法了. -- 注意, >描述的是eface(interface{})的处理, 因为fmt传入的是eface, fmt包里面断言其有String() string方法; 但yaegi没有办法把一个eface也包装, 所以不能输出aaaa -- 但这里, 是明确的带方法的iface, 那么yaegi就能wrap 这个iface 空指针引用panic 对应的应用代码 var pids pidValue func main() { flags := flag.NewFlagSet(\"\", flag.ContinueOnError) flags.SetOutput(os.Stdout) flags.Var(&pids, \"p\", \"process id. Multiple -p is supported, but -tree and -child are ignored (default -1)\") flags.BoolVar(&sf.memMB, \"MB\", false, \"show mem in MB (default in KB)\") ... if err = flags.Parse(args); err != nil { if err == flag.ErrHelp { err = nil } return err } } 上面的pid是自定义的满足falg.Value的接口: 注意我加了调试打印 type pidValue []int func (pids *pidValue) String() string { fmt.Println(\"===== string\") return \"[-1]\" } func (pids *pidValue) Set(value string) error { pid, err := strconv.Atoi(value) if err != nil { return err } *pids = append(*pids, pid) return nil } 解释: 首先, pidValue的String()方法能够被调用, 能打印\"===== string\"; 说明yaegi里面方法明确的iface方法是能够被调用的 代码在flags.Parse(args)里面panic 加-h打印help时出现panic 路径显示在flag.isZeroValue有空引用 runtime error: invalid memory address or nil pointer dereference flag.isZeroValue(0xc00028dd00, 0x0, 0x0, 0xc0000f7801) flag.(*FlagSet).PrintDefaults.func1(0xc00028dd00) 对应的代码isZeroValue()是在打印help的过程中被PrintDefaults()调用的: // isZeroValue determines whether the string represents the zero // value for a flag. func isZeroValue(flag *Flag, value string) bool { // Build a zero value of the flag's Value type, and see if the // result of calling its String method equals the value passed in. // This works unless the Value type is itself an interface type. typ := reflect.TypeOf(flag.Value) var z reflect.Value if typ.Kind() == reflect.Ptr { z = reflect.New(typ.Elem()) } else { z = reflect.Zero(typ) } return value == z.Interface().(Value).String() } 普通bool flag定义: flags.BoolVar(&sf.memMB, \"MB\", false, \"show mem in MB (default in KB)\")这个BoolVar对应到isZeroValue()的入参flag是:&flag.Flag{Name:\"MB\", Usage:\"show mem in MB (default in KB)\", Value:(*flag.boolValue)(0xc000728142), DefValue:\"false\"}显示其底层是*flag.boolValue类型. flag.Value iface定义:而flags.Var(&pids, \"p\", \"process id. Multiple -p is supported, but -tree and -child are ignored (default -1)\")因为func (f *FlagSet) Var(value Value, name string, usage string)函数要求value是flag.Value这个iface, 而pids是pidValue满足接口要求, yaegi就\"构造\"了一个wrapper:&flag.Flag{Name:\"p\", Usage:\"process id. Multiple -p is supported, but -tree and -child are ignored (default -1)\", Value:stdlib._flag_Value{IValue:(*[]int)(0xc000444ed0), WSet:(func(string) error)(0x4c5bc0), WString:(func() string)(0x4c5bc0)}, DefValue:\"\"}注意, 此时在isZeroValue()看来, 这个flag就是stdlib._flag_Value类型了但为什么会panic? 需要往下看:为了比较这个flag值是否为零值, z = reflect.Zero(typ)调用后, z的值为零值, 其Wstring方法也是nil:stdlib._flag_Value{IValue:interface {}(nil), WSet:(func(string) error)(nil), WString:(func() string)(nil)}那么在调用的时候, func (W _flag_Value) String() string { return W.WString() }就会引用nil, 从而产生panic 解决 我的解决办法是在代码生成模板里面加nil的check: We have interface wrapper that has funcion wrappers which may be nil in some cases, for example in stdlib flag.go type _flag_Value struct { IValue interface{} WSet func(a0 string) (r0 error) WString func() (r0 string) } WString can be nil in flag package calling PrintDefaults() in which isZeroValue() is called where String() is called on zero value: func isZeroValue(flag *Flag, value string) bool { ... z = reflect.Zero(typ) return value == z.Interface().(Value).String() } This causes runtime error: invalid memory address or nil pointer dereference because WString is nil: func (W _flag_Value) String() string { return W.WString() } The fix is adding a check before calling the func wrapper: func (W _flag_Value) String() (r0 string) { if W.WString == nil { return } return W.WString() } reflect出现assignable错误 出现错误: reflect.Set: value of type interface {} is not assignable to type interp.valueInterface 出错代码在: // messageOut represents a message to be sent type messageOut interface { isMessageOut() } var outputCh chan messageOut = make(chan messageOut, 30) select { case 这里的valueInterface在interp/run.go type valueInterface struct { node *node value reflect.Value } 看字面意思: interface{}的值不能赋值给interp.valueInterface 我理解应该是interp规定的interface在bin里可能是不认的. Methods can not be called by bin If a struct has String() string method, fmt.Printf will call this method in compiled go: type test struct { a int c string } func (t *test) String() string { return \"aaaa\" } func main() { fmt.Println(\"Hello, world!\") fmt.Printf(\"%v\\n\", &test{1, \"nihao\"}) } $ go run hello.go Hello, world! aaaa But gshell output: $ gsh exec hello.go Hello, world! {1 nihao} 说明在解释器模式下, fmt.Printf()是看不到test类型的任何方法的. 实际上, type定义的结构体其实是没有名字的, 这是reflect的限制, 用reflect只能产生匿名的结构体. go embed和yaegi 嵌入scriptlib.go import _ \"embed\" // embed libs //go:embed scriptlib/scriptlib.go var scriptlib string func (sh *shell) loadScriptLib() error { _, err := sh.Eval(scriptlib) if err != nil { return fmt.Errorf(\"load script libs error: %s\", err) } return nil } scriptlib是要解释执行的库 // Package scriptlib should be used as loadable scripts package scriptlib import ( \"fmt\" \"io\" \"net/http\" ) // HTTPGet gets file from url func HTTPGet(url string) ([]byte, error) { resp, err := http.Get(url) if err != nil { return nil, err } defer resp.Body.Close() if resp.StatusCode != 200 { return nil, fmt.Errorf(\"file not found: %d error\", resp.StatusCode) } body, err := io.ReadAll(resp.Body) if err != nil { return nil, err } return body, nil } 使用时 newShell以后, loadScriptLib就是sh.Eval(scriptlib), 就把embed的scriptlib.go解释编译了.v, err := crs.sh.Eval(\"scriptlib.HTTPGet\")就是把文本的符号scriptlib.HTTPGet解释成一个函数, 然后强制转换成native go能够执行的函数:crs.httpGet = v.Interface().(func(url string) ([]byte, error)) crs := &codeRepoSvc{sh: newShell(interp.Options{}), repoInfo: repoInfo} if err := crs.sh.loadScriptLib(); err != nil { return err } v, err := crs.sh.Eval(\"scriptlib.HTTPGet\") if err != nil { return err } crs.httpGet = v.Interface().(func(url string) ([]byte, error)) if err := s.Publish(\"codeRepo\", codeRepoKnownMsgs, as.OnNewStreamFunc(func(ctx as.Context) { ctx.SetContext(crs) }), ); err != nil { return err } yaegi如何执行go语句 ast阶段 // ast parses src string containing Go code and generates the corresponding AST. // The package name and the AST root node are returned. // The given name is used to set the filename of the relevant source file in the // interpreter's FileSet. func (interp *Interpreter) ast(src, name string, inc bool) (string, *node, error) switch nod.(type) case *ast.GoStmt: st.push(addChild(&root, anc, pos, goStmt, aNop), nod) cfg阶段 // cfg generates a control flow graph (CFG) from AST (wiring successors in AST) // and pre-compute frame sizes and indexes for all un-named (temporary) and named // variables. A list of nodes of init functions is returned. // Following this pass, the CFG is ready to run. func (interp *Interpreter) cfg(root *node, importPath, pkgName string) ([]*node, error) switch n.kind { case deferStmt, goStmt: wireChild(n) run阶段 builtin数组里面, aCall和aCallSlice的action是call func call(n *node) { goroutine := n.anc.kind == goStmt n.exec = func(f *frame) bltn { bf := value(f) if bf.IsValid() { // 如果是bin func if goroutine { go bf.Call(in) // go关键词, 起goroutine来调用bf.Call return tnext } out := bf.Call(in) // 直接调用bf.Call ... } //下面是脚本的func执行流程 nf := newFrame(anc, len(def.types), anc.runid()) // 先建立新frame if goroutine { go runCfg(def.child[3].start, nf, def, n) // goroutine执行函数体 return tnext } runCfg(def.child[3].start, nf, def, n) // 直接执行函数体 } runCfg()函数内部已经recover了panic, 但会再次触发panic, 这点不是我们想要的: func runCfg(n *node, f *frame, funcNode, callNode *node) { defer func() { f.mutex.Lock() f.recovered = recover() for _, val := range f.deferred { val[0].Call(val[1:]) } if f.recovered != nil { oNode := originalExecNode(n, exec) if oNode == nil { oNode = n } fmt.Fprintln(n.interp.stderr, oNode.cfgErrorf(\"panic\")) f.mutex.Unlock() panic(f.recovered) } f.mutex.Unlock() }() } 上面逻辑对应的调用栈: panic: test panic [recovered] //对应上面代码的recover panic: test panic //代码里再次panic github.com/traefik/yaegi/interp.runCfg.func1 //对应runCfg的defer执行的函数 panic github.com/traefik/yaegi/interp._panic.func1 //对应脚本里调用panic github.com/traefik/yaegi/interp.runCfg github.com/traefik/yaegi/interp.call.func6 所以: 脚本里调用的panic, 实际上是interp/run.go里的 func _panic(n *node) { value := genValue(n.child[1]) n.exec = func(f *frame) bltn { panic(value(f)) } } case callExpr里面callBin被当作快速路径? // ast阶段代码 case callExpr: case isBinCall(n): n.gen = callBin // Callbin calls a function from a bin import, accessible through reflect. func callBin(n *node) { case n.anc.kind == goStmt: // Execute function in a goroutine, discard results. n.exec = func(f *frame) bltn { in := make([]reflect.Value, l) for i, v := range values { in[i] = v(f) } go callFn(value(f), in) return tnext } } yaegi使用 Eval interp.Eval()可以认为默认是main包, 单独行的Eval()可以执行, 比如: i := interp.New(interp.Options{}) i.Use(stdlib.Symbols) i.Eval(`import \"fmt\"`) i.Eval(`fmt.Println(\"hello\")`) //会打印 hello 但如果待执行的字符串有import动作, 则\"独立\"的语句不执行: i.Eval(`import \"fmt\"; fmt.Println(\"hello\")`) //不会打印hello, 会有如下error _.go:1:28: expected declaration, found fmt 带import动作的脚本, 需要有main函数才能执行: i.Eval(`import \"fmt\"; func main(){fmt.Println(\"hello\")}`) //可以打印 hello 加上package main效果和上面一样: i.Eval(`package main; import \"fmt\"; func main(){fmt.Println(\"hello\")}`) //可以打印 hello 但是加上package other就不会执行main了, 实际上非main包也不应该有main函数 i.Eval(`package module; import \"fmt\"; func main(){fmt.Println(\"hello\")}`) //不会打印hello, 执行不会出错 每次Eval都会执行main 比如我写了个hello.go, 里面是package main, 打印hello package main import ( \"fmt\" ) func main() { fmt.Println(\"Hello, playground~\") } func Stop() { fmt.Println(\"stopping\") } 我想在框架里调用Stop(), 比如这样: sh := newShell(interp.Options{}) sh.runFile(file) // 就是run这个hello.go sh.Eval(\"Stop()\") // 可以执行Stop, 打印stopping, 但Hello, playground~会再打印一遍 // output Hello, playground~ stopping Hello, playground~ 解释: 对main包来说, 每次Eval都会执行main 引用main包的函数, 不能加main前缀, 比如main.Stop, 加了会报undefined selector: Stop 如果hello.go不是main包, 比如是test. 那么 要加test前缀来引用, 比如sh.Eval(\"test.Stop()\") 因为是非main包, 执行sh.Eval(\"test.Stop()\")不会导致main()函数被二次执行 代码解释: 因为在compile阶段, main()函数每次都会被加到node列表里 func (interp *Interpreter) compile(src, name string, inc bool) (*Program, error) { ... // Add main to list of functions to run, after all inits. if m := gs.sym[mainID]; pkgName == mainID && m != nil { initNodes = append(initNodes, m.node) } ... } Stop脚本 bin函数执行时不能被cancel EvalWithContext()函数在cancel()的时候不能停止bin的函数, 但估计可以停止所有脚本的后续执行.比如脚本在执行一个bin的函数http.Serve(lnr, fs), 这个函数会卡住, 一直accept连接来服务http请求. lnr, err = net.Listen(\"tcp\", \":\"+*port) fs := http.FileServer(http.Dir(*dir)) http.Serve(lnr, fs) 即使用了带ctx的Eval函数: ctx, cancel := context.WithCancel(context.Background()) vc.newShell() vc.sh.EvalWithContext(ctx, \"_main()\") 但在cancel()的时候, 虽然EvalWithContext()能退出来, 但是起里面执行的Eval()却无法退出, 因为Eval在单独的goroutine里面正在执行http.Serve(lnr, fs) // EvalWithContext evaluates Go code represented as a string. It returns // a map on current interpreted package exported symbols. func (interp *Interpreter) EvalWithContext(ctx context.Context, src string) (reflect.Value, error) { var v reflect.Value var err error interp.mutex.Lock() interp.done = make(chan struct{}) interp.cancelChan = !interp.opt.fastChan interp.mutex.Unlock() done := make(chan struct{}) go func() { defer close(done) v, err = interp.Eval(src) }() select { case 怎么解决呢? 思路: 在脚本里定义func Stop()函数: var lnr net.Listener var hello = \"nihao\" func Start() (err error) { hello = \"wo ye hao\" lnr, err = net.Listen(\"tcp\", \":\"+*port) ... http.Serve(lnr, fs) } func Stop() { fmt.Println(\"stopping\") fmt.Println(hello) fmt.Println(lnr == nil) lnr.Close() } 然后在cancel()之前, 由解释器来调用Stop函数: switch msg.Cmd { case \"kill\": if vc.stat == vmStatRunning { // no need to atomic fmt.Fprintln(&vc.stderr, \"calling Stop()\") vc.sh.Eval(\"Stop()\") //注意这里, 解释执行脚本里的Stop函数 vc.cancel() atomic.CompareAndSwapInt32(&vc.stat, vmStatRunning, vmStatAborting) ids = append(ids, vc.ID) } 结果 脚本的stop函数会被调用, 而且, 脚本的内部变量还能\"看到\" /repo1/services/http 8088 stopping //注意这里说明stop函数被解释器\"单独\"的调用了 wo ye hao //但是, 这次\"单独\"的调用依然能看到main()函数里的变量的改变. false // 同上, 能看到变量改变 accept tcp [::]:8088: use of closed network connection //这里的错误信息说明, lnr已经被close了 calling Stop() //我重新安排了输出, 按理说这句应该在前面 56:12: panic // 这两个panic我不知道从哪里来的 1:28: panic context canceled 题外 因为这里的例子是http的file server, 我发现以下事实: chrome浏览器打开了http://10.182.105.179:8088连接, 来访问我这里的http服务. 这是个长连接, 即使页面关闭了, 还会一直存在. 所以表面看起来, 脚本stop了还是可以访问http文件, 是因为这个长连接并没有关闭: 下面是stop后的连接netstat -an | grep 8088 tcp6 0 0 192.168.0.18:8088 10.243.141.21:58826 ESTABLISHED 对比stop前的连接, 明显看到listen的socket没有了, 被关闭了netstat -an | grep 8088 tcp6 0 0 :::8088 :::* LISTEN tcp6 0 0 192.168.0.18:8088 10.243.141.21:58826 ESTABLISHED yaegi已知问题 脚本的结构体没有名字 脚本里定义的结构体, 没有名字. 因为reflect创建的结构体都没有名字 package main import ( \"fmt\" \"reflect\" ) func main() { structFields := []reflect.StructField{ { Name: \"Name\", Type: reflect.TypeOf(\"\"), }, } structDec := reflect.StructOf(structFields) fmt.Printf(\"Type Dynamic : %+v\\n\", structDec) fmt.Printf(\"Type Static : %+v\\n\", reflect.TypeOf(struct{ Name string }{})) } 而yaegi是基于reflect来解释执行代码的: type testA struct { A int B string } fmt.Printf(\"%#v\\n\", testA{}) 所以上面的代码打印: struct { A int; B string }{A:0, B:\"\"} 相关的讨论: Representation of types by reflect and printing values using %T may give different results between compiled mode and interpreted mode. https://github.com/traefik/yaegi/issues/947 stackoveflow 结论: 只有bin里的结构体才能有名字. 如果脚本里需要使用结构体的名字, 比如注册结构体到gotiny, 或者定义结构体的方法, 这个结构体应该在native go代码里定义. yaegi执行过程 interp.(*Interpreter).EvalPath() interp.(*Interpreter).importSrc() interp.(*Interpreter).run() //在这之前已经生成了CFG interp.runCfg() //这里这个node isBinCall()为真, 就是as.RegisterType() //对应这句: callFn := func(v reflect.Value, in []reflect.Value) []reflect.Value { return v.Call(in) } interp.callBin.func10() reflect.Value.Call() reflect.Value.call() adaptiveservice.RegisterType() yaegi集成到gshell new 解释器 type Options struct { // GoPath sets GOPATH for the interpreter. GoPath string // BuildTags sets build constraints for the interpreter. BuildTags []string // Standard input, output and error streams. // They default to os.Stdin, os.Stdout and os.Stderr respectively. Stdin io.Reader Stdout, Stderr io.Writer // SourcecodeFilesystem is where the _sourcecode_ is loaded from and does // NOT affect the filesystem of scripts when they run. // It can be any fs.FS compliant filesystem (e.g. embed.FS, or fstest.MapFS for testing) // See example/fs/fs_test.go for an example. SourcecodeFilesystem fs.FS } yaegi使用 Yet Another Go Interpreter, with the E standing for Elegant, Embedded, Easy 入门文章 使用简单, 只有New() Eval() Use()三个API 完全兼容go规范 编译运行 目前只在go1.14以上才能编 cd yaegi make generate cd cmd/yaegi go build //编译出来yaegi又22M 运行 yingjieb@godev-server /repo/yingjieb/3rdparty/yaegi/cmd/yaegi $ ./yaegi -h Yaegi is a Go interpreter. Usage: yaegi [command] [arguments] The commands are: extract generate a wrapper file from a source package help print usage information run execute a Go program from source test execute test functions in a Go package version print version Use \"yaegi help \" for more information about a command. If no command is given or if the first argument is not a command, then the run command is assumed. debug 打印ast和cfg图: YAEGI_AST_DOT=1 YAEGI_CFG_DOT=1 ./yaegi 输入的每一行都会在当前目录下生成, 覆盖前一个; yaegi-cfg-_.dot yaegi-ast-_.dot 这里的小bug是, 会生成一堆的dot进程. 注, dot是linux命令, 用来绘图. dot文件转成svg后用firefox打开 watch -n1 \"dot -Tsvg yaegi-ast-_.dot -o ast.svg; dot -Tsvg yaegi-cfg-_.dot -o cfg.svg\" firefox \"file:///repo/yingjieb/3rdparty/yaegi/cmd/yaegi/ast.svg\" ast和cfg举例图 空敲回车 对应的ast图cfg图为空 a := 100 s := \"hello world\" if > if s == \"hello world\" { a = 200 } : 200 slice > si := []int{1,2,3,4,5} : [1 2 3 4 5] import import \"fmt\" for range > for i, num := range(si) { fmt.Println(i, num)} 函数定义 func myPrint(p ...interface{}) { fmt.Println(p...) } func call > myPrint(\"ni\", \"hao\", \"ma\", 123) 使用例子 命令循环模式 $ yaegi > 1 + 2 3 > import \"fmt\" > fmt.Println(\"Hello World\") Hello World > 嵌入别的代码里: package main import ( \"github.com/containous/yaegi/interp\" \"github.com/containous/yaegi/stdlib\" ) func main() { i := interp.New(interp.Options{}) i.Use(stdlib.Symbols) i.Eval(`import \"fmt\"`) i.Eval(`fmt.Println(\"hello\")`) } This example demonstrates the ability to use executable pre-compiled symbols in the interpreter. Thanks to the statement i.Use(stdlib.Symbols), the interpreted import \"fmt\"will load the fmt package from the executable itself (wrapped in reflect.Values) instead of trying to parse source files. Yaegi also provides the goexports command to build the binary wrapper of any package from its source. This is the command we used to generate all stdlib wrappers provided by default. 注意, stdlib是预编译好的bin. 这个解释器能够执行已经编译好的代码. i.Use(stdlib.Symbols)的作用是把导入编译后的符号给解释器用. 实现的关键是reflect.Values包装. 动态代码 入前文所说, 解释执行和编译执行能够交互. 下面的例子中, 这个文件都是正常编译的. 但里面的v, _ := i.Eval(\"foo.Bar\")却是解释执行的. package main import \"github.com/containous/yaegi/interp\" const src = `package foo func Bar(s string) string { return s + \"-Foo\" }` func main() { i := interp.New(interp.Options{}) i.Eval(src) //v是reflect.Value v, _ := i.Eval(\"foo.Bar\") //需要先把v还原成interface再断言. bar := v.Interface().(func(string) string) r := bar(\"Kung\") println(r) // Output: // Kung-Foo } 解释器调用bin符号 -- 代码生成部分 在yaegi中, 初始化时用map[\"符号名\"]reflect.Value保存bin中的符号信息. 解释执行过程中, 查找符号名, 得到reflect.Value, 对其进行refect.Value.Call()调用, 就像直接调用这个符号一样. 这个过程如下: go generate 先是go generate ./internal/cmd/extract internal/cmd/extract/extract.go中, 首先第一行就是 //go:generate go build 其实就是go build出来一个叫extract的bin程序, 该程序负责使用模板技术生成标准库的wrapper调用 extract包 extract/extract.go包提供了生成wrapper的模板和相关辅助函数 不用New的对象初始化 做为一个package, 一般的入口函数是New一个对象. 但这里一个简单的结构体初始化就搞定了: ext := extract.Extractor{ Dest: path.Base(wd), } //可以根据情况给ext的其他属性field赋值 ext.Exclude = strings.Split(excludeString, \",\") 相对于一般的NewObj()等API来说, 这个模式简单, 直观, 但就是写法上稍显啰嗦 也有NewObj(Options...)的模式, 可以传入不定长的Options. 本质上和显示结构体初始化一样. Extract方法 var buf bytes.Buffer //这里Extract把模板替换后的代码输出到bytes.Buffer, 后者会被io.Copy到文件中. importPath, err := ext.Extract(pkgIdent, \"\", &buf) f, err := os.Create(prefix + \"_\" + oFile) _, err := io.Copy(f, &buf) f.Close() 从这里开始, 需要有reflect基础. go/importer 和 go/types func ForCompiler(fset *token.FileSet, compiler string, lookup Lookup) types.Importer ForCompiler returns an Importer for importing from installed packages for the compilers \"gc\" and \"gccgo\", or for importing directly from the source if the compiler argument is \"source\". //\"source\"类型的importer pkg, err := importer.ForCompiler(token.NewFileSet(), \"source\", nil).Import(\"pkgname\") //Import以后, \"pkgname\"的包就是`*types.Package`类型的对象 //根据模板生成内容. ipp是import 路径 content, err := e.genContent(ipp, pkg) genContent代码 // Val stores the value name and addressable status of symbols. type Val struct { Name string // \"package.name\" Addr bool // true if symbol is a Var } // Method stores information for generating interface wrapper method. type Method struct { Name, Param, Result, Arg, Ret string } // Wrap stores information for generating interface wrapper. type Wrap struct { Name string Method []Method } func (e *Extractor) genContent(importPath string, p *types.Package) ([]byte, error) { //声明+初始化 typ := map[string]string{} val := map[string]Val{} wrap := map[string]Wrap{} imports := map[string]bool{} //返回这个package的对象空间, 持有这个package的包括的各种对象 //Scope returns the (complete or incomplete) package scope holding the objects declared at package level (TypeNames, Consts, Vars, and Funcs). sc := p.Scope() //import路径从p.Imports()而来 for _, pkg := range p.Imports() { imports[pkg.Path()] = false } //Scope的Names返回其持有的所有对象的名字 for _, name := range sc.Names() { o := sc.Lookup(name) // skip if name不在e.Include里面 or 在e.Exclude里面 switch o := o.(type) { case *types.Const: case *types.Func: //pname是name的全称, 即\"package.name\" val[name] = Val{pname, false} case *types.Var: val[name] = Val{pname, true} //以上Const, Func, Var都算var //typ是什么? case *types.TypeName: typ[name] = pname //底层是interface时, 构造methods if t, ok := o.Type().Underlying().(*types.Interface); ok { var methods []Method for i := 0; i func (s *Scope) Lookup(name string) Object 返回的是types.Object, 是个接口. 一个函数返回接口, 说明这个东西是变化的. An Object describes a named language entity such as a package, constant, type, variable, function (incl. methods), or label. All objects implement the Object interface. type Object interface { Parent() *Scope // scope in which this object is declared; nil for methods and struct fields Pos() token.Pos // position of object identifier in declaration Pkg() *Package // package to which this object belongs; nil for labels and objects in the Universe scope Name() string // package local object name Type() Type // object type Exported() bool // reports whether the name starts with a capital letter Id() string // object name if exported, qualified name if not exported (see func Id) // String returns a human-readable string of the object. String() string // contains filtered or unexported methods } 变化的接口, 代表了一种抽象; 但抽象是不能直接用的, 所以一般会跟类型断言, 来\"具化\"这个接口变量:switch o := o.(type) { case *types.Const: case *types.Func: case *types.Var: case *types.TypeName: } 模板替换 基本上, 符号被分成三类: Val: 变量 函数 Typ: 结构体对象 Wrap: interface的方法集 通过对源码的分析, 把符号分类后, 传给模板 data := map[string]interface{}{ \"Dest\": e.Dest, \"Imports\": imports, \"PkgName\": importPath, \"Val\": val, \"Typ\": typ, \"Wrap\": wrap, \"BuildTags\": buildTags, \"License\": e.License, } base := template.New(\"extract\") parse, err := base.Parse(model) b := new(bytes.Buffer) err = parse.Execute(b, data) // format格式 source, err := format.Source(b.Bytes()) 模板 const model = ` func init() { Symbols[\"{ {.PkgName} }\"] = map[string]reflect.Value{ { {- if .Val} } // function, constant and variable definitions { {range $key, $value := .Val -} } //value是变量的时候, 先取地址, 再Elem() -- 不知道为啥 { {- if $value.Addr -} } \"{ {$key} }\": reflect.ValueOf(&{ {$value.Name} }).Elem(), //value是个函数, 或者常量 { {else -} } \"{ {$key} }\": reflect.ValueOf({ {$value.Name} }), { {end -} } { {end} } { {- end} } //typ类型包装成指针 { {- if .Typ} } // type definitions { {range $key, $value := .Typ -} } \"{ {$key} }\": reflect.ValueOf((*{ {$value} })(nil)), { {end} } { {- end} } { {- if .Wrap} } // interface wrapper definitions { {range $key, $value := .Wrap -} } \"_{ {$key} }\": reflect.ValueOf((*{ {$value.Name} })(nil)), { {end} } { {- end} } } } { {range $key, $value := .Wrap -} } // { {$value.Name} } is an interface wrapper for { {$key} } type type { {$value.Name} } struct { { {range $m := $value.Method -} } W{ {$m.Name} } func{ {$m.Param} } { {$m.Result} } { {end} } } { {range $m := $value.Method -} } func (W { {$value.Name} }) { {$m.Name} }{ {$m.Param} } { {$m.Result} } { { {$m.Ret} } W.W{ {$m.Name} }{ {$m.Arg} } } { {end} } { {end} } ` 替换结果举例 stdlib/go1_14_io.go package stdlib import ( \"go/constant\" \"go/token\" \"io\" \"reflect\" ) func init() { Symbols[\"io\"] = map[string]reflect.Value{ // function, constant and variable definitions \"Copy\": reflect.ValueOf(io.Copy), \"CopyBuffer\": reflect.ValueOf(io.CopyBuffer), \"EOF\": reflect.ValueOf(&io.EOF).Elem(), \"ErrClosedPipe\": reflect.ValueOf(&io.ErrClosedPipe).Elem(), \"SeekCurrent\": reflect.ValueOf(constant.MakeFromLiteral(\"1\", token.INT, 0)), \"SeekEnd\": reflect.ValueOf(constant.MakeFromLiteral(\"2\", token.INT, 0)), // type definitions \"Reader\": reflect.ValueOf((*io.Reader)(nil)), \"Writer\": reflect.ValueOf((*io.Writer)(nil)), // interface wrapper definitions \"_Reader\": reflect.ValueOf((*_io_Reader)(nil)), \"_Writer\": reflect.ValueOf((*_io_Writer)(nil)), } } // _io_Reader is an interface wrapper for Reader type type _io_Reader struct { WRead func(p []byte) (n int, err error) } func (W _io_Reader) Read(p []byte) (n int, err error) { return W.WRead(p) } // _io_Writer is an interface wrapper for Writer type type _io_Writer struct { WWrite func(p []byte) (n int, err error) } func (W _io_Writer) Write(p []byte) (n int, err error) { return W.WWrite(p) } yaegi 背景知识 AST语法树 AST不依赖于具体的文法，不依赖于语言的细节，我们将源代码转化为AST后，可以对AST做很多的操作，包括一些你想不到的操作，这些操作实现了各种各样形形色色的功能，给你带进一个不一样的世界。 抽象语法树（abstract syntax code，AST）是源代码的抽象语法结构的树状表示，树上的每个节点都表示源代码中的一种结构，这所以说是抽象的，是因为抽象语法树并不会表示出真实语法出现的每一个细节，比如说，嵌套括号被隐含在树的结构中，并没有以节点的形式呈现。抽象语法树并不依赖于源语言的语法，也就是说语法分析阶段所采用的上下文无文文法，因为在写文法时，经常会对文法进行等价的转换（消除左递归，回溯，二义性等），这样会给文法分析引入一些多余的成分，对后续阶段造成不利影响，甚至会使合个阶段变得混乱。因些，很多编译器经常要独立地构造语法分析树，为前端，后端建立一个清晰的接口。 1+3*(4-1)+2 xml ShiChuang 12478 Nosic while while b != 0 { if a > b a = a-b else b = b-a } return a for sum=0 for i in range(0,100) sum=sum+i end 为什么需要抽象语法树 当在源程序语法分析工作时，是在相应程序设计语言的语法规则指导下进行的。语法规则描述了该语言的各种语法成分的组成结构，通常可以用所谓的前后文无关文法或与之等价的Backus-Naur范式(BNF)将一个程序设计语言的语法规则确切的描述出来。前后文无关文法有分为这么几类：LL(1)，LR(0)，LR(1)， LR(k) ,LALR(1)等。每一种文法都有不同的要求，如LL(1)要求文法无二义性和不存在左递归。当把一个文法改为LL(1)文法时，需要引入一些隔外的文法符号与产生式。 AST的重要特征就是和语法无关, 只关注抽象. 比如C的if if(condition) { do_something(); } 和fortran的if语法就不一样 If condition then do_somthing() end if 但它们的AST都是一样的: 在源程序中出现的括号，或者是关键字，都会被丢掉。 函数 // 简单函数 function square(n) { return n * n; } // 转换后的AST { type: \"FunctionDeclaration\", id: { type: \"Identifier\", name: \"square\" }, params: [ { type: \"Identifier\", name: \"n\" } ], ... } 第一步：词法分析，也叫扫描scanner 它读取我们的代码，然后把它们按照预定的规则合并成一个个的标识 tokens。同时，它会移除空白符、注释等。最后，整个代码将被分割进一个 tokens 列表（或者说一维数组）。 const a = 5; // 转换成 [{value: 'const', type: 'keyword'}, {value: 'a', type: 'identifier'}, ...] 第二步：语法分析，也称解析器 它会将词法分析出来的数组转换成树形的形式，同时，验证语法。语法如果有错的话，抛出语法错误。 [{value: 'const', type: 'keyword'}, {value: 'a', type: 'identifier'}, ...] // 语法分析后的树形形式 { type: \"VariableDeclarator\", id: { type: \"Identifier\", name: \"a\" }, ... } 当生成树的时候，解析器会删除一些没必要的标识 tokens（比如：不完整的括号），因此 AST 不是 100% 与源码匹配的。 main cmd/yaegi/yaegi.go的main()是入口 func main() run(os.Args[1:]) //New一个解释器 i := interp.New(interp.Options{GoPath: build.Default.GOPATH, BuildTags: strings.Split(tags, \",\")}) // Symbols variable stores the map of stdlib symbols per package. // var Symbols = map[string]map[string]reflect.Value{} //reflect.Value表示任意对象实例 // Symbols[\"github.com/traefik/yaegi/stdlib\"] = map[string]reflect.Value{ \"Symbols\": reflect.ValueOf(Symbols)} //第一个key的值就是自身的reflect.Value表达 // 所以Symbols是个很大的map表的集合 i.Use(stdlib.Symbols) // 使用解释器导出的symbol, 这个很小. 只有\"New\" \"Interpreter\" \"Options\" \"Panic\" i.Use(interp.Symbols) // 使用其他种类的符号表 i.Use(syscall.Symbols) i.Use(unsafe.Symbols) i.Use(unrestricted.Symbols) //cmd是-e选项传过来的要执行的字符串 _, err = i.Eval(cmd) //如果没有cmd就执行REPL循环 i.REPL() map[string]reflect.Value{} //reflect.Value表示任意对象实例 解释器 interp/interp.go 一个解释器包括全局变量和状态 // Interpreter contains global resources and state. type Interpreter struct { // id is an atomic counter counter used for run cancellation, // only accessed via runid/stop // Located at start of struct to ensure proper alignment on 32 bit // architectures. id uint64 // nindex is a node number incremented for each new node. // It is used for debug (AST and CFG graphs). As it is atomically // incremented, keep it aligned on 64 bits boundary. nindex int64 name string // name of the input source file (or main) opt // user settable options cancelChan bool // enables cancellable chan operations fset *token.FileSet // fileset to locate node in source code binPkg Exports // binary packages used in interpreter, indexed by path rdir map[string]bool // for src import cycle detection mutex sync.RWMutex frame *frame // program data storage during execution universe *scope // interpreter global level scope scopes map[string]*scope // package level scopes, indexed by import path srcPkg imports // source packages used in interpreter, indexed by path pkgNames map[string]string // package names, indexed by import path done chan struct{} // for cancellation of channel operations hooks *hooks // symbol hooks } 解释器调用bin里的符号 用i.Use(stdlib.Symbols)可以在yaegi的解释器里面, 调用已经编译好的标准库. 怎么做到的呢? // Exports stores the map of binary packages per package path. type Exports map[string]map[string]reflect.Value // Use loads binary runtime symbols in the interpreter context so // they can be used in interpreted code. func (interp *Interpreter) Use(values Exports) { for k, v := range values { if k == selfPrefix { interp.hooks.Parse(v) continue } if interp.binPkg[k] == nil { interp.binPkg[k] = make(map[string]reflect.Value) } for s, sym := range v { //双map表. 值是reflect.Value interp.binPkg[k][s] = sym } } // Checks if input values correspond to stdlib packages by looking for one // well known stdlib package path. if _, ok := values[\"fmt\"]; ok { fixStdio(interp) } } 比如stdlib/go1_14_bytes.go中, func init() { Symbols[\"bytes\"] = map[string]reflect.Value{ ... //这里bytes.Join指代的是Join这个函数; 有点像函数指针. //是否通过这个函数指针就可以调用bin里的函数了? \"Join\": reflect.ValueOf(bytes.Join), } } 使用refect.Value.Call()的例子 func TestGetFunc(t *testing.T) { i := interp.New(interp.Options{GoPath: \"./_gopath/\"}) i.Use(stdlib.Symbols) if _, err := i.Eval(`import \"github.com/foo/bar\"`); err != nil { t.Fatal(err) } //bar.NewFoo并没有执行, 只是获取了NewFoo的对象的reflect.Value值 //val是reflect.Value类型, 因为Eval返回reflect.Value,error val, err := i.Eval(`bar.NewFoo`) if err != nil { t.Fatal(err) } fmt.Println(val.Call(nil)) } 这里的NewFoo是个函数 type Foo struct { A string } func NewFoo() *Foo { return &Foo{A: \"test\"} } Call的原型如下: func (v Value) Call(in []Value) []Value Call calls the function v with the input arguments in. For example, if len(in) == 3, v.Call(in) represents the Go call v(in[0], in[1], in[2]). Call panics if v's Kind is not Func. It returns the output results as Values. As in Go, each input argument must be assignable to the type of the function's corresponding input parameter. If v is a variadic function, Call creates the variadic slice parameter itself, copying in the corresponding values. 此时v的Kind必须是Func vc可以是func (v Value) MethodByName(name string) Value的返回值; 此时vc.Call()默认第一个参数是v, 其他参数才是Call传入的 查找bin 的method 在cfg阶段, 通过判断node中的信息(typ, child等), 发现这个是个对bin的method的调用. if m, lind, isPtr, ok := n.typ.lookupBinMethod(n.child[1].ident); ok { n.action = aGetMethod if isPtr && n.typ.fieldSeq(lind).cat != ptrT { n.gen = getIndexSeqPtrMethod } else { n.gen = getIndexSeqMethod } // n.recv = &receiver{node: n.child[0], index: lind} n.val = append([]int{m.Index}, lind...) n.typ = &itype{cat: valueT, rtype: m.Type, recv: n.child[0].typ} } 前面说过, 初始化的时候, 对标准库的引用, 是个双map的表 type Exports map[string]map[string]reflect.Value 对一个函数级的符号来说, 就是比如interp.binPkg[\"fmt\"][\"Println\"]查到reflect.ValueOf(fmt.Println), 这是个reflect.Value类型的值, 存储了\"函数指针\"fmt.Println的所有内部表达. // LookupBinMethod returns a method and a path to access a field in a struct object (the receiver). func (t *itype) lookupBinMethod(name string) (m reflect.Method, index []int, isPtr, ok bool) { //指针类型下 if t.cat == ptrT { return t.val.lookupBinMethod(name) } for i, f := range t.field { //是闭包的意思吗? if f.embed { if m2, index2, isPtr2, ok2 := f.typ.lookupBinMethod(name); ok2 { index = append([]int{i}, index2...) return m2, index, isPtr2, ok2 } } } //这里关键的黑魔法来了 //reflect.Value的MethodByName方法查找对象的\"name\"方法, 返回reflect.Method类型. //在go里面, 方法集是绑定在类型上的, m, ok = t.TypeOf().MethodByName(name) if !ok { //没找到就找指针指向的对象的method m, ok = reflect.PtrTo(t.TypeOf()).MethodByName(name) isPtr = ok } return m, index, isPtr, ok } 反射的Method是这样的: type Method struct { // Name is the method name. // PkgPath is the package path that qualifies a lower case (unexported) // method name. It is empty for upper case (exported) method names. // The combination of PkgPath and Name uniquely identifies a method // in a method set. // See https://golang.org/ref/spec#Uniqueness_of_identifiers Name string PkgPath string Type Type // method type Func Value // func with receiver as first argument Index int // index for Type.Method } interp/run.go的call()函数 func call(n *node) { //value是由genValue返回的闭包函数 //n.child[0]就是要call的函数名 value := genValue(n.child[0]) //child[0]是个receiver对象 if n.child[0].recv != nil { ... } 准备in参数 准备out参数 基本上最后每个参数都是个闭包函数的返回值 最后给n.exec赋值, 值为一个闭包函数{ 如果是bin func bf := value(f) //in 和 out都是[]reflect.Value 闭包函数里面调用了out := bf.Call(in) 返回 如果是解释执行的func 最后调用runCfg(def.child[3].start, nf) } } ast的node type node struct { child []*node // child subtrees (AST) anc *node // ancestor (AST) start *node // entry point in subtree (CFG) tnext *node // true branch successor (CFG) fnext *node // false branch successor (CFG) interp *Interpreter // interpreter context frame *frame // frame pointer used for closures only (TODO: suppress this) index int64 // node index (dot display) findex int // index of value in frame or frame size (func def, type def) level int // number of frame indirections to access value nleft int // number of children in left part (assign) or indicates preceding type (compositeLit) nright int // number of children in right part (assign) kind nkind // kind of node pos token.Pos // position in source code, relative to fset sym *symbol // associated symbol typ *itype // type of value in frame, or nil recv *receiver // method receiver node for call, or nil types []reflect.Type // frame types, used by function literals only; 每个type代表一个变量? action action // action exec bltn // generated function to execute gen bltnGenerator // generator function to produce above bltn val interface{} // static generic value (CFG execution) rval reflect.Value // reflection value to let runtime access interpreter (CFG) ident string // set if node is a var or func } // receiver stores method receiver object access path. type receiver struct { node *node // receiver value for alias and struct types val reflect.Value // receiver value for interface type and value type index []int // path in receiver value for interface or value type } // frame contains values for the current execution level (a function context). type frame struct { // id is an atomic counter used for cancellation, only accessed // via newFrame/runid/setrunid/clone. // Located at start of struct to ensure proper aligment. id uint64 anc *frame // ancestor frame (global space) data []reflect.Value // values mutex sync.RWMutex deferred [][]reflect.Value // defer stack recovered interface{} // to handle panic recover done reflect.SelectCase // for cancellation of channel operations } Eval interpreter的Eval方法, 把string解释执行 func (interp *Interpreter) eval(src, name string, inc bool) (res reflect.Value, err error) { // 调用go标准库的语法库解析生成AST. root就是根节点 pkgName, root, err := interp.ast(src, interp.name, inc) // 可以打印这个graph root.astDot(dotWriter(dotCmd), interp.name) // cfg是control flow graph. 控制流的图表达 initNodes, err := interp.cfg(root, pkgName) // Perform global types analysis. err = interp.gtaRetry([]*node{root}, pkgName) gs := interp.scopes[pkgName] // Add main to list of functions to run, after all inits. if m := gs.sym[\"main\"]; pkgName == mainID && m != nil { initNodes = append(initNodes, m.node) } // Generate node exec closures. err = genRun(root) //准备frame内存 // Init interpreter execution memory frame. interp.frame.setrunid(interp.runid()) interp.frame.mutex.Lock() interp.resizeFrame() interp.frame.mutex.Unlock() // Execute node closures. interp.run(root, nil) // Wire and execute global vars. n, err := genGlobalVars([]*node{root}, interp.scopes[pkgName]) interp.run(n, nil) // main也在这个initNodes里面 for _, n := range initNodes { interp.run(n, interp.frame) } //genValue返回一个函数闭包 // v是返回的函数: func(*frame) reflect.Value v := genValue(root) res = v(interp.frame) return res, err } ast函数 在ast.go里面实现interpreter包的ast树功能, 使用了标准库的go/ast go/token go/parser go/scanner // Note: no type analysis is performed at this stage, it is done in pre-order // processing of CFG, in order to accommodate forward type declarations. // ast parses src string containing Go code and generates the corresponding AST. // The package name and the AST root node are returned. // The given name is used to set the filename of the relevant source file in the // interpreter's FileSet. func (interp *Interpreter) ast(src, name string, inc bool) (string, *node, error) { //先parse f, err := parser.ParseFile(interp.fset, name, src, mode) var root *node var anc astNode var st nodestack var pkgName string //Inspect会深度优先遍历ast //这里传入的func是个巨长的函数, 在遍历过程中, 对每个node调用 //它检查node的类型, ast.Inspect(f, func(nod ast.Node) bool { //st是node栈 anc = st.top() //根据node的类型不同, 操作st栈. 一般都是st.push() //type类型断言 switch a := nod.(type) { case nil: case *ast.ArrayType: case *ast.AssignStmt: case *ast.BlockStmt: case *ast.BranchStmt: case *ast.CallExpr: case *ast.CaseClause: case *ast.ChanType: case *ast.CommClause: case *ast.DeclStmt: case *ast.DeferStmt: case *ast.ExprStmt: case *ast.ForStmt: case *ast.File: case *ast.Field: case *ast.GoStmt: case *ast.IfStmt: case *ast.MapType: 还有很多case. 一个语言, 所有支持的操作都在此. } }) } builtin预定义action run.go会提供一个builtin数组, 里面是不同操作码对应的动作: var builtin = [...]bltnGenerator{ aNop: nop, aAddr: addr, aAssign: assign, aAdd: add, aAddAssign: addAssign, aAnd: and, aAndAssign: andAssign, aAndNot: andNot, aAndNotAssign: andNotAssign, aBitNot: bitNot, aCall: call, aCallSlice: call, aCase: _case, aCompositeLit: arrayLit, aDec: dec, aEqual: equal, aGetFunc: getFunc, aGreater: greater, aGreaterEqual: greaterEqual, aInc: inc, aLand: land, aLor: lor, aLower: lower, aLowerEqual: lowerEqual, aMul: mul, aMulAssign: mulAssign, aNeg: neg, aNot: not, aNotEqual: notEqual, aOr: or, aOrAssign: orAssign, aPos: pos, aQuo: quo, aQuoAssign: quoAssign, aRange: _range, aRecv: recv, aRem: rem, aRemAssign: remAssign, aReturn: _return, aSend: send, aShl: shl, aShlAssign: shlAssign, aShr: shr, aShrAssign: shrAssign, aSlice: slice, aSlice0: slice0, aStar: deref, aSub: sub, aSubAssign: subAssign, aTypeAssert: typeAssertShort, aXor: xor, aXorAssign: xorAssign, } 在ast阶段就把操作码的动作\"编译\"进node树里: addChild := func(root **node, anc astNode, pos token.Pos, kind nkind, act action) *node { ... n := &node{anc: anc.node, interp: interp, index: nindex, pos: pos, kind: kind, action: act, val: &i, gen: builtin[act]} ... } 比如所有的\"+\"操做, 都会调用: func add(n *node) { switch typ.Kind() { case reflect.String: case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: //各种类型断言, 使用反射赋值; 注意这里并不是马上执行, 而是返回一个闭包函数 switch { case isInterface: v0 := genValueInt(c0) v1 := genValueInt(c1) n.exec = func(f *frame) bltn { _, i := v0(f) _, j := v1(f) dest(f).Set(reflect.ValueOf(i + j).Convert(typ)) return next } case c0.rval.IsValid(): i := vInt(c0.rval) v1 := genValueInt(c1) n.exec = func(f *frame) bltn { _, j := v1(f) dest(f).SetInt(i + j) return next } case c1.rval.IsValid(): v0 := genValueInt(c0) j := vInt(c1.rval) n.exec = func(f *frame) bltn { _, i := v0(f) dest(f).SetInt(i + j) return next } default: v0 := genValueInt(c0) v1 := genValueInt(c1) n.exec = func(f *frame) bltn { _, i := v0(f) _, j := v1(f) dest(f).SetInt(i + j) return next } } case reflect.Float32, reflect.Float64: } cfg函数 cfg函数根据ast, 生成控制流的图 入参是root node, 返回node类型的切片 // cfg generates a control flow graph (CFG) from AST (wiring successors in AST) // and pre-compute frame sizes and indexes for all un-named (temporary) and named // variables. A list of nodes of init functions is returned. // Following this pass, the CFG is ready to run. func (interp *Interpreter) cfg(root *node, importPath string) ([]*node, error) { sc := tinterp.initScopePkg(importPath) check := typecheck{} var initNodes []*node var err error //这里传了两个函数 //第一个函数, 根据node的类型, 很多地方在调用sc = sc.pushBloc() //比如这样的 //case forStmt0, forStmt1, forStmt2, forStmt3, forStmt4, forStmt5, forStmt6, forStmt7, forRangeStmt: // sc = sc.pushBloc() // sc.loop, sc.loopRestart = n, n.lastChild() // root.Walk(func(n *node) bool {}, func(n *node)) ... } walk函数深度优先遍历树, 对每个节点, 遍历之前调用in函数, 遍历之后调用out函数. in函数又称为pre-ordering函数 out函数又称为post-ordering函数 // Walk traverses AST n in depth first order, call cbin function // at node entry and cbout function at node exit. func (n *node) Walk(in func(n *node) bool, out func(n *node)) { if in != nil && !in(n) { return } for _, child := range n.child { child.Walk(in, out) } if out != nil { out(n) } } frame类型 函数level的frame // frame contains values for the current execution level (a function context). type frame struct { // id is an atomic counter used for cancellation, only accessed // via newFrame/runid/setrunid/clone. // Located at start of struct to ensure proper aligment. id uint64 anc *frame // ancestor frame (global space) data []reflect.Value // values mutex sync.RWMutex deferred [][]reflect.Value // defer stack recovered interface{} // to handle panic recover done reflect.SelectCase // for cancellation of channel operations } //newFrame生成一个frame func newFrame(anc *frame, len int, id uint64) *frame { f := &frame{ anc: anc, data: make([]reflect.Value, len), id: id, } if anc != nil { f.done = anc.done } return f } run函数 func (interp *Interpreter) run(n *node, cf *frame) { if n == nil { return } var f *frame if cf == nil { f = interp.frame } else { //初始frame, 其data切片的大小是len(n.types) //但为什么大小是n.types f = newFrame(cf, len(n.types), interp.runid()) } interp.mutex.RLock() c := reflect.ValueOf(interp.done) interp.mutex.RUnlock() f.mutex.Lock() f.done = reflect.SelectCase{Dir: reflect.SelectRecv, Chan: c} f.mutex.Unlock() for i, t := range n.types { //每种type在f.data里面才有个位置? 还是说f.data[]里面每个type都代表了一个变量? //这里先给每个变量new空间. 用reflect.New f.data[i] = reflect.New(t).Elem() } //调用runCfg. run这个node的流程控制图(CFG) // runCfg executes a node AST by walking its CFG and running node builtin at each step. runCfg(n.start, f) { for exec = n.exec; exec != nil && f.runid() == n.interp.runid(); { exec = exec(f) } } } exec举例 上面的exec是这个node的exec主要是在op.go run.go中定义. 基本上, 每个基础操作都对应一个exec. 比如run.go中的not操作: func not(n *node) { dest := genValue(n) value := genValue(n.child[0]) tnext := getExec(n.tnext) if n.fnext != nil { fnext := getExec(n.fnext) n.exec = func(f *frame) bltn { if !value(f).Bool() { dest(f).SetBool(true) return tnext } dest(f).SetBool(false) return fnext } } else { n.exec = func(f *frame) bltn { dest(f).SetBool(!value(f).Bool()) return tnext } } } 再比如op.go中的 对string的+操作 func add(n *node) { next := getExec(n.tnext) typ := n.typ.concrete().TypeOf() dest := genValueOutput(n, typ) c0, c1 := n.child[0], n.child[1] switch typ.Kind() { case reflect.String: switch { case c0.rval.IsValid(): s0 := vString(c0.rval) v1 := genValue(c1) n.exec = func(f *frame) bltn { dest(f).SetString(s0 + v1(f).String()) return next } case c1.rval.IsValid(): v0 := genValue(c0) s1 := vString(c1.rval) n.exec = func(f *frame) bltn { dest(f).SetString(v0(f).String() + s1) return next } default: v0 := genValue(c0) v1 := genValue(c1) n.exec = func(f *frame) bltn { dest(f).SetString(v0(f).String() + v1(f).String()) return next } } case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: ... } genValue()和genValueOutput(n, typ)都返回一个闭包函数, 底层是value.go基于反射实现的. dest(f)就是调用这个闭包函数. func genValue(n *node) func(*frame) reflect.Value { i := n.sym.index if n.sym.global { return func(f *frame) reflect.Value { return n.interp.frame.data[i] } } return valueGenerator(n, i) } func valueGenerator(n *node, i int) func(*frame) reflect.Value { switch n.level { case 0: return func(f *frame) reflect.Value { return valueOf(f.data, i) } case 1: return func(f *frame) reflect.Value { return valueOf(f.anc.data, i) } case 2: return func(f *frame) reflect.Value { return valueOf(f.anc.anc.data, i) } default: return func(f *frame) reflect.Value { for level := n.level; level > 0; level-- { f = f.anc } return valueOf(f.data, i) } } } // valueOf safely recovers the ith element of data. This is necessary // because a cancellation prior to any evaluation result may leave // the frame's data empty. func valueOf(data []reflect.Value, i int) reflect.Value { if i dest(f)展开就是 f.data[i] 总结 解释执行的过程是 先New一个解释器实例 Eval(string)解释 使用了标准库的go/ast go/token go/parser go/scanner来生成ast. ast表达的是go的抽象语法树; 至此每个node都有个类型, 比如*ast.MapType *ast.BlockStmt *ast.AssignStmt 根据ast生成控制流的图表达(cfg): 深度优先walk这个ast, 对每个node, 遍历之前调用in函数, 遍历之后调用out函数; 生成initNodes的切片. main函数也会被加入这个切片 建立frame: 应该是每个函数有个frame, frame.data[]表示函数内的所有变量, 其类型是反射的通用值类型reflect.Value. frame.data[]和node的types []reflect.Type是对应的. 即先有ast的reflect.Type, 再有frame.data[i] 真正run的是node的exec()函数. 这个函数会循环调用exec() exec = exec(f). exec()是每个node的闭包函数, 比如dest(f).SetBool(!value(f).Bool()), 又比如dest(f).SetString(s0 + v1(f).String()), 这里利用反射对f.data[i]赋值 整个过程只使用了go的标准库 相关标准库go/*的介绍在这里: https://github.com/golang/example/tree/master/gotypes Starting at the bottom, the go/token package defines the lexical tokens of Go. The go/scanner package tokenizes an input stream and records file position information for use in diagnostics or for file surgery in a refactoring tool. The go/ast package defines the data types of the abstract syntax tree (AST). The go/parser package provides a robust recursive-descent parser that constructs the AST. And go/constant provides representations and arithmetic operations for the values of compile-time constant expressions, as we'll see in Constants. 代码生成 op.go的代码是go run ../internal/genop/genop.go生成的 //用{ {$name} }来做模板替换 const model = `代码模板` base := template.New(\"genop\") parse, err := base.Parse(model) b := &bytes.Buffer{} data := map[string]interface{} { 预定义的data } //把data按照模板parse进b parse.Execute(b, data) //gofmt代码 source, err := format.Source(b.Bytes()) //结果写道文件里 ioutil.WriteFile(\"op.go\", source, 0666) REPL循环 // REPL performs a Read-Eval-Print-Loop on input reader. // Results are printed to the output writer of the Interpreter, provided as option // at creation time. Errors are printed to the similarly defined errors writer. // The last interpreter result value and error are returned. func (interp *Interpreter) REPL() (reflect.Value, error) { in, out, errs := interp.stdin, interp.stdout, interp.stderr ctx, cancel := context.WithCancel(context.Background()) end := make(chan struct{}) // channel to terminate the REPL sig := make(chan os.Signal, 1) // channel to trap interrupt signal (Ctrl-C) lines := make(chan string) // channel to read REPL input lines prompt := getPrompt(in, out) // prompt activated on tty like IO stream s := bufio.NewScanner(in) // read input stream line by line var v reflect.Value // result value from eval var err error // error from eval src := \"\" // source string to evaluate //注册Ctrl-C signal.Notify(sig, os.Interrupt) defer signal.Stop(sig) prompt(v) //管输入的routine go func() { defer close(end) //Ctrl+D EOF会退出 for s.Scan() { lines EvalWithContext 这段写的很标准, 有带cancel的context. // EvalWithContext evaluates Go code represented as a string. It returns // a map on current interpreted package exported symbols. func (interp *Interpreter) EvalWithContext(ctx context.Context, src string) (reflect.Value, error) { var v reflect.Value var err error interp.mutex.Lock() interp.done = make(chan struct{}) interp.cancelChan = !interp.opt.fastChan interp.mutex.Unlock() done := make(chan struct{}) //在routine里执行Eval的好处是后面的主循环会马上等待ctx.Done() //这样用户Ctrl+C能马上生效; 要优雅的生效, interp.stop()必不可少. go func() { //close用的漂亮 defer close(done) //直接用外面的变量赋值 v, err = interp.Eval(src) }() select { case 优雅的异步中断pattern: 在新的go routine里执行耗时函数 主循环在select里等待ctx.Done() 收到异步停止信号后(比如超时到, 比如ctx的cancel()触发), 调用stop() 重点是执行方提供一个stop()函数, 比如这里, interp的stop就是close掉done channel // stop sends a semaphore to all running frames and closes the chan // operation short circuit channel. stop may only be called once per // invocation of EvalWithContext. func (interp *Interpreter) stop() { atomic.AddUint64(&interp.id, 1) close(interp.done) } 总结 REPL循环使用bufio的scanner获取输入, 调用interp的Eval来执行. context 以及输入routine, Eval routine, 配合signal, 和interp.stop函数, 能及时退出本次eval执行. "},"notes/golang_tengo.html":{"url":"notes/golang_tengo.html","title":"解释器tengo","keywords":"","body":" 增加VM的并发run 编译函数 VM执行函数 函数怎么调用的? 编译阶段 执行阶段 函数怎么退出的? 如何理解字节码? 运行时会改变/增加/删除 global或constant数组吗? CompiledFunction的Free对象指针数组是干什么的? 运行阶段 结论 例子 tengo指令集和go的操作码 tengo运行过程 初始状态 a := 1 后 b := 2 后 c := a+b 后 f := func(a, b) { return a + b } 后 FormatConstants函数 那么什么是constant? constants在何处使用, 在何处定义 为什么constants要传递给NewCompiler? extension 为什么extension.UserFunction不生效? -- 注意Copy()方法 调查 结论 bash 能够在bash的命令里引用脚本的变量吗? 解决方法 添加新的builtin函数ex() 能否添加到builtinFuncs表 添加到global表 tengo代码 examples/interoperability/main.go 可被注册的对象: native go 可被注册的对象: tengo脚本 native go对象穿越脚本的黑魔法 dlv调查 对象穿越魔法揭秘 使用注意 总结 tengo锁 tengo并发 代码组织: 总结 error.go require/require.go parser/opcodes.go parser/source_file.go parser/parser.go NewParser()函数 ParseFile()函数 formatter.go Pool对象池技术 tengo.go FromInterface()和ToInterface()函数是go和脚本交互的核心 什么是callable对象 CountObjects这个递归函数写的真好 script.go Script.Add用于从native go添加变量到tengo脚本 NewScript Compile函数 preCompile()函数 RemoveDuplicates()去掉重复常量? RunContext()函数 Run函数 variable.go builtins.go compiler.go Compile()函数 emit()函数 Compile之module compileModule()函数 module默认路径 Bytecode()函数返回编译好的字节码 modules.go module类型: 支持import native go对象和tengo代码 symbol_table.go NewSymbolTable()函数 Define()函数 builtin符号除了保存在store中, 还保存在单独的builtinSymbols中 Fork()函数 Resolve()函数 总结 vm.go VM New函数 VM Run函数 vm.run总结 stdlib/func_typedefs.go tengo的后继 tengo 入门 语法 token 一个go调脚本的例子 所有都是值类型 tengo值类型和go类型 error升级为一等类型 值不可变 未定义也是一种类型 广义的array和map 函数也是值, 一等公民, 支持闭包 变量scope 内置类型转换 支持三目操作 []和.能作用于复合类型:array map string和bytes 再切片和go一样 if支持前置执行语句, 和go一样; for的结构也和go一样样的; for支持 for in 其他和native go的不同点 内置函数 被嵌入执行 直接代码执行 代码实时\"编译\"后执行 外部代码里import 用户可以自定义类型 自定义类型举例 增加更多功能 总结 模块化和标准库 标准库 runtime对象类型 安全性 并发 这里说的VM感觉就是编译后的\"表达树\"? 官方例子 更多官方例子 gento代码转成lua 有限状态机 增加VM的并发run 思路是浅拷贝当前的VM, 来run一个compiledFunc 编译函数 在compiler.go中 // Compile compiles the AST node. func (c *Compiler) Compile(node parser.Node) error { case *parser.FuncLit: //函数编译 c.enterScope() for _, p := range node.Type.Params.List { s := c.symbolTable.Define(p.Name) // function arguments is not assigned directly. s.LocalAssigned = true } if err := c.Compile(node.Body); err != nil { return err } // code optimization c.optimizeFunc(node) freeSymbols := c.symbolTable.FreeSymbols() //FreeSymbols函数返回\"原始\"symbol, 即被捕获的symbol, 所以才包含ScopeLocal和ScopeFree两个类型 numLocals := c.symbolTable.MaxSymbols() instructions, sourceMap := c.leaveScope() for _, s := range freeSymbols { //这段没看明白, 这里已经是父函数scope, OpGetFreePtr到栈上? -- 是的. 在定义的时候就把子函数的free变量全部放到栈上备用. 对应VM的OpClosure会把这些free变量放到其 switch s.Scope { case ScopeLocal: if !s.LocalAssigned { c.emit(node, parser.OpNull) c.emit(node, parser.OpDefineLocal, s.Index) s.LocalAssigned = true } c.emit(node, parser.OpGetLocalPtr, s.Index) //捕获了父函数的local变量, s.Index是local变量在栈上相对basePointer的index case ScopeFree: c.emit(node, parser.OpGetFreePtr, s.Index) //捕获了父函数的free变量, index是父函数freeVar数组中的index } } compiledFunction := &CompiledFunction{ Instructions: instructions, NumLocals: numLocals, NumParameters: len(node.Type.Params.List), VarArgs: node.Type.Params.VarArgs, SourceMap: sourceMap, } if len(freeSymbols) > 0 { c.emit(node, parser.OpClosure, c.addConstant(compiledFunction), len(freeSymbols)) } else { c.emit(node, parser.OpConstant, c.addConstant(compiledFunction)) } case *parser.CallExpr: //函数调用 if err := c.Compile(node.Func); err != nil { return err } for _, arg := range node.Args { if err := c.Compile(arg); err != nil { return err } } ellipsis := 0 if node.Ellipsis.IsValid() { ellipsis = 1 } c.emit(node, parser.OpCall, len(node.Args), ellipsis) //OpCall操作码 } VM执行函数 func (v *VM) run() { case parser.OpCall: numArgs := int(v.curInsts[v.ip+1]) spread := int(v.curInsts[v.ip+2]) v.ip += 2 //对应编译阶段的emit Opcall, 参数个数, 是否变长 //比如两个参数的func, 栈是 //sp-->| | //sp-1 | arg1 | //sp-2 | arg0 | //sp-3 | func | value := v.stack[v.sp-1-numArgs] //sp-3的object就是func if !value.CanCall() { v.err = fmt.Errorf(\"not callable: %s\", value.TypeName()) return } if spread == 1 { //如果最后的参数是变长的, 则那个object必然是array; 把array的成员都展开到栈上, 栈向上增长. 更新numArgs的值 v.sp-- switch arr := v.stack[v.sp].(type) { case *Array: for _, item := range arr.Value { v.stack[v.sp] = item v.sp++ } numArgs += len(arr.Value) - 1 case *ImmutableArray: for _, item := range arr.Value { v.stack[v.sp] = item v.sp++ } numArgs += len(arr.Value) - 1 default: v.err = fmt.Errorf(\"not an array: %s\", arr.TypeName()) return } } if callee, ok := value.(*CompiledFunction); ok { if callee.VarArgs { // if the closure is variadic, // roll up all variadic parameters into an array realArgs := callee.NumParameters - 1 varArgs := numArgs - realArgs if varArgs >= 0 { numArgs = realArgs + 1 args := make([]Object, varArgs) spStart := v.sp - varArgs for i := spStart; i =%d, got=%d\", callee.NumParameters-1, numArgs) } else { v.err = fmt.Errorf( \"wrong number of arguments: want=%d, got=%d\", callee.NumParameters, numArgs) } return } // test if it's tail-call if callee == v.curFrame.fn { // recursion nextOp := v.curInsts[v.ip+1] if nextOp == parser.OpReturn || (nextOp == parser.OpPop && parser.OpReturn == v.curInsts[v.ip+2]) { for p := 0; p = MaxFrames { v.err = ErrStackOverflow return } // update call frame v.curFrame.ip = v.ip // store current ip before call v.curFrame = &(v.frames[v.framesIndex]) //framesIndex是提前++的, 所以这里就是下一个frame v.curFrame.fn = callee v.curFrame.freeVars = callee.Free v.curFrame.basePointer = v.sp - numArgs //帧指针的初值是sp的当前值减去参数个数 v.curInsts = callee.Instructions v.ip = -1 v.framesIndex++ v.sp = v.sp - numArgs + callee.NumLocals //给局部变量留好空间, callee.NumLocals包括了arg的个数 } } 举例, 比如2个arg和4个局部变量的栈的初始情况 | | | local obj 0 | | arg obj 1 | | arg obj 0 | 函数怎么调用的? 比如下面的代码 fn := func(i) { return i+1 } ... res := fn(5) //res=6 是如何编译执行的? 编译阶段 编译器发现是case *parser.FuncLit:, 就编译func(i) { return i+1 }, 生成compiledFunction对象, 并把这个对象放到constant数组里, emit OpConstant操作码: c.emit(node, parser.OpConstant, c.addConstant(compiledFunction)); 如果是闭包函数, emit parser.OpClosure操做码. tengo不支持声明函数, 而是用赋值模式. 那么上面一步把func(i) { return i+1 }编译完成后, 把compiledFunction对象保存到constant数组, 并马上放到栈上. 因为接下来就是赋值操做 编译器发现接下来马上是case *parser.AssignStmt:对fn变量赋值: 在确定fn的符号位置后, 发送操作码到字节码:c.emit(node, parser.OpSetGlobal, symbol.Index) //或 c.emit(node, parser.OpSetLocal, symbol.Index) //或 c.emit(node, parser.OpSetFree, symbol.Index) 现在假设代码运行到某处, 需要调用fn:res := fn(5). 编译器需要先解析fn这个符号. 这个例子中fn就是符号引用, 但更复杂的情况可以是res := someMap.fn(5), 下面c.Compile(node.Func)就是解析这个表达式, 最终get到这个compiledFunction对象fn:这里面包括两个过程: 4.1. 先把fn放到栈上 4.2. 依次编译args, 把结果args对象依次放到栈上case *parser.CallExpr: if err := c.Compile(node.Func); err != nil { //最终对应*parser.Ident来确定符号, 对应emit的操做码是OpGetGlobal或OpGetLocal或OpGetBuiltin或OpGetFree, 效果是把compiledFunction对象fn放到栈上 return err } for _, arg := range node.Args { //比如这里的arg就是5, 它是个*parser.IntLit, 对应emit操作码OpConstant, 把5放到栈上 if err := c.Compile(arg); err != nil { return err } } ellipsis := 0 if node.Ellipsis.IsValid() { ellipsis = 1 } c.emit(node, parser.OpCall, len(node.Args), ellipsis) //最后emit OpCall 比如 //比如两个参数的func, 栈是 //sp-->| | //sp-1 | arg1 | //sp-2 | arg0 | //sp-3 | func | 执行阶段 VM负责执行 对应编译阶段的前三步, VM执行fn := func(i) { return i+1 }, 效果是把fn这个compiledFunction对象先临时保存在v.stack[v.sp-1]中, 再根据变量scope, 保存在下面三种变量区的一个 全局对象区, 即vm的globals数组中 栈中: 因为上一步已经把fn放在了v.stack[v.sp-1], 这里做的就是把v.stack[v.sp-1]赋值给v.stack[v.curFrame.basePointer + localIndex]. 这个localIndex是操做码里指定的, 编译阶段就知道了 frame的free数组中: *v.curFrame.freeVars[freeIndex].Value = v.stack[v.sp-1] VM执行到函数执行阶段res := fn(5)时: 对应case parser.OpCall: //比如两个参数的func, 栈是 //sp-->| | //sp-1 | arg1 | //sp-2 | arg0 | //sp-3 | func | 进入下一个栈帧前, 做准备: 保存当前ip到父栈帧 准备空的栈帧, 栈帧切换到子函数 子栈帧的fn为子函数callee 子栈帧的freeVars为callee.Free, 此时callee.Free里面已经准备好了 因为参数是父栈帧准备的, 这里子栈帧的basePointer = v.sp - numArgs 子栈帧的字节码为callee.Instructions 子栈帧的ip从-1开始, 正好下一次从0开始执行 把local变量的位置留出来, 子栈帧的sp从local变量区顶部开始. 进入下一个栈帧, 从ip=0开始执行fn.Instructions | | | local obj 0 | | arg obj 1 | | arg obj 0 | 函数怎么退出的? 在编译阶段, 空的return会c.emit(node, parser.OpReturn, 0) return一个表达式的情况, 会先编译这个表达式, 最终的结果对象放到栈顶, 然后c.emit(node, parser.OpReturn, 1) 执行阶段, 如果发现OpReturn的第二个操作数是1, 就从栈上拿到返回值; 然后还原栈帧, 还原sp, 并把返回值放到栈顶(此时已经是父函数的栈了). 如何理解字节码? 看这个文件compiler_test.go 运行时会改变/增加/删除 global或constant数组吗? 首先, constant数组是在编译时确定的, 在运行时不改变. 其次, global数组是可以更改的, 但不需要增加/删除, 因为对global的操做的index是在编译时就确定的. CompiledFunction的Free对象指针数组是干什么的? 在编译阶段, Resolve symbol的时候, 这个symbol可以是global的, 也可以是自己函数局部的, 还可以是父级函数路径上的局部函数. 最后这种情况就是free变量. if symbol is defined in parent table and if it's not global/builtin then it's free variable. free变量是一路父函数上的局部变量, resolve要化不少代价, 所以在编译生成函数对象CompiledFunction的时候就用Free []*ObjectPtr来保存对\"捕获\"的父函数局部变量的指针. 运行阶段 只有闭包函数有free变量, 闭包在编译的时候, emit的是OpClosure, 在这之前free变量已经从父函数的local区和free区拷贝到栈上了. if len(freeSymbols) > 0 { c.emit(node, parser.OpClosure, c.addConstant(compiledFunction), len(freeSymbols)) } else { c.emit(node, parser.OpConstant, c.addConstant(compiledFunction)) } 那么运行时 case parser.OpClosure: v.ip += 3 constIndex := int(v.curInsts[v.ip-1]) | int(v.curInsts[v.ip-2]) OpClosure操作码后面应该是接着赋值操做. 还有几个case: OpGetFreePtr:从freeVars数组取index对应的ptr到栈顶 OpGetFree: 从freeVars数组取index的ptr的Value到栈顶 OpSetFree: 栈顶obj赋值给freeVars数组index对应的ptr, 注意是赋值给*ptr OpGetLocalPtr: 把本frame的指定local变量v.stack[v.curFrame.basePointer + localIndex], 封装为*ObjectPtr, 放到栈顶. OpSetSelFree: 把selectors序列对应的对象依次写入v.curFrame.freeVars 结论 子函数可以是普通的函数, 也可以是Closure, 他们都是compiledFunction. 区别在于函数声明后, 必定会赋值到一个变量. 到变量赋值这里后, closure的compiledFunction的Free域就有值了, 这些值是指针, 是对free变量的指针表. 闭包对free变量的访问不是去父函数路径上的栈里去找, 而是去自己的free变量的指针表里操做. 例子 比如下面的代码 f1 := func(a, b) { return a + b}; func(fn, ...args){ return fn(args...) }(f1, 1, 2) 会被编译成 0000 CONST 0 //对应第一个函数从const 0取到栈顶 0003 SETG 0 //对应f1的赋值 0006 CONST 1 //对应第二个函数从const 1取到栈顶 0009 GETG 0 //对应f1入参 0012 CONST 2 //对应常量1入参 0015 CONST 3 //对应常量2入参 0018 CALL 3 0 //对应函数调用 0021 POP //对应这块代码无返回值 0022 SUSPEND //对应这块代码的结束 对应的const数组 [ 0] (Compiled Function|0xc0000946e8) 0000 GETL 0 //对应得到入参a 0002 GETL 1 //对应得到入参b 0004 BINARYOP 11 //a+b 0006 RET 1 //return 值 [ 1] (Compiled Function|0xc0000946f0) 0000 GETL 0 //对应得到fn 0002 GETL 1 //对应应该传入的args 0004 CALL 1 1 //call一个参数, 最后一个参数变长 0007 RET 1 //return栈上的值 [ 2] 1 (Int|0xc0000fd1e0) [ 3] 2 (Int|0xc0000fd200) tengo指令集和go的操作码 GO的编译器也有自己一套的”操作码”. 是对所有CPU指令集的common抽象, 比如下面的CALL就相当于MIPS指令集的jal或者ARM的blr Tengo的指令级比这个”高阶”, 比如数据访问永远都是以obj为单位. 但基本上思路是一样的. tengo运行过程 在REPL中加打印, 主要考察符号表, 全局变量, 和constants 初始状态 symbols: &tengo.SymbolTable{parent:(*tengo.SymbolTable)(nil), block:false, store:map[string]*tengo.Symbol{\"ex\":(*tengo.Symbol)(0xc0000df980), \"show\":(*tengo.Symbol)(0xc0000df9e0)}, numDe$ inition:2, maxDefinition:2, freeSymbols:[]*tengo.Symbol(nil), builtinSymbols:[]*tengo.Symbol(nil)} 没有父table, 是全局符号表. 里面有内建的两个函数: ex和show. 没毛病 constant为空 global只有两个, 对应ex和show. 没毛病 globals: []tengo.Object{(*tengo.UserFunction)(0xc0000df9b0), (*tengo.UserFunction)(0xc0000dfa10), ...后面都是nil a := 1 后 symtable由于第一次执行后, 多了内置的很多函数, 也多了变量a symbols: &tengo.SymbolTable{parent:(*tengo.SymbolTable)(nil), block:false, store:map[string]*tengo.Symbol{\"a\":(*tengo.Symbol)(0xc00018e690), \"append\":(*tengo.Symbol)(0xc00018e0f0), \"bool\":(*tengo.Symbol)(0xc00018e1e0), \"bytes\":(*tengo.Symbol)(0xc00018e270), \"char\":(*tengo.Symbol)(0xc00018e240), \"copy\":(*tengo.Symbol)(0xc00018e0c0), \"delete\":(*tengo.Symbol)(0xc00018e120), \"ex\":(*tengo.Symbol)(0xc0000df980), \"float\":(*tengo.Symbol)(0xc00018e210), \"format\":(*tengo.Symbol)(0xc00018e600), \"int\":(*tengo.Symbol)(0xc00018e1b0), \"is_array\":(*tengo.Symbol)(0xc00018e3f0), \"is_bool\":(*tengo.Symbol)(0xc00018e360), \"is_bytes\":(*tengo.Symbol)(0xc00018e3c0), \"is_callable\":(*tengo.Symbol)(0xc00018e5a0), \"is_char\":(*tengo.Symbol)(0xc00018e390), \"is_error\":(*tengo.Symbol)(0xc00018e510), \"is_float\":(*tengo.Symbol)(0xc00018e300), \"is_function\":(*tengo.Symbol)(0xc00018e570), \"is_immutable_array\":(*tengo.Symbol)(0xc00018e420), \"is_immutable_map\":(*tengo.Symbol)(0xc00018e480), \"is_int\":(*tengo.Symbol)(0xc00018e2d0), \"is_iterable\":(*tengo.Symbol)(0xc00018e4b0), \"is_map\":(*tengo.Symbol)(0xc00018e450), \"is_string\":(*tengo.Symbol)(0xc00018e330), \"is_time\":(*tengo.Symbol)(0xc00018e4e0), \"is_undefined\":(*tengo.Symbol)(0xc00018e540), \"len\":(*tengo.Symbol)(0xc00018e090), \"show\":(*tengo.Symbol)(0xc0000df9e0), \"splice\":(*tengo.Symbol)(0xc00018e150), \"string\":(*tengo.Symbol)(0xc00018e180), \"time\":(*tengo.Symbol)(0xc00018e2a0), \"type_name\":(*tengo.Symbol)(0xc00018e5d0)}, numDefinition:3, maxDefinition:3, freeSymbols:[]*tengo.Symbol(nil), builtinSymbols:[]*tengo.Symbol{(*tengo.Symbol)(0xc00018e090), (*tengo.Symbol)(0xc00018e0c0), (*tengo.Symbol)(0xc00018e0f0), (*tengo.Symbol)(0xc00018e120), (*tengo.Symbol)(0xc00018e150), (*tengo.Symbol)(0xc00018e180), (*tengo.Symbol)(0xc00018e1b0), (*tengo.Symbol)(0xc00018e1e0), (*tengo.Symbol)(0xc00018e210), (*tengo.Symbol)(0xc00018e240), (*tengo.Symbol)(0xc00018e270), (*tengo.Symbol)(0xc00018e2a0), (*tengo.Symbol)(0xc00018e2d0), (*tengo.Symbol)(0xc00018e300), (*tengo.Symbol)(0xc00018e330), (*tengo.Symbol)(0xc00018e360), (*tengo.Symbol)(0xc00018e390), (*tengo.Symbol)(0xc00018e3c0), (*tengo.Symbol)(0xc00018e3f0), (*tengo.Symbol)(0xc00018e420), (*tengo.Symbol)(0xc00018e450), (*tengo.Symbol)(0xc00018e480), (*tengo.Symbol)(0xc00018e4b0), (*tengo.Symbol)(0xc00018e4e0), (*tengo.Symbol)(0xc00018e510), (*tengo.Symbol)(0xc00018e540), (*tengo.Symbol)(0xc00018e570), (*tengo.Symbol)(0xc00018e5a0), (*tengo.Symbol)(0xc00018e5d0), (*tengo.Symbol)(0xc00018e600)}} constant多了一个 constants: []tengo.Object{(*tengo.Int)(0xc000138028)} globals多了一个, 多的这个和constant多出来的是一个地址. globals: []tengo.Object{(*tengo.UserFunction)(0xc0000df9b0), (*tengo.UserFunction)(0xc0000dfa10), (*tengo.Int)(0xc000138028) b := 2 后 symbol表多了b, 但似乎其他的符号地址都变了. -- 这里好像有bug symbols: &tengo.SymbolTable{parent:(*tengo.SymbolTable)(nil), block:false, store:map[string]*tengo.Symbol{\"a\":(*tengo.Symbol)(0xc00018e690), \"append\":(*tengo.Symbol)(0xc00020a0f0), \"b\":(*tengo.Symbol)(0xc00020a690), \"bool\":(*tengo.Symbol)(0xc00020a1e0), \"bytes\":(*tengo.Symbol)(0xc00020a270), \"char\":(*tengo.Symbol)(0xc00020a240), \"copy\":(*tengo.Symbol)(0xc00020a0c0), \"delete\":(*tengo.Symbol)(0xc00020a120), \"ex\":(*tengo.Symbol)(0xc0000df980), \"float\":(*tengo.Symbol)(0xc00020a210), \"format\":(*tengo.Symbol)(0xc00020a600), \"int\":(*tengo.Symbol)(0xc00020a1b0), \"is_array\":(*tengo.Symbol)(0xc00020a3f0), \"is_bool\":(*tengo.Symbol)(0xc00020a360), \"is_bytes\":(*tengo.Symbol)(0xc00020a3c0), \"is_callable\":(*tengo.Symbol)(0xc00020a5a0), \"is_char\":(*tengo.Symbol)(0xc00020a390), \"is_error\":(*tengo.Symbol)(0xc00020a510), \"is_float\":(*tengo.Symbol)(0xc00020a300), \"is_function\":(*tengo.Symbol)(0xc00020a570), \"is_immutable_array\":(*tengo.Symbol)(0xc00020a420), \"is_immutable_map\":(*tengo.Symbol)(0xc00020a480), \"is_int\":(*tengo.Symbol)(0xc00020a2d0), \"is_iterable\":(*tengo.Symbol)(0xc00020a4b0), \"is_map\":(*tengo.Symbol)(0xc00020a450), \"is_string\":(*tengo.Symbol)(0xc00020a330), \"is_time\":(*tengo.Symbol)(0xc00020a4e0), \"is_undefined\":(*tengo.Symbol)(0xc00020a540), \"len\":(*tengo.Symbol)(0xc00020a090), \"show\":(*tengo.Symbol)(0xc0000df9e0), \"splice\":(*tengo.Symbol)(0xc00020a150), \"string\":(*tengo.Symbol)(0xc00020a180), \"time\":(*tengo.Symbol)(0xc00020a2a0), \"type_name\":(*tengo.Symbol)(0xc00020a5d0)}, numDefinition:4, maxDefinition:4, freeSymbols:[]*tengo.Symbol(nil), builtinSymbols:[]*tengo.Symbol{(*tengo.Symbol)(0xc00018e090), (*tengo.Symbol)(0xc00018e0c0), (*tengo.Symbol)(0xc00018e0f0), (*tengo.Symbol)(0xc00018e120), (*tengo.Symbol)(0xc00018e150), (*tengo.Symbol)(0xc00018e180), (*tengo.Symbol)(0xc00018e1b0), (*tengo.Symbol)(0xc00018e1e0), (*tengo.Symbol)(0xc00018e210), (*tengo.Symbol)(0xc00018e240), (*tengo.Symbol)(0xc00018e270), (*tengo.Symbol)(0xc00018e2a0), (*tengo.Symbol)(0xc00018e2d0), (*tengo.Symbol)(0xc00018e300), (*tengo.Symbol)(0xc00018e330), (*tengo.Symbol)(0xc00018e360), (*tengo.Symbol)(0xc00018e390), (*tengo.Symbol)(0xc00018e3c0), (*tengo.Symbol)(0xc00018e3f0), (*tengo.Symbol)(0xc00018e420), (*tengo.Symbol)(0xc00018e450), (*tengo.Symbol)(0xc00018e480), (*tengo.Symbol)(0xc00018e4b0), (*tengo.Symbol)(0xc00018e4e0), (*tengo.Symbol)(0xc00018e510), (*tengo.Symbol)(0xc00018e540), (*tengo.Symbol)(0xc00018e570), (*tengo.Symbol)(0xc00018e5a0), (*tengo.Symbol)(0xc00018e5d0), (*tengo.Symbol)(0xc00018e600), (*tengo.Symbol)(0xc00020a090), (*tengo.Symbol)(0xc00020a0c0), (*tengo.Symbol)(0xc00020a0f0), (*tengo.Symbol)(0xc00020a120), (*tengo.Symbol)(0xc00020a150), (*tengo.Symbol)(0xc00020a180), (*tengo.Symbol)(0xc00020a1b0), (*tengo.Symbol)(0xc00020a1e0), (*tengo.Symbol)(0xc00020a210), (*tengo.Symbol)(0xc00020a240), (*tengo.Symbol)(0xc00020a270), (*tengo.Symbol)(0xc00020a2a0), (*tengo.Symbol)(0xc00020a2d0), (*tengo.Symbol)(0xc00020a300), (*tengo.Symbol)(0xc00020a330), (*tengo.Symbol)(0xc00020a360), (*tengo.Symbol)(0xc00020a390), (*tengo.Symbol)(0xc00020a3c0), (*tengo.Symbol)(0xc00020a3f0), (*tengo.Symbol)(0xc00020a420), (*tengo.Symbol)(0xc00020a450), (*tengo.Symbol)(0xc00020a480), (*tengo.Symbol)(0xc00020a4b0), (*tengo.Symbol)(0xc00020a4e0), (*tengo.Symbol)(0xc00020a510), (*tengo.Symbol)(0xc00020a540), (*tengo.Symbol)(0xc00020a570), (*tengo.Symbol)(0xc00020a5a0), (*tengo.Symbol)(0xc00020a5d0), (*tengo.Symbol)(0xc00020a600)}} constant多了一个, 就是b constants: []tengo.Object{(*tengo.Int)(0xc000138028), (*tengo.Int)(0xc00012a178)} globals也多了这一个 globals: []tengo.Object{(*tengo.UserFunction)(0xc0000df9b0), (*tengo.UserFunction)(0xc0000dfa10), (*tengo.Int)(0xc000138028), (*tengo.Int)(0xc00012a178) c := a+b 后 symbol table多了c, 但还是之前的问题: builtin的符号都被重新注册了一次, 地址都变了.但constants没有变化, 即c不是constantglobals多了c, 其他都一样. globals: []tengo.Object{(*tengo.UserFunction)(0xc0000df9b0), (*tengo.UserFunction)(0xc0000dfa10), (*tengo.Int)(0xc000138028), (*tengo.Int)(0xc00012a178), (*tengo.Int)(0xc0001e4228) f := func(a, b) { return a + b } 后 首先符号表多了f这个没有疑问. constants多了f, 类型是CompiledFunction constants: []tengo.Object{(*tengo.Int)(0xc000138028), (*tengo.Int)(0xc00012a178), (*tengo.CompiledFunction)(0xc0000c86e0)} 这个f也出现在globals里面 globals: []tengo.Object{(*tengo.UserFunction)(0xc0000df9b0), (*tengo.UserFunction)(0xc0000dfa10), (*tengo.Int)(0xc000138028), (*tengo.Int)(0xc00012a178), (*tengo.Int)(0xc0001e4228), (*ten go.CompiledFunction)(0xc0000c86e0) FormatConstants函数 这个函数可以查看constant的值, 比如: fmt.Println(bytecode.FormatConstants()) 会打印: [[ 0] 1 (Int|0xc0000f4920) [ 1] 2 (Int|0xc0000f4950) [ 2] (Compiled Function|0xc0000c4730) 0000 GETL 0 0002 GETL 1 0004 BINARYOP 11 0006 RET 1 ] 这个Compiled Function和汇编的风格很像. 同时可以看到FormatConstants函数能够把编译后的字节码打印出来. 那么什么是constant? 为什么constants数组在编译和运行时段都存在?constants是个对象数组, 保存的是固定值的变量, 比如上文的 a := 1 b := 2 f := func(a, b){...} constants在何处使用, 在何处定义 首先, VM在运行的时候, 在当前指令是parser.OpConstant的时候, 回去constants数组找需要的对象: v.stack[v.sp] = v.constants[cidx] func (v *VM) run() { for atomic.LoadInt64(&v.aborting) == 0 { v.ip++ switch v.curInsts[v.ip] { case parser.OpConstant: v.ip += 2 cidx := int(v.curInsts[v.ip]) | int(v.curInsts[v.ip-1]) 注意, constants对象数组是靠index来索引的. 这些constant对象, 是在编译的时候, 编译器发现a := 1变量是个常量, 就把它放到constants数组里, 并emit parser.OpConstant指令. func (c *Compiler) addConstant(o Object) int { if c.parent != nil { // module compilers will use their parent's constants array return c.parent.addConstant(o) } c.constants = append(c.constants, o) if c.trace != nil { c.printTrace(fmt.Sprintf(\"CONST %04d %s\", len(c.constants)-1, o)) } return len(c.constants) - 1 } // Compile compiles the AST node. func (c *Compiler) Compile(node parser.Node) error { ... case *parser.IntLit: c.emit(node, parser.OpConstant, c.addConstant(&Int{Value: node.Value})) case *parser.FloatLit: c.emit(node, parser.OpConstant, c.addConstant(&Float{Value: node.Value})) 为什么constants要传递给NewCompiler? 主要是用在REPL场景下, 把上一次的constants传递给这一次, 因为REPL是增量式编译执行模式, 需要前面的常量表和符号表, 而增量式的run也需要上一次的globals表. srcFile := fileSet.AddFile(\"repl\", -1, len(line)) p := parser.NewParser(srcFile, []byte(line), nil) file, err := p.ParseFile() if err != nil { fmt.Println(err) continue } c := tengo.NewCompiler(srcFile, sh.symbolTable, constants, sh.modules, nil) if err := c.Compile(file); err != nil { fmt.Println(err) continue } bytecode := c.Bytecode() bytecode.RemoveDuplicates() machine := tengo.NewVM(bytecode, sh.globals, -1) if err := machine.Run(); err != nil { fmt.Println(err) continue } constants = bytecode.Constants fmt.Println(bytecode.FormatConstants()) extension 为什么extension.UserFunction不生效? -- 注意Copy()方法 我在eobjects.go里面, 继承了tengo.UserFunction type UserFunction struct { tengo.UserFunction Signature string Help string } 我是想重载String方法, 这样fmt.println会调用到这个String方法, 显示help信息. func (o *UserFunction) TypeName() string { return \"user-function(extended):\" + o.Name } func (o *UserFunction) String() string { return o.Signature + \"\\n\" + o.Help } 在注册function的时候, 类型为&extension.UserFunction 编译通过, 似乎没问题. var module = map[string]tengo.Object{ \"newx\": &extension.UserFunction{ UserFunction: tengo.UserFunction{ Name: \"new\", Value: newStat, }, Signature: \"new({option1:true, option2:false}) => statCollector\", Help: \"option can be \", }, // new({option1:true, option2:false}) => statCollector } 但为什么还是调到了原tengo.UserFunction? 应该会打印帮助文本啊??? pidstat := import(\"pidstat\") fmt := import(\"fmt\") fmt.println(pidstat) {newx: , __module_name__: \"pidstat\"} 调查 用vscode和dlv调查, 发现在注册的时候是对的, object类型是&extension.UserFunction \"newx\": ) data: (0xc0000f8050) 但调用到fmt.println的时候, 传入的object类型就变成了 ) 是go的\"继承\"系统出了问题吗? 看起来像是对象从派生类变成基类了? -- 不是. go的继承没问题. 问题在注册module对象的时候, 返回了原module对象的Copy()方法, 目的是返回一个ImmutableMap // BuiltinModule is an importable module that's written in Go. type BuiltinModule struct { Attrs map[string]Object } // Import returns an immutable map for the module. func (m *BuiltinModule) Import(moduleName string) (interface{}, error) { return m.AsImmutableMap(moduleName), nil } // AsImmutableMap converts builtin module into an immutable map. func (m *BuiltinModule) AsImmutableMap(moduleName string) *ImmutableMap { attrs := make(map[string]Object, len(m.Attrs)) for k, v := range m.Attrs { attrs[k] = v.Copy() } attrs[\"__module_name__\"] = &String{Value: moduleName} return &ImmutableMap{Value: attrs} } 注意AsImmutableMap()函数里面, 调用了attrs[k] = v.Copy() 问题就出在这里: 我继承了基类的Copy()方法: // Copy returns a copy of the type. func (o *UserFunction) Copy() Object { return &UserFunction{Value: o.Value} } 它返回一个tengo.UserFunction对象. 所以后面fmt.println()的时候, 实际打印的是这个对象. 结论 tengo在注册module的时候, 为了不改变原对象, 对原对象进行了Copy(), 返回了immutable对象. immutable对象实际是调用原对象的Copy()方法来的, 要extend的话, 需要自己实现Copy()方法. bash 能够在bash的命令里引用脚本的变量吗? file := \"test\" fmt.println(bash.run(`touch $file`).output()) 简单回答: 不能. 因为bash.run()实际是调用的native go的代码, 调用的时候已经是在tengo的VM中运行的字节码调用的. 在ast阶段是有符号概念的, 但ast编译成字节码之后, 符号已经变成了\"地址\"了.所以, 调用到bash.run()时, 已经没有\"file\"这个变量了, 只有其对应的地址. 除非在ast中新增对$的解析, 在ast编译成字节码的阶段, 把touch $file对file的访问, emit成一个GetLocal的op. 比如c.emit(node, parser.OpGetLocal, symbol.Index) 解决方法 只有分两步走: file := \"testfile\" cmd := fmt.sprintf(\"touch %s\", file) fmt.println(bash.run(cmd).output()) 注: 使用tengo内置的format函数更简单点 pid := 10086 fmt.println(format(\"hello %d\", pid)) 添加新的builtin函数ex() 能否添加到builtinFuncs表 先说结论: tengo的builtin函数表是固定的, 外面无法更改. builtins.go中, 有个固化的表: var builtinFuncs = []*BuiltinFunction{ { Name: \"len\", Value: builtinLen, }, { Name: \"copy\", Value: builtinCopy, }, } 调用这个表里的函数, 不是以字符串方式查找函数的, 而是index: vm.go执行字节码阶段的run()函数: case parser.OpGetBuiltin: v.ip++ builtinIndex := int(v.curInsts[v.ip]) v.stack[v.sp] = builtinFuncs[builtinIndex] v.sp++ 从字节码里面取出builtinIndex, 查找builtinFuncs, 得到函数, 放到stack上. 而字节码的builtinIndex, 是在编译阶段compiler.go中Compile()函数: case *parser.Ident: symbol, _, ok := c.symbolTable.Resolve(node.Name, false) if !ok { return c.errorf(node, \"unresolved reference '%s'\", node.Name) } switch symbol.Scope { case ScopeGlobal: c.emit(node, parser.OpGetGlobal, symbol.Index) case ScopeLocal: c.emit(node, parser.OpGetLocal, symbol.Index) case ScopeBuiltin: c.emit(node, parser.OpGetBuiltin, symbol.Index) case ScopeFree: c.emit(node, parser.OpGetFree, symbol.Index) } 对符号的处理, 统一都是Resolve()当前的symbolTable, 得到symbol的Index信息, emit到字节码中. 字节码里面已经没有符号, 都是通过index来操作的. 这样最高效. 而最开始的符号, 是初始化的时候加的: gshell.go中runREPL()函数 symbolTable := tengo.NewSymbolTable() for idx, fn := range tengo.GetAllBuiltinFunctions() { symbolTable.DefineBuiltin(idx, fn.Name) } 这里只是加了符号表信息, 把符号的名字和index对上. 实际运行阶段, 按前文所述, vm会去builtinFuncs表中找. 添加到global表 函数也是对象, 那就可以当作\"全局变量\"添加到global表: 在symbolTable里定义一个ex的符号, 用返回的index和globals里面实际定义的函数对应起来. globals := make([]tengo.Object, tengo.GlobalsSize) symbolTable := tengo.NewSymbolTable() symbol := symbolTable.Define(\"ex\") globals[symbol.Index] = &tengo.UserFunction{ Name: \"ex\", Value: func(args ...tengo.Object) (ret tengo.Object, err error) { if len(args) != 1 { return nil, tengo.ErrWrongNumArguments } return extension.ExtendObj(args[0]) }, } 然后在NewCompiler()的时候传入symbolTable; 在NewVM()的时候传入globals 因为之前符号表和全局变量对的上, 那么运行时就能找到正确的函数. tengo代码 从简单的例子开始: import \"github.com/d5/tengo/v2\" var code = ` reduce := func(seq, fn) { s := 0 for x in seq { fn(x, s) } return s } print(reduce([1, 2, 3], func(x, s) { s += x })) ` func main() { s := tengo.NewScript([]byte(code)) if _, err := s.Run(); err != nil { panic(err) } } 上面是直接运行的例子. 下面是编译成字节码后运行的例子. s := tengo.NewScript([]byte(`a := b + 20`)) s.Add(\"b\", 10) c, err := s.Compile() err := c.Run() a := c.Get(\"a\") c.Set(\"b\", 20) c.Run() examples/interoperability/main.go func main() { src := ` // goproxy and proxy must be imported. goproxy := import(\"goproxy\") proxy := import(\"proxy\") global := 0 callbacks := { sum: func(a, b) { return a + b }, multiply: func(a, b) { return a * b }, increment: func() { global++ return global } } // Register callbacks to call them in goproxy loop. goproxy.register(callbacks) // goproxy loop waits for new call requests and run them with the help of // \"proxy\" source module. Cancelling the context breaks the loop. for goproxy.next() { proxy(goproxy.args()) } ` // 5 seconds context timeout is enough for an example. ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() script := tengo.NewScript([]byte(src)) moduleMap := tengo.NewModuleMap() goproxy := NewGoProxy(ctx) // register modules moduleMap.AddBuiltinModule(\"goproxy\", goproxy.ModuleMap()) moduleMap.AddSourceModule(\"proxy\", []byte(ProxySource)) script.SetImports(moduleMap) compiled, err := script.Compile() if err != nil { panic(err) } // call \"sum\", \"multiply\", \"increment\" functions from tengo in a new goroutine go func() { callChan := goproxy.CallChan() result := make(chan tengo.Object, 1) // TODO: check tengo error from result channel. loop: for { select { case 可被注册的对象: native go // NewGoProxy creates GoProxy object. func NewGoProxy(ctx context.Context) *GoProxy { mod := new(GoProxy) mod.ctx = ctx mod.callbacks = make(map[string]tengo.Object) mod.callChan = make(chan *CallArgs, 1) mod.moduleMap = map[string]tengo.Object{ \"next\": &tengo.UserFunction{Value: mod.next}, \"register\": &tengo.UserFunction{Value: mod.register}, \"args\": &tengo.UserFunction{Value: mod.args}, } mod.tasks = list.New() return mod } // GoProxy is a builtin tengo module to register tengo functions and run them. type GoProxy struct { tengo.ObjectImpl //匿名包含tengo.ObjectImpl就是tengo的Object ctx context.Context moduleMap map[string]tengo.Object callbacks map[string]tengo.Object callChan chan *CallArgs tasks *list.List mtx sync.Mutex } 上面的mod.next mod.args等符号, 是函数: 比如 func (mod *GoProxy) register(args ...tengo.Object) (tengo.Object, error) { if len(args) == 0 { return nil, tengo.ErrWrongNumArguments } mod.mtx.Lock() defer mod.mtx.Unlock() switch v := args[0].(type) { case *tengo.Map: mod.callbacks = v.Value case *tengo.ImmutableMap: mod.callbacks = v.Value default: return nil, tengo.ErrInvalidArgumentType{ Name: \"first\", Expected: \"map\", Found: args[0].TypeName(), } } return tengo.UndefinedValue, nil } 这些函数必须符合CallableFunc签名: // CallableFunc is a function signature for the callable functions. type CallableFunc = func(args ...Object) (ret Object, err error) 注意, 这里mod.register等函数, 在语法上是*GoProxy的方法, 为什么符合CallableFunc签名呢?tengo脚本里面的goproxy.register(callbacks) 又是怎么调用到func (mod *GoProxy) register(args ...tengo.Object) (tengo.Object, error)的呢? 这里的receiver是从哪里来的呢?还有, New过的goproxy, 怎么在脚本和native go之前共享的呢?goproxy := NewGoProxy(ctx)见 native go对象穿越脚本的黑魔法 注: native go也可以调用tengo的函数脚本的goproxy.register(callbacks)其实会调用到native go的register函数, 而它的callbacks是tengo脚本里的函数 global := 0 callbacks := { sum: func(a, b) { return a + b }, multiply: func(a, b) { return a * b }, increment: func() { global++ return global } } 上面的脚本函数对应native go的*tengo.CompiledFunction对象. 在neitive go里断言得到compiledFunc对象. //mod.callbacks是在register的时候赋值的 //mod.callbacks = v.Value f, ok := mod.callbacks[callArgs.Func] compiledFunc, ok := f.(*tengo.CompiledFunction) 然后return一个不可改的tengo.Map return &tengo.ImmutableMap{ Value: map[string]tengo.Object{ ... \"callable\": compiledFunc, } } 通过这个对象, 脚本就又可以调用\"callable\"函数了, 即最终, 脚本调用\"callable\"是compiledFunc, 而后者就是从tengo脚本compile来的. 通常使用类型断言来解参数, 比如 switch v := args[0].(type) { case *tengo.Map: mod.callbacks = v.Value case *tengo.ImmutableMap: mod.callbacks = v.Value 这需要直到tengo中Object的具体类型的定义: type Map struct { ObjectImpl Value map[string]Object } native go里实现的函数, 可以做参数检查: 在这里是提示tengo脚本里的入参类型不对 default: return nil, tengo.ErrInvalidArgumentType{ Name: \"first\", Expected: \"map\", Found: args[0].TypeName(), } 从tengo脚本调用native go的过程就是解tengo.Object到go对象, 运算, 再返回tengo.Object的过程 函数方法返回的Object, 可以继续是一个BuiltinModule func (mod *GoProxy) args(args ...tengo.Object) (tengo.Object, error) { mod.mtx.Lock() defer mod.mtx.Unlock() if mod.tasks.Len() == 0 { return tengo.UndefinedValue, nil } el := mod.tasks.Front() callArgs, ok := el.Value.(*CallArgs) if !ok || callArgs == nil { return nil, errors.New(\"invalid call arguments\") } mod.tasks.Remove(el) f, ok := mod.callbacks[callArgs.Func] if !ok { return tengo.UndefinedValue, nil } compiledFunc, ok := f.(*tengo.CompiledFunction) if !ok { return tengo.UndefinedValue, nil } params := callArgs.Params if params == nil { params = make([]tengo.Object, 0) } // callable.VarArgs implementation is omitted. return &tengo.ImmutableMap{ Value: map[string]tengo.Object{ \"result\": &tengo.UserFunction{ Value: func(args ...tengo.Object) (tengo.Object, error) { if len(args) > 0 { callArgs.Result 注: native go&tengo.ImmutableMap中的\"params\": &tengo.Array{Value: params},可以被tengo脚本使用: v = callable(args.params[0], args.params[1], args.params[2]) 可被注册的对象: tengo脚本 在main()中import了tengo的源码: moduleMap.AddSourceModule(\"proxy\", []byte(ProxySource)) 脚本源码在此: // ProxySource is a tengo script to handle bidirectional arguments flow between // go and pure tengo functions. Note: you should add more if conditions for // different number of parameters. // TODO: handle variadic functions. var ProxySource = ` export func(args) { if is_undefined(args) { return } callable := args.callable if is_undefined(callable) { return } result := args.result num_params := args.num_params v := undefined // add more else if conditions for different number of parameters. if num_params == 0 { v = callable() } else if num_params == 1 { v = callable(args.params[0]) } else if num_params == 2 { v = callable(args.params[0], args.params[1]) } else if num_params == 3 { v = callable(args.params[0], args.params[1], args.params[2]) } result(v) } ` 注: 要在外部脚本引用的对象, 用export关键词导出 native go对象穿越脚本的黑魔法 在native go中, New了对象后, 只是把goproxy的moduleMap注册给script goproxy := NewGoProxy(ctx) moduleMap.AddBuiltinModule(\"goproxy\", goproxy.ModuleMap()) 其中, 这个map包括了这个模块支持的方法 mod.moduleMap = map[string]tengo.Object{ \"next\": &tengo.UserFunction{Value: mod.next}, \"register\": &tengo.UserFunction{Value: mod.register}, \"args\": &tengo.UserFunction{Value: mod.args}, } 比如, register函数原型是 func (mod *GoProxy) register(args ...tengo.Object) (tengo.Object, error) 被包装成了&tengo.UserFunction{Value: mod.register}保存在goproxy.ModuleMap中 而在tengo脚本中, import只是得到这个map, 就直接调用native go的register方法了 goproxy := import(\"goproxy\") //调用native go的方法 goproxy.register(callbacks) 那么问题是, receiver哪去了? 没有receiver怎么调用 dlv调查 tengo脚本经过compile后, Run这个字节码: compiled.RunContext(ctx) vm.run()的执行循环中 for atomic.LoadInt64(&v.aborting) == 0 { v.ip++ switch v.curInsts[v.ip] { case parser.OpCall: //支持CompiledFunction类型的执行, 这块对应tengo编译后的函数 //但这里走的是UserFunction的分支 var args []Object args = append(args, v.stack[v.sp-numArgs:v.sp]...) //这里就是函数调用了 //value的静态类型是tengo.Object, 动态类型是tengo.UserFunction //其值是main.(*GoProxy).register-fm, 见下图当时value的值 ret, e := value.Call(args...) v.sp -= numArgs + 1 ... 当时value的值到这里有点有意思了: native go注册的函数是mod.register mod.moduleMap = map[string]tengo.Object{ \"register\": &tengo.UserFunction{Value: mod.register}, } 这里看到实际是main.(*GoProxy).register-fm 这个带fm字样的函数应该是编译器生成的, 或者说是编译器内部对\"方法\"到\"函数\"的转换表达: 它自带.this做为receiverdlv对main.(*GoProxy).register-fm的处理也是隐形的: 它直接定位到func (mod *GoProxy) register(args ...tengo.Object) (tengo.Object, error)函数, 但调用栈能看到:register-fm是register的上级函数:注意: register-fm的.this就是注册时候的\"register\": &tengo.UserFunction{Value: mod.register},中的mod, 是同一个对象. 待调用到register时, .this从register-fm变为receiver. 对象穿越魔法揭秘 编译的时候, 编译器发现这里把\"方法\"赋值给\"函数\", 比如:func (mod *GoProxy) register(args ...tengo.Object) (tengo.Object, error)赋值给CallableFunc, 其定义为func(args ...Object) (ret Object, err error)即:\"register\": &tengo.UserFunction{Value: mod.register} 那么此时编译器会给每个obj.function自动生成functionName-fm()函数, obj被保存到.this. 运行的时候functionName-fm()会调用obj.function(), 并把保存的.this做为receiver, 类似调用(.this).fucntion()编译后的符号表有functionName-fm()出现: go tool objdump -S interoperability看的非常清楚: 赋值的时候就是register-fm这样赋值的结果是: mod对象会被带进UserFunction 所以, 这里的魔法是编译器在把\"方法\"转换为\"函数\"时, 生成的-fm包装代码. 详见: src/cmd/compile/internal/gc/closure.go的makepartialcall()函数 -- 真正的黑科技永远是芯片和编译器 使用注意 注意要用实际对象的方法来注册, 即下面的mod是个实例化过的对象. // NewGoProxy creates GoProxy object. func NewGoProxy(ctx context.Context) *GoProxy { mod := new(GoProxy) mod.ctx = ctx mod.callbacks = make(map[string]tengo.Object) mod.callChan = make(chan *CallArgs, 1) mod.moduleMap = map[string]tengo.Object{ \"next\": &tengo.UserFunction{Value: mod.next}, \"register\": &tengo.UserFunction{Value: mod.register}, \"args\": &tengo.UserFunction{Value: mod.args}, } mod.tasks = list.New() return mod } 其实(*GoProxy).next也是语法合法的, 但它是type func(*GoProxy, args ...v2.Object) (v2.Object, error), 第一个参数是*GoProxy; 在这里不能赋值给func(args ...Object) (ret Object, err error) 总结 tengo脚本和自定义native go的交互: native go的入参和返回值都是tengo.Object native go返回的tengo.Object的concrete类型可以是 &tengo.UserFunction: 脚本可以继续调函数 &tengo.Int: 脚本能直接用做Int &tengo.Array: 脚本能按[index]来访问 其他Object类型 估计也可以自定义类型, 见用户可以自定义类型 tengo脚本可以调用native go的代码 native go也可以调用tengo的函数 native go的对象方法能够转换为tengo脚本的函数. 要在tengo脚本里import(\"module_name\"), 这个module必须先在native go代码里注册. 参考stdlib/stdlib.go中的GetModuleMap()函数 tengo锁 tengo并发 script_test.go中, 有个测并发的函数: 用了compiled.Clone()复制一个compiled对象, 每个go routine用复制的compiled对象来运行. for i := 0; i Clone函数主要是clone了golbals全局变量集, 这样routine之前的全局变量不打架.其他的几个filed, 都没有实际拷贝, 而是用了引用. // Clone creates a new copy of Compiled. Cloned copies are safe for concurrent // use by multiple goroutines. func (c *Compiled) Clone() *Compiled { c.lock.Lock() defer c.lock.Unlock() clone := &Compiled{ globalIndexes: c.globalIndexes, bytecode: c.bytecode, globals: make([]Object, len(c.globals)), maxAllocs: c.maxAllocs, } // copy global objects for idx, g := range c.globals { if g != nil { clone.globals[idx] = g } } return clone } 说明: 在vM执行过程中, bytecode是不会变的 global的对照表也不变 代码组织: tengo很多代码都是直接属于tengo包的. 总结 SourceFile和symbolTable和constants和modules是Compiler(*tengo.Compiler)的属性. 而经过parser解析文本内容而来的代表ast的parser.File是Compiler的输入 编译后的bytecode和全局变量array是运行时VM的输入 constants是运行时\"不变\"的Object的集合. 比如:a:=1和b:=2中的a和b是constant; 而c=a+b的c就不是constant. 不变的函数也是constant. 随着bytecode传递, 每次执行会改变 tengo的Script经过compile后的compiled对象, 代表了VM之前的所有步骤. compiled包括globals和bytecode 在没有compiled.Run之前, globals是可以改的. compiled.Set()可以改 compiled.Get()可以得到结果. compiled的Get()和Set()是go调用tengo脚本的时候, 和脚本交互变量用的. error.go 内部预定义错误, 比如ErrStringLimit = errors.New(\"exceeding string size limit\") require/require.go require.go依赖标准库testing, 提供了一些type断言的功能. 主要是tengo的内部test代码在用. parser/opcodes.go opcodes定义了支持的所有操作: 注意这里是\"指令流\"的操作, 没有for, 因为for已经被编译成类似Jump的指令了 // List of opcodes const ( OpConstant Opcode = iota // Load constant OpBComplement // bitwise complement OpPop // Pop OpTrue // Push true OpFalse // Push false OpEqual // Equal == OpNotEqual // Not equal != OpMinus // Minus - OpLNot // Logical not ! OpJumpFalsy // Jump if falsy OpAndJump // Logical AND jump OpOrJump // Logical OR jump OpJump // Jump OpNull // Push null OpArray // Array object OpMap // Map object OpError // Error object OpImmutable // Immutable object OpIndex // Index operation OpSliceIndex // Slice operation OpCall // Call function OpReturn // Return OpGetGlobal // Get global variable OpSetGlobal // Set global variable OpSetSelGlobal // Set global variable using selectors OpGetLocal // Get local variable OpSetLocal // Set local variable OpDefineLocal // Define local variable OpSetSelLocal // Set local variable using selectors OpGetFreePtr // Get free variable pointer object OpGetFree // Get free variables OpSetFree // Set free variables OpGetLocalPtr // Get local variable as a pointer OpSetSelFree // Set free variables using selectors OpGetBuiltin // Get builtin function OpClosure // Push closure OpIteratorInit // Iterator init OpIteratorNext // Iterator next OpIteratorKey // Iterator key OpIteratorValue // Iterator value OpBinaryOp // Binary operation OpSuspend // Suspend VM ) parser/source_file.go 提供了脚本file的表达, 重点是file 集合 // SourceFileSet represents a set of source files. type SourceFileSet struct { Base int // base offset for the next file Files []*SourceFile // list of files in the order added to the set LastFile *SourceFile // cache of last file looked up } 其中SourceFile还可以包括Files // SourceFile represents a source file. type SourceFile struct { // SourceFile set for the file set *SourceFileSet // SourceFile name as provided to AddFile Name string // SourcePos value range for this file is [base...base+size] Base int // SourceFile size as provided to AddFile Size int // Lines contains the offset of the first character for each line // (the first entry is always 0) Lines []int } 所以一个file集合是个树状的. parser/parser.go parser的底层是token, 对下调用token的方法, 对上提供词法分析 parser持有scanner实例, 提供next方法 // Parser parses the Tengo source files. It's based on Go's parser // implementation. type Parser struct { file *SourceFile errors ErrorList scanner *Scanner pos Pos token token.Token tokenLit string exprLevel int // = 0: in expression syncPos Pos // last sync position syncCount int // number of advance calls without progress trace bool indent int traceOut io.Writer } NewParser()函数 NewParser返回一个parser对象, 值得一提的是, 如果trace不是nil, 会输出debug信息到指定的io.Writer // NewParser creates a Parser. func NewParser(file *SourceFile, src []byte, trace io.Writer) *Parser { p := &Parser{ file: file, trace: trace != nil, traceOut: trace, } p.scanner = NewScanner(p.file, src, func(pos SourceFilePos, msg string) { p.errors.Add(pos, msg) }, 0) p.next() return p } ParseFile()函数 ParseFile的核心是返回一个[]Stmt, 即表达式的集合 // ParseFile parses the source and returns an AST file unit. func (p *Parser) ParseFile() (file *File, err error) { defer func() { if e := recover(); e != nil { if _, ok := e.(bailout); !ok { panic(e) } } p.errors.Sort() //这里用defer在最后来排序erros err = p.errors.Err() }() if p.trace { defer untracep(tracep(p, \"File\")) //使用了defer的trace技术 } if p.errors.Len() > 0 { return nil, p.errors.Err() } stmts := p.parseStmtList() if p.errors.Len() > 0 { return nil, p.errors.Err() } file = &File{ InputFile: p.file, Stmts: stmts, } return } stmt是个抽象化的接口 type Stmt interface { Node stmtNode() } parseStmtList()不断调用p.parseStmt(), 并把结果放到[]Stmt中 func (p *Parser) parseStmtList() (list []Stmt) { if p.trace { defer untracep(tracep(p, \"StatementList\")) } for p.token != token.RBrace && p.token != token.EOF { list = append(list, p.parseStmt()) } return } parseStmt()是核心函数, 根据每次根据token的类型做动作, 并且前进(advance) func (p *Parser) parseStmt() (stmt Stmt) { if p.trace { defer untracep(tracep(p, \"Statement\")) } switch p.token { case // simple statements token.Func, token.Error, token.Immutable, token.Ident, token.Int, token.Float, token.Char, token.String, token.True, token.False, token.Undefined, token.Import, token.LParen, token.LBrace, token.LBrack, token.Add, token.Sub, token.Mul, token.And, token.Xor, token.Not: s := p.parseSimpleStmt(false) p.expectSemi() return s case token.Return: return p.parseReturnStmt() case token.Export: return p.parseExportStmt() case token.If: return p.parseIfStmt() case token.For: return p.parseForStmt() case token.Break, token.Continue: return p.parseBranchStmt(p.token) case token.Semicolon: s := &EmptyStmt{Semicolon: p.pos, Implicit: p.tokenLit == \"\\n\"} p.next() return s case token.RBrace: // semicolon may be omitted before a closing \"}\" return &EmptyStmt{Semicolon: p.pos, Implicit: true} default: pos := p.pos p.errorExpected(pos, \"statement\") p.advance(stmtStart) return &BadStmt{From: pos, To: p.pos} } } 比如其中的token.If func (p *Parser) parseIfStmt() Stmt { if p.trace { defer untracep(tracep(p, \"IfStmt\")) } pos := p.expect(token.If) init, cond := p.parseIfHeader() body := p.parseBlockStmt() var elseStmt Stmt if p.token == token.Else { p.next() switch p.token { case token.If: elseStmt = p.parseIfStmt() case token.LBrace: elseStmt = p.parseBlockStmt() p.expectSemi() default: p.errorExpected(p.pos, \"if or {\") elseStmt = &BadStmt{From: p.pos, To: p.pos} } } else { p.expectSemi() } return &IfStmt{ IfPos: pos, Init: init, Cond: cond, Body: body, Else: elseStmt, } } 这个过程存在不少的递归. 比如if的body就是body := p.parseBlockStmt(), 而BlockStmt里面又可以包含任何的语句. func (p *Parser) parseBlockStmt() *BlockStmt { if p.trace { defer untracep(tracep(p, \"BlockStmt\")) } lbrace := p.expect(token.LBrace) list := p.parseStmtList() rbrace := p.expect(token.RBrace) return &BlockStmt{ LBrace: lbrace, RBrace: rbrace, Stmts: list, } } formatter.go 提供了format tengo对象Object的函数, 这些函数是自己实现的, 不依赖标准库fmt. // Format is like fmt.Sprintf but using Objects. func Format(format string, a ...Object) (string, error) Pool对象池技术 这里使用了sync.Pool技术来避免重复分配内存. 注: sync.Pool是标准库提供的对象池化技术, 主要用于cache对象, 减轻gc压力. 要点: 提供Put()和Get()接口, 用来存取pool中对象. Put()和Get()没有相关性. 不保证Put过的对象就一定能Get()到 实际上, 这里是对象池. 使用者不应该关心对象携带的\"历史\"信息. Get()一个就是一个新的对象. 可以提供一个New func() interface{}函数, Get()不到的时候也返回一个新的. 并发安全 标准库fmt使用了Pool技术 pool不能被拷贝 似乎比较heavy. 轻量的free list的需求场景建议自己实现对象free list 新建对象池, 这里提供了默认的New方法: var ppFree = sync.Pool{ New: func() interface{} { return new(pp) }, } 从对象池get: // newPrinter allocates a new pp struct or grabs a cached one. func newPrinter() *pp { p := ppFree.Get().(*pp) p.erroring = false p.fmt.init(&p.buf) return p } free对象, 放到对象池 // free saves used pp structs in ppFree; avoids an allocation per invocation. func (p *pp) free() { // Proper usage of a sync.Pool requires each entry to have approximately // the same memory cost. To obtain this property when the stored type // contains a variably-sized fmtbuf, we add a hard limit on the maximum // fmtbuf to place back in the pool. // // See https://golang.org/issue/23199 if cap(p.buf) > 64 在这里, 被池化的对象是 // pp is used to store a printer's state and is reused with sync.Pool to avoid // allocations. type pp struct { buf fmtbuf // arg holds the current item. arg Object // fmt is used to format basic items such as integers or strings. fmt formatter // reordered records whether the format string used argument reordering. reordered bool // goodArgNum records whether the most recent reordering directive was // valid. goodArgNum bool // erroring is set when printing an error string to guard against calling // handleMethods. erroring bool } tengo.go tengo.go里面的函数, 入参都是统一的Object, 利用类型断言来搞事情, 提供入参是Object, 对外统一的函数. 比如: func ToInt(o Object) (v int, ok bool) func CountObjects(o Object) (c int) ... //最后这对方法很特别, 是native go和tengo类型互转的关键 func ToInterface(o Object) (res interface{}) func FromInterface(v interface{}) (Object, error) 对外提供统一的API, 即入参是Object的API, 有两个思路 本例中, 传入Object接口, 在函数实现里面搞类型断言, 比如:// ToTime will try to convert object o to time.Time value. func ToTime(o Object) (v time.Time, ok bool) { switch o := o.(type) { case *Time: v = o.Value ok = true case *Int: v = time.Unix(o.Value, 0) ok = true } return } 所有的对外API都定义成接口, 比如要求Object全部实现func ToTime(o Object) (v time.Time, ok bool)方法 比较而言, 第一种好点: 并不是所有Object都需要ToTime, 对一个array来搞ToTime有点怪. 而通过一个统一函数, ToTime(Object)的方式, 不怪, 如果传入Array类型的Object, 就返回0值就好了. FromInterface()和ToInterface()函数是go和脚本交互的核心 FromInterface()从go的interface{}推断得到tengo的Object; 而ToInterface()正好相反 // FromInterface will attempt to convert an interface{} v to a Tengo Object func FromInterface(v interface{}) (Object, error) { switch v := v.(type) { case nil: return UndefinedValue, nil //UndefinedValue Object = &Undefined{} 定义于objects.go case string: if len(v) > MaxStringLen { //tengo的String不能大于MaxStringLen, 2G, 已经非常大了 return nil, ErrStringLimit } return &String{Value: v}, nil case int64: return &Int{Value: v}, nil case int: return &Int{Value: int64(v)}, nil case bool: if v { return TrueValue, nil } return FalseValue, nil case rune: return &Char{Value: v}, nil case byte: return &Char{Value: rune(v)}, nil case float64: return &Float{Value: v}, nil case []byte: if len(v) > MaxBytesLen { return nil, ErrBytesLimit } return &Bytes{Value: v}, nil //Bytes就是[]byte的tengo表达 case error: return &Error{Value: &String{Value: v.Error()}}, nil //Error默认是值为string case map[string]Object: //注意这个case, 比下个case更具体, 要放在前面; 从go代码调用下来, 有能力断言Object return &Map{Value: v}, nil case map[string]interface{}: //层层嵌套的map kv := make(map[string]Object) for vk, vv := range v { vo, err := FromInterface(vv) //递归调用 if err != nil { return nil, err } kv[vk] = vo } return &Map{Value: kv}, nil case []Object: //array类型 return &Array{Value: v}, nil case []interface{}: //层层嵌套的arrary arr := make([]Object, len(v)) for i, e := range v { vo, err := FromInterface(e) //递归调用 if err != nil { return nil, err } arr[i] = vo } return &Array{Value: arr}, nil case time.Time: return &Time{Value: v}, nil //Time就是time.Time的包装 case Object: return v, nil case CallableFunc: return &UserFunction{Value: v}, nil } return nil, fmt.Errorf(\"cannot convert to object: %T\", v) } 什么是callable对象 符合这个签名的都是: // CallableFunc is a function signature for the callable functions. type CallableFunc = func(args ...Object) (ret Object, err error) 经过测试 type test struct { a int } 和下面带=号的版本, 都能编过, 效果差不多 type test = struct { a int } 但还是有些差别: =版本的type, 只是别名, an alternate spelling; 别名拥有原名的一切属性 普通版本的type定义, 是一个全新的类型, 不具有原类型的方法 CountObjects这个递归函数写的真好 最里层返回预设值1, 其他情况递归的计算array/map的元素个数 // CountObjects returns the number of objects that a given object o contains. // For scalar value types, it will always be 1. For compound value types, // this will include its elements and all of their elements recursively. func CountObjects(o Object) (c int) { c = 1 switch o := o.(type) { case *Array: for _, v := range o.Value { c += CountObjects(v) } case *ImmutableArray: for _, v := range o.Value { c += CountObjects(v) } case *Map: for _, v := range o.Value { c += CountObjects(v) } case *ImmutableMap: for _, v := range o.Value { c += CountObjects(v) } case *Error: c += CountObjects(o.Value) } return } script.go 依赖parser, 用于嵌入代码和调用go代码的交互. 新建script实例, 从go代码add变量进script 还提供了一些API func (s *Script) EnableFileImport(enable bool) Script.Add用于从native go添加变量到tengo脚本 即把interface{}转换为{name, Object}, 加到script的variablesmap里 // Add adds a new variable or updates an existing variable to the script. func (s *Script) Add(name string, value interface{}) error { obj, err := FromInterface(value) //见tengo.go里的函数实现 if err != nil { return err } s.variables[name] = &Variable{ name: name, value: obj, } return nil } NewScript 在script.go中, NewScript简单到返回一个结构体: // Variable is a user-defined variable for the script. type Variable struct { name string value Object //Object是tengo的数据类型的统一表述(接口) } // Script can simplify compilation and execution of embedded scripts. type Script struct { variables map[string]*Variable //script和外部go的变量交互通过这个map modules *ModuleMap input []byte maxAllocs int64 maxConstObjects int enableFileImport bool importDir string } // NewScript creates a Script instance with an input script. func NewScript(input []byte) *Script { return &Script{ variables: make(map[string]*Variable), input: input, maxAllocs: -1, maxConstObjects: -1, } } Compile函数 Script对象的Compile方法把代码编译成Compiled对象 Compiled对象包括了字节码和全局变量, 和一个锁 // Compiled is a compiled instance of the user script. Use Script.Compile() to // create Compiled object. type Compiled struct { globalIndexes map[string]int // global symbol name to index globals []Object //以上两个域一起, 实际就是map[string]Object; 这里作者这么搞怕不是有什么优化 bytecode *Bytecode maxAllocs int64 lock sync.RWMutex } Compile函数流程 func (s *Script) Compile() (*Compiled, error) { symbolTable, globals, err := s.prepCompile() //新建符号表, 建立全局变量索引 fileSet := parser.NewFileSet() //新建一个fileset, fileset类似文件描述符, 本身不存储文件内容 srcFile := fileSet.AddFile(\"(main)\", -1, len(s.input)) //AddFile加默认的main文件, 此时只是传入len p := parser.NewParser(srcFile, s.input, nil) //到NewParser才把文件和s.input内容联系起来. file, err := p.ParseFile() c := NewCompiler(srcFile, symbolTable, nil, s.modules, nil) c.EnableFileImport(s.enableFileImport) c.SetImportDir(s.importDir) err := c.Compile(file) //优化全局变量 ... // remove duplicates from constants bytecode := c.Bytecode() bytecode.RemoveDuplicates() //检查最大object数目是否超限制 //这里的变量名和域名一样, 是合法的. return &Compiled{ globalIndexes: globalIndexes, bytecode: bytecode, //看起来这个bytecode是关键 globals: globals, maxAllocs: s.maxAllocs, }, nil } preCompile()函数 preCompile函数负责创建初始symbolTable, 并把Script.Add()加入的变量, Define到symbolTable中. 注意Define只是增加个符号, 而不是保存实际值. 实际值保存在单独的变量表中: preCompile还增加builtin的符号 preCompile返回符号表和全局变量表. func (s *Script) prepCompile() ( symbolTable *SymbolTable, globals []Object, err error, ) { var names []string for name := range s.variables { names = append(names, name) } symbolTable = NewSymbolTable() for idx, fn := range builtinFuncs { symbolTable.DefineBuiltin(idx, fn.Name) } globals = make([]Object, GlobalsSize) for idx, name := range names { symbol := symbolTable.Define(name) if symbol.Index != idx { panic(fmt.Errorf(\"wrong symbol index: %d != %d\", idx, symbol.Index)) } globals[symbol.Index] = s.variables[name].value //实际的Object保存在global中 } return } RemoveDuplicates()去掉重复常量? 没细看 RunContext()函数 这是个带超时的Run()函数 // RunContext is like Run but includes a context. func (c *Compiled) RunContext(ctx context.Context) (err error) { c.lock.Lock() defer c.lock.Unlock() v := NewVM(c.bytecode, c.globals, c.maxAllocs) ch := make(chan error, 1) go func() { ch Run函数 script的Run // Run compiles and runs the scripts. Use returned compiled object to access // global variables. func (s *Script) Run() (compiled *Compiled, err error) { compiled, err = s.Compile() if err != nil { return } err = compiled.Run() return } Compiled的Run // Run executes the compiled script in the virtual machine. func (c *Compiled) Run() error { c.lock.Lock() defer c.lock.Unlock() v := NewVM(c.bytecode, c.globals, c.maxAllocs) return v.Run() } VM的Run在vm.go中 variable.go variable.go提供了从Variable类型到native go的转换. type Variable struct { name string value Object } 典型的转换如下: _ = compiled.Set(\"a\", a) _ = compiled.Set(\"b\", b) _ = compiled.Set(\"c\", c) err := compiled.Run() require.NoError(t, err) d = compiled.Get(\"d\").Int() e = compiled.Get(\"e\").Int() builtins.go builtin函数的实现 var builtinFuncs = []*BuiltinFunction{ { Name: \"len\", Value: builtinLen, }, { Name: \"copy\", Value: builtinCopy, }, 等等 又少不了类型断言... compiler.go compiler的作用是把ast转化为字节码 它依赖下层的token和parser. compiler管符号表, 模块, 已经被编译过的函数, // Compiler compiles the AST into a bytecode. type Compiler struct { file *parser.SourceFile parent *Compiler modulePath string importDir string constants []Object symbolTable *SymbolTable scopes []compilationScope scopeIndex int modules *ModuleMap compiledModules map[string]*CompiledFunction allowFileImport bool loops []*loop loopIndex int trace io.Writer indent int } new一个compiler就是 &Compiler{ file: file, symbolTable: symbolTable, constants: constants, scopes: []compilationScope{mainScope}, //每个scope都有自己的字节码 scopeIndex: 0, //scope从0开始 loopIndex: -1, trace: trace, modules: modules, compiledModules: make(map[string]*CompiledFunction), } 特别的, NewCompiler()的时候, 也可以传入一个io.Writer做为trace, 方便debug. io.Writer配合defer的trace功能, 就能详细的log软件逻辑.compiler的allowFileImport和importDir一般和script的对应属性一样. Compile()函数 Compile()的入参是parser.Node, 它是个接口; parser.ParseFile()返回的*parser.File就是其中的一种实现func (c *Compiler) Compile(node parser.Node) errorCompile()的实现又是典型的类型断言+递归的方式, 它支持File树, 支持表达式树, 进一步支持更加拆分细化的基础操作.用递归调用来化整为零, 很经典: // Compile compiles the AST node. func (c *Compiler) Compile(node parser.Node) error { switch node := node.(type) { case *parser.File: //如果是File类型, 只是对其中的每个声明做递归的Compile for _, stmt := range node.Stmts { if err := c.Compile(stmt); err != nil { //再次调用Compile函数 return err } } case *parser.ExprStmt: //如果是表达式 if err := c.Compile(node.Expr); err != nil { return err } c.emit(node, parser.OpPop) //表达式是有具体动作的: emit POP(出栈)字节码到c.scopes[c.scopeIndex].Instructions的最后 其他更加拆分的case, 比如 case *parser.BinaryExpr: //处理加减乘除, emit OpBinaryOp case *parser.IntLit: case *parser.StringLit: case *parser.FloatLit: //以上带Lit后缀的是literature, 即字面值. emit OpConstant case *parser.UnaryExpr:: //一元操作 case *parser.IncDecStmt: //++ -- case *parser.IfStmt: // open new symbol table for the statement c.symbolTable = c.symbolTable.Fork(true) //if块有自己的符号scope, 所以这里fork出一个子的scope defer func() { c.symbolTable = c.symbolTable.Parent(false) //退出if块的时候, 还原父scope }() if node.Init != nil { //和go语法一样, if支持前置表达式 if err := c.Compile(node.Init); err != nil { return err } } if err := c.Compile(node.Cond); err != nil { //条件部分 return err } // first jump placeholder jumpPos1 := c.emit(node, parser.OpJumpFalsy, 0) //不要被这里的0 offset迷惑 后面会修正 //注意, 这里对应 vm.run()中的执行部分: 当前ip是操作码OpJumpFalsy, 判断当前sp的值是否为假, 是的话, ip跳转到pos-1, 这个pos就是指令码里的offset, 看起来是用两个字节表示的. 最大跳转65535字节. //case parser.OpJumpFalsy: // v.ip += 2 // v.sp-- // if v.stack[v.sp].IsFalsy() { // pos := int(v.curInsts[v.ip]) | int(v.curInsts[v.ip-1]) 0 { //如果引用了父scope的局部变量, 那这个函数就是个闭包; emit OpClosure c.emit(node, parser.OpClosure, c.addConstant(compiledFunction), len(freeSymbols)) } else { //普通函数, emit OpConstant //先把上面的compiledFunction加到constant数组里, 然后把这个对象放到栈中. c.emit(node, parser.OpConstant, c.addConstant(compiledFunction)) } case *parser.ReturnStmt: //函数返回 if c.symbolTable.Parent(true) == nil { // outside the function return c.errorf(node, \"return not allowed outside function\") } if node.Result == nil { c.emit(node, parser.OpReturn, 0) //空return } else { if err := c.Compile(node.Result); err != nil { return err } c.emit(node, parser.OpReturn, 1) //return值 } case *parser.CallExpr: //函数调用 if err := c.Compile(node.Func); err != nil { return err } for _, arg := range node.Args { if err := c.Compile(arg); err != nil { return err } } ellipsis := 0 if node.Ellipsis.IsValid() { ellipsis = 1 } c.emit(node, parser.OpCall, len(node.Args), ellipsis) 等等 } 在没有类型断言的语言里, 恐怕最常规的思路是写一堆的CompileXxx函数, 来互相调用, 比如: CompileExprStmt() CompileIfStmt() CompileBinaryExpr() 等等 源文件会比较乱. 注: 实际上, 这里还真有compileForStmt()函数 emit()函数 通常的调用比如: c.emit(node, parser.OpBinaryOp, int(token.Add)) c.emit(node, parser.OpMinus) pos := c.emit(node, parser.OpJump, 0) 第二个参数都是OpCode, 每个OpCode只有1个字节, 被放到字节码中. 全部的OpCode不多, 在parser/opcodes.go中定义最终这个OpCode被写入c.scopes[c.scopeIndex].Instructions: func (c *Compiler) emit( node parser.Node, opcode parser.Opcode, operands ...int, ) int { filePos := parser.NoPos if node != nil { filePos = node.Pos() } inst := MakeInstruction(opcode, operands...) pos := c.addInstruction(inst) c.scopes[c.scopeIndex].SourceMap[pos] = filePos if c.trace != nil { c.printTrace(fmt.Sprintf(\"EMIT %s\", FormatInstructions( c.scopes[c.scopeIndex].Instructions[pos:], pos)[0])) } return pos } func (c *Compiler) addInstruction(b []byte) int { posNewIns := len(c.currentInstructions()) c.scopes[c.scopeIndex].Instructions = append( c.currentInstructions(), b...) return posNewIns } func (c *Compiler) currentInstructions() []byte { return c.scopes[c.scopeIndex].Instructions } Compile之module Compile遇到import语句时, import先从注册过的module查找. 没有的话, 从文件查找 case *parser.ImportExpr: if node.ModuleName == \"\" { return c.errorf(node, \"empty module name\") } if mod := c.modules.Get(node.ModuleName); mod != nil { v, err := mod.Import(node.ModuleName) if err != nil { return err } switch v := v.(type) { case []byte: // module written in Tengo 注册过的tengo代码, 还是原始文本代码 compiled, err := c.compileModule(node, //所以这里需要compile node.ModuleName, v, false) if err != nil { return err } c.emit(node, parser.OpConstant, c.addConstant(compiled)) c.emit(node, parser.OpCall, 0, 0) case Object: // builtin module c.emit(node, parser.OpConstant, c.addConstant(v)) default: panic(fmt.Errorf(\"invalid import value type: %T\", v)) } } else if c.allowFileImport { //如果使能了文件module moduleName := node.ModuleName if !strings.HasSuffix(moduleName, \".tengo\") { moduleName += \".tengo\" //module必须以.tengo结尾 } modulePath, err := filepath.Abs( filepath.Join(c.importDir, moduleName)) //module name是个相对路径, 要和c.importDir结合才能找到文件 if err != nil { return c.errorf(node, \"module file path error: %s\", err.Error()) } moduleSrc, err := ioutil.ReadFile(modulePath) if err != nil { return c.errorf(node, \"module file read error: %s\", err.Error()) } compiled, err := c.compileModule(node, modulePath, moduleSrc, true) if err != nil { return err } c.emit(node, parser.OpConstant, c.addConstant(compiled)) c.emit(node, parser.OpCall, 0, 0) } else { return c.errorf(node, \"module '%s' not found\", node.ModuleName) } case *parser.ExportStmt: // export statement must be in top-level scope if c.scopeIndex != 0 { return c.errorf(node, \"export not allowed inside function\") } // export statement is simply ignore when compiling non-module code if c.parent == nil { break } if err := c.Compile(node.Result); err != nil { return err } c.emit(node, parser.OpImmutable) c.emit(node, parser.OpReturn, 1) compileModule()函数 一个module被编译后, 实际上是个*CompiledFunction, 定义于objects.go // CompiledFunction represents a compiled function. type CompiledFunction struct { ObjectImpl Instructions []byte NumLocals int // number of local variables (including function parameters) NumParameters int VarArgs bool SourceMap map[int]parser.Pos Free []*ObjectPtr } 它先检查是否有循环依赖. 然后检查是否该模块是否已经编译过了, 编译过就不需要再编了, 直接返回之前的.然后才是编译.模块的编译使用了fork的概念, 即fork一个上级compiler的副本, 再填入module的信息来编译.编译完成后还要从字节码的角度来优化代码. 最后保存这个编译好的module简化流程如下: c.checkCyclicImports(node, modulePath) c.loadCompiledModule(modulePath) modFile := c.file.Set().AddFile(modulePath, -1, len(src)) p := parser.NewParser(modFile, src, nil) file, err := p.ParseFile() // inherit builtin functions symbolTable := NewSymbolTable() // no global scope for the module symbolTable = symbolTable.Fork(false) // compile module moduleCompiler := c.fork(modFile, modulePath, symbolTable, isFile) moduleCompiler.Compile(file) // code optimization moduleCompiler.optimizeFunc(node) compiledFunc := moduleCompiler.Bytecode().MainFunction c.storeCompiledModule(modulePath, compiledFunc) return compiledFunc, nil 注: storeCompiledModule()和loadCompiledModule()都是对最顶层的Compiler操作的 func (c *Compiler) loadCompiledModule( modulePath string, ) (mod *CompiledFunction, ok bool) { if c.parent != nil { return c.parent.loadCompiledModule(modulePath) } mod, ok = c.compiledModules[modulePath] return } func (c *Compiler) storeCompiledModule( modulePath string, module *CompiledFunction, ) { if c.parent != nil { c.parent.storeCompiledModule(modulePath, module) } c.compiledModules[modulePath] = module } module默认路径 c.importDir默认为\"\", 即从当前目录找module也可以调用c.SetImportDir(filepath.Dir(inputFile))把import路径设为文件名的路径. 这个主意不错. Bytecode()函数返回编译好的字节码 它调用了上面的c.currentInstructions() // Bytecode returns a compiled bytecode. func (c *Compiler) Bytecode() *Bytecode { return &Bytecode{ FileSet: c.file.Set(), MainFunction: &CompiledFunction{ Instructions: append(c.currentInstructions(), parser.OpSuspend), SourceMap: c.currentSourceMap(), }, Constants: c.constants, } } modules.go tengo的模块支持ModuleMap是个简单的mapImportable是个可以被import的对象: Import()的签名足够简单 // Importable interface represents importable module instance. type Importable interface { // Import should return either an Object or module source code ([]byte). Import(moduleName string) (interface{}, error) } // ModuleMap represents a set of named modules. Use NewModuleMap to create a // new module map. type ModuleMap struct { m map[string]Importable } NewModuleMap()就返回一个初始的ModuleMap module类型: 支持import native go对象和tengo代码 下面代码中有三种module类型 // Add adds an import module. func (m *ModuleMap) Add(name string, module Importable) { m.m[name] = module } // AddBuiltinModule adds a builtin module. func (m *ModuleMap) AddBuiltinModule(name string, attrs map[string]Object) { m.m[name] = &BuiltinModule{Attrs: attrs} } // AddSourceModule adds a source module. func (m *ModuleMap) AddSourceModule(name string, src []byte) { m.m[name] = &SourceModule{Src: src} } 普通的实现了Import()方法的对象 Builtin模块: 用于import native go实现的对象. 就是add一个map[string]Object, import builtin模块返回一个ImmutableMap对象 定义于objects.go // BuiltinModule is an importable module that's written in Go. type BuiltinModule struct { Attrs map[string]Object } // Import returns an immutable map for the module. func (m *BuiltinModule) Import(moduleName string) (interface{}, error) { return m.AsImmutableMap(moduleName), nil } // AsImmutableMap converts builtin module into an immutable map. func (m *BuiltinModule) AsImmutableMap(moduleName string) *ImmutableMap { attrs := make(map[string]Object, len(m.Attrs)) for k, v := range m.Attrs { attrs[k] = v.Copy() } attrs[\"__module_name__\"] = &String{Value: moduleName} return &ImmutableMap{Value: attrs} } // ImmutableMap represents an immutable map object. type ImmutableMap struct { ObjectImpl Value map[string]Object } 源码模块: 用于import tengo脚本代码 // SourceModule is an importable module that's written in Tengo. type SourceModule struct { Src []byte } // Import returns a module source code. func (m *SourceModule) Import(_ string) (interface{}, error) { return m.Src, nil } 注: 这里的Import的源码模块, 是没有经过编译的. 名字被故意去掉了, 可能是后面和\"main\"脚本一起编译. symbol_table.go 提供symbol的定义和存储, define一个symbol的操作 symbol分为四种: // List of symbol scopes const ( ScopeGlobal SymbolScope = \"GLOBAL\" ScopeLocal SymbolScope = \"LOCAL\" ScopeBuiltin SymbolScope = \"BUILTIN\" ScopeFree SymbolScope = \"FREE\" ) SymbolTable应该是个树结构, 但只能往上找parent; 这很好理解: 一般的call stack中, 都是一路向下的调用, caller函数其实更关心怎么return到父级函数, 而不怎么关心callee函数 // Symbol represents a symbol in the symbol table. type Symbol struct { Name string Scope SymbolScope Index int LocalAssigned bool // if the local symbol is assigned at least once } // SymbolTable represents a symbol table. type SymbolTable struct { parent *SymbolTable block bool store map[string]*Symbol numDefinition int maxDefinition int freeSymbols []*Symbol builtinSymbols []*Symbol } 注意这里symbolTable只关注(name, index), 即symbolTable本身只保存符号和index, 并不保存Object. NewSymbolTable()函数 返回一个SymbolTable结构体 // NewSymbolTable creates a SymbolTable. func NewSymbolTable() *SymbolTable { return &SymbolTable{ store: make(map[string]*Symbol), } } Define()函数 func (t *SymbolTable) Define(name string) *Symbol 确定这个Symbol的scope: 如果t有parent, 则这个symbol是local的 否则是global的 然后放在这个t的store中: t.store[name] = symbol builtin符号除了保存在store中, 还保存在单独的builtinSymbols中 builtin符号保存在最顶层的符号表中: // DefineBuiltin adds a symbol for builtin function. func (t *SymbolTable) DefineBuiltin(index int, name string) *Symbol { if t.parent != nil { return t.parent.DefineBuiltin(index, name) } symbol := &Symbol{ Name: name, Index: index, Scope: ScopeBuiltin, } t.store[name] = symbol t.builtinSymbols = append(t.builtinSymbols, symbol) return symbol } Fork()函数 当扫描ast发现是一个block statement时, 调用SymbolTable的Fork函数, 在当前SymbolTable下, 新建一个SymbolTable.退出这个block statement时, 还原SymbolTable到父symbolTablecompile函数片段: case *parser.BlockStmt: if len(node.Stmts) == 0 { return nil } //注意这里, compile到这里发现是个新的语句块, 比如if, for的body部分 //fork一个新的symbolTable, 并做为当前的symbolTable: 注意下面这句 c.symbolTable = c.symbolTable.Fork(true) defer func() { //退出这个block的时候, 还原symbolTable为父symbolTable c.symbolTable = c.symbolTable.Parent(false) }() for _, stmt := range node.Stmts { if err := c.Compile(stmt); err != nil { return err } } Resolve()函数 Resolve()函数从本SymbolTable开始, 递归的沿parent路径查找, 直到在路径上的t.store map中找到该name的symbol.这就像是在本函数作用域查找变量一样: 在本函数没有, 就找父函数, 直到global的符号表.如果本函数没有, 但在某个父函数找到了这个符号, 这个符号就是free scope类型的.找到free scope类型的符号后, 添加到本函数的SymbolTable中. // if symbol is defined in parent table and if it's not global/builtin // then it's free variable. if !t.block && depth > 0 && symbol.Scope != ScopeGlobal && symbol.Scope != ScopeBuiltin { return t.defineFree(symbol), depth, true } free scope这个名字很贴切, \"游离\"的变量: 定义于某个函数, 但在其子函数中被引用到 -- 这就是闭包的概念.对子函数来说, 引用父函数的变量, 是free scope; 但对被引用的这个父函数变量来说, 它在父函数中是local的.在compile生成字节码阶段就调用了Resolve()函数 case *parser.Ident: // 在当前symbolTable查找name, symbolTable有父symbolTable的指针 // 当前找不到会依次往上查找 symbol, _, ok := c.symbolTable.Resolve(node.Name, false) if !ok { return c.errorf(node, \"unresolved reference '%s'\", node.Name) } switch symbol.Scope { case ScopeGlobal: c.emit(node, parser.OpGetGlobal, symbol.Index) case ScopeLocal: c.emit(node, parser.OpGetLocal, symbol.Index) case ScopeBuiltin: c.emit(node, parser.OpGetBuiltin, symbol.Index) case ScopeFree: c.emit(node, parser.OpGetFree, symbol.Index) } 总结 基本上一个symbolTable对应一个block体, 比如for的的代码块主体就是一个symbolTable.一个函数也是一个新的symbolTable, 函数return返回的时候symbolTable也恢复为其父symbolTable. symbolTable在编译阶段发挥作用, 即从ast到字节码的过程中, 根据语义分析的ast, 如果是对变量的引用, 就在当前symbolTable中查找变量的符号, 并最终emit到字节码中(见上面代码).如果是对变量的赋值, 比如对局部变量赋值, 会调用c.emit(node, parser.OpSetLocal, symbol.Index) 看到这里我认为字节码中并没有符号信息, 就像汇编里已经不是变量名了, 而是地址. vm.go 看起来到VM阶段, 字节码已经是解结构化的, 类似汇编式的指令流了. 所以这个run函数的主体是个for, 通过控制ip的移动来\"执行\"指令流. 所以这里不是解释器那种的递归调用Eval的情况. VM是个固定栈大小的(目前是固定2048个Object对象), 有global的引用, 最大1024个frame的VM.注意这里的栈大小是整个VM的栈, 随着fram的增减而上下浮动. 对应C里面ulimit -s的栈大小, 一般是8192K. // VM is a virtual machine that executes the bytecode compiled by Compiler. type VM struct { constants []Object stack [StackSize]Object sp int globals []Object fileSet *parser.SourceFileSet frames [MaxFrames]frame framesIndex int curFrame *frame curInsts []byte ip int aborting int64 maxAllocs int64 allocs int64 err error } //主要限制如下: const ( // GlobalsSize is the maximum number of global variables for a VM. GlobalsSize = 1024 // StackSize is the maximum stack size for a VM. StackSize = 2048 // MaxFrames is the maximum number of function frames for a VM. MaxFrames = 1024 ) frame管状态记录的, 定义如下: // frame represents a function call frame. type frame struct { fn *CompiledFunction //CompiledFunction也是Object对象, 主要包括对应的字节码 freeVars []*ObjectPtr //ObjectPrt是指向Object的结构, 见下面: ip int basePointer int } // CompiledFunction represents a compiled function. type CompiledFunction struct { ObjectImpl Instructions []byte NumLocals int // number of local variables (including function parameters); 这个是在编译阶段就确定了的 NumParameters int VarArgs bool SourceMap map[int]parser.Pos Free []*ObjectPtr //持有ObjectPtr是要干什么呢? 可能是\"堆\"变量 } // ObjectPtr represents a free variable. type ObjectPtr struct { ObjectImpl Value *Object } VM New函数 传入的globals可以在多个VM中共享 // NewVM creates a VM. func NewVM( bytecode *Bytecode, globals []Object, maxAllocs int64, ) *VM { if globals == nil { globals = make([]Object, GlobalsSize) } v := &VM{ constants: bytecode.Constants, sp: 0, globals: globals, fileSet: bytecode.FileSet, framesIndex: 1, ip: -1, maxAllocs: maxAllocs, } v.frames[0].fn = bytecode.MainFunction v.frames[0].ip = -1 v.curFrame = &v.frames[0] v.curInsts = v.curFrame.fn.Instructions return v } VM在run阶段, 会把产生的全局变量放到globals中. case parser.OpSetGlobal: v.ip += 2 v.sp-- globalIndex := int(v.curInsts[v.ip]) | int(v.curInsts[v.ip-1]) VM Run函数 Script, Compiled的Run, 最后都是调用VM.Run();如果去掉错误处理, VM.Run()是下面的样子 // Run starts the execution. func (v *VM) Run() (err error) { // reset VM states //VM真的有sp, ip, frame等操作 v.sp = 0 v.curFrame = &(v.frames[0]) v.curInsts = v.curFrame.fn.Instructions v.framesIndex = 1 v.ip = -1 v.allocs = v.maxAllocs + 1 //重点是这个run函数 v.run() atomic.StoreInt64(&v.aborting, 0) err = v.err ... } VM.run()是真正执行部分 func (v *VM) run() { for atomic.LoadInt64(&v.aborting) == 0 { //对应VM Abort来停止 v.ip++ //字节码的执行依靠ip指针的向后移动 switch v.curInsts[v.ip] { case parser.OpConstant: v.ip += 2 cidx := int(v.curInsts[v.ip]) | int(v.curInsts[v.ip-1])= 0 { numArgs = realArgs + 1 args := make([]Object, varArgs) spStart := v.sp - varArgs for i := spStart; i =%d, got=%d\", callee.NumParameters-1, numArgs) } else { v.err = fmt.Errorf( \"wrong number of arguments: want=%d, got=%d\", callee.NumParameters, numArgs) } return } // test if it's tail-call if callee == v.curFrame.fn { // recursion nextOp := v.curInsts[v.ip+1] if nextOp == parser.OpReturn || (nextOp == parser.OpPop && parser.OpReturn == v.curInsts[v.ip+2]) { for p := 0; p = MaxFrames { v.err = ErrStackOverflow return } //下面非常重要!!!!! 一个CompiledFunction运行在独立的frame里, 全部的frame是个1024个大小的frame数组. // update call frame //进入下一个循环, switch v.curInsts[v.ip] v.curFrame.ip = v.ip // store current ip before call v.curFrame = &(v.frames[v.framesIndex]) v.curFrame.fn = callee v.curFrame.freeVars = callee.Free v.curFrame.basePointer = v.sp - numArgs v.curInsts = callee.Instructions v.ip = -1 //下个循环中, v.ip++刚好为0 v.framesIndex++ v.sp = v.sp - numArgs + callee.NumLocals //注意这里, sp并没有独立的\"frame\". 这里的NumLocals是包括了参数个数的:number of local variables (including function parameters) } else { //难道else对应用户自定义函数? var args []Object args = append(args, v.stack[v.sp-numArgs:v.sp]...) ret, e := value.Call(args...) v.sp -= numArgs + 1 // runtime error if e != nil { if e == ErrWrongNumArguments { v.err = fmt.Errorf( \"wrong number of arguments in call to '%s'\", value.TypeName()) return } if e, ok := e.(ErrInvalidArgumentType); ok { v.err = fmt.Errorf( \"invalid type for argument '%s' in call to '%s': \"+ \"expected %s, found %s\", e.Name, value.TypeName(), e.Expected, e.Found) return } v.err = e return } // nil return -> undefined if ret == nil { ret = UndefinedValue } v.allocs-- if v.allocs == 0 { v.err = ErrObjectAllocLimit return } v.stack[v.sp] = ret v.sp++ } } //这个frame return case parser.OpReturn: v.ip++ var retVal Object if int(v.curInsts[v.ip]) == 1 { //有return 值 retVal = v.stack[v.sp-1] } else { retVal = UndefinedValue // 没有return默认return UndefinedValue } //v.sp-- v.framesIndex-- //撤销这个frame, 下面几句还原上一个frame的现场 v.curFrame = &v.frames[v.framesIndex-1] v.curInsts = v.curFrame.fn.Instructions v.ip = v.curFrame.ip //v.sp = lastFrame.basePointer - 1 v.sp = v.frames[v.framesIndex].basePointer // skip stack overflow check because (newSP) Abort用atomic写入v.aborting // Abort aborts the execution. func (v *VM) Abort() { atomic.StoreInt64(&v.aborting, 1) } 下面的几个操作有什么区别? 使用场景是什么? 栈变量? 堆变量? OpDefineLocal // Define local variable OpSetSelLocal // Set local variable using selectors OpGetFreePtr // Get free variable pointer object OpGetFree // Get free variables OpSetFree // Set free variables OpGetLocalPtr // Get local variable as a pointer 粗看下来, 我感觉变量的第一使用现场都是在stack [StackSize]Object, 虽然这里叫stack, 但实际是Object的运动场, \"堆\"变量也保存在这里. 那有人要问了, 明明看到这个stack有sp, 而且sp会上下浮动. 如果当然frame的堆变量保存在此, 那sp\"回退\"到上个frame怎么办? 感觉OpGetFree和OpSetFree就是来解决这个问题的 case parser.OpGetFree: v.ip++ freeIndex := int(v.curInsts[v.ip]) val := *v.curFrame.freeVars[freeIndex].Value v.stack[v.sp] = val v.sp++ case parser.OpSetFree: v.ip++ freeIndex := int(v.curInsts[v.ip]) *v.curFrame.freeVars[freeIndex].Value = v.stack[v.sp-1] v.sp-- OpGetFree从v.curFrame.freeVars这个map里得到值, 放到v.stack[v.sp]中 OpSetFree相反, 把栈变量放到frame的freeVars中. 注意这里都是值拷贝. 即: 变量都是在stack运动场上参与运动(CPU计算), 变量退场的时候, 其值被拷贝(值拷贝)到当前休息区curFrame.freeVars; 等下次轮到这个变量上场的时候, 再次值拷贝到运动场(stack). 前面说过, callee函数也是做为一个Object被放到stack上的, 所以这里的stack并不是完全的C的\"栈\"的概念. 应该说是对象的运动场/训练场更合适. vm.run总结 ip是字节码的\"pc\"指针, op和op的操作指令放在字节码里 sp向上增长, op的操作数放在栈上. 比如 判断左右两个操作数相等, 左右两个操作数都在栈上, 出栈后判断是否相等, 并把结果压栈.case parser.OpEqual: right := v.stack[v.sp-1] left := v.stack[v.sp-2] v.sp -= 2 if left.Equals(right) { v.stack[v.sp] = TrueValue } else { v.stack[v.sp] = FalseValue } v.sp++ stdlib/func_typedefs.go 提供了go的函数签名到tengo callable对象的包装函数: 比如: // FuncARI transform a function of 'func() int' signature into CallableFunc // type. func FuncARI(fn func() int) tengo.CallableFunc { return func(args ...tengo.Object) (ret tengo.Object, err error) { if len(args) != 0 { return nil, tengo.ErrWrongNumArguments } return &tengo.Int{Value: int64(fn())}, nil } } tengo的后继 https://github.com/ozanh/ugo tengo的v2版本处于维护状态. tengo的一个contributor自己也建了一个类似的解释器: ugo tengo https://github.com/d5/tengo Reddit讨论在此 tengo似乎是个VM模式的解释语言. 语法和go非常相近, 性能似乎不错: fib(35) fibt(35) Language (Type) Tengo 2,931ms 4ms Tengo (VM) go-lua 4,824ms 4ms Lua (VM) GopherLua 5,365ms 4ms Lua (VM) goja 5,533ms 5ms JavaScript (VM) starlark-go 11,495ms 5ms Starlark (Interpreter) Yaegi 15,645ms 12ms Yaegi (Interpreter) gpython 16,322ms 5ms Python (Interpreter) otto 73,093ms 10ms JavaScript (Interpreter) Anko 79,809ms 8ms Anko (Interpreter) - - - - Go 53ms 3ms Go (Native) Lua 1,612ms 3ms Lua (Native) Python 2,632ms 23ms Python 2 (Native) 编译出来size也很小, 4.8M. 没有外部package引用, 没有cgo 被设计成类似lua的被嵌入的语言. -- 更容易集成 似乎扩展性不错. -- 有库的概念. 库是go语言写的 github 2.1k个星 入门 a b c d四个变量求和: package main import ( \"context\" \"fmt\" \"github.com/d5/tengo/v2\" ) func main() { // Tengo script code src := ` each := func(seq, fn) { for x in seq { fn(x) } } sum := 0 mul := 1 each([a, b, c, d], func(x) { sum += x mul *= x })` // create a new Script instance script := tengo.NewScript([]byte(src)) // set values _ = script.Add(\"a\", 1) _ = script.Add(\"b\", 9) _ = script.Add(\"c\", 8) _ = script.Add(\"d\", 4) // run the script compiled, err := script.RunContext(context.Background()) if err != nil { panic(err) } // retrieve values sum := compiled.Get(\"sum\") mul := compiled.Get(\"mul\") fmt.Println(sum, mul) // \"22 288\" } 语法 token 有几个token值得注意: Ellipsis: \"...\", Func: \"func\", Error: \"error\", Immutable: \"immutable\", Export: \"export\", True: \"true\", False: \"false\", In: \"in\", Undefined: \"undefined\", Import: \"import\", 比如... error immutable undefined export import都是关键词 一个go调脚本的例子 package main import ( \"log\" \"github.com/d5/tengo/v2\" \"github.com/d5/tengo/v2/stdlib\" ) func main() { src := ` text := import(\"text\") m := { contains: func(args) { return text.contains(args.str, args.substr) } } out := undefined if f := m[argsMap.function]; !is_undefined(f) { out = f(argsMap) } else { out = error(\"unknown function\") } ` script := tengo.NewScript([]byte(src)) script.SetImports(stdlib.GetModuleMap(\"text\")) argsMap := map[string]interface{}{ \"function\": \"contains\", \"str\": \"foo bar\", \"substr\": \"bar\"} if err := script.Add(\"argsMap\", argsMap); err != nil { log.Fatal(err) } c, err := script.Run() if err != nil { log.Fatal(err) } out := c.Get(\"out\") if err := out.Error(); err != nil { log.Fatal(err) } // If it returns a dynamic type use type switch using out.Value() log.Println(\"result =\", out.Bool()) } 所有都是值类型 19 + 84 // int values \"aomame\" + `kawa` // string values -9.22 + 1e10 // float values true || false // bool values '九' > '9' // char values [1, false, \"foo\"] // array value {a: 12.34, b: \"bar\"} // map value func() { /*...*/ } // function value tengo值类型和go类型 Tengo Type Description Equivalent Type in Go int signed 64-bit integer value int64 float 64-bit floating point value float64 bool boolean value bool char unicode character rune string unicode string string bytes byte array []byte error error value - time time value time.Time array value array (mutable) []interface{} immutable array immutable array - map value map with string keys (mutable) map[string]interface{} immutable map immutable map - undefined undefined value - function function value - user-defined value of user-defined types - error升级为一等类型 err1 := error(\"oops\") // error with string value err2 := error(1+2+3) // error with int value if is_error(err1) { // 'is_error' builtin function err_val := err1.value // get underlying value } 值不可变 除了map和array, 其他类型的值不能改变 s := \"12345\" s[1] = 'b' // illegal: String is immutable a := [1, 2, 3] a[1] = \"two\" // ok: a is now [1, \"two\", 3] 用immutable关键词可以把map和array也设成不可变 b := immutable([1, 2, 3]) b[1] = \"foo\" // illegal: 'b' references to an immutable array. 注意, 重新赋值和immutabiltiy没有关系: 对变量重新赋值永远都是可以的 s := \"abc\" s = \"foo\" // ok a := immutable([1, 2, 3]) a = false // ok immutable改变只是当前变量属性, 对map/array里的元素没有约束 a := immutable({b: 4, c: [1, 2, 3]}) a.b = 5 // illegal a.c[1] = 5 // ok: because 'a.c' is not immutable a = immutable({b: 4, c: immutable([1, 2, 3])}) a.c[1] = 5 // illegal 未定义也是一种类型 没有return的函数是undefined类型 不存在的index/key返回undefined类型 强转失败返回undefined类型 a := func() { b := 4 }() // a == undefined b := [1, 2, 3][10] // b == undefined c := {a: \"foo\"}[\"b\"] // c == undefined d := int(\"foo\") // d == undefined 注: 这里看到, index超过范围返回的是undefined类型, 而不是直接panic 广义的array和map array和map被设计成解释器该有的样子: array的元素可以是任意类型, 支持嵌套: [1, 2, 3][0] // == 1 [1, 2, 3][2] // == 3 [1, 2, 3][3] // == undefined [\"foo\", \"bar\", [1, 2, 3]] // ok: array with an array element array支持加法操作: (array) + (array): return a concatenated array map的元素可以用[]也可以用.来访问 m := { a: 1, b: false, c: \"foo\" } m[\"b\"] // == false m.c // == \"foo\" m.x // == undefined {a: [1,2,3], b: {c: \"foo\", d: \"bar\"}} // ok: map with an array element and a map element array和map都支持比较操作 函数也是值, 一等公民, 支持闭包 my_func := func(arg1, arg2) { return arg1 + arg2 } adder := func(base) { return func(x) { return base + x } // capturing 'base' } add5 := adder(5) nine := add5(4) // == 9 和go的区别是, tengo里的函数必须是值声明的方式来定义 声明函数的方式不支持 func my_func(arg1, arg2) { // illegal return arg1 + arg2 } 支持变长参数: 变长部分被组成一个array variadic := func (a, b, ...c) { return [a, b, c] } variadic(1, 2, 3, 4) // [1, 2, [3, 4]] variadicClosure := func(a) { return func(b, ...c) { return [a, b, c] } } variadicClosure(1)(2, 3, 4) // [1, 2, [3, 4]] 变长部分只能在最后: // illegal, because a is variadic and is not the last parameter illegal := func(a..., b) { /*... */ } 支持go式的...解array: f1 := func(a, b, c) { return a + b + c } f1([1, 2, 3]...) // => 6 f1(1, [2, 3]...) // => 6 f1(1, 2, [3]...) // => 6 f1([1, 2]...) // Runtime Error: wrong number of arguments: want=3, got=2 f2 := func(a, ...b) {} f2(1) // valid; a = 1, b = [] f2(1, 2) // valid; a = 1, b = [2] f2(1, 2, 3) // valid; a = 1, b = [2, 3] f2([1, 2, 3]...) // valid; a = 1, b = [2, 3] 变量scope 和abs不同, tengo支持函数级的scope :=在当前scope定义新变量 =在当前scope重新赋值变量 变量的值类型是动态的:a := 123 // assigned 'int' a = \"123\" // re-assigned 'string' a = [1, 2, 3] // re-assigned 'array' scope例子: a := \"foo\" // define 'a' in global scope func() { // function scope A b := 52 // define 'b' in function scope A func() { // function scope B c := 19.84 // define 'c' in function scope B a = \"bee\" // ok: assign new value to 'a' from global scope b = 20 // ok: assign new value to 'b' from function scope A b := true // ok: define new 'b' in function scope B // (shadowing 'b' from function scope A) } a = \"bar\" // ok: assigne new value to 'a' from global scope b = 10 // ok: assigne new value to 'b' a := -100 // ok: define new 'a' in function scope A // (shadowing 'a' from global scope) c = -9.1 // illegal: 'c' is not defined b := [1, 2] // illegal: 'b' is already defined in the same scope } b = 25 // illegal: 'b' is not defined a := {d: 2} // illegal: 'a' is already defined in the same scope 内置类型转换 比如int转为string是可以的: string(x): tries to convert x into string; returns undefined if failed //在native go里, string(1984)是不行的; 但这里可以 s1 := string(1984) // \"1984\" i2 := int(\"-999\") // -999 f3 := float(-51) // -51.0 b4 := bool(1) // true c5 := char(\"X\") // 'X' 所有类型都有false的概念: Int: n == 0 String: len(s) == 0 Float: isNaN(f) Bool: !b Char: c == 0 Bytes: len(bytes) == 0 Array: len(arr) == 0 Map: len(map) == 0 Time: Time.IsZero() Error: true (Error is always falsy) Undefined: true (Undefined is always falsy) 支持三目操作 a := true ? 1 : -1 // a == 1 min := func(a, b) { return a []和.能作用于复合类型:array map string和bytes 特别的用m.x = 5能新增一个(key value) [\"one\", \"two\", \"three\"][1] // == \"two\" m := { a: 1, b: [2, 3, 4], c: func() { return 10 } } m.a // == 1 m[\"b\"][1] // == 3 m.c() // == 10 m.x = 5 // add 'x' to map 'm' m[\"b\"][5] // == undefined m[\"b\"][5].d // == undefined m.b[5] = 0 // == undefined m.x.y.z // == undefined 再切片和go一样 可惜-1不是倒数第一个的意思, [1, 2, 3, 4, 5][3:-1]是非法的 a := [1, 2, 3, 4, 5][1:3] // == [2, 3] b := [1, 2, 3, 4, 5][3:] // == [4, 5] c := [1, 2, 3, 4, 5][:3] // == [1, 2, 3] d := \"hello world\"[2:10] // == \"llo worl\" c := [1, 2, 3, 4, 5][-1:10] // == [1, 2, 3, 4, 5] if支持前置执行语句, 和go一样; for的结构也和go一样样的; for支持 for in for v in [1, 2, 3] { // array: element // 'v' is value } for i, v in [1, 2, 3] { // array: index and element // 'i' is index // 'v' is value } for k, v in {k1: 1, k2: 2} { // map: key and value // 'k' is key // 'v' is value } 其他和native go的不同点 没有struct -- 有map了, 不需要struct 没有go routine和channel 没有defer 没有switch case 没有panic 没有类型断言 内置函数 不是很多, format len copy append delete等等 a := [1, 2, 3] s := format(\"Foo: %v\", a) // s == \"Foo: [1, 2, 3]\" v := [1, 2, 3] l := len(v) // l == 3 v1 := [1, 2, 3] v2 := v1 v3 := copy(v1) v1[1] = 0 print(v2[1]) // \"0\"; 'v1' and 'v2' referencing the same array print(v3[1]) // \"2\"; 'v3' not affected by 'v1' v := [1] v = append(v, 2, 3) // v == [1, 2, 3] v := {key: \"value\"} delete(v, \"key\") // v == {} delete(v, \"missing\") // v == {\"key\": \"value\"} 还有类型转换和类型判断 string() is_string() v := bytes(\"foo\") // v == [102 111 111] is_bytes() 等等 被嵌入执行 直接代码执行 import \"github.com/d5/tengo/v2\" var code = ` reduce := func(seq, fn) { s := 0 for x in seq { fn(x, s) } return s } print(reduce([1, 2, 3], func(x, s) { s += x })) ` func main() { s := tengo.NewScript([]byte(code)) if _, err := s.Run(); err != nil { panic(err) } } 代码实时\"编译\"后执行 这个例子中, 代码被\"编译\"了一次, 但执行了2次. 全局变量可以通过Compiled.Set和Compiled.Get来从外部访问. import ( \"fmt\" \"github.com/d5/tengo/v2\" ) func main() { s := tengo.NewScript([]byte(`a := b + 20`)) // define variable 'b' _ = s.Add(\"b\", 10) // compile the source c, err := s.Compile() if err != nil { panic(err) } // run the compiled bytecode // a compiled bytecode 'c' can be executed multiple times without re-compiling it if err := c.Run(); err != nil { panic(err) } // retrieve value of 'a' a := c.Get(\"a\") fmt.Println(a.Int()) // prints \"30\" // re-run after replacing value of 'b' if err := c.Set(\"b\", 20); err != nil { panic(err) } if err := c.Run(); err != nil { panic(err) } fmt.Println(c.Get(\"a\").Int()) // prints \"40\" } 外部代码里import 这里的外部代码指调用tengo的go代码: s := tengo.NewScript([]byte(`math := import(\"math\"); a := math.abs(-19.84)`)) s.SetImports(stdlib.GetModuleMap(\"math\")) // or, to include all stdlib at once s.SetImports(stdlib.GetModuleMap(stdlib.AllModuleNames()...)) 也可以引用自定义module: s := tengo.NewScript([]byte(`double := import(\"double\"); a := double(20)`)) mods := tengo.NewModuleMap() mods.AddSourceModule(\"double\", []byte(`export func(x) { return x * 2 }`)) s.SetImports(mods) 用户可以自定义类型 用户实现了Object接口就可以自定义类型. 用户的自定义类型和内置类型待遇一样.即要实现下面的接口: //类型名字 TypeName() string //值的字面字符串表达 String() string //重载操作符: +, -, *, /, %, &, |, ^, &^, >>, , >= //有错误发生时, 可以返回Error值到res(不中断脚本执行) //也可以直接返回err, 比如ErrInvalidOperator, 但会中断VM的执行 BinaryOp(op token.Token, rhs Object) (res Object, err error) IsFalsy() bool Equals(o Object) bool //内建的类型是深拷贝模式, 但用户也可以在自定义类型中搞浅拷贝 Copy() Object //If Object is not indexable, ErrNotIndexable should be returned as error. If nil is returned as value, it will be converted to Undefined value by the runtime. IndexGet(index Object) (value Object, err error) IndexSet(index, value Object) error //对象可以有call方法 CanCall() bool //Call的格式比native go更死板一点, 返回值必须是两个 Call(args ...Object) (ret Object, err error) //对象可以被迭代 CanIterate() bool //Iterator是返回的对象, 实现了Iterator接口 Iterate() Iterator //Iterator接口包括: Next() bool Key() Object Value() Object 自定义类型举例 和native go的核心精神一样, 下面的*StringArray实现了tengo的Object要求: 主要是实现了string array的+操作 注意StringArray匿名包含了tengo.ObjectImpl, 这是个典型的继承操作: 继承了tengo.ObjectImpl的方法集, 后者是个空结构体type ObjectImpl struct {}, 但由tengo/objects.go提供的默认类型方法实现. type StringArray struct { tengo.ObjectImpl Value []string } func (o *StringArray) String() string { return strings.Join(o.Value, \", \") } func (o *StringArray) BinaryOp(op token.Token, rhs tengo.Object) (tengo.Object, error) { if rhs, ok := rhs.(*StringArray); ok { switch op { //这里是核心实现 case token.Add: if len(rhs.Value) == 0 { return o, nil } return &StringArray{Value: append(o.Value, rhs.Value...)}, nil } } return nil, tengo.ErrInvalidOperator } func (o *StringArray) IsFalsy() bool { return len(o.Value) == 0 } func (o *StringArray) Equals(x tengo.Object) bool { if x, ok := x.(*StringArray); ok { if len(o.Value) != len(x.Value) { return false } for i, v := range o.Value { if v != x.Value[i] { return false } } return true } return false } func (o *StringArray) Copy() tengo.Object { return &StringArray{ Value: append([]string{}, o.Value...), } } func (o *StringArray) TypeName() string { return \"string-array\" } 那么一个*StringArray对象可以被直接Add进脚本, 不需要\"注册\"步骤, tengo就知道自动调用*StringArray重载的+方法: // script that uses 'my_list' s := tengo.NewScript([]byte(` print(my_list + \"three\") `)) myList := &StringArray{Value: []string{\"one\", \"two\"}} s.Add(\"my_list\", myList) // add StringArray value 'my_list' s.Run() // prints \"one, two, three\" 增加更多功能 在StringArray的实现里可以增加index的支持. func (o *StringArray) IndexGet(index tengo.Object) (tengo.Object, error) { intIdx, ok := index.(*tengo.Int) if ok { if intIdx.Value >= 0 && intIdx.Value = 0 && intIdx.Value 也可以增加call的支持: func (o *StringArray) CanCall() bool { return true } func (o *StringArray) Call(args ...tengo.Object) (ret tengo.Object, err error) { if len(args) != 1 { return nil, tengo.ErrWrongNumArguments } s1, ok := tengo.ToString(args[0]) if !ok { return nil, tengo.ErrInvalidArgumentType{ Name: \"first\", Expected: \"string\", Found: args[0].TypeName(), } } for i, v := range o.Value { if v == s1 { return &tengo.Int{Value: int64(i)}, nil } } return tengo.UndefinedValue, nil } 这样这个对象就可以被函数式调用: s := tengo.NewScript([]byte(` print(my_list(\"two\")) `)) myList := &StringArray{Value: []string{\"one\", \"two\", \"three\"}} s.Add(\"my_list\", myList) // add StringArray value 'my_list' s.Run() // prints \"1\" (index of \"two\") 也可以增加迭代支持: func (o *StringArray) CanIterate() bool { return true } func (o *StringArray) Iterate() tengo.Iterator { return &StringArrayIterator{ strArr: o, } } type StringArrayIterator struct { tengo.ObjectImpl strArr *StringArray idx int } func (i *StringArrayIterator) TypeName() string { return \"string-array-iterator\" } func (i *StringArrayIterator) Next() bool { i.idx++ return i.idx 总结 tengo使用了go的匿名继承, \"斧头帮\"式的接口概念, 可以非常容易的自定义类型. 自己搞个工程, 定义类型, 和tengo编译在一起, 这样其脚本就支持非常丰富的自定义操作. 但上面的例子中, my_list变量是在go代码里定义的, 在脚本里使用. 如何在脚本里直接定义StringArray类型的变量呢? 模块化和标准库 tengo支持模块化, 有两个层次的: tengo脚本 sum := import(\"./sum\") // load module from a local file fmt.print(sum(10)) // module function sum.tengo的内容如下: 用export来声明要导出的对象, 可以是任何tengo类型, 比如map base := 5 export func(x) { return x + base } export就是文件级别的return, export返回的对象都是immutable的. 没有export声明的module, 返回undefined类型. go代码的模块 标准库是go代码实现的math := import(\"math\") a := math.abs(-19.84) // == 19.84 如何实现的? 标准库 标准库由: os: platform-independent interface to operating system functionality. text: regular expressions, string conversion, and manipulation math: mathematical constants and functions times: time-related functions rand: random functions fmt: formatting functions json: JSON functions enum: Enumeration functions 有each(x, fn) all(x, fn) => bool any(x, fn) => bool等针对array和map调用fn的函数 hex: hex encoding and decoding functions base64: base64 encoding and decoding functions runtime对象类型 Primitive value types: Int, String, Float, Bool, Char, Bytes, Time Composite value types: Array, ImmutableArray, Map, ImmutableMap Functions: CompiledFunction, BuiltinFunction, UserFunction Iterators: StringIterator, ArrayIterator, MapIterator, ImmutableMapIterator Error Undefined Other internal objects: Break, Continue, ReturnValue 安全性 有几个API可以设置最大对象个数, 最大code长度等等 Script.SetMaxAllocs(n int64) //默认关闭从文件load模块 Script.EnableFileImport(enable bool) tengo.MaxStringLen tengo.MaxBytesLen 并发 编译后的tengo代码被Compiled.Clone后, 可以多个goroutine并发执行. for i := 0; i 这里说的VM感觉就是编译后的\"表达树\"? Although it's not recommended, you can directly create and run the Tengo Compiler, and VM for yourself instead of using Scripts and Script Variables. It's a bit more involved as you have to manage the symbol tables and global variables between them, but, basically that's what Script and Script Variable is doing internally. 用tengo默认的cli命令, 可以看到: $ cat test.tengo fmt := import(\"fmt\") fmt.println(\"hello\") #可以直接执行tengo脚本 $ ./tengo test.tengo hello #也可以\"编译\"成字节码, 编译后大概1k $ ./tengo -o test test.tengo $ llh total 4.8M -rwxr-xr-x 1 yingjieb platform 4.8M Dec 4 08:53 tengo -rwxr-xr-x 1 yingjieb platform 1019 Dec 4 08:53 test -rw-r--r-- 1 yingjieb platform 42 Dec 4 08:53 test.tengo #可以直接运行字节码 $ ./tengo test hello vi test看到这个\"字节码\": 官方例子 编译成字节码后执行 tengo -o myapp myapp.tengo # compile 'myapp.tengo' into binary file 'myapp' tengo myapp # execute the compiled binary `myapp` 加#!/usr/local/bin/tengo后脚本方式执行 脚本必须以.tengo结尾. 似乎是这个cli程序的限制 # copy tengo executable to a dir where PATH environment variable includes cp tengo /usr/local/bin/ # add shebang line to source file cat > myapp.tengo 更多官方例子 gento代码转成lua 从 each := func(x, f) { for k, v in x { f(k, v) } } sum := 0 each([1, 2, 3], func(i, v) { sum += v }) 自动转到: 似乎有点丑... function __iter__(v) if v.__a then local idx = 0 return function() if v[idx] == nil then return nil end idx = idx + 1 return idx-1, v[idx-1] end else return pairs(v) end end getmetatable(\"\").__add=function(a,b) return a..b end local each=function(x,f) for k, v in __iter__(x) do local __cont_1__ = false repeat f(k,v) __cont_1__ = true until 1 if not __cont_1__ then break end end end local sum=0 each({[0]=(1),(2),(3), __a=true},function(i,v) sum=sum+v end ) 有限状态机 看起来挺绕的. https://github.com/d5/go-fsm 全是go代码, 但里面调用了tengo, 实现了fsm框架 main函数只依赖\"github.com/d5/go-fsm\"的API, 但状态机的定义是\"文本\"的: package main import ( \"fmt\" \"github.com/d5/go-fsm\" ) var decimalsScript = []byte(` fmt := import(\"fmt\") export { // test if the first character is a digit is_digit: func(src, dst, v) { return v[0] >= '0' && v[0] %s: %q\\n\", src, dst, v) }, // cut the first character enter: func(src, dst, v) { return v[1:] }, enter_end: func(src, dst, v) { return \"valid number\" }, enter_error: func(src, dst, v) { return \"invalid number: \" + v } }`) func main() { // build and compile state machine //这个调用很吊, 注释和.夹杂 machine, err := fsm.New(decimalsScript). State(\"S\", \"enter\", \"\"). // start State(\"N\", \"enter\", \"\"). // whole numbers State(\"P\", \"enter\", \"\"). // decimal point State(\"F\", \"enter\", \"\"). // fractional part State(\"E\", \"enter_end\", \"\"). // end State(\"X\", \"enter_error\", \"\"). // error Transition(\"S\", \"E\", \"is_eol\", \"print_tx\"). Transition(\"S\", \"N\", \"is_digit\", \"print_tx\"). Transition(\"S\", \"X\", \"\", \"print_tx\"). Transition(\"N\", \"E\", \"is_eol\", \"print_tx\"). Transition(\"N\", \"N\", \"is_digit\", \"print_tx\"). Transition(\"N\", \"P\", \"is_dot\", \"print_tx\"). Transition(\"N\", \"X\", \"\", \"print_tx\"). Transition(\"P\", \"F\", \"is_digit\", \"print_tx\"). Transition(\"P\", \"X\", \"\", \"print_tx\"). Transition(\"F\", \"E\", \"is_eol\", \"print_tx\"). Transition(\"F\", \"F\", \"is_digit\", \"print_tx\"). Transition(\"F\", \"X\", \"\", \"print_tx\"). Compile() if err != nil { panic(err) } // test case 1: \"123.456\" res, err := machine.Run(\"S\", \"123.456\") if err != nil { panic(err) } fmt.Println(res) // test case 2: \"12.34.65\" res, err = machine.Run(\"S\", \"12.34.56\") if err != nil { panic(err) } fmt.Println(res) } "},"notes/golang_govaluate.html":{"url":"notes/golang_govaluate.html","title":"解释器govaluate","keywords":"","body":" govaluate parse阶段 parseTokens token类型 planStages operator 执行阶段 总结 govaluate govaluate提供了简单的C类似的表达式的求值功能. expression, err := govaluate.NewEvaluableExpression(\"10 > 0\"); result, err := expression.Evaluate(nil); // result is now set to \"true\", the bool value. 传参需要用个map[string]interface{}来传递. expression, err := govaluate.NewEvaluableExpression(\"(requests_made * requests_succeeded / 100) >= 90\"); parameters := make(map[string]interface{}, 8) parameters[\"requests_made\"] = 100; parameters[\"requests_succeeded\"] = 80; result, err := expression.Evaluate(parameters); // result is now set to \"false\", the bool value. 除了返回bool, 也可以返回数字 expression, err := govaluate.NewEvaluableExpression(\"(mem_used / total_mem) * 100\"); parameters := make(map[string]interface{}, 8) parameters[\"total_mem\"] = 1024; parameters[\"mem_used\"] = 512; result, err := expression.Evaluate(parameters); // result is now set to \"50.0\", the float64 value. 也可以预定义可以执行的函数, 用govaluate.NewEvaluableExpressionWithFunctions注册 functions := map[string]govaluate.ExpressionFunction { \"strlen\": func(args ...interface{}) (interface{}, error) { length := len(args[0].(string)) return (float64)(length), nil }, } expString := \"strlen('someReallyLongInputString') parse阶段 func NewEvaluableExpression(expression string) (*EvaluableExpression, error) { functions := make(map[string]ExpressionFunction) return NewEvaluableExpressionWithFunctions(expression, functions) //也要经过解析token //在循环里逐个查看字符, 获得token的切片: []ExpressionToken -- 这里的token都不是一个ast ret.tokens, err = parseTokens(expression, functions) err = checkBalance(ret.tokens) err = checkExpressionSyntax(ret.tokens) //优化token slice. ret.tokens, err = optimizeTokens(ret.tokens) //planStages把token列表转为执行树 ret.evaluationStages, err = planStages(ret.tokens) } parseTokens 对input的每个字符都parse func newLexerStream(source string) *lexerStream { var ret *lexerStream var runes []rune for _, character := range source { runes = append(runes, character) } ret = new(lexerStream) ret.source = runes ret.length = len(runes) return ret } token类型 token是{Kind, Value} type ExpressionToken struct { //Kind是预定义的int标号 Kind TokenKind //值就是万能interface Value interface{} } type TokenKind int const ( UNKNOWN TokenKind = iota PREFIX NUMERIC BOOLEAN STRING PATTERN TIME VARIABLE FUNCTION SEPARATOR ACCESSOR COMPARATOR LOGICALOP MODIFIER CLAUSE CLAUSE_CLOSE TERNARY ) planStages 从token到执行树. 那么执行树里面有什么呢? /* Creates a `evaluationStageList` object which represents an execution plan (or tree) which is used to completely evaluate a set of tokens at evaluation-time. The three stages of evaluation can be thought of as parsing strings to tokens, then tokens to a stage list, then evaluation with parameters. */ func planStages(tokens []ExpressionToken) (*evaluationStage, error) { stream := newTokenStream(tokens) stage, err := planTokens(stream) if err != nil { return nil, err } // while we're now fully-planned, we now need to re-order same-precedence operators. // this could probably be avoided with a different planning method reorderStages(stage) stage = elideLiterals(stage) return stage, nil } operator 在plan执行树的时候, 所有最底层的操作都被定义为evaluationStage.operator /* A truly special precedence function, this handles all the \"lowest-case\" errata of the process, including literals, parmeters, clauses, and prefixes. */ func planValue(stream *tokenStream) (*evaluationStage, error) { ... //根据token的kind信息决定operator switch token.Kind { ... case VARIABLE: operator = makeParameterStage(token.Value.(string)) case NUMERIC: fallthrough case STRING: fallthrough case PATTERN: fallthrough case BOOLEAN: symbol = LITERAL operator = makeLiteralStage(token.Value) } } 每个具体的操作都有对应的stage func subtractStage(left interface{}, right interface{}, parameters Parameters) (interface{}, error) { return left.(float64) - right.(float64), nil } func multiplyStage(left interface{}, right interface{}, parameters Parameters) (interface{}, error) { return left.(float64) * right.(float64), nil } 它们被放到一个map表里 var stageSymbolMap = map[OperatorSymbol]evaluationOperator{ EQ: equalStage, NEQ: notEqualStage, GT: gtStage, LT: ltStage, GTE: gteStage, LTE: lteStage, REQ: regexStage, NREQ: notRegexStage, AND: andStage, OR: orStage, IN: inStage, BITWISE_OR: bitwiseOrStage, BITWISE_AND: bitwiseAndStage, BITWISE_XOR: bitwiseXORStage, BITWISE_LSHIFT: leftShiftStage, BITWISE_RSHIFT: rightShiftStage, PLUS: addStage, MINUS: subtractStage, MULTIPLY: multiplyStage, DIVIDE: divideStage, MODULUS: modulusStage, EXPONENT: exponentStage, NEGATE: negateStage, INVERT: invertStage, BITWISE_NOT: bitwiseNotStage, TERNARY_TRUE: ternaryIfStage, TERNARY_FALSE: ternaryElseStage, COALESCE: ternaryElseStage, SEPARATE: separatorStage, } 执行阶段 /* Same as `Eval`, but automatically wraps a map of parameters into a `govalute.Parameters` structure. */ func (this EvaluableExpression) Evaluate(parameters map[string]interface{}) (interface{}, error) { if parameters == nil { return this.Eval(nil) } /* Runs the entire expression using the given [parameters]. e.g., If the expression contains a reference to the variable \"foo\", it will be taken from `parameters.Get(\"foo\")`. This function returns errors if the combination of expression and parameters cannot be run, such as if a variable in the expression is not present in [parameters]. In all non-error circumstances, this returns the single value result of the expression and parameters given. e.g., if the expression is \"1 + 1\", this will return 2.0. e.g., if the expression is \"foo + 1\" and parameters contains \"foo\" = 2, this will return 3.0 */ return this.Eval(MapParameters(parameters)) { return this.evaluateStage(this.evaluationStages, parameters) { //这里其实对应的是这个stage, 比如是multiplyStage, 执行 //left.(float64) * right.(float64), nil return stage.operator(left, right, parameters) } } } 总结 这个库是个非常简化版的解释器. 也有标准的三步: token阶段, 对应ast planStage阶段, 每个基础操作都有个operaor, 对应执行树 执行阶段, 执行预定义好的动作operaor. "},"notes/golang_encoding_gotiny.html":{"url":"notes/golang_encoding_gotiny.html","title":"gotiny编解码","keywords":"","body":" 警告 gotiny会直接用传入的buf 原因 解决 问答 gotiny_test baseTyp 带方法的类型 interface变量 构造测试数据 测试流程 补充 interface和reflect.Value 例子 代码阅读之encode Marshal Encoder Encode 总结 encode核心函数 基础类型编码 bool编码 int编码 其他 非基础类型编码 每个类型都对应一个encEngine 获取Interface的实体类型名 从指向interface的指针到其数据(解引用) 疑问 补充: reflect.Value源码 总结 代码阅读之decode Unmarshal 解码engine Decoder类型 解码bool类型 解码string getDecEngine() 总结 encoder和decoder总结 警告 gotiny会直接用传入的buf 遇到一个问题, 用在循环里用gotiny解码, 传入了相同的buf: dec := gotiny.NewDecoderWithPtr((*streamTransportMsg)(nil)) bufSize := make([]byte, 4) bufMsg := make([]byte, 512) for { //从网络读size和buf到bufSize和bufMsg var tm streamTransportMsg dec.Decode(bufMsg, &tm) //解码到tm, tm是个结构体, 里面包括msg域是[]byte // swap src and dst streamChan 奇怪的现象是, for循环里大概收到了几次的报文, 经过解码得到: 3 8 hello world 在第9行, send到channel之前打印tm.msg, 都是对的. 但另外一个goroutine读这个streamChan, 也能得到4次数据, 但是是这样的: 8 8 world world 原因 gotiny对[]byte的编码直接用了用户传入的buf func decBytes(d *Decoder, p unsafe.Pointer) { bytes := (*[]byte)(p) if d.decIsNotNil() { l := int(d.decUint32()) *bytes = d.buf[d.index : d.index+l] //这里的d.buf就是Decode传入的用户buf d.index += l } else if !isNil(p) { *bytes = nil } } 这么来看, 因为bufMsg := make([]byte, 512)是共享的, 另外一个goroutine还没有来得及读channel, 这个bufMsg就会被下次的Decode调用改变掉, 导致tm.msg变化. 除了decBytes, 字符串和int8/uint8都直接用了buf.--2022.09.10更新, string, int8, uint8在赋值的时候发生了值拷贝. 特别的, 把一个byte array强转成string, 虽然string是个胖指针, 但我认为其底层的字符串内容也发生了每个字节的拷贝. func decString(d *Decoder, p unsafe.Pointer) { l, val := int(d.decUint32()), (*string)(p) *val = string(d.buf[d.index : d.index+l]) d.index += l } func decInt8(d *Decoder, p unsafe.Pointer) { *(*int8)(p) = int8(d.buf[d.index]); d.index++ } func decUint8(d *Decoder, p unsafe.Pointer) { *(*uint8)(p) = d.buf[d.index]; d.index++ } 解决 给gotiny增加copy mode, 使能之后在decBytes时就拷贝一份 bytes := (*[]byte)(p) if d.decIsNotNil() { l := int(d.decUint32()) if d.copyMode { buf := make([]byte, l) copy(buf, d.buf[d.index:d.index+l]) *bytes = buf } else { *bytes = d.buf[d.index : d.index+l] } d.index += l } else if !isNil(p) { *bytes = nil 详见这个PR: https://github.com/niubaoshu/gotiny/pull/6 问答 为什么Marshal强制要求入参是指针?答: 估计是性能方面的考虑. 入参是普通对象也是可以的, 但参数也会值拷贝. 强制要求入参是指针, 就避免了用户传入\"值\"带来的深拷贝. 这个设计挺好的. 为什么要用这样的结构?reflect.ValueOf(&接口变量).Elem().InterfaceData()[1]从功能上看, 这和reflect.ValueOf(接口变量).InterfaceData()[1]是不是一样的?猜测: 我认为从功能上看是一样的. 因为对一个接口变量取地址再ValueOf再Elem就还原了这个接口变量. 那么作者这么做的用意是避免拷贝吗? 取地址再ValueOf能避免interface直接赋值带来的拷贝, 但是再Elem不是还要拷贝吗? 比如rv := reflect.ValueOf(a)实际上是得到a的副本的值 那这里空转了一下的意义又是什么呢? gotiny_test baseTyp 首先定义了一个baseTyp, 包含了基本类型, array, interface, 以及匿名包含了另外一个结构体 没有slice, 没有maptype baseTyp struct { ... //基本类型 array [3]uint32 inter interface{} A //匿名包含A, A是个结构体, 里面是name phone等有实际意义的field } 还有无限循环的自定义类型, 很神type ( cirTyp *cirTyp cirStruct struct { a int *cirStruct } cirMap map[int]cirMap cirSlice []cirSlice ) var( vcir cirTyp v2cir cirTyp = &vcir v3cir cirTyp = &v2cir ) 带方法的类型 tint实现了io readWriter type tint int func (tint) Read([]byte) (int, error) { return 0, nil } func (tint) Write([]byte) (int, error) { return 0, nil } func (tint) Close() error { return nil } gotiny自己的编解码接口, 外部类型可以实现这两个接口, 框架会调用注意Encode只返回[]byte, 而Decode返回使用了多少个字节的buf. 两个接口都不返回错误. 那么错误只能通过panic传递. // 只应该由指针来实现该接口 type GoTinySerializer interface { // 编码方法，将对象的序列化结果append到入参数并返回，方法不应该修改入参数值原有的值 GotinyEncode([]byte) []byte // 解码方法，将入参解码到对象里并返回使用的长度。方法从入参的第0个字节开始使用，并且不应该修改入参中的任何数据 GotinyDecode([]byte) int } // 下面这个gotinyTest实现了上面的接口, 演示了 type gotinyTest string func (v *gotinyTest) GotinyEncode(buf []byte) []byte { return append(buf, gotiny.Marshal((*string)(v))...) } func (v *gotinyTest) GotinyDecode(buf []byte) int { return gotiny.Unmarshal(buf, (*string)(v)) } interface变量 vnilptr *int v2nilptr []string vnilptrptr = &vnilptr v0interface interface{} vinterface interface{} = varray v1interface io.ReadWriteCloser = tint(2) v2interface io.ReadWriteCloser = os.Stdin v3interface interface{} = &vinterface v4interface interface{} = &v1interface v5interface interface{} = &v2interface v6interface interface{} = &v3interface v7interface interface{} = &v0interface v8interface interface{} = &vnilptr v9interface interface{} = &v8interface 构造测试数据 这里的数据是个interface切片 vs = []interface{}{ 里面是各种生成的, 预赋值的变量 } length = len(vs) buf = make([]byte, 0, 1 要看懂InterfaceData()函数, 要看源码: 把v.ptr当作[2]uintptr的指针, 取值后返回. 注意最外层的取值*操做, 就是拷贝*[2]uintptr指向的[2]uintptr的意思, 也就是返回\"只读\"的[2]uintptr // InterfaceData returns the interface v's value as a uintptr pair. // It panics if v's Kind is not Interface. func (v Value) InterfaceData() [2]uintptr { // TODO: deprecate this v.mustBe(Interface) // We treat this as a read operation, so we allow // it even for unexported data, because the caller // has to import \"unsafe\" to turn it into something // that can be abused. // Interface value is always bigger than a word; assume flagIndir. return *(*[2]uintptr)(v.ptr) } 测试流程 func TestEncodeDecode(t *testing.T) { buf := gotiny.Marshal(srci...) //srci是interface切片, 底层是指针 gotiny.Unmarshal(buf, reti...) //retiye是interface切片, 实际也是指针 for i, r := range reti { Assert(t, buf, srci[i], r) //最后判断编解码是否一致 } } 补充 interface和reflect.Value 这里的Value就是reflect.Value type Value struct { // typ holds the type of the value represented by a Value. typ *rtype // Pointer-valued data or, if flagIndir is set, pointer to data. // Valid when either flagIndir is set or typ.pointers() is true. ptr unsafe.Pointer //带了一个flag, 表示这个值的metadata // flag holds metadata about the value. // The lowest bits are flag bits: // - flagStickyRO: obtained via unexported not embedded field, so read-only // - flagEmbedRO: obtained via unexported embedded field, so read-only // - flagIndir: val holds a pointer to the data 注意这里, ptr可能是\"值\", 也可能是指针 // - flagAddr: v.CanAddr is true (implies flagIndir) // - flagMethod: v is a method value. // The next five bits give the Kind of the value. // This repeats typ.Kind() except for method values. // The remaining 23+ bits give a method number for method values. // If flag.kind() != Func, code can assume that flagMethod is unset. // If ifaceIndir(typ), code can assume that flagIndir is set. flag // A method value represents a curried method invocation // like r.Read for some receiver r. The typ+val+flag bits describe // the receiver r, but the flag's Kind bits say Func (methods are // functions), and the top bits of the flag give the method number // in r's type's method table. } interface有空的interface和带方法的interface两种: 大小都是两个指针 代码在/usr/local/go/src/reflect/value.go // emptyInterface is the header for an interface{} value. type emptyInterface struct { typ *rtype word unsafe.Pointer } // nonEmptyInterface is the header for an interface value with methods. type nonEmptyInterface struct { // see ../runtime/iface.go:/Itab itab *struct { ityp *rtype // static interface type typ *rtype // dynamic concrete type hash uint32 // copy of typ.hash _ [4]byte fun [100000]unsafe.Pointer // method table } word unsafe.Pointer } 例子 src1, src2 := \"hello\", []byte(\" world!\") ret1, ret2 := \"\", []byte{3, 4, 5} gotiny.Unmarshal(gotiny.Marshal(&src1, &src2), &ret1, &ret2) fmt.Println(ret1 + string(ret2)) // print \"hello world!\" enc := gotiny.NewEncoder(src1, src2) dec := gotiny.NewDecoder(ret1, ret2) Marshal可传入多个interface, 但必须是指针形式 Unmarshal也是是多个interface, 必须是指针 NewEncoder和NewDecoder要传入所有编解码类型的实例 代码阅读之encode Marshal func Marshal(is ...interface{}) []byte { return NewEncoderWithPtr(is...).Encode(is...) } 实际每个Marshal都是先NewEncoder Encoder要预先生成 func NewEncoderWithPtr(ps ...interface{}) *Encoder { l := len(ps) engines := make([]encEng, l) for i := 0; i NewEncoderWithPtr函数的核心是build一个engine切片engines, 按照入参顺序建立编码引擎. engines[i] = getEncEngine(rt.Elem()) NewEncoder函数类似, 但入参不是指针 func NewEncoder(is ...interface{}) *Encoder { l := len(is) engines := make([]encEng, l) for i := 0; i 反正都要rt := reflect.TypeOf(ps[i])或reflect.TypeOf(is[i]), 那这两个函数可以合并的吧 Encoder type Encoder struct { buf []byte //编码目的数组 off int boolPos int //下一次要设置的bool在buf中的下标,即buf[boolPos] boolBit byte //下一次要设置的bool的buf[boolPos]中的bit位 engines []encEng length int } Encode encode的作用是, 按照出参顺序, 依次encode到byte数组里 func (e *Encoder) Encode(is ...interface{}) []byte { engines := e.engines for i := 0; i engines是encEngine数组encEngine是个函数type encEng func(*Encoder, unsafe.Pointer) 这里关键是这句:engines[i](e, (*[2]unsafe.Pointer)(unsafe.Pointer(&is[i]))[1]) 其中(unsafe.Pointer(&is[i]))是把输入的参数取地址后转成unsafe.Pointer(*[2]unsafe.Pointer)强转后的值[1]是把强转后的地址强转成指向unsafe.Pointer的数组 [2]unsafe.Pointer.这里用到了数组go的数组表达: 切片的表达是个结构体, 包括了数组的指针和大小, 但数组还是和C一样的\"原始\"样子: 指向首元素的指针可以代表这个数组.比如 func main() { s := [7]int{1,2,3,4,5,6,7} //数组的指针可以当数组用 sp := &s //如果s是切片, 则下面语句报错:(type *[]int does not support indexing) sp[1] = 999 fmt.Println(sp) //强转成指向数组的指针可以突破数组的length限制 //但要注意, 你明确知道在干什么. 否则, segment fault snp := (*[20]int)(unsafe.Pointer(&s[0])) snp[15] = 995 fmt.Println(snp) } 那么强转成(*[2]unsafe.Pointer)是什么道理呢? 原来这里用到了interface的内部表达: type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 注意到这里取的就是interface的data域, 因为不论是eface还是iface, data域都是\"第二个\"unsafe.Pointer所以, 这里我猜, type encEng func(*Encoder, unsafe.Pointer)就是要把这个unsafe.Pointer指向的数据, 保存在encoder的buf中. 总结 每个入参interface都有对应的一个encEngine, 这个engine在NewEncoder的时候build好. encEngine负责把interface的data指针编码到encoder中 encode核心函数 上面说到, 入参interface的encEngine需要预先build好. 那NewEncoder里面, 调用的getEncEngine就是干这个的. 到这里已经是解引用了, 这个reflect.Type就是入参interface的实际类型. func getEncEngine(rt reflect.Type) encEng { encLock.RLock() engine := rt2encEng[rt] encLock.RUnlock() if engine != nil { return engine } encLock.Lock() buildEncEngine(rt, &engine) encLock.Unlock() return engine } 先在全局表里按照reflect.Type来查找encEngine这里写的很统一, 实际上, 为什么不用比如reflect.TypeOf(true)呢? 非要先取指针再Elem()这些都是基础类型 rt2encEng = map[reflect.Type]encEng{ reflect.TypeOf((*bool)(nil)).Elem(): encBool, reflect.TypeOf((*int)(nil)).Elem(): encInt, reflect.TypeOf((*int8)(nil)).Elem(): encInt8, reflect.TypeOf((*int16)(nil)).Elem(): encInt16, reflect.TypeOf((*int32)(nil)).Elem(): encInt32, reflect.TypeOf((*int64)(nil)).Elem(): encInt64, reflect.TypeOf((*uint)(nil)).Elem(): encUint, reflect.TypeOf((*uint8)(nil)).Elem(): encUint8, reflect.TypeOf((*uint16)(nil)).Elem(): encUint16, reflect.TypeOf((*uint32)(nil)).Elem(): encUint32, reflect.TypeOf((*uint64)(nil)).Elem(): encUint64, reflect.TypeOf((*uintptr)(nil)).Elem(): encUintptr, reflect.TypeOf((*unsafe.Pointer)(nil)).Elem(): encPointer, reflect.TypeOf((*float32)(nil)).Elem(): encFloat32, reflect.TypeOf((*float64)(nil)).Elem(): encFloat64, reflect.TypeOf((*complex64)(nil)).Elem(): encComplex64, reflect.TypeOf((*complex128)(nil)).Elem(): encComplex128, reflect.TypeOf((*[]byte)(nil)).Elem(): encBytes, reflect.TypeOf((*string)(nil)).Elem(): encString, reflect.TypeOf((*time.Time)(nil)).Elem(): encTime, reflect.TypeOf((*struct{})(nil)).Elem(): encIgnore, reflect.TypeOf(nil): encIgnore, } 基础的编码函数在encbase.go 特别的, 空的结构体和nil按encIgnore编码(也就是啥也不做) func encIgnore(*Encoder, unsafe.Pointer) {} 基础类型编码 bool编码 比如对bool类型的编码: 作者github上是这么描述的: bool类型占用一位，真值编码为1，假值编码为0。当第一次遇到bool类型时会申请一个字节，将值编入最低位，第二次遇到时编入次低位，第九次遇到bool值时再申请一个字节编入最低位，以此类推。 func encBool(e *Encoder, p unsafe.Pointer) { e.encBool(*(*bool)(p)) } func (e *Encoder) encBool(v bool) { if e.boolBit == 0 { e.boolPos = len(e.buf) e.buf = append(e.buf, 0) e.boolBit = 1 } if v { e.buf[e.boolPos] |= e.boolBit } e.boolBit 解释: 这里的boolBit是个byte类型的变量, 每左移8次后变回0. 每次变回0的时候, 就新申请一个byte. int编码 uint8和int8 类型作为一个字节编入字符串的下一个字节。 uint16,uint32,uint64,uint,uintptr 采用Varints编码方式。 int16,int32,int64,int 采用ZigZag转换成一个无符号数后采用Varints编码方式。 从代码上看, int先转为int64, 再转为uint64, 但不是直接转, 而是用zigzag方式转. zigzag的思想来自于我们常用的int都是小整数, 比如15, 2048等等的. 那么可以\"压缩\"来减小体积: 把符号位移到最后, 再做处理. 因为有符号数是原码取反加一(即补码), 对计算机来说和一个非常大的无符号数差不多, 所以要把符号位挪到最后. 详见zigzag算法详细解释 func encInt(e *Encoder, p unsafe.Pointer) { e.encUint64(int64ToUint64(int64(*(*int)(p)))) } // int -5 -4 -3 -2 -1 0 1 2 3 4 5 6 // uint 9 7 5 3 1 0 2 4 6 8 10 12 func int64ToUint64(v int64) uint64 { return uint64((v > 63)) } // uint 9 7 5 3 1 0 2 4 6 8 10 12 // int -5 -4 -3 -2 -1 0 1 2 3 4 5 6 func uint64ToInt64(u uint64) int64 { v := int64(u) return (-(v & 1)) ^ (v>>1)&0x7FFFFFFFFFFFFFFF } func (e *Encoder) encUint64(v uint64) { switch { case v >7)) case v >7)|0x80, byte(v>>14)) case v >7)|0x80, byte(v>>14)|0x80, byte(v>>21)) case v >7)|0x80, byte(v>>14)|0x80, byte(v>>21)|0x80, byte(v>>28)) case v >7)|0x80, byte(v>>14)|0x80, byte(v>>21)|0x80, byte(v>>28)|0x80, byte(v>>35)) case v >7)|0x80, byte(v>>14)|0x80, byte(v>>21)|0x80, byte(v>>28)|0x80, byte(v>>35)|0x80, byte(v>>42)) case v >7)|0x80, byte(v>>14)|0x80, byte(v>>21)|0x80, byte(v>>28)|0x80, byte(v>>35)|0x80, byte(v>>42)|0x80, byte(v>>49)) default: e.buf = append(e.buf, byte(v)|0x80, byte(v>>7)|0x80, byte(v>>14)|0x80, byte(v>>21)|0x80, byte(v>>28)|0x80, byte(v>>35)|0x80, byte(v>>42)|0x80, byte(v>>49)|0x80, byte(v>>56)) } } 所以一般情况下, 比如一个几百的无符号数, zigzag后也不大, 那走上面的switch case估计要走到第二个. 其实如果不考虑大小, 直接存储应该是最方便快速的. 其他 float32和float64采用gob中对浮点类型的编码方式。 complex64类型会强转为一个uint64后采用uint64的编码方式。 complex128类型分别将虚实部分作为float64类型编码。 字符串类型先将字符串长度强转为uint64类型编码，然后将字符串字节数组自身原样编码。 指针类型判断是否为nil，如果是nil，编入一个bool类型的false值后结束，如果不为nil，编入一个bool类型true值，之后将指针解引用，按解引用后的类型编码。 array和slice类型先将长度强转为一个uint64后采用uint64的编码方式编入，然后将每一个元素安装自身的类型编码。 map同上，先编入长度，然后编入一个健，后面跟健对应的值，在编入一个健，接着是值，以此类推。 struct类型将结构体的所有成员按其类型编码，无论是否导出，非导出的字段也会编码。结构体会严格还原。 对于实现encoding包BinaryMarshaler/BinaryUnmarshaler 或 实现 gob包GobEncoder/GobDecoder 接口的类型会用实现的方法编码。 对于实现了gotiny.GoTinySerialize包的类型将采用实现的方法编码和解码 channel和function不能编码 非基础类型编码 是这个函数负责的:buildEncEngine() 基本上能想象, 这是个不断递归的过程. 这个函数写的神了! func buildEncEngine(rt reflect.Type, engPtr *encEng) { ... //如果实现了其他编解码的接口, 先调用那些接口 kind := rt.Kind() var eEng encEng switch kind { case reflect.Ptr: //解引用然后调用其encEngine defer buildEncEngine(rt.Elem(), &eEng) engine = func(e *Encoder, p unsafe.Pointer) { isNotNil := !isNil(p) e.encIsNotNil(isNotNil) if isNotNil { eEng(e, *(*unsafe.Pointer)(p)) } } case reflect.Array: et, l := rt.Elem(), rt.Len() defer buildEncEngine(et, &eEng) size := et.Size() engine = func(e *Encoder, p unsafe.Pointer) { for i := 0; i 0 { //iface engine = func(e *Encoder, p unsafe.Pointer) { isNotNil := !isNil(p) e.encIsNotNil(isNotNil) if isNotNil { v := reflect.ValueOf(*(*interface { M() //注意这里的M的意思是临时定义一个含有M方法的interface. M无入参, 无返回值 })(p)) et := v.Type() e.encString(getNameOfType(et)) getEncEngine(et)(e, getUnsafePointer(&v)) } } } else { //eface engine = func(e *Encoder, p unsafe.Pointer) { isNotNil := !isNil(p) e.encIsNotNil(isNotNil) if isNotNil { v := reflect.ValueOf(*(*interface{})(p)) et := v.Type() e.encString(getNameOfType(et)) getEncEngine(et)(e, getUnsafePointer(&v)) } } } case reflect.Chan, reflect.Func: panic(\"not support \" + rt.String() + \" type\") default: engine = encEngines[kind] } rt2encEng[rt] = engine //build一次, 永久使用 *engPtr = engine } 注: func buildEncEngine(rt reflect.Type, engPtr *encEng)的递归形式是出参形式, 而非return方式type encEng func(*Encoder, unsafe.Pointer)中的unsafe.Pointer指向的类型就是前面rt reflect.Type, 它们是NewEncoder的入参interface的两种表达, rt reflect.Type是类型, 是入参interface用TypeOf得来; unsafe.Pointer是数据, 是入参interface的data域(*[2]unsafe.Pointer)(unsafe.Pointer(入参的地址))[1] interface类型先编码一个encIsNotNil, 再编码其concrete类型的名字e.encString(getNameOfType(et)), 最后编码其值. 也就是说interface类型的编码前面总是会先编码类型名. 整个buildEncEngine的过程是有锁的. 每个类型都对应一个encEngine unsafe.Pointer指向这个类型的实例在编码Interface时, 先编码是否nil, 再编码类型名, 最后编码实体对象. 这里的类型名怎么来的? 首先要知道engine的数据指针p unsafe.Pointer对应的数据类型就是这个engine对应的类型. case reflect.Interface: if rt.NumMethod() > 0 { engine = func(e *Encoder, p unsafe.Pointer) { isNotNil := !isNil(p) e.encIsNotNil(isNotNil) if isNotNil { v := reflect.ValueOf(*(*interface { M() })(p)) et := v.Type() e.encString(getNameOfType(et)) getEncEngine(et)(e, getUnsafePointer(&v)) } } } else { engine = func(e *Encoder, p unsafe.Pointer) { isNotNil := !isNil(p) e.encIsNotNil(isNotNil) if isNotNil { v := reflect.ValueOf(*(*interface{})(p)) et := v.Type() e.encString(getNameOfType(et)) getEncEngine(et)(e, getUnsafePointer(&v)) } } } 比如上面代码中, p unsafe.Pointer指向的是第一行的reflect.Interface. 已知这个data指针p, 想得到其值v, 有两种情况: 带方法的iface 这里定义了一个临时的方法M(), 用来占位?v := reflect.ValueOf(*(*interface { M() })(p)) 不带方法的efacev := reflect.ValueOf(*(*interface{})(p)) 获取Interface的实体类型名 得到v后, 从et := v.Type()中就能得到类型名getNameOfType(et): func getNameOfType(rt reflect.Type) string { if name, has := type2name[rt]; has { //先从已知表中查找 return name } else { return registerType(rt) } } func Register(i interface{}) string { return registerType(reflect.TypeOf(i)) } func registerType(rt reflect.Type) string { name := GetNameByType(rt) RegisterName(name, rt) return name } func RegisterName(name string, rt reflect.Type) { if name == \"\" { panic(\"attempt to register empty name\") } if rt == nil || rt.Kind() == reflect.Invalid { panic(\"attempt to register nil type or invalid type\") } if _, has := type2name[rt]; has { panic(\"gotiny: registering duplicate types for \" + GetNameByType(rt)) } if _, has := name2type[name]; has { panic(\"gotiny: registering name\" + name + \" is exist\") } name2type[name] = rt type2name[rt] = name } 如果已知表中没有查到, 就要注册这个rt. 注册就是把type和name分别放到两个查找表中(name2type, type2name), 双向可查. 重点是 func GetNameByType(rt reflect.Type) string { return string(getName([]byte(nil), rt)) } func getName(prefix []byte, rt reflect.Type) []byte { if rt == nil || rt.Kind() == reflect.Invalid { return append(prefix, []byte(\"\")...) } if rt.Name() == \"\" { //未命名的，组合类型 switch rt.Kind() { case reflect.Ptr: return getName(append(prefix, '*'), rt.Elem()) case reflect.Array: // array是带大小的, 比如[11] return getName(append(prefix, \"[\"+strconv.Itoa(rt.Len())+\"]\"...), rt.Elem()) case reflect.Slice: // slice只是加个[] return getName(append(prefix, '[', ']'), rt.Elem()) case reflect.Struct: // struct的形式类似struct{f1 f1Type; f2 f2Type} prefix = append(prefix, \"struct {\"...) nf := rt.NumField() if nf > 0 { prefix = append(prefix, ' ') } for i := 0; i 0 { prefix = append(prefix, ' ') } for i := 0; i 0 { prefix = append(prefix, ' ') } if no > 1 { prefix = append(prefix, '(') } for i := 0; i 1 { prefix = append(prefix, ')') } return prefix } } //有名的类型走这里, 直接加上package名和类型名 if rt.PkgPath() == \"\" { prefix = append(prefix, rt.Name()...) } else { prefix = append(prefix, rt.PkgPath()+\".\"+rt.Name()...) } return prefix } 从指向interface的指针到其数据(解引用) 还是下面这段代码, 已知指向interface case reflect.Interface 的指针p p unsafe.Pointer 求其值的解码 case reflect.Interface: //化简为eface engine = func(e *Encoder, p unsafe.Pointer) { isNotNil := !isNil(p) e.encIsNotNil(isNotNil) if isNotNil { v := reflect.ValueOf(*(*interface{})(p)) et := v.Type() e.encString(getNameOfType(et)) getEncEngine(et)(e, getUnsafePointer(&v)) } } 以eface为例. 首先p是个指针, 指向上级interface的data, 而这个data还是个interface. 这里先把p转成指向interface的指针, 那么再取值*(*interface{})(p)就是这个interface了.然后ValueOf这个值得到的v, 就是要被编码的interface的reflect.Value表达.那么接下来先编码代表这个类型的字符串.然后递归的调用getEncEngine(et)(e, getUnsafePointer(&v)) 在unsafe.go中, 作者把reflect.Value以复制代码的形式, 定义成refVal.\"原版\"的reflect.Value的域成员是小写的无法导出, 只有源码拷贝定义才行.这里用到了go的链接指示词//go:linkname flagIndir reflect.flagIndir, 把flagIndir当作reflect.flagIndir来链接. type refVal struct { _ unsafe.Pointer ptr unsafe.Pointer flag flag } type flag uintptr //go:linkname flagIndir reflect.flagIndir const flagIndir flag = 1 这里的逻辑是, 如果rv *reflect.Value的ptr是个Pointer-valued data, 就返回它的地址; 如果是普通的指针, 就返回它本身. 疑问 这里先取到指针p指向的interface, 获得其reflect.Value表达v, 然后用reflect.Value再去生成encEngine来调用, 并传入getUnsafePointer(&v)做为下一级的unsafe.Pointer. 问题是, 为什么不直接用interface呢? 像这样: case reflect.Interface: //化简为eface engine = func(e *Encoder, p unsafe.Pointer) { isNotNil := !isNil(p) e.encIsNotNil(isNotNil) if isNotNil { i := *(*interface{})(p) //先得到这个interface的值 i et := reflect.TypeOf(i) e.encString(getNameOfType(et)) getEncEngine(et)(e, (*[2]unsafe.Pointer)(unsafe.Pointer(&i))[1]) //或者直接用p getEncEngine(et)(e, (*[2]unsafe.Pointer)(p)[1]) } } 有两种可能: 避免值拷贝. 很明显i := *(*interface{})(p)会发生interface的值拷贝, 但拷贝interface似乎不heavy? interface里面存interface的情况下, 不能用\"第二个\"unsafe.Pointer指针找到data. 补充: reflect.Value源码 根据/usr/local/go/src/reflect/value.go的注释: type Value struct { // typ holds the type of the value represented by a Value. typ *rtype // Pointer-valued data or, if flagIndir is set, pointer to data. // Valid when either flagIndir is set or typ.pointers() is true. ptr unsafe.Pointer // flag holds metadata about the value. flag } type flag uintptr const ( flagKindWidth = 5 // there are 27 kinds flagKindMask flag = 1 总结 为什么要defer里面递归?因为这个函数的最后, 把生成的engine要放到全局变量rt2encEng中, 以后再次遇到同类型的值, 就不需要再build一次了.defer的意思是先让本次的结果进到这个rt2encEng里面, 这样如果递归的过程还需要用到这个类型, 就可以直接查找到了. 很神 func buildEncEngine(rt reflect.Type, engPtr *encEng)的递归形式是出参形式, 而非return方式type encEng func(*Encoder, unsafe.Pointer)中的unsafe.Pointer指向的类型就是前面rt reflect.Type, 它们是NewEncoder的入参interface的两种表达, rt reflect.Type是类型, 是入参interface用TypeOf得来; unsafe.Pointer是数据, 是入参interface的data域(*[2]unsafe.Pointer)(unsafe.Pointer(入参的地址))[1] interface类型先编码一个encIsNotNil, 再编码其concrete类型的名字e.encString(getNameOfType(et)), 最后编码其值. 也就是说interface类型的编码前面总是会先编码类型名. 整个buildEncEngine的过程是有锁的. 代码阅读之decode Unmarshal func Unmarshal(buf []byte, is ...interface{}) int { return NewDecoderWithPtr(is...).Decode(buf, is...) } Decode的核心逻辑是按照入参is的类型, 从buf里解码 解码engine 解码engine的形式竟然和编码一样: type decEng func(*Decoder, unsafe.Pointer) 也是从一个全局表里查 rt2decEng = map[reflect.Type]decEng{ reflect.TypeOf((*bool)(nil)).Elem(): decBool, reflect.TypeOf((*int)(nil)).Elem(): decInt, reflect.TypeOf((*int8)(nil)).Elem(): decInt8, reflect.TypeOf((*int16)(nil)).Elem(): decInt16, reflect.TypeOf((*int32)(nil)).Elem(): decInt32, reflect.TypeOf((*int64)(nil)).Elem(): decInt64, reflect.TypeOf((*uint)(nil)).Elem(): decUint, reflect.TypeOf((*uint8)(nil)).Elem(): decUint8, reflect.TypeOf((*uint16)(nil)).Elem(): decUint16, reflect.TypeOf((*uint32)(nil)).Elem(): decUint32, reflect.TypeOf((*uint64)(nil)).Elem(): decUint64, reflect.TypeOf((*uintptr)(nil)).Elem(): decUintptr, reflect.TypeOf((*unsafe.Pointer)(nil)).Elem(): decPointer, reflect.TypeOf((*float32)(nil)).Elem(): decFloat32, reflect.TypeOf((*float64)(nil)).Elem(): decFloat64, reflect.TypeOf((*complex64)(nil)).Elem(): decComplex64, reflect.TypeOf((*complex128)(nil)).Elem(): decComplex128, reflect.TypeOf((*[]byte)(nil)).Elem(): decBytes, reflect.TypeOf((*string)(nil)).Elem(): decString, reflect.TypeOf((*time.Time)(nil)).Elem(): decTime, reflect.TypeOf((*struct{})(nil)).Elem(): decIgnore, reflect.TypeOf(nil): decIgnore, } Decoder类型 type Decoder struct { buf []byte //buf index int //下一个要使用的字节在buf中的下标 boolPos byte //下一次要读取的bool在buf中的下标,即buf[boolPos] boolBit byte //下一次要读取的bool的buf[boolPos]中的bit位 engines []decEng //解码器集合 length int //解码器数量 } 解码bool类型 解码的思路就是把数据还原, 写到unsafe.Pointer中. 比如解码bool, 是编码bool的逆过程 func decBool(d *Decoder, p unsafe.Pointer) { *(*bool)(p) = d.decBool() } func (d *Decoder) decBool() (b bool) { if d.boolBit == 0 { d.boolBit = 1 d.boolPos = d.buf[d.index] d.index++ } b = d.boolPos&d.boolBit != 0 d.boolBit 解码string 先解出len, 把buf的index到index+len的字符串拷贝到指针p里. func decString(d *Decoder, p unsafe.Pointer) { l, val := int(d.decUint32()), (*string)(p) *val = string(d.buf[d.index : d.index+l]) d.index += l } 对比编码string的过程是先编码p指向的string的len, 再依次拷贝s的字符到buf func encString(e *Encoder, p unsafe.Pointer) { s := *(*string)(p) e.encUint32(uint32(len(s))) e.buf = append(e.buf, s...) } getDecEngine() 和Marshal一样, Unmarshal也要先build解码器, 其核心是 engines[i] = getDecEngine(reflect.TypeOf(入参interface)) 也是先从全局表查找, 基础类型的decEngine早已写好到rt2decEng func getDecEngine(rt reflect.Type) decEng { decLock.RLock() engine := rt2decEng[rt] decLock.RUnlock() if engine != nil { return engine } decLock.Lock() buildDecEngine(rt, &engine) decLock.Unlock() return engine } 复合类型需要build func buildDecEngine(rt reflect.Type, engPtr *decEng) { //如果递归调用到这里, 先看看之前是否有新加入的decEng engine, has := rt2decEng[rt] if has { *engPtr = engine return } if _, engine = implementOtherSerializer(rt); engine != nil { rt2decEng[rt] = engine *engPtr = engine return } kind := rt.Kind() var eEng decEng switch kind { case reflect.Ptr: //p指向的是ptr et := rt.Elem() defer buildDecEngine(et, &eEng) engine = func(d *Decoder, p unsafe.Pointer) { if d.decIsNotNil() { //因为是ptr, 在编码的时候是先编码一个bool的, 标识是否nil if isNil(p) { // p指向的值是nil *(*unsafe.Pointer)(p) = unsafe.Pointer(reflect.New(et).Elem().UnsafeAddr()) // 新申请一个et类型的变量空间, 并赋值给p; 现在p指向这个新的空间. 关键是reflect.New函数 } eEng(d, *(*unsafe.Pointer)(p)) //调用指针指向的value的decEng } else if !isNil(p) { //原值(即编码时的值)就是nil *(*unsafe.Pointer)(p) = nil } } case reflect.Array: //和编码结构高度一致 l, et := rt.Len(), rt.Elem() size := et.Size() defer buildDecEngine(et, &eEng) engine = func(d *Decoder, p unsafe.Pointer) { for i := 0; i 总结 解码的思路就是把数据还原, 写到unsafe.Pointer p中 但这里一个明显的不足是, 必须要预先指定要解码的数据类型. 解码器需要按照指定的入参类型来解码. 要decode interface, 需要预先显式注册该interface的实体类型(即建立name到reflect.Type的映射关系). 这点和gob一样. 编码interface的类型字符串只是用来当作key查找其reflect.Type类型的. encoder和decoder总结 encoder根据入参类型build encEngine表; decoder类似 如果要decode interface, 要先注册其concrete类型 encode不需要预先注册interface的concrete类型, encode流程里会自动注册. "},"notes/golang_abs.html":{"url":"notes/golang_abs.html","title":"解释器abs","keywords":"","body":" abs代码细看 为什么stdin能被迭代? evalIdentifier() 回到for in 现在清楚了 abs代码 代码组织 代码风格 从cli开始 全局env NewEnvironment 基础对象 string基础对象 Array 内置函数 内置函数的实现 内置函数如何被调用 -- Eval()的魔法 Run() require和source 第一步 lexer 第二步 parser 举例: ParseNumberLiteral 第三步 ParseProgram parseReturnStatement parseAssignStatement() parseExpressionStatement() 以上三个函数, 都调用了parseExpression() Eval() ast.Node是不是树? 树分叉一般发生在Program和BlockStatement级别 function Eval的实现 ast 总结 abs abs -- go实现的类shell 字符串 内置通用array结构 内置通用hash结构, 不同于go的map, 这里的key只能是string 函数 内置函数 装饰器 自带的标准库 cli cli举例 repl cli 举例 函数cache abs代码细看 为什么stdin能被迭代? 官方文档中, stdin()是个函数, 可以用来从标准输入读取输入 echo(\"What do you like?\") echo(\"Oh, you like %s!\", stdin()) # This line will block until user enters some text 但stdin又能用于for # Will read all input to the # stdin and output it back for input in stdin { echo(input) } # Or from the REPL: ⧐ for input in stdin { echo((input.int() / 2).str() + \"...try again:\") } 10 5...try again: 5 2.5...try again: ... 那么stdin到底是什么呢? 注意到functions.go里面, 注册内置函数的时候, 有: // stdin() \"stdin\": &object.Builtin{ Next: stdinNextFn, Types: []string{}, Fn: stdinFn, }, 是把内置对象放到map[string]*object.Builtin中, 它是全局的变量evaluator.Fns object.Builtin是个结构体: type Builtin struct { Token token.Token Fn BuiltinFunction Next func() (Object, Object) Types []string Iterable bool } stdin有点特殊, 它除了有Fn函数, 还有Next函数. 在所有内置的方法中, 只有stdin有Next函数. // stdin() -- implemented with 2 functions func stdinFn(tok token.Token, env *object.Environment, args ...object.Object) object.Object { v := scanner.Scan() if !v { return EOF } return &object.String{Token: tok, Value: scanner.Text()} } func stdinNextFn() (object.Object, object.Object) { v := scanner.Scan() if !v { return nil, EOF } defer func() { scannerPosition += 1 }() return &object.Number{Value: float64(scannerPosition)}, &object.String{Token: tok, Value: scanner.Text()} } evalIdentifier() 这个函数中, 先是在env变量里面找, 优先返回变量; 其次返回builtin的对象.比如node.Value是\"stdin\"的时候, 就返回上面注册的stdin的对象 func evalIdentifier( node *ast.Identifier, env *object.Environment, ) object.Object { if val, ok := env.Get(node.Value); ok { return val } if builtin, ok := Fns[node.Value]; ok { return builtin } return newError(node.Token, \"identifier not found: \"+node.Value) } env是管变量对象的 Fns是管内建对象的 回到for in for in结构的执行在Eval()函数里 case *ast.ForInExpression: return evalForInExpression(node, env) case *ast.Identifier: return evalIdentifier(node, env) evalForInExpression()函数中, 先调用Eval()得到iterable, 如果这个iterable是*object.Builtin类型, // for k,v in 1..10 {v} func evalForInExpression( fie *ast.ForInExpression, env *object.Environment, ) object.Object { iterable := Eval(fie.Iterable, env) // If \"k\" and \"v\" were already declared, let's keep // them aside... existingKeyIdentifier, okk := env.Get(fie.Key) existingValueIdentifier, okv := env.Get(fie.Value) // ...so that we can restore them after the for // loop is over //这个defer用的漂亮: 后面的loopIterable()函数会给fie.Key和fie.Value赋新值 //这里用defer保证退出的时候, 恢复原Key Value的值, 或者如果当前env就没有这两个变量, 就删掉后面生成的. //漂亮!!!!! 事情还没做, 就把清理工作写好了! defer func() { if okk { env.Set(fie.Key, existingKeyIdentifier) } else { env.Delete(fie.Key) } if okv { env.Set(fie.Value, existingValueIdentifier) } else { env.Delete(fie.Value) } }() switch i := iterable.(type) { case object.Iterable: defer func() { i.Reset() }() return loopIterable(i.Next, env, fie, 0) case *object.Builtin: //这里正好对应\"stdin\"是有Next函数的 if i.Next == nil { return newError(fie.Token, \"builtin function cannot be used in loop\") } return loopIterable(i.Next, env, fie, 0) default: return newError(fie.Token, \"'%s' is a %s, not an iterable, cannot be used in for loop\", i.Inspect(), i.Type()) } } loopIterable()函数要求迭代函数next每次调用都返回一个k, v对. 这也是为什么next函数的签名必须是func() (object.Object, object.Object). 这个k, v对会当作变量保存在env中. // This function iterates over an iterable // represented by the next() function: everytime // we call it, a new kv pair is popped from the // iterable func loopIterable(next func() (object.Object, object.Object), env *object.Environment, fie *ast.ForInExpression, index int64) object.Object { // Let's get the first kv pair out k, v := next() // Let's keep going until there are no // more kv pairs for k != nil && v != EOF { // set the special k v variables in the // environment env.Set(fie.Key, k) env.Set(fie.Value, v) res := Eval(fie.Block, env) if isError(res) { // If we have an error it could be: // * a break, so we get out of the loop // * a continue, so we go ahead with the next execution // * an actual error, so we wreak havoc switch res.(type) { case *object.BreakError: return NULL case *object.ContinueError: case *object.Error: return res } } // We had a return from within the FOR..IN loop switch res.(type) { case *object.ReturnValue: return res default: // do nothing } // Let's increment our index, and // pull the next kv pair index++ k, v = next() } if k == nil || v == EOF { // If the index we're at is 0, it means the iterable // was empty. If so, let's try to eval its else condition // (eg. for x in [] {...} else {...}) if index == 0 && fie.Alternative != nil { return Eval(fie.Alternative, env) } } return NULL } 现在清楚了 stdin()是个内置函数 而stdin本身是个关键词, 内部表达是个Builtin的对象, 这个对象有Next方法, 能够被迭代 所有内建函数的名字都是Builtin对象. abs应该是允许变量名和内置对象名重名的, 这种情况下, 用户的变量名优先. abs代码 代码组织 object: object是abs对象的抽象, 是个interface. 实现了Type() Inspect() Json()这三个基本函数的都是object对象. abs对象是abs语法里面的string array hash等基础数据类型. environment.go 是对函数上下文的抽象, 类似frame的概念. 其核心是per function的env, 里面用store map[string]Object 表示变量 evaluator: 核心是递归调用的Eval()函数, 里面有对语法的底层执行代码 functions.go里面实现了基础数据类型的内置方法, 比如len()函数; lexer: lexer把原始的string输入, 通过nextToken()和peekToken等函数的向后移动, 来遍历原始输入. parser: parser.go提供主要的词法分析. 有优先级的定义; 随着token的向后移动, 目的是生成对每个词法的ast.Statement, 即ast树上的nodeconst ( _ int = iota LOWEST AND // && or || EQUALS // == or != LESSGREATER // > or ast: ast的Node是个树, 但在表现上是以interface存在的. node扩展成statement和expression token: token.go很简单, 定义了token的常量. 就像C里面的宏定义. 比如 PLUS = \"+\"作用是如果改语法的token关键词, 改这个文件就好了 util: 代码风格 代码里面用了大量的map数据结构, map表意清楚, 用法直观, 深受喜爱. 比如. 解释语言中, 什么东西都是从string解释而来, nubmer也不意外. abs支持numberLiteral(即string化的number)后面带k m b等单位 // NumberAbbreviations is a list of abbreviations that can be used in numbers eg. 1k, 20B var NumberAbbreviations = map[string]float64{ \"k\": 1000, \"m\": 1000000, \"b\": 1000000000, \"t\": 1000000000000, } 在parser解析number的时候, 这个number是个数字的字符串, 比如1 1.1 或者1.1k 下面的代码就是看最后一个字符是否带量级标记, 是的话就查map表得到abbr的数字. abs的数字默认是float64类型. func (p *Parser) ParseNumberLiteral() ast.Expression { lit := &ast.NumberLiteral{Token: p.curToken} var abbr float64 var ok bool number := p.curToken.Literal // Check if the last character of this number is an abbreviation if abbr, ok = token.NumberAbbreviations[strings.ToLower(string(number[len(number)-1]))]; ok { number = p.curToken.Literal[:len(p.curToken.Literal)-1] } value, err := strconv.ParseFloat(number, 64) if err != nil { msg := fmt.Sprintf(\"could not parse %q as number\", number) p.reportError(msg, p.curToken) return nil } //到这里做的工作就是把1k转为1 * 1000 if abbr != 0 { value *= abbr } //这里的value已经是float64类型了 lit.Value = value return lit } 从cli开始 go build就能编译出abs // 这个函数支持交互式, 也支持执行脚本, 通过命令参数区分 func BeginRepl(args []string, version string) { //比如是脚本模式 //这里的set就是e.store[name] = val; e是下面的*object.Environment env.Set(\"ABS_INTERACTIVE\", evaluator.FALSE) code, err := ioutil.ReadFile(args[1]) Run(string(code), false) } 全局env 每个function都有一个env 基本上, 一般都只有一个env. 这是类shell解释器的通常思路: 所有变量, 函数等都是全局的. 一个文件就像一个大函数. //这里的env是指interp包的全局的环境, 包括所有变量等 var env *object.Environment // Environment represent the environment associated // with the execution context of an ABS script: it // holds all variables etc. type Environment struct { store map[string]Object // Arguments this environment was created in. // When we call function(1, 2, 3), a new environment // for the function to execute is created, and 1/2/3 // are recorded as arguments for this environment. // // Later, if we need to access the arguments passed // to the function, we can refer back to them // through env.CurrentArgs. This is how ... is // implemented. CurrentArgs []Object //每个function都有一个env, 这里的outer是其上层env outer *Environment // Used to capture output. This is typically os.Stdout, // but you could capture in any io.Writer of choice Writer io.Writer // Dir represents the directory from which we're executing code. // It starts as the directory from which we invoke the ABS // executable, but changes when we call require(\"...\") as each // require call resets the dir to its own directory, so that // relative imports work. // // If we have script A and B in /tmp, A can require(\"B\") // wihout having to specify its full absolute path // eg. require(\"/tmp/B\") Dir string // Version of the ABS runtime Version string } NewEnvironment 按照shell的惯例, 所有变量都应该是一个\"frame\" 在repl的init里会新建env 在require(\"file.abs\")的时候会新建env \"{}\".json()方法里面会新建env. 特别的, 执行用户自定义的function时(applyFunction()函数)也会新建一个env, 但这个env是NewEnclosedEnvironment()创建的, 它能够访问外面的(outer)env // NewEnclosedEnvironment creates an environment // with another one embedded to it, so that the // new environment has access to identifiers stored // in the outer one. func NewEnclosedEnvironment(outer *Environment, args []Object) *Environment { env := NewEnvironment(outer.Writer, outer.Dir, outer.Version) env.outer = outer env.CurrentArgs = args return env } 基础对象 abs种的基础对象有: const ( NULL_OBJ = \"NULL\" ERROR_OBJ = \"ERROR\" NUMBER_OBJ = \"NUMBER\" BOOLEAN_OBJ = \"BOOLEAN\" STRING_OBJ = \"STRING\" RETURN_VALUE_OBJ = \"RETURN_VALUE\" // ANY_OBJ represents any ABS type ANY_OBJ = \"ANY\" FUNCTION_OBJ = \"FUNCTION\" BUILTIN_OBJ = \"BUILTIN\" ARRAY_OBJ = \"ARRAY\" HASH_OBJ = \"HASH\" ) // 对象是个interface抽象 type Object interface { Type() ObjectType Inspect() string Json() string } 比如对Number的抽象就是 type Number struct { Token token.Token Value float64 } func (n *Number) Type() ObjectType { return NUMBER_OBJ } // If the number we're dealing with is // an integer, print it as such (1.0000 becomes 1). // If it's a float, let's remove as many zeroes // as possible (1.10000 becomes 1.1). func (n *Number) Inspect() string { if n.IsInt() { return fmt.Sprintf(\"%d\", int64(n.Value)) } return strconv.FormatFloat(n.Value, 'f', -1, 64) } func (n *Number) IsInt() bool { return n.Value == float64(int64(n.Value)) } func (n *Number) Json() string { return n.Inspect() } func (n *Number) ZeroValue() float64 { return float64(0) } func (n *Number) Int() int { return int(n.Value) } 大部分基础对象有Value, 小部分没有 //Boolean就有Value, 很显然, 是个bool type Boolean struct { Token token.Token Value bool } //Function没有Value, 但也实现了Object的方法, 也是Object对象 type Function struct { Token token.Token Name string Parameters []*ast.Parameter Body *ast.BlockStatement Env *Environment Node *ast.FunctionLiteral } string基础对象 string有点特别. 为了支持直接调用shell命令, 字符串还要实现Ok和Done方法 string的典型用法: // cmd = `ls -la` // type(cmd) // STRING // cmd.ok // TRUE // // cmd = `curlzzzzz` // type(cmd) // STRING // cmd.ok // FALSE // // cmd = `sleep 10 &` // type(cmd) // STRING // cmd.done // FALSE // cmd.wait() // ... // cmd.done // TRUE 所以string有更多的属性 type String struct { Token token.Token Value string Ok *Boolean // A special property to check whether a command exited correctly Cmd *exec.Cmd // A special property to access the underlying command Stdout *bytes.Buffer Stderr *bytes.Buffer Done *Boolean mux *sync.Mutex } // string的几个函数写的漂亮 func (s *String) Type() ObjectType { return STRING_OBJ } func (s *String) Inspect() string { return s.Value } func (s *String) Json() string { return `\"` + strings.ReplaceAll(s.Inspect(), `\"`, `\\\"`) + `\"` } func (s *String) ZeroValue() string { return \"\" } func (s *String) HashKey() HashKey { return HashKey{Type: s.Type(), Value: s.Value} } // Function that ensure a mutex // instance is created on the // string func (s *String) mustHaveMutex() { if s.mux == nil { s.mux = &sync.Mutex{} } } // To be called when the command // is done. Releases the internal // mutex. func (s *String) SetDone() { s.mustHaveMutex() s.mux.Unlock() } // To be called when the command // is starting in background, so // that anyone accessing it will // be blocked. func (s *String) SetRunning() { s.mustHaveMutex() s.mux.Lock() } // To be called when we want to // wait on the background command // to be done. func (s *String) Wait() { s.mustHaveMutex() s.mux.Lock() s.mux.Unlock() } // To be called when we want to // kill the background command func (s *String) Kill() error { err := s.Cmd.Process.Kill() // The command value includes output and possible error // We might want to change this output := s.Stdout.String() outputErr := s.Stderr.String() s.Value = strings.TrimSpace(output) + strings.TrimSpace(outputErr) if err != nil { return err } s.Done = TRUE return nil } // Sets the result of the underlying command // on the string. // 3 things are set: // - the string itself (output of the command) // - str.ok // - str.done func (s *String) SetCmdResult(Ok *Boolean) { s.Ok = Ok var output string if Ok.Value { output = s.Stdout.String() } else { output = s.Stderr.String() } // trim space at both ends of out.String(); works in both linux and windows s.Value = strings.TrimSpace(output) s.Done = TRUE } Array abs的Array是个万能容器 type Array struct { Token token.Token Elements []Object // ... is aliased to an array of arguments. // // Since this is a special case of an array, // we need a flag to make sure we know when // to unpack them, else if we do func(...), // func would receive only one array argument // as opposd to the unpacked arguments. IsCurrentArgs bool position int } 内置函数 evaluator/evaluator.go中, 有内置的函数. 内置函数放在一个全局的map表中 var ( NULL = object.NULL EOF = object.EOF TRUE = object.TRUE FALSE = object.FALSE Fns map[string]*object.Builtin ) func init() { Fns = getFns() } 这个map里面是: 部分例子, 很多都是针对string的. map[string]*object.Builtin{ // len(var:\"hello\") \"len\": &object.Builtin{ Types: []string{object.STRING_OBJ, object.ARRAY_OBJ}, Fn: lenFn, }, // cd() or cd(path) \"cd\": &object.Builtin{ Types: []string{}, Fn: cdFn, }, // echo(arg:\"hello\") \"echo\": &object.Builtin{ Types: []string{}, Fn: echoFn, }, // int(string:\"123\") // int(number:\"123\") \"int\": &object.Builtin{ Types: []string{object.STRING_OBJ, object.NUMBER_OBJ}, Fn: intFn, }, // round(string:\"123.1\") // round(number:\"123.1\", 2) \"round\": &object.Builtin{ Types: []string{object.STRING_OBJ, object.NUMBER_OBJ}, Fn: roundFn, }, // number(string:\"1.23456\") \"number\": &object.Builtin{ Types: []string{object.STRING_OBJ, object.NUMBER_OBJ}, Fn: numberFn, }, // stdin() \"stdin\": &object.Builtin{ Next: stdinNextFn, Types: []string{}, Fn: stdinFn, }, // env(variable:\"PWD\") or env(string:\"KEY\", string:\"VAL\") \"env\": &object.Builtin{ Types: []string{}, Fn: envFn, }, // type(variable:\"hello\") \"type\": &object.Builtin{ Types: []string{}, Fn: typeFn, }, // fn.call(args_array) \"call\": &object.Builtin{ Types: []string{object.FUNCTION_OBJ, object.BUILTIN_OBJ}, Fn: callFn, }, // \"{}\".json() // Converts a valid JSON document to an ABS hash. \"json\": &object.Builtin{ Types: []string{object.STRING_OBJ}, Fn: jsonFn, }, // \"a %s\".fmt(b) \"fmt\": &object.Builtin{ Types: []string{object.STRING_OBJ}, Fn: fmtFn, }, // sum(array:[1, 2, 3]) \"sum\": &object.Builtin{ Types: []string{object.ARRAY_OBJ}, Fn: sumFn, }, // sort(array:[1, 2, 3]) \"sort\": &object.Builtin{ Types: []string{object.ARRAY_OBJ}, Fn: sortFn, }, // map(array:[1, 2, 3], function:f(x) { x + 1 }) \"map\": &object.Builtin{ Types: []string{object.ARRAY_OBJ}, Fn: mapFn, }, // every(array:[1, 2, 3], function:f(x) { x == 2 }) \"every\": &object.Builtin{ Types: []string{object.ARRAY_OBJ}, Fn: everyFn, }, // find(array:[1, 2, 3], function:f(x) { x == 2 }) \"find\": &object.Builtin{ Types: []string{object.ARRAY_OBJ}, Fn: findFn, }, // repeat(\"abc\", 3) \"repeat\": &object.Builtin{ Types: []string{object.STRING_OBJ}, Fn: repeatFn, }, // sleep(3000) \"sleep\": &object.Builtin{ Types: []string{object.NUMBER_OBJ}, Fn: sleepFn, }, // source(\"file.abs\") -- soure a file, with access to the global environment \"source\": &object.Builtin{ Types: []string{object.STRING_OBJ}, Fn: sourceFn, }, // require(\"file.abs\") -- require a file without giving it access to the global environment \"require\": &object.Builtin{ Types: []string{object.STRING_OBJ}, Fn: requireFn, }, // exec(command) -- execute command with interactive stdIO \"exec\": &object.Builtin{ Types: []string{object.STRING_OBJ}, Fn: execFn, }, // eval(code) -- evaluates code in the context of the current ABS environment \"eval\": &object.Builtin{ Types: []string{object.STRING_OBJ}, Fn: evalFn, }, } type Builtin struct { Token token.Token Fn BuiltinFunction Next func() (Object, Object) Types []string //这个函数支持的对象类型, 可以支持多个类型, 这里是个切片 Iterable bool } 内置函数的实现 比如, 内置对象是object.Builtin类型 type Builtin struct { Token token.Token Fn BuiltinFunction Next func() (Object, Object) Types []string Iterable bool } //其中BuiltinFunction接受token, env, 其他变长的Object类型参数. 返回Object type BuiltinFunction func(tok token.Token, env *Environment, args ...Object) Object 比如len(\"hello\")的实现就是 // len(var:\"hello\") \"len\": &object.Builtin{ Types: []string{object.STRING_OBJ, object.ARRAY_OBJ}, Fn: lenFn, }, 这个Fn的实现是 // len(var:\"hello\") func lenFn(tok token.Token, env *object.Environment, args ...object.Object) object.Object { //args的个数应该是1 //如果有多个参数, 第一个参数的类型要在[][]string[0]中, 第二个参数要在[][]string[1]中 //这里只有一个arg, 它的类型要在{object.STRING_OBJ, object.ARRAY_OB}中 err := validateArgs(tok, \"len\", args, 1, [][]string{{object.STRING_OBJ, object.ARRAY_OBJ}}) if err != nil { return err } switch arg := args[0].(type) { case *object.Array: return &object.Number{Token: tok, Value: float64(len(arg.Elements))} case *object.String: return &object.Number{Token: tok, Value: float64(len(arg.Value))} default: return newError(tok, \"argument to `len` not supported, got %s\", args[0].Type()) } } 内置函数如何被调用 -- Eval()的魔法 内置函数的基本调用形式有2种 #函数式 len(\"nihaoma\") 7 #对象方法方式 \"nihaoma\".len() 7 #连续调用 \"nihaoma\".len().type() NUMBER #连续的连续 \"nihaoma\".len().type().type() STRING 调用到Fn的路径是, evaluator/evaluator.go中: func applyMethod(tok token.Token, o object.Object, me *ast.MethodExpression, env *object.Environment, args []object.Object) object.Object { method := me.Method.String() //hash类型可以有用户自定义的方法 hash, isHash := o.(*object.Hash) //hash类型时,调用用户态自定义的函数 // If so, run the user-defined function if isHash && hash.GetKeyType(method) == object.FUNCTION_OBJ { pair, _ := hash.GetPair(method) //自定义的函数就不传obj本身了. 是否可以改进成也传入对象本身? 这样这个函数就能访问对象的属性了. return applyFunction(tok, pair.Value.(*object.Function), env, args) } // Now, check if there is a builtin function with the given name f, ok := Fns[method] //检查参数是否类型合法 if util.Contains(f.Types, string(o.Type())) //真正的黑魔法, 调用这个函数 //第一个参数是对象本身, 其他的参数依次append到后面. 这里写的漂亮 args = append([]object.Object{o}, args...) return f.Fn(tok, env, args...) } func applyFunction(tok token.Token, fn object.Object, env *object.Environment, args []object.Object) object.Object { switch fn := fn.(type) { case *object.Function: extendedEnv, err := extendFunctionEnv(fn, args) if err != nil { return err } evaluated := Eval(fn.Body, extendedEnv) return unwrapReturnValue(evaluated) case *object.Builtin: return fn.Fn(tok, env, args...) default: return newError(tok, \"not a function: %s\", fn.Type()) } } 上面的applyMethod被Eval()调用 evaluator.go里面的Eval是个核心函数, 它根据抽象语法树(ast)的node类型, 执行相应的方法. 实际上, Eval()不仅能执行内置的函数, 它能执行任意的\"文本\"代码. 详见下文 Run() cli刚开始的时候, 调用Run()来解释执行代码 // 这个函数支持交互式, 也支持执行脚本, 通过命令参数区分 func BeginRepl(args []string, version string) { //比如是脚本模式 //这里的set就是e.store[name] = val; e是下面的*object.Environment env.Set(\"ABS_INTERACTIVE\", evaluator.FALSE) code, err := ioutil.ReadFile(args[1]) Run(string(code), false) } 其中, Run()函数使用了lexer parser evaluator等包的功能, 负责解释执行string类型的code. func Run(code string, interactive bool) { //词法器 lex := lexer.New(code) //解析器 p := parser.New(lex) //现在是program了 program := p.ParseProgram() evaluated := evaluator.BeginEval(program, env, lex) } // BeginEval (program, env, lexer) object.Object // REPL and testing modules call this function to init the global lexer pointer for error location // NB. Eval(node, env) is recursive func BeginEval(program ast.Node, env *object.Environment, lexer *lexer.Lexer) object.Object { //这里竟然是属于evaluator的全局变量: 用于出错时定位错误在哪一行 // global lexer lex = lexer // run the evaluator //这里的Eval和上面的就对上了 return Eval(program, env) } Eval program实际上就是对program里的每个statement, 递归调用Eval(), 如果返回ReturnValue, 说明可以提前返回; 或者返回Error也要提前返回 func evalProgram(program *ast.Program, env *object.Environment) object.Object { var result object.Object for _, statement := range program.Statements { result = Eval(statement, env) switch result := result.(type) { case *object.ReturnValue: return result.Value case *object.Error: return result } } return result } require和source evaluator/functions.go里面的doSource()函数和Run的流程类似, 它读取一个source文件, 创建lexer, parser, 然后Eval这个program. 第一步 lexer 基本上, lexer的原理是按每个单个字符读入分析. lexer关注字符, 所以每个字符都是rune类型. lexer关注字符的位置; 基本上是把包含code的string, 转化为input []rune, 和其他一些辅助属性. 用于后续解析. type Lexer struct { position int // current position in input (points to current char) readPosition int // current reading position in input (after current char) ch rune // current rune under examination input []rune // map of input line boundaries used by linePosition() for error location lineMap [][2]int // array of [begin, end] pairs: [[0,12], [13,22], [23,33] ... ] } Run()的第一步就是lex := lexer.New(code) func New(in string) *Lexer { l := &Lexer{input: []rune(in)} // map the input line boundaries for CurrentLine() l.buildLineMap() // read the first char l.readChar() return l } 第二步 parser parser是从原始文法, 到ast树的关键.ast token等基础概念可以interface抽象, 而parser是要实际干活的了, 它是个struct.Parser持有一个Lexer的实例, 当前token, 下个token; 还有index表达, 属性表达.另外还有基础词法parse的函数集. type Parser struct { l *lexer.Lexer errors []string curToken token.Token peekToken token.Token // support assignment to index expressions: a[0] = 1, h[\"a\"] = 1 prevIndexExpression *ast.IndexExpression // support assignment to hash property h.a = 1 prevPropertyExpression *ast.PropertyExpression //如果都是预定义好的解析函数, 直接用全局变量函数不是更好? prefixParseFns map[token.TokenType]prefixParseFn infixParseFns map[token.TokenType]infixParseFn } 两个register函数注册解析函数到parser. func (p *Parser) registerPrefix(tokenType token.TokenType, fn prefixParseFn) { p.prefixParseFns[tokenType] = fn } func (p *Parser) registerInfix(tokenType token.TokenType, fn infixParseFn) { p.infixParseFns[tokenType] = fn } New()方法会注册基础关键词的解析函数 func New(l *lexer.Lexer) *Parser { p := &Parser{ l: l, errors: []string{}, } //每个关键词, 都对应一个预定义的解析函数. 比如token.TRUE对一个ParseBoolean. p.prefixParseFns = make(map[token.TokenType]prefixParseFn) p.registerPrefix(token.IDENT, p.parseIdentifier) //前文中, 分析过ParseNumberLiteral, 是把string的\"1k\"转为float64类型的值 p.registerPrefix(token.NUMBER, p.ParseNumberLiteral) p.registerPrefix(token.STRING, p.ParseStringLiteral) p.registerPrefix(token.NULL, p.ParseNullLiteral) p.registerPrefix(token.BANG, p.parsePrefixExpression) p.registerPrefix(token.MINUS, p.parsePrefixExpression) p.registerPrefix(token.TILDE, p.parsePrefixExpression) p.registerPrefix(token.TRUE, p.ParseBoolean) p.registerPrefix(token.FALSE, p.ParseBoolean) ... //infix又是什么呢? p.infixParseFns = make(map[token.TokenType]infixParseFn) p.registerInfix(token.QUESTION, p.parseQuestionExpression) p.registerInfix(token.DOT, p.parseDottedExpression) p.registerInfix(token.PLUS, p.parseInfixExpression) p.registerInfix(token.MINUS, p.parseInfixExpression) p.registerInfix(token.SLASH, p.parseInfixExpression) p.registerInfix(token.EXPONENT, p.parseInfixExpression) p.registerInfix(token.MODULO, p.parseInfixExpression) ... // 最后读两个token出来, 让事情转起来. // Read two tokens, so curToken and peekToken are both set p.nextToken() p.nextToken() return p } prefix和infix对应的是关键词前 关键词中需要的函数; 区别是infix需要额外的入参. 可能就是前序解析出来的ast.Expression type ( prefixParseFn func() ast.Expression infixParseFn func(ast.Expression) ast.Expression ) 举例: ParseNumberLiteral 在parser解析number的时候, 这个number是个数字的字符串, 比如1 1.1 或者1.1k下面的代码就是看最后一个字符是否带量级标记, 是的话就查map表得到abbr的数字.abs的数字默认是float64类型. func (p *Parser) ParseNumberLiteral() ast.Expression { lit := &ast.NumberLiteral{Token: p.curToken} var abbr float64 var ok bool number := p.curToken.Literal // Check if the last character of this number is an abbreviation if abbr, ok = token.NumberAbbreviations[strings.ToLower(string(number[len(number)-1]))]; ok { number = p.curToken.Literal[:len(p.curToken.Literal)-1] } value, err := strconv.ParseFloat(number, 64) if err != nil { msg := fmt.Sprintf(\"could not parse %q as number\", number) p.reportError(msg, p.curToken) return nil } //到这里做的工作就是把1k转为1 * 1000 if abbr != 0 { value *= abbr } //这里的value已经是float64类型了 lit.Value = value return lit } 第三步 ParseProgram parser现在已经有lexer实例, 从而有了从原始string读token的能力; 也注册了基本词法的解析器.现在perser可以把token转换为ast.Expression后面会看到, p.nextToken()会随着每个词法的解析, 根据情况来向后移动. program := p.ParseProgram() 这个ParseProgram()函数也写的非常漂亮 func (p *Parser) ParseProgram() *ast.Program { program := &ast.Program{} program.Statements = []ast.Statement{} //从头到尾逐个token来解析 for !p.curTokenIs(token.EOF) { //解析完成后放到program.Statements中 stmt := p.parseStatement() if stmt != nil { program.Statements = append(program.Statements, stmt) } //下一个token, 实际是调用底层的lexer的 p.l.NextToken() p.nextToken() } return program } parseStatement()先检查是否是Return类型的, 然后尝试先按Assign类型去解析, 最后用Expression类型去解析. func (p *Parser) parseStatement() ast.Statement { if p.curToken.Type == token.RETURN { return p.parseReturnStatement() } statement := p.parseAssignStatement() if statement != nil { return statement } return p.parseExpressionStatement() } parseReturnStatement 题外: 这个peekToken的设计真是绝了. 让我想起了awk的getline()内置函数. peek这个词用的真是绝了. // return x func (p *Parser) parseReturnStatement() *ast.ReturnStatement { //这里的curToken就是\"return\" stmt := &ast.ReturnStatement{Token: p.curToken} returnToken := p.curToken // return; if p.peekTokenIs(token.SEMICOLON) { stmt.ReturnValue = &ast.NullLiteral{Token: p.curToken} } else if p.peekTokenIs(token.RBRACE) || p.peekTokenIs(token.EOF) { // return stmt.ReturnValue = &ast.NullLiteral{Token: returnToken} } else { // return xyz p.nextToken() //LOWEST的意思是当前的优先级最低. parseExpression里面的token现在还不知道, 每个token都有它的优先级的. stmt.ReturnValue = p.parseExpression(LOWEST) } if p.peekTokenIs(token.SEMICOLON) { p.nextToken() } return stmt } parseAssignStatement() 这个函数处理各种赋值语句. // assign to variable: x = y // destructuring assignment: x, y = [z, zz] // assign to index expressions: a[0] = 1, h[\"a\"] = 1 // assign to hash property expressions: h.a = 1 func (p *Parser) parseAssignStatement() ast.Statement { stmt := &ast.AssignStatement{} // Is this a regular x = y assignment? if p.peekTokenIs(token.COMMA) { lexerPosition := p.l.CurrentPosition() // Let's figure out if we are destructuring x, y = [z, zz] if !p.curTokenIs(token.IDENT) { return nil } stmt.Names = p.parseDestructuringIdentifiers() if !p.peekTokenIs(token.ASSIGN) { p.Rewind(lexerPosition) return nil } } else if p.curTokenIs(token.IDENT) { stmt.Name = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal} } else if p.curTokenIs(token.ASSIGN) { stmt.Token = p.curToken if p.prevIndexExpression != nil { // support assignment to indexed expressions: a[0] = 1, h[\"a\"] = 1 stmt.Index = p.prevIndexExpression p.nextToken() stmt.Value = p.parseExpression(LOWEST) // consume the IndexExpression p.prevIndexExpression = nil if p.peekTokenIs(token.SEMICOLON) { p.nextToken() } return stmt } if p.prevPropertyExpression != nil { // support assignment to hash properties: h.a = 1 stmt.Property = p.prevPropertyExpression p.nextToken() stmt.Value = p.parseExpression(LOWEST) // consume the PropertyExpression p.prevPropertyExpression = nil if p.peekTokenIs(token.SEMICOLON) { p.nextToken() } return stmt } } if !p.peekTokenIs(token.ASSIGN) { return nil } p.nextToken() stmt.Token = p.curToken p.nextToken() stmt.Value = p.parseExpression(LOWEST) if p.peekTokenIs(token.SEMICOLON) { p.nextToken() } return stmt } parseExpressionStatement() // (x * y) + z func (p *Parser) parseExpressionStatement() *ast.ExpressionStatement { stmt := &ast.ExpressionStatement{Token: p.curToken} stmt.Expression = p.parseExpression(LOWEST) if p.peekTokenIs(token.SEMICOLON) { p.nextToken() } return stmt } 以上三个函数, 都调用了parseExpression() 这个函数写的真好. 它调用了New parser时注册的各个词法的prefixParseFns和infixParseFns, 这是处理语法中最复杂的地方. 别看这个函数不长, 但却是prefix和infix等基础函数的总调用入口. func (p *Parser) parseExpression(precedence int) ast.Expression { prefix := p.prefixParseFns[p.curToken.Type] if prefix == nil { p.noPrefixParseFnError(p.curToken) return nil } leftExp := prefix() for !p.peekTokenIs(token.SEMICOLON) && precedence Eval() parser阶段, 把lexer的token按照字面语法移动, 得到相应的ast. Expression, 这就是个ast.Node节点.node是个抽象, 实现了下面两个方法的实体类型, 都是node. 这个node就是ast的节点.evaluator.go里面的Eval是个核心函数, 它根据抽象语法树(ast)的node类型, 执行相应的方法. 实际上, Eval()不仅能执行内置的函数, 它能执行任意的\"文本\"代码. 经过前面的三步, 每个词法都对应了一个ast.Node树, ast.Node是个抽象, 一般是Statement或Expression. 从表面上看, node只是个节点, 还是interface, 好像不是个树. 其定义如下: type Node interface { TokenLiteral() string String() string } 特别的, Statement和Expression是Node的扩展抽象. // All statement nodes implement this type Statement interface { Node statementNode() } // All expression nodes implement this type Expression interface { Node expressionNode() } 其中, Expression实现了statementNode()方法, 它本身是个Statement type ExpressionStatement struct { Token token.Token // the first token of the expression Expression Expression } func (es *ExpressionStatement) statementNode() {} func (es *ExpressionStatement) TokenLiteral() string { return es.Token.Literal } func (es *ExpressionStatement) String() string { if es.Expression != nil { return es.Expression.String() } return \"\" } ast.Node是不是树? 表面上看, ast.Node跟树完全扯不上关系 -- 它只是个接口, 而且只有两个返回string的方法. 但其具体实现里, 都是有树的. 比如: BlockStatement就包括了子节点Statements type BlockStatement struct { Token token.Token // the { token Statements []Statement } 一个Program也是Statements的集合, 属性里少了token字段, 但比BlockStatement概念要大, 是整个代码段的入口 type Program struct { Statements []Statement } ExpressionStatement很常用: type ExpressionStatement struct { Token token.Token // the first token of the expression Expression Expression } AssignStatement是个相对复杂的结构: type AssignStatement struct { Token token.Token // the token.ASSIGN token Name *Identifier Names []Expression Index *IndexExpression // support assignment to indexed expressions: a[0] = 1, h[\"a\"] = 1 Property *PropertyExpression // support assignment to hash properties: h.a = 1 Value Expression } number是最简单的, 其值为翻译后的float64 type NumberLiteral struct { Token token.Token Value float64 } Boolean也是类似的 type Boolean struct { Token token.Token Value bool } prefix是两个操作符, infix是三个(比如 x = a + b 中, infix指+) type PrefixExpression struct { Token token.Token // The prefix token, e.g. ! Operator string Right Expression } type InfixExpression struct { Token token.Token // The operator token, e.g. + Left Expression Operator string Right Expression } 我最喜欢的for in组合 type ForInExpression struct { Token token.Token // The 'for' token Block *BlockStatement // The block executed inside the for loop Iterable Expression // An expression that should return an iterable ([1, 2, 3] or x in 1..10) Key string Value string Alternative *BlockStatement } 树分叉一般发生在Program和BlockStatement级别 从上文可以看出, BlockStatement包括Statements集合, 一对{...}是个树, 里面的每个块也是个树; 块里面的Statements是顺序的. 这个是最自然的理解 function function地位特别, 但实现上也似乎没有专门对待. 有参数列表, 有函数体(是个 * BlockStatement类型), 就是个函数. type FunctionLiteral struct { Token token.Token // The 'fn' token Name string // identifier for this function Parameters []*Parameter Body *BlockStatement } Eval的实现 Eval()函数我一行都没舍得删, 完全搬到这里来: 下面是已经实现了node抽象的实体类型 *ast.Program *ast.BlockStatement *ast.ExpressionStatement *ast.ReturnStatement *ast.AssignStatement *ast.NumberLiteral *ast.NullLiteral *ast.CurrentArgsLiteral *ast.StringLiteral *ast.Boolean *ast.PrefixExpression *ast.InfixExpression *ast.CompoundAssignment *ast.IfExpression *ast.WhileExpression *ast.ForExpression *ast.ForInExpression *ast.Identifier *ast.FunctionLiteral *ast.Decorator *ast.CallExpression *ast.MethodExpression *ast.PropertyExpression *ast.ArrayLiteral *ast.IndexExpression *ast.HashLiteral *ast.CommandExpression *ast.BreakStatement *ast.ContinueStatement Eval()的作用是根据输入的ast.Node和env, recursive调用相应的Eval()方法, 最后得到abs的对象表达: object.Object func Eval(node ast.Node, env *object.Environment) object.Object { //node重新赋值为实现了node的实体类型 switch node := node.(type) { // Statements case *ast.Program: return evalProgram(node, env) case *ast.BlockStatement: return evalBlockStatement(node, env) //很多地方都是再次调用Eval //首先, *ast.ExpressionStatement实现了node的接口, 是node //其实体包括一个token和一个Expression //但这里直接忽略其本体实现, 直接使用了其Expression域 //type ExpressionStatement struct { // Token token.Token // the first token of the expression // Expression Expression //} case *ast.ExpressionStatement: //如上文交代的, Expression是node的扩展抽象. 很多基础expression都实现了这个抽象, 比如*ForInExpression或者*NumberLiteral //再次进Eval获取实体类型, 就会跑到其实体类型对应的case里面去 return Eval(node.Expression, env) case *ast.ReturnStatement: val := Eval(node.ReturnValue, env) if isError(val) { return val } return &object.ReturnValue{Value: val} case *ast.AssignStatement: err := evalAssignment(node, env) if isError(err) { return err } return NULL // Expressions case *ast.NumberLiteral: return &object.Number{Token: node.Token, Value: node.Value} case *ast.NullLiteral: return NULL case *ast.CurrentArgsLiteral: return &object.Array{Token: node.Token, Elements: env.CurrentArgs, IsCurrentArgs: true} case *ast.StringLiteral: return &object.String{Token: node.Token, Value: util.InterpolateStringVars(node.Value, env)} case *ast.Boolean: return nativeBoolToBooleanObject(node.Value) case *ast.PrefixExpression: right := Eval(node.Right, env) if isError(right) { return right } return evalPrefixExpression(node.Token, node.Operator, right) case *ast.InfixExpression: return evalInfixExpression(node.Token, node.Operator, node.Left, node.Right, env) case *ast.CompoundAssignment: return evalCompoundAssignment(node, env) case *ast.IfExpression: return evalIfExpression(node, env) case *ast.WhileExpression: return evalWhileExpression(node, env) case *ast.ForExpression: return evalForExpression(node, env) case *ast.ForInExpression: return evalForInExpression(node, env) case *ast.Identifier: return evalIdentifier(node, env) case *ast.FunctionLiteral: params := node.Parameters body := node.Body name := node.Name fn := &object.Function{Token: node.Token, Parameters: params, Env: env, Body: body, Name: name, Node: node} if name != \"\" { env.Set(name, fn) } return fn case *ast.Decorator: return evalDecorator(node, env) case *ast.CallExpression: //对应函数调用 function := Eval(node.Function, env) if isError(function) { return function } args := evalExpressions(node.Arguments, env) // Did we pass arguments as ...? // If so, replace arguments with the // environment's CurrentArgs. // If other arguments were passed afterwards // (eg. func(..., x, y)) we also add those. if len(args) > 0 { firstArg, ok := args[0].(*object.Array) if ok && firstArg.IsCurrentArgs { newArgs := env.CurrentArgs args = append(newArgs, args[1:]...) } } if len(args) == 1 && isError(args[0]) { return args[0] } return applyFunction(node.Token, function, env, args) case *ast.MethodExpression: o := Eval(node.Object, env) if isError(o) { return o } args := evalExpressions(node.Arguments, env) if len(args) == 1 && isError(args[0]) { return args[0] } return applyMethod(node.Token, o, node, env, args) case *ast.PropertyExpression: return evalPropertyExpression(node, env) case *ast.ArrayLiteral: elements := evalExpressions(node.Elements, env) if len(elements) == 1 && isError(elements[0]) { return elements[0] } return &object.Array{Token: node.Token, Elements: elements} case *ast.IndexExpression: return evalIndexExpression(node, env) case *ast.HashLiteral: return evalHashLiteral(node, env) case *ast.CommandExpression: //这个函数也很经典! //执行shell命令. 系统中必须有bash, 所有命令都是bash -c运行的 //对输入的string类型的命令, 利用正则技术, 找出里面的所有变量, 在env里查找到变量值后, 替换string中的$VAR和${VAR}; 注意这里是把abs的变量展开为字符替换到cmd string中, 由bash去解析 //如果命令string cmd以 &结尾, 说明是要后台执行; 注意这里, abs会自己处理后台的操作, 如果命令后台执行, 需要用字符串的Wait()方法来等待. //利用标准库的exec包来执行cmd, 把stdout stderror都定向到内部bytes.Buffer中 return evalCommandExpression(node.Token, node.Value, env) // break and continue are treated just like errors: they will stop // the execution of the current code. Within FOR blocks, though, they // are caught and handled accordingly (see evalForExpression). case *ast.BreakStatement: return newBreakError(node.Token, \"break called outside of a loop\") // break and continue are treated just like errors: they will stop // the execution of the current code. Within FOR blocks, though, they // are caught and handled accordingly (see evalForExpression). case *ast.ContinueStatement: return newContinueError(node.Token, \"continue called outside of a loop\") } return NULL } 以上可以看到, Eval()函数根据node的类型断言, 调用相应的实体类型的实现函数; 而在实体类型中, 很多也是包含了node类型的struct, 再次调用Eval()来获取其子实体类型 type typeA struct { others Other //fieldX 是个interface fieldX node } type typeB struct { others Other //fieldY 是个interface fieldY node } func Eval(node ast.Node, env *object.Environment) object.Object { switch node := node.(type) { // typeA是struct类型, 实体类型 case typeA: //fieldX是个node类型的interface Eval(node.fieldX, env) case typeB: Eval(node.fieldY, env) } } 所以, 一次递归的Eval()调用, 就对应了实体strcut{}中嵌套的一个node interface变量. 在设计node的时候, 实体类型里嵌套包括node的interface, 再递归调用Eval(), 这是个很精妙的框架设计 ast ast对语法树的抽象是: //基本的node只有两个方法, 都返回string // The base Node interface type Node interface { TokenLiteral() string String() string } // All statement nodes implement this type Statement interface { Node statementNode() } // All expression nodes implement this type Expression interface { Node expressionNode() } //program就是statement的集合 // Represents the whole program // as a bunch of statements type Program struct { Statements []Statement } 比如for的表达是 type ForExpression struct { Token token.Token // The 'for' token Identifier string // \"x\" Starter Statement // x = 0 Closer Statement // x++ Condition Expression // x 总结 相对yaegi, abs更倾向于使用interface来抽象, 看起来更简洁. 比如对node的抽象, abs就是个interface, 只规定了两个实现函数; 而yaegi则使用了传统的struct类型的node, 缺点是必须在这个struct里面, 定义一组\"大而全\"的字段, 以适应所有情况. 在某些情况下, 某些字段是无意义的. abs 看了yaegi和govaluate的实现, 先简单对比一下: yaegi: 基于go标准库的词法解析树, 最底层利用reflect.Value等反射方法来执行 只依赖标准库, 但受限于此, 只能解释go的语法, 支持所有go语言的特性. 完成度比较高, 能解释执行go代码. 利用反射和go的runtime交互, 底层执行靠runtime的反射来实现. 比如调用fmt.Println实际上是调用的是已经编译好的runtime内部的符号. govaluate: 自造词法解析, 构建执行流, 底层直接调用基本函数. 所谓的基本函数就是left.(float64) * right.(float64)的运算 只支持简单的\"表达式\"计算, 侧重于得到表达式的值. abs是个自定义语法的完整解释器实现. 下面我们来一探究竟. abs -- go实现的类shell 看起来非常不错!!!!!库地址: https://github.com/abs-lang/abs主页: https://www.abs-lang.org 作者简介, 大神 解释器基于Thorsten Ball的Writing An Interpreter In Go, 另外还有一本Writing A Compiler In Go 还有个类似的用go写的解释器:Magpie Programming Language 是国人写的 reddit讨论 特点如下: 解释执行 兼备shell的灵活性和通用语言的准确性 first look # Simple program that fetches your IP and sums it up res = `curl -s 'https://api.ipify.org?format=json'` if !res.ok { echo(\"An error occurred: %s\", res) exit(1) } ip = res.json().ip total = ip.split(\".\").map(int).sum() if total > 100 { echo(\"The sum of [$ip] is a large number, $total.\") } 字符串 字符串是用引号括起来的: \"hello world\" 'hello world' 用转义可以转义引号: \"I said: \\\"hello world\\\"\" 字符串支持切片操作, 也支持python一样的-index; 也支持+操作 \"hello world\"[1] # e \"string\"[-2] # \"n\" \"string\"[0:3] // \"str\" \"string\"[0:3] // \"str\" \"string\"[1:] // \"tring\" \"string\"[0:-1] // \"strin\" \"hello\" + \" \" + \"world\" # \"hello world\" 支持in操作 \"str\" in \"string\" # true \"xyz\" in \"string\" # false 在字符串中引用变量要加$前缀, 比如 file = \"/etc/hosts\" x = \"File name is: $file\" echo(x) # \"File name is: /etc/hosts\" 或者在命令里面引用变量也要加$ var = \"/etc\" out = `ls -la $var` echo(out) 内置通用array结构 array是个万能容器 # array [1, 2, \"hello\", [1, f(x){ x + 1 }]] # array提供很多fancy的内置函数 [0, 1, 2].every(f(x){x == 0}) # false [1, 2, 3].diff([3, 1]) # [2] [[1, 2], 3, [4]].flatten() # [1, 2, 3, 4] [[[1, 2], [[[[3]]]], [4]]].flatten_deep() # [1, 2, 3, 4] [1, 2, 3].join(\"_\") # \"1_2_3\" [1, 2, 3].intersect([3, 1]) # [1, 3] (1..2).keys() # [0, 1] [1, 2].len() # 2 #每个元素调用函数 [0, 1, 2].map(f(x){x+1}) # [1, 2, 3] [0, 5, -10, 100].max() # 100 f odd(n) { return !!(n % 2) } [0, 1, 2, 3, 4, 5].partition(odd) # [[0, 2, 4], [1, 3, 5]] # pop a = [1, 2, 3] a.pop() # 3 a # [1, 2] # shift a = [1, 2, 3] a.shift() # 1 a # [2, 3] [\"b\", \"a\", \"c\"].sort() # [\"a\", \"b\", \"c\"] [1, 1, 1, 2].unique() # [1, 2] 内置通用hash结构, 不同于go的map, 这里的key只能是string h = {\"a\": 1, \"b\": 2, \"c\": 3} h # {a: 1, b: 2, c: 3} # index assignment h[\"a\"] = 99 h # {a: 99, b: 2, c: 3} # property assignment h.a # 99 h.a = 88 h # {a: 88, b: 2, c: 3} # compound operator assignment to property h.a += 1 h.a # 89 h # {a: 88, b: 2, c: 3} # create new keys via index or property h[\"x\"] = 10 h.y = 20 h # {a: 88, b: 2, c: 3, x: 10, y: 20} h = {\"a\": 1, \"b\": 2, \"c\": 3} h # {a: 1, b: 2, c: 3} # extending a hash by += compound operator h += {\"c\": 33, \"d\": 4, \"e\": 5} h # {a: 1, b: 2, c: 33, d: 4, e: 5} # 也有很多fancy的内置函数 h = {\"a\": 1, \"b\": 2, \"c\": 3} h.items() # [[a, 1], [b, 2], [c, 3]] items(h) # [[a, 1], [b, 2], [c, 3]] h = {\"a\": 1, \"b\": 2, \"c\": 3} h.keys() # [a, b, c] keys(h) # [a, b, c] h = {\"a\": 1, \"b\": 2, \"c\": {\"x\": 10, \"y\":20}} h.pop(\"a\") # {a: 1} h # {b: 2, c: {x: 10, y: 20}} h = {\"a\": 1, \"b\": 2, \"c\": 3} h.values() # [1, 2, 3] values(h) # [1, 2, 3] hash = {\"greeter\": f(name) { return \"Hello $name!\" }} hash.greeter(\"Sally\") # \"Hello Sally!\" 函数 #有名字 f greet(name) { echo(\"Hello $name!\") } greet(`whoami`) # \"Hello root!\" #没名字 f(x, y) { x + y } #带不带return都行 f(x, y) { return x + y } #匿名函数 [1, 2, 3].map(f(x){ x + 1}) # [2, 3, 4] #一等公民 func = f(x){ x + 1} [1, 2, 3].map(func) # [2, 3, 4] #默认参数 f greet(name, greeting = \"hello\") { echo(\"$greeting $name!\") } greet(\"user\") # hello user! greet(\"user\", \"hola\") # hola user! #使用...特殊变量做变长参数 f sum_numbers() { s = 0 for x in ... { s += x } return s } sum_numbers(1) # 1 sum_numbers(1, 2, 3) # 6 f echo_wrapper() { echo(..., \"root\") } echo_wrapper(\"hello %s %s\", \"sir\") # \"hello sir root\" 内置函数 type(1) # NUMBER arg(n) args() [\"abs\", \"--flag1\", \"--flag2\", \"arg1\", \"arg2\"] cd(path) #echo直接支持格式化打印 # echo实际上底层调用的是fmt.Fprintf(env.Writer, args[0].Inspect(), arguments...) # 见evaluator/functions.go echo(\"hello %s\", \"world\") env(\"PATH\") # \"/go/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" #执行文本 eval(\"1 + 1\") # 2 eval('object = {\"x\": 10}; object.x') # 10 exit(code [, message]) #参数 abs --test --test2 2 --test3=3 --test4 -test5 flag(\"test2\") 2 pwd() #随机数 rand(10) # 7 #支持引入外部脚本 mod = require(\"module.abs\") echo(mod.adder(1, 2)) # 3 #展开其他脚本在本脚本 source(path_to_file.abs) #睡眠 sleep(1000) # sleeps for 1 second #读取输入 stdin() #从epoch开始的时间戳 unix_ms() 装饰器 竟然支持装饰器! f uppercase(fn) { return f() { return fn(...).upper() } } @uppercase f stringer(x) { return x.str() } stringer({}) # \"{}\" stringer(12) # \"12\" stringer(\"hello\") # \"HELLO\" 如果函数执行太久就打印 f log_if_slow(treshold_ms) { return f(original_fn) { return f() { start = `date +%s%3N`.int() res = original_fn(...) end = `date +%s%3N`.int() if end - start > treshold_ms { echo(\"mmm, we were pretty slow...\") } return res } } } @log_if_slow(500) f return_random_number_after_sleeping(seconds) { `sleep $seconds` return rand(1000) } 自带的标准库 abs自带标准库, 也是用require来引用 mod = require('@module') # Loads \"module\" from the standard library mod = require('./module') # Loads \"module\" from the current directory mod = require('module') # Loads \"module\" that was installed through the ABS package manager 目前的标准库只有cli runtime 和util cli cli库本身只有100行! cli = require('@cli') #注册一个cmd @cli.cmd(\"date\", \"prints the current date\", {format: ''}) f date(args, flags) { format = flags.format return `date ${format}` } #运行这个cli cli.run() #交互式运行cli cli.repl() cli举例 #!/usr/bin/env abs cli = require('@cli') @cli.cmd(\"ip\", \"finds our IP address\", {}) f ip_address(arguments, flags) { return `curl icanhazip.com` } @cli.cmd(\"date\", \"Is it Friday already?\", {\"format\": \"\"}) f date(arguments, flags) { format = flags.format return `date ${format}` } cli.run() 把上面脚本保存为./cli, 调用这个脚本 $ ./cli Available commands: * date - Is it Friday already? * help - print this help message * ip - finds our IP address $ ./cli help Available commands: * date - Is it Friday already? * help - print this help message * ip - finds our IP address $ ./cli ip 87.201.252.69 $ ./cli date Sat Apr 4 18:06:35 +04 2020 $ ./cli date --format +%s 1586009212 repl cli 举例 #!/usr/bin/env abs cli = require('@cli') res = {\"count\": 0} @cli.cmd(\"count\", \"prints a counter\", {}) f counter(arguments, flags) { echo(res.count) } @cli.cmd(\"incr\", \"Increment our counter\", {}) f incr(arguments, flags) { res.count += 1 return \"ok\" } @cli.cmd(\"incr_by\", \"Increment our counter\", {}) f incr_by(arguments, flags) { echo(\"Increment by how much?\") n = stdin().number() res.count += n return \"ok\" } cli.repl() 使用 $ ./cli help Available commands: * count - prints a counter * help - print this help message * incr - Increment our counter * incr_by - Increment our counter count 0 incr ok incr ok count 2 incr_by Increment by how much? -10 ok count -8 函数cache 比如一个函数要算个东西, 很久. 第一次执行的时候算, 后面如果入参都一样, 就直接用cache里面保存的. 这里的cache是指util.memoize这个装饰器 util = require('@util') @util.memoize(60) f expensive_task(x, y, z) { # do something very expensive here... } "},"notes/golang_调试记录.html":{"url":"notes/golang_调试记录.html","title":"调试记录","keywords":"","body":" 命令记录 dlv使用 dlv headless模式 修改内存 打印unsafe.Pointer 记录debug gvisor 设置package级别的断点 gvisor syscall调试 为什么date -s命令返回Operation not permitted 记录debug adaptiveservice 记录tengo debug go-prompt 性能问题调查 内存还给OS MADV_FREE和MADV_DONTNEED GOGC比例 topid申请内存错误 背景 错误1 错误2 错误3 调查 释放内存后运行 重启后运行 -- nok golang版本1.13换到1.16问题依旧 和版本相关? gshell server内存调试 问题场景 操做1: 首次运行50个govm_test 操做2: 50个govm_test同时restart 第一次内存优化 操做1 加上第90行的效果 操做2 加上第90行的效果 进一步优化思路 goroutine泄漏调试 vscode debug模式 为何dlv总是提示Could not load source 正常的dlv使用 一次空指针访问的panic 调用栈解析和参数解读 切片, 字符串, 和int 变长参数 interface 方法 参数packing 返回值 结构体 指针 slice的make和append性能 只声明切片 -- 400 ns/op make 1 -- 444 ns/op make 10 -- 604 ns/op make 100 -- 2527 ns/op 更正 更正后最终版 最终版结果 结论 pidinfo调试 执行测试 in docker out docker 打开cpu分析 host上profile CPU pprof的refine功能 tooManyTimer调试 命令记录 go tool pprof的http方式 内存 goroutine的情况 同步 锁 阻塞应该也支持, 待调查 trace 代码打开trace 不同的profile文件对比 传统火焰图方式 代码里加调试支持 命令行调试: \"runtime/pprof\" 网页调试: \"net/http/pprof\" 使用debug网页 使用go tool pprof top命令 list命令 svg命令和perf火焰图对比 对照代码片段分析: handleOnu, 主要是select pprof svg perf 火焰图 对照代码片段分析: timerproc notetsleepg 问题: futex唤醒路径是干啥用的? 对照代码片段分析:sysmon 结论 打印调用栈 以json_load为例 pstack打印不了go的调用栈 用-SIGQUIT 注册信号handler 结果 goroutine 0 goroutine 1 用taskset -c 1强制一个核跑 如果只有两个goroutine, 但为什么要起6个线程呢? 命令记录 # 手动访问随机debug端口 http://10.182.105.138:41259/debug/pprof # pprof生成内存视图服务 go tool pprof -http=0.0.0.0:8000 http://10.182.105.138:41259/debug/pprof/heap # 访问内存视图 http://10.182.105.138:64321/ui/?si=inuse_space # debug gshell内存申请导致CPU 100%的问题. perf record -g -p `pidof gshell` -- sleep 60 perf script | /repo/yingjieb/FlameGraph/stackcollapse-perf.pl | /repo/yingjieb/FlameGraph/flamegraph.pl > gshell.svg go tool pprof -http=0.0.0.0:8000 http://10.182.105.138:9998/debug/pprof/profile?seconds=30 最后访问 http://10.182.105.138:60080/ui/ go test -c -o pidinfotest ./pidinfotest -test.run xxxxxx -test.bench BenchmarkP1InfoUpdate ./pidinfotest -test.run xxxxxx -test.bench . -test.benchtime 10s go test -run xxxxxx -bench BenchmarkP1InfoUpdate -cpuprofile cpuiter.out go test -run xxxxxx -bench BenchmarkMapInter -cpuprofile cpuiter.out go test -run xxxxxx -bench BenchmarkMapInter -benchtime 30s -cpuprofile cpuiter.out go tool pprof -http=0.0.0.0:8000 cpuiter.out go tool pprof -http=0.0.0.0:8000 --base cpuiter1.out cpuiter10.out dlv使用 dlv headless模式 启动dlv调试server dlv --headless exec bin/runsc -- -h #成功后会打印 API server listening at: 127.0.0.1:37619 也可以指定port: dlv --headless -l 127.0.0.1:37619 exec bin/runsc -- -h 在client侧: dlv connect 127.0.0.1:37619 (dlv) # 像正常使用dlv一样 修改内存 比如我要修改一个地址的内存 (dlv) x -fmt hex -size 4 0x7bf6c 0x7bf6c: 0x97ff9ee9 //也可以这样显示 (dlv) p %x *(*uint32)(0x7bf6c) //改为0x17ff9ee8 set *(*uint32)(0x7bf6c) = 0x17ff9ee9 修改前:修改后: 可以看到, call指令换成了jmp指令 参考: arm64指令查看在线工具 打印unsafe.Pointer 我在这个函数里: func bluepillHandler(context unsafe.Pointer) 我想打印context (dlv) p context unsafe.Pointer(0x4000460e20) context类型实际上是*arch.UContext64, 但直接p会报错: (dlv) p *(*arch.UContext64)(context) Command failed: can not convert \"context\" to *struct gvisor.dev/gvisor/pkg/sentry/arch.UContext64 但这样可以: (dlv) p *(*arch.UContext64)(0x4000460e20) gvisor.dev/gvisor/pkg/sentry/arch.UContext64 { Flags: 0, Link: 0, Stack: gvisor.dev/gvisor/pkg/abi/linux.SignalStack {Addr: 274882469888, Flags: 0, _:64, Size: 32768}, Sigset: 0, _pad: [120]uint8 [88,245,3,0,64,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,8,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,32,4,7,0,64,0,0,0,...+56 more], _pad2: [8]uint8 [72,15,70,0,64,0,0,0], MContext: gvisor.dev/gvisor/pkg/sentry/arch.SignalContext64 { FaultAddr: 0, Regs: [31]uint64 [274879089664,0,2,274878169088,0,274882992368,1,1,274879089664,18446462873611930624,0,1648372627,815018159,0,0,0,274879438312,274879438160,0,0,274879438648,274879437192,274882469888,0,0,0,274879436488,25907712,274882992224,274879437992,9805828], Sp: 274879438000, Pc: 9815768, Pstate: 536875008, _pad: [8]uint8 [24,16,70,0,64,0,0,0], Fpsimd64: (*\"gvisor.dev/gvisor/pkg/sentry/arch.FpsimdContext\")(0x4000460ff0), }, } 还可以16进制显示: p %x *(*arch.UContext64)(0x4000460e20) 记录debug gvisor 设置package级别的断点 比如调试gvisor, 要给这个函数打断点: package kernel //@pkg/sentry/kernel/task_syscall.go func (t *Task) executeSyscall(sysno uintptr, args arch.SyscallArguments) (rval uintptr, ctrl *SyscallControl, err error) { ... } 在dlv里: 断点的格式是b package.(type).func b pkg/sentry/kernel.(*Task).executeSyscall gvisor syscall调试 先用runsc启动一个docker container docker run --cpus=2 -m 2g --rm --runtime=runsc -it --name=test centos:7 bash // 先找到runsc-sandbox进程pid ./dlv attach 7014 (dlv) b kernel.(*Task).executeSyscall //在container里面敲个回车都会触发断点 //next执行几次 (dlv) p s.Table //设置print命令显示array的个数, 用config -list看具体各项的值 (dlv) config max-array-values 1000 (dlv) next next next ... (dlv) p sysno 1 (dlv) p s.lookup[1] gvisor.dev/gvisor/pkg/sentry/syscalls/linux/vfs2.Write 对应代码 func (t *Task) executeSyscall(sysno uintptr, args arch.SyscallArguments) (rval uintptr, ctrl *SyscallControl, err error) { s := t.SyscallTable() } 解释p s.Table的部分结果: 20: { Name: \"writev\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls/linux/vfs2.Writev, SupportLevel: 3, Note: \"Fully Supported.\", URLs: []string len: 0, cap: 0, nil,}, 59: { Name: \"execve\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls/linux/vfs2.Execve, SupportLevel: 3, Note: \"Fully Supported.\", URLs: []string len: 0, cap: 0, nil,}, 41: { Name: \"socket\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls/linux/vfs2.Socket, SupportLevel: 3, Note: \"Fully Supported.\", URLs: []string len: 0, cap: 0, nil,}, 321: { Name: \"bpf\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls.CapError.func1, SupportLevel: 1, Note: \"Returns \\\"operation not permitted\\\" if the process URLs: []string len: 0, cap: 0, nil,}, 9: { Name: \"mmap\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls/linux/vfs2.Mmap, SupportLevel: 3, Note: \"Fully Supported.\", URLs: []string len: 0, cap: 0, nil,}, 96: { Name: \"gettimeofday\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls/linux.Gettimeofday, SupportLevel: 3, Note: \"Fully Supported.\", URLs: []string len: 0, cap: 0, nil,}, 227: { Name: \"clock_settime\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls/linux.ClockSettime, SupportLevel: 3, Note: \"Fully Supported.\", URLs: []string len: 0, cap: 0, nil,}, 14: { Name: \"rt_sigprocmask\", Fn: gvisor.dev/gvisor/pkg/sentry/syscalls/linux.RtSigprocmask, SupportLevel: 3, Note: \"Fully Supported.\", URLs: []string len: 0, cap: 0, nil,}, 为什么date -s命令返回Operation not permitted 首先, date -s调用的是系统调用clock_settime(), 由上面的表得知, gvisor对应的函数是gvisor.dev/gvisor/pkg/sentry/syscalls/linux.ClockSettime 打断点到这个函数, 然后在container里执行date -s 12:00:00, 就会触发断点: > gvisor.dev/gvisor/pkg/sentry/syscalls/linux.ClockSettime() pkg/sentry/syscalls/linux/sys_time.go:160 (hits goroutine(600):1 total:1) (PC: 0xa140c0) Warning: debugging optimized function (dlv) bt 0 0x0000000000a140c0 in gvisor.dev/gvisor/pkg/sentry/syscalls/linux.ClockSettime at pkg/sentry/syscalls/linux/sys_time.go:160 1 0x000000000096b776 in gvisor.dev/gvisor/pkg/sentry/kernel.(*Task).executeSyscall at pkg/sentry/kernel/task_syscall.go:103 2 0x000000000096c2ed in gvisor.dev/gvisor/pkg/sentry/kernel.(*Task).doSyscallInvoke at pkg/sentry/kernel/task_syscall.go:238 3 0x000000000096bfa5 in gvisor.dev/gvisor/pkg/sentry/kernel.(*Task).doSyscallEnter at pkg/sentry/kernel/task_syscall.go:198 4 0x000000000096bcda in gvisor.dev/gvisor/pkg/sentry/kernel.(*Task).doSyscall at pkg/sentry/kernel/task_syscall.go:173 5 0x0000000000960c45 in gvisor.dev/gvisor/pkg/sentry/kernel.(*runApp).execute at pkg/sentry/kernel/task_run.go:254 6 0x000000000095f78c in gvisor.dev/gvisor/pkg/sentry/kernel.(*Task).run at pkg/sentry/kernel/task_run.go:95 7 0x000000000096a2ca in gvisor.dev/gvisor/pkg/sentry/kernel.(*Task).Start·dwrap·230 at pkg/sentry/kernel/task_start.go:339 8 0x0000000000469321 in runtime.goexit 而这个函数直接返回linuxerr.EPERM // ClockSettime implements linux syscall clock_settime(2). func ClockSettime(*kernel.Task, arch.SyscallArguments) (uintptr, *kernel.SyscallControl, error) { return 0, nil, linuxerr.EPERM } 记录debug adaptiveservice # 注意要用./binary的形式 # 给binary传参数用-- dlv exec ./echo -- -c -cmd timeout -d # 断点 b main.main b (*timeouter).SetTimeout 记录tengo debug # dlv exec执行一个程序, 可以带参数 dlv exec bin/gshell example/govm_test.gsh # 程序停在最开始阶段 # 设断点 (dlv) b SourcePos Breakpoint 1 set at 0x52670f for github.com/d5/tengo/v2.(*CompiledFunction).SourcePos() /repo/yingjieb/github/godevsig/tengo/objects.go:609 # continue, 程序停在断点 (dlv) c # 开始debug, bt, p等常用gdb命令是一样的 (dlv) l > github.com/d5/tengo/v2.(*CompiledFunction).SourcePos() /repo/yingjieb/github/godevsig/tengo/objects.go:610 (PC: 0x52671d) Warning: debugging optimized function 605: return false 606: } 607: 608: // SourcePos returns the source position of the instruction at ip. 609: func (o *CompiledFunction) SourcePos(ip int) parser.Pos { => 610: for ip >= 0 { 611: if p, ok := o.SourceMap[ip]; ok { 612: return p 613: } 614: ip-- 615: } (dlv) p o *github.com/d5/tengo/v2.CompiledFunction { ObjectImpl: github.com/d5/tengo/v2.ObjectImpl {}, Instructions: []uint8 len: 43, cap: 64, [22,0,3,0,0,2,18,0,0,8,20,1,0,2,34,33,0,0,6,0,0,6,0,0,6,0,0,6,0,0,6,20,5,0,2,30,0,20,0,0,2,21,0], NumLocals: 0, NumParameters: 0, VarArgs: false, SourceMap: map[int]github.com/d5/tengo/v2/parser.Pos nil, Free: []*github.com/d5/tengo/v2.ObjectPtr len: 1, cap: 1, [ *(*\"github.com/d5/tengo/v2.ObjectPtr\")(0xc00000e938), ],} (dlv) p ip 32 # 可以调用任意函数 (dlv) call FormatInstructions(o.Instructions, 0) > github.com/d5/tengo/v2.(*CompiledFunction).SourcePos() /repo/yingjieb/github/godevsig/tengo/objects.go:610 (PC: 0x52671d) Warning: debugging optimized function Values returned: ~r2: []string len: 18, cap: 32, [ \"0000 GETG 3 \", \"0003 CONST 2 \", \"0006 INDEX \", \"0007 CONST 8 \", \"0010 CALL 1 0 \", \"0013 POP \", \"0014 BUILTIN 33 \", \"0016 CONST 6 \", \"0019 CONST 6 \", \"0022 CONST 6 \", \"0025 CONST 6 \", \"0028 CONST 6 \", \"0031 CALL 5 0 \", \"0034 POP \", \"0035 GETF 0 \", \"0037 CALL 0 0 \", \"0040 POP \", \"0041 RET 0 \", ] # 新增断点, 重新run这个程序 (dlv) b postRun (dlv) restart //会停在刚开始 (dlv) c # 停在func (v *VM) postRun() (err error) (dlv) p v.framesIndex 3 (dlv) p v.curFrame *github.com/d5/tengo/v2.frame { fn: *github.com/d5/tengo/v2.CompiledFunction { ObjectImpl: github.com/d5/tengo/v2.ObjectImpl {}, Instructions: []uint8 len: 43, cap: 64, [22,0,3,0,0,2,18,0,0,8,20,1,0,2,34,33,0,0,6,0,0,6,0,0,6,0,0,6,0,0,6,20,5,0,2,30,0,20,0,0,2,21,0], NumLocals: 0, NumParameters: 0, VarArgs: false, SourceMap: map[int]github.com/d5/tengo/v2/parser.Pos nil, Free: []*github.com/d5/tengo/v2.ObjectPtr len: 1, cap: 1, [ *(*\"github.com/d5/tengo/v2.ObjectPtr\")(0xc00000e9b0), ],}, freeVars: []*github.com/d5/tengo/v2.ObjectPtr len: 1, cap: 1, [ *(*\"github.com/d5/tengo/v2.ObjectPtr\")(0xc00000e9b0), ], ip: 0, basePointer: 5,} (dlv) p v.ip 33 go-prompt 性能问题调查 go-prompt时一个交互式cli框架, 但似乎性能有点问题. 一个简单的cli例子程序CPU就占了10%.基于go-prompt的abs也一样空跑都占比10%以上. 看火焰图似乎是timer的使用问题.原因在于 func (p *Prompt) Run() { for { select { default: //有default就是非阻塞, 这里sleep 10ms time.Sleep(10 * time.Millisecond) } } } 内存还给OS MADV_FREE和MADV_DONTNEED go1.12版本中, gc把不用的内存还给OS时, 调用了int madvise(void *addr, size_t length, int advice), 使用了MADV_FREE标记. man madvise说的很清楚, 虽然内存还给了OS, 但OS只有在系统内存不够时才回收. 导致go程序虽然认为自己已经还了内存给OS, 但其RSS一直居高不下. On Linux, the runtime now uses MADV_FREE to release unused memory. This is more efficient but may result in higher reported RSS. The kernel will reclaim the unused data when it is needed. To revert to the Go 1.11 behavior (MADV_DONTNEED), set the environment variable GODEBUG=madvdontneed=1. go1.11及之前, gc用MADV_DONTNEED来还内存给OS, RSS会马上下降. 理论说法是, MADV_FREE性能更好, 但会导致RSS的值不准确. 实际上, 随着gc算法的提高, OS的MADV_FREE lazy回收模式, 就没有太大意义了. go1.16版本又把MADV_DONTNEED的行为做为默认了. 注意: 如果用GODEBUG=madvdontneed=1还是不能让RSS下降, 需要搭配强制gc的方法, 否则一般情况下, gc要很长时间, 比如几分钟, 才工作. go1.13里面有个优化提到: 之前, gc会持有内存5分钟或更长时间才开始还给OS, 但1.13会更积极的还内存. The runtime is now more aggressive at returning memory to the operating system to make it available to co-tenant applications. Previously, the runtime could retain memory for five or more minutes following a spike in the heap size. It will now begin returning it promptly after the heap shrinks. However, on many OSes, including Linux, the OS itself reclaims memory lazily, so process RSS will not decrease until the system is under memory pressure. 参考: https://golang.org/pkg/runtime/ 搜索madvdontneed 下面就是最新的1.16版本的说法: madvdontneed: setting madvdontneed=0 will use MADV_FREE instead of MADV_DONTNEED on Linux when returning memory to the kernel. This is more efficient, but means RSS numbers will drop only when the OS is under memory pressure. https://golang.org/doc/go1.12#runtime https://vec.io/posts/golang-and-memory GOGC比例 GOGC默认是100, 即新分配的内存和上次gc完成时剩下的内存的比例是1:1时, gc才启动. 也就是说, 只有内存翻了一倍时, gc才开始收集垃圾. 想控制RSS占用的话, GOGC设置小一点. topid申请内存错误 背景 某次版本后, topid启动马上出错: 每次栈还不一样, 但最后都是runtime.mallocgc的栈 错误1 ~ # ./topid -tag ZAPPING_MCASTV4_v2 -p 1 -tree Hello 你好 Hola Hallo Bonjour Ciao Χαίρετε こんにちは 여보세요 Version: 0.1.4 runtime: s.allocCount= 3 s.nelems= 5 fatal error: s.allocCount != s.nelems && freeIndex == s.nelems goroutine 1 [running]: runtime.throw(0x1a8caa, 0x31) runtime/panic.go:774 +0x54 fp=0x40000a0ca0 sp=0x40000a0c70 pc=0x3bc84 runtime.(*mcache).nextFree(0x7f82a2a6d0, 0xa2f47, 0x4000000180, 0x200000003, 0x4000000180) runtime/malloc.go:852 +0x204 fp=0x40000a0cf0 sp=0x40000a0ca0 pc=0x1aa44 runtime.mallocgc(0x600, 0x15d600, 0x1, 0x0) runtime/malloc.go:1022 +0x688 fp=0x40000a0db0 sp=0x40000a0cf0 pc=0x1b0e8 runtime.makeslice(0x15d600, 0x600, 0x600, 0x0) runtime/slice.go:49 +0x74 fp=0x40000a0de0 sp=0x40000a0db0 pc=0x51364 bytes.makeSlice(0x600, 0x0, 0x0, 0x0) bytes/buffer.go:229 +0x64 fp=0x40000a0e50 sp=0x40000a0de0 pc=0x7af84 bytes.(*Buffer).grow(0x40000a0f80, 0x200, 0x200) bytes/buffer.go:142 +0x12c fp=0x40000a0ea0 sp=0x40000a0e50 pc=0x7aabc bytes.(*Buffer).ReadFrom(0x40000a0f80, 0x1d39e0, 0x4000081268, 0x3, 0x0, 0x0) bytes/buffer.go:202 +0x48 fp=0x40000a0f10 sp=0x40000a0ea0 pc=0x7ada8 io/ioutil.readAll(0x1d39e0, 0x4000081268, 0x200, 0x0, 0x0, 0x0, 0x0, 0x0) io/ioutil/ioutil.go:36 +0xb0 fp=0x40000a0fb0 sp=0x40000a0f10 pc=0x12bb80 io/ioutil.ReadAll(...) io/ioutil/ioutil.go:45 pidinfo.(*TidInfo).updateStat(0x40001830e0, 0x0, 0x0) pidinfo/pidinfo.go:486 +0x190 fp=0x40000a10f0 sp=0x40000a0fb0 pc=0x12d510 pidinfo.(*PidInfo).update(0x40001830e0, 0x40001472a0, 0x0) pidinfo/pidinfo.go:799 +0x2c fp=0x40000a1190 sp=0x40000a10f0 pc=0x13017c pidinfo.newPidInfo(0x28e, 0x40000bee10, 0x28e, 0x2f4f20, 0x0) pidinfo/pidinfo.go:631 +0x2f8 fp=0x40000a1280 sp=0x40000a1190 pc=0x12e478 错误2 ~ # Hello 你好 Hola Hallo Bonjour Ciao Χαίρετε こんにちは 여보세요 Version: 0.1.4 Visit below URL to get the chart: http://10.182.105.138:9888/ZAPPING_MCASTV4_v2/1992780262 runtime: s.allocCount= 3 s.nelems= 5 fatal error: s.allocCount != s.nelems && freeIndex == s.nelems goroutine 1 [running]: runtime.throw(0x1a8caa, 0x31) runtime/panic.go:774 +0x54 fp=0x40000a0b00 sp=0x40000a0ad0 pc=0x3bc84 runtime.(*mcache).nextFree(0x7f887a26d0, 0xa2f47, 0x4000000180, 0x200000003, 0x4000000180) runtime/malloc.go:852 +0x204 fp=0x40000a0b50 sp=0x40000a0b00 pc=0x1aa44 runtime.mallocgc(0x600, 0x15d600, 0x1, 0x0) runtime/malloc.go:1022 +0x688 fp=0x40000a0c10 sp=0x40000a0b50 pc=0x1b0e8 runtime.makeslice(0x15d600, 0x600, 0x600, 0x0) runtime/slice.go:49 +0x74 fp=0x40000a0c40 sp=0x40000a0c10 pc=0x51364 bytes.makeSlice(0x600, 0x0, 0x0, 0x0) bytes/buffer.go:229 +0x64 fp=0x40000a0cb0 sp=0x40000a0c40 pc=0x7af84 bytes.(*Buffer).grow(0x40000a0de0, 0x200, 0x200) bytes/buffer.go:142 +0x12c fp=0x40000a0d00 sp=0x40000a0cb0 pc=0x7aabc bytes.(*Buffer).ReadFrom(0x40000a0de0, 0x1d39e0, 0x40000851b8, 0xb7bc4, 0x40001354e0, 0x12) bytes/buffer.go:202 +0x48 fp=0x40000a0d70 sp=0x40000a0d00 pc=0x7ada8 io/ioutil.readAll(0x1d39e0, 0x40000851b8, 0x200, 0x0, 0x0, 0x0, 0x0, 0x0) io/ioutil/ioutil.go:36 +0xb0 fp=0x40000a0e10 sp=0x40000a0d70 pc=0x12bb80 io/ioutil.ReadFile(0x40001354e0, 0x12, 0x0, 0x0, 0x0, 0x0, 0x0) io/ioutil/ioutil.go:73 +0xc4 fp=0x40000a0eb0 sp=0x40000a0e10 pc=0x12bcf4 pidinfo.(*PidInfo).init(0x40001a84b0, 0xa, 0x1d6860) 错误3 ./topid -tag ZAPPING_MCASTV4_v2 -p 1 -chartserver 10.182.105.138:9887 -i 3 -c 3600 -record -sys -child & ~ # Hello \\xe4\\xbd\\xa0\\xe5\\xa5\\xbd Hola Hallo Bonjour Ciao \\xce\\xa7\\xce\\xb1\\xce\\xaf\\xcf\\x81\\xce\\xb5\\xcf\\x84\\xce\\xb5 \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf \\xec\\x97\\xac\\xeb\\xb3\\xb4\\xec\\x84\\xb8\\xec\\x9a\\x94 Version: 0.1.4 Visit below URL to get the chart: http://10.182.105.138:9888/ZAPPING_MCASTV4_v2/2938934727 runtime: s.allocCount= 492 s.nelems= 512 fatal error: s.allocCount != s.nelems && freeIndex == s.nelems goroutine 1 [running]: runtime.throw(0x1a8caa, 0x31) runtime/panic.go:774 +0x54 fp=0x4000040b50 sp=0x4000040b20 pc=0x3bc84 runtime.(*mcache).nextFree(0x7f9c7ab6d0, 0x51305, 0x4000040c08, 0x38e8c, 0x4000040c18) runtime/malloc.go:852 +0x204 fp=0x4000040ba0 sp=0x4000040b50 pc=0x1aa44 runtime.mallocgc(0x8, 0x15d400, 0x0, 0x0) runtime/malloc.go:998 +0x4f4 fp=0x4000040c60 sp=0x4000040ba0 pc=0x1af54 runtime.convT64(0x1, 0x7f9a53ef28) runtime/iface.go:352 +0x5c fp=0x4000040c90 sp=0x4000040c60 pc=0x18d0c internal/poll.errnoErr(...) internal/poll/errno_unix.go:32 internal/poll.(*pollDesc).init(0x4000219338, 0x4000219320, 0x1, 0x4000219320) internal/poll/fd_poll_runtime.go:45 +0x8c fp=0x4000040cd0 sp=0x4000040c90 pc=0xb312c internal/poll.(*FD).Init(0x4000219320, 0x19fa28, 0x4, 0x1, 0x40001fe800, 0x0) internal/poll/fd_unix.go:63 +0x68 fp=0x4000040d00 sp=0x4000040cd0 pc=0xb3888 os.newFile(0x5, 0x40001fe7e0, 0x12, 0x1, 0x4000000000) os/file_unix.go:151 +0xe8 fp=0x4000040d60 sp=0x4000040d00 pc=0xb6ed8 os.openFileNolog(0x40001fe7e0, 0x12, 0x0, 0x0, 0x8, 0x12, 0x40001fe7e0) os/file_unix.go:222 +0x19c fp=0x4000040dc0 sp=0x4000040d60 pc=0xb715c os.OpenFile(0x40001fe7e0, 0x12, 0x0, 0x0, 0x2, 0x40001fe7e0, 0x40001fe7ea) os/file.go:300 +0x54 fp=0x4000040e10 sp=0x4000040dc0 pc=0xb6964 os.Open(...) os/file.go:280 io/ioutil.ReadFile(0x40001fe7e0, 0x12, 0x0, 0x0, 0x0, 0x0, 0x0) io/ioutil/ioutil.go:53 +0x48 fp=0x4000040eb0 sp=0x4000040e10 pc=0x12bc78 pidinfo.(*PidInfo).init(0x400020d1d0, 0xa, 0x1d6860) pidinfo/pidinfo.go:587 +0x130 fp=0x4000040f50 sp=0x4000040eb0 pc=0x12dfe0 调查 释放内存后运行 重启后运行 -- nok 看起来是内存申请失败, 那么先系统内存的情况: ~ # free -m total used free shared buff/cache available Mem: 853 533 8 115 312 179 Swap: 0 0 0 强制释放内存试一下: echo 3 > /proc/sys/vm/drop_caches 再看一下内存: ~ # free -m total used free shared buff/cache available Mem: 853 537 103 115 212 175 Swap: 0 0 0 有103M了, topid通常是占用RSS 6M, 那么100M应该是够了. 但运行还是一样的runtime.mallocgc之后runtime.(*mcache).nextFree错误. 重启板子再运行, 也是出错. golang版本1.13换到1.16问题依旧 注意1.16默认使用go mod, 需要手动off掉 export GOPATH=`pwd` GOARCH=arm64 GO111MODULE=off go build topid.go 和版本相关? 288版本是好的, 289版本就不行了.. kernel改了什么? gshell server内存调试 问题场景 正常一个govm_test应该是11秒结束. 这里的问题主要是内存问题.有人可能问了, go不是自动gc的吗? 为什么内存还有问题?这个要仔细看下面的内容了. 操做1: 首次运行50个govm_test 起50个govm_testhtop显示内存46M显示 Inuse 62M # HeapAlloc = 59398296 # HeapSys = 133005312 # HeapIdle = 70754304 # HeapInuse = 62251008 # HeapReleased = 64618496 # HeapObjects = 31588 go tool pprof -http=0.0.0.0:8000 http://10.182.105.138:42459/debug/pprof/heap得到:大部分是shallowClone产生的 操做2: 50个govm_test同时restart 现象是同时restart后, 系统24核CPU占用100%持续大概1分钟, 每个govm_test的结束时间长至50秒左右.htop显示物理内存上升到129M, 多做几次restart会升到200多M. 200多M的时候, 有的时候就不会100%CPU了. perf record -g -p `pidof gshell` -- sleep 60 perf script | /repo/yingjieb/FlameGraph/stackcollapse-perf.pl | /repo/yingjieb/FlameGraph/flamegraph.pl > gshell.svg 火焰图显示绝大部分时间在runtime.newobject函数里.用go tool的objdump可以看到, runtime.newobject是从堆分配的关键函数, 由编译器插入. 第一次内存优化 源码的逻辑是新建个clone的VM来运行, 运行结束后其实就不用了.注意:第90行是新加的, 上面的实验数据是没有第90行的数据.这个函数在最后把gvm返回了, 被当作一个对象保存在上级VM的stack上. 操做1 加上第90行的效果 既然gvm会被引用到, 那gvm.VM也不会被gc. 但实际上, 这个子VM已经执行完毕, 可以安全的释放了.加了第90行来让gc可以回收这个VM. 同样运行50个govm_test, htop显示物理内存45M, 和之前一样.但pprof显示, Inuse小了不少, 整体的HeapSys也比之前小了一半. # HeapAlloc = 34263112 # HeapSys = 65961984 # HeapIdle = 29892608 # HeapInuse = 36069376 # HeapReleased = 18497536 # HeapObjects = 46161 有经过一小会, 稳定后Inuse更小了, 为11M左右. # HeapAlloc = 9485592 # HeapSys = 65994752 # HeapIdle = 54206464 # HeapInuse = 11788288 # HeapReleased = 52912128 # HeapObjects = 25051 pprof的top也显示, 没有了50M的shallowClone的占用. 效果非常明显! 操做2 加上第90行的效果 运行2次后, 还是会100%, 但感觉时间短了些. govmtest会在15秒左右结束.看火焰图还是在runtime.newobject![](img/golang调试记录_20220913224711.png) pprof显示HeapInuse为14M.也不是多很多, 但HeapIdle为117M, 说明有大量的内存申请过但已经使用完毕. # HeapAlloc = 10403200 # HeapSys = 131563520 # HeapIdle = 117334016 # HeapInuse = 14229504 # HeapReleased = 116457472 # HeapObjects = 37464 第三次以后再全部restart, 占用就很低了, 最多只占单核的10%左右, 一般2%. 内存稳定再110M左右.我很好奇现在的火焰图, 于是抓了一个:runtime.newobject变得非常小了 govm_test的\"应用逻辑\"其实占比非常小, 占的多的主要是: park_m stop_m等熟悉的goroutine和M的结合动作. time.Sleep futext相关. 进一步优化思路 需要在VM运行结束后, 重置stack和frame的空间.去掉object的引用, 触发gc的回收. 固定size的array stack [StackSize]Object frames [MaxFrames]frame 变为slice, 按需append stack []Object frames []frame 把静态的内存分配改成动态append方式, 给个比较小的初始值, 动态扩展. 在VM运行完毕后, 通过把frame和stack置为nil的方式, 告诉gc释放内存. 具体修改见这个commit 结果是全部restart场景下, 完全没有24核100%占用的情况;htop观察到物理内存稳定峰值从之前的200M降低到20M.实际上, idle后使用的内存大约为10M.但并发的峰值减小更能说明, 在重启50个VM时候, 由于govm_test内部会起大概10个VM, 一共500个 VM, 并没有同时申请大量内存. goroutine泄漏调试 topid程序改成goroutine版本之后, 出了很多很典型的并发问题. 其中有channel和goroutine的生命周期没配合好, 导致的卡死问题. 即channel发送或者读取的\"对端\"goroutine异常条件退出了, 但没有处理好channel的善后, 导致对方卡住在channel操作. 但goroutine还是在泄漏. 问题的根源在于, 靠树形结构的上一级节点来触发下一级动作的时候, 程序的思路是:假设进程A的子进程有[B1 B2 B3], 在下一次触发的时候, A的子进程变成了[B2 B3 B4]其内在逻辑是, kernel报告B1进程退出了, 但是这里的逻辑是只新建B4的pidinfo结构.那么B1的守护进程处于什么状态呢?答案是B1会永远等待触发channel, 但永远没有人会写这个channel. 因为B1已经从A的子树里拿掉了.这样就造成了goroutine的泄漏.解决办法是在B1的守护进程里, 同时监听(select) cleanup channel, A除了要处理新建的B4, 还要负责触发B1的cleanup 另外一个场景是 A -> B -> C的进程链, 如果B和C同时(一秒内)都消亡了, 那么按照A触发B, B再触发C的cleanup逻辑, C永远不能被触发, 因为树从顶向下, 先触发B的cleanup, 而C就没有机会被B cleanup.解决办法是再A触发B的cleanup时, 递归的触发B的所有子树的cleanup. vscode debug模式 参考文档: https://github.com/golang/vscode-go/blob/master/docs/debugging.md#remote-debugging 修改lauch.json { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Launch\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"auto\", \"program\": \"/repo/yingjieb/godev/practice/src/tools/topid.go\", \"env\": {\"GOPATH\":\"/go:/repo/yingjieb/godev/practice\"}, \"args\": [\"-p\", \"1\", \"-tree\"] } ] } 注意env和args的用法 另外一个更通用的配置: 下面这个默认的配置直接就能用. { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Launch\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"auto\", \"program\": \"${fileDirname}\", \"env\": {}, \"args\": [] } ] } 还是这个链接有详细的说明: https://github.com/golang/vscode-go/blob/master/docs/debugging.md#using-vs-code-variables 为何dlv总是提示Could not load source 即使直接启动dlv也有这个问题: dlv exec examples/interoperability/interoperability (dlv) b main.main Breakpoint 1 set at 0x5014eb for main.main() github.com/d5/tengo/v2@/examples/interoperability/main.go:185 (dlv) c //能断点, 能bt (dlv) bt 0 0x00000000005014eb in main.main at github.com/d5/tengo/v2@/examples/interoperability/main.go:185 1 0x000000000042cbf6 in runtime.main at runtime/proc.go:203 2 0x0000000000456c31 in runtime.goexit at runtime/asm_amd64.s:1357 //但不能看代码, why???? (dlv) l > main.main() github.com/d5/tengo/v2@/examples/interoperability/main.go:185 (hits goroutine(1):1 total:1) (PC: 0x5014eb) Warning: debugging optimized function Command failed: open github.com/d5/tengo/v2@/examples/interoperability/main.go: no such file or directory 因为我hack了go命令, 添加了-trimpath, 这个选项把文件名搞成了相对路径了(短路径). 而dlv依赖绝对路径来debug... 去掉-trimpath就好了. 正常的dlv使用 dlv exec ./interoperability (dlv) b main.main Breakpoint 1 set at 0x5014eb for main.main() ./main.go:185 (dlv) c > main.main() ./main.go:185 (hits goroutine(1):1 total:1) (PC: 0x5014eb) Warning: debugging optimized function //能直接显示代码 一次空指针访问的panic yingjieb@3a9f377eee5d /repo/yingjieb/godev/practice/src/pidinfo $ go test -run xxxxxx -bench BenchmarkP1InfoUpdate -cpuprofile cpuiter.out goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-23 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x50 pc=0x5046c9] goroutine 54 [running]: pidinfo.(*PidInfo).updateTime(0x0, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:227 +0x59 pidinfo.(*PidInfo).Update(0x0, 0xc0000905d0, 0x6f7e) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:302 +0x32 pidinfo.(*PidInfo).updateChildren(0xc0001e03c0, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:206 +0x35e pidinfo.(*PidInfo).Update(0xc0001e03c0, 0xc000090570, 0x4507) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:307 +0x70 pidinfo.(*PidInfo).updateChildren(0xc0001e0320, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:206 +0x35e pidinfo.(*PidInfo).Update(0xc0001e0320, 0xc000090450, 0x11) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:307 +0x70 pidinfo.(*PidInfo).updateChildren(0xc0001e00a0, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:206 +0x35e pidinfo.(*PidInfo).Update(0xc0001e00a0, 0xc000090270, 0xc000451d68) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:307 +0x70 pidinfo.(*PidInfo).updateChildren(0xc0001e0000, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:216 +0x2c1 pidinfo.(*PidInfo).Update(0xc0001e0000, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:307 +0x70 pidinfo.BenchmarkP1InfoUpdate(0xc0001f41c0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo_test.go:77 +0x16f testing.(*B).runN(0xc0001f41c0, 0x5b8) /usr/local/go/src/testing/benchmark.go:190 +0xcc testing.(*B).launch(0xc0001f41c0) /usr/local/go/src/testing/benchmark.go:320 +0x10c created by testing.(*B).doBench /usr/local/go/src/testing/benchmark.go:275 +0x55 exit status 2 FAIL pidinfo 0.592s error应该是占两个\"位置\" 能打出调用栈来的, 那返回值的位置没有意义, 因为底层函数还没有返回. 调用栈解析和参数解读 经常看到, 调用栈打印的参数比函数定义时的参数个数要多, 为什么呢?原文: https://www.ardanlabs.com/blog/2015/01/stack-traces-in-go.html 这要理解不同类型参数的传递规则: 切片, 字符串, 和int // Declaration main.Example(slice []string, str string, i int) // Call to Example by main. slice := make([]string, 2, 4) Example(slice, \"hello\", 10) // Stack trace main.Example(0x2080c3f50, 0x2, 0x4, 0x425c0, 0x5, 0xa) //解释切片: // Slice header values Pointer: 0x2080c3f50 Length: 0x2 Capacity: 0x4 //解释字符串 // String parameter value \"hello\" // String header values Pointer: 0x425c0 Length: 0x5 我实验的版本 package main import \"fmt\" func main() { slice := make([]string, 2, 4) m := map[string]int{\"1st\": 1, \"2nd\": 100} Example(slice, \"hello\", 0x88, m) } func Example(slice []string, str string, i int, m map[string]int) { fmt.Println(slice, str, i, m) //没有这行fmt, 似乎结果里的参数只显示..., 应该是编译器自动优化过了 panic(\"Want stack trace\") } //结果: $ ./tmp [ ] hello 136 map[1st:1 2nd:100] panic: Want stack trace goroutine 1 [running]: main.Example(0xc0000c8040, 0x2, 0x4, 0x4c24f9, 0x5, 0x88, 0xc0000cc000) /repo/yingjieb/godev/practice/src/misc/tmp.go:13 +0x16c main.main() /repo/yingjieb/godev/practice/src/misc/tmp.go:8 +0x114 注意0x88后面那个map, 只占一个位置, 所以map是个指针. 切片是个三个值的结构, 指针, len和cap 字符串是2个值的结构, 指针, len 整型参数就是一个值 map参数是一个位置 变长参数 比如 func panicFmt(v ...interface{}) { ... 主动panic } #在main里调用 panicFmt(1,2,3) 或 panicFmt(1, 2, 3, 4, \"hello\") #结果 goroutine 1 [running]: main.panicFmt(0xc0000a2150, 0x3, 0x3) 结论: 不管有多少个入参, 都是先组成一个slice, 再传给panicFmt函数. slice的表达是3个值. interface interface是2个值, 准确的说是两个指针 type eface struct { // 16 bytes _type *_type data unsafe.Pointer } type iface struct { // 16 bytes tab *itab data unsafe.Pointer } 方法 对象的方法调用, call trace的第一个参数是那个对象 参数packing 如果参数拼在一起能够放在一个word里, 那么go会自动的把这几个参数pack在一个word里, 放在栈上传递下面的例子中, 3个bool变量和一个uint8被拼在一个32位的\"参数\"里 bool类型也是8bit 01 package main 02 03 func main() { 04 Example(true, false, true, 25) 05 } 06 07 func Example(b1, b2, b3 bool, i uint8) { 08 panic(\"Want stack trace\") 09 } //结果: 01 goroutine 1 [running]: 02 main.Example(0x19010001) /Users/bill/Spaces/Go/Projects/src/github.com/goinaction/code/ temp/main.go:8 +0x64 03 main.main() /Users/bill/Spaces/Go/Projects/src/github.com/goinaction/code/ temp/main.go:4 +0x32 解释: 感觉是先拼第一个原始参数, 移位, 再拼第二个原始参数... // Parameter values true, false, true, 25 // Word value Bits Binary Hex Value 00-07 0000 0001 01 true 08-15 0000 0000 00 false 16-23 0000 0001 01 true 24-31 0001 1001 19 25 // Declaration main.Example(b1, b2, b3 bool, i uint8) // Stack trace main.Example(0x19010001) 返回值 返回值在对象, 入参之后. 这个例子来说, 最后的两个值就是返回值. 如果是返回int和string, 那string是两个值(指针和长度) func f(a, b int) (sum int, tag int) { c := a + b fmt.Println(c) if c > 64 { panic(\"aaaaa\") } fmt.Printf(\"%p\\n\", &c) return c, c+10 } func main() { f(2, 5) f(64, 8) } //输出: 7 0xc000020028 72 panic: aaaaa goroutine 1 [running]: //返回值好像也是在栈里的, 第三个值和第四个值其实是上次的返回值. //本次还没有返回值就panic了, 返回值是栈里的值. 正好是上次留下来的返回值 main.f(0x40, 0x8, 0x7, 0x11) /repo/yingjieb/godev/practice/src/benchmarks/hashmap/pidinfomap.go:9 +0x167 main.main() /repo/yingjieb/godev/practice/src/benchmarks/hashmap/pidinfomap.go:18 +0x49 exit status 2 结构体 结构体(非结构体指针)不管是入参还是返回值, 都直接展开在栈上传递 比如 type eee struct { a,b,c,d,e int s string } func f(a, b int, e eee) { c := a + b fmt.Println(c) if c > 64 { panic(\"aaaaa\") } fmt.Printf(\"%p\\n\", &c) //return eee{1, 2, 3, 4, 5, \"sssssss\"} } f(64, 8, eee{1, 2, 3, 4, 5, \"sssssss\"}) //panic的时候 goroutine 1 [running]: main.f(0x40, 0x8, 0x1, 0x2, 0x3, 0x4, 0x5, 0x4c3839, 0x7) 指针 callstack里面, 指针只占一个位置. slice的make和append性能 还是在pidinfo代码里面 被测函数根据map, 创建个切片返回 // Children returns first level children nodes func (pi *PidInfo) Children() []*PidInfo { //后面的几个测试都只改这里, 主要是改children切片的初始化方法 //不同的方式差别非常大 var children []*PidInfo //children := make([]*PidInfo, 100) for _, child := range pi.children { children = append(children, child) } return children } 其测试代码如下: func BenchmarkMapInter(b *testing.B) { pi, err := NewPidInfo(1, true) if err != nil { b.Errorf(\"main: %v\\n\", err) return } if err := pi.Update(); err != nil { b.Errorf(\"main: %v\\n\", err) return } b.ResetTimer() for i := 0; i 本意是想测试map表的遍历效率, 没想到切片的make和append效率才是瓶颈. 应该和切片的类型是结构体指针有关. 只声明切片 -- 400 ns/op 迭代map占比25%, 切片操作占比56%. 为什么切片比map还费事呢?看起来对切片的操作append是runtime.growslice, 而它会调用mallocgc申请内存.为什么要创建gc呢? 所有类型的切片都要创建GC吗? 这个创建gc的动作和切片的size有关吗? // growslice handles slice growth during append. // It is passed the slice element type, the old slice, and the desired new minimum capacity, // and it returns a new slice with at least that capacity, with the old data // copied into it. // The new slice's length is set to the old slice's length, // NOT to the new requested capacity. // This is for codegen convenience. The old slice's length is used immediately // to calculate where to write new values during an append. // TODO: When the old backend is gone, reconsider this decision. // The SSA backend might prefer the new length or to return only ptr/cap and save stack space. func growslice(et *_type, old slice, cap int) slice { //根据et的类型确定扩大比例 //et.ptrdata的解释是 size of memory prefix holding all pointers if et.ptrdata == 0 p = mallocgc(capmem, nil, false) else p = mallocgc(capmem, et, true) memmove(p, old.array, lenmem) return slice{p, old.len, newcap} } // Allocate an object of size bytes. // Small objects are allocated from the per-P cache's free lists. // Large objects (> 32 kB) are allocated straight from the heap. func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { //type是nil或者不包括指针, 就不用scan了 noscan := typ == nil || typ.ptrdata == 0 //要分配的内存大小 dataSize := size c := gomcache() //小于32K在M的cache里面分 //大于32K从堆里分 //如果要scan // It is known that the type has pointers somewhere; //能调到这里, 说明元素类型里面某些地方有指针 //这个函数非常非常复杂!!!!! // heapBitsSetType records that the new allocation [x, x+size) // holds in [x, x+dataSize) one or more values of type typ. // (The number of values is given by dataSize / typ.size.) //size是元素的size, datasize是刚申请的字节数 heapBitsSetType(uintptr(x), size, dataSize, typ) ...省略 } append实际在运行时是growslice, 这个函数负责切片扩容 传入切片元素类型, 原切片, 返回最小cap大小的新切片, 并拷贝老切片 切片的length决定下一个元素写在哪 mallocgc的意思是要申请内存了, go是有垃圾回收的, 那任意的内存申请都是要gc知道的 小的对象被malloc到per CPU的空闲内存中 大的对象(32KB以上)则从堆中分配 malloc之后, 如果元素类型里面有指针, 要scan, 调用的heapBitsSetType函数非常复杂 make 1 -- 444 ns/op 比上一个多了makeslice函数调用, makeslice主要也是调用mallocgc() func (pi *PidInfo) Children() []*PidInfo { //var children []*PidInfo children := make([]*PidInfo, 1) for _, child := range pi.children { children = append(children, child) } return children } 对于上面的被测函数的逻辑看, make 1次, 要append好几次. make 10 -- 604 ns/op 比make 1稍稍多了一点 make 100 -- 2527 ns/op 平均一次的执行时间多了好几倍! 为什么呢? 下面是make 100 case的图: 注意, 这个图默认不显示runtime.makeslice, 很奇怪, 这部分占比挺大的. 可以点下图选中函数的REFINE, 就能看全了. 起始pprof把makeslice省略也是说得通的, 因为它本身的执行时间是0, 而且和growslice都调用mallocgc, 从采样和执行时间分析的角度, 这两个通路是重叠的, 图上默认显示一个通路就好了 仔细对比发现, runtime.growslice和runtime.mallocgc比make 1的时候, 从时间上看, 有所浮动, 但应该是下降了点. runtime.mallocgc在make 1的时候花了0.92s runtime.mallocgc在make 1的时候花了0.66s ~ 0.82s 但gc的占比飙升了.对比两个火焰图, make 100的时候, 可以看到, runtime.gcBgMarkWorker占比明显提高. make 100时, runtime.gcBgMarkWorker占比20% make 1时, runtime.gcBgMarkWorker占比才0.53% 改一下代码: func (pi *PidInfo) Children() []*PidInfo { //var children []*PidInfo children := make([]*PidInfo, 100) i := 0 for _, child := range pi.children { //children = append(children, child) children[i] = child i++ } return children } 把append改成直接赋值, 快了很多! 2062 ns/op -> 461 ns/op 但要预先make好一个足够大的切片, 否则会运行时错误, 说超出切片的index范围 这样说, make 100的时候, 预留了足够的大小, 从执行效率上看, make([]*PidInfo, 100)和make([]*PidInfo, 1) 本身并没有差多少, 可能make 100确实稍稍快了一点, 理论上减少了切片\"扩容\"的次数; 但其代价是增大GC的压力. 从结果上看得不偿失. 更正 实际上, 对make([]*PidInfo, 100)和make([]*PidInfo, 1)的append操作是不一样的: append的元素是在len后面的, 对len=100来说, append的扩容会比初始len=1的情况, 拷贝很多元素.所以上面的例子的对比思路是有问题的.下面的例子说明, append是在10个0之后 func main() { sl := make([]int, 10) sl = append(sl, 1) sl = append(sl, 2) fmt.Println(sl) } 输出 [0 0 0 0 0 0 0 0 0 0 1 2] 更正后最终版 使用make([]T, 0, max)和append的搭配 // Threads returns threads of the process func (pi *PidInfo) Threads() []*TidInfo { if pi.checkLevel&CheckThread != CheckThread { return nil } if pi.pid == -1 { return nil } //threads := make([]*TidInfo, pi.threads.Len()) //申请已知的len, 结合下面的直接赋值, 理论性能最佳 threads := make([]*TidInfo, 0, pi.threads.Len()) //申请已知cap, 从0开始append, 和上面性能差不多 //var threads []*TidInfo //从0开始生长, 每次翻倍扩容都有开销, 性能最差. for i, tid := range pi.threads.Keys() { thrdi, _ := pi.threads.Get(tid) //threads[i] = thrdi.(*TidInfo) threads = append(threads, thrdi.(*TidInfo)) //如果没有发生slice扩容, append的性能很好, 几乎和直接赋值差不多. } return threads } 最终版结果 slice初始化方式 性能 threads := make([]*TidInfo, pi.threads.Len()) + threads[i] = thrdi.(*TidInfo) 726 ns/op threads := make([]*TidInfo, 0, pi.threads.Len()) + append 729 ns/op var threads []*TidInfo + append 1114 ns/op 结论 make([]T, length, capacity)的原型中 make切片对应的时runtime.makeslice() append切片对应runtime.growslice() 如果slice的元素里面包括指针, 则slice里面的元素越多, gc压力越大 如果已知length大小, 推荐make直接填入length, 在后面用for循环给切片元素赋值, 不用append. 这样理论上性能最好; 但要注意, 超过切片的len的赋值会panic. 而append则不会. 切片的append操作如果不发生扩容, 和直接赋值性能差不多; 但如果有扩容, 则性能就差太多了. 应该说任何内存申请, 都会伴随gc相关的工作. 除非申请的内存明确知道没有指针. 切片并不廉价, 初始化切片大小时, 要考虑对GC的影响 推荐length为0, 但设置足够的capacity方式初始化切片: make([]*PidInfo, 0, 100); 后面用append\"追加\"元素. 这样即兼顾了性能, 又不会出现index越界的panic pidinfo调试 主要用testing框架来调试. 我是先写的testing, 再写package代码, 同步修改, 相辅相成.test case里加了benchmarking的case, 主要想测Update()的效率. 因为Update()里面有递归的创建子进程的pidinfo和更新执行时间等操作, 最复杂. func BenchmarkP1InfoUpdate(b *testing.B) { pi, err := NewPidInfo(1, true) if err != nil { b.Errorf(\"main: %v\\n\", err) return } b.ResetTimer() for i := 0; i 执行测试 in docker 可以直接在开发目录下执行 yingjieb@3a9f377eee5d /repo/yingjieb/godev/practice/src/pidinfo $ go test -run xxxxxx -bench . -benchtime 10s goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-23 86350 168270 ns/op PASS ok pidinfo 15.962s 我不想run普通的test项, 所以用随意的xxxx来匹配test项, 匹配不到, 所以不run 用-bench .执行所有的benchmark项 用-benchtime指定稳定时间, testing框架默认1s docker里面的pid1进程树, 大概0.2ms运行一轮 out docker 先docker里面编译 yingjieb@3a9f377eee5d /repo/yingjieb/godev/practice/src/pidinfo $ go test -c -o pidinfotest 然后在host上运行 用testing框架编译出来的测试程序, 都带了testing框架的选项, 选项比普通的go test命令要多test.前缀, 其他都一样 $ ./pidinfotest -h Usage of ./pidinfotest: -test.bench regexp run only benchmarks matching regexp -test.benchmem print memory allocations for benchmarks -test.benchtime d run each benchmark for duration d (default 1s) -test.blockprofile file write a goroutine blocking profile to file -test.blockprofilerate rate set blocking profile rate (see runtime.SetBlockProfileRate) (default 1) -test.count n run tests and benchmarks n times (default 1) #最后这样运行 ./pidinfotest -test.run xxxxxx -test.bench . -test.benchtime 10s 结果: 大概1ms $ ./pidinfotest -test.run xxxxxx -test.bench . -test.benchtime 30s goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-24 37700 1066736 ns/op PASS 能看到htop显示这个程序占比109%左右. 说明这个程序的主体的活只能单核干, 加上调度开销, 就是110%左右. 打开cpu分析 go test -run xxxxxx -bench . -benchtime 10s -cpuprofile cpu.out go tool pprof -http=0.0.0.0:8000 cpu.out 大部分都是在系统调用耗时 没看到有runtime hash等函数的身影? -- 多试几次能看到 用perf top -p $(pidof pidinfotest)能看到 runtime.mapiternext这个map迭代器的占比: 0.58% pidinfotest [.] runtime.mapiternext host上profile CPU yingjieb@godev-server /repo/yingjieb/godev/practice/src/pidinfo $ ./pidinfotest -test.run xxxxxx -test.bench . -test.benchtime 30s -test.cpuprofile cpuhost.o ut goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-24 33567 1115273 ns/op PASS 从pprof看来, 系统调用占比较大. pprof的refine功能 默认的调用图是调整过的, 比如有些占比小的函数用虚线代替, 有的就干脆不显示了. 但我想看看map的迭代器在运行时的情况, 那就要用refine功能: 先选中要看的函数, 如上图, 我选中了runtime.mapiternext 点REFINE->focus pprof会根据采样记录的调用栈关系, 以选中的函数为主体, 重新显示调用; 之前不显示的相关调用会显示出来 沿途的CPU占比都做过了调整, 都是根据选中的函数来调整的. tooManyTimer调试 命令记录 go tool pprof -http=0.0.0.0:8000 http://10.182.105.138:9999/debug/pprof/profile wget http://10.182.105.138:9999/debug/pprof/trace?seconds=10 -O testtrace go tool trace -http=0.0.0.0:8000 testtrace 最后访问http://10.182.105.138:60080/ui/ go tool pprof的http方式 用go tool pprof -http=0.0.0.0:8000 /home/yingjieb/pprof/pprof.tooManyTimer.samples.cpu.003.pb.gz可以在docker实例内启动一个http,port是8000; 把8000映射到外部的一个端口号, 比如60080, 就可以从外部访问这个http服务了.注意, 必须要指明0.0.0.0:port, 否则只能在docker实例内部访问. 访问http://10.182.105.138:60080/ui/有火焰图, 这个是go1.14版本 内存 go tool pprof -http=0.0.0.0:8000 http://10.182.105.138:9999/debug/pprof/heap内存有几个视角: 已经分配的对象个数和内存占用, 这个好像是累加的 正在使用的对象个数和内存占用 goroutine的情况 go tool pprof -http=0.0.0.0:8000 http://10.182.105.138:9999/debug/pprof/goroutine可以看到谁在哪里创建了多少个goroutine, 这是抓的当时时刻的情况. 同步 锁 阻塞应该也支持, 待调查 待调查 trace go test框架已经把trace功能集成进去了.引入import _ \"net/http/pprof\"也是很方便的触发trace的手段.下面是用pprof包触发并分析trace的记录: #先触发并下载30秒的trace wget http://10.182.105.138:9999/debug/pprof/trace?seconds=10 -O testtrace #用trace tool来分析, 不加http就默认使用随机端口起http go tool trace -http=0.0.0.0:8000 testtrace 用chrome打开链接指定链接. 需要注意的是, go tool trace使用了chrome已经不支持的技术, 导致80版本后的chrome不能显示trace. 详见: https://github.com/golang/go/issues/34374 经过我的验证, 下载个79版本的旧chrome可以显示trace页面.可以在docker里面打开这个工具, 在docker外面访问:http://10.182.105.138:60080/ 使用wsad等快捷键来浏览. 代码打开trace 上面介绍的是pprof提供的网页式打开trace的方法, 好处是比较方便, 但要引入http等上层协议. 在代码里可以直接打开trace. 引入“runtime/trace”包，调用方法trace.Start()/trace.Stop() 不同的profile文件对比 #对比1和2的差异 go tool pprof -http=:8080 --base dumps/heap-profile-cmp-001.pb.gz dumps/heap-profile-cmp-002.pb.gz 传统火焰图方式 perf record -g -p `pidof tooManyTimer` -- sleep 60 perf script | /repo/yingjieb/FlameGraph/stackcollapse-perf.pl | /repo/yingjieb/FlameGraph/flamegraph.pl > tooManyTimer60s.svg perf top -p `pidof tooManyTimer` x86下面-g --call-graph dwarf选项效果不好, 调用栈不全 代码里加调试支持 go doc pprof可以查到两种debug方式, 原理都差不多, 区别是使用方式不同. 这两种方式都能生成profile文件, 用于go tool pprof进一步检查 命令行调试: \"runtime/pprof\" go test框架自带pprof支持, 用下面的命令可以得到cpu和mem的profile. go test -cpuprofile cpu.prof -memprofile mem.prof -bench . 自己的程序要得到这个效果, 需要runtime/pprof 加类似下面的代码: var cpuprofile = flag.String(\"cpuprofile\", \"\", \"write cpu profile to `file`\") var memprofile = flag.String(\"memprofile\", \"\", \"write memory profile to `file`\") func main() { flag.Parse() if *cpuprofile != \"\" { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(\"could not create CPU profile: \", err) } defer f.Close() if err := pprof.StartCPUProfile(f); err != nil { log.Fatal(\"could not start CPU profile: \", err) } defer pprof.StopCPUProfile() } // ... rest of the program ... if *memprofile != \"\" { f, err := os.Create(*memprofile) if err != nil { log.Fatal(\"could not create memory profile: \", err) } defer f.Close() runtime.GC() // get up-to-date statistics if err := pprof.WriteHeapProfile(f); err != nil { log.Fatal(\"could not write memory profile: \", err) } } } 网页调试: \"net/http/pprof\" import ( \"net/http\" _ \"net/http/pprof\" ) func main() { go func() { fmt.Println(http.ListenAndServe(\":9999\", nil)) }() ... } 这里的port随便填 \"net/http/pprof\"会注册一个default的httpHandler, 访问http://ip:port/debug/pprof/会使用此默认的handler 使用debug网页 Web网页http://ip:port/debug/pprof/能提供很多有用的信息: /debug/pprof/profile：访问这个链接会自动进行 CPU profiling，持续 30s，并生成一个文件供下载; 用go tool pprof 这个文件可以进行后续分析 /debug/pprof/block：Goroutine阻塞事件的记录，默认每发生一次阻塞事件时取样一次。 /debug/pprof/goroutines：活跃Goroutine的信息的记录，仅在获取时取样一次。 /debug/pprof/heap： 堆内存分配情况的记录，默认每分配512K字节时取样一次。 /debug/pprof/mutex: 查看争用互斥锁的持有者。 /debug/pprof/threadcreate: 系统线程创建情况的记录，仅在获取时取样一次。 /debug/pprof/trace: 和profile使用方式类似, 产生当前程序的执行trace文件. 用go tool trace可以分析这个trace 这个网页的基本逻辑是点一次, 产生一次数据. 结合go tool pprof可以做更多的事 使用go tool pprof go tool pprof的基本命令格式是:pprof [options] [binary] ...如果没有指定output format, 则进入交互模式.source是网页产生的profile文件. 一般就直接写URL地址go tool pprof http://10.182.105.138:9999/debug/pprof/profile默认的取样时间是30s ，可以通过-seconds 命令来指定取样时间 ，取样完成后会进入命令行状态 $ go tool pprof http://10.182.105.138:9999/debug/pprof/profile Fetching profile over HTTP from http://10.182.105.138:9999/debug/pprof/profile Saved profile in /home/yingjieb/pprof/pprof.tooManyTimer.samples.cpu.002.pb.gz File: tooManyTimer Type: cpu Time: Apr 8, 2020 at 10:56am (UTC) Duration: 30s, Total samples = 1.35s ( 4.50%) Entering interactive mode (type \"help\" for commands, \"o\" for options) 上面例子中, 会写明profile文件放在用户目录下的~/pprof路径下. 默认采样30s, 一共采到了1.35s, 占比4.5% top命令 (pprof) top 20 Showing nodes accounting for 1.19s, 88.15% of 1.35s total Showing top 20 nodes out of 70 flat flat% sum% cum cum% 0.65s 48.15% 48.15% 0.65s 48.15% runtime.futex 0.09s 6.67% 54.81% 0.25s 18.52% runtime.notetsleep_internal 0.07s 5.19% 60.00% 0.07s 5.19% runtime.siftdownTimer 0.07s 5.19% 65.19% 0.07s 5.19% runtime.usleep 0.03s 2.22% 67.41% 0.08s 5.93% runtime.selectgo 0.03s 2.22% 69.63% 0.19s 14.07% runtime.startm 0.02s 1.48% 71.11% 0.02s 1.48% runtime.(*gList).pop 0.02s 1.48% 72.59% 0.19s 14.07% runtime.findrunnable 0.02s 1.48% 74.07% 0.02s 1.48% runtime.gopark 0.02s 1.48% 75.56% 0.23s 17.04% runtime.mcall 0.02s 1.48% 77.04% 0.02s 1.48% runtime.osyield 0.02s 1.48% 78.52% 0.02s 1.48% runtime.retake 0.02s 1.48% 80.00% 0.21s 15.56% runtime.schedule 0.02s 1.48% 81.48% 0.02s 1.48% runtime.sellock 0.02s 1.48% 82.96% 0.17s 12.59% runtime.stopm 0.02s 1.48% 84.44% 0.24s 17.78% runtime.sysmon 0.02s 1.48% 85.93% 0.67s 49.63% runtime.timerproc 0.01s 0.74% 86.67% 0.11s 8.15% main.handleOnu 0.01s 0.74% 87.41% 0.01s 0.74% runtime.(*gList).empty 0.01s 0.74% 88.15% 0.01s 0.74% runtime.(*mcache).prepareForSweep profile文件的基本原理还是采样, 在上面例子中: flat是本函数执行的时间, 不包括其他已经被采样的函数 cum包括本函数及从其调用出去的所有时间, 包括所有子函数, 当然包括其他已经被采样的函数 默认按照%flat排序, 这很好理解, flat基本表示了这个函数本身的执行时间. 如果它的子函数也被采样到了, 是不计入本函数的时间的. flat和cum重要, 分别反应了本函数的效率和所有子函数的效率 sum%只是排序累加, 没啥大意思. list命令 list命令和gdb的list看源码用户体验很像, 但能显示采样信息 (flat, cum)的意思是: 第一列时间是采样发生在本函数的; 第二列是采样发生在子函数里的. (pprof) list runtime.timerproc Total: 1.35s ROUTINE ======================== runtime.timerproc in /usr/local/go/src/runtime/time.go 20ms 670ms (flat, cum) 49.63% of Total . . 260: delta = t.when - now . . 261: if delta > 0 { . . 262: break . . 263: } . . 264: ok := true 10ms 10ms 265: if t.period > 0 { . . 266: // leave in heap but adjust next time to fire 10ms 10ms 267: t.when += t.period * (1 + -delta/t.period) . 70ms 268: if !siftdownTimer(tb.t, 0) { . . 269: ok = false . . 270: } svg命令和perf火焰图对比 svg命令可以生成采样分布图和调用关系图 perf的火焰图 pprof和perf对比几点说明: svg显示的采样占比和top一致. 比如也是分自身时间和累积时间 perf版本的火焰图调用栈解析细节不完整, 比如最左边runtime.notetsleep_internal是从timeproc调用下来的. perf有内核态的路径, pprof没有 perf和pprof的图要结合看, 互补. 对照代码片段分析: handleOnu, 主要是select pprof svg select会被编译器转化为运行时的(*waitq)enqueue和gopark把当前goroutine调度出去 select有一把锁(sellock), 锁住所有case? handleOnu代码占比8.15%, 大部分是在搞goroutine的切换准备.perf 火焰图 perf对go是无感知的, 它的调用栈解析相对不是那么精确, 但感觉大致是对的. runtime.mcall是func mcall(fn func(*g)), 作用是从当前g切换到g0栈, 并执行fn; mcall是CPU ARCH相关的汇编入口. pprof的svg图里面, mcall不是在selectgo()函数里调用的, 而是一个独立的runtime._System入口.这个入口似乎是调度器的入口, 被单独提出来了. 但实际上, mcall(parkm)就是在selectgo里面调用的. park_m会调用schedule()触发调度.![](img/golang调试记录_20220914083305.png)结合上面perf火焰图, 调度器最终会调用futex系统调用来触发kernel级别的调度.我估计这里的逻辑是: 当没有活真正要干时, 调用park_m进而层层调用futex来让M进入休眠状态. 从这点上看, perf火焰图把它放在selectgo里面是合理的. 实际上, 这里的采样点这么多, 是因为timer多, 每个timer每秒都要调这么一圈. 对照代码片段分析: timerproc timerproc是goroutine, 所以在这里是个入口. pprof报告这部分占49.63%. perf报告这部分占27%. 但结合来看, 应该把perf的runtime.notetsleep_internal部分的23%也算在一起, 合起来也是差不多50% time.sendTime做为回调函数, 在timerproc里被调用. 它是个简单的非阻塞的channel写 select { //有default是非阻塞发送 case c.(chan Time) 对应go代码runtime.ChanSend -> 从channel的等待队列取goroutine:runtime.(*waitq).dequeue 唤醒等待的goroutine:goready -> 放到runq:runqput这部分没有系统调用, 完全是用户态.并且占比不高, 只有3%. shiftdownTimer函数负责对timer堆排序. 在2000个timer的情况下, 占5%. 也不是很多 大头在notetsleep, 这是timerproc循环中处理完本次timer堆后调用的, 阻塞等待下次timer超时.再往下分, entersyscallblock占14%, exitsyscall占14%. 这个函数都要调用runtime.systemstack, 在进入系统调用阻塞前, 先handoffp和P解绑定, 然后M就休眠了; 但解绑后的P不能闲着, 会再次绑定一个M; 这就是为什么handoffp后, 马上会调用startm启动或唤醒一个新的M; 下图中, 唤醒路径(左箭头)和睡眠路径(右箭头)都是调用futex系统调用 notetsleepg timerproc里面, 回调函数占一小部分, timer堆排序占一小部分, 大头都是在notetsleep前后的准备工作, 包括: entersyscallblock: 此时已经知道本G所在的M要调用阻塞的系统调用而休眠, 要做一些准备工作: 在进入休眠之前, 先交出P的使用权, 即handoffp; 此时空出来的P要求绑定一个新的M, 即上图中的startm, 后者调用futexwakeup去唤醒其他的M.哪些M见下个小节 exitsyscall: 正常来讲, 一个M被唤醒时, 要acquirep, 也许就是刚刚让出来的P, 来绑定本M; 但上面的统计得出, 本M被唤醒后, 走fast_pidle流程, 就是说很多时候P是idle的, 这和htop的4.5%CPU占用率相符; 一个程序, 可能大部分时间比例都不真正占用CPU. P是idle的情况下, 继续走notewakeup流程, 但看起来不太对啊, 此时不是应该真正休眠吗? 也许是个bug? 怎么有反复wakup的嫌疑? // same as runtime·notetsleep, but called on user g (not g0) // calls only nosplit functions between entersyscallblock/exitsyscall func notetsleepg(n *note, ns int64) bool { gp := getg() if gp == gp.m.g0 { throw(\"notetsleepg on g0\") } entersyscallblock() ok := notetsleep_internal(n, ns) exitsyscall() return ok } 问题: futex唤醒路径是干啥用的? 按理说, timerproc的futex都是带超时的, 那等待超时, kernel自然会wakeup这个M. 那上文中, P和M分离后, 要选一个新的M来wakeup来干活, 那么是哪些M会被wakeup呢? 首先, 从htop中看到, 一共由4个线程, 那么就是4个M timerproc那个routine所在的M应该最忙, 也就很可能是pid 21217 第二个忙的M应该是sysmon所在的M 其他的可能跑GC啥的 那如果timerproc让出了P, 很可能是给sysmon用. 对照代码片段分析:sysmon sysmon在>中有所说明 从图上看, 几条路径都会走到阻塞的系统调用来休眠. 结论 从handleOnu的select等待路径和timerproc中time.sendTime唤醒路径看 goroutine的调度开销很小, 因为gopark, goready等函数都在用户态就完成了goroutine切换 channel的开销也比较小, 同样也是用户态. channel的send和receive会触发goroutine调度 M的切换和调度依赖kernel的阻塞的系统调用, go在系统调用前后都有\"埋伏\"函数, 这些函数是调度器的入口点. 打印调用栈 以json_load为例 #运行后, 有6个线程 ./json_load -fileName test.json -loopNum 10000 > /dev/null cat /proc/17212/status Threads: 6 pstack打印不了go的调用栈 提示could not find _DYNAMIC symbol, 因为pstack底层使用gdb, 而gdb对go的理解不好. 用-SIGQUIT 在go程序运行时, 用kill -SIGQUIT 17167给go进程发信号, 会导致go进程终止, 该进程终止时会打印调用栈或者在进程执行时, 按ctrl+\\发SIGQUIT信号, 效果一样 注册信号handler 参考 https://www.jianshu.com/p/abbe6663b672 结果 显示只有2个goroutine goroutine 0 goroutine 1 中间很长, 这个是个多层函数调用嵌套的过程, 因为输入test.json里面有多层嵌套 用taskset -c 1强制一个核跑 还是2个goroutine 如果只有两个goroutine, 但为什么要起6个线程呢? 实际上, goroutine不止2个. 加GOTRACEBACK=system环境变量, 能看到系统级的goroutine GOTRACEBACK=system ./json_load -fileName test.json -loopNum 100000 > /dev/null 然后按ctrl+\\, 得到调用栈 全部goroutine如下: goroutine 0 [idle]: //用户goroutine goroutine 1 [runnable]: //以下是system级别的 goroutine 2 [force gc (idle)]: goroutine 3 [GC sweep wait]: goroutine 4 [finalizer wait]: goroutine 5 [GC worker (idle)]: goroutine 17 [GC worker (idle)]: goroutine 18 [GC worker (idle)]: goroutine 19 [GC worker (idle)]: 用 GODEBUG=schedtrace=10000,scheddetail=1可以10s打印一次调度信息 P: 代表CPU M: 代表OS线程 G: 代表goroutine "},"notes/golang_topid性能优化.html":{"url":"notes/golang_topid性能优化.html","title":"topid性能优化","keywords":"","body":" topid性能优化(倒叙阅读) 单核和多核数据背离 24核运行时 单核运行时 对比多核, 单核运行时 新版本 老版本 结论 pprof数据和实际观测的背离(还是不全面) htop采集的运行数据 pprof的采集数据 哪个数据是准确的? perf火焰图数据来仲裁 新版本在内核态多搞了什么事情? 结论 topid性能优化(不全面) topid和htop性能对比 数据 阶段解读1 benchmark关键函数 分析热点调用链 递归的routine化改造 改造思路和细节 docker instance里面的结果 在host上运行 系统调用次数 open的fd数 goroutine数量 pprof数据 同时运行新老版本 结论 再改进: 保存fd句柄, 但不在goroutine上下文中. 题外: 尝试加goroutine topid是纯go写的类似top的进程性能统计工具, 和topidchart联用可以实时图形化显示性能. gshell topid代码 虽然本文调试的时候topid还没有使用gshell框架, 但是它们的主体代码都是lib pidinfo, 主要的活是lib干的. topid性能优化(倒叙阅读) 单核和多核数据背离 背景见下面. 还是新版本和老版本, 一点都没变. 当用taskset绑定单核运行时, 结果有惊人的变化. 24核运行时 见下面 htop采集的运行数据 小节 左侧是新版本, 右侧是老版本 单核运行时 分别将新老两个版本绑定到15 16核运行 注: taskset和GOMAXPROCS=1都能够限制单核, 实测效果一样. 但后者支持跨核调度, 更好点. GOMAXPROCS=1 ./topid.dd0301e -p 1 -tree -thread taskset -c 15 ./topid.dd0301e -p 1 -tree -thread 左侧是新版本, 右侧是老版本 对比多核, 单核运行时 新版本和老版本的CPU占用都下来了. 新版本的CPU占用下降更多; 甚至比老版本还快. 新老版本使用的OS线程数量都明显下降了, 新版本减小的更多. taskset1以后, 采样数量都小了很多 新版本 多核运行时:单核运行时: 解读: runtime.mcall大大减少, 从24核的2759次减小为31次 runtime.futex大大减小, 从24核的4397次减小为51次 runtime.sellock大大减小, 从24核的1131次减小为3次 gc相关的比例还是30%多, 但绝对数量也大大减小 老版本 多核运行时:单核运行时: 和上面类似 runtime.mcall大大减少 runtime.futex大大减小 runtime.sellock本来也没有啥 连gc相关的比例都减小了 结论 go的性能和P和M的数量关系巨大, 即PMG三者中, P是执行者, M是执行环境, 代码逻辑是要干的活; M的数量受G的数量和P的数量约束 P的数量可以用GOMAXPROCS=n来静态配置, 也可以调用runtime的GOMAXPROCS()函数来配置. 默认和CPU核数相等. M是runtime根据需要动态生成的, 和P的数量看起来是成比例相关性. 应该说G的数量是需求, P是比例系数, 最终确定M的数量 主要影响M个数的还是P, 因为P是执行者, P要结合执行环境M才能干活. P越多, 环境也要求越多. 活分给1个G或者多个G, 对性能影响不大. G和业务逻辑自然对应就好.不要苛求. G越多, M的数量也会多. 并不是G越多并发就越好, 但其实G多了也没啥大影响. -- 补充, 在P数量很少的情况下是的. 但如果P数量大, 比如24个, 然后你的程序的G又多, 那么效果就是M会大大增多, P和M的分离和结合是go调度器的核心, 也是性能开销巨大的地方. P的数量影响锁. 因为P是真正并发的个数, 并发才需要锁. 上面的数据中, P为1的时候, 原来的\"广播\"channel的锁的开销也变得非常小了. P为24的时候, \"广播\"channel的锁开销很大 总的来说, 活不多的时候, 多少个G做都无所谓, 主要是P越小越好. 即一个P能干完的活, 用一个P干比让多个P干更省系统资源. 活多的时候, 一个P干不过来, 表现是一个CPU长期100%也干不完, 那就要增大P. 增大P能多出活, 但要代价是要承担多P的调度开销, 通常来讲这个开销很不小. 多核环境下, 默认的P等于核数的策略, 开销很大. 建议每个go程序都要根据情况手动配置GOMAXPROCS pprof数据和实际观测的背离(还是不全面) 背景见下面: topid性能优化(不全面) 但里面的分析落入了\"用户态\"陷阱. 有很多数据对不上 htop采集的运行数据 左边是新版本topid运行情况右边是老版本topid运行情况无论是从观察CPU占用的情况, 还是TIME时间统计, 新版本都比老版本CPU占用高, 累计运行时间长. 这两个程序我同时起的, 但左边新版本累计运行(即在R状态的时间)了55分钟, 右边是32分钟. 即新版本比老版本CPU占用几乎高2倍. pprof的采集数据 同样采样10分钟:新版本: 老版本: 可以看到, 同样是采样10分钟, pprof采样认为, 新版本真正运行了13.86s ( 2.31%); 而老版本真正运行了24.73s ( 4.12%) 即pprof认为新版本性能更好. 哪个数据是准确的? pprof的采集数据和htop显示的数据是矛盾的吗? 新版本比老版本真的性能更好吗?从代码逻辑上说, 新版本是做了优化的: 优化了文件open的逻辑, 打开不关闭, 下次继续用. 新增每个线程一个goroutine, 来更新status情况. 大概有900个这样的goroutine 感觉上, 新版本应该性能更好. 从pprof的数据看来, 确实系统调用占比下降了. 其他也没有明显的增加, 只大概gc部分和systemstack部分有所增加. 真的吗? perf火焰图数据来仲裁 同样采样60秒:新版本: 老版本: 新版本的采样数为9048老版本的采样数为4338 这个数据很硬, 说明新版比老版本慢了. 和htop的观测数据基本一致的.那么怎么看pprof数据呢? 它错了吗?pprof也没错, 但它只报告用户态的数据. 从用户态来看, 新版本更快了.但从用户态加内核态来看, 新版本反而慢了一倍多. 另外, pprof的采样频率不高:10分钟期间新版本采样1386个, 每秒才采集到2个点.老版本采样2473个, 每秒才采集到4个点.采样频率太低了!而perf的采样每秒能到150个点. 这个差距太大了 似乎pprof只关注用户态, 即使采样到本进程的内核态函数, 似乎pprof就忽略了, 并不计入统计. 就好像这个进程的内核态时间不算一样. 这样就可以解释, 比如在pprof看来, 新老版本的runtime.futex的采样数差不多, 但perf看来确实新版本比老版本多两倍. 如果pprof采样时, 只看用户态的栈, 那么比如某个时刻pprof采样到内核态, 它不管了; 但实际上, 此时是内核在做runtime.futex的事情. perf会通过回溯内核栈知道是runtime.futex, 但pprof没有能力知道这个信息, 就没有统计进. PS: 网上说runtime的 func SetCPUProfileRate(hz int)可以修改采样频率. -- 好像加了没有用? 还是默认的100 新版本在内核态多搞了什么事情? 新版本用户态的逻辑确实快了, 但却带了更大的内核态开销.要对比一下:新版本的采样数为9048老版本的采样数为4338 runtime.futex, 这个函数是goroutine睡眠和唤醒的关键函数 新版本: 9048*48.6% = 4397 老版本: 4338*53.7% = 2329 新版比老版多了近一倍 runtime.sellock 新版本: 9048*12.5% = 1131 老版本: 几乎可以忽略 因为新版本中, 900个gotouine都\"监听\"一个channel, 这个channel用close来\"广播\"事件. 这个channel的锁开销非常大 runtime.mcall 新版本: 9048*30.5% = 2759 老版本: 4338*36.7% = 1592 新版本也是老版本的2倍, 是因为线程多吗? runtime.sysmon 新版本: 4.9%, 443个 老版本: 8.5%, 368个 sysmon并没有太大影响 gc相关(统计正则\"bg|gc\") 新版本: 35% 老版本: 29% 还是新版本多了不少 结论 新版本比老版本慢. 主要原因是goroutine调度和channel的锁, 以及gc开销变大 新版本的线程数也多, mcall也有开销. pprof工具不统计目标进程的内核态的开销, 导致和实际观测结果不一致. 说三遍 pprof工具不统计目标进程的内核态的开销, 导致和实际观测结果不一致. 说三遍 pprof工具不统计目标进程的内核态的开销, 导致和实际观测结果不一致. 说三遍 topid性能优化(不全面) topid和htop性能对比 测试命令: ./topid -p 1 -tree -thread和htop或者GOMAXPROCS=1 ./topid -p 1 -tree -thread 数据 目测htop的CPU占用在3%左右. 偶尔能到7% htop的系统调用 perf stat --log-fd 1 -e 'syscalls:sys_enter_*' -p 17470 -- sleep 10 | egrep -v \"[[:space:]]+0\" Performance counter stats for process id '17470': 62 syscalls:sys_enter_poll 4,044 syscalls:sys_enter_getdents 12 syscalls:sys_enter_newstat 2,046 syscalls:sys_enter_newfstat 23,928 syscalls:sys_enter_read 413 syscalls:sys_enter_write 17,946 syscalls:sys_enter_openat 13,992 syscalls:sys_enter_close 12 syscalls:sys_enter_rt_sigaction 10.221686634 seconds time elapsed topid, e86db98(opt1)的CPU占用总体较高, 跳跃幅度大, 最小3%, 最大有11%. topid的系统调用 #连续3次执行 perf stat --log-fd 1 -e 'syscalls:sys_enter_*' -p 28187 -- sleep 10 | egrep -v \"[[:space:]]+0\" #1 Performance counter stats for process id '28187': 40,904 syscalls:sys_enter_epoll_ctl 243 syscalls:sys_enter_epoll_pwait 2,174 syscalls:sys_enter_getdents64 24 syscalls:sys_enter_fcntl 27,688 syscalls:sys_enter_read 9,368 syscalls:sys_enter_write 18,749 syscalls:sys_enter_openat 18,748 syscalls:sys_enter_close 1,770 syscalls:sys_enter_madvise 6,026 syscalls:sys_enter_futex 2,927 syscalls:sys_enter_nanosleep 6,749 syscalls:sys_enter_sched_yield 14.298493125 seconds time elapsed #2 Performance counter stats for process id '28187': 30,728 syscalls:sys_enter_epoll_ctl 198 syscalls:sys_enter_epoll_pwait 1,782 syscalls:sys_enter_getdents64 20 syscalls:sys_enter_fcntl 22,691 syscalls:sys_enter_read 7,677 syscalls:sys_enter_write 15,364 syscalls:sys_enter_openat 15,364 syscalls:sys_enter_close 1,294 syscalls:sys_enter_madvise 3,415 syscalls:sys_enter_futex 1,668 syscalls:sys_enter_nanosleep 25,145 syscalls:sys_enter_sched_yield 11.999374271 seconds time elapsed #3 Performance counter stats for process id '28187': 30,730 syscalls:sys_enter_epoll_ctl 197 syscalls:sys_enter_epoll_pwait 1,978 syscalls:sys_enter_getdents64 24 syscalls:sys_enter_fcntl 27,721 syscalls:sys_enter_read 9,379 syscalls:sys_enter_write 18,771 syscalls:sys_enter_openat 18,770 syscalls:sys_enter_close 1,650 syscalls:sys_enter_madvise 4,870 syscalls:sys_enter_futex 2,535 syscalls:sys_enter_nanosleep 166 syscalls:sys_enter_sched_yield 12.300680961 seconds time elapsed topid, f7a11ed(opt2+other): 相比较opt1, 没有明显CPU利用率的变化, 最小3.3%, 7.2%, 9.1%, 偶尔到11.1% 阶段解读1 从文件open和read来看, htop和topid数量级差不多 文件close上htop要少 从以上看似乎htop并没有采取\"保持open\"的策略 topid的opt2对比opt1没有性能上的变化, opt2只是去掉了map的遍历以及多调用的一次pi.Children()调用, 都属于很小的优化点. opt2的代码可以做为baseline benchmark关键函数 关键函数是Update() 该baseline的benchmark性能在2ms左右, 这是docker实例里的pid1的 //benchmark: for i := 0; i #结果 yingjieb@3a9f377eee5d /repo/yingjieb/godev/practice/src/pidinfo $ go test -run xxxxxx -bench BenchmarkP1InfoUpdate goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-23 712 1539443 ns/op PASS ok pidinfo 1.293s 分析热点调用链 #先利用go test记录cpu的profile文件 go test -run xxxxxx -bench BenchmarkP1InfoUpdate -cpuprofile cpu.out #打开pprof工具分析 go tool pprof -http=0.0.0.0:8000 cpu.out #网页浏览 http://10.182.105.138:60080 从图中得出, 关键在频繁的open read close系统调用.而且, go的runtime特别喜欢在系统调用路径上埋桩, 比如open的时候会把fd加到epoll里面, 导致epollctl比较高, 几乎和open+close相当. 10秒3万次.相对于C的htop, 虽然open和close也在每秒万次级别, 但htop没有使用epollctl; htop只有几十次的poll系统调用 到这里, 可以看到, GO程序的开销还是比较大的, 主要有: 系统调用开销: go的open read write系统调用, 首先是受runtime用户态调度的; 即read()发生时, runtime把这个goroutine调度出去, 待该fd可以read了再调度回来. 之所以能做到用户态调度, 是因为runtime记录了每个open的文件的fd, 并加到epoll_ctl里面管理. GC的开销 实际上, 可以利用go的\"同步\"特性, 用保持open的方式来避免反复的open read close文件. 如果去掉上图的 1 2 3, 只留read, 估计至少可以提高性能一倍. 即下面这个函数相关的逻辑要改造 func readFile(filename string) ([]byte, error) { f, err := os.Open(filename) if err != nil { return nil, fmt.Errorf(\"%s: %w\", here(), err) } defer f.Close() return ioutil.ReadAll(f) } 关键是怎么利用goroutine, 让open的文件保持. 整个程序的思路要从C的递归思路, 转变为go的routine思路. 递归的routine化改造 改造思路和细节 docker instance里面的结果 benchmarking的结果是: 同一个环境, 老版本和新版本都run三次 新版本(并发版本)大概在2ms左右 $ go test -run xxxxxx -bench BenchmarkP1InfoUpdate goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-23 732 2105706 ns/op PASS ok pidinfo 4.919s 老版本(递归版本)大概4ms $ go test -run xxxxxx -bench BenchmarkP1InfoUpdate goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-23 273 4075231 ns/op PASS ok pidinfo 1.557s 从这个数据看, 新版本优于老版本. 在host上运行 系统调用次数 系统调用次数统计中, epoll_ctl, open和close次数减小的非常明显, 符合预期. root@godev-server:/repo/yingjieb/godev/practice/src/tools# perf stat --log-fd 1 -e 'syscalls:sys_enter_*' -p 3632 -- sleep 10 | egrep -v \"[[:space:]]+0\" Performance counter stats for process id '3632': 24 syscalls:sys_enter_epoll_ctl 277 syscalls:sys_enter_epoll_pwait 2,954 syscalls:sys_enter_getdents64 8 syscalls:sys_enter_fcntl 22,029 syscalls:sys_enter_lseek 30,716 syscalls:sys_enter_read 2,204 syscalls:sys_enter_write 6 syscalls:sys_enter_openat 8 syscalls:sys_enter_close 1,600 syscalls:sys_enter_madvise 5,544 syscalls:sys_enter_futex 2,615 syscalls:sys_enter_nanosleep 708 syscalls:sys_enter_sched_yield 21.666616483 seconds time elapsed open的fd数 大概在2K数量级, 超过了默认的1024. 要先ulimit -n 10240扩大打开文件的上限. yingjieb@godev-server /proc/3632/fd $ ll | wc -l 1972 goroutine数量 大概2K个 pprof数据 是系统调用, 主要是read; 占33% 是GC, 占35% 是调度, 占7% 综合来看, 这么多个goroutine(2K)情况下, 调度其实占比不多. 而实际上, 系统调用次数和开销明显减小了; 但GC的情况变得很糟糕, 有1/3的时间全部在搞GC. 同时运行新老版本 同时运行两个版本, 用htop观察 可以看到, 新版本并没有变好, 甚至观察到比老版本还稍差. 打开的fd多, 需要先修改ulimit的文件打开上限数 占用内存多, 新版本21M, 老版本8M 结论 新版本的思路是用goroutine长期持有fd, open了不关闭, 需要read的时候, 用channel来触发. 但新版本并没有保存fd到记录, 而是每个新的fd都开一个goroutine来守护, 同时搭配channel来协同工作. 这是用goroutine+channel的组合来替换反复的open close文件操作. 当进程数较少时, 新版本有性能优势. 因为避免了老版本的重复open close文件的开销 当进程数很多时, 新版本反而性能更差. 其实调度的开销并不是很大, 这么多个goroutine才7%左右; 补充, 有的时候也能到20% 开销大的是GC. 异步程序设计复杂, 程序逻辑更多. 也加剧了GC的开销.大量的map使用, 应该是主要原因. 所以凡事无绝对, 要看什么场景. 再改进: 保存fd句柄, 但不在goroutine上下文中. 减小goroutine的数量. 减小异步交互. 减小逻辑复杂度. 最终的目的是减小GC压力. 题外: 尝试加goroutine 在调用点 for循环里得到线程列表, 调用线程的update函数的时候, 用goroutine for循环里得到子进程的历表, 调用子进程的update函数的时候, 用goroutine 类似这样: //fmt.Printf(\"Process %d's child processes:%v\\n\", pi.pid, pi.children) for _, childpid := range pi.childrenIds { childpid := childpid childpi := pi.children[childpid] //wrong use of goroutine, 并发panic go func() { //fmt.Println(\"Updating PidInfo for\", childpid) if err := childpi.Update(); err != nil { delete(pi.children, childpid) } }() } 注意, 这样使用会有并发问题 go test -run xxxxxx -bench BenchmarkP1InfoUpdate执行后, 会报错: yingjieb@3a9f377eee5d /repo/yingjieb/godev/practice/src/pidinfo $ go test -run xxxxxx -bench BenchmarkP1InfoUpdate goos: linux goarch: amd64 pkg: pidinfo BenchmarkP1InfoUpdate-23 fatal error: concurrent map read and map write goroutine 13 [running]: runtime.throw(0x5623be, 0x21) /usr/local/go/src/runtime/panic.go:774 +0x72 fp=0xc0000b5d98 sp=0xc0000b5d68 pc=0x42d232 runtime.mapaccess1_fast64(0x52d800, 0xc0000b2450, 0x2900, 0xc000150828) /usr/local/go/src/runtime/map_fast64.go:21 +0x1a6 fp=0xc0000b5dc0 sp=0xc0000b5d98 pc=0x410136 pidinfo.(*PidInfo).updateThreads(0xc0000fc300, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:315 +0x3e0 fp=0xc0000b5f08 sp=0xc0000b5dc0 pc=0x506f30 pidinfo.(*PidInfo).Update(0xc0000fc300, 0x0, 0x0) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:486 +0x16e fp=0xc0000b5fa0 sp=0xc0000b5f08 pc=0x50885e pidinfo.(*PidInfo).updateChildren.func1(0xc0000fc300, 0xc0000fc000, 0x2885) /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:393 +0x2b fp=0xc0000b5fc8 sp=0xc0000b5fa0 pc=0x509eab runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc0000b5fd0 sp=0xc0000b5fc8 pc=0x45b8b1 created by pidinfo.(*PidInfo).updateChildren /repo/yingjieb/godev/practice/src/pidinfo/pidinfo.go:391 +0x8e9 因为在更新线程状态的时候, 会对同一个map读写.说明runtime有一定能力检测并发问题, 并进行运行时的panic处理. "},"notes/golang_gshell性能调试.html":{"url":"notes/golang_gshell性能调试.html","title":"gshell性能调试","keywords":"","body":" asbench调试 背景 在x86服务器上性能不稳定 试验 目前的结论: topid性能调试 baseline CPU chart 火焰图 float改int有效果吗? asbench调试 背景 测试adaptiveservice性能 在x86服务器上性能不稳定 测试命令: 启动daemon, 注意这里限定了GOMAXPROCS=8, 就是说默认grg的最大proc数为8 GSHELL_NOUPDATE=1 GOMAXPROCS=8 bin/gshell -loglevel info daemon -registry 10.182.105.179:11985 -bcast 9923 启动asbenchserver: gsh run -group asbench benchmark/asbench/server/asbenchserver.go 启动client, 测试性能 gsh run -group asbench -i -rm benchmark/asbench/client/asbenchclient.go -t 10 -scope os -s32 -n 1 发现有时候TPS数据差异很大: Transaction Per Second(TPS): 15088.94 Transaction Per Second(TPS): 13968.29 Transaction Per Second(TPS): 16901.58 但有时候又很稳定: Transaction Per Second(TPS): 24853.32 Transaction Per Second(TPS): 25749.64 Transaction Per Second(TPS): 24608.96 试验 经过简单的调整golang运行时的参数, 比如: GODEBUG=madvdontneed=0,schedtrace=1000,scheddetail=1,asyncpreemptoff=1 GOGC=off taskset -c 11 ./asbench -packet -t 10 -mode c GODEBUG=madvdontneed=0,schedtrace=1000,scheddetail=1,asyncpreemptoff=1 GOGC=off GOMAXPROCS=1 ./asbench -packet -t 10 -mode c taskset似乎能起一定的作用, 但TPS还是不稳. 目前的结论: 本测试是在云服务器(VM)上进行的, 似乎是KVM虚拟机. 在VM上用top看到, 性能稳定的时候, 都是0.0st(红框部分).但性能不稳定的时候, 是零点几的st: 0.3st, 虽然只有零点几, 但可能是host上有什么负载, 或者是同一台物理机上其他人的VM有大load.因为KVM的核也是host上qemu的一个线程, 在VM中跑load, 会受到host的影响, 但这种影响似乎在VM上很难察觉. topid性能调试 baseline gshell版本v21.11.02.rc2 启动命令: ~/gshell # gsh run -rt 91 -i app-plat/topid/topid.go -chart -snapshot -sys -i 3 -tag eonuTest -info \"cat /tmp/boardname,typeA_panda_show,typeA_squirrel_show\" CPU chart CPU chart(on ppc32, gccgo): CPU chart(on x86, gcgo): 火焰图 火焰图上看, 占比比较大的有: yaegi解释器 进程update 调度 GC 而gotidy编解码占比非常小 float改int有效果吗? topid client在向server端传输数据的时候, CPU占用率用的是float表示. 我们直到, 即使是简单的float值, 比如1.05, 其实在内存中的表达也是一个很大的\"数值\", 那么能不能传输int, 比如105, 这样可以大大简化提高gotiny的编码效率. 那float改成对应的int, 实际效果如何呢?-- 几乎没改善, 和perf火焰图一致.从火焰图上看, 应该效果非常小. 真的吗?把float64改成uint64 CPU实际更擅长\"纯数值\"计算, 在一个应用逻辑中, 除了计算, 还有IO操作, 比如topid中, 更多的工作是proc文件系统操作和网络IO, 比例远远大于\"纯数值\"计算. 所以理论上float变成int能够提高编码效率, 但因为这部分计算占应用的比例太低, 实际上性能没有什么提高. "},"notes/golang_zmq.html":{"url":"notes/golang_zmq.html","title":"消息中间件基本概念和zero mq","keywords":"","body":" zmq和nanomsg nanomsg支持的socket类型 nanomsg的transport类型 nanomsg和nng nng的纯go版本 高级REQ-REP 经过ROUTER会加\"address\" frame 地址的生成 Router再把标识符剥掉, 传给REQ 总结 搭配 合法的搭配 不合法的搭配 总结 zmq使用 transport类型 线程间 进程间 TCP pgm zmq socket server和client zmq socket类型 zmq的send和recv和tcp的不同 zmq的message framing Frames 兼容性 IO thread和context zmq_poll()函数 不用poll 使用poll 分片的msg 服务发现 多对多的client和server 其他模型 并发支持 zmq的应用代码可以run在线程, 进程, 或node上. pub到已知数量的subscriber 零拷贝 pub-sub实际上是msg filter 高水位 丢包怎么定位? 消息交互模式 PAIR类型 为社么要用pair req-rep server端 client端 pub-sub server侧 client侧 push-pull 生产者 ventilator 消费者worker sink 总结 context pipeline fanout 灵魂几问 阻塞还是异步? 谁当server谁当client? 怎么在wire上表示一个message? 如果对端没准备好的时候, 要发送的数据缓存在哪里? 拥塞控制策略? 消息丢失怎么办? 要保证送达吗? 如果有新的transport方法怎么办? app要改吗? 比如增加支持yipc? 消息怎么路由? 多语言怎么适配? encoding怎么选择? 网络错误怎么处理? 作者观点 zero mq(zmq, 0mq) 问题: REQ-REP模式下的RPC, 怎么把异步同步化的? zmq使用最基本的模式, send后马上recv go标准库的rpc 问题和改进思路 zmq和nanomsg zmq的作者之一后来自立门户, 创立了nanomsg https://nanomsg.org/documentation-zeromq.html 上面文章详细写了nanomsg和zmq的不同点. 总的来说, zmq的作者之一对2008年当时的实现有所反思, 然后在实现方式上有所改进, 但整体思想是有延续性的, 比如都是以lib形式提供的. 特别的, nanomsg是MIT的license nanomsg支持的socket类型 PAIR - simple one-to-one communication BUS - simple many-to-many communication REQREP - allows to build clusters of stateless services to process user requests PUBSUB - distributes messages to large sets of interested subscribers PIPELINE - aggregates messages from multiple sources and load balances them among many destinations SURVEY - allows to query state of multiple applications in a single go nanomsg的transport类型 INPROC - transport within a process (between threads, modules etc.) IPC - transport between processes on a single machine TCP - network transport via TCP WS - websockets over TCP nanomsg和nng nng又是nanomsg的改版: https://github.com/nanomsg/nng 看起来不错: https://github.com/nanomsg nng的纯go版本 https://github.com/nanomsg/mangos 目前是v3版本 看起来完成度不错. 高级REQ-REP REP都有envelop, envelop其实就是加\"报文头\". We already looked briefly at multipart messages. Let’s now look at a major use case, which is reply message envelopes. An envelope is a way of safely packaging up data with an address, without touching the data itself. By separating reply addresses into an envelope we make it possible to write general purpose intermediaries such as APIs and proxies that create, read, and remove addresses no matter what the message payload or structure is. In the request-reply pattern, the envelope holds the return address for replies. It is how a ZeroMQ network with no state can create round-trip request-reply dialogs. When you use REQ and REP sockets you don’t even see envelopes; these sockets deal with them automatically. But for most of the interesting request-reply patterns, you’ll want to understand envelopes and particularly ROUTER sockets. We’ll work through this step-by-step. zmq用多frame描述一个msg, 地址和data在不同的frame中. The ZeroMQ reply envelope formally consists of zero or more reply addresses, followed by an empty frame (the envelope delimiter), followed by the message body (zero or more frames). The envelope is created by multiple sockets working together in a chain. We’ll break this down. We’ll start by sending “Hello” through a REQ socket. The REQ socket creates the simplest possible reply envelope, which has no addresses, just an empty delimiter frame and the message frame containing the “Hello” string. This is a two-frame message. 简单的REQ-REP没地址, 但有个空的分隔frame. 第一个数字是字节数zmq会把前面的envelop头剥掉, 只传递data frame给应用层.every request and every reply is in fact two frames, an empty frame and then the body 经过ROUTER会加\"address\" frame 这里的address是用来识别connection的. 因为router面对的是多个connection. 地址的生成 The ROUTER socket invents a random identity for each connection with which it works. If there are three REQ sockets connected to a ROUTER socket, it will invent three random identities, one for each REQ socket. router的socket会给每个连接生成随机的标识符. 比如ABC. router内部用map来跟踪这个标识符和connection的对应关系.然后这三个frame被发到DEALER socket出去. 从而REP的socket也收到这3个frame.REP的应用层不关心这个标识frame, 所以zmq暂存这个标识, 剥掉前两个frame, 只返回Hello给应用层.应用层处理后, zmq把保存的frame重新包装回frame, 回去还是3个frame.为什么不用底层socket的地址做为标识? 这样就不用生成随机的标识了呀???? 是安全性考虑吗? Router再把标识符剥掉, 传给REQ DEALER还是把3个frame都给ROUTER, ROUTER查表得到connection, 剥掉标识符那个frame, 只发2个frame给REQ socket. ROUTER sockets don’t care about the whole envelope. They don’t know anything about the empty delimiter. All they care about is that one identity frame that lets them figure out which connection to send a message to. 总结 The REQ socket sends, to the network, an empty delimiter frame in front of the message data. REQ sockets are synchronous. REQ sockets always send one request and then wait for one reply. REQ sockets talk to one peer at a time. If you connect a REQ socket to multiple peers, requests are distributed to and replies expected from each peer one turn at a time. The REP socket reads and saves all identity frames up to and including the empty delimiter, then passes the following frame or frames to the caller. REP sockets are synchronous and talk to one peer at a time. If you connect a REP socket to multiple peers, requests are read from peers in fair fashion, and replies are always sent to the same peer that made the last request. The DEALER socket is oblivious to the reply envelope and handles this like any multipart message. DEALER sockets are asynchronous and like PUSH and PULL combined. They distribute sent messages among all connections, and fair-queue received messages from all connections. The ROUTER socket is oblivious to the reply envelope, like DEALER. It creates identities for its connections, and passes these identities to the caller as a first frame in any received message. Conversely, when the caller sends a message, it uses the first message frame as an identity to look up the connection to send to. ROUTERS are asynchronous. 搭配 详见: https://zguide.zeromq.org/docs/chapter3/#Request-Reply-Combinations 合法的搭配 REQ to REP DEALER to REP REQ to ROUTER DEALER to ROUTER DEALER to DEALER ROUTER to ROUTER不合法的搭配 REQ to REQ REQ to DEALER REP to REP REP to ROUTER总结 DEALER is like an asynchronous REQ socket, and ROUTER is like an asynchronous REP socket. Where we use a REQ socket, we can use a DEALER; we just have to read and write the envelope ourselves. Where we use a REP socket, we can stick a ROUTER; we just need to manage the identities ourselves. Think of REQ and DEALER sockets as “clients” and REP and ROUTER sockets as “servers”. zmq使用 libzmq是zmq的核心lib server端用zmq_bind()绑定到\"well known\"的地址 client端从是不固定的, 动态的地址zmq_connect()到server 所有的zmq socket都是在zmq的context里面. zmq的context是一个IO线程池加底层socket的合体. API void *zmq_init (int io_threads)可以来配置io thread的个数. transport类型 transport用下面的格式来说明: transport://地址 线程间 inproc://名字 实际上是直接线程间内存传递, 此时zmq没有IO thread参与, 即void *zmq_init (int io_threads);可以传0. 其他的transport需要背景io线程至少一个. // Assign the in-process name \"#1\" rc = zmq_bind(socket, \"inproc://#1\"); assert (rc == 0); // Assign the in-process name \"my-endpoint\" rc = zmq_bind(socket, \"inproc://my-endpoint\"); assert (rc == 0); // Connect to the in-process name \"#1\" rc = zmq_connect(socket, \"inproc://#1\"); assert (rc == 0); // Connect to the in-process name \"my-endpoint\" rc = zmq_connect(socket, \"inproc://my-endpoint\"); assert (rc == 0); 不支持disconnected模式, 即一定要server先起. 可能后面版本会支持 进程间 ipc://路径 实际上是unix domain socket // Assign the pathname \"/tmp/feeds/0\" rc = zmq_bind(socket, \"ipc:///tmp/feeds/0\"); assert (rc == 0); // Connect to the pathname \"/tmp/feeds/0\" rc = zmq_connect(socket, \"ipc:///tmp/feeds/0\"); assert (rc == 0); 也支持disconnected模式. 即server后起起, client先起, 但还是连的上. TCP 对tcp的地址做了简化封装 // TCP port 5555 on all available interfaces rc = zmq_bind(socket, \"tcp:/// :5555\"); assert (rc == 0); // TCP port 5555 on the local loop-back interface on all platforms rc = zmq_bind(socket, \"tcp://127.0.0.1:5555\"); assert (rc == 0); // TCP port 5555 on the first Ethernet network interface on Linux rc = zmq_bind(socket, \"tcp://eth0:5555\"); assert (rc == 0); // Connecting using an IP address rc = zmq_connect(socket, \"tcp://192.168.1.1:5555\"); assert (rc == 0); // Connecting using a DNS name rc = zmq_connect(socket, \"tcp://server1:5555\"); assert (rc == 0); tcp类型的transport支持disconnected模式. 即server后起起, client先起, 但还是连的上. pgm PGM (Pragmatic General Multicast) is a protocol for reliable multicast transport of data over IP networks. zmq支持两种pgm: pgm: 基于raw IP epgm: 基于UDP pgm的socket只能用于PUB SUB模式 pgm的地址格式有点长: interface名;多播地址;端口// Connecting to the multicast address 239.192.1.1, port 5555, // using the first Ethernet network interface on Linux // and the Encapsulated PGM protocol rc = zmq_connect(socket, \"epgm://eth0;239.192.1.1:5555\"); assert (rc == 0); // Connecting to the multicast address 239.192.1.1, port 5555, // using the network interface with the address 192.168.1.1 // and the standard PGM protocol rc = zmq_connect(socket, \"pgm://192.168.1.1;239.192.1.1:5555\"); assert (rc == 0); zmq socket 一个zmq socket可以同时有多个incoming和outgoing连接 zmq的socket没有accept概念: 一个bind了的socket, 自动会accept连接 背景io线程会处理原始连接, 自动断线重连 app层不应该关心原始socket, 实际上app层也不能直接使用原始socket server和client server代表一个不变的组件. server有well-konwn地址, 用zmq_bind() client更多的是动态的. 用zmq_connect()来连server zmq会缓存message. client和server可以任意顺序启动. server可以bind多中transport类型, 比如tcp和进程间, 线程间都可以混在一起bind到一个zmq的socket上zmq_bind (socket, \"tcp://*:5555\"); zmq_bind (socket, \"tcp://*:9999\"); zmq_bind (socket, \"inproc://somename\"); 但同一个transport一般不能bind两次, 比如tcp, 肯定是端口重复. zmq socket类型 socket的类型决定了交互模式, 路由方式, 缓存策略等等. 是zmq对交互模式的归类和抽象 zmq的send和recv和tcp的不同 zmq的message有边界的, 就像UDP; 而tcp是stream式的. zmq有后台IO线程, message先进local的input queue; 发送的message也是从local 的output queue里面来的. zmq的socket可以1发多, 即1:N的多播. zmq_send()只是把message发送到queue里, 后台的IO线程会异步的发送这个message. 除非特别情况, 这个API不会阻塞 zmq_msg_send()后面还要研究一下 zmq的message framing zmq内部对wire上的数据是做了按size分割的. 是类UDP的设计. 所以recv的API被设计成要传入buffer size的格式: int zmq_send (void *socket, void *buf, size_t len, int flags) int zmq_recv (void *socket, void *buf, size_t len, int flags) 那么zmq_recv会根据用户提供的buf size来\"截断\"消息. 这个用起来就不地道. 所以zmq提供了另外两个API, 这里面就没有size, 每次调用都是一个完整的msg int zmq_msg_send (zmq_msg_t *msg, void *socket, int flags) int zmq_msg_recv (zmq_msg_t *msg, void *socket, int flags) 实际上, 对msg的操作是一系列的API Initialise a message: zmq_msg_init(), zmq_msg_init_size(), zmq_msg_init_data(). Sending and receiving a message: zmq_msg_send(), zmq_msg_recv(). Release a message: zmq_msg_close(). Access message content: zmq_msg_data(), zmq_msg_size(), zmq_msg_more(). Work with message properties: zmq_msg_get(), zmq_msg_set(). Message manipulation: zmq_msg_copy(), zmq_msg_move(). 用户要自己选择合适的\"纯数据\"的表现形式, 比如用gpb/json来序列化等等, 这个zmq不管. 使用msg的要点: You create and pass around zmq_msg_t objects, not blocks of data. To read a message, you use zmq_msg_init() to create an empty message, and then you pass that to zmq_msg_recv(). To write a message from new data, you use zmq_msg_init_size() to create a message and at the same time allocate a block of data of some size. You then fill that data using memcpy, and pass the message to zmq_msg_send(). To release (not destroy) a message, you call zmq_msg_close(). This drops a reference, and eventually ZeroMQ will destroy the message. To access the message content, you use zmq_msg_data(). To know how much data the message contains, use zmq_msg_size(). Do not use zmq_msg_move(), zmq_msg_copy(), or zmq_msg_init_data() unless you read the man pages and know precisely why you need these. After you pass a message to zmq_msg_send(), ØMQ will clear the message, i.e., set the size to zero. You cannot send the same message twice, and you cannot access the message data after sending it. 需要的话, 用zmq_msg_copy()增加引用, 但实际并不拷贝msg内容. 最后一个引用被send成功后, msg会被自动销毁. These rules don’t apply if you use zmq_send() and zmq_recv(), to which you pass byte arrays, not message structures. Frames zmq定义了自己的frame格式. frame是msg的基本承载单元. 一个msg可以包括多个frame. frame的size是确定的 frame的定义在protocol called ZMTP The ZeroMQ Message Transport Protocol (ZMTP) is a transport layer protocol for exchanging messages between two peers over a connected transport layer such as TCP. This document describes ZMTP/2.0. ZMTP delimits the TCP stream as ‘frames’. A message can consist of multiple frames, for purposes of structuring. A frame consists of a flags field, followed by a length field and a frame body of length octets. The length does not include the flags field, nor itself, so an empty frame has a length of zero. Bit 0 (MORE): More frames to follow. A value of 0 indicates that there are no more frames to follow. A value of 1 indicates that more frames will follow. On messages consisting of a single frame the MORE bit MUST be 0. Bit 1 (LONG): Long message. A value of 0 indicates that the message length is encoded as a single octet. A value of 1 indicates that the message length is encoded as a 64-bit unsigned integer in network byte order. Bits 2-7: Reserved. Bits 2-7 are reserved for future use and MUST be zero. The following diagram shows the layout of a final frame with a length of 0 to 255 octets: +-----------------+ Octet 0 | 0 0 0 0 0 0 0 0 | +-----------------+ Octet 1 | Length | +-----------------+- ... -----------------+ Octets 2+ | Body Length octets | +------------------- ... -----------------+ The following diagram shows the layout of a final LONG frame: +-----------------+ Octet 0 | 0 0 0 0 0 0 1 0 | +-----------------+ Octets 1-8 | Length 8 octets | +------------------ ... ------------------+ Octets 9+ | Body Length octets | +------------------ ... ------------------+ 概念点: A message can be one or more parts. These parts are also called “frames”. Each part is a zmq_msg_t object. You send and receive each part separately, in the low-level API. Higher-level APIs provide wrappers to send entire multipart messages. 使用要点: You may send zero-length messages, e.g., for sending a signal from one thread to another. ZeroMQ guarantees to deliver all the parts (one or more) for a message, or none of them. ZeroMQ does not send the message (single or multipart) right away, but at some indeterminate later time. A multipart message must therefore fit in memory. A message (single or multipart) must fit in memory. If you want to send files of arbitrary sizes, you should break them into pieces and send each piece as separate single-part messages. Using multipart data will not reduce memory consumption. You must call zmq_msg_close() when finished with a received message, in languages that don’t automatically destroy objects when a scope closes. You don’t call this method after sending a message. 兼容性 PAIR accepts connections from PAIR. PUB accepts connections from SUB. SUB accepts connections from PUB. REQ accepts connections from REP or ROUTER. REP accepts connections from REQ or DEALER. DEALER accepts connections from REP, DEALER, or ROUTER. ROUTER accepts connections from REQ, DEALER, or ROUTER. PULL accepts connections from PUSH. PUSH accepts connections from PULL. IO thread和context IO thread从属于context. 一个context创建的时候, 就默认启动了一个IO thread. 其后从属于context创建的socket们, 共同使用这个IO thread.有个apizmq_ctx_set (context, ZMQ_IO_THREADS, io_threads);可以更改io thread的个数. zmq_poll()函数 如果一个zmq的socket有多个对端, 我们想同时读怎么办?一般用zmq_poll(), 比如把poll包装在框架里, 框架分发event, 应用侧代码只负责react. 用户需要自己实现基于zmq的事件驱动框架, zmq不提供这个框架. An even better way might be to wrap zmq_poll() in a framework that turns it into a nice event-driven reactor, but it’s significantly more work than we want to cover here. 不用poll // // Reading from multiple sockets // This version uses a simple recv loop // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"time\" ) func main() { context, _ := zmq.NewContext() defer context.Close() // Connect to task ventilator receiver, _ := context.NewSocket(zmq.PULL) defer receiver.Close() receiver.Connect(\"tcp://localhost:5557\") // Connect to weather server subscriber, _ := context.NewSocket(zmq.SUB) defer subscriber.Close() subscriber.Connect(\"tcp://localhost:5556\") subscriber.SetSubscribe(\"10001\") // Process messages from both sockets // We prioritize traffic from the task ventilator for { // ventilator for b, _ := receiver.Recv(zmq.NOBLOCK); b != nil; { // fake process task } // weather server for b, _ := subscriber.Recv(zmq.NOBLOCK); b != nil; { // process task fmt.Printf(\"found weather =%s\\n\", string(b)) } // No activity, so sleep for 1 msec time.Sleep(1e6) } fmt.Println(\"done\") } 在循环里非阻塞读, 每轮傻傻的sleep 1ms. 使用poll // // Reading from multiple sockets // This version uses zmq.Poll() // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" ) func main() { context, _ := zmq.NewContext() defer context.Close() // Connect to task ventilator receiver, _ := context.NewSocket(zmq.PULL) defer receiver.Close() receiver.Connect(\"tcp://localhost:5557\") // Connect to weather server subscriber, _ := context.NewSocket(zmq.SUB) defer subscriber.Close() subscriber.Connect(\"tcp://localhost:5556\") subscriber.SetSubscribe(\"10001\") pi := zmq.PollItems{ zmq.PollItem{Socket: receiver, Events: zmq.POLLIN}, zmq.PollItem{Socket: subscriber, Events: zmq.POLLIN}, } // Process messages from both sockets for { _, _ = zmq.Poll(pi, -1) switch { case pi[0].REvents&zmq.POLLIN != 0: // Process task pi[0].Socket.Recv(0) // eat the incoming message case pi[1].REvents&zmq.POLLIN != 0: // Process weather update pi[1].Socket.Recv(0) // eat the incoming message } } fmt.Println(\"done\") } 添加poll item, 不用傻sleep 分片的msg 没仔细看, 详见: https://zguide.zeromq.org/docs/chapter2/#Multipart-Messages 发送方: zmq_msg_send (&message, socket, ZMQ_SNDMORE); ... zmq_msg_send (&message, socket, ZMQ_SNDMORE); ... zmq_msg_send (&message, socket, 0); 接收方: while (1) { zmq_msg_t message; zmq_msg_init (&message); zmq_msg_recv (&message, socket, 0); // Process the message frame ... zmq_msg_close (&message); if (!zmq_msg_more (&message)) break; // Last message frame } 服务发现 服务发现解决的是网络主体间如何知道对方的问题. hard code或者静态配置式的都不算是服务发现. 因为你在写静态配置的时候, 已经知道你的网络的样子了. 比如下面静态配置的网络: 如果简单的增加subscriber是简单的, 每个subscriber写死192.168.55.210:5556就行了.但如果增加publisher呢? 原来的subscriber也要改吗? 用下面的图来解决这个问题: 增加中间人. 这是典型的M:N到M: 1 :N的解耦 那为什么zmq不退出一个默认的中心式的broker? 让网络一开始就是星形的中心结构? 作者对broker是持有谨慎的态度的, 一方面是担心性能, 一方面担心担心故障 You might wonder, if all networks eventually get large enough to need intermediaries, why don’t we simply have a message broker in place for all applications? For beginners, it’s a fair compromise. Just always use a star topology, forget about performance, and things will usually work. However, message brokers are greedy things; in their role as central intermediaries, they become too complex, too stateful, and eventually a problem. 最后抽象的典型模式是: 多对多的client和server 比如每个client连接所有的server, servers都提供同一个服务, 以至于client和哪个server请求, 都是回一样的数据. 多个server扩展了网络的处理能力, 但这样要求每个client都知道所有的server. 可以演化为这种模式:中间人会记住哪个client来的req, 当某个server给出对这个req的回复的时候, 中间人会找到之前记住的client来沿路返回rep. zmq把中间这个转发逻辑抽象成API: int zmq_proxy (const void *frontend, const void *backend, const void *capture) 其他模型 并发支持 简单来说, zmq做了你能想到的所有对并发的支持: we don’t need mutexes, locks, or any other form of inter-thread communication except messages sent across ZeroMQ sockets 作者的基本思想是: 不要共享任何东西, stateless就是最好的并发模型 -- 因为什么都不需要保护 Isolate data privately within its thread and never share data in multiple threads. The only exception to this are ZeroMQ contexts, which are threadsafe.不要共享数据... Stay away from the classic concurrency mechanisms like as mutexes, critical sections, semaphores, etc. These are an anti-pattern in ZeroMQ applications.不要用锁啥的. 和zmq八字不合. Create one ZeroMQ context at the start of your process, and pass that to all threads that you want to connect via inproc sockets. Use attached threads to create structure within your application, and connect these to their parent threads using PAIR sockets over inproc. The pattern is: bind parent socket, then create child thread which connects its socket.在线程间使用inproc socket pair Use detached threads to simulate independent tasks, with their own contexts. Connect these over tcp. Later you can move these to stand-alone processes without changing the code significantly. All interaction between threads happens as ZeroMQ messages, which you can define more or less formally.和go一样, 使用\"通信\"来代替\"共享\" Don’t share ZeroMQ sockets between threads. ZeroMQ sockets are not threadsafe. Technically it’s possible to migrate a socket from one thread to another but it demands skill. The only place where it’s remotely sane to share sockets between threads are in language bindings that need to do magic like garbage collection on sockets.虽然context是并发安全的. 但socket不是. 不要在线程间共享socket. Do not use or close sockets except in the thread that created them.除了创建socket的线程, 不要在另外的线程使用和关闭socket. zmq的应用代码可以run在线程, 进程, 或node上. 通过zmq的抽象, 应用代码面对的是通信编程, 可以方便的在各种环境中扩展. 比如要实现下面的模块: 虚框内是一个进程 // Multithreaded Hello World server. // Uses Goroutines. We could also use channels (a native form of // inproc), but I stuck to the example. // // Author: Brendan Mc. // Requires: http://github.com/alecthomas/gozmq package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"time\" ) func main() { // Launch pool of worker threads for i := 0; i != 5; i = i + 1 { go worker() } // Prepare our context and sockets context, _ := zmq.NewContext() defer context.Close() // Socket to talk to clients clients, _ := context.NewSocket(zmq.ROUTER) //和clients连 defer clients.Close() clients.Bind(\"tcp://*:5555\") // Socket to talk to workers workers, _ := context.NewSocket(zmq.DEALER) defer workers.Close() workers.Bind(\"ipc://workers.ipc\") //应该是unix socket // connect work threads to client threads via a queue zmq.Device(zmq.QUEUE, clients, workers) //这个后面要看一下 } func worker() { context, _ := zmq.NewContext() defer context.Close() // Socket to talk to dispatcher receiver, _ := context.NewSocket(zmq.REP) defer receiver.Close() receiver.Connect(\"ipc://workers.ipc\") for true { received, _ := receiver.Recv(0) fmt.Printf(\"Received request [%s]\\n\", received) // Do some 'work' time.Sleep(time.Second) // Send reply back to client receiver.Send([]byte(\"World\"), 0) } } 解释 The server starts a set of worker threads. Each worker thread creates a REP socket and then processes requests on this socket. Worker threads are just like single-threaded servers. The only differences are the transport (inproc instead of tcp), and the bind-connect direction. The server creates a ROUTER socket to talk to clients and binds this to its external interface (over tcp). The server creates a DEALER socket to talk to the workers and binds this to its internal interface (over inproc). The server starts a proxy that connects the two sockets. The proxy pulls incoming requests fairly from all clients, and distributes those out to workers. It also routes replies back to their origin. pub到已知数量的subscriber 已知subscriber数量, publisher通过REP类型的socket等待所有订阅者连上来(1,2步), 然后发消息(第3步)发布者代码: // Synchronized publisher // // Author: Brendan Mc. // Requires: http://github.com/alecthomas/gozmq package main import ( zmq \"github.com/alecthomas/gozmq\" ) var subsExpected = 10 func main() { context, _ := zmq.NewContext() defer context.Close() // Socket to talk to clients publisher, _ := context.NewSocket(zmq.PUB) defer publisher.Close() publisher.Bind(\"tcp://*:5561\") // Socket to receive signals syncservice, _ := context.NewSocket(zmq.REP) defer syncservice.Close() syncservice.Bind(\"tcp://*:5562\") // Get synchronization from subscribers for i := 0; i 订阅者代码 // Synchronized subscriber // // Author: Aleksandar Janicijevic // Requires: http://github.com/alecthomas/gozmq package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"time\" ) func main() { context, _ := zmq.NewContext() defer context.Close() subscriber, _ := context.NewSocket(zmq.SUB) defer subscriber.Close() subscriber.Connect(\"tcp://localhost:5561\") subscriber.SetSubscribe(\"\") // 0MQ is so fast, we need to wait a while... time.Sleep(time.Second) // Second, synchronize with publisher syncclient, _ := context.NewSocket(zmq.REQ) defer syncclient.Close() syncclient.Connect(\"tcp://localhost:5562\") // - send a synchronization request fmt.Println(\"Send synchronization request\") syncclient.Send([]byte(\"\"), 0) fmt.Println(\"Wait for synchronization reply\") // - wait for synchronization reply syncclient.Recv(0) fmt.Println(\"Get updates\") // Third, get our updates and report how many we got update_nbr := 0 for { reply, _ := subscriber.Recv(0) if string(reply) == \"END\" { break } update_nbr++ } fmt.Printf(\"Received %d updates\\n\", update_nbr) } 用shell起10个订阅者进程, 然后再起发布者进程. echo \"Starting subscribers...\" for ((a=0; a 结果 Starting subscribers... Starting publisher... Received 1000000 updates Received 1000000 updates ... Received 1000000 updates Received 1000000 updates 零拷贝 这里的拷贝是指应用层的发送buffer到zmq的socket之间的拷贝. 零拷贝指发送的时候, 应用层的buffer直接用于zmq的发送, 而不是先拷贝到zmq的buffer, 再发送. To do zero-copy, you use zmq_msg_init_data() to create a message that refers to a block of data already allocated with malloc() or some other allocator, and then you pass that to zmq_msg_send(). When you create the message, you also pass a function that ZeroMQ will call to free the block of data, when it has finished sending the message. This is the simplest example, assuming buffer is a block of 1,000 bytes allocated on the heap: 代码如下: void my_free (void *data, void *hint) { free (data); } // Send message from buffer, which we allocate and ZeroMQ will free for us zmq_msg_t message; zmq_msg_init_data (&message, buffer, 1000, my_free, NULL); zmq_msg_send (&message, socket, 0); Note that you don’t call zmq_msg_close() after sending a message–libzmq will do this automatically when it’s actually done sending the message. pub-sub实际上是msg filter 订阅系统实际上做的是string的prefix match: 在数据里搜索prefix, 匹配到了就是命中订阅. 订阅的filter发生在发送侧.但问题是, 比如prefix是xyz, 如果\"纯数据\"种也有xyz怎么办? -- 用zmq的key和data分离 因为这个prefix的匹配会在msg内搜索, 但不会跨frame. --那么第一个frame来发key, 后面的frame发data就可以了. 这样prefix只会在第一个frame种匹配发布方: // // Pubsub envelope publisher // package main import ( zmq \"github.com/alecthomas/gozmq\" \"time\" ) func main() { context, _ := zmq.NewContext() defer context.Close() publisher, _ := context.NewSocket(zmq.PUB) defer publisher.Close() publisher.Bind(\"tcp://*:5563\") for { publisher.SendMultipart([][]byte{[]byte(\"A\"), []byte(\"We don't want to see this\")}, 0) publisher.SendMultipart([][]byte{[]byte(\"B\"), []byte(\"We would like to see this\")}, 0) time.Sleep(time.Second) } } 订阅方: // // Pubsub envelope subscriber // package main import ( zmq \"github.com/alecthomas/gozmq\" ) func main() { context, _ := zmq.NewContext() defer context.Close() subscriber, _ := context.NewSocket(zmq.SUB) defer subscriber.Close() subscriber.Connect(\"tcp://localhost:5563\") subscriber.SetSubscribe(\"B\") for { address, _ := subscriber.Recv(0) content, _ := subscriber.Recv(0) print(\"[\" + string(address) + \"] \" + string(content) + \"\\n\") } } 如果此时加新需求: 增加多个发布者, 那么可以设计交互格式为: 高水位 作者对于flow control有经典的描述, 详见: https://zguide.zeromq.org/docs/chapter2/#High-Water-Marks作者认为高水线后, 向app发送反压\"stop\"是不好的. 如果A高频率给B发, B由于gc或者CPU load高处理不了, 消息会在这个通信系统上堆积, A的应用侧也会有消息堆积. ZeroMQ uses the concept of HWM (high-water mark) to define the capacity of its internal pipes. Each connection out of a socket or into a socket has its own pipe, and HWM for sending, and/or receiving, depending on the socket type. Some sockets (PUB, PUSH) only have send buffers. Some (SUB, PULL, REQ, REP) only have receive buffers. Some (DEALER, ROUTER, PAIR) have both send and receive buffers.In ZeroMQ v3.x, it’s set to 1,000 by defaultzmq内部也使用高水线定义buffer的容量. 默认是10000个msg. When your socket reaches its HWM, it will either block or drop data depending on the socket type. PUB and ROUTER sockets will drop data if they reach their HWM, while other socket types will block. Over the inproc transport, the sender and receiver share the same buffers, so the real HWM is the sum of the HWM set by both sides.到达高水线后, 不同的socket type的策略不同: PUB和ROUTER类型的是丢弃; 而其他类型是阻塞. 丢包怎么定位? 见这里: https://zguide.zeromq.org/docs/chapter2/#Missing-Message-Problem-Solver要点: On SUB sockets, set a subscription using zmq_setsockopt()ZMQ_SUBSCRIBE, or you won’t get messages. Because you subscribe to messages by prefix, if you subscribe to \"” (an empty subscription), you will get everything. If you start the SUB socket (i.e., establish a connection to a PUB socket) after the PUB socket has started sending out data, you will lose whatever it published before the connection was made. If this is a problem, set up your architecture so the SUB socket starts first, then the PUB socket starts publishing. Even if you synchronize a SUB and PUB socket, you may still lose messages. It’s due to the fact that internal queues aren’t created until a connection is actually created. If you can switch the bind/connect direction so the SUB socket binds, and the PUB socket connects, you may find it works more as you’d expect. If you’re using REP and REQ sockets, and you’re not sticking to the synchronous send/recv/send/recv order, ZeroMQ will report errors, which you might ignore. Then, it would look like you’re losing messages. If you use REQ or REP, stick to the send/recv order, and always, in real code, check for errors on ZeroMQ calls. If you’re using PUSH sockets, you’ll find that the first PULL socket to connect will grab an unfair share of messages. The accurate rotation of messages only happens when all PULL sockets are successfully connected, which can take some milliseconds. As an alternative to PUSH/PULL, for lower data rates, consider using ROUTER/DEALER and the load balancing pattern. If you’re sharing sockets across threads, don’t. It will lead to random weirdness, and crashes. If you’re using inproc, make sure both sockets are in the same context. Otherwise the connecting side will in fact fail. Also, bind first, then connect. inproc is not a disconnected transport like tcp. If you’re using ROUTER sockets, it’s remarkably easy to lose messages by accident, by sending malformed identity frames (or forgetting to send an identity frame). In general setting the ZMQ_ROUTER_MANDATORY option on ROUTER sockets is a good idea, but do also check the return code on every send call. Lastly, if you really can’t figure out what’s going wrong, make a minimal test case that reproduces the problem, and ask for help from the ZeroMQ community. 消息交互模式 zmq文档中有详细解释 核心的交互模式有4种: Request-reply, which connects a set of clients to a set of services. This is a remote procedure call and task distribution pattern. rpc或通常的client server Pub-sub, which connects a set of publishers to a set of subscribers. This is a data distribution pattern. 订阅-发布 Pipeline, which connects nodes in a fan-out/fan-in pattern that can have multiple steps and loops. This is a parallel task distribution and collection pattern. 这就是例子push-pull Exclusive pair, which connects two sockets exclusively. This is a pattern for connecting two threads in a process, not to be confused with “normal” pairs of sockets. 线程间的socket对. socket类型配对: PUB and SUB REQ and REP REQ and ROUTER (take care, REQ inserts an extra null frame) DEALER and REP (take care, REP assumes a null frame) DEALER and ROUTER DEALER and DEALER ROUTER and ROUTER PUSH and PULL PAIR and PAIR PAIR类型 对于线程间的\"共享\", zmq的策略是不要用锁啥的, 用zmq的通信机制. use PAIR sockets over the inproc transport 比如下面这个模型: // Multithreaded relay. // Uses Goroutines. We could also use channels (a native form of // inproc), but I stuck to the example. // // Author: Brendan Mc. // Requires: http://github.com/alecthomas/gozmq package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" ) func main() { // Prepare our context and sockets context, _ := zmq.NewContext() defer context.Close() // Bind inproc socket before starting step2 receiver, _ := context.NewSocket(zmq.PAIR) defer receiver.Close() receiver.Bind(\"ipc://step3.ipc\") go step2() // Wait for signal receiver.Recv(0) fmt.Println(\"Test successful!\") } func step1() { // Connect to step2 and tell it we're ready context, _ := zmq.NewContext() defer context.Close() xmitter, _ := context.NewSocket(zmq.PAIR) defer xmitter.Close() xmitter.Connect(\"ipc://step2.ipc\") fmt.Println(\"Step 1 ready, signaling step 2\") xmitter.Send([]byte(\"READY\"), 0) } func step2() { context, _ := zmq.NewContext() defer context.Close() // Bind inproc before starting step 1 receiver, _ := context.NewSocket(zmq.PAIR) defer receiver.Close() receiver.Bind(\"ipc://step2.ipc\") go step1() // wait for signal and pass it on receiver.Recv(0) // Connect to step3 and tell it we're ready xmitter, _ := context.NewSocket(zmq.PAIR) defer xmitter.Close() xmitter.Connect(\"ipc://step3.ipc\") fmt.Println(\"Step 2 ready, singaling step 3\") xmitter.Send([]byte(\"READY\"), 0) } 注意这里的go的例子, 用的是ipc的transport类型, 而实际上, 这里要表达的是inproc的transport类型, 似乎这个文档的当时还不支持go的inproc transport? 下面是c版本: // Multithreaded relay #include \"zhelpers.h\" #include static void * step1 (void *context) { // Connect to step2 and tell it we're ready void *xmitter = zmq_socket (context, ZMQ_PAIR); zmq_connect (xmitter, \"inproc://step2\"); printf (\"Step 1 ready, signaling step 2\\n\"); s_send (xmitter, \"READY\"); zmq_close (xmitter); return NULL; } static void * step2 (void *context) { // Bind inproc socket before starting step1 void *receiver = zmq_socket (context, ZMQ_PAIR); zmq_bind (receiver, \"inproc://step2\"); pthread_t thread; pthread_create (&thread, NULL, step1, context); // Wait for signal and pass it on char *string = s_recv (receiver); free (string); zmq_close (receiver); // Connect to step3 and tell it we're ready void *xmitter = zmq_socket (context, ZMQ_PAIR); zmq_connect (xmitter, \"inproc://step3\"); printf (\"Step 2 ready, signaling step 3\\n\"); s_send (xmitter, \"READY\"); zmq_close (xmitter); return NULL; } int main (void) { void *context = zmq_ctx_new (); // Bind inproc socket before starting step2 void *receiver = zmq_socket (context, ZMQ_PAIR); zmq_bind (receiver, \"inproc://step3\"); pthread_t thread; pthread_create (&thread, NULL, step2, context); // Wait for signal char *string = s_recv (receiver); free (string); zmq_close (receiver); printf (\"Test successful!\\n\"); zmq_ctx_destroy (context); return 0; } 注意用inproc类型的transport的主要场景是低延迟, 高性能. 但这个类型的transport扩展性不好. 如果是用tcp或者是ipc, 多线程的模型可以很轻易的breakdown到多进程. 为社么要用pair You can use PUSH for the sender and PULL for the receiver. This looks simple and will work, but remember that PUSH will distribute messages to all available receivers. If you by accident start two receivers (e.g., you already have one running and you start a second), you’ll “lose” half of your signals. PAIR has the advantage of refusing more than one connection; the pair is exclusive. You can use DEALER for the sender and ROUTER for the receiver. ROUTER, however, wraps your message in an “envelope”, meaning your zero-size signal turns into a multipart message. If you don’t care about the data and treat anything as a valid signal, and if you don’t read more than once from the socket, that won’t matter. If, however, you decide to send real data, you will suddenly find ROUTER providing you with “wrong” messages. DEALER also distributes outgoing messages, giving the same risk as PUSH. You can use PUB for the sender and SUB for the receiver. This will correctly deliver your messages exactly as you sent them and PUB does not distribute as PUSH or DEALER do. However, you need to configure the subscriber with an empty subscription, which is annoying. req-rep 典型的rpc模式或最常用的client-server模式, 同步的. 按作者的说法是, lock-step:从示例代码来看 server端 // // Hello World Zeromq server // // Author: Aaron Raddon github.com/araddon // Requires: http://github.com/alecthomas/gozmq // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"time\" ) func main() { context, _ := zmq.NewContext() socket, _ := context.NewSocket(zmq.REP) //REP类型, server侧 defer context.Close() defer socket.Close() socket.Bind(\"tcp://*:5555\") // Wait for messages for { msg, _ := socket.Recv(0) println(\"Received \", string(msg)) // do some fake \"work\" time.Sleep(time.Second) // send reply back to client reply := fmt.Sprintf(\"World\") socket.Send([]byte(reply), 0) } } 从server的app角度看: server只\"监听\"tcp://*:5555的数据 zmq对app屏蔽了listen, accept过程, app看不到数据通道的socket. 那么在app看来, 它不知道对端client是谁. 很可能这次recv的数据, 和下次recv的数据, 都不是一个client发过来的.-- 所以作者提到lockstep: 本次recv的东西要马上处理, 马上send, 才能保证两次操作是对一个client. 这里zmq的示例代码是典型的同步结构.或者说是框架代码和app代码混在一起的.作者专门提到: Now this looks too simple to be realistic, but ZeroMQ sockets have, as we already learned, superpowers. You could throw thousands of clients at this server, all at once, and it would continue to work happily and quickly. For fun, try starting the client and then starting the server, see how it all still works, then think for a second what this means. 这个看起来简单的server代码, 可以同时支持上千个client发起请求; 即使先启动client, 再启动server, 还能正常工作. -- 似乎暗示了zmq为client侧提供的lib库有缓存msg功能. client端 // // Hello World Zeromq Client // // Author: Aaron Raddon github.com/araddon // Requires: http://github.com/alecthomas/gozmq // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" ) func main() { context, _ := zmq.NewContext() socket, _ := context.NewSocket(zmq.REQ) //REQ类型, client侧 defer context.Close() defer socket.Close() fmt.Printf(\"Connecting to hello world server...\") socket.Connect(\"tcp://localhost:5555\") for i := 0; i client的关键操作是socket.Connect(\"tcp://localhost:5555\"), 从此这个socket代表了和server的连接.说明从app的角度看: client是持有server连接信息的 client send后马上recv, 虽然不是rcp的call形式, 但这里必须是\"lockstep\"式的同步等. 因为过了这个点, app就不知道reply对应的是那个request. pub-sub 一个pub, 多个sub. 复制消息, 异步模式 subcriber需要用zmq_setsockopt()来订阅一个string关键词.sub的\"socket\"是只读的, pub的\"socket\"是只写的.虽然理论上client也可以pub, 但一般都是server pub, client来订阅.从下面作者的描述来看: A subscriber can connect to more than one publisher, using one connect call each time. Data will then arrive and be interleaved (“fair-queued”) so that no single publisher drowns out the others.一个subscriber可以从多个publisher来订阅. 从这个sub的\"socket\"读能读到所有订阅的消息. 从多个publisher来的消息交叉放置在socket里 If a publisher has no connected subscribers, then it will simply drop all messages.如果没有人订阅, publisher会丢弃所有消息. -- 说明订阅者是直接和发布者有真正的socket连接的, publisher都知道. If you’re using TCP and a subscriber is slow, messages will queue up on the publisher. We’ll look at how to protect publishers against this using the “high-water mark” later.如果是远端机器上的慢速subscriber, 那消息会在publisher侧拥塞. -- 更加说明了没有\"中间人\"来转发. From ZeroMQ v3.x, filtering happens at the publisher side when using a connected protocol (tcp或ipc). Using the epgm protocol, filtering happens at the subscriber side. In ZeroMQ v2.x, all filtering happened at the subscriber side.zmq的2.0版本, filtering发生在接收方; 而zmq3.0版本, filtering发生在发送方. server侧 // // Weather update server // Binds PUB socket to tcp://*:5556 // Publishes random weather updates // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"math/rand\" \"time\" ) func main() { context, _ := zmq.NewContext() socket, _ := context.NewSocket(zmq.PUB) //注意这里指明了PUB类型 defer context.Close() defer socket.Close() socket.Bind(\"tcp://*:5556\") socket.Bind(\"ipc://weather.ipc\") //似乎PUB类型能绑定多个地址? // Seed the random number generator rand.Seed(time.Now().UnixNano()) // loop for a while aparently for { // make values that will fool the boss zipcode := rand.Intn(100000) temperature := rand.Intn(215) - 80 relhumidity := rand.Intn(50) + 10 msg := fmt.Sprintf(\"%d %d %d\", zipcode, temperature, relhumidity) // Send message to all subscribers socket.Send([]byte(msg), 0) } } client侧 // // Weather proxy listens to weather server which is constantly // emitting weather data // Binds SUB socket to tcp://*:5556 // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"os\" \"strconv\" \"strings\" ) func main() { context, _ := zmq.NewContext() socket, _ := context.NewSocket(zmq.SUB) //SUB类型 defer context.Close() defer socket.Close() var temps []string var err error var temp int64 total_temp := 0 filter := \"59937\" // find zipcode if len(os.Args) > 1 { // ./wuclient 85678 filter = string(os.Args[1]) } // Subscribe to just one zipcode (whitefish MT 59937) fmt.Printf(\"Collecting updates from weather server for %s…\\n\", filter) socket.SetSubscribe(filter) //订阅实际就是filter socket.Connect(\"tcp://localhost:5556\") for i := 0; i push-pull zmq的push和pull模式用于生产 消费系统push生产, pull来消费. 可以一个push, 多个pull. 但很显然, push的消息不会复制广播给每个puller A ventilator that produces tasks that can be done in parallel A set of workers that process tasks A sink that collects results back from the worker processes push和pull没有固定的server client角色, client也可以pull, 也可以push. 这里的所有框框都是独立的进程. 生产者 ventilator // // Task ventilator // Binds PUSH socket to tcp://localhost:5557 // Sends batch of tasks to workers via that socket // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"math/rand\" \"time\" ) func main() { context, _ := zmq.NewContext() defer context.Close() // Socket to send messages On sender, _ := context.NewSocket(zmq.PUSH) defer sender.Close() sender.Bind(\"tcp://*:5557\") // Socket to send start of batch message on sink, _ := context.NewSocket(zmq.PUSH) defer sink.Close() sink.Connect(\"tcp://localhost:5558\") fmt.Print(\"Press Enter when the workers are ready: \") var line string fmt.Scanln(&line) fmt.Println(\"Sending tasks to workers…\") sink.Send([]byte(\"0\"), 0) // Seed the random number generator rand.Seed(time.Now().UnixNano()) total_msec := 0 for i := 0; i 消费者worker // // Task Wroker // Connects PULL socket to tcp://localhost:5557 // Collects workloads from ventilator via that socket // Connects PUSH socket to tcp://localhost:5558 // Sends results to sink via that socket // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"strconv\" \"time\" ) func main() { context, _ := zmq.NewContext() defer context.Close() // Socket to receive messages on receiver, _ := context.NewSocket(zmq.PULL) defer receiver.Close() receiver.Connect(\"tcp://localhost:5557\") // Socket to send messages to task sink sender, _ := context.NewSocket(zmq.PUSH) defer sender.Close() sender.Connect(\"tcp://localhost:5558\") // Process tasks forever for { msgbytes, _ := receiver.Recv(0) fmt.Printf(\"%s.\\n\", string(msgbytes)) // Do the work msec, _ := strconv.ParseInt(string(msgbytes), 10, 64) time.Sleep(time.Duration(msec) * 1e6) // Send results to sink sender.Send([]byte(\"\"), 0) } } sink // // Task sink // Binds PULL socket to tcp://localhost:5558 // Collects results from workers via that socket // package main import ( \"fmt\" zmq \"github.com/alecthomas/gozmq\" \"time\" ) func main() { context, _ := zmq.NewContext() defer context.Close() // Socket to receive messages on receiver, _ := context.NewSocket(zmq.PULL) defer receiver.Close() receiver.Bind(\"tcp://*:5558\") // Wait for start of batch msgbytes, _ := receiver.Recv(0) fmt.Println(\"Received Start Msg \", string(msgbytes)) // Start our clock now start_time := time.Now().UnixNano() // Process 100 confirmations for i := 0; i 总结 The workers connect upstream to the ventilator, and downstream to the sink. This means you can add workers arbitrarily. If the workers bound to their endpoints, you would need (a) more endpoints and (b) to modify the ventilator and/or the sink each time you added a worker. We say that the ventilator and sink are stable parts of our architecture and the workers are dynamic parts of it.worker对上对下都是client, 所以worker能够动态的添加. 而上下两层都是server, 架构上是稳定的. We have to synchronize the start of the batch with all workers being up and running. This is a fairly common gotcha in ZeroMQ and there is no easy solution. The zmq_connect method takes a certain time. So when a set of workers connect to the ventilator, the first one to successfully connect will get a whole load of messages in that short time while the others are also connecting. If you don’t synchronize the start of the batch somehow, the system won’t run in parallel at all. Try removing the wait in the ventilator, and see what happens.如果生产者ventilator不等所有worker连接成功, 那在第一个连上的worker会收到大量的work. 而其他的worker还在连接中. zmq的经验是, 建立连接需要ms级的时间, 这个时间内足够大量的消息交互了. -- 可能说的是跨机器跨网络的场景. The ventilator’s PUSH socket distributes tasks to workers (assuming they are all connected before the batch starts going out) evenly. This is called load balancing and it’s something we’ll look at again in more detail.load balance发生在生产者即ventilator里面 The sink’s PULL socket collects results from workers evenly. This is called fair-queuing.sinker收集结果的时候, 从每个worker公平的收集. 公平队列 context 上面go代码中, 首先要建个context, socket是从属于context的. zmq建议: 每个进程一个context. You should create and use exactly one context in your process. Technically, the context is the container for all sockets in a single process, and acts as the transport for inproc sockets, which are the fastest way to connect threads in one process. pipeline fanout 灵魂几问 https://zguide.zeromq.org/docs/chapter1/#Why-We-Needed-ZeroMQ摘要如下: 阻塞还是异步? 阻塞性能不佳, 异步很难搞对. How do we handle I/O? Does our application block, or do we handle I/O in the background? This is a key design decision. Blocking I/O creates architectures that do not scale well. But background I/O can be very hard to do right.How do we handle I/O? Does our application block, or do we handle I/O in the background? This is a key design decision. Blocking I/O creates architectures that do not scale well. But background I/O can be very hard to do right. 谁当server谁当client? 需要server永远在吗? 需要断线重连吗? 怎么在wire上表示一个message? 我觉得用结构体, 或者tengo中的Object抽象 如果对端没准备好的时候, 要发送的数据缓存在哪里? 拥塞控制策略? 消息丢失怎么办? 要保证送达吗? 如果有新的transport方法怎么办? app要改吗? 比如增加支持yipc? What if we need to use a different network transport. Say, multicast instead of TCP unicast? Or IPv6? Do we need to rewrite the applications, or is the transport abstracted in some layer? 消息怎么路由? How do we route messages? Can we send the same message to multiple peers? Can we send replies back to an original requester? 多语言怎么适配? encoding怎么选择? 网络错误怎么处理? 作者观点 消息处理框架不好搞. 很多人越高越复杂, 故障率越高. 这包括了broker概念的发明和广泛使用. 在带来方便的同时, broker也有很多问题, 比如broker系统本身需要人维护, 只适合大型系统.对中小型的系统开发来说, 通常的结局作者已经预言了: Either they avoid network programming and make monolithic applications that do not scale. Or they jump into network programming and make brittle, complex applications that are hard to maintain. Or they bet on a messaging product, and end up with scalable applications that depend on expensive, easily broken technology.不是自己瞎搞, 就是赌上一个新技术来瞎搞. 作者认为的理想消息系统: What we need is something that does the job of messaging, but does it in such a simple and cheap way that it can work in any application, with close to zero cost. It should be a library which you just link, without any other dependencies. No additional moving pieces, so no additional risk. It should run on any OS and work with any programming language. 只是个库, 简单, 高效, 没有其他的比如broker, 消息中心等独立实体. It handles I/O asynchronously, in background threads. These communicate with application threads using lock-free data structures, so concurrent ZeroMQ applications need no locks, semaphores, or other wait states.背景线程处理异步IO, 无锁设计. app层不关心锁 Components can come and go dynamically and ZeroMQ will automatically reconnect. This means you can start components in any order. You can create “service-oriented architectures” (SOAs) where services can join and leave the network at any time.自动重连 It queues messages automatically when needed. It does this intelligently, pushing messages as close as possible to the receiver before queuing them.自动缓存消息 It has ways of dealing with over-full queues (called “high water mark”). When a queue is full, ZeroMQ automatically blocks senders, or throws away messages, depending on the kind of messaging you are doing (the so-called “pattern”).拥塞时有考虑 It lets your applications talk to each other over arbitrary transports: TCP, multicast, in-process, inter-process. You don’t need to change your code to use a different transport.多transport支持: tcp, 多播, 进程间, 线程间 It handles slow/blocked readers safely, using different strategies that depend on the messaging pattern.还是关于拥塞的 It lets you route messages using a variety of patterns such as request-reply and pub-sub. These patterns are how you create the topology, the structure of your network.支持多模式, 比如req-rep, pub-sub等等 It lets you create proxies to queue, forward, or capture messages with a single call. Proxies can reduce the interconnection complexity of a network.支持proxy来做转发, 转存, 抓包等 It delivers whole messages exactly as they were sent, using a simple framing on the wire. If you write a 10k message, you will receive a 10k message.消息级别传输. 而不是报文级别 It does not impose any format on messages. They are blobs from zero to gigabytes large. When you want to represent data you choose some other product on top, such as msgpack, Google’s protocol buffers, and others.从zmq级别来看, zmq不对传输的数据做包装. It handles network errors intelligently, by retrying automatically in cases where it makes sense.对网络错误有一套处理 zmq底层是背景线程管理的\"连接\" In the ZeroMQ universe, sockets are doorways to fast little background communications engines that manage a whole set of connections automagically for you. You can’t see, work with, open, close, or attach state to these connections. Whether you use blocking send or receive, or poll, all you can talk to is the socket, not the connections it manages for you. The connections are private and invisible, and this is the key to ZeroMQ’s scalability. This is because your code, talking to a socket, can then handle any number of connections across whatever network protocols are around, without change. A messaging pattern sitting in ZeroMQ scales more cheaply than a messaging pattern sitting in your application code. zmq对app提供的socket不是原始的os级别socket, 而是os.socket+os.thread组成的一套系统. zero mq(zmq, 0mq) https://zeromq.org/get-started/ https://lwn.net/Articles/466304/ 概念: http://zguide.zeromq.org/page:all http://zguide.zeromq.org/page:chapter1 纯go实现zero mq https://github.com/zeromq/gomq https://github.com/go-zeromq/zmq4 cgo版本: https://github.com/zeromq/goczmq https://github.com/pebbe/zmq4 zero mq api: http://api.zeromq.org/2-1:zmq-connect 问题: REQ-REP模式下的RPC, 怎么把异步同步化的? 比如socket send后, 怎么等待socket recv? 最简单的send, 原地recv可以, 但并发场景呢? 我记得在哪里看到过, 思路有点像channel in channel. 但client方需要有个守护routine, 收到REP后, 给对应的goroutine发channel zmq使用最基本的模式, send后马上recv client代码 // Hello World client #include #include #include #include int main (void) { printf (\"Connecting to hello world server...\\n\"); void *context = zmq_ctx_new (); void *requester = zmq_socket (context, ZMQ_REQ); zmq_connect (requester, \"tcp://localhost:5555\"); int request_nbr; for (request_nbr = 0; request_nbr != 10; request_nbr++) { char buffer [10]; printf (\"Sending Hello %d...\\n\", request_nbr); //先send zmq_send (requester, \"Hello\", 5, 0); //原地recv zmq_recv (requester, buffer, 10, 0); printf (\"Received World %d\\n\", request_nbr); } zmq_close (requester); zmq_ctx_destroy (context); return 0; } server侧代码 // Hello World server #include #include #include #include #include int main (void) { // Socket to talk to clients void *context = zmq_ctx_new (); void *responder = zmq_socket (context, ZMQ_REP); int rc = zmq_bind (responder, \"tcp://*:5555\"); assert (rc == 0); while (1) { char buffer [10]; //先接收 zmq_recv (responder, buffer, 10, 0); printf (\"Received Hello\\n\"); sleep (1); // Do some 'work' //再发送 zmq_send (responder, \"World\", 5, 0); } return 0; } 在这个基本模式下, zmq不允许同时发REQ: The REQ-REP socket pair is in lockstep. The client issues zmq_send() and then zmq_recv(), in a loop (or once if that’s all it needs). Doing any other sequence (e.g., sending two messages in a row) will result in a return code of -1 from the send or recv call. go标准库的rpc 在src/net/rpc/client.go中, client支持同时多个REQ并发发送到server, 怎么做到的? // Client represents an RPC Client. // There may be multiple outstanding Calls associated // with a single Client, and a Client may be used by // multiple goroutines simultaneously. type Client struct { codec ClientCodec reqMutex sync.Mutex // protects following request Request mutex sync.Mutex // protects following //秘诀在seq和后面的pending map seq uint64 pending map[uint64]*Call closing bool // user has called Close shutdown bool // server has told us to stop } 在send的时候 func (client *Client) send(call *Call) { client.mutex.Lock() //在加锁的情况下, 把seq++并加到map中 seq := client.seq client.seq++ client.pending[seq] = call client.mutex.Unlock() //发送 client.request.Seq = seq client.codec.WriteRequest(&client.request, call.Args) } 这里面的Call是这次RPC调用的抽象: // Call represents an active RPC. type Call struct { ServiceMethod string // The name of the service and method to call. Args interface{} // The argument to the function (*struct). Reply interface{} // The reply from the function (*struct). Error error // After completion, the error status. Done chan *Call // Strobes when call is complete. } 好了, 下面看看client.Call // Call invokes the named function, waits for it to complete, and returns its error status. func (client *Client) Call(serviceMethod string, args interface{}, reply interface{}) error { call := Go函数里面, 实例化一个Call, 和一个channel, send这个Call给server, 返回这个channel. 注意, Go函数并不等待server的REP过来. // Go invokes the function asynchronously. It returns the Call structure representing // the invocation. The done channel will signal when the call is complete by returning // the same Call object. If done is nil, Go will allocate a new channel. // If non-nil, done must be buffered or Go will deliberately crash. func (client *Client) Go(serviceMethod string, args interface{}, reply interface{}, done chan *Call) *Call { call := new(Call) call.ServiceMethod = serviceMethod call.Args = args call.Reply = reply if done == nil { done = make(chan *Call, 10) // buffered. } else { // If caller passes done != nil, it must arrange that // done has enough buffer for the number of simultaneous // RPCs that will be using that channel. If the channel // is totally unbuffered, it's best not to run at all. if cap(done) == 0 { log.Panic(\"rpc: done channel is unbuffered\") } } call.Done = done client.send(call) return call } 等待发生在Go函数里面, 等待这个返回的channel. 好了, 但是哪里写这个channel呢? 每个client都启动了一个守护goroutine, 叫input // NewClientWithCodec is like NewClient but uses the specified // codec to encode requests and decode responses. func NewClientWithCodec(codec ClientCodec) *Client { client := &Client{ codec: codec, pending: make(map[uint64]*Call), } go client.input() return client } 前面说过了, client.Call函数只是调用了send, 然后等待在chennel上. 没有调用recv 是这个input routine不断的调用recv来收包的. func (client *Client) input() { for { response = Response{} //recv收header err = client.codec.ReadResponseHeader(&response) //包头里面由seq号 seq := response.Seq client.mutex.Lock() //根据seq号找到call channel call := client.pending[seq] delete(client.pending, seq) client.mutex.Unlock() //读Reply client.codec.ReadResponseBody(call.Reply) //这个函数写channel, 通知client.Call停止等待 call.done() } } 总结: send之前实例化一个call结构体, 用来传递信息. 同时实例化一个channel(每个call一个). 发送的时候, 每个req都有个序号, 这个序号和call是一一对应的, 把这个对应关系保存在map里. client等待在这个channel. server端把seq原封不动的搬到reply的header里面: resp.Seq = req.Seq 有个input goroutine不断的读socket, 把header里面包含的seq序号, 通过map查到pending的call结构体. 读reply到这个call结构体, 写channel通知client本次call完成. 问题和改进思路 个人感觉这个RPC写的一般, 很啰嗦, 用seq和map来记录每个call, server会原封不动的把seq返回来, client再根据seq号查找到本次call实例. 这里面有map的hash计算, 扩容等等性能不好的地方.我的想法是, 既然server要把client发送的seq号原封不动的返回, 何不在client直接\"封装\"chennel信息, server端还是原封不动返回, 这样client的input守护routine在收到回复报文的时候, 就可以直接用这个channel了, 省掉了hash map.但input守护routine是没有办法省掉的. 这和routine之间channel in channel的RPC不同, 因为socket RPC跨了进程. "},"notes/golang_mango.html":{"url":"notes/golang_mango.html","title":"消息中间件mango","keywords":"","body":" 库地址 代码走读 接口抽象 socket.go socket context options.go pipe.go message.go message pool msg对象的buffer管理 protocol.go 离用户最近的NewSocket transport.go TranPipe本质上是连接conn transport是NewDialer和NewListener和命名方式的组合 TranDialer TranListener 总结 顶层listener.go和dialer.go device.go transport transport/transport.go transport/handshaker.go transport/conn.go recv和send写的很有水平 发送接收总结 option函数就是字符串版本的ioctl header和同步协议握手 后台握手接口 transport/tcp/tcp.go NewDialer和NewListener dialer listener adress和close Set和Get Option 总结 transport小节 transport/inproc/inproc.go 全局listener表 Listen Accept Dial Send和Recv 总结 transport/ipc internal/core internal/core/socket.go NewDialer和NewListener socket具体定义 核心动作: addPipe send和recv internal/core/pipe.go pipe定义 pipeList addPipe和ID生成 pipe的send和recv 为什么底层send或者recv失败要close掉pipe? 携带额外数据的典型模式: SetPrivate internal/core/dialer.go internal/core/listener.go 总结 protocol protocol/req/req.go 核心结构体定义 为什么要有context? req的SendMsg 发送小节 NewSocket AddPipe方法 RecvMsg receiver()函数 接收小结 REQ小结 protocol/rep/rep.go NewSocket AddPipe 每个连接一个sender 每个连接一个receiver RecvMsg SendMsg REP小节 req rep疑问 xreq和xrep xreq xrep 再看核心层的核心价值 总结 库地址 https://github.com/nanomsg/mangos.git mangos是nanomsg的纯go版本实现. Mangos™ is an implementation in pure Go of the SP (“Scalability Protocols”) messaging system. These are colloquially known as a “nanomsg”. The design is intended to make it easy to add new transports with almost trivial effort, as well as new topologies (“protocols” in SP parlance.) At present, all of the Req/Rep, Pub/Sub, Pair, Bus, Push/Pull, and Surveyor/Respondent patterns are supported. This project also supports an experimental protocol called Star. 代码走读 mangos的顶层go文件, 是典型的抽象定义模式: 先在顶层定义好抽象, 子文件夹管实现. 这是自顶向下的设计方法. 接口抽象 socket.go socket.go提供了socket的抽象. 这里的socket是zeroMQ的socket概念, 是对更底层\"socket\"的场景化抽象. socket是应用侧访问这个SP system的接口. socket.go是对internal/core/socket.go的对外呈现, core的socket.go是实现者. socket 接口设计的很简洁, 符合zeroMQ类似的抽象. // Socket is the main access handle applications use to access the SP // system. It is an abstraction of an application's \"connection\" to a // messaging topology. Applications can have more than one Socket open // at a time. type Socket interface { // Info returns information about the protocol (numbers and names) // and peer protocol. Info() ProtocolInfo // Close closes the open Socket. Further operations on the socket // will return ErrClosed. Close() error // Send puts the message on the outbound send queue. It blocks // until the message can be queued, or the send deadline expires. // If a queued message is later dropped for any reason, // there will be no notification back to the application. Send([]byte) error // Recv receives a complete message. The entire message is received. Recv() ([]byte, error) // SendMsg puts the message on the outbound send. It works like Send, // but allows the caller to supply message headers. AGAIN, the Socket // ASSUMES OWNERSHIP OF THE MESSAGE. SendMsg(*Message) error // RecvMsg receives a complete message, including the message header, // which is useful for protocols in raw mode. RecvMsg() (*Message, error) // Dial connects a remote endpoint to the Socket. The function // returns immediately, and an asynchronous goroutine is started to // establish and maintain the connection, reconnecting as needed. // If the address is invalid, then an error is returned. Dial(addr string) error DialOptions(addr string, options map[string]interface{}) error // NewDialer returns a Dialer object which can be used to get // access to the underlying configuration for dialing. NewDialer(addr string, options map[string]interface{}) (Dialer, error) // Listen connects a local endpoint to the Socket. Remote peers // may connect (e.g. with Dial) and will each be \"connected\" to // the Socket. The accepter logic is run in a separate goroutine. // The only error possible is if the address is invalid. Listen(addr string) error ListenOptions(addr string, options map[string]interface{}) error NewListener(addr string, options map[string]interface{}) (Listener, error) // GetOption is used to retrieve an option for a socket. GetOption(name string) (interface{}, error) // SetOption is used to set an option for a socket. SetOption(name string, value interface{}) error // OpenContext creates a new Context. If a protocol does not // support separate contexts, this will return an error. OpenContext() (Context, error) // SetPipeEventHook sets a PipeEventHook function to be called when a // Pipe is added or removed from this socket (connect/disconnect). // The previous hook is returned (nil if none.) (Only one hook can // be used at a time.) SetPipeEventHook(PipeEventHook) PipeEventHook } Send和Recv是不带header的, 而SendMsg和RecvMsg带header; 发送都是发往outbound Q. Q满了会阻塞 Dial表达的是connect, Listen是bind GetOption和SetOption用来设置底层socket context 每个protocol都有个默认的context. 只有部分protocol允许自建context context的抽象和socket一样? 只是socket的子集? -- context是建立在socket之上的, 顾名思义, 是带上下文的socket. // Context is a protocol context, and represents the upper side operations // that applications will want to use. Every socket has a default context, // but only a certain protocols will allow the creation of additional // Context instances (only if separate stateful contexts make sense for // a given protocol). type Context interface { // Close closes the open Socket. Further operations on the socket // will return ErrClosed. Close() error // GetOption is used to retrieve an option for a socket. GetOption(name string) (interface{}, error) // SetOption is used to set an option for a socket. SetOption(name string, value interface{}) error // Send puts the message on the outbound send queue. It blocks // until the message can be queued, or the send deadline expires. // If a queued message is later dropped for any reason, // there will be no notification back to the application. Send([]byte) error // Recv receives a complete message. The entire message is received. Recv() ([]byte, error) // SendMsg puts the message on the outbound send. It works like Send, // but allows the caller to supply message headers. AGAIN, the Socket // ASSUMES OWNERSHIP OF THE MESSAGE. SendMsg(*Message) error // RecvMsg receives a complete message, including the message header, // which is useful for protocols in raw mode. RecvMsg() (*Message, error) } options.go 上文提到的option, 都在这里定义, 注释写的非常确切. options大大小小包括很多, 比如raw mode, 比如超时时间, Q的size 举几个例子: const ( // OptionRaw is used to test if the socket in RAW mod. The details of // how this varies from normal mode vary from protocol to protocol, // but RAW mode is generally minimal protocol processing, and // stateless. RAW mode sockets are constructed with different // protocol constructor. Raw mode is generally used with Device() // or similar proxy configurations. OptionRaw = \"RAW\" // OptionRecvDeadline is the time until the next Recv times out. The // value is a time.Duration. Zero value may be passed to indicate that // no timeout should be applied. A negative value indicates a // non-blocking operation. By default there is no timeout. OptionRecvDeadline = \"RECV-DEADLINE\" //默认不超时, 永远等 // OptionRetryTime is used by REQ. The argument is a time.Duration. // When a request has not been replied to within the given duration, // the request will automatically be resent to an available peer. // This value should be longer than the maximum possible processing // and transport time. The value zero indicates that no automatic // retries should be sent. The default value is one minute. // // Note that changing this option is only guaranteed to affect requests // sent after the option is set. Changing the value while a request // is outstanding may not have the desired effect. OptionRetryTime = \"RETRY-TIME\" //默认一分钟 // OptionSubscribe is used by SUB/XSUB. The argument is a []byte. // The application will receive messages that start with this prefix. // Multiple subscriptions may be in effect on a given socket. The // application will not receive messages that do not match any current // subscriptions. (If there are no subscriptions for a SUB/XSUB // socket, then the application will not receive any messages. An // empty prefix can be used to subscribe to all messages.) OptionSubscribe = \"SUBSCRIBE\" //subscribe通过option来操作 // OptionWriteQLen is used to set the size, in messages, of the write // queue channel. By default, it's 128. This option cannot be set if // Dial or Listen has been called on the socket. OptionWriteQLen = \"WRITEQ-LEN\" //发送q的大小, 默认128个message // OptionLinger is used to set the linger property. This is the amount // of time to wait for send queues to drain when Close() is called. // Close() may block for up to this long if there is unsent data, but // will return as soon as all data is delivered to the transport. // Value is a time.Duration. Default is one second. OptionLinger = \"LINGER\" // close默认等待1秒, 好让还没发送出去的msg发出去. // OptionMaxRecvSize supplies the maximum receive size for inbound // messages. This option exists because the wire protocol allows // the sender to specify the size of the incoming message, and // if the size were overly large, a bad remote actor could perform a // remote Denial-Of-Service by requesting ridiculously large message // sizes and then stalling on send. The default value is 1MB. // // A value of 0 removes the limit, but should not be used unless // absolutely sure that the peer is trustworthy. // // Not all transports honor this limit. For example, this limit // makes no sense when used with inproc. // // Note that the size includes any Protocol specific header. It is // better to pick a value that is a little too big, than too small. // // This option is only intended to prevent gross abuse of the system, // and not a substitute for proper application message verification. // // This option is type int64. OptionMaxRecvSize = \"MAX-RCV-SIZE\" //这个厉害了, DDOS, 默认最大收1MB, 防止对端饱和攻击. // OptionReconnectTime is the initial interval used for connection // attempts. If a connection attempt does not succeed, then ths socket // will wait this long before trying again. An optional exponential // backoff may cause this value to grow. See OptionMaxReconnectTime // for more details. This is a time.Duration whose default value is // 100msec. This option must be set before starting any dialers. OptionReconnectTime = \"RECONNECT-TIME\" //重连间隔, 默认100ms // OptionBestEffort enables non-blocking send operations on the // socket. Normally (for some socket types), a socket will block if // there are no receivers, or the receivers are unable to keep up // with the sender. (Multicast sockets types like Bus or Star do not // behave this way.) If this option is set, instead of blocking, the // message will be silently discarded. The value is a boolean, and // defaults to False. OptionBestEffort = \"BEST-EFFORT\" //这个厉害了, 有这个标记的socket, 如果遇到发送时对端没准备好等情况, 直接丢弃msg // OptionLocalAddr expresses a local address. For dialers, this is // the (often random) address that was locally bound. For listeners, // it is usually the service address. The value is a net.Addr. This // is generally a read-only value for pipes, though it might sometimes // be available on dialers or listeners. OptionLocalAddr = \"LOCAL-ADDR\" //获取本地地址 // OptionRemoteAddr expresses a remote address. For dialers, this is // the service address. For listeners, its the address of the far // end dialer. The value is a net.Addr. It is generally read-only // and available only on pipes and dialers. OptionRemoteAddr = \"REMOTE-ADDR\" //获取对端地址, 对pipe和dialer有效. 等等 pipe.go pipe似乎很重要, 但接口定义很简单: // Pipe represents the high level interface to a low level communications // channel. There is one of these associated with a given TCP connection, // for example. This interface is intended for application use. // // Note that applications cannot send or receive data on a Pipe directly. type Pipe interface { // ID returns the numeric ID for this Pipe. This will be a // 31 bit (bit 32 is clear) value for the Pipe, which is unique // across all other Pipe instances in the application, while // this Pipe exists. (IDs are recycled on Close, but only after // all other Pipe values are used.) ID() uint32 // Address returns the address (URL form) associated with the Pipe. // This matches the string passed to Dial() or Listen(). Address() string // GetOption returns an arbitrary option. The details will vary // for different transport types. GetOption(name string) (interface{}, error) // Listener returns the Listener for this Pipe, or nil if none. Listener() Listener // Dialer returns the Dialer for this Pipe, or nil if none. Dialer() Dialer // Close closes the Pipe. This does a disconnect, or something similar. // Note that if a dialer is present and active, it will redial. Close() error } message.go message是对数据的承载载体, 包括header 对mesage的分包因protocol而异. 这里的message不包括比如tcp/ip头. 对transport来说, 这个message就是个大的payload. // Message encapsulates the messages that we exchange back and forth. The // meaning of the Header and Body fields, and where the splits occur, will // vary depending on the protocol. Note however that any headers applied by // transport layers (including TCP/ethernet headers, and SP protocol // independent length headers), are *not* included in the Header. type Message struct { // Header carries any protocol (SP) specific header. Applications // should not modify or use this unless they are using Raw mode. // No user data may be placed here. Header []byte // Body carries the body of the message. This can also be thought // of as the message \"payload\". Body []byte // Pipe may be set on message receipt, to indicate the Pipe from // which the Message was received. There are no guarantees that the // Pipe is still active, and applications should only use this for // informational purposes. Pipe Pipe //这个有点像channel in channel的意思. bbuf []byte hbuf []byte bsize int refcnt int32 } message pool 和标准库fmt包一样, msg也用了pool模式, 按照msg的size进行了分块. 这样做是为了减小GC的压力. type msgCacheInfo struct { maxbody int pool *sync.Pool } func newMsg(sz int) *Message { m := &Message{} m.bbuf = make([]byte, 0, sz) //实际的size全部在body中分配 m.hbuf = make([]byte, 0, 32) //这里很清楚, 默认的header大小为32字节 m.bsize = sz return m } // We can tweak these! var messageCache = []msgCacheInfo{ { maxbody: 64, pool: &sync.Pool{ New: func() interface{} { return newMsg(64) }, }, }, { maxbody: 128, pool: &sync.Pool{ New: func() interface{} { return newMsg(128) }, }, }, { ... 一直翻倍到65536 补充: sync.Pool可以传入一个New函数, 在pool里面没有对象的时候, 默认new一个. 有了这个Pool, 可以手动free msg, 进一步减轻gc压力. // Free releases the message to the pool from which it was allocated. // While this is not strictly necessary thanks to GC, doing so allows // for the resources to be recycled without engaging GC. This can have // rather substantial benefits for performance. func (m *Message) Free() { if m != nil { if atomic.AddInt32(&m.refcnt, -1) == 0 { for i := range messageCache { if m.bsize == messageCache[i].maxbody { messageCache[i].pool.Put(m) //free其实就是返还到pool return } } } } } msg对象的buffer管理 msg对象有如下方法: 上面说的Free() Clone() 只是把引用计数加一, 表示这个msg是共享的. 调用Clone()的人不要修改msg, 因为这个msg还是别人的. Dup() 深拷贝这个msg, 可以修改. MakeUnique() 一般用m = m.MakeUnique()来保证这个msg是自己独享的: 如果msg的引用计数为1, 返回msg本身; 否则Dup()一份, 删掉原msg, 返回Dup的, 即MakeUnique()后, 原msg也不能使用了. 最后是NewMessage()函数: 从pool中new一个msg // NewMessage is the supported way to obtain a new Message. This makes // use of a \"cache\" which greatly reduces the load on the garbage collector. func NewMessage(sz int) *Message { var m *Message for i := range messageCache { if sz protocol.go protocol就是场景化的套路类型: 比如Req/Rep Pub/Sub // Useful constants for protocol numbers. Note that the major protocol number // is stored in the upper 12 bits, and the minor (subprotocol) is located in // the bottom 4 bits. const ( ProtoPair = (1 * 16) ProtoPub = (2 * 16) ProtoSub = (2 * 16) + 1 ProtoReq = (3 * 16) ProtoRep = (3 * 16) + 1 ProtoPush = (5 * 16) ProtoPull = (5 * 16) + 1 ProtoSurveyor = (6 * 16) + 2 ProtoRespondent = (6 * 16) + 3 ProtoBus = (7 * 16) ProtoStar = (100 * 16) // Experimental! ) protocol就是下面的接口: // ProtocolPipe represents the handle that a Protocol implementation has // to the underlying stream transport. It can be thought of as one side // of a TCP, IPC, or other type of connection. type ProtocolPipe interface { // ID returns a unique 31-bit value associated with this. // The value is unique for a given socket, at a given time. ID() uint32 // Close does what you think. Close() error // SendMsg sends a message. On success it returns nil. This is a // blocking call. SendMsg(*Message) error // RecvMsg receives a message. It blocks until the message is // received. On error, the pipe is closed and nil is returned. RecvMsg() *Message // SetPrivate is used to set protocol private data. SetPrivate(interface{}) // GetPrivate returns the previously stored protocol private data. GetPrivate() interface{} } context就是protocol+使用上下文; 所有context都是stateful的. 奇怪的是RecvMsg() (*Message, error)的签名, 只有它和protocol长得不一样 // ProtocolContext is a \"context\" for a protocol, which contains the // various stateful operations such as timers, etc. necessary for // running the protocol. This is separable from the protocol itself // as the protocol may permit the creation of multiple contexts. type ProtocolContext interface { // Close closes the context. Close() error // SendMsg sends the message. The message may be queued, or // may be delivered immediately, depending on the nature of // the protocol. On success, the context assumes ownership // of the message. On error, the caller retains ownership, // and may either resend the message or dispose of it otherwise. SendMsg(*Message) error // RecvMsg receives a complete message, including the message header, // which is useful for protocols in raw mode. RecvMsg() (*Message, error) // GetOption is used to retrieve the current value of an option. // If the protocol doesn't recognize the option, EBadOption should // be returned. GetOption(string) (interface{}, error) // SetOption is used to set an option. EBadOption is returned if // the option name is not recognized, EBadValue if the value is // invalid. SetOption(string, interface{}) error } ProtocolBase匿名包含了ProtocolContext // ProtocolBase provides the protocol-specific handling for sockets. // This is the new style API for sockets, and is how protocols provide // their specific handling. type ProtocolBase interface { ProtocolContext // Info returns the information describing this protocol. Info() ProtocolInfo // XXX: Revisit these when we can use Pipe natively. // AddPipe is called when a new Pipe is added to the socket. // Typically this is as a result of connect or accept completing. // The pipe ID will be unique for the socket at this time. // The implementation must not call back into the socket, but it // may reject the pipe by returning a non-nil result. AddPipe(ProtocolPipe) error // RemovePipe is called when a Pipe is removed from the socket. // Typically this indicates a disconnected or closed connection. // This is called exactly once, after the underlying transport pipe // is closed. The Pipe ID will still be valid. RemovePipe(ProtocolPipe) // OpenContext is a request to create a unique instance of the // protocol state machine, allowing concurrent use of states on // a given protocol socket. Protocols that don't support this // should return ErrProtoOp. OpenContext() (ProtocolContext, error) } ProtocolInfo定义: // ProtocolInfo is a description of the protocol. type ProtocolInfo struct { Self uint16 Peer uint16 SelfName string PeerName string } 离用户最近的NewSocket 用户使用的时候, 一般会调用NewSocket, 这个API就是对下面protocol的MakeSocket的调用. // MakeSocket creates a Socket on top of a Protocol. func MakeSocket(proto Protocol) Socket { return core.MakeSocket(proto) } 核心层的实现如下 func newSocket(proto mangos.ProtocolBase) *socket { s := &socket{ proto: proto, reconnMinTime: defaultReconnMinTime, reconnMaxTime: defaultReconnMaxTime, maxRxSize: defaultMaxRxSize, } return s } // MakeSocket is intended for use by Protocol implementations. The intention // is that they can wrap this to provide a \"proto.NewSocket()\" implementation. func MakeSocket(proto mangos.ProtocolBase) mangos.Socket { return newSocket(proto) } transport.go 提供给transport类型实现方使用的统一的transport的抽象. 这是root下的tansport.go文件, transport下面还有自己的transport.go 这两个文件以后估计会merge到一起. TranPipe本质上是连接conn 注意, ransport的实现方才关心pipe, 应用侧不要用pipe. // TranPipe behaves like a full-duplex message-oriented connection between two // peers. Callers may call operations on a Pipe simultaneously from // different goroutines. (These are different from net.Conn because they // provide message oriented semantics.) // // Pipe is only intended for use by transport implementors, and should // not be directly used in applications. type TranPipe interface { // Send sends a complete message. In the event of a partial send, // the Pipe will be closed, and an error is returned. For reasons // of efficiency, we allow the message to be sent in a scatter/gather // list. Send(*Message) error // Recv receives a complete message. In the event that either a // complete message could not be received, an error is returned // to the caller and the Pipe is closed. // // To mitigate Denial-of-Service attacks, we limit the max message // size to 1M. Recv() (*Message, error) // Close closes the underlying transport. Further operations on // the Pipe will result in errors. Note that messages that are // queued in transport buffers may still be received by the remote // peer. Close() error // GetOption returns an arbitrary transport specific option on a // pipe. Options for pipes are read-only and specific to that // particular connection. If the property doesn't exist, then // ErrBadOption should be returned. GetOption(string) (interface{}, error) } transport是NewDialer和NewListener和命名方式的组合 下面会看到很清楚, 这个文件旨在统一transport的抽象, 我们从上到下看: // Transport is the interface for transport suppliers to implement. type Transport interface { // Scheme returns a string used as the prefix for SP \"addresses\". // This is similar to a URI scheme. For example, schemes can be // \"tcp\" (for \"tcp://xxx...\"), \"ipc\", \"inproc\", etc. Scheme() string // NewDialer creates a new Dialer for this Transport. NewDialer(url string, sock Socket) (TranDialer, error) // NewListener creates a new PipeListener for this Transport. // This generally also arranges for an OS-level file descriptor to be // opened, and bound to the the given address, as well as establishing // any \"listen\" backlog. NewListener(url string, sock Socket) (TranListener, error) } 一个transport本质要提供 一个命名规则: 比如\"tcp://xxx...\" 一个NewDialer方法 一个NewListener方法 TranDialer TranListener TranDialer TranListener都分别有别名Dialer和Listener // TranDialer represents the client side of a connection. Clients initiate // the connection. // // TranDialer is only intended for use by transport implementors, and should // not be directly used in applications. type TranDialer interface { // Dial is used to initiate a connection to a remote peer. Dial() (TranPipe, error) // SetOption sets a local option on the dialer. // ErrBadOption can be returned for unrecognized options. // ErrBadValue can be returned for incorrect value types. SetOption(name string, value interface{}) error // GetOption gets a local option from the dialer. // ErrBadOption can be returned for unrecognized options. GetOption(name string) (value interface{}, err error) } // TranListener represents the server side of a connection. Servers respond // to a connection request from clients. // // TranListener is only intended for use by transport implementors, and should // not be directly used in applications. type TranListener interface { // Listen actually begins listening on the interface. It is // called just prior to the Accept() routine normally. It is // the socket equivalent of bind()+listen(). Listen() error // Accept completes the server side of a connection. Once the // connection is established and initial handshaking is complete, // the resulting connection is returned to the client. Accept() (TranPipe, error) // Close ceases any listening activity, and will specifically close // any underlying file descriptor. Once this is done, the only way // to resume listening is to create a new Server instance. Presumably // this function is only called when the last reference to the server // is about to go away. Established connections are unaffected. Close() error // SetOption sets a local option on the listener. // ErrBadOption can be returned for unrecognized options. // ErrBadValue can be returned for incorrect value types. SetOption(name string, value interface{}) error // GetOption gets a local option from the listener. // ErrBadOption can be returned for unrecognized options. GetOption(name string) (value interface{}, err error) // Address gets the local address. The value may not be meaningful // until Listen() has been called. Address() string } 以上的\"二级\"接口依然不是最终的接口, 最终的接口是TranPipe, 就是本节最开头的接口定义. 总结 这里对transport的抽象是\"分级\"的. 接口的函数返回接口, 是对\"另一件事\"的抽象.比如Transport的NewDialer()方法, 返回TranDialer抽象; 再由其的Dial()方法返回TranPipe抽象, 后者才有Send(*Message) error和Recv() (*Message, error)方法. 抽象是有层次的, 抽象返回抽象. 对比我模糊的对transport的抽象认知: transport似乎应该是包括了send recv等多个方法的单一接口.mangos的抽象更有层次, 更清晰. 顶层listener.go和dialer.go 和transport的listener和dialer完全不一样, 顶层的定义是面向用户api的. // Listener is an interface to the underlying listener for a transport // and address. type Listener interface { // Close closes the listener, and removes it from any active socket. // Further operations on the Listener will return ErrClosed. Close() error // Listen starts listening for new connectons on the address. Listen() error // Address returns the string (full URL) of the Listener. Address() string // SetOption sets an option on the Listener. Setting options // can only be done before Listen() has been called. SetOption(name string, value interface{}) error // GetOption gets an option value from the Listener. GetOption(name string) (interface{}, error) } // Dialer is an interface to the underlying dialer for a transport // and address. type Dialer interface { // Close closes the dialer, and removes it from any active socket. // Further operations on the Dialer will return ErrClosed. Close() error // Dial starts connecting on the address. If a connection fails, // it will restart. Dial() error // Address returns the string (full URL) of the Listener. Address() string // SetOption sets an option on the Dialer. Setting options // can only be done before Dial() has been called. SetOption(name string, value interface{}) error // GetOption gets an option value from the Listener. GetOption(name string) (interface{}, error) } device.go 用于在socket之间转发, 这两个socket必须都是raw模式 func Device(s1 Socket, s2 Socket) error { go forwarder(s1, s2) if s2 != s1 { go forwarder(s2, s1) } return nil } // Forwarder takes messages from one socket, and sends them to the other. // The sockets must be of compatible types, and must be in Raw mode. func forwarder(fromSock Socket, toSock Socket) { for { m, err := fromSock.RecvMsg() if err != nil { // Probably closed socket, nothing else we can do. return } err = toSock.SendMsg(m) if err != nil { return } } } transport transport/transport.go 提供注册transport实现到全局变量表的方法 var transports = map[string]Transport{} // RegisterTransport is used to register the transport globally, // after which it will be available for all sockets. The // transport will override any others registered for the same // scheme. func RegisterTransport(t Transport) { lock.Lock() transports[t.Scheme()] = t lock.Unlock() } // GetTransport is used by a socket to lookup the transport // for a given scheme. func GetTransport(scheme string) Transport { lock.RLock() defer lock.RUnlock() if t, ok := transports[scheme]; ok { return t } return nil } 多出使用了技巧: type和等号实际上是alias // Pipe is a transport pipe. type Pipe = mangos.TranPipe // Dialer is a factory that creates Pipes by connecting to remote listeners. type Dialer = mangos.TranDialer // Listener is a factory that creates Pipes by listening to inbound dialers. type Listener = mangos.TranListener // Transport is our transport operations. type Transport = mangos.Transport transport/handshaker.go 这里handshaker是对异步握手的抽象. 所谓异步握手就是握手会在后台进行, 不block当前流程. // Handshaker is used to support dealing with asynchronous // handshaking used for some transports. This allows the // initial handshaking to be done in the background, without // stalling the server's accept queue. This is important to // ensure that a slow remote peer cannot bog down the server // or effect a denial-of-service for new connections. type Handshaker interface { // Start injects a pipe into the handshaker. The // handshaking is done asynchronously on a Go routine. Start(Pipe) // Waits for until a pipe has completely finished the // handshaking and returns it. Wait() (Pipe, error) // Close is used to close the handshaker. Any existing // negotiations will be canceled, and the underlying // transport sockets will be closed. Any new attempts // to start will return mangos.ErrClosed. Close() } transport/conn.go 这个文件实现了基于net.conn的TranPipe. 这个TranPipe也有别名connPipe, 其他的stream式的transport实现可以被被包装成connPipe, 使用这里通用的分包方法和握手协议. // conn implements the Pipe interface on top of net.Conn. The // assumption is that transports using this have similar wire protocols, // and conn is meant to be used as a building block. type conn struct { c net.Conn proto ProtocolInfo open bool options map[string]interface{} //对于option, 一把get set操作不频繁, 用string类的map再合适不过了. maxrx int sync.Mutex } recv和send写的很有水平 对net库, encoding/binary库的使用很到位: // Recv implements the TranPipe Recv method. The message received is expected // as a 64-bit size (network byte order) followed by the message itself. func (p *conn) Recv() (*Message, error) { var sz int64 var err error var msg *Message //先读size //binary标准库解析字节序列到size, 到结构体都行. 需要指明大小端. if err = binary.Read(p.c, binary.BigEndian, &sz); err != nil { return nil, err } // Limit messages to the maximum receive value, if not // unlimited. This avoids a potential denial of service. if sz 0 && sz > int64(p.maxrx)) { return nil, mangos.ErrTooLong } //根据size准备buffer //这里是从pool里new msg msg = mangos.NewMessage(int(sz)) msg.Body = msg.Body[0:sz] //用io.ReadFull读完整的msg, 也就是size长度的msg. //很明显, 这里的前提是stream方式的数据报. if _, err = io.ReadFull(p.c, msg.Body); err != nil { msg.Free() return nil, err } return msg, nil } // Send implements the Pipe Send method. The message is sent as a 64-bit // size (network byte order) followed by the message itself. func (p *conn) Send(msg *Message) error { //使用net包的Buffer对象发送 //net的Buffer是[][]byte, 是典型scatter模式, 即离散buffer模式. var buff = net.Buffers{} //这里size一定是大端格式的, 而且这个size是header和body的和. // Serialize the length header l := uint64(len(msg.Header) + len(msg.Body)) lbyte := make([]byte, 8) binary.BigEndian.PutUint64(lbyte, l) //lbyte是大端, msg.Header, msg.Body还是原始字节序 //用append来组包, 因为是二维byte, append只拷贝`[]byte`头, 不存在额外数据拷贝. // Attach the length header along with the actual header and body buff = append(buff, lbyte, msg.Header, msg.Body) //buffer自带的writeTo函数, 一把写完. if _, err := buff.WriteTo(p.c); err != nil { return err } msg.Free() return nil } 注意, 以上的函数中的header部分是[]byte, 对其具体的header格式没有认知. 发送接收总结 发送接收都是先有个size, 再根据size取出\"payload\". size是header+body的总大小 因为共享size, 所以接收方没有办法分别知道Header和Body的大小. 所以只能都用Body来接收 即发送方发的是Header+Body, 到接收方结构体中, Header为空, Body是原Header+Body 使用了encoding/binary对字节序列进行\"解释\", 比如size就是按大端字节序解析的. 发送的是net.Buffers, 是个二维byte [][]byte, 本质上是scatter的指针数组, 不拷贝数据 接收用的是sync.Pool的内存池化方式, 减小gc压力. 对header和body不做假设, 也没有知识. 发送接收认为他们都是[]byte option函数就是字符串版本的ioctl func (p *conn) GetOption(n string) (interface{}, error) { switch n { case mangos.OptionMaxRecvSize: return p.maxrx, nil } if v, ok := p.options[n]; ok { return v, nil } return nil, mangos.ErrBadProperty } func (p *conn) SetOption(n string, v interface{}) { switch n { case mangos.OptionMaxRecvSize: p.maxrx = v.(int) } p.options[n] = v } header和同步协议握手 // connHeader is exchanged during the initial handshake. type connHeader struct { Zero byte // must be zero S byte // 'S' P byte // 'P' Version byte // only zero at present Proto uint16 Reserved uint16 // always zero at present } header里面固定的字段意义 握手的过程是交换header的过程. // handshake establishes an SP connection between peers. Both sides must // send the header, then both sides must wait for the peer's header. // As a side effect, the peer's protocol number is stored in the conn. // Also, various properties are initialized. func (p *conn) handshake() error { var err error h := connHeader{S: 'S', P: 'P', Proto: p.proto.Self} //这里的binary.Write就是直接对底层conn p.c 做send操作. if err = binary.Write(p.c, binary.BigEndian, &h); err != nil { return err } //再从对端读出handshake信息 if err = binary.Read(p.c, binary.BigEndian, &h); err != nil { _ = p.c.Close() return err } if h.Zero != 0 || h.S != 'S' || h.P != 'P' || h.Reserved != 0 { _ = p.c.Close() return mangos.ErrBadHeader } // The only version number we support at present is \"0\", at offset 3. if h.Version != 0 { _ = p.c.Close() return mangos.ErrBadVersion } // The protocol number lives as 16-bits (big-endian) at offset 4. if h.Proto != p.proto.Peer { _ = p.c.Close() return mangos.ErrBadProto } p.open = true return nil } 后台握手接口 上面是同步的握手函数, 是具体实现. 同步的接口可以被异步框架异步化, 来满足handshaker的要求 基本上, 握手是底层建立连接后要做的第一件事. 下面是conn.go提供的异步包装框架, 是承上(transport/handshaker.go要求的后台握手)启下(各个transport类型实现的handshake) type connHandshakerPipe interface { handshake() error //被包装的对象要实现handshake函数 Pipe //和send recv等tranpipe接口, 这个接口是对所有transport类型的统一抽象. } type connHandshakerItem struct { c connHandshakerPipe e error } type connHandshaker struct { workq map[connHandshakerPipe]bool //interface可以当map的key doneq []*connHandshakerItem //注意这里, handshaker是个汇聚者, 这里包括了listen后accept的所有conn(被包装为connHandshakerPipe) closed bool cv *sync.Cond sync.Mutex } 先看start: 一个connHandshaker可以和多个pipe后台握手, 每个pipe都启动一个go routine; 一个pipe代表了一个conn func (h *connHandshaker) Start(p Pipe) { // If the following type assertion fails, then its a software bug. conn := p.(connHandshakerPipe) h.Lock() h.workq[conn] = true //标记这个conn正在握手中 h.Unlock() go h.worker(conn) } func (h *connHandshaker) worker(conn connHandshakerPipe) { item := &connHandshakerItem{c: conn} item.e = conn.handshake() //这里直接调用同步版本的handshake函数. 此时必然已经建立连接, 否则也不会有conn对象. h.Lock() defer h.Unlock() delete(h.workq, conn) //有错误就close掉这个conn if item.e != nil { _ = item.c.Close() item.c = nil } else if h.closed { item.e = mangos.ErrClosed _ = item.c.Close() } //把结果放到doneq里 h.doneq = append(h.doneq, item) h.cv.Broadcast() //广播会唤醒所有等待的goroutine, 但实际上wait路径上有锁, 结果是只能有一个routine在cv上wait. 其他人在锁上wait. } wait是等待返回任意一个已经完成握手的conn func (h *connHandshaker) Wait() (Pipe, error) { h.Lock() defer h.Unlock() for len(h.doneq) == 0 && !h.closed { h.cv.Wait() //持有锁的wait } if h.closed { return nil, mangos.ErrClosed } item := h.doneq[0] //按完成顺序取 h.doneq = h.doneq[1:] //整个过程被锁保护 return item.c, item.e } close func (h *connHandshaker) Close() { h.Lock() h.closed = true h.cv.Broadcast() for conn := range h.workq { _ = conn.Close() } for len(h.doneq) != 0 { item := h.doneq[0] h.doneq = h.doneq[1:] if item.c != nil { _ = item.c.Close() } } h.Unlock() } transport/tcp/tcp.go tcp实现了Scheme NewDialer NewListener方法, 满足了transport接口. type tcpTran int func (t tcpTran) Scheme() string { return \"tcp\" } 有意思的是, tcpTran只是个int类型的重命名. 在init里, 注册这个tcpTran类型 const ( // Transport is a transport.Transport for TCP. Transport = tcpTran(0) ) //本质上是注册接口类型: transports[t.Scheme()] = t func init() { transport.RegisterTransport(Transport) } NewDialer和NewListener 这两个接口类似工厂类, 其产品transport.Dialer和transport.Listener才是重点. func (t tcpTran) NewDialer(addr string, sock mangos.Socket) (transport.Dialer, error) { var err error //StripScheme把tcp://192.168.0.1:1234中的192.168.0.1:1234部分提取出来 if addr, err = transport.StripScheme(t, addr); err != nil { return nil, err } // check to ensure the provided addr resolves correctly. //实际上是调用net.ResolveTCPAddr if _, err = transport.ResolveTCPAddr(addr); err != nil { return nil, err } d := &dialer{ //返回重点, 就是这个dialer addr: addr, proto: sock.Info(), //这里transport也关心应用socket类型了? hs: transport.NewConnHandshaker(), //handshake是应用侧socket交换信息的开始 } return d, nil } func (t tcpTran) NewListener(addr string, sock mangos.Socket) (transport.Listener, error) { var err error l := &listener{ //返回重点, 就是这个listener proto: sock.Info(), closeq: make(chan struct{}), } if addr, err = transport.StripScheme(t, addr); err != nil { return nil, err } l.addr = addr l.handshaker = transport.NewConnHandshaker() return l, nil } dialer dialer要实现Dial GetOption和SetOption接口 type dialer struct { addr string proto transport.ProtocolInfo hs transport.Handshaker maxRecvSize int d net.Dialer lock sync.Mutex } func (d *dialer) Dial() (_ transport.Pipe, err error) { conn, err := d.d.Dial(\"tcp\", d.addr) // 先dail得到conn, 也就是pipe if err != nil { return nil, err } p := transport.NewConnPipe(conn, d.proto) //包装已有的conn得到connPipe, stream方式的Conn都可以用它来实现transport. 但为什么这里要知道proto? proto是应用侧socket的类型, 包括自己和对端. d.lock.Lock() p.SetOption(mangos.OptionMaxRecvSize, d.maxRecvSize) //似乎默认maxRecvSize为0 d.lock.Unlock() d.hs.Start(p) //里面会断言p是connHandshakerPipe, 因为NewConnPipe()返回的p, 实现了handshake()函数. 注意这里的handshake()函数是小写开头, 外部不能直接调用. 但go编译器的类型系统还是会判定p实现了不对外的handshake()函数. return d.hs.Wait() //先start再wait, 这就是同步化了, 实际就像是调了p.handshake()函数. 但实际上handshake()是不对外的, 只能用异步再同步化操作. } 注: 这里把接口的隐含属性用的出神入化. p是个interface, 把p传入给d.hs.Start(p)时, p的方法集变成了TranPipe接口的方法集; 在transport/conn.go里的start实现中, 断言入参TranPipe是conn := p.(connHandshakerPipe) 因为p是transport/conn.go里NewConnPipe()函数返回的, 保证能被同一个文件里的start函数断言成功. 而且其签名函数handshake()可以小写. 这些都是内部的事情. listener listener要复杂点, 要实现Accept Listen Address Close和Set/Get Option的方法 type listener struct { addr string bound net.Addr proto transport.ProtocolInfo l net.Listener lc net.ListenConfig maxRecvSize int handshaker transport.Handshaker closeq chan struct{} once sync.Once lock sync.Mutex } Accept()一般紧跟着Listen()之后, 等待并返回协商成功的pipe func (l *listener) Accept() (transport.Pipe, error) { if l.l == nil { return nil, mangos.ErrClosed } return l.handshaker.Wait() } Listen启动了一个goroutine来做accept func (l *listener) Listen() (err error) { select { case adress和close address返回全称, 比如tcp://192.168.1.1:1111 close先用close channel的方式改变listener的状态, 这样其他例程可以安全的检查listener是否已经被close掉了. -- 似乎比bool的方式先进些? close的意思是停止listen和accept, 但之前已经建立的连接不受影响. func (l *listener) Address() string { if b := l.bound; b != nil { return \"tcp://\" + b.String() } return \"tcp://\" + l.addr } func (l *listener) Close() error { l.once.Do(func() { close(l.closeq) if l.l != nil { _ = l.l.Close() } l.handshaker.Close() }) return nil } Set和Get Option 和dialer类似, 有 OptionMaxRecvSize OptionKeepAliveTime 总结 tcp是stream方式的transport, 底层使用net标准库的方法, 最主要的是把net.Conn包装成了connPipe, 后者是mangos的统一化的流式pipe的实现, 有最简单的根据header+body的size定界方法, 和协议握手的方法. 可以说, tcp使用了connPipe的\"helper\"方法, 实现了流式transport, 满足了transport的所有接口要求. 需要注意的是, mangos做为nanomsg的纯go版本实现, 并没有follow其前身zeroMQ对报文格式的规定, 即分frame的规定. -- 有待确认. transport小节 transport是知道顶层socket信息的, 因为transport先于protocol动作, 比如在client dial的时候, 就要握手交换protocol的信息做验证. server listen的时候也如是. transport/inproc/inproc.go 前面我们知道, transport首先要实现NewDialer, NewListener, 后续要实现Dial和Listen方法, 最后一层要实现Send和Recv. 注意Send和Recv都是规定好的m *mangos.Message -- 为什么不规定个interface来做msg抽象? 全局listener表 var listeners struct { // Who is listening, on which \"address\"? byAddr map[string]*listener //记录了全局的名字 cv sync.Cond mx sync.Mutex } Listen NewListener就不看了, 就是返回一个带Listen功能和Accept功能的对象. Listen很简单, 如果要Listen的名字没有人用, 表示可以listen, 就记录到全局表中. func (l *listener) Listen() error { listeners.mx.Lock() if l.closed { listeners.mx.Unlock() return mangos.ErrClosed } if _, ok := listeners.byAddr[l.addr]; ok { listeners.mx.Unlock() return mangos.ErrAddrInUse } l.active = true listeners.byAddr[l.addr] = l listeners.cv.Broadcast() //这里要广播给谁呢? listeners.mx.Unlock() return nil } Accept 每次Accept生成一个新的inproc类型的server func (l *listener) Accept() (mangos.TranPipe, error) { server := &inproc{ selfProto: l.selfProto, peerProto: l.peerProto, addr: addr(l.addr), } server.readyq = make(chan struct{}) server.closeq = make(chan struct{}) listeners.mx.Lock() if !l.active || l.closed { listeners.mx.Unlock() return nil, mangos.ErrClosed } l.accepters = append(l.accepters, server) //这里这么早就add了, 不好吧? 要不放到case里 -- 根据下文逻辑, 一定要先在l.accepters里有server listeners.cv.Broadcast() listeners.mx.Unlock() select { case Dial func (d *dialer) Dial() (transport.Pipe, error) { var server *inproc client := &inproc{ selfProto: d.selfProto, peerProto: d.peerProto, addr: addr(d.addr), //client也直接用dial的addr, 不合适吧? } client.readyq = make(chan struct{}) client.closeq = make(chan struct{}) listeners.mx.Lock() // NB: No timeouts here! for { var l *listener var ok bool if l, ok = listeners.byAddr[d.addr]; !ok || l == nil { //一定要先有listenr才能Dial, 不支持先有client, 再有server. -- 其实没必要 listeners.mx.Unlock() return nil, mangos.ErrConnRefused } if (client.selfProto != l.peerProto) || //这是个简单的协商机制 (client.peerProto != l.selfProto) { listeners.mx.Unlock() return nil, mangos.ErrBadProto } if len(l.accepters) != 0 { server = l.accepters[len(l.accepters)-1] //取最后一个server l.accepters = l.accepters[:len(l.accepters)-1] break } listeners.cv.Wait() continue } listeners.mx.Unlock() //到这里client和server已经配对. server.wq = make(chan *transport.Message) //才建立server的通道, 注意都是unbuffer类型的 server.rq = make(chan *transport.Message) client.rq = server.wq //client和server共用一个channel, 只是方向不一样 client.wq = server.rq server.peer = client client.peer = server close(server.readyq) close(client.readyq) return client, nil } Send和Recv func (p *inproc) Send(m *mangos.Message) error { // Upper protocols expect to have to pick header and body part. // Also we need to have a fresh copy of the message for receiver, to // break ownership. nmsg := mangos.NewMessage(len(m.Header) + len(m.Body)) nmsg.Body = append(nmsg.Body, m.Header...) nmsg.Body = append(nmsg.Body, m.Body...) //复制报文, 但是不free? select { case p.wq func (p *inproc) Recv() (*transport.Message, error) { select { case m := 总结 server和client都是*inproc类型 Send msg是拷贝式的. 基于名字查找和共享channel的消息传递, 开销比较小. transport/ipc internal/core internal/core/socket.go NewDialer和NewListener transport提供了GetTransport()函数从全局map表var transports = map[string]Transport{}中获取已经注册的transport工厂对象, 该对象的NewDialer和NewListener方法会新建连接. 而这里internal core里面, 就调用了GetTransport(), 根据传入的string, 返回mangos.Dialer. 注意这个Dialer已经不是transport的Dialer了. func (s *socket) NewDialer(addr string, options map[string]interface{}) (mangos.Dialer, error) { t := s.getTransport(addr) td, err := t.NewDialer(addr, s) //调用transport层的NewDialer d := &dialer{ d: td, s: s, //很重要, dialer保持了这个socket的信息 reconnMinTime: s.reconnMinTime, reconnMaxTime: s.reconnMaxTime, asynch: s.dialAsynch, addr: addr, } for n, v := range options { //处理options d.SetOption(n, v) 或td.SetOption(n, v) } s.dialers = append(s.dialers, d) //把刚才New的dialer关联到socket; socket可以有多个dialer return d, nil } 上面的NewDialer就是顶层API func (s *socket) Dial(addr string) error或func (s *socket) DialOptions(addr string, opts map[string]interface{}) error调用下来的. func (s *socket) Dial(addr string) error s.DialOptions(addr, nil) d, err := s.NewDialer(addr, opts) return d.Dial() //注意这里并不是transport的Dial, 而是应用侧的dial; 应用侧的dial签名不同, 它没有返回conn 同样的listen也是类似的过程 socket.ListenOptions 或socket.Listen l := socket.NewListener() l.Listen() //注意这里开始Listen, 这也是应用侧的listen, 只返回error 后面会看到, 应用侧Dial和Listen后, conn的信息是通过socket的addPipe方法来保存的. socket具体定义 在core看起来, socket持有多个listener, 多个dialer, 以及真正的conn(也就是这里的pipeList). // socket is the meaty part of the core information. type socket struct { proto mangos.ProtocolBase sync.Mutex closed bool // true if Socket was closed at API level reconnMinTime time.Duration // reconnect time after error or disconnect reconnMaxTime time.Duration // max reconnect interval maxRxSize int // max recv size dialAsynch bool // asynchronous dialing? listeners []*listener dialers []*dialer pipes pipeList //定义于pipe.go pipehook mangos.PipeEventHook //提供给app层的hook函数入口 } 最后一个hook再详细看一下: 在socket的pipe中枢系统发生变化时, 调用这个hook. const ( // PipeEventAttaching is called before the Pipe is registered with the // socket. The intention is to permit the application to reject // a pipe before it is attached. PipeEventAttaching = iota // PipeEventAttached occurs after the Pipe is attached. // Consequently, it is possible to use the Pipe for delivering // events to sockets, etc. PipeEventAttached // PipeEventDetached occurs after the Pipe has been detached // from the socket. PipeEventDetached ) 换算成y的说法就是. onConnect, onDisconnect. 核心动作: addPipe // AddPipe is called when a new Pipe is added to the socket. // Typically this is as a result of connect or accept completing. // The pipe ID will be unique for the socket at this time. // The implementation must not call back into the socket, but it // may reject the pipe by returning a non-nil result. 就是说每当有连接的时候, 就会addPipe func (s *socket) addPipe(tp transport.Pipe, d *dialer, l *listener) p := newPipe(tp, s, d, l) s.pipes.Add(p) ph(mangos.PipeEventAttaching, p) //调用hook s.proto.AddPipe(p) //这个pipe也会被add到ProtocolBase ph(mangos.PipeEventAttached, p) //调用hook 注意这里的这句代码有学问: s.proto.AddPipe(p) p是个*core.pipe类型, 本身是小写的, 不能直接被外部使用. 但这里调用protocol的接口函数: AddPipe(p), 把p当作ProtocolPipe来看, 就把pipe的\"能力\"输出了. 这里的s.proto是mangos.ProtocolBase, 实际上是每个protocol的实现者的socket对象. 比如req.socket 要输出能力, 不一定要自己声明; 调用别人的接口, 把自己包装出去也可以. send和recv socket的重头戏, 这是核心层的对用户层API的具体实现的地方: func (s *socket) SendMsg(msg *Message) error { return s.proto.SendMsg(msg) //不要困惑 这里还没到transport. 这里的send需要protocol来决定发送给谁, 怎么发. 所以要用s.proto对象来send. } func (s *socket) Send(b []byte) error { msg := mangos.NewMessage(len(b)) msg.Body = append(msg.Body, b...) //这里打散再拼接性能会不会有问题? 不用个bytes.Buffer啥的? 看这里的情况是拷贝发送. 这里https://gist.github.com/xogeny/b819af6a0cf8ba1caaef似乎是说copy和append性能差不多 return s.SendMsg(msg) } func (s *socket) RecvMsg() (*Message, error) { return s.proto.RecvMsg() } func (s *socket) Recv() ([]byte, error) { msg, err := s.RecvMsg() if err != nil { return nil, err } b := make([]byte, 0, len(msg.Body)) //返回新buffer而不是transport侧底层的buffer; 而且是去了头的; 而且这个buffer是直接make出来的, 不是用的pool的buffer. b = append(b, msg.Body...) msg.Free() //注意这里的Free是返还给pool return b, nil } internal/core/pipe.go 这里的pipe实现了多个接口: pipe.go.Pipe接口, 暂时不知道哪里用了 // Pipe represents the high level interface to a low level communications // channel. There is one of these associated with a given TCP connection, // for example. This interface is intended for application use. // // Note that applications cannot send or receive data on a Pipe directly. type Pipe interface { // ID returns the numeric ID for this Pipe. This will be a // 31 bit (bit 32 is clear) value for the Pipe, which is unique // across all other Pipe instances in the application, while // this Pipe exists. (IDs are recycled on Close, but only after // all other Pipe values are used.) ID() uint32 // Address returns the address (URL form) associated with the Pipe. // This matches the string passed to Dial() or Listen(). Address() string // GetOption returns an arbitrary option. The details will vary // for different transport types. GetOption(name string) (interface{}, error) // Listener returns the Listener for this Pipe, or nil if none. Listener() Listener // Dialer returns the Dialer for this Pipe, or nil if none. Dialer() Dialer // Close closes the Pipe. This does a disconnect, or something similar. // Note that if a dialer is present and active, it will redial. Close() error } protocol.go.ProtocolPipe接口, 这个接口被protocol的实现者使用. 具体来讲, 在protocol的实现实例的AddPipe()被调用的时候, ProtocolPipe这个接口会被传入. // ProtocolPipe represents the handle that a Protocol implementation has // to the underlying stream transport. It can be thought of as one side // of a TCP, IPC, or other type of connection. type ProtocolPipe interface { // ID returns a unique 31-bit value associated with this. // The value is unique for a given socket, at a given time. ID() uint32 // Close does what you think. Close() error // SendMsg sends a message. On success it returns nil. This is a // blocking call. SendMsg(*Message) error // RecvMsg receives a message. It blocks until the message is // received. On error, the pipe is closed and nil is returned. RecvMsg() *Message // SetPrivate is used to set protocol private data. SetPrivate(interface{}) // GetPrivate returns the previously stored protocol private data. GetPrivate() interface{} } pipe定义 在core看起来, pipe的信息很丰富: 它毫无疑问的持有底层transport的pipe对象, 同时它还知道这个pipe的listender和dialer, 即知道对端和自己的信息. 它还持有socket对象, 知道app层的想法.总结: pipe是个中枢. // pipe wraps the Pipe data structure with the stuff we need to keep // for the core. It implements the Pipe interface. type pipe struct { id uint32 p transport.Pipe l *listener d *dialer s *socket closeOnce sync.Once data interface{} // Protocol private added bool closing bool lock sync.Mutex // held across calls to remPipe and addPipe } pipeList pipeList是个map, 保存了所有的pipe实例, 每个pipe实例有个独特的uint32 ID type pipeList struct { pipes map[uint32]*pipe lock sync.Mutex } addPipe和ID生成 socket中调用addPipe会新生成一个uint32 ID, 从随机数开始, 全局唯一. 原理是在全局表map[uint32]struct{}中, 依次找个没被使用的ID. 是的, ID被使用完了还会还到这个map里. 真正的add是调用Add把p按照p.id func (l *pipeList) Add(p *pipe) { l.lock.Lock() if l.pipes == nil { l.pipes = make(map[uint32]*pipe) } l.pipes[p.id] = p l.lock.Unlock() } pipe的send和recv pipe是原始conn的封装, 所以send recv都是直接调用底层transport的接口; 所以到这里就不是应用侧的发送接收了. func (p *pipe) SendMsg(msg *mangos.Message) error { if err := p.p.Send(msg); err != nil { _ = p.Close() return err } return nil } func (p *pipe) RecvMsg() *mangos.Message { msg, err := p.p.Recv() if err != nil { _ = p.Close() //API定义的很明白, 如果底层Recv返回错误, 就close掉这个pipe return nil } msg.Pipe = p //这里值得注意, 从msg里能够拿到pipe的信息, 进而能拿到所有信息. 但不保证到msg的处理的时候, pipe还在. return msg } 为什么底层send或者recv失败要close掉pipe? 那后面还怎么整?而且在close中, 会彻底关闭transport层的连接 func (p *pipe) Close() error { p.closeOnce.Do(func() { // Close the underlying transport pipe first. _ = p.p.Close() // Deregister it from the socket. This will also arrange // for asynchronously running the event callback, and // releasing the pipe ID for reuse. p.lock.Lock() p.closing = true if p.added { p.s.remPipe(p) } p.lock.Unlock() if p.d != nil { // Inform the dialer so that it will redial. go p.d.pipeClosed() //这里值得关注, 里面会延迟调用redial函数重新建立连接, redial会不断重试. } }) return nil } 所以回答上面的问题, 发送或者接收失败都会close掉连接. 但close的流程最后启动了redial流程.也就是说, 比如发送失败的情况下, mangos并不是直接重新再send一次, 而是把整个连接都关掉, 再重新建立新连接来重发. 携带额外数据的典型模式: SetPrivate 使用万能的interface做为输入 func (p *pipe) SetPrivate(i interface{}) { p.data = i } func (p *pipe) GetPrivate() interface{} { return p.data } internal/core/dialer.go 在socket.go里, NewDialer就是new的下面的dialer type dialer struct { sync.Mutex d transport.Dialer s *socket addr string closed bool active bool asynch bool redialer *time.Timer reconnTime time.Duration reconnMinTime time.Duration reconnMaxTime time.Duration closeq chan struct{} } dial流程 func (d *dialer) Dial() error { d.Lock() if d.active { d.Unlock() return mangos.ErrAddrInUse } if d.closed { d.Unlock() return mangos.ErrClosed } d.closeq = make(chan struct{}) d.active = true d.reconnTime = d.reconnMinTime if d.asynch { go d.redial() d.Unlock() return nil } d.Unlock() return d.dial(false) //就是下面的dial函数 } func (d *dialer) dial(redial bool) error { d.Lock() if d.closed { d.Unlock() return errors.ErrClosed } if d.asynch { redial = true } d.Unlock() p, err := d.d.Dial() if err == nil { d.s.addPipe(p, d, nil) //dial成功了就addPipe到socket return nil } //到这里就是不成功, 需要重试 d.Lock() defer d.Unlock() // We're no longer dialing, so let another reschedule happen, if // appropriate. This is quite possibly paranoia. We should only // be in this routine in the following circumstances: // // 1. Initial dialing (via Dial()) // 2. After a previously created pipe fails and is closed due to error. // 3. After timing out from a failed connection attempt. //没让你重试就返回 if !redial { return err } switch err { case mangos.ErrClosed: //对端不给连 // Stop redialing, no further action. default: //缓启动逻辑 // Exponential backoff, and jitter. Our backoff grows at // about 1.3x on average, so we don't penalize a failed // connection too badly. minfact := float64(1.1) maxfact := float64(1.5) actfact := rand.Float64()*(maxfact-minfact) + minfact rtime := d.reconnTime if d.reconnMaxTime != 0 { d.reconnTime = time.Duration(actfact * float64(d.reconnTime)) if d.reconnTime > d.reconnMaxTime { d.reconnTime = d.reconnMaxTime } } d.redialer = time.AfterFunc(rtime, d.redial) //AfterFunc会启动一个goroutine来延迟执行d.redial; 这里还用了经典的 方法转函数的编译器黑科技 } return err } func (d *dialer) redial() { _ = d.dial(true) } 总的来说, dialer实现了对底层transport的dail, 支持后台redial, 支持dail失败重试(不是马上, 而是带缓启动的重试); 支持多种option: OptionReconnectTime OptionMaxReconnectTime OptionDialAsynch internal/core/listener.go listener是对transport的listener的简单包装 type listener struct { sync.Mutex l transport.Listener s *socket addr string closed bool active bool } Listen先查看状态, 再调用transport的Listen. func (l *listener) Listen() error { // This function sets up a goroutine to accept inbound connections. // The accepted connection will be added to a list of accepted // connections. The Listener just needs to listen continuously, // as we assume that we want to continue to receive inbound // connections without limit. l.Lock() if l.closed { l.Unlock() return mangos.ErrClosed } if l.active { l.Unlock() return mangos.ErrAddrInUse } l.active = true l.Unlock() if err := l.l.Listen(); err != nil { l.Lock() l.active = false l.Unlock() return err } go l.serve() //serve()函数才是不断的在循环里Accept连接的主体 return nil } server()函数是被go的 // serve spins in a loop, calling the accepter's Accept routine. func (l *listener) serve() { for { l.Lock() if l.closed { l.Unlock() break } l.Unlock() // If the underlying PipeListener is closed, or not // listening, we expect to return back with an error. if tp, err := l.l.Accept(); err == mangos.ErrClosed { return } else if err == nil { l.s.addPipe(tp, nil, l) //把握手后的tranPipe加入socket. } else { // Debounce a little bit, to avoid thrashing the CPU. time.Sleep(time.Second / 100) } } } 总结 core的核心是pipe. 它承上启下 上面的socket负责符合app的想象, socket的send和recv都要按照protocol的套路来整, 比如多播啥的 下面的dialer和listener对下对接transport的dialer和listener, 提供了额外的重试连接, 后台连接, routine化accpet等功能. dialer和listener成功返回的连接, 被包装成pipe, add到socket里. 核心是 func (s *socket) addPipe(tp transport.Pipe, d *dialer, l *listener) 对dialer来说, 会这样调用d.s.addPipe(p, d, nil) 对listener来说, 会这样调用l.s.addPipe(tp, nil, l) 最终都是add到socket的pipes中, 这是个按ID索引的pipe表 map[uint32]*pipe protocol protocol是高于socket层的抽象, 是socket的场景化模式的归纳, 继承自zeroMQ. 目前支持 bus pair pub/sub pull/push req/rep star 以及以上带x版本的. 下面从最基本的req/rep开始, 看看protocol怎么实现的 protocol/req/req.go 每个protocol都有统一的协议编号, req/rep的大协议号一样, 后四位小协议号不同 // Protocol identity information. const ( Self = protocol.ProtoReq //48 Peer = protocol.ProtoRep //49 SelfName = \"req\" PeerName = \"rep\" ) req.go只依赖protocol包, 它对core包是无感知的.所以虽然core.pipe是唯一的mangos.ProtocolPipe实现者, 但core.pipe也是小写, 而且req.go也不引用core, 那怎么实例化mangos.ProtocolPipe的? 核心结构体定义 req的socket核心当然是socket的具体实例: type socket struct { sync.Mutex defCtx *context // default context ctxs map[*context]struct{} // all contexts (set) ctxByID map[uint32]*context // contexts by request ID nextID uint32 // next request ID closed bool // true if we are closed sendq []*context // contexts waiting to send readyq []*pipe // pipes available for sending } socket持有的context和pipe在本文件定义: type pipe struct { p protocol.Pipe s *socket //反向持有socket closed bool } type context struct { s *socket //反向持有socket cond *sync.Cond resendTime time.Duration // tunable resend time sendExpire time.Duration // how long to wait in send recvExpire time.Duration // how long to wait in recv sendTimer *time.Timer // send timer recvTimer *time.Timer // recv timer resender *time.Timer // resend timeout reqMsg *protocol.Message // message for transmit repMsg *protocol.Message // received reply sendMsg *protocol.Message // messaging waiting for send lastPipe *pipe // last pipe used for transmit reqID uint32 // request ID recvWait bool // true if a thread is blocked in RecvMsg bestEffort bool // if true, don't block waiting in send queued bool // true if we need to send a message closed bool // true if we are closed } 为什么要有context? 因为socket的SendMsg, RecvMsg都依赖context发送 func (s *socket) SendMsg(m *protocol.Message) error { return s.defCtx.SendMsg(m) } req的SendMsg 最顶层是context send func (c *context) SendMsg(m *protocol.Message) error { s := c.s id := atomic.AddUint32(&s.nextID, 1) id |= 0x80000000 // cooked mode, we stash the header m.Header = append([]byte{}, //按照大端字节序发id byte(id>>24), byte(id>>16), byte(id>>8), byte(id)) s.Lock() //每个context只能同时发送一个msg defer s.Unlock() if s.closed || c.closed { return protocol.ErrClosed } //上一次还没发送出去, 哪里有问题了... //因为req/rep是同步模式, 取消上次的发送: 上次的msg会被free掉, 延迟的timer被stop; 并把这个context从socket的sendq里面删掉: s.sendq = append(s.sendq[:i], s.sendq[i+1:]...); 最后广播c.cond.Broadcast() c.cancel() // this cancels any pending send or recv calls c.unscheduleSend() //似乎这个函数多余了, 在c.cancel()中调用过了 c.reqID = id c.queued = true c.sendMsg = m s.sendq = append(s.sendq, c) //本次的context加入socket的sendq if c.bestEffort { // for best effort case, we just immediately go the // reqMsg, and schedule it as a send. No waiting. // This means that if the message cannot be delivered // immediately, it will still get a chance later. s.send() //没看懂上面的注释, 但这里明显是调用socket的原始send, 不管错误马上返回 return nil //这里返回了, 那上面sendq怎么办? 不删掉吗? } expired := false if c.sendExpire > 0 { c.sendTimer = time.AfterFunc(c.sendExpire, func() { //超时就取消的函数 s.Lock() if c.sendMsg == m { expired = true c.cancel() // also does a wake up } s.Unlock() }) } s.send() //触发后台send // This sleeps until someone picks us up for scheduling. // It is responsible for providing the blocking semantic and // ultimately back-pressure. Note that we will \"continue\" if // the send is canceled by a subsequent send. for c.sendMsg == m && !expired && !c.closed { //sync.Cond.Wait接口需要在for里面调用 c.cond.Wait() //典型的场景是上面的s.send把c.sendMsg置为nil, 解除这里的for循环, 退出wait往下走. 但如果readyq中没有可用的pipe, 就是说没有有效的连接, SendMsg会block在这里, 直到有可用的连接为止. } if c.sendMsg == m { //到这里, 要么就是超时了, 要么就是close了;这个m现在是发不了了 c.unscheduleSend() //删除m对应的context c.sendMsg = nil //就是说这个m不发了 c.reqID = 0 if c.closed { return protocol.ErrClosed } return protocol.ErrSendTimeout //返回错误, m并没有发送. } return nil } context send里面调用了socket send 注意这里的send没有任何参数和返回值: 需要知道的已经全部知道, 它要做的就是调度发送. func (s *socket) send() { for len(s.sendq) != 0 && len(s.readyq) != 0 { //有待发送的context 并且有ready的pipe c := s.sendq[0] //取出第一个待发context s.sendq = s.sendq[1:] c.queued = false var m *protocol.Message if m = c.sendMsg; m != nil { //从sendMsg转移到reqMsg c.reqMsg = m c.sendMsg = nil s.ctxByID[c.reqID] = c //按ID记录context c.cond.Broadcast() } else { m = c.reqMsg } m.Clone() //增加msg的引用计数, 该msg是共享模式. p := s.readyq[0] //取第一个ready 的pipe s.readyq = s.readyq[1:] // Schedule a retransmit for the future. c.lastPipe = p //ready的pipe保存到lastPipe里 if c.resendTime > 0 { id := c.reqID c.resender = time.AfterFunc(c.resendTime, func() { //默认一分钟重发 c.resendMessage(id) }) } go p.sendCtx(c, m) //后台发送, 注意go了以后, 就脱离了锁的保护了 } } sendCtx()会调用底层的pipe来发送, 一般发送完还会调度自己继续发送. func (p *pipe) sendCtx(c *context, m *protocol.Message) { s := p.s // Send this message. If an error occurs, we examine the // error. If it is ErrClosed, we don't schedule our self. if err := p.p.SendMsg(m); err != nil { m.Free() if err == protocol.ErrClosed { return } } s.Lock() //重新调度发送还是需要获取锁. if !s.closed && !p.closed { s.readyq = append(s.readyq, p) s.send() //重新调度 } s.Unlock() } 发送小节 req/rep本质上是同步模式, 其实并没有同时发送的说法 但即使是简单的同步发送, 这里也要走三步: 第一步, 要send的message会和context来结合, 被放到socket的sendq中等待发送 第二步, 调用socket.send()来触发调度. 所谓调度就是从sendq取context, 从readyq取pipe 第三步, 用选定的pipe来发送这个context中的msg. 每个待发送的context都会在独立的goroutine中发送. 在本步骤会触发接下来的调度send, 即第二三步是反复互相调用的, 直到所有待发的msg都发送完成. 综上, 这里的设计是典型的同步异步化, 再同步化的过程. 同步异步化实际上是先缓存(指针)再调度的模式, 为的是快速从发送返回; 再次同步化是为了模式简单? SendMsg一般情况下会快速返回, 但在后台发送 发送失败会重传 NewSocket 看了send, 我们再回过头来从最开始的NewSocket看起.NewSocket是对上的顶层API 在实现上, req用了core的MakeSocket接口, 传入一个req.socket实例当作protocolBase // NewSocket allocates a new Socket using the REQ protocol. func NewSocket() (protocol.Socket, error) { return protocol.MakeSocket(NewProtocol()), nil } // NewProtocol allocates a new protocol implementation. func NewProtocol() protocol.Protocol { s := &socket{ nextID: uint32(time.Now().UnixNano()), // quasi-random ctxs: make(map[*context]struct{}), ctxByID: make(map[uint32]*context), } s.defCtx = &context{ s: s, cond: sync.NewCond(s), //NewCond需要传入一个locker, 而s匿名包含了sync.Mutex, 就是个locker resendTime: time.Minute, } s.ctxs[s.defCtx] = struct{}{} return s } AddPipe方法 req.socket的AddPipe方法会被core.socket在顶层dial和listen的时候有新的conn产生时调用, 会把transport层的conn\"通道\"化, 保存在req.socket的readyq里. 对REQ类型的socket来说, 所谓的readyq就是所有对端能提供REP类型的socket. func (s *socket) AddPipe(pp protocol.Pipe) error { p := &pipe{ p: pp, s: s, } pp.SetPrivate(p) s.Lock() defer s.Unlock() if s.closed { return protocol.ErrClosed } s.readyq = append(s.readyq, p) s.send() //有新的rep连接了, 触发一次调度send go p.receiver() //后面会讲 return nil } RecvMsg 无论是send还是recv msg, 都要在context上下文中进行. 因为不同于linux概念上的socket只管\"通道\"; 这里的socket的概念是应用场景下的如何使用socket的抽象, 是有状态的, 必须在状态上下文中进行. func (s *socket) SendMsg(m *protocol.Message) error { return s.defCtx.SendMsg(m) } func (s *socket) RecvMsg() (*protocol.Message, error) { return s.defCtx.RecvMsg() } ok, 从RecvMsg开始: RecvMsg是要看状态的, 而且这个函数并不是调用原始接口recv, 而是\"等待\"msg到位 -- 应该有个后台的routine一直在收包. func (c *context) RecvMsg() (*protocol.Message, error) { s := c.s s.Lock() defer s.Unlock() if s.closed || c.closed { return nil, protocol.ErrClosed } if c.recvWait || c.reqID == 0 { return nil, protocol.ErrProtoState } c.recvWait = true id := c.reqID expired := false if c.recvExpire > 0 { c.recvTimer = time.AfterFunc(c.recvExpire, func() { s.Lock() if c.reqID == id { expired = true c.cancel() } s.Unlock() }) } for id == c.reqID && c.repMsg == nil { c.cond.Wait() //在这里等待其他routine收包完成. 注意, cond.Wait会自动unlock s的mutex锁, 这是c.cond初始化时指明的. wait返回这个tmux锁会自动lock. 也就是说wait期间, s的mutex锁是开放的. 另外, go的mutex锁和routine没有关系, 可以在一个routine里lock, 但安排其他routine去unlock } //另外, cond.Wait是在for里循环的, 是有条件退出的. 即满足条件还是继续wait, 即使中间被唤醒过. m := c.repMsg c.reqID = 0 c.repMsg = nil c.recvWait = false c.cond.Broadcast() //到这里是broadcast给谁呢? if m == nil { if expired { return nil, protocol.ErrRecvTimeout } if c.closed { return nil, protocol.ErrClosed } return nil, protocol.ErrCanceled } return m, nil } 注: context.RecvMsg是一处cond.Wait()点, 另外一个点发生在context.SendMsg. 这两个地方的wait()都是在条件循环里, 即使广播式的c.cond.Broadcast()也没关系. 不是自己想要的退出条件, 还是会继续wait. receiver()函数 前面提到, 当顶层比如dial()成功了之后, 系统会把一个pipe实例AddPipe()到protocol, 也就是add到这里. 这个add流程的最后, 会 go p.receiver() 也就是说一个握了手的连接, 都对应一个go routine, 来receive msg, 可以想象, 这个receiver一定是个for循环, 从底层收了msg之后来缓存到哪里. func (p *pipe) receiver() { s := p.s for { m := p.p.RecvMsg() //从底层收完整的msg if m == nil { //m为nil的时候, 说明底层recv出现了错误, 系统会关闭错误连接, 启动redial流程新建连接. break } if len(m.Body) 接收小结 每个成功握手协商的连接都会被add到protocol里, 被protocol知道. protocol会启动一个receiver routine, 这个receiver负责收包. 然后从headder还原发送时的ID, 查表得到当时的context. 然后把接收到的msg放到c.repMsg = m, 最后返回这个msg REQ小结 从用户侧看来, req的使用很简单: sock, err = req.NewSocket() //新建req的socket, 同时也新建了默认的context; 标准API的send recv都走默认的context err = sock.Dial(url) //核心层会调用url代表的transport类型的Dial, 成功就AddPipe(); 失败会重试, 知道返回errClosed sock.Send([]byte(\"DATE\")) msg, err = sock.Recv() req.NewSocket()调用核心层的MakeSocket(REQ的接口实例)来创建socket. 特别的, 默认的最大rx size是1M REQ的socket有 默认的context sendq 代表的要发送的context readq 代表了所有可用的连接 nextID 用于给每个req分配一个唯一的ID, 这个ID用来反查ctxByID表得到context req.socket.AddPipe()会被核心层框架在新连接建立成功后调用. 这里的AddPipe()启动了receiver routine来不断的收报文. 每个新连接都会AddPipe(), 所以一个连接一个receiver routine 从收到的报文的Header部分恢复request ID, 这个ID是发送的时候填的, 代表了一个req的唯一存在. 用这个ID查到当时发送的context, 并给这个context的等待routine发广播唤醒 socket的接收必须结合context来接收, 默认使用default context来接收 context和具体的连接(pipe)没有绑定关系 RecvMsg()是用户行为, 没有msg的时候会阻塞. 某个连接的receiver routine收到报文后, 查到是这个context的报文, 其发送的广播唤醒会解除本RecvMsg路径上的wait. RecvMsg()还负责唤醒本context上等待的SendMsg() SendMsg也是要结合context, 默认也是默认的context来发送 得到requestID, 和context一起记录到socket的sendq中 真正的发送实际上有点像softirq, 是个触发点: 调用send()的时候, 实际上是trigger了一次后台发送序列, 该序列中会把所有之前的报文都发出去. 真正的\"通道\"级发送是每个报文都在后台发送go p.sendCtx(c, m); 在没有真正发送完成之前, 就\"广播\"到该context可以继续往下走了(见下一条), 每个待发的msg都\"广播\"一次. 如果本context还是在发本msg, 或者没有超时, 就一直wait(一般这个条件不成立) 综上, 发送是softirq式的触发一波异步发送(go p.sendCtx(c, m)), 但不用等真正的报文从\"通道\"socket发送完毕. 用户侧发送和接收都有超时设定 发送有重发机制, 默认1分钟重发. 但似乎性能很堪忧, 因为每个sendq里面的context, 在真正发送之前, 都无条件起一个1分钟定时器来重发. 就不能发送失败了再起定时器重发吗? protocol/rep/rep.go NewSocket NewSocket的套路和REQ一样: 调用核心层protocol的函数MakeSocket, 传入自己的接口实现 // NewSocket allocates a new Socket using the REP protocol. func NewSocket() (protocol.Socket, error) { //传入的参数是REP类型的protocol的实现的实例 return protocol.MakeSocket(NewProtocol()), nil } REP类型的protocol的实现的实例: // NewProtocol allocates a protocol state for the REP protocol. func NewProtocol() protocol.Protocol { s := &socket{ ttl: 8, //默认最大支持8跳, 即中间有7个\"router\"存在 contexts: make(map[*context]struct{}), recvQ: make(chan recvQEntry), // unbuffered! 注释写的很清楚, 非缓冲的channel master: &context{ closeQ: make(chan struct{}), }, } s.master.s = s s.contexts[s.master] = struct{}{} return s } 其核心实现结构体: type socket struct { closed bool ttl int sendQLen int recvQ chan recvQEntry //这个socket只有recvQ, 没有sendQ? 而且这个recvQ可以大约认为只有1个槽位. contexts map[*context]struct{} master *context sync.Mutex } AddPipe 在AddPipe()的时候, 同时起了sender routine和receiver routine. 这里的protocol.Pipe是对底层transport.Pipe的封装, 实现了核心层ProtocolPipe的接口要求. func (s *socket) AddPipe(pp protocol.Pipe) error { p := &pipe{ p: pp, s: s, sendQ: make(chan *protocol.Message, s.sendQLen), //sendQlen是有Q size的 closeQ: make(chan struct{}), } pp.SetPrivate(p) //各种回调函数变身成了名正言顺的接口的使用 s.Lock() if s.closed { s.Unlock() return protocol.ErrClosed } go p.sender() //每个连接一个sender go p.receiver() //每个连接一个receiver s.Unlock() return nil } func (s *socket) RemovePipe(pp protocol.Pipe) { p := pp.GetPrivate().(*pipe) //这里对应了AddPipe的时候SetPrivate(存钱), 这里就来取钱了. close(p.closeQ) } 注意, 这里的sendQLen默认为0; 但一般会调用SetOption()接口把protocol.OptionWriteQLen设为1, 需要手动设置. protocol/rep/rep_test.go-101- p := GetSocket(t, xreq.NewSocket) protocol/rep/rep_test.go:102: MustSucceed(t, s.SetOption(mangos.OptionWriteQLen, 1)) protocol/rep/rep_test.go-103- MustSucceed(t, p.SetOption(mangos.OptionReadQLen, 1)) 本文语境下的 socket有recvQ pipe有sendQ 每个连接一个sender 从sendQ里面拿一个msg, 发送; 发送失败就关闭这个pipe. func (p *pipe) sender() { for { select { case m := 每个连接一个receiver 从底层通道收包, 检查hops是否超过ttl 最后放到socket的recvQ中 func (p *pipe) receiver() { s := p.s outer: for { m := p.p.RecvMsg() //从protocol pipe收msg, 其具体实现在core/pipe.go; 最终是transport层收包 if m == nil { break } // Move backtrace from body to header. // 每4个字节表示一跳, 最开始都会有一跳; 最高位不是0就不是一跳 // hop信息是保存在body里面的, 因为header好像是固定字节的, 不可能把所有hop都放进去. hops := 0 for { if hops >= s.ttl { m.Free() // ErrTooManyHops continue outer } hops++ if len(m.Body) RecvMsg 用户调用Recv, core会调用到这里 func (c *context) RecvMsg() (*protocol.Message, error) { s := c.s s.Lock() //先是检查些状态 if c.closed { s.Unlock() return nil, protocol.ErrClosed } //在这个recv没有结束之前, 不能再次recv; 就是说recv路径下不能有并发 if c.recvWait { s.Unlock() return nil, protocol.ErrProtoState } c.recvWait = true cq := c.closeQ wq := nilQ expireTime := c.recvExpire s.Unlock() if expireTime > 0 { wq = time.After(expireTime) } var err error var m *protocol.Message var p *pipe select { case entry := SendMsg 用户调用send, 核心层会调用到这里 rep服务器的逻辑是, 必须先recv, 再send, 这两者必须成对出现. 而且中间不能有其他的recv或send. func (c *context) SendMsg(m *protocol.Message) error { r := c.s r.Lock() if r.closed || c.closed { r.Unlock() return protocol.ErrClosed } if c.backtrace == nil { //没有recv过, 状态错误 r.Unlock() return protocol.ErrProtoState } p := c.recvPipe //发送来的通道 c.recvPipe = nil bestEffort := c.bestEffort timeQ := nilQ if bestEffort { timeQ = closedQ } else if c.sendExpire > 0 { timeQ = time.After(c.sendExpire) } m.Header = c.backtrace //回复给client的header就是client当时发过来的, 一模一样. c.backtrace = nil cq := c.closeQ r.Unlock() select { //这个是经典的select结构:带timeout, 带close的选择器 case REP小节 从用户侧看来, 使用rep很简单: sock, err = rep.NewSocket() //新建一个rep socket实例 err = sock.Listen(url) //接受连接. 核心层有个goroutine会循环等待新连接. 每个成功建立的连接都会调用protocol的AddPipe()动作, 后者会起后台的sender和receiver msg, err = sock.Recv() //用户发起一次recv, 会从socket.recvQ中接收一个msg, 这样\"众多\"的连接的receiver routine的写recvQ的动作才能往下走. 这个recvQ是阻塞的. 用户在recv和send之间做业务逻辑 err = sock.Send([]byte(d)) //因为recv记录了来的路径到上下文, send的reply会根据上下文沿路返回到client 所有连接背后的receiver收包后, 都会往s.recvQ中写一个entry(也就是msg), 这个recvQ是unbuffered.即所有写都会阻塞, 同时只有一个能写; 在用户没有调用最顶层的recv时, 全部连接的收包都不能继续. 当用户调用了顶层recv处理了一个req后, 下一个req的msg会被送入s.recvQ receiver收包后, 会把msg和代表连接信息的pipe一起, 发给s.recvQ 用户recv并进行了业务逻辑的处理后, 调用send, 把相应msg沿路返回发送回client. recv和send时严格的lock step模式. 即一个context同时只能处理一个请求; 我认为如果业务逻辑复杂, 要么调用顶层APIOpenContext()创建并使用多context来并发处理 -- 可行. 要么就用当前context, 但用go的方式处理业务逻辑? -- 不行, 因为recv和send之间用context来传递上下文, 比如recv后, 用c.backtrace保存req的header; send的时候又要用这个header. 如果产生并发, c.backtrace会被后续的新的recv覆盖. rep支持多跳(hops), hops信息被保存在msg.Body里面; 在receiver里面, hops信息被搬到msg.Header里 在socket级别只有一个unbuffered的recvQ, 没有sendQ; sendQ是代表连接的pipe的属性. 在发送的时候, rep msg会被先放到对应连接的sendQ里, 在sender routine里, 调用protocol pipe来真正发送. 不要被protocol pipe的名字迷惑, 它实际上是核心层core对transport的pipe的包装. 不要使用bestEffort选项, rep会随机\"不发\"响应. 发送 reply失败没有重传, 超时了会返回protocol.ErrSendTimeout req rep疑问 为什么req的设计思路是sync.cond + softirq式的延迟执行, 而rep的设计思路是简单明了的channel? 在req和rep的receiver实现中, 都有下面的操作: 把body移动4个字节给header, 如果说body的前四个字节有特殊意义, 但为什么没有找到对应的发送时候填入的这四个字节? 他们是在哪里填入的?m.Header = append(m.Header, m.Body[:4]...) m.Body = m.Body[4:] 答: 他们是在transport层填入的. 在transport层看来, header和body是一体的, transport先计算总的size(int64), 然后把(size, header, body)写入通道; 而接收的时候, 先用一次系统调用得出size, 再把剩下的内容全部放到body中. 这就解释了为什么上面的protocol层的代码中, 要从body中还原header了... xreq和xrep xreq和xrep是简化版的req和rep, 他们都是同一个协议族. 他们都没有context的概念 实例代码在examples/raw xreq xreq似乎改用了channel, 更简单, 功能似乎也删减了... xreq的socket有recvQ和sendQ的channel, 里面是msg, 默认都是128个长度 在AddPipe()阶段改成了和上面rep一样的每个连接都有后台的sender和receiver 在receiver中, 还是会把对端发来的body的头四个字节当作header, 但这次是直接当header, 而不是appendm.Header = m.Body[:4] m.Body = m.Body[4:] 竟然还是有timeQ的bug???? xreq没有失败自动重传 xrep 默认的recvQ有128的长度, 而rep是unbuffered AddPipe()依然有receiver和sender后台routine 取消了context, 在接收msg的时候, 把pipe信息直接加到msg header中. 发送msg的时候, 看header就知道pipe ID, 就能原路返回 这样搞就必须要求用户直接使用RecvMsg和SendMsg 再看核心层的核心价值 提供了socket对象的实现, 这个对象被protocol层传递给用户, 它就是用户看到的socket. 这个socket对象持有的数据都是私有的, 对外只提供接口 这个socket是client和server的结合体, 既有listener列表, 又有dialer列表 持有代表连接的核心对象pipes, 被组织成按ID(unit32)查询的map 有一把全局socket锁 有其他的属性和标记, 比如是否异步dial, 最大接收size等. protocol层会调用core的MakeSocket()来创建socket, 核心层只是新建了一个socket结构体返回, 没有任何其他的routine的创建. 核心动作Dial和DialOptions最终由用户调用. 注意, 此时socket就已经知道transport的具体类型了. 实际动作包括两步: 先调用和transport约定好的的NewDialer()接口td, err := t.NewDialer(addr, s), 并包装这个td, 构成核心层的dialer结构体. 最后把这个结构体放到s.dialers中. 调用同是核心层的dialer.go中的Dial 检查状态, 调用transport层的Dial方法; 连接成功会调用核心层的addPipe()方法, 后面会讲. redial模式下会后台dial, 这里提前返回nil; 后台redial有重试的避让策略, 避免短时间大量不断重试 非redial模式下, dial不成功马上返回err 核心动作Listen是server端的用户动作 第一步也是处理完option后, 包装transport层的tl, err := t.NewListener(addr, s)对象tl, 做为核心层的listener实例. 第二步是调用transport的listen, 这个listen实际上是bind+listen的原始socket的动作 第三步是起个后台routine来做循环l.l.Accept(), 并把建立好的pipe加到socket: l.s.addPipe(tp, nil, l) 核心动作在Dial有重试, Listen有后台routine做循环accept, 这些\"附加\"的功能是核心层提供的. 核心层的Send/SendMsg, Recv/RecvMsg都是用户调用触发的, 都是直接调用protocol层的SendMsg/RecvMsg 核心层的核心是pipe, 每个连接都会addPipe(); 核心层的pipe是个混合体, 有dialer和listener, 但一般场景下, 不是同时生效. 每个连接, 不管是client dial的来的, 还是server listen得来的, 都对应一个核心层的pipe; 虽然实现在核心层, 但对外是以protocol.Pipe示人的, 即核心层的pipe实现了protocol层(更确切的说法是全局层, 对外层)Pipe规定的方法. addPipe()会新生成一个pipe实例, 并分配唯一的ID(unit32); 这个pipe实例被socket保存在map表里, 方便后面根据ID查询 addPipe()会调用与protocol层约定好的AddPipe()方法s.proto.AddPipe(p); 后者会保存p以便发送, 接收 核心层的pipe的Send和Recv以及Close, 提供失败重连的功能. 因为在addPipe阶段, 会把核心层的pipe实例以protocol.Pipe接口的形式传递给protocol, protocol想真正发送 接收msg的时候, 会调用到核心层pipe提供的SendMsg()和RecvMsg()方法, 这两个方法都是调用transport层的发送接收方法. 特别的, 从核心层收到的msg, 都会记录pipe信息到msg.Pipe域. 任何transport层的send recv失败发生时, 都会调用p.Close(); 这个close的动作会触发重建连接(redial)动作, 说明系统任务这个transport通道已然不行了, 要重建. 同时, 也会调用protocol层的RemovePipe()接口, 来让protocol层知道这个pipe已经失效. 这是个很好的策略, 即发送失败不要简单重试, 而是重新建链. 核心层的Send()实现是拷贝式send, 即用户提供的buffer会被拷贝到新buffer后再send; Recv()也是拷贝式的,即接收的msg.Body会被拷贝到新buffer后返回新buffer; 题外: 作者特别喜欢用append来拷贝buffer msg.Body = append(msg.Body, b...) 但对应的SendMsg()和RecvMsg()就都不会有新buffer产生. 总结 核心层对上直接承接了用户api的接口, 它既规定了protocol要实现的接口: AddPipe() SendMsg() RecvMsg(), 又规定了transport必须实现的接口: NewListener(), NewDialer(), Dial(), Listen(), Accept(). 通过这些规定的接口, 核心层把protocol层和transport层解耦了.核心层对连接的抽象是combine的, 即把client和server的dial和listen过程独立抽象, 但他们的结果都是新建一个pipe, 而这个pipe就承载了后面的发送, 接收功能. 核心层在建立连接后, 会把自己对protocol的承诺(也就是protocol.pipe)的实例, 传递addPipe(p)给protocol层, 这个p就代表了transport的抽象. 同时, 核心层还提供如下功能: 核心层会在redial模式下重试dial 核心层会启动后台routine帮助server来accept连接 核心层在调用transport层的发送接收api失败时, 会断开当前连接, 自动重建新连接. 核心层并没有提供以下机制: 队列 反压 统计 调度 即核心层负责抽象和解耦, 只提供最基本的功能. "},"notes/golang_libp2p.html":{"url":"notes/golang_libp2p.html","title":"p2p网络","keywords":"","body":" libp2p文档 入门 transport QUIC 特性 libp2p里的quic 地址格式 同时支持多transport Nat穿透 circuit relay 协议和stream 内置协议 peer ID 内容路由和peer发现 安全 发布和订阅 发现peer full message和meta message 多路复用 知识点 go的开发状态 transport Stream muxers Crypto channels Connection & Connection Upgrades Peer routing NAT Traversal Discovery 其他 例子 echo makeBasicHost runListener runSender 总结 host routed echo 总结 chat 使用 既然要IP, 那后面那一大串p2p的地址是干啥的? 代码 chat mdns 使用 代码 chat with peer发现, 基于dht 用到的package 代码 总结 pub sub chat room 代码 relay 代码 multipro 代码 总结 总结的总结 扩展 host的option 默认值 规范 如何建立连接 协议协商 连接升级 新建stream 具体实现 隧道 relay Addressing STUN-like Coordination 节点发现机制 几种场景 问答 将来work Peer Ids and Keys key的使用场景 identify协议 mplex协议 Rendezvous集结协议 大概原理 Protocols汇总 基础知识 公钥与私钥 讨论 对称加密（Symmetric Cryptography） 非对称加密（Asymmetric Cryptography） 总结 libp2p文档 https://docs.libp2p.io/introduction/ libp2p是个开发p2p应用的框架. libp2p起源于IPFS, 以模块化的方式把基础的p2p网络分离为独立的libp2p. 那么libp2p有哪些功能? 解决了哪些通用问题? Transport: transport是p2p网络的基础, 负责peer间的实际数据的发送/接收. 为了支持现有的和将来的协议, libp2p定义了一组统一的interface Identity: 身份标识是安全和可靠网络的保证. libp2p用非对称加密的公钥做为peer的标识(PeerId), 这个PeerId就是每个peer的全球唯一名字; 因为p2p的\"open\"本质, PeerId既是名字又是公钥, 其他任何peer都可以通过PeerId得到其公钥. 这样在peer之间的通信是安全的. Security: libp2p支持TLS1.3(就是ssh用的那个, 前身是ssl)和Noise协议在transport上面加密传输数据. Peer Routing: 知道了PeerId, 还要知道网络上怎么访问到它. 经常我们只知道PeerId不知道网络位置, 这就需要peer路由. libp2p用DHT(distributed hash table, 通常每个node都预分配key空间, 所有的node组成一个大的hash表)来查询peer routing, DHT也可以提供其他metadata的key value的查询服务. go支持Kademlia的DHT算法(UDP based, O(log(n))的搜索效率) Content Discovery: 有时候我们不关心对方peer在哪, 只关心我要的内容能不能被其他peer提供. libp2p提供了内容发现的接口, 底层基于同样的Kademlia的DHT技术. Messaging / PubSub: peer发送消息给其他peer是p2p网络的核心, 其中pub/sub模式最为实用.libp2p定义了pub/sub的接口, 用于在给定topic下面发送消息给所有的peer. 目前支持简单粗暴的floodsub和比较高端的gossipsub. 后者的升级版本episub正在开发中. 入门 listen的地址是0号端口, 自动分配. 这里关闭了内置的ping(还有内置的ping?) func main() { ... // start a libp2p node that listens on a random local TCP port, // but without running the built-in ping protocol node, err := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/127.0.0.1/tcp/0\"), libp2p.Ping(false), ) // configure our own ping protocol pingService := &ping.PingService{Host: node} node.SetStreamHandler(ping.ID, pingService.PingHandler) ... } transport 最常见的transport是TCP, 另外也提到了QUIC(Quick UDP Internet Connections, google发布的基于UDP的协议), 其目标是替代TCP libp2p的设计初衷是transport透明化, 由开发者决定使用哪种transport, 或者同时支持多种transport. QUIC QUIC 与现有 TCP + TLS + HTTP/2 方案相比，有以下几点主要特征： 1）利用缓存，显著减少连接建立时间； 2）改善拥塞控制，拥塞控制从内核空间到用户空间； 3）没有 head of line 阻塞的多路复用； 4）前向纠错，减少重传； 5）连接平滑迁移，网络状态的变更不会影响连接断线。 特性 采用 多路复用 思想，一个连接可以同时承载多个 流 ( stream )，同时发起多个请求。 请求间完全 独立 ，某个请求阻塞甚至报文出错均不影响其他请求。 对比 HTTP 长连接，由于 TCP 是只实现一个字节流，如果请求阻塞，新请求无法发起。 新的安全机制比 TLS 性能更好，而且具有各种攻击防御策略。 前向纠错 TCP 采用 重传 机制，而 QUIC 采用 纠错 机制。 TCP 发生丢包时，需要一个等待延时判断发生了丢包，然后再启动重传机制，这个过程会造成一定的阻塞，影响传输时间。 而 QUIC 则采用一种更主动的方案，有点类似 RAID5 ，每 n 个包额外发一个 校验和包 。 如果这 n 个包中丢 应用程序内实现 QUIC 直接基于客户端(应用进程)实现，而非基于内核，可以快速迭代更新，不需要操作系统层面的改造，部署灵活。 这也是不使用基于迭代升级 TCP 方案的原因 —— TCP 在操作系统内核中实现，很难进行大规模调整以及推广。 连接保持 QUIC 在客户端保存连接标识，当客户端 IP 或者端口发生变化时，可以快速恢复连接 —— 客户端以标识请求服务端，服务端验证标识后感知客户端新地址端口并重新关联，继续通讯。 这对于改善移动端应用连接体验意义重大(从 WiFi 切换到流量)。 libp2p里的quic go-libp2p-quic-transport uses quic-go to provide QUIC support for libp2p. 地址格式 libp2p使用一种叫multiaddr的东西来描述地址, 这个描述兼容所有的transport类型.比如 /ip4/7.7.7.7/tcp/6543 libp2p的通信单元叫peer, 用peerId来唯一标识; 必须指定peerId来建立安全信道来通信. /ip4/1.2.3.4/tcp/4321/p2p/QmcEPrat8ShnCph8WjkREzt5CPXF2RwhYxYBALDcLC1iV6 同时支持多transport 一般libp2p是支持多transport, 比如一个服务可以同时对使用TCP的一个守护进程和使用websocket的浏览器服务. 能实现对多transport的多路复用, 是因为libp2p有个switch层(也叫swarm层), 提供了 协议协商: 当客户端dialing一个新的stream的时候, 它会发送protocol id来和服务端协商, 如果服务端也支持该协议, 就会返回这个协议ID, 之后的通信会使用这个协商好的协议来进行. 如果不支持, 返回不支持, 那么客户端要么停止, 要么发起另外一个protocol ID来进行下一轮协商. -- 想法: encoding也要协商 stream多路复用: 就是使用一个物理的transport(比如一个TCP连接)来支持多个逻辑上的stream的通信. 一个stream有个很短的header来标记stream. libp2p使用mplex multiplexing实现, 同时也提供了yamux和spdy实现. mplex: 每次通信都会加个header, payload是固定长度的data segment. header是个base128的变长数, 最长9字节. mplex基于可靠的, 保序的传输层协议比如TCP或UDS. 这个应该是默认的.| header | length | data | | uvarint | uvarint | 'length' bytes | Yamux: 另外一种multiplexing, 支持双向stream, 支持流控, 同时支持大量stream消耗比较小. spdy: chrome浏览器项目, 面向web协议的 建立安全连接 Nat穿透 代码在go-libp2p-nat 有的路由器支持UPnP或nat-pmp协议, libp2p会尝试自动配置端口映射. STUN打洞: 内网能dial出去, 是因为内网路由器会map这个内部端口到对外可见的端口. 有的路由会把incoming的到这个端口的连接也转发给内网. libp2pyong SO_REUSEPORT选项复用这个IP的端口号 内网出去方向的连接会在内网路由器分配一个对外的端口号, 这个端口号外部可见, 但内部是不知道的. 那么可以让外部的peer告诉我们我们的外部地址是什么, 然后我们就可以告诉p2p网络, 这个地址可以到达我们. 那么谁来当这个外部的观察者呢?传统的STUN实现需要固定的外部观察者, 而libp2p使用了identify protocol在peer间交换信息:https://github.com/libp2p/specs/tree/master/identify, 基本上是个/ipfs/id/1.0.0这个协议ID, 交换的信息如下, 其中就有observedAddrmessage Identify { optional string protocolVersion = 5; optional string agentVersion = 6; optional bytes publicKey = 1; repeated bytes listenAddrs = 2; optional bytes observedAddr = 4; repeated string protocols = 3; } AutoNAT服务: 在identify告知我们的外部观察port后, 还可以让它peer回拨我们的port, 这需要使能AutoNAT服务, 让对方回拨. 回拨成功就知道这个端口可以允许穿透内网. Circuit Relay (TURN): 有时候内网就是出不去, 这个协议可以先在内网找个跳板节点再访问. 比如内网的QmAlice想让QmBob访问, 她可以找个relay的节点:/ip4/7.7.7.7/tcp/55555/p2p/QmRelay/p2p-circuit/p2p/QmAlice告知QmBob, 这样QmBob就可以通过这个relay的节点访问QmAlice了. circuit relay 打开了autorelay的话, libp2p会使用内容路由的接口, 自动发现提供relay服务的peer. 当autoNAT服务发现我们在受限的NAT网络里面后, autorelay就起作用了 discovering relay nodes around the world, establishing long-lived connections to them, and advertising relay-enabled addresses for ourselves to our peers, thus making ourselves routable through delegated routing. When AutoNAT service detects we’re behind a NAT that blocks inbound connections, Autorelay jumps into action, and the following happens: We locate candidate relays by running a DHT provider search for the /libp2p/relay namespace. We select three results at random, and establish a long-lived connection to them (/libp2p/circuit/relay/0.1.0 protocol). Support for using latency as a selection heuristic will be added soon. We enhance our local address list with our newly acquired relay-enabled multiaddrs, with format: /ip4/1.2.3.4/tcp/4001/p2p/QmRelay/p2p-circuit, where: 1.2.3.4 is the relay’s public IP address, 4001 is the libp2p port, and QmRelay is the peer ID of the relay. Elements in the multiaddr can change based on the actual transports at use. We announce our new relay-enabled addresses to the peers we’re already connected to via the IdentifyPush protocol. The last step is crucial, as it enables peers to learn our updated addresses, and in turn return them when another peer looks us up. 协议和stream 这里说的协议是应用定义的协议, 协议id是任意字符串, 但按惯例是类似这样的: /my-app/amazing-protocol/1.0.1 两端在协议对接的时候, 有个协商过程. 协议id使用全匹配方式 每个协议都可以set一个handler. 也可以set一个match handler, 自己进行协议匹配. 可以注册多个协议匹配handler, 当一个协议没有确切的handler的时候, 会逐个调用匹配handler来匹配. 可以使用MultistreamSemverMatcher来匹配版本号 dial的时候要传入协议id, 可以是多个, 通常是一个协议的多个版本. stream可以是半关闭的, 即以把写关了, 只保留读. stream地下的switch层是加密的, 但stream看到的是解密后的数据 内置协议 内置协议都使用protobuf编码 /ipfs/ping/1.0.0: 一个peer来ping, 另外一个响应. 记录lattency /ipfs/id/1.0.0: 交换peerId的协议, 告知对方自己的信息. 特别的, identify协议的响应消息里有observedAddr, 用于告知对方它的外部观测的地址. /ipfs/id/push/1.0.0: 用于通知别人自己的网络有变化 /secio/1.0.0: secure IO. 用于加密通信. 因为peerId实际上是从公钥得出的, 所以可以验证签名是否正确. 这样就不需有像TLS中Certificate Authority的过程. -- 注意, secio是默认的加密协议, 但以后的默认加密协议是TLS1.3 /ipfs/kad/1.0.0: dht协议 /libp2p/circuit/relay/0.1.0: realy协议 peer ID 每个peer都有自己知道的私钥, 并把公钥公开到p2p网络中, 公钥的hash就是peer ID. 所以 连接上的peer都知道每个人的公钥 peer ID其实不是字符串, 只是hash值用base58编码后, 字符串化了. peer info结构包括peerID和这个peer监听的multiaddr地址. 每个peer都有个\"电话本\", 记录它知道的peer info 内容路由和peer发现 待续 安全 libp2p的底层通信是加密, 但只是在传输层. 一个p2p网络通常还需要某种\"权限控制\"策略, 来决定谁有权限去做什么. libp2p没有提供内置的\"权限控制\"功能. 发布和订阅 基于gossipsub协议的消息扩散策略. Reliability: All messages get delivered to all peers subscribed to the topic. Speed: Messages are delivered quickly. Efficiency: The network is not flooded with excess copies of messages. Resilience: Peers can join and leave the network without disrupting it. There is no central point of failure. Scale: Topics can have enormous numbers of subscribers and handle a large throughput of messages. Simplicity: The system is simple to understand and implement. Each peer only needs to remember a small amount of state. 发现peer 这里的发现指发现同一个topic的peer, 如果gossipsub已经基于一个建立好的p2p网络, 怎么知道谁订阅了某个topic呢? 应用需要自己发现peer, 用下面的方法: Distributed hash tables Local network broadcasts Exchanging peer lists with existing peers Centralized trackers or rendezvous points Lists of bootstrap peers full message和meta message 比如上图中, 有连接的节点都是一个topic下面的, 但只有粗实线的连接被用来传递\"gossip\". 上图配置成3个peer来做粗线, 通常配置成6, 一般在4-12之间. meta data的连接用来维护gossip网络 粗线和细线可以互相转换: https://docs.libp2p.io/concepts/publish-subscribe/#grafting-and-pruning subscribe和unsubscribe信息交换: 每个peer都和它相连的peer交换各自的topic订阅信息. 发送消息: 消息会被粗线连接扩散. 谣言八卦: 每秒钟, 细线连接间都互相八卦说我看到了什么gossip. 目的是补充实线网络中的遗漏, 如果一个peer发现它得到的八卦总是少点, 它就需要和别人多增加实线连接. 不需要订阅就可以发送某个topic下面的消息: 随机选择6个连接来发送 信息聚合: 不同类型的信息可以聚合在一起, 用一个报文发送 多路复用 多路复用的目的是使用一个底层transport来服务多个stream. 这个switch(aka swarm)是在第一次建立transport连接的时候协商的. libp2p提供: mplex:libp2p自己写的, 比较简单 yamux: 复杂点, 支持一些高级特性比如流控 quic: 基于UDP的用户态TCP. 它实际上是一个transport, 但有native multiplexing能力. libp2p会在支持quic协议的节点直接使用这个能力. spdy: 目标是http2.0 muxado: 可能比较小众... 知识点 https://docs.libp2p.io/reference/glossary/ Circuit Relay: 在两个不能直接连接的节点之间, 通过第三个willing node来连接. 比如两个不同内网的节点通过共同的外网节点relay; 或者一个说tcp, 一个说websocket的节点, 通过第三个说双语的节点来talk. DHT: 分布式的hash表. peer routing和content routing依赖DHT. 可以用来做内容发现和服务广播. Multihash: 用来产生peerID和其他libp2p系统内的hash值的.multihash在原hash基础上加了两个字节的头.这两个字节表示了hash算法和长度. 比如用base58编码后的QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N, Qm就是加的两个字节, 表示SHA-256, 256bit长度. go的开发状态 https://libp2p.io/implementations transport libp2p-tcp libp2p-quic libp2p-websockets 支持比较好 Stream muxers libp2p-multiplex libp2p-yamux 已ready Crypto channels libp2p-secio libp2p-tls libp2p-noise Connection & Connection Upgrades libp2p-conn Peer routing libp2p-kad-dht NAT Traversal libp2p-nat还在开发中, 不稳定 Discovery bootstrap random-walk mdns-discovery都OK 其他 libp2p-floodsub libp2p-gossipsub crypto libp2p-ping libp2p-peer-info libp2p-peer-book libp2p-swarm都OK. 例子 echo 运行两个echo实例, 一个是listener, 一个是sender 它们都是个basichost, 它是更底层的go-libp2p swarms的封装. swarm处理更细节的流, 连接, 多协议多路复用等. makeBasicHost // makeBasicHost creates a LibP2P host with a random peer ID listening on the // given multiaddress. It won't encrypt the connection if insecure is true. func makeBasicHost(listenPort int, insecure bool, randseed int64) (host.Host, error) { var r io.Reader if randseed == 0 { r = rand.Reader } else { r = mrand.New(mrand.NewSource(randseed)) } // Generate a key pair for this host. We will use it at least // to obtain a valid host ID. priv, _, err := crypto.GenerateKeyPairWithReader(crypto.RSA, 2048, r) if err != nil { return nil, err } opts := []libp2p.Option{ libp2p.ListenAddrStrings(fmt.Sprintf(\"/ip4/127.0.0.1/tcp/%d\", listenPort)), libp2p.Identity(priv), libp2p.DisableRelay(), } if insecure { opts = append(opts, libp2p.NoSecurity) } return libp2p.New(context.Background(), opts...) } crypto.GenerateKeyPairWithReader: 先用RSA生成私钥, 私钥可以推导出公钥 libp2p.ListenAddrStrings: 使用写死的地址: /ip4/127.0.0.1/tcp/%d libp2p.Identity: 使用上面的priv key生成PeerId libp2p.DisableRelay(): 禁止relay transport libp2p.NoSecurity: libp2p默认都是加密的, 初非用这个显式声明非加密 libp2p.New: 新建libp2p node的核心接口, 支持很多配置选项, 如果没有显式的指定, 有合理的默认值: 默认监听/ip4/0.0.0.0/tcp/0 和 /ip6/::/tcp/0 默认使用TCP和websocket传输协议 默认使用多路复用协议yamux和mplux, 多路复用协议会在peer间协商? 默认加密, 使用noise协议或者TLS 默认使用RSA 2048产生随机的PeerId 默认用空的peerstore(用于peer routing) 有个API NewWithoutDefaults没有任何default配置, 但不建议使用. Host是p2p网络的一个实体, 它既是server, 可以提供服务; 又是client, 可以发送请求. 所以叫host, 是二合一. host有一系列聚合的抽象: type Host interface { // ID returns the (local) peer.ID associated with this Host ID() peer.ID // Peerstore returns the Host's repository of Peer Addresses and Keys. Peerstore() peerstore.Peerstore // Returns the listen addresses of the Host Addrs() []ma.Multiaddr // Networks returns the Network interface of the Host Network() network.Network // Mux returns the Mux multiplexing incoming streams to protocol handlers Mux() protocol.Switch // Connect ensures there is a connection between this host and the peer with // given peer.ID. Connect will absorb the addresses in pi into its internal // peerstore. If there is not an active connection, Connect will issue a // h.Network.Dial, and block until a connection is open, or an error is // returned. // TODO: Relay + NAT. Connect(ctx context.Context, pi peer.AddrInfo) error // SetStreamHandler sets the protocol handler on the Host's Mux. // This is equivalent to: // host.Mux().SetHandler(proto, handler) // (Threadsafe) SetStreamHandler(pid protocol.ID, handler network.StreamHandler) // SetStreamHandlerMatch sets the protocol handler on the Host's Mux // using a matching function for protocol selection. SetStreamHandlerMatch(protocol.ID, func(string) bool, network.StreamHandler) // RemoveStreamHandler removes a handler on the mux that was set by // SetStreamHandler RemoveStreamHandler(pid protocol.ID) // NewStream opens a new stream to given peer p, and writes a p2p/protocol // header with given ProtocolID. If there is no connection to p, attempts // to create one. If ProtocolID is \"\", writes no header. // (Threadsafe) NewStream(ctx context.Context, p peer.ID, pids ...protocol.ID) (network.Stream, error) // Close shuts down the host, its Network, and services. Close() error // ConnManager returns this hosts connection manager ConnManager() connmgr.ConnManager // EventBus returns the hosts eventbus EventBus() event.Bus } runListener func runListener(ctx context.Context, ha host.Host, listenPort int, insecure bool) { fullAddr := getHostAddress(ha) log.Printf(\"I am %s\\n\", fullAddr) // Set a stream handler on host A. /echo/1.0.0 is // a user-defined protocol name. ha.SetStreamHandler(\"/echo/1.0.0\", func(s network.Stream) { log.Println(\"listener received new stream\") if err := doEcho(s); err != nil { log.Println(err) s.Reset() } else { s.Close() } }) log.Println(\"listening for connections\") if insecure { log.Printf(\"Now run \\\"./echo -l %d -d %s -insecure\\\" on a different terminal\\n\", listenPort+1, fullAddr) } else { log.Printf(\"Now run \\\"./echo -l %d -d %s\\\" on a different terminal\\n\", listenPort+1, fullAddr) } // Wait until canceled getHostAddress: 使用mutliaddr的Encapsulate函数, 把peerId包装进network地址中:I am /ip4/127.0.0.1/tcp/10000/p2p/QmW1Ze4AbEtWtTg5ibcnsLgUPJsZ3wh1VuGzhqHtrvAp2e SetStreamHandler(pid protocol.ID, handler network.StreamHandler): 给mux层设定一个handler. 第一个参数是个string, 描述协议的, 第二个参数handler的签名是type StreamHandler func(Stream), 有点像OnConnect(), 同样的是会被框架传入Stream, 这是个在mux层之上的概念, 提供逻辑上的2个agent之间的双向通信, 是io reader和io writer, 它的下面是个multiplexer. 这里这个handler很简单, 就是doEcho. 因为s network.Stream是框架传入的, 能直接做io读写操做. // doEcho reads a line of data a stream and writes it back func doEcho(s network.Stream) error { buf := bufio.NewReader(s) str, err := buf.ReadString('\\n') if err != nil { return err } log.Printf(\"read: %s\", str) _, err = s.Write([]byte(str)) return err } runSender sender通过用于输入-d的地址, 比如/ip4/127.0.0.1/tcp/10000/p2p/QmW1Ze4AbEtWtTg5ibcnsLgUPJsZ3wh1VuGzhqHtrvAp2e来dial listener. 通过multiaddr的Decapsulate操做, 把targetPeerAddr提取出来:/ip4/127.0.0.1/tcp/10000 然后add到peerstore中: ha.Peerstore().AddAddr(peerid, targetAddr, peerstore.PermanentAddrTTL) s, err := ha.NewStream(context.Background(), peerid, \"/echo/1.0.0\"): NewStream连listener, 使用相同的echo1.0.0协议. 然后直接调用s.Write([]byte(\"Hello, world!\\n\"))来发送. 总结 listener和sender都是host, host是p2p网络的一个node host可以定制, 列表在https://pkg.go.dev/github.com/libp2p/go-libp2p listener指定stream的处理函数, 有新的stream连接的时候会调用. RSA等非对称算法生成的key是peerId multiaddr能够处理多地址协议, 统一地址的表达方式 空的peerstore不能\"发现\"peer, 所以本例的连接信息还是要用户输入. host.Newstream(ctx, peerId, ...protocolId)用于向指定peerId发起一个stream连接, protocolId是个[]string, 指定要走的用户(多个)协议, 比如\"/echo/1.0.0\" stream的抽象是io reader writer, 面向字节流的. sender类似client, client的逻辑是建立连接然后直接write host 之前的echo的例子只是用了简单的option. 我们在这个例子里会用一些常用的option, 使能了routing, 使nat网络也能发现. // To construct a simple host with all the default settings, just use `New` h, err := libp2p.New(ctx) //h2是个定制的host h2, err := libp2p.New(ctx, // Use the keypair we generated, 使用自定义key libp2p.Identity(priv), // Multiple listen addresses, 指定多个listen地址 libp2p.ListenAddrStrings( \"/ip4/0.0.0.0/tcp/9000\", // regular tcp connections \"/ip4/0.0.0.0/udp/9000/quic\", // a UDP endpoint for the QUIC transport ), // support TLS connections libp2p.Security(libp2ptls.ID, libp2ptls.New), // support secio connections libp2p.Security(secio.ID, secio.New), // support QUIC - experimental libp2p.Transport(libp2pquic.NewTransport), // support any other default transports (TCP) libp2p.DefaultTransports, // DefaultTransports是tcp和websocket // Let's prevent our peer from having too many // connections by attaching a connection manager. libp2p.ConnectionManager(connmgr.NewConnManager( 100, // Lowwater 400, // HighWater, time.Minute, // GracePeriod )), // 下面这几个配置了NAT可达 // Attempt to open ports using uPNP for NATed hosts. libp2p.NATPortMap(), // Let this host use the DHT to find other hosts libp2p.Routing(func(h host.Host) (routing.PeerRouting, error) { idht, err = dht.New(ctx, h) return idht, err }), // Let this host use relays and advertise itself on relays if // it finds it is behind NAT. Use libp2p.Relay(options...) to // enable active relays and more. libp2p.EnableAutoRelay(), // If you want to help other peers to figure out if they are behind // NATs, you can launch the server-side of AutoNAT too (AutoRelay // already runs the client) // // This service is highly rate-limited and should not cause any // performance issues. libp2p.EnableNATService(), ) 配置好了host, 为了让这个host高可达, 还要连接预配置的bootstrap nodes. // This connects to public bootstrappers for _, addr := range dht.DefaultBootstrapPeers { pi, _ := peer.AddrInfoFromP2pAddr(addr) // We ignore errors as some bootstrap peers may be down // and that is fine. h2.Connect(ctx, *pi) } routed echo 在简单echo和host的基础上, routed echo配置一个host使用DHT,连接bootstrap节点, 使其能够被peer发现. 其他peer可以只根据peerId来访问它. makeRoutedHost函数首先生成私钥, 然后配置options如下, 此时它还是个basic host opts := []libp2p.Option{ libp2p.ListenAddrStrings(fmt.Sprintf(\"/ip4/0.0.0.0/tcp/%d\", listenPort)), libp2p.Identity(priv), libp2p.DefaultTransports, libp2p.DefaultMuxers, libp2p.DefaultSecurity, libp2p.NATPortMap(), } ctx := context.Background() basicHost, err := libp2p.New(ctx, opts...) 然后新建datastroe // Construct a datastore (needed by the DHT). This is just a simple, in-memory thread-safe datastore. dstore := dsync.MutexWrap(ds.NewMapDatastore()) // Make the DHT dht := dht.NewDHT(ctx, basicHost, dstore) // Make the routed host -- 这步就是把basic host包装成routed host // 可以看出, routed host需要basic host和dht routedHost := rhost.Wrap(basicHost, dht) //这里的rhost就是go-libp2p/p2p/host/routed // connect to the chosen ipfs nodes // for每个bootstrap peer, 调用host.Connect // 奇怪的是在connect之前就把每个bootstrap peer的地址加到自己的peerstore中了: ph.Peerstore().AddAddrs(p.ID, p.Addrs, peerstore.PermanentAddrTTL) // -- 不奇怪, 要先知道地址信息, 再connect. 因为connect只需要peer ID err = bootstrapConnect(ctx, routedHost, bootstrapPeers) // Bootstrap the host err = dht.Bootstrap(ctx) bootstrap peer如何确定的? 可以是全局写死的, 比如: IPFS_PEERS = convertPeers([]string{ \"/ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\", \"/ip4/104.236.179.241/tcp/4001/p2p/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM\", \"/ip4/128.199.219.111/tcp/4001/p2p/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu\", \"/ip4/104.236.76.40/tcp/4001/p2p/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64\", \"/ip4/178.62.158.247/tcp/4001/p2p/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd\", }) 或者从本地http server获取LOCAL_PEER_ENDPOINT = \"http://localhost:5001/api/v0/id\" resp, err := http.Get(LOCAL_PEER_ENDPOINT) 总结 client和server都连接了bootstrap节点, 都有dht 用到的包: go-libp2p basichost 基本的host, 没有peer发现的能力 go-libp2p-kad-dht peer ID查找 go-libp2p/p2p/host/routed 包装上述两个对象成为routed host routed host创建后, 就可以调用NewStream打开一个双向的stream了, 这个stream就可以read write了. host也可以调用SetStreamHandle来listen incoming的连接. chat 一个简单的聊天应用. 假设 A在内网, B在外网(有公网IP) 或者A和B都在局域网 使用 在138机器上开启A:根据提示, 把127的地址改成大网IP. 在190服务器上连接A. 190服务器的这个chat叫做B.我又在138的docker环境里开了C, 同样连接A A能看到B和C发的消息 A的回复只能B看到 C不会收到回复 必须显式指定ip才能连上 所以chat只是两个人的chat, 第一次连上的两个. 既然要IP, 那后面那一大串p2p的地址是干啥的? 答: 校验用的. 如果填错p2p地址, 比如B错填了A的地址, 会报错, 不让连接 代码 打印颜色 // Green console colour: \\x1b[32m // Reset console colour: \\x1b[0m fmt.Printf(\"\\x1b[32m%s\\x1b[0m> \", str) 如果初始随机值一样, 得出的key每次都一样的: if *debug { // Use the port number as the randomness source. // This will always generate the same host ID on multiple executions, if the same port number is used. // Never do this in production code. r = mrand.New(mrand.NewSource(int64(*sourcePort))) } else { r = rand.Reader } 全0的地址会listen所有的网络接口// 0.0.0.0 will listen on any interface device. sourceMultiAddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"/ip4/0.0.0.0/tcp/%d\", port)) \"服务端\"要SetStreamHandler 可以让系统自动分配端口 // Let's get the actual TCP port from our listen multiaddr, in case we're using 0 (default; random available port). var port string for _, la := range h.Network().ListenAddresses() { if p, err := la.ValueForProtocol(multiaddr.P_TCP); err == nil { port = p break } } if port == \"\" { log.Println(\"was not able to find actual local port\") return } \"客户端\"不仅要建立自己的host, 还要connect\"服务端\". 要先从-d选项的字符串里提取地址信息 // Turn the destination into a multiaddr. maddr, err := multiaddr.NewMultiaddr(destination) if err != nil { log.Println(err) return nil, err } // Extract the peer ID from the multiaddr. info, err := peer.AddrInfoFromP2pAddr(maddr) if err != nil { log.Println(err) return nil, err } 先在peerstore里面add对端的地址, 然后就可以发起连接了. // Add the destination's peer multiaddress in the peerstore. // This will be used during connection and stream creation by libp2p. h.Peerstore().AddAddrs(info.ID, info.Addrs, peerstore.PermanentAddrTTL) // Start a stream with the destination. // Multiaddress of the destination peer is fetched from the peerstore using 'peerId'. s, err := h.NewStream(context.Background(), info.ID, \"/chat/1.0.0\") 使用bufio可以把阻塞的io读写变成非阻塞的: // Start a stream with the destination. // Multiaddress of the destination peer is fetched from the peerstore using 'peerId'. s, err := h.NewStream(context.Background(), info.ID, \"/chat/1.0.0\") // Create a buffered stream so that read and writes are non blocking. rw := bufio.NewReadWriter(bufio.NewReader(s), bufio.NewWriter(s)) chat mdns 使能里mdns发现的chat. 其他的和chat一样 使用 ./chat-with-mdns -port 6666 ./chat-with-mdns -port 6668 代码 先New一个基本的host, 这个和普通的chat一样; SetStreamHandler也一样 // 0.0.0.0 will listen on any interface device. sourceMultiAddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"/ip4/%s/tcp/%d\", cfg.listenHost, cfg.listenPort)) // libp2p.New constructs a new libp2p Host. // Other options can be added here. host, err := libp2p.New( ctx, libp2p.ListenAddrs(sourceMultiAddr), libp2p.Identity(prvKey), ) // Set a function as stream handler. // This function is called when a peer initiates a connection and starts a stream with this peer. host.SetStreamHandler(protocol.ID(cfg.ProtocolID), handleStream) 使能mDNS, 等待并连接peer. peerChan := initMDNS(ctx, host, cfg.RendezvousString) peer := go-libp2p/p2p/discovery提供了mDNS发现功能. 这个discovery包目前只有mdns发现方式. discoveryNotifee是被通知的一方. mdns发现新的peer, 就会发送到PeerChan, 这样就接上前面的从peerChan读peer信息, 再connect, 再NewStream的操做了. //Initialize the MDNS service func initMDNS(ctx context.Context, peerhost host.Host, rendezvous string) chan peer.AddrInfo { // An hour might be a long long period in practical applications. But this is fine for us ser, err := discovery.NewMdnsService(ctx, peerhost, time.Hour, rendezvous) //register with service so that we get notified about peer discovery n := &discoveryNotifee{} n.PeerChan = make(chan peer.AddrInfo) ser.RegisterNotifee(n) return n.PeerChan } \"github.com/whyrusleeping/mdns\"是底层提供mdns的包, mdns的query返回ServiceEntry // ServiceEntry is returned after we query for a service type ServiceEntry struct { Name string Host string AddrV4 net.IP AddrV6 net.IP Port int Info string // peerID就是用这个field来传递的. InfoFields []string Addr net.IP // @Deprecated hasTXT bool } p2p/discovery/mdns.go的NewMdnsService函数中, 起了个mdns.NewMDNSService(), 自己的ID就会被当作Info传进去 info := []string{myid} if serviceTag == \"\" { serviceTag = ServiceTag } service, err := mdns.NewMDNSService(myid, serviceTag, \"\", \"\", port, ipaddrs, info) chat with peer发现, 基于dht 用到的package \"github.com/libp2p/go-libp2p\" \"github.com/libp2p/go-libp2p-core/network\" \"github.com/libp2p/go-libp2p-core/peer\" \"github.com/libp2p/go-libp2p-core/protocol\" \"github.com/libp2p/go-libp2p-discovery\" dht \"github.com/libp2p/go-libp2p-kad-dht\" multiaddr \"github.com/multiformats/go-multiaddr\" 代码 还是先New一个host // libp2p.New constructs a new libp2p Host. Other options can be added // here. host, err := libp2p.New(ctx, libp2p.ListenAddrs([]multiaddr.Multiaddr(config.ListenAddresses)...), ) // Set a function as stream handler. This function is called when a peer // initiates a connection and starts a stream with this peer. host.SetStreamHandler(protocol.ID(config.ProtocolID), handleStream) 后面这里厉害了, 注意看注释: New了一个dht还不够, 还需要Bootstrap, 这样每个node都有个dht的拷贝, 即使初始节点down了也不影响后续的peer发现. Bootstrap这个函数会每5分钟后台刷新这个dht // Start a DHT, for use in peer discovery. We can't just make a new DHT // client because we want each peer to maintain its own local copy of the // DHT, so that the bootstrapping node of the DHT can go down without // inhibiting future peer discovery. kademliaDHT, err := dht.New(ctx, host) // Bootstrap the DHT. In the default configuration, this spawns a Background // thread that will refresh the peer table every five minutes. err = kademliaDHT.Bootstrap(ctx) 接下来就要连接bootstrap节点了for _, peerAddr := range config.BootstrapPeers { peerinfo, _ := peer.AddrInfoFromP2pAddr(peerAddr) go func() { host.Connect(ctx, *peerinfo) } } 接下来要声明\"meet me here\"服务, 然后通过FindPeer功能找到\"同类\"discovery这块在go-libp2p-discovery/routing.go // We use a rendezvous point \"meet me here\" to announce our location. // This is like telling your friends to meet you at the Eiffel Tower. logger.Info(\"Announcing ourselves...\") routingDiscovery := discovery.NewRoutingDiscovery(kademliaDHT) discovery.Advertise(ctx, routingDiscovery, config.RendezvousString) logger.Debug(\"Successfully announced!\") // Now, look for others who have announced // This is like your friend telling you the location to meet you. logger.Debug(\"Searching for other peers...\") peerChan, err := routingDiscovery.FindPeers(ctx, config.RendezvousString) RoutingDiscovery是个子类, 继承了go-libp2p-core/routing的ContentRoutingContentRouting是对内容的routing, 那么内容由一个hash值标识(Cid) // RoutingDiscovery is an implementation of discovery using ContentRouting. // Namespaces are translated to Cids using the SHA256 hash. type RoutingDiscovery struct { routing.ContentRouting } ContentRouting在go-libp2p-core/routing/routing.go // ContentRouting is a value provider layer of indirection. It is used to find // information about who has what content. // // Content is identified by CID (content identifier), which encodes a hash // of the identified content in a future-proof manner. type ContentRouting interface { // Provide adds the given cid to the content routing system. If 'true' is // passed, it also announces it, otherwise it is just kept in the local // accounting of which objects are being provided. Provide(context.Context, cid.Cid, bool) error // Search for peers who are able to provide a given key // // When count is 0, this method will return an unbounded number of // results. FindProvidersAsync(context.Context, cid.Cid, int) 得到了peerChan, 那么最后就range这个peerChan, 对每个peer都Newstream一把. 总结 和上个chat不同的是, 这里使用dht来发现peer. 上一个是用mdns协议在局域网发现. pub sub chat room 代码 还是首先建立一个基本的host, 使用系统分配的端口 ctx := context.Background() // create a new libp2p Host that listens on a random TCP port h, err := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/0\")) 用gossipsub协议建立一个pubsub服务 // create a new PubSub service using the GossipSub router ps, err := pubsub.NewGossipSub(ctx, h) 用到了libp2p/go-libp2p-pubsub包, 这个包重度使用了map, 有点复杂. gossip网络扩散\"gossip\", 但每个peer只扩散大约4个周边的peer. node对topic进行订阅, 发布者在某个topic上发布消息, 消息扩散到所有订阅了topic的node. 这个行为又叫overlay multicast. pubsub对象基于topic, 提供基础方法; 在此基础上提供了三个router: 暴力广播式的Floodsub, 随机选择下线peer的Randomsub, 基于gossip协议的Gossipsub 用topic的Publish APi来发送消息, 不用订阅topic就可以发送消息 用topic的Subscribe来订阅返回sub对象, sub对象的Next方法返回下一条消息. 消息是用protocol buf来封装的 配合官方pubsub说明来理解: https://docs.libp2p.io/concepts/publish-subscribe/ 使用mdns协议内网发现, 默认1个小时更新一次列表 // setup local mDNS discovery err = setupDiscovery(ctx, h) 接下来就是加入聊天室开始ui // join the chat room cr, err := JoinChatRoom(ctx, ps, h.ID(), nick, room) // draw the UI ui := NewChatUI(cr) ui.Run() join的过程就是pubsub Join一个topic的过程, 底层是个Subscribe的过程.最后开始后台routine, 读这个topic.Next, 发送给ui注意虽然pubsub使用gpb编码的, 但里面的msg.Data是json编码的 ```go // join the pubsub topic topic, err := ps.Join(topicName(roomName)) // and subscribe to it sub, err := topic.Subscribe() cr := &ChatRoom{ ctx: ctx, ps: ps, topic: topic, sub: sub, self: selfID, nick: nickname, roomName: roomName, Messages: make(chan *ChatMessage, ChatRoomBufSize), } // start reading messages from the subscription in a loop go cr.readLoop() * ui负责打印收到的message. ## relay ### 代码 * h1显式使能了relay功能, 这里指使用realy功能的功能 ```go // Tell the host use relays h1, err := libp2p.New(context.Background(), libp2p.EnableRelay()) h2能给其他node提供relay功能 // Tell the host to relay connections for other peers (The ability to *use* // a relay vs the ability to *be* a relay) h2, err := libp2p.New(context.Background(), libp2p.EnableRelay(circuit.OptHop)) h3清空了listen地址(默认是全部interface监听), 让h3只能通过上面的circuit relay来通信 // Zero out the listen addresses for the host, so it can only communicate // via p2p-circuit for our example h3, err := libp2p.New(context.Background(), libp2p.ListenAddrs(), libp2p.EnableRelay()) 分别连接h1和h3到h2, 但h1和h3不直接连接 h2info := peer.AddrInfo{ ID: h2.ID(), Addrs: h2.Addrs(), } err := h1.Connect(context.Background(), h2info) err := h3.Connect(context.Background(), h2info) 测试h1到h3的连通性 // Now, to test things, let's set up a protocol handler on h3 h3.SetStreamHandler(\"/cats\", func(s network.Stream) { log.Println(\"Meow! It worked!\") s.Close() }) //下面这块演示了直接从h1连接到h3是不行的. _, err = h1.NewStream(context.Background(), h3.ID(), \"/cats\") if err == nil { log.Println(\"Didnt actually expect to get a stream here. What happened?\") return } log.Printf(\"Okay, no connection from h1 to h3: %v\", err) log.Println(\"Just as we suspected\") // Creates a relay address to h3 using h2 as the relay relayaddr, err := ma.NewMultiaddr(\"/p2p/\" + h2.ID().Pretty() + \"/p2p-circuit/ipfs/\" + h3.ID().Pretty()) //先清理h3, 因为刚才连接失败了, 默认不让马上连 // Since we just tried and failed to dial, the dialer system will, by default // prevent us from redialing again so quickly. Since we know what we're doing, we // can use this ugly hack (it's on our TODO list to make it a little cleaner) // to tell the dialer \"no, its okay, let's try this again\" h1.Network().(*swarm.Swarm).Backoff().Clear(h3.ID()) //使用h3的relay地址连接 h3relayInfo := peer.AddrInfo{ ID: h3.ID(), Addrs: []ma.Multiaddr{relayaddr}, } //h1可以连接到h3了 h1.Connect(context.Background(), h3relayInfo) s, err := h1.NewStream(context.Background(), h3.ID(), \"/cats\") s.Read(make([]byte, 1)) // block until the handler closes the stream multipro 创建两个host, 同时支持自定义的ping协议和echo协议. 每个自定的协议都是用protobuf来request和response 这样的好处是, 通过协议号先分流不同的行为, 而不是像一般的应用, 只有一个protobuf的结构体, 里面有大量的可选fields. 这个例子可以处理异步的response, 并匹配到其对应的request. 在message级别使用libp2p protocol multiplexing 代码 Node是个多协议的组合体// Node type - a p2p host implementing one or more p2p protocols type Node struct { host.Host // lib-p2p host *PingProtocol // ping protocol impl *EchoProtocol // echo protocol impl // add other protocols here... } new一个Node就是new ping协议和echo协议// Create a new node with its implemented protocols func NewNode(host host.Host, done chan bool) *Node { node := &Node{Host: host} node.PingProtocol = NewPingProtocol(node, done) node.EchoProtocol = NewEchoProtocol(node, done) return node } ping协议有两级的protocol名// pattern: /protocol-name/request-or-response-message/version const pingRequest = \"/ping/pingreq/0.0.1\" const pingResponse = \"/ping/pingresp/0.0.1\" ping使用一个map来记录request和response的关系// PingProtocol type type PingProtocol struct { node *Node // local host requests map[string]*p2p.PingRequest // used to access request data from response handlers done chan bool // only for demo purposes to stop main from terminating } NewPingProtocol的时候要set两个handler, pingreq和pingresp分别一个. 另外, 这里还用到了高级技巧: 方法当作函数func NewPingProtocol(node *Node, done chan bool) *PingProtocol { p := &PingProtocol{node: node, requests: make(map[string]*p2p.PingRequest), done: done} node.SetStreamHandler(pingRequest, p.onPingRequest) node.SetStreamHandler(pingResponse, p.onPingResponse) return p } pingreq的handler// remote peer requests handler func (p *PingProtocol) onPingRequest(s network.Stream) { //大概流程是从s读request, 然后马上关闭s. 因为s只包括一次request //读到data先proto.Unmarshal到&p2p.PingRequest{}结构体 data := &p2p.PingRequest{} buf, err := ioutil.ReadAll(s) s.Close() proto.Unmarshal(buf, data) //这部就关键了: 每个request都要验证签名 valid := p.node.authenticateMessage(data, data.MessageData) //然后组一个response, 并签名 resp := &p2p.PingResponse{MessageData: p.node.NewMessageData(data.MessageData.Id, false), Message: fmt.Sprintf(\"Ping response from %s\", p.node.ID())} signature, err := p.node.signProtoMessage(resp) // add the signature to the message resp.MessageData.Sign = signature //最后发送这个response, 这个函数里面每次都会新建一个stream来发送. 对Lip2p来说, 因为用了多路复用, 一个stream好像没有那么重. p.node.sendProtoMessage(s.Conn().RemotePeer(), pingResponse, resp) } pingrep的handler类似的, 逻辑很简单, 就是收到对方的response, 说明对方收到了我们的request, 并且回复了, 那我们就删除之前的reqeust map里面记录的id. // locate request data and remove it if found _, ok := p.requests[data.MessageData.Id] if ok { // remove request from map as we have processed it here delete(p.requests, data.MessageData.Id) } else { log.Println(\"Failed to locate request data boject for response\") return } echo协议也非常类似 main流程如下: 建立两个对等的host, 比较普通的那种 priv, _, _ := crypto.GenerateKeyPair(crypto.Secp256k1, 256) listen, _ := ma.NewMultiaddr(fmt.Sprintf(\"/ip4/127.0.0.1/tcp/%d\", port)) host, _ := libp2p.New( context.Background(), libp2p.ListenAddrs(listen), libp2p.Identity(priv), ) 最后run 注意这里也是先Peerstore添加peer的信息, 但没有马上connect. 而是等到后面NewStream的时候再连接. // connect peers h1.Peerstore().AddAddrs(h2.ID(), h2.Addrs(), peerstore.PermanentAddrTTL) h2.Peerstore().AddAddrs(h1.ID(), h1.Addrs(), peerstore.PermanentAddrTTL) // send messages using the protocols h1.Ping(h2.Host) h2.Ping(h1.Host) h1.Echo(h2.Host) h2.Echo(h1.Host) 总结 使用了host的SetStreamHandler()函数注册协议的handler, 这里使用了多个协议(ping和echo), 大协议里面还有小协议(req和rep). 可见一个host可以set多个协议的handler. 总结的总结 host是个基础设施实体, 类似IP协议的地位, 上面可以运行不同的protocol(可以类比为端口号) 比如pubsub.NewGossipSub(ctx, h)的入参是一个ctx和一个host. 并不是说\"注册\"一个gossipsub给这个host, 相反的, host只提供基础能力, gossipsub主动使用host的能力, 自主的维护基于这个host节点的gossip网络. 多个不同的\"功能\"可以在一个host节点上同时运行. 比如同时运行一个mdns服务 SetStreamHandler是每个protocol一个, 这里的protocol不是指tcp啥的, 而是一个string, 比如/chat/1.1.0, 或者/echo/1.0.0 对应的, \"client\"在NewStream的时候, 也要传入一个protocol.ID 扩展 host的底层是swarm(蜂巢), 新建一个swarm需要5个参数:swarm, err := NewSwarm(ctx, laddrs, pid, pstore, bwc) ctx: ctx laddrs: an array of multiaddrs that the swarm will open up listeners for pid: peer id. 通常是RSA的key生成的ID pstore: 存peer id用的 bwc: 统计用的. swarm是基于多路复用的. stream可以set handlerswrm.SetStreamHandler(func(s inet.Stream) { defer s.Close() fmt.Println(\"Got a stream from: \", s.SwarmConn().RemotePeer()) fmt.Fprintln(s, \"Hello Friend!\") }) 也可以直接连接NewStreamWithPeers, err := swrm.NewStreamWithPeer(ctx, rpid) defer s.Close() io.Copy(os.Stdout, s) // pipe the stream to stdout 在swarm这一层, 没有protocol ID; 后者是host层加的. host的option libp2p.New: 新建libp2p node的核心接口, 支持很多配置选项, 如果没有显式的指定, 有合理的默认值: 默认监听/ip4/0.0.0.0/tcp/0 和 /ip6/::/tcp/0 默认使用TCP和websocket传输协议 默认使用多路复用协议yamux和mplux, 多路复用协议会在peer间协商? 默认加密, 使用noise协议或者TLS 默认使用RSA 2048产生随机的PeerId 默认用空的peerstore(用于peer routing) 有个API NewWithoutDefaults没有任何default配置, 但不建议使用. 可选配置如下: ListenAddrStrings: 指定(多个)listen地址, 使用原始字符串表达libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/0\")) libp2p.ListenAddrStrings( \"/ip4/0.0.0.0/tcp/9000\", // regular tcp connections \"/ip4/0.0.0.0/udp/9000/quic\", // a UDP endpoint for the QUIC transport ) ListenAddrs: 指定(多个)listen地址, 使用Multiaddr表达listen, _ := ma.NewMultiaddr(fmt.Sprintf(\"/ip4/127.0.0.1/tcp/%d\", port)) libp2p.ListenAddrs(listen), Security: 配置transport加密// support TLS connections libp2p.Security(libp2ptls.ID, libp2ptls.New), // support secio connections libp2p.Security(secio.ID, secio.New), NoSecurity: 不加密 Muxer: 配置multiplexing Transport: 配置支持的transport// support QUIC - experimental libp2p.Transport(libp2pquic.NewTransport), libp2p.DefaultTransports, // DefaultTransports是tcp和websocket Peerstore: 配置使用peerstore PrivateNetwork: 保护私有网络, 只有同样的私有网络标识才能连接 BandwidthReporter: 配置带宽报告 Identity: 配置keypriv, _, err := crypto.GenerateKeyPairWithReader(crypto.RSA, 2048, r) libp2p.Identity(priv), ConnectionManager: 配置连接管理libp2p.ConnectionManager(connmgr.NewConnManager( 100, // Lowwater 400, // HighWater, time.Minute, // GracePeriod )), AddrsFactory: 地址工厂 EnableRelay: 传入OptHop会让这个host 广告自己可以是relay hoplibp2p.EnableRelay(circuit.OptHop) DisableRelay: 禁用relay. 默认使能 EnableAutoRelay: 使能relay服务(对别人提供relay功能)libp2p.EnableAutoRelay(), StaticRelays: 配置静态relay DefaultStaticRelays: 使用内置的代码写死的relay节点// These are the known PL-operated relays var DefaultRelays = []string{ \"/ip4/147.75.80.110/tcp/4001/p2p/QmbFgm5zan8P6eWWmeyfncR5feYEMPbht5b1FW1C37aQ7y\", \"/ip4/147.75.195.153/tcp/4001/p2p/QmW9m57aiBDHAkKj9nmFSEn7ZqrcF1fZS4bipsTCHburei\", \"/ip4/147.75.70.221/tcp/4001/p2p/Qme8g49gm3q4Acp7xWBKg3nAa9fxZ1YmyDJdyGgoG6LsXh\", } ForceReachabilityPublic: 在autoNAT时, 强制让这个host相信自己public可达 ForceReachabilityPrivate: 在autoNAT时, 强制让这个host相信自己在内部NAT网络 EnableNATService: 使能nat观测服务. 尝试用新连接回连到peer, 并告知对端是否成功, 帮助对端判断自己是否外网可访问. AutoNATServiceRateLimit: 限制回连服务的次数 ConnectionGater: 配置一个连接看护人来拒绝特定的inbound和outbound连接 NATPortMap: 尝试使用路由器的UPnP功能来穿透NAT NATManager: 上面的api使用默认的nat manager, 这个api是自己配置一个. Ping: 使能ping服务. 默认使能 Routing: // Let this host use the DHT to find other hosts libp2p.Routing(func(h host.Host) (routing.PeerRouting, error) { idht, err = dht.New(ctx, h) return idht, err }), NoListenAddrs: 配置这个node不listen UserAgent: user-agent sent MultiaddrResolver: dns resolver 默认值 这里提供默认值的目的是让用户扩展选项, 同时也有这些默认值 var DefaultSecurity = ChainOptions( Security(noise.ID, noise.New), Security(tls.ID, tls.New), ) var DefaultMuxers = ChainOptions( Muxer(\"/yamux/1.0.0\", yamux.DefaultTransport), Muxer(\"/mplex/6.7.0\", mplex.DefaultTransport), ) var DefaultTransports = ChainOptions( Transport(tcp.NewTCPTransport), Transport(ws.New), ) // DefaultPeerstore configures libp2p to use the default peerstore. var DefaultPeerstore Option = func(cfg *Config) error { return cfg.Apply(Peerstore(pstoremem.NewPeerstore())) } // RandomIdentity generates a random identity. (default behaviour) var RandomIdentity = func(cfg *Config) error { priv, _, err := crypto.GenerateKeyPairWithReader(crypto.RSA, 2048, rand.Reader) return cfg.Apply(Identity(priv)) } // DefaultListenAddrs configures libp2p to use default listen address. var DefaultListenAddrs = func(cfg *Config) error { defaultIP4ListenAddr, err := multiaddr.NewMultiaddr(\"/ip4/0.0.0.0/tcp/0\") defaultIP6ListenAddr, err := multiaddr.NewMultiaddr(\"/ip6/::/tcp/0\") return cfg.Apply(ListenAddrs( defaultIP4ListenAddr, defaultIP6ListenAddr, )) } // DefaultEnableRelay enables relay dialing and listening by default. var DefaultEnableRelay = func(cfg *Config) error { return cfg.Apply(EnableRelay()) } 规范 在 https://github.com/libp2p/specs 如何建立连接 先是建立raw transport连接, 比如tcp连接. 这部分很标准. 在raw连接基础上, 规范描述了如何协商安全特性和多路复用等能力的过程, 包括了从最初的传输建立后, 到打开应用层的stream, 识别应用层的protocol ID, 根据ID找到合适的handler 有连个核心的特性: 安全: 最初的握手之后, 数据都是加密的, 用签名的方式 stream是可靠的, 双向的, 通信channel, 是基于在底层transport多路复用的基础上的. stream必须支持反压, 支持半连接, 比如可以关了写, 但是可以读. stream的好处是可以多个逻辑的流共享一个底层transport, 节约建立通道的开销. 有的transport协议比如QUIC, 本身就有内置的安全和多路复用. 其他的协议比如TCP, 就必须在原始的transport之上建立安全和多路复用. 对于这种本身没有安全和多路复用支持的情况, 就需要\"连接升级\" 协议协商 协议号是个字符串, 通常带版本号. 比如/multistream/1.0.0 multistream也叫multistream-select, 使用utf8编码的字符串来传递消息. 协商不上返回na\\n 连接升级 连接升级也是使用/multistream/1.0.0来协商的过程:比如上图的过程, 在原始连接基础上: 一定是先协商安全特性, 这里发起方先发送/tls/1.0.0, 但对方不支持, 发送方再协商/noise, 这回对方支持了 接下来协商多路复用, 一下子就协商成了mplex/1.0.0 新建stream 上面的过程是升级一个底层连接, 在连接上面, 可以新建多个逻辑上的stream. 新建stream的过程也是要使用/multistream/1.0.0协议来协商\"应用层\"的协议: 比如发送方发送/echo/1.0.1, 接收方查询自己是否有/echo/1.0.1协议的handler(或能match到这个协议的match handler), 没有就返回na\\n, 那发送方就停止交互, 或者再换一个应用层协议. 如果接收方支持echo协议, 双方就可以按照echo协议开始干活了. 具体实现 推荐使用Noise安全特性(又有说法是回切换到tls) 推荐使用mplex多路复用 推荐提供peer metadata storage, see go-libp2p-peerstore 推荐进行连接限制 连接状态通知类型: Event Description Connected A new connection has been opened Disconnected A connection has closed OpenedStream A new stream has opened over a connection ClosedStream A stream has closed Listen We've started listening on a new address ListenClose We've stopped listening on an address 隧道 底层transport有两种情况 non-browser: 通常是tcp或quic browser: 不能直接dial, 不能直接控制底层socket 能\"穿透\"的协议有 relay TURN: Traversal Using Relays around NAT (TURN), 基于中间节点 circuit relay v1和circuit relay v2: 双方都知晓这个relay server的存在 relay的地址格式: []/p2p-circuit/ Addressing /p2p-circuit multiaddrs don't carry any meaning of their own. They need to encapsulate a /p2p address, or be encapsulated in a /p2p address, or both. As with all other multiaddrs, encapsulation of different protocols determines which metaphorical tubes to connect to each other. A /p2p-circuit circuit address, is formated following: []/p2p-circuit/ Examples: /p2p-circuit/p2p/QmVT6GYwjeeAF5TR485Yc58S3xRF5EFsZ5YAF4VcP3URHt - Arbitrary relay node /ip4/127.0.0.1/tcp/5002/p2p/QmdPU7PfRyKehdrP5A3WqmjyD6bhVpU1mLGKppa2FjGDjZ/p2p-circuit/p2p/QmVT6GYwjeeAF5TR485Yc58S3xRF5EFsZ5YAF4VcP3URHt - Specific relay node This opens the room for multiple hop relay, where the second relay is encapsulated in the first relay multiaddr, such as: /p2p-circuit//p2p-circuit/ A few examples: Using any relay available: /p2p-circuit/p2p/QmTwo Dial QmTwo, through any available relay node (or find one node that can relay). The relay node will use peer routing to find an address for QmTwo if it doesn't have a direct connection. /p2p-circuit/ip4/../tcp/../p2p/QmTwo Dial QmTwo, through any available relay node, but force the relay node to use the encapsulated /ip4 multiaddr for connecting to QmTwo. Specify a relay: /p2p/QmRelay/p2p-circuit/p2p/QmTwo Dial QmTwo, through QmRelay. Use peer routing to find an address for QmRelay. The relay node will also use peer routing, to find an address for QmTwo. /ip4/../tcp/../p2p/QmRelay/p2p-circuit/p2p/QmTwo Dial QmTwo, through QmRelay. Includes info for connecting to QmRelay. The relay node will use peer routing to find an address for QmTwo. Double relay: /p2p-circuit/p2p/QmTwo/p2p-circuit/p2p/QmThree Dial QmThree, through a relayed connection to QmTwo. The relay nodes will use peer routing to find an address for QmTwo and QmThree. We'll not support nested relayed connections for now, see Future Work section. STUN-like 让另外一个host来观测自己是否是在NAT里面, 并帮助自己发现端口映射. libp2p使用AutoNAT和identify来实现 Coordination 在relay协议基础上, 让两个host来互相写作进行打洞. 比如Session Description Protocol (SDP) and Direct Connection Upgrade through Relay. 节点发现机制 这里主要是libp2p Kademlia and Gossipsub protocol 几种场景 Public Non-Browser (A) to Public Non-Browser (B): 不需要打洞, 直接连. Private Non-Browser (A) to Public Non-Browser (B): 不需要打洞, A可以直接连B Private Browser (A) to Public Non-Browser (B): B需要支持Websocket, 因为之后websocket才能直接连. B也必须支持TLS Public or Private Non-Browser (A) to Private Non-Browser (B): 可以有几种方式连接: B使用了AutoNAT和Identify得到\"对外\"的ip和端口, 这样A就能够访问到. 但A或B是symmeritc, NAT这招就不好用了. B使用 circuit relay v2 protocol协议, 先主动连接某个relay server, B广播自己的relay地址让. A通过访问这个relay地址来访问B, A和B连接上之后, 执行升级协议Direct Connection Upgrade through Relay, 进最大可能做打洞建立直接连接. 问答 打洞失败会怎么样?确实有可能失败, 没办法, 上层的协议要接受这一点. 但两个节点间还是可以用relay节点连接, 虽然这个连接是比较绕远的, 但没办法. 为什么同时使用AutoNAT and STUN, 为什么不用其中一个就好了?browser场景下只能用STUN, 不能用AutoNAT. TCP或QUIC场景下可以用STUN取代AutoNAT. --但上文中看到, AutoNAT配合identify机制, 是libp2p对SATUN的实现. 将来work 优化协商协议multistream-select 优化connection manager 支持quic(好像已经支持了) event bus Peer Ids and Keys libp2p使用使用密钥来给message签名, 以及生成peer ID. 下面是key的protobuf定义 syntax = \"proto2\"; enum KeyType { RSA = 0; Ed25519 = 1; Secp256k1 = 2; ECDSA = 3; } message PublicKey { required KeyType Type = 1; required bytes Data = 2; } message PrivateKey { required KeyType Type = 1; required bytes Data = 2; } 其中data域可以有其他的编码方式 PrivateKey不会在线路中传输, 但可以以protobuf的编码保存在本地存储上, 从而可以被load来重用这个key. key的使用场景 给message签名 IPNS records PubSub messages SECIO handshake 生成peerID identify协议 用/ipfs/id/1.0.0和/ipfs/id/push/1.0.0来查询remote peer和广播自己的peerID.里面包含public key message Identify { optional string protocolVersion = 5; optional string agentVersion = 6; optional bytes publicKey = 1; repeated bytes listenAddrs = 2; optional bytes observedAddr = 4; repeated string protocols = 3; } mplex协议 mplex是个简单的多路复用协议, 比如简单到没有流控. open一个streamd时候要先生成个stream ID, stream名只是用来debug 写stream是个message, 用MessageReceiver (1) or MessageInitiator (2)标记是否是发起者, data域是你要写的内容, 最大1MB 还有大小限制?! 可以半关 reset操做会同时关闭读和写 Rendezvous集结协议 一个去中心化的, 轻量化的, 通用的发现协议. 我的理解是加入集结就能发现周边的peer. During bootstrap, a node can use known rendezvous points to discover peers that provide critical services. For instance, rendezvous can be used to discover circuit relays for connectivity restricted nodes. During initialization, a node can use rendezvous to discover peers to connect with the rest of the application. For instance, rendezvous can be used to discover pubsub peers within a topic. In a real time setting, applications can poll rendezvous points in order to discover new peers in a timely fashion. In an application specific routing setting, rendezvous points can be used to progressively discover peers that can answer specific queries or host shards of content. 大概原理 实现了/rendezvous/1.0.0的每个node都可以是集结点, 其他节点连接到集结点时, 会注册自己的名字空间. 其他节点可以向集结点发请求查询某个namespace, 返回其包括的节点. 也支持cookie来进行增量查询 注册的时候可以指定TTL, 设置老化时间. 默认时2个小时, 最大72小时. namespace最大255, 最大注册数1000 Protocols汇总 These specs define wire protocols that are used by libp2p for connectivity, security, multiplexing, and other purposes. The protocols described below all use protocol buffers (aka protobuf) to define message schemas. Version proto2 is used unless stated otherwise. identify - Exchange keys and addresses with other peers mplex - The friendly stream multiplexer plaintext - An insecure transport for non-production usage pnet - Private networking in libp2p using pre-shared keys pubsub - PubSub interface for libp2p gossipsub - An extensible baseline PubSub protocol episub - Proximity Aware Epidemic PubSub for libp2p relay - Circuit Switching for libp2p (similar to TURN) rendezvous - Rendezvous Protocol for generalized peer discovery secio - SECIO, a transport security protocol for libp2p tls - The libp2p TLS Handshake (TLS 1.3+) 基础知识 公钥与私钥 数字签名是什么？ 鲍勃有两把钥匙，一把是公钥，另一把是私钥。 鲍勃把公钥送给他的朋友们----帕蒂、道格、苏珊----每人一把。 苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。 鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。 鲍勃给苏珊回信，决定采用\"数字签名\"。他写完后先用Hash函数，生成信件的摘要（digest）。 然后，鲍勃使用私钥，对这个摘要加密，生成\"数字签名\"（signature）。 鲍勃将这个签名，附在信件下面，一起发给苏珊。 苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。 复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成\"数字签名\"，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。 后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\"证书中心\"（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\"数字证书\"（Digital Certificate）。 鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。 苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\"数字签名\"是否真的是鲍勃签的。 下面，我们看一个应用\"数字证书\"的实例：https协议。这个协议主要用于网页加密。 首先，客户端向服务器发出加密请求。 服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。 客户端（浏览器）的\"证书管理器\"，有\"受信任的根证书颁发机构\"列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。 如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。 如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。 讨论 那么鲍勃发给苏珊的信件，帕蒂不是也能打开了么??(既然大家都有鲍勃的公钥)?这个问题其实被作者简化了（如果我没记错的话），实际上bob和Susan的通信过程应该是：1.他俩用公钥和私钥通信达成一个临时的协议，包括一个对称加密的密钥，密码因为是通过非对称加密的方式（就像此文第一个加密传输过程)传输所以能在第一次传输的时候也保证安全和正确。2.然后他俩用这个对称加密的密钥通信，帕蒂就没办法解密密文了。 所以实际上真正的通信过程应该是大部分基于对称加密，和小部分（对称加密密钥)基于非对称加密。 你好，本人非密码学专业出身。可否请教一下：既然 Bob 公钥是公开的，那 Susan 用 Bob 公钥加密的内容为什么无法被其他有 Bob 公钥的人解密呢？公钥加密得到的密文只能由私钥进行解密，如果不知道私钥，仅有公钥和密文是无法计算出明文的 对称加密（Symmetric Cryptography） 对称加密是最快速、最简单的一种加密方式，加密（encryption）与解密（decryption）用的是同样的密钥（secret key）。对称加密有很多种算法，由于它效率很高，所以被广泛使用在很多加密协议的核心当中。 对称加密通常使用的是相对较小的密钥，一般小于256 bit。因为密钥越大，加密越强，但加密与解密的过程越慢。如果你只用1 bit来做这个密钥，那黑客们可以先试着用0来解密，不行的话就再用1解；但如果你的密钥有1 MB大，黑客们可能永远也无法破解，但加密和解密的过程要花费很长的时间。密钥的大小既要照顾到安全性，也要照顾到效率，是一个trade-off。 2000年10月2日，美国国家标准与技术研究所（NIST--American National Institute of Standards and Technology）选择了Rijndael算法作为新的高级加密标准（AES--Advanced Encryption Standard）。.NET中包含了Rijndael算法，类名叫RijndaelManaged，下面举个例子。 对称加密的一大缺点是密钥的管理与分配，换句话说，如何把密钥发送到需要解密你的消息的人的手里是一个问题。在发送密钥的过程中，密钥有很大的风险会被黑客们拦截。现实中通常的做法是将对称加密的密钥进行非对称加密，然后传送给需要它的人。 非对称加密（Asymmetric Cryptography） 非对称加密为数据的加密与解密提供了一个非常安全的方法，它使用了一对密钥，公钥（public key）和私钥（private key）。私钥只能由一方安全保管，不能外泄，而公钥则可以发给任何请求它的人。非对称加密使用这对密钥中的一个进行加密，而解密则需要另一个密钥。比如，你向银行请求公钥，银行将公钥发给你，你使用公钥对消息加密，那么只有私钥的持有人--银行才能对你的消息解密。与对称加密不同的是，银行不需要将私钥通过网络发送出去，因此安全性大大提高。 目前最常用的非对称加密算法是RSA算法，是Rivest, Shamir, 和Adleman于1978年发明，他们那时都是在MIT。.NET中也有RSA算法，请看下面的例子： 虽然非对称加密很安全，但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。为了解释这个过程，请看下面的例子： （1） Alice需要在银行的网站做一笔交易，她的浏览器首先生成了一个随机数作为对称密钥。 （2） Alice的浏览器向银行的网站请求公钥。 （3） 银行将公钥发送给Alice。 （4） Alice的浏览器使用银行的公钥将自己的对称密钥加密。 （5） Alice的浏览器将加密后的对称密钥发送给银行。 （6） 银行使用私钥解密得到Alice浏览器的对称密钥。 （7） Alice与银行可以使用对称密钥来对沟通的内容进行加密与解密了。 总结 （1） 对称加密加密与解密使用的是同样的密钥，所以速度快，但由于需要将密钥在网络传输，所以安全性不高。 （2） 非对称加密使用了一对密钥，公钥与私钥，所以安全性高，但加密与解密速度慢。 （3） 解决的办法是将对称加密的密钥使用非对称加密的公钥进行加密，然后发送出去，接收方使用私钥进行解密得到对称加密的密钥，然后双方可以使用对称加密来进行沟通。 "},"notes/golang_gvisor代码_KVM.html":{"url":"notes/golang_gvisor代码_KVM.html","title":"gvisor KVM模式代码","keywords":"","body":" gvisor代码概览图: host mode和guest mode切换小结 go 汇编和arm64知识 ARM64页表和进程切换知识 ARM64异常处理 ARM64寄存器 gvisor介绍 原理简介 编译和调试 代码结构 abi sentry的内存管理 传统mm shared map private map 匿名映射 如何在用户态处理page fault signal方式 userfaultfd方式用户态page管理 sentry的mm 性能对比 netstask pkg/abi/linux pkg/abi/linux/seccomp.go pkg/hostarch/hostarch.go pkg/seccomp/seccomp.go pkg/sentry/arch/arch.go kernel task的状态机 runsc boot流程 platform 哪里调用了Switch() ptrace thread.setRegs 主要结构体 ptrace系统调用 ptrace可以做什么? kvm golang的汇编基础 arm64 exception level arm64内存基础 VM的地址空间 KVM基础 gvisor对CPU和ring0.kernel的抽象 machine和vCPU的定义 pagetable之虚拟地址region到物理地址region的map表 KVM_SET_USER_MEMORY_REGION mapPhysical()的调用路径之用户态page falut处理路径 mapPhysical的调用路径之seccompMmapHandler mapPhysical的调用路径之newMachine KVM新建一个VM newMachine arm64异常向量 EL0同步异常 EL0同步异常之SVC系统调用异常 kernelExitToEl1 顺便看一下kernelExitToEl0 EL1同步异常El1_sync EL1其他异常(irq, fiq, error)都走shutdown流程, 关闭guest KVM_CREATE_VCPU kernelAddr可以获取一个eface和func的内核地址 KVM_ARM_VCPU_INIT 入口代码 KVM的context实现 arm64的cpu.SwitchToUser bluepill()汇编函数 vCPU.CPU.SwitchToUser函数 补充 go linkname用法 gvisor代码概览图: host mode和guest mode切换小结 总的来说, 虽然用了kvm, 但gvisor巧妙地设计了从guest PA到host VA的映射, 从而让guest能读写host一样的地址空间, 而且gvisor会把所有的guest app也都映射到这个地址空间. 这样产生的现象是guest和host交替执行这个地址空间上的代码. 切换点在(*vCPU).SwitchToUser这个函数, 在bluepill前在host模式执行, 然后 切换到guest模式继续执行接下来的代码(包括EL1特权代码), 其中的关键函数是kernelExitToEl0, 效果是让geust执行guest的EL0代码, 直到遇到SVC系统调用指令 guest的SVC指令导致guest模式退出, ucontext被设置为guest执行SVC前的状态, 但交给host来接力执行. 接着host来执行SVC指令, 在host模式下触发syscall, 让host kernel来执行syscall go 汇编和arm64知识 伪寄存器: SB: Static base pointer 全局基地址. 比如foo(SB)就是foo这个symbol的地址 FP: 帧指针. 用来传参的 SP: 栈指针. 指向栈顶. 用于局部变量. 注意真寄存器叫RSP PC: 程序指针 函数格式: TEXT symbol(SB), [flags,] $framesize[-argsize] symbol: 函数名 SB: SB伪寄存器 flags: 可以是 NOSPLIT: 不让编译器插入栈分裂的代码 WRAPPER: 不增加函数帧计数 NEEDCTXT: 需要上下文参数, 一般用于闭包 $framesize: 局部变量大小, 包含要传给子函数的参数部分 -argsize: 参数+返回值的大小, 可以省略由编译器自己推导 ARM64页表和进程切换知识 每个进程都有自己的translation table, 这个table是kernel分配的, 把其物理地址配置到ttbr0寄存器. 上下文切换的时候, kernel会保存/恢复如下上下文: general-purpose registers X0-X30. Advanced SIMD and Floating-point registers V0 - V31. Some status registers. TTBR0_EL1 and TTBR0. Thread Process ID (TPIDxxx) Registers. Address Space ID (ASID). EL0和EL1有两个translation table, TTBR0_EL1负责bottom空间(用户空间), TTBR1_EL1负责top空间(kernel空间). 大家都用TTBR1_EL1做kernel空间, 所以进程切换的时候, TTBR1_EL1不用变, 所以kernel的映射不用变. ASID配置在TTBR0_EL1里 ASID(Address Space ID)寄存器用来标记页表entry所属的task, 由kernel分配.当TLB更新的时候, TLB entry除了保存地址翻译信息, 还会包括这个ASID.TLB查询的时候, 只有当前的ASID和TLB entry保存的ASID匹配的时候, 才算TLB命中. 所以上下文切换的时候不需要flush TLB.把ASID值放在TTBR0_EL1里的好处是, 一个指令就可以原子的更改ASID和页表. AARCH64支持虚拟内存的tag, 虚拟内存的最高8位是tag, 在地址翻译的时候会被忽略. PC, LR, SP, ELR里面都是VA AArch64有48位VA, 空间有256TB, 有两个range空间 0xFFFF_0000_0000_0000 到 0xFFFF_FFFF_FFFF_FFFF 基址寄存器是TTBR1, 内核态 或 0x0000_0000_0000_0000 到 0x0000_FFFF_FFFF_FFFF 基址寄存器是TTBR0, 用户态 IPA也是48位 PA也是48位, 并且secure和non-secure的物理地址空间是独立的 TTBR是地址转换表的基址寄存器, 这个表由硬件自动查, 并被缓存到TLB中; TTBR里面保存的是物理地址, 是给硬件MMU waker看的. 这个表最多有四级, 地址最多48位, 最大64KB一个映射 ARM64异常处理 异常发生的时候, CPU会自动的实施如下动作: 将PSTATE保存到SPSR_ELn 比如异常发生在EL0, 一般会在EL1处理. 那PSTATE会保存在SPSR_EL1 更新PSTATE以反映新的CPU状态, 比如已经进入EL1 硬件会将返回地址保存在ELR_Eln. 还是比如异常发生在EL0, 但在EL1处理, 那返回地址保存在ELR_EL1 eret指令用来从异常处理返回: 从SPSR_ELn恢复异常前的PSTATE 从ELR_ELn恢复PC 异常返回, 从恢复的PC和PSTATE继续执行 在发生异常时, 硬件会自动更新ELR, 根据情况, 返回地址有几种可能: 比如SVC指令触发的同步异常, ELR里保存的是其下一条指令 比如异步异常(即外部中断), ELR里保存的是下一个没被执行(或完全执行)的指令 ELR可以在异常处理程序里面被更改. 每个exception level都有独立的异常向量表 VBAR_EL3, VBAR_EL2 and VBAR_EL1向量表的虚拟地址配在VBAR寄存器里 arm64的sp寄存器每个EL都有, 但不一定都用: SPSel选择寄存器的0位, 来决定用哪个SP 默认每个EL使用自己的level对应的SP ARM64寄存器 In AArch64 state, the following registers are available: Thirty-one 64-bit general-purpose registers X0-X30, the bottom halves of which are accessible as W0-W30. Four stack pointer registers SP_EL0, SP_EL1, SP_EL2, SP_EL3. Three exception link registers ELR_EL1, ELR_EL2, ELR_EL3. Three saved program status registers SPSR_EL1, SPSR_EL2, SPSR_EL3. One program counter. For the purposes of function calls, the general-purpose registers are divided into four groups: r30(LR): The Link Register r29(FP): The Frame Pointer r19...r28: Callee-saved registers r18: The Platform Register, if needed; otherwise a temporary register. r17(IP1): The second intra-procedure-call temporary register r16(IP0): The first intra-procedure-call scratch register r9...r15: Temporary registers r8: Indirect result location register r0...r7: Parameter/result registers XZR是zero寄存器PC寄存器BL或ADL指令可以修改SP向下增长, 必须16字节对齐PSR寄存器: Process State, 反映一些比较操作的状态 gvisor介绍 gvisor是一个用户态操做系统, 自带一个runsc, 可以和conainterd等编排工具集成. gvisor主打安全特性. As outlined in the previous blog post, gVisor’s secure design principles are: Defense in Depth: each component of the software stack trusts each other component as little as possible. Least Privilege: each software component has only the permissions it needs to function, and no more. Attack Surface Reduction: limit the surface area of the host exposed to the sandbox. Secure by Default: the default choice for a user should be safe. 原理简介 原文: https://www.infoq.com/presentations/gvisor-os-go/ 编译和调试 clone gvisor后, 切换到go分支, 在runsc下面go build编译出来的runsc可以直接使用.修改daemon.json并且systemctl reload docker就可以使用runsc了: docker run --cpus=2 -m 2g --rm --runtime=runsc -it --name=test centos:7 bash 顺利的话就进入container里面了 debug的log在/tmp/runsc, 其中比如runsc.log.20220315-022030.789081.boot就是主进程的log docker run后, 找到对应的sndbox进程runsc-sandbox, 就可以用dlv attach pid来调试. 官方github里面install提到的containerd-shim-runsc-v1是没用到的.实际docker使用的是/usr/bin/containerd-shim-runc-v2 如果在arm64的raspberry pi上, 需要修改/boot/firmware/cmdline.txt, 增加cgroup_enable=memory net.ifnames=0 dwc_otg.lpm_enable=0 console=serial0,115200 console=tty1 root=LABEL=writable rootfstype=ext4 elevator=deadline rootwait fixrtc cgroup_enable=memory 代码结构 gvisor的依赖包很多, 有containerd和docker等容器的, 有k8s的, 有protobuf和grpc的, 有报文解析相关的gopacket, 有更加基础的btree库... 很多gvisor有很多自己实现的基础库https://github.com/google/gvisor/tree/master/pkg可以说, gvisor的这些基础库本身, 就是系统级linux基础的golang实现的参考库.比如eventfd包就包装了linux的enventfd系统调用.比如在标准库基础上的sync包 abi gvisor提供了兼容linux的abi: https://github.com/google/gvisor/tree/master/pkg/abi/linux就是说gvisor支持大部分的c的abi: 比如aio, bpf, elf, epoll, fcntl, fs, ipc, mm, netlink, netfilter, ptrace, sched, time, uio, socket等等 sentry的内存管理 sentry是gvisor用户态kernel的核心. 传统mm mmap的任务是在一个进程里, map一个文件到一个虚拟地址范围. 当这个虚拟地址被访问的时候, 没有PTE的时候会产生page fault异常, kernel才分配物理页, 从文件copy实际内容到这个物理页. page是有cache的, 使用Least Recently Used (LRU)策略换出不经常使用的page. 当dirty page超过一个ratio, kernel会flush脏页. Read-ahead技术预加载page从而避免缺页异常的产生. madvise系统调用可以告知kernel app对内容范围的期望. shared map linux的mmap系统调用, 比如: mmap( /* addr = */ 0x400000, /* length = */ 0x1000, PROT_READ | PROT_WRITE, MAP_SHARED, /* fd = */ 3, /* offset = */ 0); 创建一个从fd 3到virtual memory areas (VMAs)的mapping.这个mapping从VA 0x400000开始, 长度为0x1000字节, offset是0.假设fd 3对应的文件是/tmp/foo内核中这个mapping表示为: VMA: VA:0x400000 -> /tmp/foo:0x0 创建VMA的时候并没有分配PA, 因为这个时候linux还没有准备物理地址来保存/tmp/foo的内容. 直到应用读VA地址0x400000, 产生缺页异常, 才分配物理页, 然后copy文件内容到这个物理页. 比如kernel选择了PA:0x2fb000, 此时VMA是这样的: VMA: VA:0x400000 -> /tmp/foo:0x0 Filemap: /tmp/foo:0x0 -> PA:0x2fb000 这里的Filemap对应kernel的struct address_space 这个时候kernel使用page table entry (PTE)来做VA到PA的转换表. VMA: VA:0x400000 -> /tmp/foo:0x0 Filemap: /tmp/foo:0x0 -> PA:0x2fb000 PTE: VA:0x400000 -----------------> PA:0x2fb000 注意, VMA和Filemap是相对独立的东西, 而PTE受二者的影响, 比如: 这个应用调用了munmap系统调用, 这就解除了VMA: VA:0x400000 -> /tmp/foo:0x0的映射, 进而解除了PTE: VA:0x400000 -----------------> PA:0x2fb000. 但是, Filemap: /tmp/foo:0x0 -> PA:0x2fb000不一定就解除了, 因为从文件/tmp/foo:0x0到物理地址PA:0x2fb000的映射以后还能用得上. 这个应用也可能调用ftruncate来invalidate这个文件的内容. 这就解除了Filemap: /tmp/foo:0x0 -> PA:0x2fb000, 进而解除了PTE: VA:0x400000 -----------------> PA:0x2fb000; 而VMA: VA:0x400000 -> /tmp/foo:0x0就不需要改变, 因为PTE解除了, VA:0x400000需要另一个缺页异常来分配新的物理页, 所以VA仍然反应了文件内容的改变. private map 对private map来说, 读和写都可能会有缺页异常. 首次读产生的缺页异常会产生一个只读的物理页: VMA: VA:0x400000 -> /tmp/foo:0x0 (private) Filemap: /tmp/foo:0x0 -> PA:0x2fb000 PTE: VA:0x400000 -----------------> PA:0x2fb000 (read-only) 此时如果是shared map, 写操做也会写到PA:0x2fb000. 但private map会产生另外一个缺页异常, kernel另外选择一个物理页(比如0x5ea000), 拷贝之前的物理页内容到这个新分配的物理页, 然后更新map: VMA: VA:0x400000 -> /tmp/foo:0x0 (private) Filemap: /tmp/foo:0x0 -> PA:0x2fb000 PTE: VA:0x400000 -----------------> PA:0x5ea000 匿名映射 flag里面如果有MAP_ANONYMOUS就使用匿名映射, 就是不需要文件的映射. 匿名也分shared和private. shared模式下面, 会产生一个临时的零字节的文件, 大家都map到这个文件. private模式下面, 就没有这个临时文件了. 而是一开始都用一个固定的readonly的全零的页, 直到copy on write新分配一个可写的物理页. 如何在用户态处理page fault signal方式 参考: https://lwn.net/Articles/550555/ 一般的, 可以使用mprotect(PROT_NONE)来产生SIGSEGV, 然后在SIGSEGV的handler里面在用户态处理page fault. #include int mprotect(void *addr, size_t len, int prot); int pkey_mprotect(void *addr, size_t len, int prot, int pkey); The SIGBUS signal handler's job is to handle the page fault by mapping a real page to the faulting address. That can be done in current kernels with the mremap() system call. The problem with mremap() is that it works by splitting the virtual memory area (VMA) structure used to describe the memory range within the kernel. Frequent mremap() calls will result in the kernel having to manage a large number of VMAs, which is an expensive proposition. mremap() will also happily overwrite existing memory mappings, making it harder to detect errors (or race conditions) in user-space handlers. For these reasons, mremap() is not an ideal solution to the problem. 还可以选madvise(MADV_USERFAULT), 似乎更好 Perhaps I'm misunderstanding something here, but I don't understand how MADV_USERFAULT is different/superior from doing an mprotect(PROT_NONE) and then handling the SIGSEGV. Can someone help me out? For one there is the uglyness of properly handling SIGSEGVs which requires sigaltstack et al. which is far from easy. For another, if you would go that way you would need to call mmap() for every single page fault which would probably end up being horrendously expensive since you would end up with thousands of different mmap()s setup which is rather expensive. With the patchset, as far as I understand it, there's just one memory region setup in the kernel and just when it cannot find backing memory it falls back to the userspace page fault handler. userfaultfd方式用户态page管理 上面描述的是使用SIGSEGV信号及其handler在用户态处理page fault, 简称umap而这篇文章: https://arxiv.org/ftp/arxiv/papers/1910/1910.07566.pdf提到了使用userfaultfd的umap技术, 在用户app的单独线程里处理page fault. Page faults in the address ranges are delivered asynchronously so that the faulting process is blocked instead of idling, allowing other processes to be scheduled to proceed. 参考: man userfaultfd userfaultfd() creates a new userfaultfd object that can be used for delegation of page-fault handling to a user-space application, and returns a file descriptor that refers to the new object. The new userfaultfd object is configured using ioctl(2). Once the userfaultfd object is configured, the application can use read(2) to receive userfaultfd notifications. The reads from userfaultfd may be blocking or non-blocking, depending on the value of flags used for the creation of the userfaultfd or subsequent calls to fcntl(2). 另外参考: https://www.kernel.org/doc/html/latest/admin-guide/mm/userfaultfd.html The real advantage of userfaults if compared to regular virtual memory management of mremap/mprotect is that the userfaults in all their operations never involve heavyweight structures like vmas (in fact the userfaultfd runtime load never takes the mmap_lock for writing). Vmas are not suitable for page- (or hugepage) granular fault tracking when dealing with virtual address spaces that could span Terabytes. Too many vmas would be needed for that. The userfaultfd once opened by invoking the syscall, can also be passed using unix domain sockets to a manager process, so the same manager process could handle the userfaults of a multitude of different processes without them being aware about what is going on (well of course unless they later try to use the userfaultfd themselves on the same region the manager is already tracking, which is a corner case that would currently return -EBUSY). The userland application should set the feature flags it intends to use when invoking the UFFDIO_API ioctl, to request that those features be enabled if supported. Once the userfaultfd API has been enabled the UFFDIO_REGISTER ioctl should be invoked (if present in the returned uffdio_api.ioctls bitmask) to register a memory range in the userfaultfd by setting the uffdio_register structure accordingly. The uffdio_register.mode bitmask will specify to the kernel which kind of faults to track for the range. The UFFDIO_REGISTER ioctl will return the uffdio_register.ioctls bitmask of ioctls that are suitable to resolve userfaults on the range registered. Not all ioctls will necessarily be supported for all memory types (e.g. anonymous memory vs. shmem vs. hugetlbfs), or all types of intercepted faults. Userland can use the uffdio_register.ioctls to manage the virtual address space in the background (to add or potentially also remove memory from the userfaultfd registered range). This means a userfault could be triggering just before userland maps in the background the user-faulted page. 这个page fault处理线程使用UFFDIO_COPY ioctl来解决page fault, 这个ioctl的好处是保证file内容被完全拷贝到新分配的物理内容, 才会唤醒app进程. 这个用户态处理page fault的过程, 可以使用app的knowledge, 比如可以设置page size, 预取和换出策略. 这些\"定制化\"的策略只影响这个app, 其他的app可以选择不同的策略. 这个灵活性是kernel无法提供的. 同时, 写进物理页的内容也可以是从其他非文件的地方来, 比如远程的数据服务器. 总的来说, Umap在用户态实现了page的管理. 在用户app的虚拟地址空间, umap管理深蓝色部分. 产生的page faults入队列, 由filler们把数据从不同的存储实体(stroe object)里填充到内部buffer, 如果buffer满了, 就触发eviction机制, 由evictor把脏页写回到存储实体里. 为了提高并发, fillers和evictors都是IO线程池. umap可以让app自己配置page size, 这个对性能提高帮助很大. 也可以让app配置灵活的prefetching策略. 硬件的prefetching往往不够灵活, 因为现实的预取的pattern很复杂, 很难有一个通用的策略. 内核代码可以使用prefetch相关的函数来直到硬件预取, 但一般的实现里用户态没有相关的api. umap的API类似mmap: int fd = open(fname , O_RDWR); void* base_addr = umap(NULL, totalbytes, PROT_READ|PROT_WRITE, UMAP_PRIVATE, fd, 0); //Select two non -contiguous pages to prefetch std::vector pfi; umap_prefetch_item p0 = { .page_base_addr = &base[5 *psize] }; pfi.push_back(p0); umap_prefetch_item p1 = { .page_base_addr = &base[15* psize] }; pfi.push_back(p1); umap_prefetch(num_prefetch_pages , &pfi[0]); computation(); //release resources uunmap(base_addr , totalbytes); umap的性能在page size为4K的时候还是低于mmap的, 但从64K开始, 已经开始超越:这说明基本上, umap的性能超越来自于page size可以修改, 而不是来自于其本身的框架. 因为userfaultfd的机制通知用户态本身就有不小的overhead. sentry的mm 参考: https://xhfu.me/files/ad5e3bbbdb2e7f4dbb5dc19c121e89a9/cse291_project_final_report.pdf 对sentry来说, app的mmap会被sentry拦截并解析(使用ptrace或kvm), 创建sentry的VMA到这个file的映射, 然后使用pgalloc包创建这个file到一个host临时文件的映射: Create sentry VMA: Maps virtual address to offset of file in sentry (instead of host kernel). After triggered by a sentry page fault (VA accessed for 1st time) Create sentry filemap: pgalloc is used to map file and offset in sentry to file and offset on host. Create host VMA: Maps virtual address from 1. to file and offset on host from 2. by calling the host mmap syscall. After triggered by a host page fault (VA acessed for 2nd time) Create host filemap: Maps file and offset on host to physical address. Create PTE: Maps virtual address from 1. to physical address from 4. 性能对比 netstask netstask是gvisor的用户态kernel sentry的tcp/ip协议栈. 代码在https://github.com/google/gvisor/tree/master/pkg/sentry/socket/netstack tcp/ip协议栈的核心实现在https://github.com/google/gvisor/tree/master/pkg/tcpip gvisor支持NetworkSandbox和NetworkHost: 前者是默认的, 用的是gvisor自己实现的协议栈; 后者是直接使用host的syscall. const ( // NetworkSandbox uses internal network stack, isolated from the host. NetworkSandbox NetworkType = iota // NetworkHost redirects network related syscalls to the host network. NetworkHost // NetworkNone sets up just loopback using netstack. NetworkNone ) pkg/abi/linux 这个包提供了很多系统级宏定义, 结构体定义, 按功能.go文件来组织的, 比较清楚, 相对全面, 比如 mm.go ip.go fs.go epoll_arm64.go 等等, 很多. 下面是其中一个seccomp.go的举例: pkg/abi/linux/seccomp.go 看起来都是手动根据系统头文件整理的, 比如: // Seccomp constants taken from . const ( SECCOMP_MODE_NONE = 0 SECCOMP_MODE_FILTER = 2 SECCOMP_RET_ACTION_FULL = 0xffff0000 SECCOMP_RET_ACTION = 0x7fff0000 SECCOMP_RET_DATA = 0x0000ffff SECCOMP_SET_MODE_FILTER = 1 SECCOMP_FILTER_FLAG_TSYNC = 1 SECCOMP_GET_ACTION_AVAIL = 2 ) // BPFAction is an action for a BPF filter. type BPFAction uint32 // BPFAction definitions. const ( SECCOMP_RET_KILL_PROCESS BPFAction = 0x80000000 SECCOMP_RET_KILL_THREAD BPFAction = 0x00000000 SECCOMP_RET_TRAP BPFAction = 0x00030000 SECCOMP_RET_ERRNO BPFAction = 0x00050000 SECCOMP_RET_TRACE BPFAction = 0x7ff00000 SECCOMP_RET_ALLOW BPFAction = 0x7fff0000 ) pkg/hostarch/hostarch.go host只依赖标准库\"encoding/binary\"和unix系统库\"golang.org/x/sys/unix\", 它描述了host的地址空间host包很简单, 主要是pagesize, 目前只支持4K的页. func init() { // Make sure the page size is 4K on arm64 platform. if size := unix.Getpagesize(); size != PageSize { panic(\"Only 4K page size is supported on arm64!\") } } 还有rwx的读写执行的属性定义. pkg/seccomp/seccomp.go seccomp用于产生seccomp filter. 看起来是用的比较原始的bpf汇编. pkg/sentry/arch/arch.go 依赖 \"gvisor.dev/gvisor/pkg/abi/linux\" \"gvisor.dev/gvisor/pkg/cpuid\" \"gvisor.dev/gvisor/pkg/hostarch\" \"gvisor.dev/gvisor/pkg/log\" \"gvisor.dev/gvisor/pkg/marshal\" \"gvisor.dev/gvisor/pkg/sentry/arch/fpu\" \"gvisor.dev/gvisor/pkg/sentry/limits\" arch目前支持amd64和arm64, 里面定义了上下文的接口, 用接口来抽象: Context provides architecture-dependent information for a specific thread. 每个线程都有个context, 里面有系统调用相关的, 栈相关的, 寄存器恢复相关的. 为了通用性, 值都用uintptr来表示, 比如: type SyscallArgument struct { // Prefer to use accessor methods instead of 'Value' directly. Value uintptr } // SyscallArguments represents the set of arguments passed to a syscall. type SyscallArguments [6]SyscallArgument context有个方法, get和set所有寄存器 // PtraceGetRegs implements ptrace(PTRACE_GETREGS) by writing the // general-purpose registers represented by this Context to dst and // returning the number of bytes written. PtraceGetRegs(dst io.Writer) (int, error) // PtraceSetRegs implements ptrace(PTRACE_SETREGS) by reading // general-purpose registers from src into this Context and returning the // number of bytes read. PtraceSetRegs(src io.Reader) (int, error) 寄存器有统一的抽象 比如pkg/sentry/arch/arch_aarch64.go中, 定义的寄存器: // State contains the common architecture bits for aarch64 (the build tag of this // file ensures it's only built on aarch64). // // +stateify savable type State struct { // The system registers. Regs Registers // Our floating point state. fpState fpu.State `state:\"wait\"` // FeatureSet is a pointer to the currently active feature set. FeatureSet *cpuid.FeatureSet // OrigR0 stores the value of register R0. OrigR0 uint64 } 注意这里的Registers其实用的是linux.PtraceRegs // Registers represents the CPU registers for this architecture. // // +stateify savable type Registers struct { linux.PtraceRegs // TPIDR_EL0 is the EL0 Read/Write Software Thread ID Register. TPIDR_EL0 uint64 } 这个linux.PtraceRegs在pkg/abi/linux/ptrace_arm64.go中定义, 这是个只在arm64上编译的文件, 属于linux abi的一部分. // PtraceRegs is the set of CPU registers exposed by ptrace. Source: // syscall.PtraceRegs. // // +marshal // +stateify savable type PtraceRegs struct { Regs [31]uint64 Sp uint64 Pc uint64 Pstate uint64 } 上面的State实现了部分context接口的函数, 被pkg/sentry/arch/arch_arm64.go的context64使用: // context64 represents an ARM64 context. // // +stateify savable type context64 struct { State sigFPState []fpu.State // fpstate to be restored on sigreturn. } 这个context64就实现了全部的context要求的接口, 这要求有对底层寄存器的ABI的知识, 比如: // General purpose registers usage on Arm64: // R0...R7: parameter/result registers. // R8: indirect result location register. // R9...R15: temporary rgisters. // R16: the first intra-procedure-call scratch register. // R17: the second intra-procedure-call scratch register. // R18: the platform register. // R19...R28: callee-saved registers. // R29: the frame pointer. // R30: the link register. kernel package kernel里面实现了基础的内核组件: task 调度 signal等等... 标准的kernel的调度对象是线程, 而gvisor的调度对象是goroutine 在标准的kernel下, 一个线程可以在如下情况下被调度出去: 线程自己让出执行, 或被抢占, 线程仍然runnable, 但已经不在执行 线程退出. sentry里面, 从Task.run里退出就可以了 线程进入可打断的sleep, 线程可以被自己唤醒或收到信号. sentry里面是用blocking这个模式, 所有事件block在go channel的select, 所以可以被打断. 在task_block.go 线程进入不可打断的睡眠, 只有用户自己定义的wakeup条件达到才能唤醒. 大体上, sentry还是用了checkpoints技术在关键点设置调度代码. task的状态机 runsc boot流程 比如如下命令: docker run --cpus=2 -m 2g --rm --runtime=runsc -it --name=test centos:7 bash 会导致containerd-shim调用runsc boot命令 runsc --root=/var/run/docker/runtime-runsc/moby --debug=true --log=/run/containerd/io.containerd.runtime.v1.linux/moby/8142acd62c66b0847eddee55c7c247a05a04e91b0e4a0db2c6942075ceb75f2e/log.json --log-format=json --debug-log=/tmp/runsc/ --platform=kvm --strace=true --log-fd=3 --debug-log-fd=4 boot --bundle=/run/containerd/io.containerd.runtime.v1.linux/moby/8142acd62c66b0847eddee55c7c247a05a04e91b0e4a0db2c6942075ceb75f2e --controller-fd=5 --mounts-fd=6 --spec-fd=7 --start-sync-fd=8 --io-fds=9 --io-fds=10 --io-fds=11 --io-fds=12 --device-fd=13 --pidns=true --setup-root --stdio-fds=14 --stdio-fds=15 --stdio-fds=16 --cpu-num 24 --total-memory76005576704 8142acd62c66b0847eddee55c7c247a05a04e91b0e4a0db2c6942075ceb75f2e] kernel就是runsc boot进程, 这个进程也叫sandbox进程 比如在vm里ls或者ps, 用户程序代码段会被map到runsc boot进程空间, 用pmap能看到 所有用户态程序都是用goroutine运行的 所有的用户态程序都是在runsc boot进程空间的, 对host来说都是一个runsc boot进程, 如果看CPU占用率就会看到都是runsc boot进程在占用CPU. KVM的platform的内存映射的核心逻辑是通过kVM的KVM_SET_USER_MEMORY_REGION 来配置VM的PA到host进程的VA, 使得VM的VA被map到host进程的对应VA, 从而使用host进程的PA. 比如在VM里面执行ls命令, kernel(即runsc boot)发现是syscall的exec, 所以退出VM, 在host进程 空间load这个ls的elf, 做好memory映射 //runsc boot: launch a sandbox process //@runsc/cli/main.go Main() //@runsc/cmd/boot.go (b *Boot) Execute() //Setting up sandbox chroot in \"/tmp\" setUpChroot() //原理上是调用unix.Mount()准备chroot的目录, 比如/tmp /proc等 //然后调用pivot_root系统调用做chroot pivotRoot(\"/tmp\") //使用controller-fd mounts-fd spec-fd start-sync-fd io-fds io-fds device-fd和上层交互 //使用上面的信息Create the loader. bootArgs := boot.Args{ ID: f.Arg(0), Spec: spec, Conf: conf, ControllerFD: b.controllerFD, Device: os.NewFile(uintptr(b.deviceFD), \"platform device\"), GoferFDs: b.ioFDs.GetArray(), StdioFDs: b.stdioFDs.GetArray(), NumCPU: b.cpuNum, TotalMem: b.totalMem, UserLogFD: b.userLogFD, ProfileBlockFD: b.profileBlockFD, ProfileCPUFD: b.profileCPUFD, ProfileHeapFD: b.profileHeapFD, ProfileMutexFD: b.profileMutexFD, TraceFD: b.traceFD, } //新建一个kvm类型的VM做为flatform, 新建一个临时文件做为backed memory file //map VDSO, 新建一个timekeeper, 新建rootNetwork, 注册文件系统, 作为kernel //用上面的kernel做一个loader, 启动service响应socket的control请求 l, err := boot.New(bootArgs) // l是loader //createPlatform在kvm实现下是新建一个vm //在Restore流程里也会调用createPlatform, 从当前的kernel恢复到新建的kernel //@runsc/boot/loader.go p, err := createPlatform(args.Conf, args.Device) p, err := platform.Lookup(\"kvm\") //这里是kvm的New //@pkg/sentry/platform/kvm/kvm.go p.New(deviceFile) updateGlobalOnce() updateSystemValues(int(fd)) sz, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(fd), _KVM_GET_VCPU_MMAP_SIZE, 0) runDataSize = int(sz) hasGuestPCID = true //@pkg/ring0/lib_arm64.go ring0.Init() //目前为空 physicalInit() //重要全局变量, 记录了这个进程状态下的VA和虚拟物理地址(或者叫IPA)的映射. //把host空间用mmap填满 physicalRegions = computePhysicalRegions(fillAddressSpace()) //ioctl创建一个vm vm, _, errno = unix.Syscall(unix.SYS_IOCTL, fd, _KVM_CREATE_VM, 0) //@pkg/sentry/platform/kvm/machine.go machine, err := newMachine(int(vm)) m := &machine{fd: vm} maxVCPUs, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CHECK_EXTENSION, _KVM_CAP_MAX_VCPUS) m.vCPUsByTID = make(map[uint64]*vCPU) m.vCPUsByID = make([]*vCPU, m.maxVCPUs) //这个kernel不是kernel.Kernel, 而是ring0.kernel, 是给kvm用的 m.kernel.Init(m.maxVCPUs) //24个核是24个VCPU maxSlots, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CHECK_EXTENSION, _KVM_CAP_MAX_MEMSLOTS) //509个 hasTSCControl, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CHECK_EXTENSION, _KVM_CAP_TSC_CONTROL) //我这里是false // Create the upper shared pagetables and kernel(sentry) pagetables. m.upperSharedPageTables = pagetables.New(newAllocator()) m.mapUpperHalf(m.upperSharedPageTables) m.upperSharedPageTables.Allocator.(*allocator).base.Drain() m.upperSharedPageTables.MarkReadOnlyShared() m.kernel.PageTables = pagetables.NewWithUpper(newAllocator(), m.upperSharedPageTables, ring0.KernelStartAddress) // 配置seccomp为trap mmap, 其他allow; mmap会触发SIGSYS信号 seccompMmapRules(m) // Map everything in the lower half. //即physicalRegions里的每个region都生成一个PTE(page table entry), 都在lower half m.kernel.PageTables.Map() // 把当前host进程已经map的虚拟地址空间(\"/proc/self/maps\")映射进VM for line in open(\"/proc/self/maps\") if vr.accessType.Execute //有代码被加到VM的页表 m.kernel.PageTables.Map() m.mapPhysical(physical, length, physicalRegions) // 用KVM的SET_USER_MEMORY_REGION ioctl来配置kvm的第二次翻译 // map host va和VM pa handleBluepillFault(m, physical, phyRegions) virtualStart, physicalStart, length, pr := calculateBluepillFault(physical, phyRegions) m.setMemoryRegion(int(slot), physicalStart, length, virtualStart, flags) unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_SET_USER_MEMORY_REGION, uintptr(unsafe.Pointer(&userRegion))) //@pkg/sentry/platform/kvm/machine_arm64_unsafe.go m.initArchState() unix.RawSyscall(_KVM_ARM_PREFERRED_TARGET) for maxVCPU //对每个vCPU //@pkg/sentry/platform/kvm/machine.go m.createVCPU(i) //KVM ioctl _KVM_CREATE_VCPU fd, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CREATE_VCPU, uintptr(id)) c := &vCPU{ id: id, fd: int(fd), machine: m, } c.CPU.Init(&m.kernel, c.id, c) // Set the kernel stack pointer(virtual address). c.registers.Sp = uint64(c.StackTop()) //这个kernel的stack是给中断用的 m.vCPUsByID[c.id] = c c.setSignalMask() //Defines which signals are blocked during execution of KVM_RUN //按理说应该是每个线程来配置, 但这里没有开新go routine unix.RawSyscall(_KVM_SET_SIGNAL_MASK) //runData是mmap来的, 是用户态和KVM交互用的 runData, err := mapRunData(int(fd)) c.runData = runData //@pkg/sentry/platform/kvm/machine_arm64_unsafe.go c.initArchState() //KVM_ARM_VCPU_INIT会把cpu重置为初始值. 如果没有这一步, KVM_RUN就会错误 unix.RawSyscall(_KVM_ARM_VCPU_INIT) //用setOneRegister()设置如下寄存器: //tcr_el1: Translation Control Register //mair_el1: Multiprocessor Affinity Register //ttbr0_el1: 用户态页表基地址, 这里对应sentry, 代码里也对应c.SetTtbr0Kvm(uintptr(data)) //ttbr1_el1: 内核态页表基地址, 这里是upper空间 //sp_el1: 内核态的sp, 处理中断的 //pc: 初始指向ring0.Start() //r8: r8是platform专用寄存器, 指向c.CPU //vbar_el1: 异常vector基地址, 是ring0.Vectors, 这是代码段 //给这个vCPU设置时间 //在arm64上是setOneRegister _KVM_ARM64_REGS_TIMER_CNT c.setSystemTime() // m代表的machine是垃圾回收的, 用SetFinalizer机制来调用m.Destroy清理 runtime.SetFinalizer(m, (*machine).Destroy) //这里new一个kernel.Kernel, 包括了一个新建的kvm platform的实例 k := &kernel.Kernel{ Platform: p, } //使用一个叫\"runsc-memory\"的临时文件做为backed memory file mf, err := createMemoryFile() memfd, err := memutil.CreateMemFD(\"runsc-memory\", 0) memfile := os.NewFile(uintptr(memfd), memfileName) //@pkg/sentry/pgalloc/pgalloc.go mf, err := pgalloc.NewMemoryFile(memfile, pgalloc.MemoryFileOpts{}) k.SetMemoryFile(mf) //VDSO vdso, err := loader.PrepareVDSO(k) //这个vdsodata.Binary是个自动生成的[]byte数组 //好像是从vdso_bin里读出来的 //在@pkg/sentry/loader/vdsodata/vdso_arm64.go vdsoFile := &byteFullReader{data: vdsodata.Binary} //检测VDSO的elf头, 返回一个elfInfo结构体 info, err := validateVDSO(nil, vdsoFile, uint64(len(vdsodata.Binary))) size, ok := hostarch.Addr(len(vdsodata.Binary)).RoundUp() mf := mfp.MemoryFile() //给VDSO申请页 vdso, err := mf.Allocate(uint64(size), pgalloc.AllocOpts{Kind: usage.System}) ims, err := mf.MapInternal(vdso, hostarch.ReadWrite) _, err = safemem.CopySeq(ims, safemem.BlockSeqOf(safemem.BlockFromSafeSlice(vdsodata.Binary))) //再申请一个参数页 paramPage, err := mf.Allocate(hostarch.PageSize, pgalloc.AllocOpts{Kind: usage.System}) //新建一个timekeeper. 包括Monotonic和Realtime两种 //@pkg/sentry/time/calibrated_clock.go tk := kernel.NewTimekeeper(k, vdso.ParamPage.FileRange()) tk.SetClocks(time.NewCalibratedClocks()) // Create root network namespace/stack. netns, err := newRootNetworkNamespace(args.Conf, tk, k) case config.NetworkHost: inet.NewRootNamespace(hostinet.NewStack(), nil) case config.NetworkNone, config.NetworkSandbox: s, err := newEmptySandboxNetworkStack(clock, uniqueID, conf.AllowPacketEndpointWrite) creator := &sandboxNetstackCreator{ clock: clock, uniqueID: uniqueID, allowPacketEndpointWrite: conf.AllowPacketEndpointWrite, } inet.NewRootNamespace(s, creator) // Create capabilities. caps, err := specutils.Capabilities(args.Conf.EnableRaw, args.Spec.Process.Capabilities) // Create credentials. creds := auth.NewUserCredentials( auth.KUID(args.Spec.Process.User.UID), auth.KGID(args.Spec.Process.User.GID), extraKGIDs, caps, auth.NewRootUserNamespace()) //初始化kernel k.Init(kernel.InitKernelArgs{ FeatureSet: cpuid.HostFeatureSet().Fixed(), Timekeeper: tk, RootUserNamespace: creds.UserNamespace, RootNetworkNamespace: netns, ApplicationCores: uint(args.NumCPU), Vdso: vdso, RootUTSNamespace: kernel.NewUTSNamespace(args.Spec.Hostname, args.Spec.Hostname, creds.UserNamespace), RootIPCNamespace: kernel.NewIPCNamespace(creds.UserNamespace), RootAbstractSocketNamespace: kernel.NewAbstractSocketNamespace(), PIDNamespace: kernel.NewRootPIDNamespace(creds.UserNamespace), }) registerFilesystems(k) adjustDirentCache(k) procArgs, err := createProcessArgs(args.ID, args.Spec, creds, k, k.RootPIDNamespace()) err := initCompatLogs(args.UserLogFD) mountHints, err := newPodMountHints(args.Spec) eid := execID{cid: args.ID} //loader包括kernel.Kernel l := &Loader{ k: k, watchdog: dog, sandboxID: args.ID, processes: map[execID]*execProcess{eid: {}}, mountHints: mountHints, root: info, stopProfiling: stopProfiling, } sighandling.IgnoreChildStop() //Create the control server using the provided FD. ctrl, err := newController(args.ControllerFD, l) ctrl := &controller{} //创建基于unix socket urpc server ctrl.srv, err = server.CreateFromFD(fd) //注册控制接口 ctrl.srv.Register(ctrl.manager) ctrl.srv.Register(net) ctrl.srv.Register(&control.Events{}) ctrl.srv.Register(&control.Fs{Kernel: l.k}) ctrl.srv.Register(&control.Lifecycle{Kernel: l.k}) ctrl.srv.Register(&control.Logging{}) ctrl.srv.Register(&control.Usage{Kernel: l.k}) ctrl.srv.Register(&control.Proc{Kernel: l.k}) ctrl.srv.Register(&control.State{Kernel: l.k}) ctrl.srv.Register(&debug{}) l.ctrl = ctrl //起一个go routine accept socket连接 ctrl.srv.StartServing() //通知父进程sandbox已经启动完毕, 已经准备好controller服务 // Wait for the start signal from runsc. //等待runsc发start信号 l.WaitForStartSignal() // Run runs the root container. // Run the application and wait for it to finish. l.Run() //installs sandbox seccomp filters with the host. l.installSeccompFilters() //如果不是restore场景, 就新起一个进程load user mode程序 // Create the root container init task. It will begin running // when the kernel is started. l.createContainerProcess(true, l.sandboxID, &l.root) // Create the FD map, which will set stdin, stdout, and stderr. createFDTable(ctx, info.spec.Process.Terminal, info.stdioFDs, info.spec.Process.User) //起一个监测gofer的routine l.startGoferMonitor(cid, int32(info.goferFDs[0].FD())) mntr := newContainerMounter(info, l.k, l.mountHints, kernel.VFS2Enabled) if root mntr.processHints(info.conf, info.procArgs.Credentials) //set up the file system for all containers //即所有的container都看到同一份/目录, mount的信息放在&info.procArgs setupContainerFS(ctx, info.conf, mntr, &info.procArgs) //@pkg/sentry/kernel/kernel.go // CreateProcess creates a new task in a new thread group with the given // options. The new task has no parent and is in the root PID namespace. //新的task在root pid 空间里, 没有parent l.k.CreateProcess(info.procArgs) //准备mount namespace //建一个空的thread group tg := k.NewThreadGroup(mntns, args.PIDNamespace, NewSignalHandlers(), linux.SIGCHLD, args.Limits) // Create a fresh task context. remainingTraversals := args.MaxSymlinkTraversals loadArgs := loader.LoadArgs{ Opener: opener, RemainingTraversals: &remainingTraversals, ResolveFinal: true, Filename: args.Filename, File: args.File, CloseOnExec: false, Argv: args.Argv, Envv: args.Envv, Features: k.featureSet, } // LoadTaskImage loads a specified file into a new TaskImage. //@pkg/sentry/kernel/task_image.go image, se := k.LoadTaskImage(ctx, loadArgs) //新建一个空的memoryManager with no mappings and 1 user //@pkg/sentry/mm/lifecycle.go m := mm.NewMemoryManager(k, k, k.SleepForAddressSpaceActivation) //@pkg/sentry/loader/loader.go //Load loads args.File into a MemoryManager. os, ac, name, err := loader.Load(ctx, args, k.extraAuxv, k.vdso) loaded, ac, file, newArgv, err := loadExecutable(ctx, args) //看文件头, 分elf(\"\\x7fELF\")和script(\"#!\") case \"\\x7fELF\": // loadELF loads args.File into the Task address space. //@pkg/sentry/loader/elf.go loaded, ac, err := loadELF(ctx, args) //加载args.File到args.MemoryManager, 底层调用MemoryManager.MMap建立一个内存区域 bin, ac, err := loadInitialELF(ctx, args.MemoryManager, args.Features, args.File) if 解释器 interp, err = loadInterpreterELF(ctx, args.MemoryManager, intFile, bin) case \"#!\": //返回解释器的路径 args.Filename, args.Argv, err = parseInterpreterScript(ctx, args.Filename, args.File, args.Argv) // Lookup our new syscall table. st, ok := LookupSyscallTable(os, ac.Arch()) // Create the task. config := &TaskConfig{ Kernel: k, ThreadGroup: tg, TaskImage: image, FSContext: fsContext, FDTable: args.FDTable, Credentials: args.Credentials, NetworkNamespace: k.RootNetworkNamespace(), AllowedCPUMask: sched.NewFullCPUSet(k.applicationCores), UTSNamespace: args.UTSNamespace, IPCNamespace: args.IPCNamespace, AbstractSocketNamespace: args.AbstractSocketNamespace, MountNamespaceVFS2: mntnsVFS2, ContainerID: args.ContainerID, UserCounters: k.GetUserCounters(args.Credentials.RealKUID), } t, err := k.tasks.NewTask(ctx, config) t, err := ts.newTask(cfg) t.traceExecEvent(image) // Simulate exec for tracing. l.watchdog.Start() //45s周期, 3m超时 l.k.Start() k.started = true k.cpuClockTicker = ktime.NewTimer(k.timekeeper.monotonicClock, newKernelCPUClockTicker(k)) k.cpuClockTicker.Swap(ktime.Setting{ Enabled: true, Period: linux.ClockTick, }) // Start task goroutines. for t, tid := range k.tasks.Root.tids { t.Start(tid) //@pkg/sentry/kernel/task_run.go go t.run(uintptr(tid)) // Activate our address space. t.Activate() //调用platform的NewAddressSpace() for t.doStop() //等待下一次运行 //注意这个结构, 一行就支持状态机的迁移 //因为多个状态都有execute函数, 执行后返回下一个状态 //不同的状态: //runSyscallAfterPtraceEventClone //runSyscallAfterVforkStop //runSyscallAfterExecStop //runExit //runExitMain //runExitNotify //runApp //runInterrupt //runInterruptAfterSignalDeliveryStop //runSyscallAfterPtraceEventSeccomp //runSyscallAfterSyscallEnterStop //runSyscallAfterSysemuStop //runSyscallReinvoke //runSyscallExit //runVsyscallAfterPtraceEventSeccomp //初始状态是(*runApp): t.runState = t.runState.execute(t) if t.interrupted() return (*runInterrupt)(nil) //下个状态是interrupt //在返回用户态之前, 执行task work if atomic.LoadInt32(&t.taskWorkCount) > 0 queue := t.taskWork for _, work := range queue work.TaskWork(t) //处理可能的SyscallReturn //处理可能的SavedSignalMask //调用platform的switch info, at, err := t.p.Switch(t, t.MemoryManager(), t.Arch(), t.rseqCPU) switch err { case nil: return t.doSyscall() //默认就是syscall case platform.ErrContextInterrupt: //被platform.Context.Interrupt()打断 return (*runApp)(nil) case platform.ErrContextSignal: //被信号打断 t.MemoryManager().HandleUserFault() //处理用户pagefault if 是同步signal t.SendSignal(info) else t.k.sendExternalSignal(info, \"application\") return (*runApp)(nil) case platform.ErrContextCPUPreempted: t.rseqPreempted = true return (*runApp)(nil) } } l.WaitExit() l.Destroy() platform kernel包括了platform, 比如在初始化的时候: p, err := createPlatform(cm.l.root.conf, deviceFile) //Kernel包括platform k := &kernel.Kernel{ Platform: p, } platform抽象了一个platform的能力, 主要是描述调度能力, 地址空间能力. 比如MemoryManager是在地址空间之上的一种抽象: // MemoryManager represents an abstraction above the platform address space // which manages memory mappings and their contents. type MemoryManager interface { //usermem.IO provides access to the contents of a virtual memory space. usermem.IO // MMap establishes a memory mapping. MMap(ctx context.Context, opts memmap.MMapOpts) (hostarch.Addr, error) // AddressSpace returns the AddressSpace bound to mm. AddressSpace() AddressSpace } 地址空间 // AddressSpace represents a virtual address space in which a Context can // execute. type AddressSpace interface { // MapFile creates a shared mapping of offsets fr from f at address addr. // Any existing overlapping mappings are silently replaced. // // If precommit is true, the platform should eagerly commit resources (e.g. // physical memory) to the mapping. The precommit flag is advisory and // implementations may choose to ignore it. // // Preconditions: // * addr and fr must be page-aligned. // * fr.Length() > 0. // * at.Any() == true. // * At least one reference must be held on all pages in fr, and must // continue to be held as long as pages are mapped. MapFile(addr hostarch.Addr, f memmap.File, fr memmap.FileRange, at hostarch.AccessType, precommit bool) error // Unmap unmaps the given range. // // Preconditions: // * addr is page-aligned. // * length > 0. Unmap(addr hostarch.Addr, length uint64) // Release releases this address space. After releasing, a new AddressSpace // must be acquired via platform.NewAddressSpace(). Release() // PreFork() is called before creating a copy of AddressSpace. This // guarantees that this address space will be in a consistent state. PreFork() // PostFork() is called after creating a copy of AddressSpace. PostFork() // AddressSpaceIO methods are supported iff the associated platform's // Platform.SupportsAddressSpaceIO() == true. AddressSpaces for which this // does not hold may panic if AddressSpaceIO methods are invoked. AddressSpaceIO } platform包括了Context抽象, 包括上下文切换: // Switch resumes execution of the thread specified by the arch.Context // in the provided address space. This call will block while the thread // is executing. // 正常应该是成功调用一个系统调用. // 如果正在执行这个系统调用的时候有signal, 返回ErrContextSignal // 如果调用了Interrupt()则返回ErrContextInterrupt Switch(ctx context.Context, mm MemoryManager, ac arch.Context, cpu int32) (*linux.SignalInfo, hostarch.AccessType, error) // PullFullState() pulls a full state of the application thread. PullFullState(as AddressSpace, ac arch.Context) // Interrupt interrupts a concurrent call to Switch(), causing it to return // ErrContextInterrupt. Interrupt() // Release() releases any resources associated with this context. Release() 根据g3doc/architecture_guide/platforms.md, gvisor需要平台实现系统调用的拦截, 上下文切换, 和memory map. 这些需求是以interface的形式来体现的: type Platform interface { NewAddressSpace() (AddressSpace, error) NewContext() Context } type Context interface { Switch(as AddressSpace, ac arch.Context) (..., error) } type AddressSpace interface { MapFile(addr hostarch.Addr, f File, fr FileRange, at hostarch.AccessType, ...) error Unmap(addr hostarch.Addr, length uint64) } 现在有ptrace方式和KVM方式: ptrace方式更通用, 但性能差; KVM方式需要硬件虚拟化支持, 性能好点. 哪里调用了Switch() 是kernel调的: 在pkg/sentry/kernel/task_run.go // run runs the task goroutine. // // threadID a dummy value set to the task's TID in the root PID namespace to // make it visible in stack dumps. A goroutine for a given task can be identified // searching for Task.run()'s argument value. func (t *Task) run(threadID uintptr) { atomic.StoreInt64(&t.goid, goid.Get()) // Construct t.blockingTimer here. We do this here because we can't // reconstruct t.blockingTimer during restore in Task.afterLoad(), because // kernel.timekeeper.SetClocks() hasn't been called yet. blockingTimerNotifier, blockingTimerChan := ktime.NewChannelNotifier() t.blockingTimer = ktime.NewTimer(t.k.MonotonicClock(), blockingTimerNotifier) defer t.blockingTimer.Destroy() t.blockingTimerChan = blockingTimerChan // Activate our address space. t.Activate() // The corresponding t.Deactivate occurs in the exit path // (runExitMain.execute) so that when // Platform.CooperativelySharesAddressSpace() == true, we give up the // AddressSpace before the task goroutine finishes executing. // If this is a newly-started task, it should check for participation in // group stops. If this is a task resuming after restore, it was // interrupted by saving. In either case, the task is initially // interrupted. t.interruptSelf() for { // Explanation for this ordering: // // - A freshly-started task that is stopped should not do anything // before it enters the stop. // // - If taskRunState.execute returns nil, the task goroutine should // exit without checking for a stop. // // - Task.Start won't start Task.run if t.runState is nil, so this // ordering is safe. t.doStop() t.runState = t.runState.execute(t) //本质上是在循环调用这个t.runState.execute, 结合后面的分析, 这个函数触发一个syscall cycle的执行. if t.runState == nil { t.accountTaskGoroutineEnter(TaskGoroutineNonexistent) t.goroutineStopped.Done() t.tg.liveGoroutines.Done() t.tg.pidns.owner.liveGoroutines.Done() t.tg.pidns.owner.runningGoroutines.Done() t.p.Release() // Deferring this store triggers a false positive in the race // detector (https://github.com/golang/go/issues/42599). atomic.StoreInt64(&t.goid, 0) // Keep argument alive because stack trace for dead variables may not be correct. runtime.KeepAlive(threadID) return } } } // The runApp state checks for interrupts before executing untrusted // application code. type runApp struct{} func (app *runApp) execute(t *Task) taskRunState { //先检查是否需要处理interrupt //在执行用户代码之前, 执行里面的taskWork for _, work := range queue { work.TaskWork(t) } if t.haveSyscallReturn { } if t.haveSavedSignalMask { } if t.rseqPreempted { } if t.hasTracer() { } //下面就调用了t.p.Switch info, at, err := t.p.Switch(t, t.MemoryManager(), t.Arch(), t.rseqCPU) switch err { case nil: // 最常见的case // Handle application system call. // 这里就是处理用户的syscall return t.doSyscall() case platform.ErrContextInterrupt: case platform.ErrContextSignalCPUID: case platform.ErrContextSignal: case platform.ErrContextCPUPreempted: default: } } 这里是执行syscall的地方 @pkg/sentry/kernel/task_syscall.go // doSyscall is the entry point for an invocation of a system call specified by // the current state of t's registers. // // The syscall path is very hot; avoid defer. func (t *Task) doSyscall() taskRunState { t.Arch().SyscallSaveOrig() sysno := t.Arch().SyscallNo() args := t.Arch().SyscallArgs() if t.syscallFilters.Load() != nil { } return t.doSyscallEnter(sysno, args) } func (t *Task) doSyscallEnter(sysno uintptr, args arch.SyscallArguments) taskRunState { if next, ok := t.ptraceSyscallEnter(); ok { return next } return t.doSyscallInvoke(sysno, args) } func (t *Task) doSyscallInvoke(sysno uintptr, args arch.SyscallArguments) taskRunState { rval, ctrl, err := t.executeSyscall(sysno, args) if ctrl != nil { if !ctrl.ignoreReturn { t.Arch().SetReturn(rval) } if ctrl.next != nil { return ctrl.next } } else if err != nil { t.Arch().SetReturn(uintptr(-ExtractErrno(err, int(sysno)))) t.haveSyscallReturn = true } else { t.Arch().SetReturn(rval) } return (*runSyscallExit)(nil).execute(t) } //这里的executeSyscall就是gvisor拦截syscall后, 真正处理这个syscall的地方 func (t *Task) executeSyscall(sysno uintptr, args arch.SyscallArguments) (rval uintptr, ctrl *SyscallControl, err error) { s := t.SyscallTable() //查表到具体的syscall fn := s.Lookup(sysno) if fn != nil { // Call our syscall implementation. rval, ctrl, err = fn(t, args) //调用fn } else { // Use the missing function if not found. rval, err = t.SyscallTable().Missing(t, sysno, args) } } ptrace gvisor试用ptrace来执行用户代码, 但不允许其执行系统调用. ptrace有context的实现实例:主要是实现了Switch()方法 // Switch runs the provided context in the given address space. func (c *context) Switch(ctx pkgcontext.Context, mm platform.MemoryManager, ac arch.Context, cpu int32) (*linux.SignalInfo, hostarch.AccessType, error) { as := mm.AddressSpace() s := as.(*subprocess) //这里的效果是让这个subprocess执行到下一次syscall, 然后停下来 isSyscall := s.switchToApp(c, ac) //有syscall和signal两种可能 ...保存faultSP, faultAddr, faultIP 如果是syscall, 就返回nil, hostarch.NoAccess, nil 如果有SIGSEGV信号, 就返回&si, hostarch.NoAccess, platform.ErrContextSignal 最后根据条件返回&si, at, platform.ErrContextSignalCPUID } Switch()的基础逻辑是执行一个syscall sycle, 然后停在下一个syscall. 这里面关键是switchToApp // switchToApp is called from the main SwitchToApp entrypoint. // // This function returns true on a system call, false on a signal. func (s *subprocess) switchToApp(c *context, ac arch.Context) bool { // Lock the thread for ptrace operations. runtime.LockOSThread() defer runtime.UnlockOSThread() // Grab our thread from the pool. currentTID := int32(procid.Current()) t := s.sysemuThreads.lookupOrCreate(currentTID, s.newThread) // Reset necessary registers. regs := &ac.StateData().Regs // 从ac里面读出regs t.resetSysemuRegs(regs) // Set registers. 要先设置寄存器, 寄存器的值来自于上次保存的值 if err := t.setRegs(regs); err != nil { panic(fmt.Sprintf(\"ptrace set regs (%+v) failed: %v\", regs, err)) } // 这里看似像是个主循环, 但实际只是想执行一次system call for { // Start running until the next system call. if isSingleStepping(regs) { if _, _, errno := unix.RawSyscall6( unix.SYS_PTRACE, unix.PTRACE_SYSEMU_SINGLESTEP, uintptr(t.tid), 0, 0, 0, 0); errno != 0 { panic(fmt.Sprintf(\"ptrace sysemu failed: %v\", errno)) } } else { if _, _, errno := unix.RawSyscall6( unix.SYS_PTRACE, unix.PTRACE_SYSEMU, //通常是走这里, 每次都用ptrace系统调用来设置, 让tracee在下一次syscall之前停住 uintptr(t.tid), 0, 0, 0, 0); errno != 0 { panic(fmt.Sprintf(\"ptrace sysemu failed: %v\", errno)) } } // Wait for the syscall-enter stop. sig := t.wait(stopped) //注释说的很明确, wait syscall-enter stop(下面会有说明) if sig == unix.SIGSTOP { // SIGSTOP was delivered to another thread in the same thread // group, which initiated another group stop. Just ignore it. continue } t.getRegs(regs) //wait()返回走到这里说明这个tracee的线程已经停在syscall了. 马上保存寄存器到t, 以便下次恢复. t.getFPRegs(fpState, uint64(fpLen), useXsave) t.getTLS(&tls) ac.SetTLS(uintptr(tls)) // Is it a system call? 如果是syscall, 就return true了, 直接从本函数返回. if sig == (syscallEvent | unix.SIGTRAP) { s.arm64SyscallWorkaround(t, regs) // Ensure registers are sane. updateSyscallRegs(regs) return true } //下面是signal的处理流程 t.getSignalInfo(&c.signalInfo) //处理的时候看这个signal是kernel发的还是自己进程发的, 其他进程发的被忽略. } } thread.setRegs 上面switchToApp()函数中, 上来就从adress space里读出保存的寄存器, 用thread.setRegs()恢复到cpu中去. 这个函数就用到了下面会提到的ptrace的PTRACE_SETREGSET命令 // setRegs sets the general purpose register set. func (t *thread) setRegs(regs *arch.Registers) error { iovec := unix.Iovec{ Base: (*byte)(unsafe.Pointer(regs)), Len: uint64(unsafe.Sizeof(*regs)), } _, _, errno := unix.RawSyscall6( unix.SYS_PTRACE, unix.PTRACE_SETREGSET, uintptr(t.tid), linux.NT_PRSTATUS, uintptr(unsafe.Pointer(&iovec)), 0, 0) if errno != 0 { return errno } return nil } 主要结构体 子进程拥有线程池 // subprocess is a collection of threads being traced. type subprocess struct { platform.NoAddressSpaceIO // requests is used to signal creation of new threads. requests chan chan *thread // sysemuThreads are reserved for emulation. sysemuThreads threadPool // syscallThreads are reserved for syscalls (except clone, which is // handled in the dedicated goroutine corresponding to requests above). syscallThreads threadPool // mu protects the following fields. mu sync.Mutex // contexts is the set of contexts for which it's possible that // context.lastFaultSP == this subprocess. contexts map[*context]struct{} } 线程 // thread is a traced thread; it is a thread identifier. // // This is a convenience type for defining ptrace operations. type thread struct { tgid int32 tid int32 cpu uint32 // initRegs are the initial registers for the first thread. // // These are used for the register set for system calls. initRegs arch.Registers } thread有个syscall方法, 用于执行一个系统调用的cycle. 注意这里用了cycle一词, 执行过程和switchToApp()很像: 也是先load寄存器, 调用ptrace的PTRACE_CONT, 然后wait(), 待tracee的线程停住后保存寄存器. 看注释这个syscall不是给app用的, 而是某种条件下inject到远程上下文的. // syscall executes a system call cycle in the traced context. // // This is _not_ for use by application system calls, rather it is for use when // a system call must be injected into the remote context (e.g. mmap, munmap). // Note that clones are handled separately. func (t *thread) syscall(regs *arch.Registers) (uintptr, error) { // Set registers. if err := t.setRegs(regs); err != nil { panic(fmt.Sprintf(\"ptrace set regs failed: %v\", err)) } for { // Execute the syscall instruction. The task has to stop on the // trap instruction which is right after the syscall // instruction. if _, _, errno := unix.RawSyscall6(unix.SYS_PTRACE, unix.PTRACE_CONT, uintptr(t.tid), 0, 0, 0, 0); errno != 0 { panic(fmt.Sprintf(\"ptrace syscall-enter failed: %v\", errno)) } sig := t.wait(stopped) if sig == unix.SIGTRAP { // Reached syscall-enter-stop. break } else { // Some other signal caused a thread stop; ignore. if sig != unix.SIGSTOP && sig != unix.SIGCHLD { log.Warningf(\"The thread %d:%d has been interrupted by %d\", t.tgid, t.tid, sig) } continue } } // Grab registers. if err := t.getRegs(regs); err != nil { panic(fmt.Sprintf(\"ptrace get regs failed: %v\", err)) } return syscallReturnValue(regs) } 线程池 // threadPool is a collection of threads. type threadPool struct { // mu protects below. mu sync.RWMutex // threads is the collection of threads. // // This map is indexed by system TID (the calling thread); which will // be the tracer for the given *thread, and therefore capable of using // relevant ptrace calls. threads map[int32]*thread } ptrace系统调用 要理解这部分, 需要看man ptrace ptrace是个系统调用, 可以让一个进程(tracer)观察和控制另一个进程(tracee)的内存和寄存器.主要是用来实现断点和系统调用跟踪用的. tracee需要先被attach到tracer上. 这个attach是以线程为单位的: 一个进程的多个线程可以分别被attach到不同的tracer上, 没有被attach的线程就还是照常执行. 记住ptrace是对一个线程的. #include //下面的pid是tid, 即线程id long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data); 两种情况下一个进程可以发起trace到另外一个进程: fork一个子进程, 然后在子进程里调用ptrace PTRACE_TRACEME, 然后再用execve. 这样这个子进程就可以被trace了 用PTRACE_ATTACH or PTRACE_SEIZE来attach到另一个线程. tracee在有signal的时候会停下来, 即使ignore的signal也会停住. 这个时候, tracer的wait()系统调用会返回, 然后tracer可以通过ptrace命令来对已经停住的tracee做检查和修改. 然后tracer让tracee继续运行. 最后用PTRACE_DETACH来解除trace状态, 让tracee可以继续正常运行. ptrace可以做什么? ptrace的command很丰富, command就是传给ptrace系统调用的request The value of request determines the action to be performed: PTRACE_TRACEME: 唯一一个tracee调用的command, 用于把自身置为tracee PTRACE_PEEKTEXT, PTRACE_PEEKDATA: 查看tracee的内存, 在linux下面, text和data是一个空间, 效果一样. PTRACE_POKETEXT, PTRACE_POKEDATA: 修改tracee的内存. PTRACE_PEEKUSER: 读tracee的USER区域, 这是个含有寄存器和其他信息的区域(见) PTRACE_POKEUSER: 修改tracee的USER区域 PTRACE_GETREGS, PTRACE_GETFPREGS: 读tracee的通用寄存器或者浮点寄存器 PTRACE_SETREGS, PTRACE_SETFPREGS: 修改tracee寄存器 PTRACE_GETREGSET: 读CPU特殊寄存器 PTRACE_SETREGSET: 修改CPU寄存器 PTRACE_GETSIGINFO: 读取signal的信息. 这个signal导致了tracee的stop PTRACE_PEEKSIGINFO PTRACE_SETSIGINFO: 修改signal信息给tracee看 PTRACE_GETSIGMASK PTRACE_SETSIGMASK PTRACE_SETOPTIONS: 使用data来区分接下来的具体option, 用于控制ptrace行为 PTRACE_CONT: 继续tracee PTRACE_SYSCALL, PTRACE_SINGLESTEP: 也是继续tracee, 但让它在下一个syscall的时候停下来, 或者是在下一个指令时停下来. PTRACE_SYSEMU, PTRACE_SYSEMU_SINGLESTEP: 和上面差不多 PTRACE_LISTEN: 也是让tracee继续, 但是不执行(不会被调度到)... PTRACE_KILL: kill tracee PTRACE_INTERRUPT: 让tracee停下来 PTRACE_ATTACH: attach tracee. 需要相应权限 PTRACE_SEIZE: 和attach类似, 但不会导致tracee停止 PTRACE_DETACH: dettach tracee有stop和running状态, 虽然在blocking的系统调用的时候tracee被阻塞了, 但实际还在内核态运行, 是running的状态. stop状态统称ptrace-stop, 当tracee进入ptrace-stop状态时, 会通过waitpid()通知tracer. 所以tracer要在循环里等待 pid = waitpid(pid_or_minus_1, &status, __WALL); ptrace-stop有几种可能: Signal-delivery-stop: 当一个进程收到signal时, 除了sigkill, kernel会选择这个进程的某个线程来handle signal(但如果这个signal是tgkill产生的, 那目标线程可以被caller指定). 如果这个被选中的线程是tracee, 就会进入signal-delivery-stop. 这个时候, signal还没有到达tracee, 而是先被tracer知道: 如果tracer不区supress这个signal, tracer的下一次ptrace restart命令会inject这个signal到tracee. Group-stop: stop signal会导致整个进程的全部线程stop. 那tracee会进入group-stop. 注意这个stop signal也是经过了Signal-delivery-stop然后由tracer inject到tracee的, 进而导致了整个进程stop. PTRACE_EVENT stops: ptrace事件导致的stop, 比如PTRACE_EVENT_FORK, PTRACE_EVENT_CLONE Syscall-stops: 这个场景是因为之前ptrace设置了PTRACE_SYSCALL or PTRACE_SYSEMU命令, 会导致tracee在调用syscall之前stop, 这个就是Syscall-stop PTRACE_EVENT_SECCOMP stops: 和seccomp有关 PTRACE_SINGLESTEP stops: 单步 注意, 因为ptrace大量用了waitpid(), 而真正的tracee的父进程一般也调用wait()来等待子进程退出, 那tracer会先收到waitpid的通知, 然后再通知tracee的父进程. kvm 目录在gvisor/pkg/sentry/platform/kvm golang的汇编基础 官方文档: https://go.dev/doc/asm FP: Frame pointer: arguments and locals. PC: Program counter: jumps and branches. SB: Static base pointer: global symbols. SP: Stack pointer: the highest address within the local stack frame. 某些CPU指令集, 比如arm64, 数据是从右到左: MRS Move System register to general-purpose register MSR Move general-purpose register to System register MRS R0,CPSR ; delivery CPSR Content to R0 MSR CPSR,R0 ; delivery R0 Content to CPSR 比如在kernel代码里: mrs x0, tpidrro_el0 // 特殊寄存器tpidrro_el0赋值给x0 msr sctlr_el1, x0 // x0赋值给特殊寄存器sctlr_el1 但注意, go里面MOV的方向是从左向右: MOVL g(CX), AX // Move g into AX. MOVL g_m(AX), BX // Move g.m into BX. 所以, ARM64的MRS/MSR在golang里是反的: 它们依然遵循从左到右的原则: MSR R1, MDSCR_EL1 // access to the DCC from EL0 MRS TTBR1_EL1, R1 再强调一次: 在go的汇编里, MSR和MRS的使用和ARM官方文档的方向相反 arm64 exception level 详见: https://developer.arm.com/documentation/102412/0102/Privilege-and-Exception-levels 寄存器都是带EL后缀的. 低EL不能访问高EL的寄存器; 强行访问会异常, 类别应该是指令异常 高EL可以访问低EL的寄存器, 但除了虚拟化场景, 其它场景并不常用? arm64内存基础 基础概念: AARCH64支持虚拟内存的tag, 虚拟内存的最高8位是tag, 在地址翻译的时候会被忽略. PC, LR, SP, ELR里面都是VA AArch64有48位VA, 空间有256TB, 有两个range空间 0xFFFF_0000_0000_0000 到 0xFFFF_FFFF_FFFF_FFFF 基址寄存器是TTBR1, 内核态 或 0x0000_0000_0000_0000 到 0x0000_FFFF_FFFF_FFFF 基址寄存器是TTBR0, 用户态 IPA也是48位 PA也是48位, 并且secure和non-secure的物理地址空间是独立的 TTBR是地址转换表的基址寄存器, 这个表由硬件自动查, 并被缓存到TLB中; TTBR里面保存的是物理地址, 是给硬件MMU waker看的. 这个表最多有四级, 地址最多48位, 最大64KB一个映射 一个VA怎么找到PA? VM的地址空间 用KVM启动的VM, 从VM看来, 它的物理地址空间就是其所在的host的qemu进程(或gvisor进程)的进程空间.第一步先用VM里的VA通过TTBR寄存器指向的page table, 查到IPA. 这个IPA其实就是启动VM的进程中某个地址.第二步拿着IPA通过VTTBR寄存器指向的page table来查PA. 这个VTTBR是在EL2里的hypervisor配置的. 再说一遍, VM看到的物理地址, 就是VM所在的进程地址. KVM基础 用户态是通过open(\"/dev/kvm\")然后做ioctl来和内核的kvm模块交互的. KVM支持的IOCTL是: // KVM ioctls. // // Only the ioctls we need in Go appear here; some additional ioctls are used // within the assembly stubs (KVM_INTERRUPT, etc.). // 这里面包括创建VM, 创建VCPU, 设置寄存器, 读取寄存器等等 const ( _KVM_CREATE_VM = 0xae01 _KVM_GET_VCPU_MMAP_SIZE = 0xae04 _KVM_CREATE_VCPU = 0xae41 _KVM_SET_TSS_ADDR = 0xae47 _KVM_RUN = 0xae80 _KVM_NMI = 0xae9a _KVM_CHECK_EXTENSION = 0xae03 _KVM_GET_TSC_KHZ = 0xaea3 _KVM_SET_TSC_KHZ = 0xaea2 _KVM_INTERRUPT = 0x4004ae86 _KVM_SET_MSRS = 0x4008ae89 _KVM_SET_USER_MEMORY_REGION = 0x4020ae46 _KVM_SET_REGS = 0x4090ae82 _KVM_SET_SREGS = 0x4138ae84 _KVM_GET_MSRS = 0xc008ae88 _KVM_GET_REGS = 0x8090ae81 _KVM_GET_SREGS = 0x8138ae83 _KVM_GET_SUPPORTED_CPUID = 0xc008ae05 _KVM_SET_CPUID2 = 0x4008ae90 _KVM_SET_SIGNAL_MASK = 0x4004ae8b _KVM_GET_VCPU_EVENTS = 0x8040ae9f _KVM_SET_VCPU_EVENTS = 0x4040aea0 ) // KVM exit reasons. const ( _KVM_EXIT_EXCEPTION = 0x1 _KVM_EXIT_IO = 0x2 _KVM_EXIT_HYPERCALL = 0x3 _KVM_EXIT_DEBUG = 0x4 _KVM_EXIT_HLT = 0x5 _KVM_EXIT_MMIO = 0x6 _KVM_EXIT_IRQ_WINDOW_OPEN = 0x7 _KVM_EXIT_SHUTDOWN = 0x8 _KVM_EXIT_FAIL_ENTRY = 0x9 _KVM_EXIT_INTERNAL_ERROR = 0x11 _KVM_EXIT_SYSTEM_EVENT = 0x18 _KVM_EXIT_ARM_NISV = 0x1c ) // KVM capability options. const ( _KVM_CAP_MAX_MEMSLOTS = 0x0a _KVM_CAP_MAX_VCPUS = 0x42 _KVM_CAP_ARM_VM_IPA_SIZE = 0xa5 _KVM_CAP_VCPU_EVENTS = 0x29 _KVM_CAP_ARM_INJECT_SERROR_ESR = 0x9e _KVM_CAP_TSC_CONTROL = 0x3c ) // KVM limits. const ( _KVM_NR_MEMSLOTS = 0x100 _KVM_NR_VCPUS = 0xff _KVM_NR_INTERRUPTS = 0x100 _KVM_NR_CPUID_ENTRIES = 0x100 ) // KVM kvm_memory_region::flags. const ( _KVM_MEM_LOG_DIRTY_PAGES = uint32(1) gvisor对CPU和ring0.kernel的抽象 注意kernel这个词在gvisor里有两个不同的意思: kernel.kernel: 是sentry的用户态kernel ring0.kernel: 专门管虚拟化的 pkg/ring0/defs.go 一个kernel可以被多个CPU共享 // Kernel is a global kernel object. // // This contains global state, shared by multiple CPUs. type Kernel struct { // PageTables are the kernel pagetables; this must be provided. PageTables *pagetables.PageTables KernelArchState } CPU // CPU is the per-CPU struct. type CPU struct { // self is a self reference. // // This is always guaranteed to be at offset zero. self *CPU // 持有对自己的引用, 第一次见这么用的... // kernel is reference to the kernel that this CPU was initialized // with. This reference is kept for garbage collection purposes: CPU // registers may refer to objects within the Kernel object that cannot // be safely freed. kernel *Kernel // CPUArchState is architecture-specific state. CPUArchState // registers is a set of registers; these may be used on kernel system // calls and exceptions via the Registers function. registers arch.Registers // floatingPointState holds floating point state. floatingPointState fpu.State // hooks are kernel hooks. hooks Hooks } 对arm64来说: // KernelArchState contains architecture-specific state. type KernelArchState struct { } // CPUArchState contains CPU-specific arch state. type CPUArchState struct { // stack is the stack used for interrupts on this CPU. stack [128]byte //中断栈只有128字节 // errorCode is the error code from the last exception. errorCode uintptr // errorType indicates the type of error code here, it is always set // along with the errorCode value above. // // It will either by 1, which indicates a user error, or 0 indicating a // kernel error. If the error code below returns false (kernel error), // then it cannot provide relevant information about the last // exception. errorType uintptr // faultAddr is the value of far_el1. faultAddr uintptr // el0Fp is the address of application's fpstate. el0Fp uintptr // ttbr0Kvm is the value of ttbr0_el1 for sentry. ttbr0Kvm uintptr // ttbr0App is the value of ttbr0_el1 for applicaton. ttbr0App uintptr // exception vector. vecCode Vector // application context pointer. appAddr uintptr // lazyVFP is the value of cpacr_el1. lazyVFP uintptr // appASID is the asid value of guest application. appASID uintptr } machine和vCPU的定义 machine就是一个kvm new出来的一个VM, 包括一个kernel和多个vCPU // machine contains state associated with the VM as a whole. type machine struct { // fd is the vm fd. fd int // machinePoolIndex is the index in the machinePool array. machinePoolIndex uint32 // nextSlot is the next slot for setMemoryRegion. // // This must be accessed atomically. If nextSlot is ^uint32(0), then // slots are currently being updated, and the caller should retry. nextSlot uint32 // upperSharedPageTables tracks the read-only shared upper of all the pagetables. upperSharedPageTables *pagetables.PageTables // kernel is the set of global structures. kernel ring0.Kernel // mu protects vCPUs. mu sync.RWMutex // available is notified when vCPUs are available. available sync.Cond // vCPUsByTID are the machine vCPUs. // // These are populated dynamically. vCPUsByTID map[uint64]*vCPU // vCPUsByID are the machine vCPUs, can be indexed by the vCPU's ID. vCPUsByID []*vCPU // maxVCPUs is the maximum number of vCPUs supported by the machine. maxVCPUs int // maxSlots is the maximum number of memory slots supported by the machine. maxSlots int // tscControl checks whether cpu supports TSC scaling tscControl bool // usedSlots is the set of used physical addresses (not sorted). usedSlots []uintptr // nextID is the next vCPU ID. nextID uint32 // machineArchState is the architecture-specific state. machineArchState } 注意这里的vCPU其实是和KVM的KVM_CREATE_VCPU对应的 // vCPU is a single KVM vCPU. type vCPU struct { // CPU is the kernel CPU data. // // This must be the first element of this structure, it is referenced // by the bluepill code (see bluepill_amd64.s). ring0.CPU // vCPU包含了CPU的抽象 // id is the vCPU id. id int // fd is the vCPU fd. fd int // tid is the last set tid. tid uint64 // userExits is the count of user exits. userExits uint64 // guestExits is the count of guest to host world switches. guestExits uint64 // faults is a count of world faults (informational only). faults uint32 // state is the vCPU state. // // This is a bitmask of the three fields (vCPU*) described above. state uint32 // runData for this vCPU. runData *runData // machine associated with this vCPU. machine *machine // active is the current addressSpace: this is set and read atomically, // it is used to elide unnecessary interrupts due to invalidations. active atomicAddressSpace // vCPUArchState is the architecture-specific state. vCPUArchState // dieState holds state related to vCPU death. dieState dieState } pagetable之虚拟地址region到物理地址region的map表 pkg/sentry/platform/kvm/physical_map.go对虚拟地址和物理地址的定义: type region struct { virtual uintptr length uintptr } type physicalRegion struct { region physical uintptr } // 用全局变量表示所有的region // region从虚拟地址0开始, 到ring0.MaximumUserAddress // 物理地址从physical := uintptr(reservedMemory)开始. // 这个reservedMemory在arm64上是0, 在amd64上是0x100000000 //比如在x86机器上 // physicalRegion: virtual [1000,3f5b92bd1000) => physical [100001000,3f5c92bd1000) // physicalRegion: virtual [7f5d12bd1000,7ffffffff000) => physical [3f5c92bd1000,3fff7ffff000) // 这里的physical地址从100001000(4G+1000)开始, 因为在x86上reservedMemory = 0x100000000 //在arm64上(a53) // region: virtual [fef5ca6000,ffff75ca6000) // physicalRegion: virtual [1000,10000) => physical [1000,10000) // physicalRegion: virtual [10000,abf000) => physical [10000,abf000) // physicalRegion: virtual [abf000,ac0000) => physical [abf000,ac0000) // physicalRegion: virtual [ac0000,181f000) => physical [ac0000,181f000) // physicalRegion: virtual [181f000,fef5ca6000) => physical [181f000,fef5ca6000) // physicalRegion: virtual [ffff75ca6000,ffff9cb58000) => physical [fef5ca6000,ff1cb58000) // physicalRegion: virtual [ffff9cb58000,ffff9cb59000) => physical [ff1cb58000,ff1cb59000) // physicalRegion: virtual [ffff9cb59000,ffff9cb5a000) => physical [ff1cb59000,ff1cb5a000) // physical_map.go:177] physicalRegion: virtual [ffff9cb5a000,fffffffff000) => physical [ff1cb5a000,ff7ffff000) var physicalRegions []physicalRegion pkg/sentry/platform/kvm/virtual_map.go type virtualRegion struct { region accessType hostarch.AccessType shared bool offset uintptr filename string } 初始的physicalRegions基本上是个virtual 和physical 1:1的映射根据host地址空间和target的VM物理地址空间计算而来, applyPhysicalRegions()函数会遍历physicalRegions以此来更改pagetable, 比如pkg/sentry/platform/kvm/machine_arm64.go中: func (m *machine) mapUpperHalf(pageTable *pagetables.PageTables) { applyPhysicalRegions(func(pr physicalRegion) bool { //增加一个pageTable映射 pageTable.Map( //这里对UpperHalf来说, 加上了ffff000000000000, 即虚拟地址=物理地址+ffff000000000000 hostarch.Addr(ring0.KernelStartAddress|pr.virtual), pr.length, pagetables.MapOpts{AccessType: hostarch.AnyAccess, Global: true}, pr.physical) return true // Keep iterating. }) } 后面会看到 vCPU初始化的时候, 会配置用户态的TTBR0和内核态的TTBR1 注意ttbr配置的是物理地址. 对VM来说, 其物理地址就是所在qemu进程(或gvisor进程)的ptes变量的虚拟地址. // ttbr0_el1 data = c.machine.kernel.PageTables.TTBR0_EL1(false, 0) reg.id = _KVM_ARM64_REGS_TTBR0_EL1 if err := c.setOneRegister(&reg); err != nil { return err } c.SetTtbr0Kvm(uintptr(data)) // ttbr1_el1 data = c.machine.kernel.PageTables.TTBR1_EL1(false, 0) reg.id = _KVM_ARM64_REGS_TTBR1_EL1 if err := c.setOneRegister(&reg); err != nil { return err } TTBR0和TTBR1分别是 PageTables下面的两个地址: rootPhysical和archPageTables.rootPhysical // TTBR0_EL1 returns the translation table base register 0. // //go:nosplit func (p *PageTables) TTBR0_EL1(noFlush bool, asid uint16) uint64 { return uint64(p.rootPhysical) | (uint64(asid)&ttbrASIDMask) TTBR0的地址是在pkg/ring0/pagetables/pagetables.go的PageTables的Init里面赋值的: // Init initializes a set of PageTables. // // +checkescape:hard,stack //go:nosplit func (p *PageTables) Init(allocator Allocator) { p.Allocator = allocator p.root = p.Allocator.NewPTEs() p.rootPhysical = p.Allocator.PhysicalFor(p.root) } 而TTBR1的地址在pkg/ring0/pagetables/pagetables_arm64.go // InitArch does some additional initialization related to the architecture. // // +checkescape:hard,stack //go:nosplit func (p *PageTables) InitArch(allocator Allocator) { if p.upperSharedPageTables != nil { p.cloneUpperShared() } else { p.archPageTables.root = p.Allocator.NewPTEs() p.archPageTables.rootPhysical = p.Allocator.PhysicalFor(p.archPageTables.root) } } 有两种Allocator, pkg/ring0/pagetables/allocator.go 这是base的allocator, 具体实现在pkg/ring0/pagetables/allocator_unsafe.go, 就是普通的new一个PTE table的结构体, 它的PhysicalFor函数实际上获取的是这个PTE的虚拟地址, uintptr(unsafe.Pointer(ptes)); 这个allocator是给kernel用的, 因为kernel运行在vm外面; 从外面看, vm的物理地址就是外面的虚拟地址. pkg/sentry/platform/kvm/bluepill_allocator.go KVM的bluepill的实现是用base的allocator申请PTE表, 再用bluepill进入guest模式一次, 然后退出guest.func (a *allocator) NewPTEs() *pagetables.PTEs { ptes := a.base.NewPTEs() // escapes: bluepill below. if a.cpu != nil { bluepill(a.cpu) } return ptes } // PhysicalFor returns the physical address for a set of PTEs. // translateToPhysical()这个函数就是从全局表physicalRegions里面匹配虚拟地址找到物理地址. // 纯软件查表, 没有硬件参与. func (a *allocator) PhysicalFor(ptes *pagetables.PTEs) uintptr { virtual := a.base.PhysicalFor(ptes) physical, _, ok := translateToPhysical(virtual) if !ok { panic(fmt.Sprintf(\"PhysicalFor failed for %p\", ptes)) // escapes: panic. } return physical } 这个是给里面用的. KVM_SET_USER_MEMORY_REGION kvm大概支持512个slot, gvisor定义了faultBlockSize为2G. setMemoryRegion()函数调用了kvm的KVM_SET_USER_MEMORY_REGION API: // setMemoryRegion initializes a region. // // This may be called from bluepillHandler, and therefore returns an errno // directly (instead of wrapping in an error) to avoid allocations. // //go:nosplit func (m *machine) setMemoryRegion(slot int, physical, length, virtual uintptr, flags uint32) unix.Errno { userRegion := userMemoryRegion{ slot: uint32(slot), flags: uint32(flags), guestPhysAddr: uint64(physical), memorySize: uint64(length), userspaceAddr: uint64(virtual), } // Set the region. _, _, errno := unix.RawSyscall( unix.SYS_IOCTL, uintptr(m.fd), _KVM_SET_USER_MEMORY_REGION, uintptr(unsafe.Pointer(&userRegion))) return errno } 注意这个API实际上是告诉KVM, 发生在EL2的第二阶段的地址该如何翻译: 初始化VM: ioctl KVM_SET_USER_MEMORY_REGION : 决定了VM_PA --> host_VA 第一阶段: VM_VA --> VM_PA 第二阶段: VM_PA --> host_VA --> host_PA mapPhysical()调用了setMemoryRegion()函数从全局表physicalRegions, 按照入参物理地址和长度, 调用kvm的ioctl来映射USER_MEMORY_REGION // mapPhysical的入参phyRegions都是传入全局变量physicalRegions //比如在x86机器上 // physicalRegion: virtual [1000,3f5b92bd1000) => physical [100001000,3f5c92bd1000) // physicalRegion: virtual [7f5d12bd1000,7ffffffff000) => physical [3f5c92bd1000,3fff7ffff000) // 这里的physical地址从100001000(4G+1000)开始, 因为在x86上reservedMemory = 0x100000000 (m *machine) mapPhysical(physical, length uintptr, phyRegions []physicalRegion, flags uint32) //传入physical, 从phyRegions里查表, 并考虑对齐, 返回virtualStart, physicalStart, length _, physicalStart, length, ok := calculateBluepillFault(physical, phyRegions) //如果没map if !m.hasSlot(physicalStart) handleBluepillFault(m, physical, phyRegions, flags) //又来一次 virtualStart, physicalStart, length, pr := calculateBluepillFault(physical, phyRegions) //因为kvm是以slot来管理内存的, 这里用atomic和for循环来自己做互斥 slot := atomic.SwapUint32(&m.nextSlot, ^uint32(0)) for slot == ^uint32(0) { //在这里等待atomic换出的value不是ffffffff yield() // Race with another call. slot = atomic.SwapUint32(&m.nextSlot, ^uint32(0)) } m.setMemoryRegion(int(slot), physicalStart, length, virtualStart, flags) //用KVM的_KVM_SET_USER_MEMORY_REGION ioctl把 unix.RawSyscall(unix.SYS_IOCTL, ..._KVM_SET_USER_MEMORY_REGION...) mapPhysical()的调用路径之用户态page falut处理路径 //pkg/sentry/mm (mm *MemoryManager) handleASIOFault() mm.mapASLocked() (mm *MemoryManager) HandleUserFault() mm.mapASLocked() (mm *MemoryManager) populateVMA() mm.mapASLocked() (mm *MemoryManager) populateVMAAndUnlock() mm.mapASLocked() (mm *MemoryManager) MLock() mm.mapASLocked() (mm *MemoryManager) MLockAll() mm.mapASLocked() //pkg/sentry/mm/address_space.go (mm *MemoryManager) mapASLocked() //pkg/sentry/platform/kvm/address_space.go mm.as.MapFile() as.mapLocked() //pkg/sentry/platform/kvm/machine.go as.machine.mapPhysical() //pkg/sentry/platform/kvm/bluepill_fault.go handleBluepillFault() //pkg/sentry/platform/kvm/machine_unsafe.go m.setMemoryRegion() unix.RawSyscall(unix.SYS_IOCTL, _KVM_SET_USER_MEMORY_REGION) mapPhysical的调用路径之seccompMmapHandler 在new一个VM的时候, host进程的mmap会被seccomp拦截, 转由seccompMmapHandler()来处理准确的说, 在newMachine()里面, seccompMmapRules()用sigsysHandler来处理sigsys // seccompMmapRules adds seccomp rules to trap mmap system calls that will be // handled in seccompMmapHandler. func seccompMmapRules(m *machine) { // 只在host进程执行一次 seccompMmapRulesOnce.Do(func() { // 调用unix.RawSyscall6(unix.SYS_RT_SIGACTION, ...)替换handler sighandling.ReplaceSignalHandler(unix.SIGSYS, addrOfSigsysHandler(), &savedSigsysHandler) rules := []seccomp.RuleSet{} rules = append(rules, []seccomp.RuleSet{ // Trap mmap system calls and handle them in sigsysGoHandler { Rules: seccomp.SyscallRules{ unix.SYS_MMAP: { { seccomp.MatchAny{}, seccomp.MatchAny{}, seccomp.MaskedEqual(unix.PROT_EXEC, 0), /* MAP_DENYWRITE is ignored and used only for filtering. */ seccomp.MaskedEqual(unix.MAP_DENYWRITE, 0), }, }, }, Action: linux.SECCOMP_RET_TRAP, }, }...) instrs, err := seccomp.BuildProgram(rules, linux.SECCOMP_RET_ALLOW, linux.SECCOMP_RET_ALLOW) }) ... 根据sigaction的配置, sigsys被触发的时候, sigsysHandler(int sig, siginfo_t *info, void *ucontext)会被调用 // The arguments are the following: // // R0 - The signal number. // R1 - Pointer to siginfo_t structure. // R2 - Pointer to ucontext structure. // TEXT ·sigsysHandler(SB),NOSPLIT,$0 // si_code should be SYS_SECCOMP. MOVD SIGINFO_CODE(R1), R7 CMPW $1, R7 BNE fallback CMPW $SYS_MMAP, R8 BNE fallback MOVD R2, 8(RSP) BL ·seccompMmapHandler(SB) // Call the handler. RET fallback: // Jump to the previous signal handler. MOVD ·savedHandler(SB), R7 B (R7) // 取上面函数的地址 // func addrOfSighandler() uintptr TEXT ·addrOfSigsysHandler(SB), $0-8 MOVD $·sigsysHandler(SB), R0 MOVD R0, ret+0(FP) RET 需要注意的是, 在初始化的时候, host进程的地址空间有很多已经mmap成了不可访问, 那么后面的mmap得到的虚拟地址, 应该是落在和目标VM物理地址范围(40bit)的连续地址空间. 在这个signal处理函数里面, 调用了seccompMmapHandler // seccompMmapHandler is a signal handler for runtime mmap system calls // that are trapped by seccomp. // // It executes the mmap syscall with specified arguments and maps a new region // to the guest. // //go:nosplit func seccompMmapHandler(context unsafe.Pointer) { //从ucontext上下文恢复当时mmap的入参, 并重新调用mmap addr, length, errno := seccompMmapSyscall(context) //类似这样: unix.RawSyscall6(uintptr(ctx.Regs[8]), uintptr(ctx.Regs[0]), ...) for 在machinePool里所有host进程管理的VM physical, length, ok := translateToPhysical(virtual) //用KVM的SET_USER_MEMORY_REGION ioctl来配置kvm的第二次翻译 m.mapPhysical(physical, length, physicalRegions) } 注: man sigaction sigaction系统调用接受两种形式的handler struct sigaction { void (*sa_handler)(int); void (*sa_sigaction)(int, siginfo_t *, void *); sigset_t sa_mask; int sa_flags; void (*sa_restorer)(void); }; 这里我们用的是void (*sa_sigaction)(int, siginfo_t *, void *) If SA_SIGINFO is specified in sa_flags, then sa_sigaction (instead of sa_handler) specifies the signal-handling function for signum. This function receives three arguments, as described below. void handler(int sig, siginfo_t *info, void *ucontext) { ... } These three arguments are as follows sig The number of the signal that caused invocation of the handler. info A pointer to a siginfo_t, which is a structure containing further information about the signal, as described below. ucontext This is a pointer to a ucontext_t structure, cast to void *. The structure pointed to by this field contains signal context information that was saved on the user-space stack by the kernel; for details, see sigreturn(2). Further information about the ucontext_t structure can be found in getcontext(3). Commonly, the handler function doesn't make any use of the third argument. The siginfo_t data type is a structure with the following fields: siginfo_t { int si_signo; /* Signal number */ int si_errno; /* An errno value */ int si_code; /* Signal code */ int si_trapno; /* Trap number that caused hardware-generated signal (unused on most architectures) */ pid_t si_pid; /* Sending process ID */ uid_t si_uid; /* Real user ID of sending process */ int si_status; /* Exit value or signal */ clock_t si_utime; /* User time consumed */ clock_t si_stime; /* System time consumed */ sigval_t si_value; /* Signal value */ int si_int; /* POSIX.1b signal */ void *si_ptr; /* POSIX.1b signal */ int si_overrun; /* Timer overrun count; POSIX.1b timers */ int si_timerid; /* Timer ID; POSIX.1b timers */ void *si_addr; /* Memory location which caused fault */ long si_band; /* Band event (was int in glibc 2.3.2 and earlier) */ int si_fd; /* File descriptor */ short si_addr_lsb; /* Least significant bit of address (since Linux 2.6.32) */ void *si_lower; /* Lower bound when address violation occurred (since Linux 3.19) */ void *si_upper; /* Upper bound when address violation occurred (since Linux 3.19) */ int si_pkey; /* Protection key on PTE that caused fault (since Linux 4.6) */ void *si_call_addr; /* Address of system call instruction (since Linux 3.5) */ int si_syscall; /* Number of attempted system call (since Linux 3.5) */ unsigned int si_arch; /* Architecture of attempted system call (since Linux 3.5) */ } 注2: man sigretrun这也是个系统调用, 但不能被用户直接调用, 而是被libc调用做为signal trampoline(蹦床).kernel在返回用户态的时候, 看到有signal pending, 就把当前上下文ucontext保存在该进程的用户空间, 然后调用用户态的sighandler, 当这个handler返回的时候, 返回到libc的signal trampoline代码, sigreturn在这个trampoline代码里被调用, 这是个系统调用, 内核会把之前的为调用sighandler的准备工作undo, 从ucontext里面恢复上下文, 恢复原来进程的执行. If the Linux kernel determines that an unblocked signal is pending for a process, then, at the next transition back to user mode in that process (e.g., upon return from a sys‐tem call or when the process is rescheduled onto the CPU), it creates a new frame on the user-space stack where it saves various pieces of process context (processor status word, registers, signal mask, and signal stack settings). The kernel also arranges that, during the transition back to user mode, the signal handler is called, and that, upon return from the handler, control passes to a piece of user-space code commonly called the \"signal trampoline\". The signal trampoline code in turn calls sigreturn(). This sigreturn() call undoes everything that was done—changing the process's signal mask, switching signal stacks (see sigaltstack(2))—in order to invoke the signal handler. Using the information that was earlier saved on the user-space stack sigreturn() restores the process's signal mask, switches stacks, and restores the process's context (processor flags and registers, including the stack pointer and instruction pointer), so that the process resumes execution at the point where it was interrupted by the signal. mapPhysical的调用路径之newMachine 见下面 KVM新建一个VM New一个kvm实例就是 func New() { deviceFile, err := os.OpenFile(\"/dev/kvm\", unix.O_RDWR, 0) fd := deviceFile.Fd() // 注意这里, 不管New多少个VM, updateGlobalOnce只被调用一次 // // Ensure global initialization is done. globalOnce.Do(func() { globalErr = updateGlobalOnce(int(fd)) physicalInit() //这个函数在host的地址空间内, 调用多次mmap, 使其地址空间充满unix.PROT_NONE属性(即不可访问)的mmap映射, 最后只保留一个小于40bit的host地址空间 //正如其名称所示, 用不可访问的地址映射填充host的大部分地址空间, 只保留一个小于40bit(ARM64)的地址空间. //这么做的目的是让host地址空间可以injective fillAddressSpace() // 这个函数返回已经map了的地址区域, 这些区域是excludedRegions //将上面excludedRegions逐个addValidRegion到全局表physicalRegions, 物理地址从reservedMemory(arm64上是0)开始递增 //将剩下的host地址空间(即上面保留的40bit大小的空间)addValidRegion到全局表physicalRegions //故全局表physicalRegion不是1:1的物理到虚拟地址的映射 //而是物理地址从0开始的, 多个到host地址空间的映射; 前面的多组映射实际上是不能访问的, 只有最后一个映射才是VM的物理地址空间到host的地址空间的一个 //比如在x86机器上 // physicalRegion: virtual [1000,3f5b92bd1000) => physical [100001000,3f5c92bd1000) // physicalRegion: virtual [7f5d12bd1000,7ffffffff000) => physical [3f5c92bd1000,3fff7ffff000) // 这里的physical地址从100001000(4G+1000)开始, 因为在x86上reservedMemory = 0x100000000 computePhysicalRegions() updateSystemValues(int(fd)) ring0.Init() }) for { //直接的syscall调用要自己用个for来处理unix.EINTR, man 7 signal说的很清楚, 像read/write/ioctl等系统调用作用在slow的device上, 如果在还没有transfer数据前被signal打断, 根据SA_RESTART的情况, 可以返回EINTR vm, _, errno = unix.Syscall(unix.SYS_IOCTL, fd, _KVM_CREATE_VM, 0) if errno == unix.EINTR { continue } if errno != 0 { return nil, fmt.Errorf(\"creating VM: %v\", errno) } break } // Create a VM context. machine, err := newMachine(int(vm)) // All set. return &KVM{ machine: machine, }, nil } // NewContext returns an interruptible context. func (k *KVM) NewContext() platform.Context { return &context{ machine: k.machine, } } newMachine // newMachine returns a new VM context. func newMachine(vm int) (*machine, error) { // Create the machine. m := &machine{fd: vm} // Pull the maximum vCPUs. // CPU虚拟化: 最大的vCPU个数 m.getMaxVCPU() // Pull the maximum slots. // 内存虚拟化: 最大的内存slot数, 大概512个 unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CHECK_EXTENSION, _KVM_CAP_MAX_MEMSLOTS) // Check TSC Scaling unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CHECK_EXTENSION, _KVM_CAP_TSC_CONTROL) // Create the upper shared pagetables and kernel(sentry) pagetables. m.upperSharedPageTables = pagetables.New(newAllocator()) // 应该是对应ffff000000000000空间(kernel) // map 虚拟地址=物理地址+ffff000000000000 m.mapUpperHalf(m.upperSharedPageTables) m.upperSharedPageTables.MarkReadOnlyShared() //新建一个pagetable, 并把upper pagetable设为上面的m.upperSharedPageTables m.kernel.PageTables = pagetables.NewWithUpper(newAllocator(), m.upperSharedPageTables, ring0.KernelStartAddress) // KernelStartAddress是ffff000000000000 // Install seccomp rules to trap runtime mmap system calls. They will // be handled by seccompMmapHandler. // 配置seccomp为trap mmap, 其他allow; mmap会触发SIGSYS信号 // 当newMachine的进程(非guest)调用mmap时, seccompMmapHandler()会被调用(位于pkg/sentry/platform/kvm/machine_unsafe.go) // 当host进程(包括VM的进程)mmap的时候, mmap会触发SIGSYS信号, handler里面 // 为每个VM, 都使用m.mapPhysical(physical, length, physicalRegions, _KVM_MEM_FLAGS_NONE) seccompMmapRules(m) // Apply the physical mappings. Note that these mappings may point to // guest physical addresses that are not actually available. These // physical pages are mapped on demand, see kernel_unsafe.go. applyPhysicalRegions(func(pr physicalRegion) bool { // Map everything in the lower half. m.kernel.PageTables.Map( hostarch.Addr(pr.virtual), pr.length, pagetables.MapOpts{AccessType: hostarch.ReadWrite}, pr.physical) return true // Keep iterating. }) // 把当前host进程已经map的虚拟地址空间映射进VM // 这个函数的作用是把host进程的已经建立的虚拟地址region映射进VM, 让VM看到和host进程相同的虚拟地址, 并对应到相同的物理地址, 即VM能够执行host进程的代码. 比如在VM执行host中的funcx, VM中直接使用funcx在host中的虚拟地址, VM中自己维护的页表把这个VA转到PA, 这个PA是VM的\"物理地址\", 因为这个PA和host的VA已经在KVM中建立了映射(ioctl KVM_SET_USER_MEMORY_REGION), 经过KVM的第二次地址翻译, 这个host的VA就被翻译成真正的PA. // 其实就是相当于经过VM的两个阶段的MMU翻译, 结果就是VM能直接访问host空间的代码. applyVirtualRegions() f, err := os.Open(\"/proc/self/maps\") //用regex解析每行得到虚拟地址start和length //对每个virtual region for 每个entry //1. 从host虚拟地址查到VM的物理地址 physical, length, ok := translateToPhysical(virtual) //2. 如果属性有execute, 即host进程的代码, install到VM的kernel pagetable里 //只有代码被加到VM的页表 m.kernel.PageTables.Map( hostarch.Addr(virtual), length, pagetables.MapOpts{AccessType: vr.accessType}, physical) //3. 每个entry都会调用kvm的ioctl KVM_SET_USER_MEMORY_REGION, 让VM可以访问host进程的地址空间区域 // Ensure the physical range is mapped. m.mapPhysical(physical, length, physicalRegions) // 做个_KVM_ARM_PREFERRED_TARGET的KVM ioctl m.initArchState() //在里面newVCPU(), 最多maxvcpu个 for int(m.nextID) arm64异常向量 https://developer.arm.com/documentation/100933/0100/AArch64-exception-vector-table 每个exception level都有独立的异常向量表 向量表的虚拟地址配在VBAR寄存器里 The virtual address of each table base is set by the Vector Based Address Registers: VBAR_EL3, VBAR_EL2 and VBAR_EL1. 每个vector table有16个entry, 每个entry固定128个字节(可以有32个指令). 硬件会根据情况找到对应的entry. The type of exception (SError, FIQ, IRQ, or Synchronous) If the exception is being taken at the same Exception level, the stack pointer to be used (SP0 or SPn) If the exception is being taken at a lower Exception level, the Execution state of the next lower level (AArch64 or AArch32). 解释一下, arm64的sp寄存器每个EL都有, 但不一定都用: SPSel选择寄存器的0位, 来决定用哪个SP SP Meaning 0b0 Use SP_EL0 at all Exception levels. 0b1 Use SP_ELx for Exception level ELx. 默认是1, 就是说默认每个EL都用自己的SP寄存器. 举例来说: If kernel code is executing at EL1 and an IRQ interrupt is signaled, an IRQ exception occurs. This particular interrupt is not associated with the hypervisor or secure environment and is also handled within the kernel, and the SPSel bit is set, so SP_EL1 is used. Execution takes place, therefore, from address VBAR_EL1 + 0x280. gvisor里面, 这个向量表在pkg/ring0/entry_arm64.s TEXT ·Vectors(SB),NOSPLIT,$0 PCALIGN $2048 // gvisor并不支持SP0, 就是说这里`SPSel`是1 B ·El1_sync_invalid(SB) PCALIGN $128 B ·El1_irq_invalid(SB) PCALIGN $128 B ·El1_fiq_invalid(SB) PCALIGN $128 B ·El1_error_invalid(SB) // 接下来的4个entry是El1触发的 PCALIGN $128 B ·El1_sync(SB) PCALIGN $128 B ·El1_irq(SB) PCALIGN $128 B ·El1_fiq(SB) PCALIGN $128 B ·El1_error(SB) // 这4个entry是64位的EL0触发的 PCALIGN $128 B ·El0_sync(SB) PCALIGN $128 B ·El0_irq(SB) PCALIGN $128 B ·El0_fiq(SB) PCALIGN $128 B ·El0_error(SB) // 这4个entry是32位的EL0触发的. 就是说这里不支持32位用户态模式 PCALIGN $128 B ·El0_sync_invalid(SB) PCALIGN $128 B ·El0_irq_invalid(SB) PCALIGN $128 B ·El0_fiq_invalid(SB) PCALIGN $128 B ·El0_error_invalid(SB) 这个地址ring0.Vectors被配置到_KVM_ARM64_REGS_VBAR_EL1 // vbar_el1 reg.id = _KVM_ARM64_REGS_VBAR_EL1 // ring0.Vectors的虚拟地址 vectorLocation := reflect.ValueOf(ring0.Vectors).Pointer() // 虚拟地址加上KernelStartAddress(ffff000000000000) data = uint64(ring0.KernelStartAddress | vectorLocation) if err := c.setOneRegister(&reg); err != nil { return err } VBAR里配的是虚拟地址, 前面讲过, kernel的虚拟地址upperhalf的虚拟地址=物理地址+ffff000000000000, 而对于VM来说, 这个物理地址就是其所在VM进程的虚拟地址.所以发生异常时, 因为是EL1, 如果TLB没命中, CPU的MMU先找到TTBR1, walk PTE(page table entry), 找到物理地址; 这个物理地址就是ring0.Vectors的虚拟地址; MMU知道现在是2 stage translate模式, 就去找VTTBR(KVM配置的)的page table基地址去找物理地址, 这次找到真正的物理地址. EL0同步异常 异常入口先保存用户上下文的寄存器, 然后比较异常原因寄存器跳转到相应处理 // El0_sync is the handler for El0_sync. TEXT ·El0_sync(SB),NOSPLIT,$0 KERNEL_ENTRY_FROM_EL0 MRS ESR_EL1, R25 // read the syndrome register LSR $ESR_ELx_EC_SHIFT, R25, R24 // exception class CMP $ESR_ELx_EC_SVC64, R24 BEQ el0_svc // SVC in 64-bit state CMP $ESR_ELx_EC_DABT_LOW, R24 BEQ el0_da // data abort in EL0 CMP $ESR_ELx_EC_IABT_LOW, R24 BEQ el0_ia // instruction abort in EL0 CMP $ESR_ELx_EC_FP_ASIMD, R24 BEQ el0_fpsimd_acc // FP/ASIMD access CMP $ESR_ELx_EC_SVE, R24 BEQ el0_sve_acc // SVE access CMP $ESR_ELx_EC_FP_EXC64, R24 BEQ el0_fpsimd_exc // FP/ASIMD exception CMP $ESR_ELx_EC_SP_ALIGN, R24 BEQ el0_sp_pc // stack alignment exception CMP $ESR_ELx_EC_PC_ALIGN, R24 BEQ el0_sp_pc // pc alignment exception CMP $ESR_ELx_EC_UNKNOWN, R24 BEQ el0_undef // unknown exception in EL0 CMP $ESR_ELx_EC_BREAKPT_LOW, R24 BEQ el0_dbg // debug exception in EL0 CMP $ESR_ELx_EC_SYS64, R24 BEQ el0_sys // configurable trap CMP $ESR_ELx_EC_WFx, R24 BEQ el0_wfx // WFX trap B el0_invalid RSP: stack pointer // RSV_REG is a register that holds el1 information temporarily. #define RSV_REG R18_PLATFORM // RSV_REG_APP is a register that holds el0 information temporarily. #define RSV_REG_APP R19 KERNEL_ENTRY_FROM_EL0()保存用户app的上下文 // KERNEL_ENTRY_FROM_EL0 is the entry code of the vcpu from el0 to el1. #define KERNEL_ENTRY_FROM_EL0 \\ SUB $16, RSP, RSP; \\ // step1, save r18, r19 into kernel temporary stack. STP (RSV_REG, RSV_REG_APP), 16*0(RSP); \\ WORD $0xd538d092; \\ // MRS TPIDR_EL1, R18 MOVD CPU_APP_ADDR(RSV_REG), RSV_REG_APP; \\ // step2, load app context pointer. //保存r0到r31等通用寄存器 REGISTERS_SAVE(RSV_REG_APP, 0); \\ // step3, save app context. MOVD RSV_REG_APP, R20; \\ LDP 16*0(RSP), (RSV_REG, RSV_REG_APP); \\ ADD $16, RSP, RSP; \\ STP (RSV_REG, RSV_REG_APP), PTRACE_R18(R20); \\ // 更新r18 r19到上下文 MRS TPIDR_EL0, R3; \\ MOVD R3, PTRACE_TLS(R20); \\ //TPIDR_EL0保存到TLS WORD $0xd5384003; \\ // MRS SPSR_EL1, R3 MOVD R3, PTRACE_PSTATE(R20); \\ //状态寄存器保存到PSTATE MRS ELR_EL1, R3; \\ MOVD R3, PTRACE_PC(R20); \\ //ELR_EL1保存到PC WORD $0xd5384103; \\ // MRS SP_EL0, R3 MOVD R3, PTRACE_SP(R20); //SP_EL0保存到SP EL0同步异常之SVC系统调用异常 // System call vectors. const ( Syscall Vector = El0SyncSVC PageFault Vector = El0SyncDa VirtualizationException Vector = El0ErrBounce ) el0_svc: WORD $0xd538d092 //MRS TPIDR_EL1, R18 MOVD $0, CPU_ERROR_CODE(RSV_REG) // Clear error code. MOVD $1, R3 MOVD R3, CPU_ERROR_TYPE(RSV_REG) // Set error type to user. //Syscall是El0SyncSVC MOVD $Syscall, R3 // 相当于c.vecCode = El0SyncSVC MOVD R3, CPU_VECTOR_CODE(RSV_REG) //如果直接eret, 则会返回EL0, 因为是在EL0触发的异常 //但这里是要返回EL1 B ·kernelExitToEl1(SB) 这里的CPU_VECTOR_CODE是c.vecCode在c(就是CPU那个结构体)的偏移量 RSV_REG是R18_PLATFORM kernelExitToEl1 kernelExitToEl1()可以在EL0_SVC里面调用, 也可以在EL1_SVC里面调用. 恢复寄存器, 最后调用eret从异常返回. 即从EL1的异常态返回到EL1的正常态. // kernelExitToEl1 is the entrypoint for sentry in guest_el1. // Prepare the vcpu environment for sentry. TEXT ·kernelExitToEl1(SB),NOSPLIT,$0 WORD $0xd538d092 //MRS TPIDR_EL1, R18 //是vCPU结构体? MOVD CPU_REGISTERS+PTRACE_PSTATE(RSV_REG), R1 WORD $0xd5184001 //MSR R1, SPSR_EL1 //恢复保存的SPSR_EL1 //设置ELR为之前保存的PC MOVD CPU_REGISTERS+PTRACE_PC(RSV_REG), R1 MSR R1, ELR_EL1 //恢复保存的ELR // restore sentry's tls. MOVD CPU_REGISTERS+PTRACE_TLS(RSV_REG), R1 MSR R1, TPIDR_EL0 //用的是TPIDR_EL0, 说明sEntry也是在VM的用户态 MOVD CPU_REGISTERS+PTRACE_SP(RSV_REG), R1 MOVD R1, RSP //恢复保存的SP REGISTERS_LOAD(RSV_REG, CPU_REGISTERS) SWITCH_TO_KVM_PAGETABLE() //使用c.ttbr0Kvm 页表, 这个好像是和sentry对应的. 也配在ttbr0基址寄存器里; 相应的, 还有个SWITCH_TO_APP_PAGETABLE, 是使用c.ttbr0App页表 MRS TPIDR_EL1, RSV_REG MOVD CPU_REGISTERS+PTRACE_R19(RSV_REG), RSV_REG_APP ERET() kernelExitToEl1返回El1, 并切换到KVM页表(或者说sEntry页表), KVM页表也是用ttbr0来配的, 算用户页表(或者说下半部页表). 这里的关键点是从TPIDR_EL1拿到vCPU的结构体, 这个应该是指VM的\"kernel\"的信息, 从里面恢复SPSR_EL1, 而SPSR_EL1里面是保存的pstate寄存器(是kernel的吗?), eret要\"退回\"的EL级别是从SPSR_EL1里查的.用当时记录的PC(CPU_REGISTERS+PTRACE_PC(RSV_REG))恢复到ELR_EL1, 那么这个ELR带我们到哪里呢? 注: SPSR_EL1是Saved Program Status Register, Holds the saved process state when an exception is taken to EL1. 当异常被EL1处理时, SPSR_EL1持有保存的状态寄存器 顺便看一下kernelExitToEl0 kernelExitToEl0这个函数在(c *CPU) SwitchToUser里面被调用, // kernelExitToEl0 is the entrypoint for application in guest_el0. // Prepare the vcpu environment for container application. TEXT ·kernelExitToEl0(SB),NOSPLIT,$0 // Step1, save sentry context into memory. MRS TPIDR_EL1, RSV_REG REGISTERS_SAVE(RSV_REG, CPU_REGISTERS) MOVD RSV_REG_APP, CPU_REGISTERS+PTRACE_R19(RSV_REG) MRS TPIDR_EL0, R3 MOVD R3, CPU_REGISTERS+PTRACE_TLS(RSV_REG) WORD $0xd5384003 // MRS SPSR_EL1, R3 MOVD R3, CPU_REGISTERS+PTRACE_PSTATE(RSV_REG) MOVD R30, CPU_REGISTERS+PTRACE_PC(RSV_REG) MOVD RSP, R3 MOVD R3, CPU_REGISTERS+PTRACE_SP(RSV_REG) MOVD CPU_REGISTERS+PTRACE_R3(RSV_REG), R3 // Step2, switch to temporary stack. LOAD_KERNEL_STACK(RSV_REG) // Step3, load app context pointer. MOVD CPU_APP_ADDR(RSV_REG), RSV_REG_APP // Step4, prepare the environment for container application. // set sp_el0. MOVD PTRACE_SP(RSV_REG_APP), R1 WORD $0xd5184101 //MSR R1, SP_EL0 // set pc. MOVD PTRACE_PC(RSV_REG_APP), R1 MSR R1, ELR_EL1 // set pstate. MOVD PTRACE_PSTATE(RSV_REG_APP), R1 WORD $0xd5184001 //MSR R1, SPSR_EL1 // need use kernel space address to excute below code, since // after SWITCH_TO_APP_PAGETABLE the ASID is changed to app's // ASID. WORD $0x10000061 // ADR R1, do_exit_to_el0 ORR $0xffff000000000000, R1, R1 JMP (R1) do_exit_to_el0: // RSV_REG & RSV_REG_APP will be loaded at the end. REGISTERS_LOAD(RSV_REG_APP, 0) MOVD PTRACE_TLS(RSV_REG_APP), RSV_REG MSR RSV_REG, TPIDR_EL0 // switch to user pagetable. LDP PTRACE_R18(RSV_REG_APP), (RSV_REG, RSV_REG_APP) SUB $STACK_FRAME_SIZE, RSP, RSP STP (RSV_REG, RSV_REG_APP), 16*0(RSP) STP (R0, R1), 16*1(RSP) WORD $0xd538d092 //MRS TPIDR_EL1, R18 SWITCH_TO_APP_PAGETABLE() LDP 16*1(RSP), (R0, R1) LDP 16*0(RSP), (RSV_REG, RSV_REG_APP) ADD $STACK_FRAME_SIZE, RSP, RSP ERET() EL1同步异常El1_sync 在El1状态下的同步异常入口下面, 通过读取ESR_EL1, 异常可分为: 数据错误, 代码错误, 栈对齐错误, pc对齐错误等错误异常. svc异常, 系统调用用的 -- 但这里已经是el1了, 还有啥系统调用? 其他异常// El1_sync is the handler for El1_sync. TEXT ·El1_sync(SB),NOSPLIT,$0 KERNEL_ENTRY_FROM_EL1 // 保存sentry上下文寄存器, load kernel stack MRS ESR_EL1, R25 // read the syndrome register LSR $ESR_ELx_EC_SHIFT, R25, R24 // exception class CMP $ESR_ELx_EC_DABT_CUR, R24 BEQ el1_da // data abort in EL1 CMP $ESR_ELx_EC_IABT_CUR, R24 BEQ el1_ia // instruction abort in EL1 CMP $ESR_ELx_EC_FP_ASIMD, R24 BEQ el1_fpsimd_acc // FP/ASIMD access CMP $ESR_ELx_EC_SVE, R24 BEQ el1_sve_acc // SVE access CMP $ESR_ELx_EC_SP_ALIGN, R24 BEQ el1_sp_pc // stack alignment exception CMP $ESR_ELx_EC_PC_ALIGN, R24 BEQ el1_sp_pc // pc alignment exception CMP $ESR_ELx_EC_UNKNOWN, R24 BEQ el1_undef // unknown exception in EL1 CMP $ESR_ELx_EC_SVC64, R24 BEQ el1_svc // SVC in 64-bit state CMP $ESR_ELx_EC_BREAKPT_CUR, R24 BEQ el1_dbg // debug exception in EL1 B el1_invalid 一般的错误异常 最后调用HaltEl1ExceptionAndResume // HaltEl1ExceptionAndResume calls Hooks.KernelException and resume. TEXT ·HaltEl1ExceptionAndResume(SB),NOSPLIT,$0-8 WORD $0xd538d092 // MRS TPIDR_EL1, R18 MOVD CPU_SELF(RSV_REG), R3 // Load vCPU. MOVD R3, 8(RSP) // First argument (vCPU). MOVD vector+0(FP), R3 MOVD R3, 16(RSP) // Second argument (vector). CALL ·kernelException(SB) // Call the trampoline. B ·kernelExitToEl1(SB) // Resume. 而svc异常调用HaltEl1SvcAndResume, 它也会调用钩子函数处理系统调用:kernelSyscall el1_svc: B ·HaltEl1SvcAndResume(SB) // HaltEl1SvcAndResume calls Hooks.KernelSyscall and resume. TEXT ·HaltEl1SvcAndResume(SB),NOSPLIT,$0 WORD $0xd538d092 // MRS TPIDR_EL1, R18 MOVD CPU_SELF(RSV_REG), R3 // Load vCPU. MOVD R3, 8(RSP) // First argument (vCPU). CALL ·kernelSyscall(SB) // Call the trampoline. B ·kernelExitToEl1(SB) // Resume. EL1其他异常(irq, fiq, error)都走shutdown流程, 关闭guest // El1_irq is the handler for El1_irq. TEXT ·El1_irq(SB),NOSPLIT,$0 B ·Shutdown(SB) // El1_fiq is the handler for El1_fiq. TEXT ·El1_fiq(SB),NOSPLIT,$0 B ·Shutdown(SB) // El1_error is the handler for El1_error. TEXT ·El1_error(SB),NOSPLIT,$0 B ·Shutdown(SB) // Shutdown stops the guest. TEXT ·Shutdown(SB),NOSPLIT,$0 // PSCI EVENT. MOVD $0x84000009, R0 HVC $0 // hypervisor call KVM_CREATE_VCPU 比如在pkg/sentry/platform/kvm/machine.go中, 有个函数newVCPU就使用了_KVM_CREATE_VCPU // newVCPU creates a returns a new vCPU. // // Precondition: mu must be held. func (m *machine) newVCPU() *vCPU { // Create the vCPU. id := int(atomic.AddUint32(&m.nextID, 1) - 1) fd, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CREATE_VCPU, uintptr(id)) if errno != 0 { panic(fmt.Sprintf(\"error creating new vCPU: %v\", errno)) } c := &vCPU{ id: id, fd: int(fd), machine: m, } c.CPU.Init(&m.kernel, c.id, c) c.self = c // Set self reference. c.kernel = k // Set kernel reference. c.init(cpuID) // Perform architectural init. // Set the kernel stack pointer(virtual address). c.registers.Sp = uint64(c.StackTop()) c.floatingPointState = fpu.NewState() // hooks是 c.hooks = hooks 或者 c.hooks = defaultHooks{} m.vCPUsByID[c.id] = c // Ensure the signal mask is correct. if err := c.setSignalMask(); err != nil { panic(fmt.Sprintf(\"error setting signal mask: %v\", err)) } // Map the run data. // 就是把fd mmap成内存, 用于kvm向用户态传递信息 runData, err := mapRunData(int(fd)) if err != nil { panic(fmt.Sprintf(\"error mapping run data: %v\", err)) } c.runData = runData // Initialize architecture state. // 相当于 if err := c.initArchState(); err != nil { panic(fmt.Sprintf(\"error initialization vCPU state: %v\", err)) } return c // Done. } 比如设置initArchState中, 就调用了setOneRegister很多次, 用_KVM_SET_ONE_REG配置寄存器, 比如ttbr0 func (c *vCPU) setOneRegister(reg *kvmOneReg) error { if _, _, errno := unix.RawSyscall( unix.SYS_IOCTL, uintptr(c.fd), _KVM_SET_ONE_REG, uintptr(unsafe.Pointer(reg))); errno != 0 { return fmt.Errorf(\"error setting one register: %v\", errno) } return nil } // 这个init是运行在用户态的, 所以需要借助KVM的`_KVM_SET_ONE_REG`功能, 通过ioctl系统调用的方式, 让KVM来设置寄存器 // initArchState initializes architecture-specific state. func (c *vCPU) initArchState() error { var ( reg kvmOneReg data uint64 regGet kvmOneReg dataGet uint64 ) reg.addr = uint64(reflect.ValueOf(&data).Pointer()) regGet.addr = uint64(reflect.ValueOf(&dataGet).Pointer()) // 先是KVM的ioctl的_KVM_ARM_VCPU_INIT vcpuInit.features[0] |= (1 kernelAddr可以获取一个eface和func的内核地址 package ring0 // eface mirrors runtime.eface. type eface struct { typ uintptr data unsafe.Pointer } // kernelAddr returns the kernel virtual address for the given object. // //go:nosplit func kernelAddr(obj interface{}) uintptr { e := (*eface)(unsafe.Pointer(&obj)) return KernelStartAddress | uintptr(e.data) } // kernelFunc returns the address of the given function. // KernelStartAddress是ffff000000000000 func kernelFunc(fn uintptr) uintptr { return KernelStartAddress | fn } 对arm64来说 type Vector uintptr // System call vectors. const ( Syscall Vector = El0SyncSVC PageFault Vector = El0SyncDa VirtualizationException Vector = El0ErrBounce ) // VirtualAddressBits returns the number bits available for virtual addresses. // 虚拟地址是48位, 和实际一样 func VirtualAddressBits() uint32 { return 48 } // PhysicalAddressBits returns the number of bits available for physical addresses. func PhysicalAddressBits() uint32 { return 40 } var ( // UserspaceSize is the total size of userspace. UserspaceSize = uintptr(1) KVM_ARM_VCPU_INIT 在ioctl KVM_CREATE_VCPU之后, 需要KVM_ARM_VCPU_INIT This tells KVM what type of CPU to present to the guest, and what optional features it should have. This will cause a reset of the cpu registers to their initial values. If this is not called, KVM_RUN will return ENOEXEC for that vcpu. KVM_ARM_VCPU_INIT会把cpu重置为初始值. 如果没有这一步, KVM_RUN就会错误. The initial values are defined as: Processor state: AArch64: EL1h, D, A, I and F bits set. All other bits are cleared. AArch32: SVC, A, I and F bits set. All other bits are cleared. General Purpose registers, including PC and SP: set to 0 FPSIMD/NEON registers: set to 0 SVE registers: set to 0 System registers: Reset to their architecturally defined values as for a warm reset to EL1 (resp. SVC) Note that because some registers reflect machine topology, all vcpus should be created before this ioctl is invoked. Userspace can call this function multiple times for a given vcpu, including after the vcpu has been run. This will reset the vcpu to its initial state. All calls to this function after the initial call must use the same target and same set of feature flags, otherwise EINVAL will be returned. 入口代码 在vCPU初始化的时候, 入口代码ring0.Start()用KVM的ioctl被写入PC // pc reg.id = _KVM_ARM64_REGS_PC data = uint64(reflect.ValueOf(ring0.Start).Pointer()) //这里的实现很关键!!!! ring0.Start是个函数, 取这个函数当作入口地址, 配到PC中. if err := c.setOneRegister(&reg); err != nil { return err } 这个Start()函数在 pkg/ring0/entry_arm64.s 应该是运行在EL1 // Start is the CPU entrypoint. TEXT ·Start(SB),NOSPLIT,$0 // Init. WORD $0xd508871f // __tlbi(vmalle1) DSB $7 // dsb(nsh) MOVD $1 KVM的context实现 上面提到platform要实现context方法: // Switch resumes execution of the thread specified by the arch.Context // in the provided address space. This call will block while the thread // is executing. // 正常应该是成功调用一个系统调用. // 如果正在执行这个系统调用的时候有signal, 返回ErrContextSignal // 如果调用了Interrupt()则返回ErrContextInterrupt Switch(ctx context.Context, mm MemoryManager, ac arch.Context, cpu int32) (*linux.SignalInfo, hostarch.AccessType, error) 按照ptrace的实现, Switch函数是执行一个sycle的用户代码直到下一个syscall. 那么kvm实现怎么做到syscall级别的呢? // Switch runs the provided context in the given address space. func (c *context) Switch(ctx pkgcontext.Context, mm platform.MemoryManager, ac arch.Context, _ int32) (*linux.SignalInfo, hostarch.AccessType, error) { as := mm.AddressSpace() localAS := as.(*addressSpace) // Grab a vCPU. // machine.Get()返回一个vCPU, vCPU是和TID绑定的, 先查表找已经绑定的; 没有就检查每个vCPU的状态, 尝试从vCPUReady转到vCPUUser状态; 最后实在不行就m.getNewVCPU()一个 cpu := c.machine.Get() // Enable interrupts (i.e. calls to vCPU.Notify). if !c.interrupt.Enable(cpu) { c.machine.Put(cpu) // Already preempted. return nil, hostarch.NoAccess, platform.ErrContextInterrupt } // Set the active address space. // // This must be done prior to the call to Touch below. If the address // space is invalidated between this line and the call below, we will // flag on entry anyways. When the active address space below is // cleared, it indicates that we don't need an explicit interrupt and // that the flush can occur naturally on the next user entry. cpu.active.set(localAS) // Prepare switch options. switchOpts := ring0.SwitchOpts{ Registers: &ac.StateData().Regs, FloatingPointState: ac.FloatingPointData(), PageTables: localAS.pageTables, Flush: localAS.Touch(cpu), FullRestore: ac.FullRestore(), } // Take the blue pill. 这里是关键 at, err := cpu.SwitchToUser(switchOpts, &c.info) // Clear the address space. cpu.active.set(nil) // Increment the number of user exits. atomic.AddUint64(&cpu.userExits, 1) // Release resources. c.machine.Put(cpu) // All done. c.interrupt.Disable() return &c.info, at, err } arm64的cpu.SwitchToUser 在pkg/sentry/platform/kvm/machine_arm64_unsafe.go中 // SwitchToUser unpacks architectural-details. func (c *vCPU) SwitchToUser(switchOpts ring0.SwitchOpts, info *linux.SignalInfo) (hostarch.AccessType, error) { // Check for canonical addresses. if regs := switchOpts.Registers; !ring0.IsCanonical(regs.Pc) { return nonCanonical(regs.Pc, int32(unix.SIGSEGV), info) } else if !ring0.IsCanonical(regs.Sp) { return nonCanonical(regs.Sp, int32(unix.SIGSEGV), info) } // Assign PCIDs. if c.PCIDs != nil { var requireFlushPCID bool // Force a flush? switchOpts.UserASID, requireFlushPCID = c.PCIDs.Assign(switchOpts.PageTables) switchOpts.Flush = switchOpts.Flush || requireFlushPCID } var vector ring0.Vector ttbr0App := switchOpts.PageTables.TTBR0_EL1(false, 0) c.SetTtbr0App(uintptr(ttbr0App)) //这里配置了用户态的基址寄存器 // Full context-switch supporting for Arm64. // The Arm64 user-mode execution state consists of: // x0-x30 // PC, SP, PSTATE // V0-V31: 32 128-bit registers for floating point, and simd // FPSR, FPCR // TPIDR_EL0, used for TLS appRegs := switchOpts.Registers c.SetAppAddr(ring0.KernelStartAddress | uintptr(unsafe.Pointer(appRegs))) entersyscall() //go:linkname entersyscall runtime.entersyscall, 这里更像是告诉go的runtime, 我要进入syscall了, 要阻塞了 bluepill(c) //bluepill enters guest mode, 进入guest模式; 下面会提到, bluepill会触发非法指令异常, 程序会在这里卡住, 等待bluepillHandler执行一次ioctl的_KVM_RUN vector = c.CPU.SwitchToUser(switchOpts) exitsyscall() switch vector { case ring0.Syscall: // Fast path: system call executed. return hostarch.NoAccess, nil case ring0.PageFault: return c.fault(int32(unix.SIGSEGV), info) case ring0.El0ErrNMI: return c.fault(int32(unix.SIGBUS), info) case ring0.Vector(bounce): // ring0.VirtualizationException. return hostarch.NoAccess, platform.ErrContextInterrupt case ring0.El0SyncUndef: return c.fault(int32(unix.SIGILL), info) case ring0.El0SyncDbg: *info = linux.SignalInfo{ Signo: int32(unix.SIGTRAP), Code: 1, // TRAP_BRKPT (breakpoint). } info.SetAddr(switchOpts.Registers.Pc) // Include address. return hostarch.AccessType{}, platform.ErrContextSignal case ring0.El0SyncSpPc: *info = linux.SignalInfo{ Signo: int32(unix.SIGBUS), Code: 2, // BUS_ADRERR (physical address does not exist). } return hostarch.NoAccess, platform.ErrContextSignal case ring0.El0SyncSys, ring0.El0SyncWfx: return hostarch.NoAccess, nil // skip for now. default: panic(fmt.Sprintf(\"unexpected vector: 0x%x\", vector)) } } bluepill()汇编函数 在上面的SwitchToUser()函数中, 先是entersyscall(), 然后调用bluepill()进入guest模式 // See bluepill.go. TEXT ·bluepill(SB),NOSPLIT,$0 begin: MOVD vcpu+0(FP), R8 MOVD $VCPU_CPU(R8), R9 ORR $0xffff000000000000, R9, R9 // Trigger sigill. // In ring0.Start(), the value of R8 will be stored into tpidr_el1. // When the context was loaded into vcpu successfully, // we will check if the value of R10 and R9 are the same. // 注意原注释里的MRS TPIDR_EL1, R10, 因为在EL0级别使用了高级别的TPIDR_EL1, 会触发指令异常 // 大部分系统寄存器都不能在EL0访问, 个别的可以, 比如TPIDR_EL0. 注意这里的后缀是EL0 // Any access from EL0 to a System register with the access right disabled causes the instruction to behave as UNDEFINED // 这个非法指令异常应该会导致当前CPU跳转到kernel配置好的异常向量 // 然后kernel会路由这个signal到下面的sighandler, 在返回用户态后执行. WORD $0xd538d08a // MRS TPIDR_EL1, R10 // 因为当前线程在执行下面的sighandler, 暂时还不会走到这里. 待 sighandler执行完成后, 再次返回内核, 内核再次调度这个线程, 才跑到这里. check_vcpu: CMP R10, R9 BEQ right_vCPU wrong_vcpu: CALL ·redpill(SB) B begin right_vCPU: RET // 异常会在这里被处理. 但问题是为什么非要触发个sigill再来处理? // sighandler: see bluepill.go for documentation. // // The arguments are the following: // // R0 - The signal number. // R1 - Pointer to siginfo_t structure. // R2 - Pointer to ucontext structure. // TEXT ·sighandler(SB),NOSPLIT,$0 // si_signo should be sigill. MOVD SIGINFO_SIGNO(R1), R7 CMPW $4, R7 BNE fallback MOVD CONTEXT_PC(R2), R7 CMPW $0, R7 BEQ fallback MOVD R2, 8(RSP) BL ·bluepillHandler(SB) // Call the handler. RET 下面就来到了bluepillHandler()这个函数, 在pkg/sentry/platform/kvm/bluepill_unsafe.go粗看下来, 这个函数核心是调用一次unix.RawSyscall(unix.SYS_IOCTL, uintptr(c.fd), _KVM_RUN, 0), 然后等待guest VM因为异常等原因退出这一次的RUN我认为在KVM_RUN syscall期间是阻塞的, 那么这里就是在signal处理函数里阻塞. func bluepillHandler(context unsafe.Pointer) { c := bluepillArchEnter(bluepillArchContext(context)) //这里返回一个*vCPU for { _, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(c.fd), _KVM_RUN, 0) // escapes: no. //检查errno是否是被打断等 //检查exitReason, 每个分支都return(除了中断注入), 也就是说for只管一次 // exitReason是kvm通过mmap传出来的值 switch c.runData.exitReason { } } } 对应一次_KVM_RUN让VM运行, stop VM是通过ioctl的_KVM_SET_VCPU_EVENTS来实现的. // bluepillStopGuest is reponsible for injecting sError. // //go:nosplit func bluepillStopGuest(c *vCPU) { // vcpuSErrBounce is the event of system error for bouncing KVM. vcpuSErrBounce := &kvmVcpuEvents{ exception: exception{ sErrPending: 1, }, } if _, _, errno := unix.RawSyscall( // escapes: no. unix.SYS_IOCTL, uintptr(c.fd), _KVM_SET_VCPU_EVENTS, uintptr(unsafe.Pointer(vcpuSErrBounce))); errno != 0 { throw(\"bounce sErr injection failed\") } } 这个runData定义是, 估计是kvm标准定义的 type runData struct { requestInterruptWindow uint8 _ [7]uint8 exitReason uint32 readyForInterruptInjection uint8 ifFlag uint8 _ [2]uint8 cr8 uint64 apicBase uint64 // This is the union data for exits. Interpretation depends entirely on // the exitReason above (see vCPU code for more information). data [32]uint64 } 为什么runData的exitReason会反应VM的退出码?因为在newVCPU()里面, 用_KVM_CREATE_VCPU出来的fd, mmap成了*runData func (m *machine) newVCPU() *vCPU { fd, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(m.fd), _KVM_CREATE_VCPU, uintptr(id)) // Map the run data. runData, err := mapRunData(int(fd)) c.runData = runData } // mapRunData maps the vCPU run data. func mapRunData(fd int) (*runData, error) { r, _, errno := unix.RawSyscall6( unix.SYS_MMAP, 0, uintptr(runDataSize), unix.PROT_READ|unix.PROT_WRITE, unix.MAP_SHARED, uintptr(fd), 0) if errno != 0 { return nil, fmt.Errorf(\"error mapping runData: %v\", errno) } return (*runData)(unsafe.Pointer(r)), nil } vCPU.CPU.SwitchToUser函数 位于pkg/ring0/kernel_arm64.go // SwitchToUser performs an eret. // // The return value is the exception vector. // // +checkescape:all // //go:nosplit func (c *CPU) SwitchToUser(switchOpts SwitchOpts) (vector Vector) { storeAppASID(uintptr(switchOpts.UserASID)) storeEl0Fpstate(switchOpts.FloatingPointState.BytePointer()) if switchOpts.Flush { LocalFlushTlbByASID(uintptr(switchOpts.UserASID)) } regs := switchOpts.Registers regs.Pstate &= ^uint64(PsrFlagsClear) regs.Pstate |= UserFlagsSet fpDisableTrap := CPACREL1() if fpDisableTrap != 0 { FPSIMDEnableTrap() } kernelExitToEl0() fpDisableTrap = CPACREL1() if fpDisableTrap != 0 { SaveFloatingPoint(switchOpts.FloatingPointState.BytePointer()) } vector = c.vecCode return } 补充 go linkname用法 pkg/sentry/platform/kvm/machine_unsafe.go中, 引用了2个runtime的小写函数: //go:linkname entersyscall runtime.entersyscall func entersyscall() //go:linkname exitsyscall runtime.exitsyscall func exitsyscall() The //go:nosplit directive must be followed by a function declaration. It specifies that the function must omit its usual stack overflow check. This is most commonly used by low-level runtime code invoked at times when it is unsafe for the calling goroutine to be preempted. //go:linkname localname [importpath.name] This special directive does not apply to the Go code that follows it. Instead, the //go:linkname directive instructs the compiler to use “importpath.name” as the object file symbol name for the variable or function declared as “localname” in the source code. If the “importpath.name” argument is omitted, the directive uses the symbol's default object file symbol name and only has the effect of making the symbol accessible to other packages. Because this directive can subvert the type system and package modularity, it is only enabled in files that have imported \"unsafe\". go:linkname有三种用法: export: localname是本地(pkgA)的有函数体的实现, export成pkgB.name. pkgB没有name的实现 import: localname是本地(pkgA)的没有函数体的声明, 它import pkgB.name的具体实现. 同名export: 不指定importpath.name, 让本来小写的符号能被外部访问. runtime.entersyscall在src/runtime/proc.go中定义 // Standard syscall entry used by the go syscall library and normal cgo calls. // // This is exported via linkname to assembly in the syscall package. // //go:nosplit //go:linkname entersyscall func entersyscall() { reentersyscall(getcallerpc(), getcallersp()) } // reentersyscall比较晦涩, 这里只贴了注释 // The goroutine g is about to enter a system call. // Record that it's not using the cpu anymore. // This is called only from the go syscall library and cgocall, // not from the low-level system calls used by the runtime. // // Entersyscall cannot split the stack: the gosave must // make g->sched refer to the caller's stack segment, because // entersyscall is going to return immediately after. // // Nothing entersyscall calls can split the stack either. // We cannot safely move the stack during an active call to syscall, // because we do not know which of the uintptr arguments are // really pointers (back into the stack). // In practice, this means that we make the fast path run through // entersyscall doing no-split things, and the slow path has to use systemstack // to run bigger things on the system stack. // // reentersyscall is the entry point used by cgo callbacks, where explicitly // saved SP and PC are restored. This is needed when exitsyscall will be called // from a function further up in the call stack than the parent, as g->syscallsp // must always point to a valid stack frame. entersyscall below is the normal // entry point for syscalls, which obtains the SP and PC from the caller. // // Syscall tracing: // At the start of a syscall we emit traceGoSysCall to capture the stack trace. // If the syscall does not block, that is it, we do not emit any other events. // If the syscall blocks (that is, P is retaken), retaker emits traceGoSysBlock; // when syscall returns we emit traceGoSysExit and when the goroutine starts running // (potentially instantly, if exitsyscallfast returns true) we emit traceGoStart. // To ensure that traceGoSysExit is emitted strictly after traceGoSysBlock, // we remember current value of syscalltick in m (_g_.m.syscalltick = _g_.m.p.ptr().syscalltick), // whoever emits traceGoSysBlock increments p.syscalltick afterwards; // and we wait for the increment before emitting traceGoSysExit. // Note that the increment is done even if tracing is not enabled, // because tracing can be enabled in the middle of syscall. We don't want the wait to hang. // //go:nosplit func reentersyscall(pc, sp uintptr) { ... } "},"notes/golang_gvisor调试.html":{"url":"notes/golang_gvisor调试.html","title":"gvisor调试","keywords":"","body":" 环境 gvisor编译 gvisor编译 go分支编译 master分支编译 gvisor调试 配置文件 运行 kvm模式运行非常缓慢 调试 调试前准备 dlv调试 signal返回到哪了? sighandler做桥, host和guest跳转过程 一次blupill流程 另外一次blupill流程 问题 断点记录: 问题1 以上修改不管用 bluepillGuestExit跳转到哪里了? 本文在raspberry pi 4上调试gvisor的kvm模式, 目的是理解gvisor的kvm运行机制. 环境 环境 说明 硬件 raspberry pi 4B OS ubuntu server 21.10 for arm64 kernel Linux ubuntu 5.13.0-1022-raspi #24-Ubuntu SMP PREEMPT Wed Mar 16 07:19:33 UTC 2022 aarch64 aarch64 aarch64 GNU/Linux gvisor编译 gvisor信息 说明 版本 https://github.com/google/gvisor.git 分支 master 编译 make copy TARGETS=runsc DESTINATION=bin/ gvisor编译 go分支编译 gvisor有两个分支: master分支, 用bazel编译 go分支, 用go build编译 使用go分支可以编译, 但无法正常运行, 提示类似/proc/self/exe: no such file or directory的错误. 调查发现gvisor需要在当前进程下把uid和guid都设置成nobody, 然后执行/proc/self/exe再次启动自身. 但这一步出错: 当前进程下存在/proc/self/exe, 它是个软连接, 指向正确的runsc的路径 代码在runsc/cmd/cmd.go的callSelfAsNobody()函数 在这个函数里, 虽然能够找到/proc/self/exe, 但执行会报错. 具体原因不明, 我加了点调试代码, 发现这个slef exe可以执行, 但报错提示/dev/null不存在.func callSelfAsNobody(args []string) error { ... binPath := \"/proc/self/exe\" dest, _ := os.Readlink(binPath) output, err := exec.Command(dest, \"-h\").CombinedOutput() log.Infof(\"error: %v\", errr) //这里提示/dev/null不存在 } gvisor的启动顺序是runsc create再runsc gofer再runsc boot再runsc start再runsc delete. 我怀疑是在runsc create阶段对这个namespace的创建不完整 master分支编译 master分支可以编译, 可以\"正常\"运行. 但在raspberry上编译极其慢, 我大概等了两三个小时. gvisor调试 下面是以master分支编译出来的runsc来进行调试 配置文件 使用runsc需要在docker里配置runtime, 如下: ubuntu@ubuntu ~ $ cat /etc/docker/daemon.json { \"runtimes\": { \"runsc\": { \"path\": \"/home/ubuntu/repo/bbb/gvisor/bin/runsc\", \"runtimeArgs\": [ \"--cpu-num-from-quota\", \"--platform=kvm\", \"--debug-log=/tmp/runsc/\", \"--debug\" ] } } } 更改配置文件需要 sudo systemctl reload docker 运行 用docker运行centos, 需要指定--runtime=runsc, --cpus=1 -m 2g指定了cpu和mem的限制:docker run --cpus=1 -m 2g --rm --runtime=runsc -it --name=test centos:7 bash kvm模式运行非常缓慢 正常docker run命令应该很快返回, 但kvm模式下观察到CPU占用非常高, 多核100%运行, docker run命令迟迟不返回. 调试 调试前准备 除了需要大概了解gvisor的代码和执行流程外, 在调试前, 需要 找到runsc boot进程的pid 我这里显示runsc-sandbox boot进程的pid是4989 反汇编runsc go tool objdump -S runsc > runsc.objdump dlv调试 $ sudo /home/ubuntu/go/bin/dlv attach 4989 (dlv) b *0x951d5c (dlv) c (dlv) bt 0 0x0000000000951d5c in gvisor.dev/gvisor/pkg/ring0.(*CPU).SwitchToUser 1 0x000000000095a02c in gvisor.dev/gvisor/pkg/sentry/platform/kvm.(*vCPU).SwitchToUser 2 0x000000000095564c in gvisor.dev/gvisor/pkg/sentry/platform/kvm.(*context).Switch 3 0x00000000005420c8 in gvisor.dev/gvisor/pkg/sentry/kernel.(*runApp).execute 4 0x000000000054152c in gvisor.dev/gvisor/pkg/sentry/kernel.(*Task).run 5 0x000000000007e154 in runtime.goexit (dlv) si Stopped at: 0x951fa0 注:0x951d5c是调用ring0.kernelExitToEl0函数的地方, 在gvisor.dev/gvisor/pkg/ring0.(*CPU).SwitchToUser里:0x951d5c 94000091 CALL gvisor.dev/gvisor/pkg/ring0.kernelExitToEl0(SB) 而0x951fa0就是kernelExitToEl0的代码: 0x951fa0 d538d092 MRS $18052, R18 //其实是MRS TPIDR_EL1, R18 这个TPIDR_EL1是thread id寄存器, 只能在EL1访问; 但这里是EL0, 于是发生指令异常:在dlv里si并没有执行0x951fa4 a90e0640 STP (R0, R1), 224(R18)这句代码而是跳转到了0x95c700就能看出来: 指令异常被host kernel deliver到触发异常的线程(即当前线程), 交由提前注册的sighandler在用户态处理.0x95c700是SIGILL的处理函数: 这个sighandler是kvm实现里非常关键的函数, 它负责执行依次KVM_RUN. _, _, errno := unix.RawSyscall(unix.SYS_IOCTL, uintptr(c.fd), _KVM_RUN, 0) 我们一路向下单步执行, 来到了这个函数的返回点: (dlv) si Stopped at: 0x95c730 => 1: no source available (dlv) si Stopped at: 0x95c734 //这句正好是kvm.sighandler的RET指令 => 1: no source available 0x95c734处的指令是kvm.sighandler的RET指令, 继续向下, 我们来到了一个很奇怪的地址: (dlv) si Stopped at: 0xffffb00ba7dc => 1: no source available (dlv) si Stopped at: 0xffffb00ba7e0 => 1: no source available 这里的0xffff开头的地址, 比普通的代码段地址高很多, objdump里还查不到相应的地址...那看看dlv的反汇编指令: (dlv) disass -a 0x0000ffffb00ba780 0x0000ffffb00ba800 这个svc指令是arm64的系统调用指令, 系统调用号放在r8里:x8的0x8b就是代码里的$139, 这个调用是: rt_sigreturn rt_sigreturn系统调用是signal处理机制的trampoline的一部分, 当用户态的sighandler返回的时候, 实际上返回的是signal的trampoline的代码, 后者再调用系统调用rt_sigreturn()让内核帮助恢复用户态上下文, 再返回到用户态被signal打断的代码.我们这里的sigill是同步异常, 那么一般情况下就应该还是这个指令; 但我们这里实际上不是 因为ucontext改变了, 见下文: signal返回到哪了? 调用kvm.sighandler时, 代表被打断的上下文的ucontext被放到R2中: // sighandler: see bluepill.go for documentation. // // The arguments are the following: // // R0 - The signal number. // R1 - Pointer to siginfo_t structure. // R2 - Pointer to ucontext structure. // TEXT ·sighandler(SB),NOSPLIT,$0 // si_signo should be sigill. MOVD SIGINFO_SIGNO(R1), R7 CMPW $4, R7 BNE fallback MOVD CONTEXT_PC(R2), R7 CMPW $0, R7 BEQ fallback MOVD R2, 8(RSP) BL ·bluepillHandler(SB) // Call the handler. RET 这里的0x95c700就是kvm.sighandler(SB)这里的R2(就是X2)为0x4000460e20这实际上是个指向arch.UContext64的指针: dlv显示Pc: 95c6d8, 这正好是触发SIGILL的指令地址. 直到调用kvm.bluepillHandler(SB)之前, 这个PC都是95c6d8 注意看这里的Regs[30]为95a004, 我们知道r30是LR寄存器, 95a004就是调用完kvm.bluepill后的地址 sighandler做桥, host和guest跳转过程 一次blupill流程 0x95c6c0 kvm.bluepill 0x95c6d8 MRS TPIDR_EL1, R10 //触发sigill 0x95c700 kvm.sighandler // with Pc: 95c6d8, 也就是前面的指令 0x954f10 kvm.bluepillHandler() 0x954e20 bluepillGuestExit // with Pc: 95c6d8 ret with Pc: 951d5c 0x95c734 ret // with Pc: 951d5c 0xffffb00ba7dc 0xffffb00ba7e0 svc // rt_sigreturn 0x951d5c CALL kernelExitToEl0() // 单步执行就到了这里, 因为前面ucontext的pc就是951d5c 0x951fa0 // in kernelExitToEl0() 第一个指令就是特权指令 0x95c700 kvm.sighandler // with Pc: 951fa0, 也就是前面的指令 0x954f10 kvm.bluepillHandler() 0x954e20 bluepillGuestExit // with Pc: 951fa0 ret with Pc: 7f41c 0x95c734 ret // with Pc: 7f41c 0xffffb00ba7dc 0xffffb00ba7e0 svc // rt_sigreturn 0x7f41c svc指令 // in runtime.futex(SB) src/runtime/sys_linux_arm64.s 0x432e8 runtime.futexsleep() 0x95c6c0 kvm.bluepill // 再次进入bluepill ... 本次实验常用地址索引: 0x951d5c CALL gvisor.dev/gvisor/pkg/ring0.kernelExitToEl0(SB) 0x951fa0 ring0.kernelExitToEl0 0x95c6c0 kvm.bluepill(SB) 0x95c700 kvm.sighandler(SB) 0x95c728 CALL gvisor.dev/gvisor/pkg/sentry/platform/kvm.bluepillHandler(SB) 0x95c734 RET 如果只打断点0x95c734, 得到跳转地址如下: 0x7f41c svc in runtime.futex(SB) 0x9272c svc in syscall.Syscall(SB) 0x95c6d8 MRS in kvm.bluepill 0x7f41c svc in runtime.futex(SB) 0x7f41c 0x7f41c 过程中观察到有多个context: p %x *(*arch.UContext64)(0x4000460e20) p %x *(*arch.UContext64)(0x4000188e20) p %x *(*arch.UContext64)(0x400014ce20) p %x *(*arch.UContext64)(0x4000008e20) p %x *(*arch.UContext64)(0x400006ce20) 另外一次blupill流程 这次是打了bluepillGuestExit断点, continue等待断点时间较长, 从host观察到CPU一直在VM状态下, 持续高负载运行, 现象是htop显示黄色(CPU stolen), 直到trigger断点此时观察到ucontext的PC是0x95c6d8, 就是blupill触发sigill的指令地址: 问题 如果断点打在ring0.(*CPU).SwitchToUser(), 会导致bluepillGuestExit里, 误认为VM退出时候的PC是ring0.(*CPU).SwitchToUser(), 导致继续运行不正确. 断点记录: b ring0.(*CPU).SwitchToUser b *0x95c700 //sigill handler入口 b *0x95c734 //sigill handler返回前 b *0x95c6c0 //bluepill入口 b kvm.bluepillHandler b kvm.bluepillGuestExit b ring0.(*CPU).SwitchToUser 问题1 每一轮的进入guest模式是从bluepill开始的, 但每轮要在guest态执行很久, CPU100%很久, 才能退出guest状态, 此时看到guest里面的调用栈非常非常深: 0x7f41c svc in runtime.futex(SB)这里的调用栈显示有太多的runtime.morestack的栈帧.这里只显示50层, 但实际上bt命令支持depth参数, 即使加到10000层也显示不完... 0x7bf70地址实际上是runtime·morestack(SB)的最后一条指令, 理论上执行不到: @src/runtime/asm_arm64.s TEXT runtime·morestack(SB),NOSPLIT|NOFRAME,$0-0 ... BL runtime·newstack(SB) // Not reached, but make sure the return PC from the call to newstack // is still in this function, and not the beginning of the next. UNDEF 怀疑和BL地址有关, 把bl改为jmp指令试试 //也可以这样显示 (dlv) p %x *(*uint32)(0x7bf6c) //改为0x17ff9ee8 set *(*uint32)(0x7bf6c) = 0x17ff9ee9 即修改前:修改后: 可以看到, call指令换成了jmp指令后, 每轮的bluepill还是会执行很久, 但调用栈似乎已经正常: 有的时候即使调用栈不深也要执行很久 以上修改不管用 还是会出现很多0x000000000007bf5c in runtime.morestack那么guest在干什么导致CPU占用这么高呢? 用sudo perf kvm --guest --guestvmlinux path/to/runsc top可以看vm的符号观察到:对应的代码: pmap显示: sudo pmap 7556 ... 000000fee2e31000 273806262272K ----- [ anon ] 0000ffff62e31000 4K rw-s- memfd:memory-usage (deleted) 0000ffff62e32000 38212K rw--- [ anon ] 0000ffff65383000 512K ----- [ anon ] 0000ffff65403000 4K rw--- [ anon ] 0000ffff65404000 523836K ----- [ anon ] 0000ffff85393000 4K rw--- [ anon ] 0000ffff85394000 65476K ----- [ anon ] 0000ffff89385000 4K rw--- [ anon ] 0000ffff89386000 8180K ----- [ anon ] 0000ffff89b83000 4K rw--- [ anon ] 0000ffff89b84000 1020K ----- [ anon ] 0000ffff89c83000 384K rw--- [ anon ] 0000ffff89ce3000 8K r---- [ anon ] 0000ffff89ce5000 4K r-x-- [ anon ] 0000ffffe2bc3000 132K rw--- [ stack ] total 273808069472K 总共273T, 其中大部分都在一个段里. bluepillGuestExit跳转到哪里了? 比如: 在0x95c734, sigill handler马上要返回了, 此时ucontext的PC已经变成了927ac, 经过signal的trampoline系统调用后, kernel恢复了从927ac开始执行的上下文:这是个fdnotifier.epollWait在执行的syscall系统调用, 是guest task执行的, 因为这个上下文是依次KVM_RUN后, 从guest VCPU里得到的. 说明guest vCPU在遇到svc指令的时候, 会退出guest mode:退出后, host继续运行0x927ac处的代码(即svc指令). 这样host就\"代表\"guest来向host kernel发出了syscall动作. 比如:0x9272c处的指令是syscall.Syscall的svc指令 比如:0x7f41c是tuntime.futex的svc指令 比如: 比如: "},"notes/golang_gvisor_ptrace.html":{"url":"notes/golang_gvisor_ptrace.html","title":"gvisor ptrace模式介绍(网摘)","keywords":"","body":"原文: https://blog.csdn.net/M2l0ZgSsVc7r69eFdTj/article/details/82754587 传统的Container由于隔离性差而不适合作为Sandbox运行不受信工作负载，VM可以提供很好隔离但却额外消耗较多的内存。Google开源的gVisor为我们提供另外一种选择：在牺牲掉一定性能的情况下，它只额外消耗非常少量的内存，却可以提供了类似等级的隔离性。在本文里我们深入gVisor，最后了解一下我们增强gVisor以支持资源控制的方案。 gVisor是什么 gVisor为在Container中运行不受信代码提供了新的解决思路，gVisor是一个Sandbox方案和实现。 gVisor尝试解决什么问题 虽然Container上可以通过Namespace和Cgroup做资源的限制，但Container里的应用程序依然可以访问很多系统资源。事实上跟没有跑在Container里的应用程序一样，Container里的应用程序可以直接通过Linux内核的系统调用陷入到内核。任何一个被允许（通过Seccomp过滤系统调用）的系统调用的缺陷都可以被恶意的应用程序利用。 主流的Sandbox基于VM虚拟机的方案，将潜在恶意的应用程序隔离在独立的虚拟机中，例如Kata Linux，该项目与Docker和Kubernetes都有集成。基于VM的方案提高了很好的隔离，但相应额外消耗的内存会多一些。在有需要运行大量Container的场景下的额外资源消耗不能被忽略。 gVisor提供了另外一种Sandbox思路，gVisor非常轻量级，额外的内存消耗非常小，但同时提供了和VM方案相当隔离等级。该分享里介绍的基于Ptrace的gVisor，系统调用的性能比较差，应用程序的兼容性也差一些。gVisor可以和Docker很好的集成，但和Kubernetes的集成还处于实验阶段。在和Docker集成的时候，gVisor遵循了OCI（Open Containers Initiative）标准，所以可以作为Docker的一个Runtime执行。 gVisor如何工作 以非特权用户运行的gVisor通过截获应用程序的系统调用，将应用程序和内核之间完全隔离。gVisor没有简单的把应用程序发出的系统调用直接作用到内核，而是实现了大多数的系统调用，通过对系统调用模拟，让应用程序间接的访问到系统资源。gVisor模拟系统调用本身时对操作系统执行系统调用，通过使用Seccomp对这些系统调用做过滤。那么gVisor是如何截获应用程序的系统调用的呢？ gVisor截获系统调用 gVisor存在两种运行模式，这次分享只介绍了基于Ptrace的gVisor。 为了理解gVisor如何拦截系统调用，需要先了解一下Ptrace：Ptrace是Linux提供的一个系统调用接口，通过Ptrace，可以在两个进程之间建立Tracer和Tracee之间的关系。Tracer可以控制Tracee，例如当Tracee收到信号的时候主动进入stopped状态，此时Tracer可以选择是否对Tracee做一些操作（比如设置Tracee的寄存器上下文或者内存中内容等），在操作执行后，Tracer可以选择是否让Tracee继续执行。 Tracee除了可以在接受到信号时候进入stopped状态外，也可以被Tracer告知在即将进入系统调用时或者即将离开系统调用时进入stopped状态。具体说Ptrace可以通过PTRACE_SYSEMU控制Tracee在即将进去系统调动时stop。gVisor也正是通过该命令来截获应用程序的系统调用。 Sentry是通过Ptrace来控制应用程序，那么应用程序是如何变为Tracee的呢？ 将应用程序变成Tracee的 下图是gVisor控制应用程序的进程关系： 当gVisor以Docker的Runtime启动的时候，可以看到类似的进程间关系：docker-containerd-shim是容器的启动器；sentry是gVisor用于截获系统调用模拟内核的程序，他也正是Tracer。Stub可以暂时不用理会，stub的子进程正是我们想要放到Sandbox里的应用程序。Sentry创建stub，随后stub创建应用程序进程，sentry通过Ptrace attach到了stub和应用程序上。当应用程序在将要执行系统调用的时候会主动stop，此时也正是sentry拦截和模拟系统调用的点。 这跟用gdb调试程序C/C++程序类似，通过命令行给gdb指定一个要调试的目标程序的时候，该程序会以子进程的方式运行，gdb作为Tracer attach到应用程序上来对应用程序进行控制。类似gdb，sentry也以类似的方式启动应用程序，只是sentry先启动了一个stub，然后让stub以它的子进程方式启动了应用程序。 应用程序被创建并变为Tracee后，接下来就是sentry如何完成应用程序的启动流程了。 启动应用程序 应用程序被初始attach到sentry后，sentry负责启动应用程序。 在操作系统启动应程序场景里，应用程序的二进制文件由操作系统加载，譬如分配虚拟内存空间用来存放二进制中的代码段、数据段、共享库或者初始化应用程序的栈空间。gVisor启动应用程序的场景下，类似的过程由sentry完成： 为了了解sentry是如何初始化应用程序的虚拟内存空间，需要先了解一下上文提到的stub进程。 Stub进程的一个重要的作用是作为应用程序的初始模板，以该模板创建应用程序。事实上stub作为sentry的子进程，在启动后会主动将虚拟内存地址空间里几乎所有的memory region（通过查看/proc/${pid}/maps查看一个进程虚拟内存地址空间里的所有memory region）甚至将代码段和数据段也unmmap掉了。只保留两个memory region：其中第一个region存放了最简化的代码，即上图中第一个段，执行该代码甚至不需要栈空间，所以连栈段也被unmap掉了。 这样的空洞的虚拟内容地址空间正好可以作为一个模板虚拟内存地址空间。当stub以子进程的方式启动应用程序后，应用程序的虚拟内存地址空间的layout与stub的一样。应用程序在创建出来后会立即被sentry attach，此时正是sentry做应用程序初始化的过程：sentry初始设置应用程序的RIP（指令执行寄存器）的初始值为应用程序二进制中读出来的应用程序入口地址，该地址一般位于应用程序虚拟地址空间的较低位置，并通过PTRACE_SYSEMU指示应用程序开始执行，直到遇到以下两种事件的时候进入stop状态： 将要执行一个系统调用 收到了来自内核或者进程发给它的信号 因为应用程序的初始执行位置在用户态的虚拟内存地址里没有对应的memory region，所以应用程序会收到来自内核发来的SIGSEGV信号（段错误）。这里的场景非常类似通常的page fault，当一个应用程序试图访问的地址位于某个虚拟内存地址段内，但该段没有对应物理内存页的时候，操作系统会因此陷入page fault，在page fault的handler中为该虚拟内存地址段映射物理页。 事实上，在sentry在启动应用程序运行环境之前，已经应用程序“分配”了一个虚拟内存地址段（这个分配并不是使用mmap或者brk真正的在应用程序的虚拟地址空间中分配地址段，该分配是一个提前占位）。上面说到当应用程序执行指令地址上因为没有实际分配虚拟内存地址段，所以收到来自内核的SIGSEGV，并且进入stopped状态，此时sentry会通过mmap在该地址上真实分配一个虚拟地址内存段（类比操作系统为虚拟内存地址段上分配物理页），并且因为mmap的源文件是二进制文件本身，所以当sentry在处理完SIGSEGV指示应用程序继续执行的后，应用程序将实际执行到该二进制中的代码。 至此应用程序就已经启动起来了。接下来需要了解就是sentry如何控制应用程序的执行了。 应用程序的执行 应用程序被启动起来后，在执行的过程中可能会陆续遇到新的SIGSEGV（譬如程序读写地址段，或者栈空间的扩展），或者执行系统调用。 在“应用程序如何被启动”里实际上已经描述了SIGSEGV信号处理的一种场景，即只读地址且有映射文件的场景，其他的场景譬如匿名地址段或者栈空间的区别在于该地址段没有mmap实际的文件，而是mmap了一个sentry提前准备好的“空白”文件中。 在“gVisor如何拦截系统调用”中描述了系统调用的拦截，当应用程序在进入系统调用之前会自动进入stopped状态，此时sentry读取应用程序的系统调用号以及系统调用入参，试图模拟该系统调用。以文件的读sys_read为例，sys_read的作用是找到指定的文件，打开并读取文件内容，并将内存写入到应用程序系统调用参数指定的虚拟内存地址上。Sentry在接到这个的系统调用时，会将文件读取请求通过9p协议发给之前提到的gofer进程（sentry和gofer之间有建立socket pair传输9p协议），由gofer进程执行真正的文件读取且将读到的内容通过9p协议返回给sentry。sentry把读取到的文件内容写入到应用程序的虚拟内存中（如果该地址没有对应的虚拟内存地址段，则分配后再复制），随后sentry将系统调用的实际模拟结果写入到应用程序的寄存器中，然后让应用程序继续执行。恢复执行后的应用程序因为得到了系统调用的结果，所以在应用程序在分不清实际上系统调用是直接由操作系统执行了还是由sentry做的模拟的情况下，系统调用得到了满足。 应用程序的访问控制 “应用程序的执行”中对于文件读系统调用处理的描述实际上也描述了对应用程序文件系统访问的控制，实际上在“应用程序启动”中为了省略的根文件系统挂载的描述，在根文件系统挂载的模拟中也涉及到了通过9p协议对文件系统的访问。文件写的处理也非常类似。 除了文件读写外，还有很多其他的系统调用，譬如共享内存或其他IPC，锁，创建线程或者进程，发送信号，socket，execv，epoll，eventfd，pid namespace等，gVisor都进行了模拟，涉及到了操作系统的方方面面。这里仅仅介绍了socket相关的系统调用： Sentry在用户态实现了基本的TCP/IP协议栈，在启动应用程序之前，gVisor会启动一个临时的start进程，在start进程会进入到docker创建的network namespace，start进程从该network namespace中获取veth pair中属于gVisor的一端的veth设备，创建AF_PACKET的socket绑定到该veth设备上来接管该设备上的网络流量（同时也将ip从该设备上去掉了），并将该socket传递给sentry进程。后续当sentry截获了应用程序的socket系统调用后，最终通过该socket将网络包实际从veth设备上发送出去；从该veth设备上接收到的网络包在经过sentry网络协议栈后递交给应用程序的socket层。 gVisor当前缺少资源限制 gVisor具备沙盒的能力，但是缺少Cgroup提供的资源使用量的限制的功能。在官方的Roadmap中计划提供Cgroup支持。但此时为了能够使用gVisor运行工作负载，需要让gVisor具备资源使用量限制的功能。 Docker通过Runtime支持资源使用量限制，gVisor则是Docker的另外一个Runtime名叫runsc。通过了解Docker原生的Runtime即runC，可以为gVisor中支持Cgroup提供思路。Docker通过OCI（Open Containers Initiative）spec跟Runtime之间进行交互，符合该标准的Runtime可以通过Docker的命令来启动。OCI spec里规范了应用程序启动资源使用量的限制的描述，Docker在启动Runtime的时候，将OCI spec内容传递给Runtime，由Runtime负责给应用程序应用这些资源限制： runC由docker shim启动，首先会创建一个init进程，该进程最终会通过execv转变为我们希望启动的应用程序，在init进程执行execv之前，runC会为init进程创建Cgroup，将实际上init进程放入到该Cgroup中。此后init进程通过execv变为应用程序，应用程序以及后来由它创建的子进程也都会进入到该Cgroup中，从而达到资源限制的功能。 gVisor的启动流程中类似也可以嵌入类似的逻辑：runsc启动流程中首先会创建gofer和boot进程，在boot进程真正启动应用程序之前，runsc为boot进程创建新的Cgroup，并将boot进程放入到该Cgroup中，后续boot进程以及被它Ptrace的应用程序就都会处于该Cgroup中，从而达到资源限制的效果。 版权声明：本文为CSDN博主「Docker_」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/M2l0ZgSsVc7r69eFdTj/article/details/82754587 "},"notes/rust_入门_brief.html":{"url":"notes/rust_入门_brief.html","title":"入门系列","keywords":"","body":"我在学习rust语法过程中的笔记, 大部分来自于网上摘录, 略有更改. "},"notes/rust_books.html":{"url":"notes/rust_books.html","title":"reference books","keywords":"","body":"参考书目: 文档汇总: https://www.rust-lang.org/learn 语法: https://doc.rust-lang.org/book 语法参考: https://doc.rust-lang.org/reference 标准库: https://doc.rust-lang.org/std/index.html 例子: https://doc.rust-lang.org/stable/rust-by-example cargo: https://doc.rust-lang.org/stable/cargo rustup: https://rust-lang.github.io/rustup 交叉编译: https://rust-lang.github.io/rustup/cross-compilation.html "},"notes/rust_入门1.html":{"url":"notes/rust_入门1.html","title":"安装和基础语法","keywords":"","body":" 安装 组件 rustup hello world 基础语法 格式化输出 语法糖 变量 类型推导 默认只读 变量遮蔽 类型别名 全局变量 基本数据类型 指针 什么是Box 什么是Rc 类型转换 字符串 复合数据类型 tuple 元组 数组 数组切片 字符串切片 非字符串切片 索引和边界检查 struct 部分初始化 输出结构体 tuple struct 元组结构体 举例 结构体方法 结构体关联函数 普遍方法 静态方法 enum enum和match 经常出现的Option就是一种enum if let代替match 表达式 if else if let和while let 循环 函数 发散函数Diverging functions main函数 const_fn trait 默认trait trait做参数 匿名trait Box impl trait for trait 为别人的类型实现trait trait不能做为参数, 返回值, 实例变量 调用trait 方法和函数没有本质不同? trait约束 trait继承 derive 常见trait 带关联类型的trait 模式解构 match ref和mut 知晓变量类型 方案一: 利用编译错误来获取变量类型 方案二: 使用标准库 方案三: 不需要nightly版本 问号操作符 问号操作背后 安装 使用rustup安装: curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh 安装了如下的文件: $ ls /home/yingjieb/.rustup downloads settings.toml tmp toolchains update-hashes $ ls /home/yingjieb/.cargo bin env $ ls /home/yingjieb/.cargo/bin cargo cargo-fmt clippy-driver rustc rustfmt rust-lldb cargo-clippy cargo-miri rls rustdoc rust-gdb rustup 在/home/yingjieb/.profile增加了 . \"$HOME/.cargo/env\" 在/home/yingjieb/.bashrc增加了 . \"$HOME/.cargo/env\" 这个env主要就是干了一件事: export PATH=\"$HOME/.cargo/bin:$PATH\" 组件 默认安装了如下组件: cargo 5.7 MiB clippy rust-docs rust-std 34.9 MiB rustc 74.2 MiB rustfmt 如果是在你的CI环境下只想用rustc来编译, 可以指定profile为minimal 比如 ## install RUST ARG RUST_TOOLCHAIN=\"1.60.0\" RUN mkdir $CARGO_HOME && chmod 777 $CARGO_HOME RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --profile minimal --default-toolchain \"$RUST_TOOLCHAIN\" \\ && rustup target add x86_64-unknown-linux-musl --toolchain \"$RUST_TOOLCHAIN\" \\ && rustup component add rustfmt \\ && rustup component add clippy rustup rustup是管理rust工具链的工具: $ rustup -V rustup 1.24.3 (ce5817a94 2021-05-31) info: This is the version for the rustup toolchain manager, not the rustc compiler. info: The currently active `rustc` version is `rustc 1.59.0 (9d1b2106e 2022-02-23) hello world $ cat hello.rs fn main() { println!(\"hello world!\"); } $ rustc hello.rs yingjieb@godev-server /repo/yingjieb/rust/practice $ ls hello hello.rs yingjieb@godev-server /repo/yingjieb/rust/practice $ ./hello hello world! yingjieb@godev-server /repo/yingjieb/rust/practice $ file hello hello: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=ae53c8a4def1de8266d96cfe6dc8d8074ffa1d2b, with debug_info, not stripped $ llh hello -rwxr-xr-x 1 yingjieb platform 3.5M Mar 23 02:59 hello yingjieb@godev-server /repo/yingjieb/rust/practice $ ldd hello linux-vdso.so.1 (0x00007ffce327e000) libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fe769517000) librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fe76930f000) libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fe7690f0000) libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fe768eec000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fe768afb000) /lib64/ld-linux-x86-64.so.2 (0x00007fe769979000) $ strip hello yingjieb@godev-server /repo/yingjieb/rust/practice $ llh total 300K -rwxr-xr-x 1 yingjieb platform 295K Mar 23 03:05 hello -rw-r--r-- 1 yingjieb platform 44 Mar 23 02:59 hello.rs 可以看到编译出来的hello可执行程序达到3.5M, 而且还动态链接了c库. strip后是295K. 这个大小正常 $ size -A hello hello : section size addr .interp 28 624 .note.ABI-tag 32 652 .note.gnu.build-id 36 684 .gnu.hash 28 720 .dynsym 1800 752 .dynstr 1232 2552 .gnu.version 150 3784 .gnu.version_r 224 3936 .rela.dyn 16776 4160 .rela.plt 96 20936 .init 23 21032 .plt 80 21056 .plt.got 8 21136 .text 217583 21152 .fini 9 238736 .rodata 20335 238752 .eh_frame_hdr 3772 259088 .eh_frame 21392 262864 .gcc_except_table 2972 284256 .tdata 40 2384528 .tbss 57 2384576 .init_array 16 2384576 .fini_array 8 2384592 .data.rel.ro 9280 2384600 .dynamic 576 2393880 .got 1696 2394456 .data 56 2396160 .bss 456 2396216 .comment 41 0 .debug_aranges 37632 0 .debug_pubnames 401408 0 .debug_info 785107 0 .debug_abbrev 3086 0 .debug_line 413191 0 .debug_frame 96 0 .debug_str 1057897 0 .debug_pubtypes 144 0 .debug_ranges 514768 0 Total 3512131 实际上是debug信息占了绝大部分size. 基础语法 用//或/**/来注释 函数声明fn Foo( input1 : i32, input2 : u32) -> i32 { ... } 局部变量声明使用let关键字开头，用双引号包含起来的部分是字符串常量 分号结尾 最简单的标准输出是使用println！宏来完成. println后面的感叹号，它代表这是一个宏，而不是一个函数。 代码组织: crate: 类似项目概念 mod: 类似namespace概念 std: 标准库. 编译器会为用户写的每个crate自动插入一句话 use std::prelude::*; 函数可以在使用的位置后面声明 格式化输出 fn main() { println!(\"{}\", 1); // 打印变量的默认格式 println!(\"{:o}\", 9); // 八进制 println!(\"{:x}\", 255); // 十六进制 小写 println!(\"{:X}\", 255); // 十六进制 大写 println!(\"{:p}\", &0); // 指针 println!(\"{:b}\", 15); // 二进制 println!(\"{:e}\", 10000f32); // 科学计数(小写) println!(\"{:E}\", 10000f32); // 科学计数(大写) println!(\"{:?}\", \"test\"); // 打印Debug println!(\"{:#?}\", (\"test1\", \"test2\")); // 带换行和缩进的Debug打印 println!(\"{a} {b} {b}\", a = \"x\", b = \"y\"); // 命名参数 } 从属于std::fmt模块, 这些是宏可以做编译时检查, 最终是调用std::io里面的函数输出. 语法糖 ..表示rangefn main() { let r = 1..10; // r是一个Range,中间是两个点,代表[1,10)这个区间 for i in r { print!(\"{:?}\\t\", i); } } 两个小数点的语法仅仅是一个“语法糖”而已，用它构造出来的变量 是Range类型use std::ops::Range; fn main() { let r = Range { start: 1, end: 10 }; // r是一个Range for i in r { print!(\"{:?}\\t\", i); } } 这个类型本身实现了Iterator trait，因此它可以直接应用到循环语句中。Range具有迭代器的全部功能，因此它能调用迭代器的成员方法。fn main() { use std::iter::Iterator; // 先用rev方法把这个区间反过来,然后用map方法把每个元素乘以10 let r = (1i32..11).rev().map(|i| i * 10); for i in r { print!(\"{:?}\\t\", i); } } 左闭右开: start..end 左闭右闭: start..=end 变量 Rust的变量必须先声明后使用, 变量必须初始化, 不初始化会报错。对于局部变量，最常见的声明语法为： let variable : i32 = 100; 类型推导 变量类型可以推导: let x = 5; 而且类型推导比较强大: fn main() { // 没有明确标出变量的类型,但是通过字面量的后缀, // 编译器知道elem的类型为u8 let elem = 5u8; // 创建一个动态数组,数组内包含的是什么元素类型可以不写 let mut vec = Vec::new(); vec.push(elem); // 到后面调用了push函数,通过elem变量的类型, // 编译器可以推导出vec的实际类型是 Vec println!(\"{:?}\", vec); } 我们甚至还可以只写一部分类型，剩下的部分让编译器去推导，比如下面的这个程序，我们只知道players变量是Vec动态数组类型，但是里面包含什么元素类型并不清楚，可以在尖括号中用下划线来代替： fn main() { let player_scores = [ (\"Jack\", 20), (\"Jane\", 23), (\"Jill\", 18), (\"John\", 19), ]; // players 是动态数组,内部成员的类型没有指定,交给编译器自动推导 let players : Vec = player_scores .iter() .map(|&(player, _score)| { player }) .collect(); println!(\"{:?}\", players); } 默认只读 默认变量是只读的, 重新赋值会出错: fn main() { let x = 5; x = 10; //编译错误: re-assignment of immutable variable`x` } 加mut关键字才能可写: let mut x = 5; // mut x: i32 x = 10; 按照我的理解, 第一次赋值叫变量绑定, 后面再修改需要加mut fn test(condition: bool) { let x: i32; // 声明 x,不必使用 mut 修饰 if condition { x = 1; // 初始化 x,不需要 x 是 mut 的,因为这是初始化,不是修改 println!(\"{}\", x); } // 如果条件不满足,x 没有被初始化 // 但是没关系,只要这里不使用 x 就没事 } 类型没有“默认构造函数”，变量没有“默认值”。对于let x：i32；如果没有显式赋值，它就没有被初始化，不要想当然地以为它的值是0。编译器会做变量检查, 没有\"绑定\"的使用会报错. 变量遮蔽 比如 fn main() { let x = \"hello\"; println!(\"x is {}\", x); let x = 5; println!(\"x is {}\", x); } 第二个let x中的x把前面的x遮蔽了, 这两个x是两个变量, 类型和在内存里的空间都不一样; 前面的x实际上从此不能再次被访问到 变量遮蔽在类型转换, 改变变量读写属性时很有用: // 注意：这段代码只是演示变量遮蔽功能,并不是Vec类型的最佳初始化方法 fn main() { let mut v = Vec::new(); // v 必须是mut修饰,因为我们需要对它写入数据 v.push(1); v.push(2); v.push(3); let v = v; // 从这里往下,v成了只读变量,可读写变量v已经被遮蔽,无法再访问 for i in &v { println!(\"{}\", i); } } 反过来也行 fn main() { let v = Vec::new(); //v是不可变的 let mut v = v; //这个v可变, 这个v和上面的v已经不是一个v了 v.push(1); println!(\"{:?}\", v); } 类型别名 type Age = u32; fn grow(age: Age, year: u32) -> Age { age + year } fn main() { let x : Age = 20; println!(\"20 years later: {}\", grow(x, 20)); } 或者用在泛型场景里: type Double = (T, Vec); // 小括号包围的是一个 tuple,请参见后文中的复合数据类型 // 那么以后使用Double的时候，就等同于（i32，Vec） 全局变量 比如: static GLOBAL: i32 = 0; 全局变量必须是静态变量 全局变量必须在声明的时候马上初始化 全局变量的初始化必须是编译期可确定的常量，不能包括执行期才能确定的表达式、语句和函数调用// 这样是允许的 static array : [i32; 3] = [1,2,3]; // 这样是不允许的 static vec : Vec = { let mut v = Vec::new(); v.push(1); v }; 但使用const fn是可以的:#![feature(const_fn)] fn main() { use std::sync::atomic::AtomicBool; static FLAG: AtomicBool = AtomicBool::new(true); } 带有mut修饰的全局变量，在使用的时候必须使用unsafe关键字 fn main() { //局部变量声明,可以留待后面初始化,只要保证使用前已经初始化即可 let x; let y = 1_i32; x = 2_i32; println!(\"{} {}\", x, y); //全局变量必须声明的时候初始化,因为全局变量可以写到函数外面,被任意一个函数使用 static G1 : i32 = 3; println!(\"{}\", G1); //可变全局变量无论读写都必须用 unsafe修饰 static mut G2 : i32 = 4; unsafe { G2 = 5; println!(\"{}\", G2); } //全局变量的内存不是分配在当前函数栈上,函数退出的时候,并不会销毁全局变量占用的内存空间,程序退出才会回收 } 基本数据类型 boolfn main() { let x = true; let y: bool = !x; // 取反运算 let z = x && y; // 逻辑与,带短路功能 println!(\"{}\", z); let z = x || y; // 逻辑或,带短路功能 println!(\"{}\", z); let z = x & y; // 按位与,不带短路功能 println!(\"{}\", z); let z = x | y; // 按位或,不带短路功能 println!(\"{}\", z); let z = x ^ y; // 按位异或,不带短路功能 println!(\"{}\", z); } charlet love = '❤'; // 可以直接嵌入任何 unicode 字符 let c1 = '\\n'; // 换行符 let c2 = '\\x7f'; // 8 bit 字符变量 let c3 = '\\u{7FFF}'; // unicode字符 因为char类型的设计目的是描述任意一个unicode字符，因此它占据的内存空间不是1个字节，而是4个字节 用u8或者前面加b前缀来表示1个字节的ASCII字符let x :u8 = 1; let y :u8 = b'A'; let s :&[u8;5] = b\"hello\"; let r :&[u8;14] = br#\"hello \\n world\"#; //这里表示byte的raw string, 好像去掉前后的#也行 注意这里的b\"hello\"和\"hello\"不一样:fn print_type_of(t: &T) { println!(\"{:#?}: {}\", t, std::any::type_name::()) } fn main() { print_type_of(&\"hello\"); print_type_of(&b\"hello\"); } //结果 \"hello\": &str [ 104, 101, 108, 108, 111, ]: &[u8; 5] 整型 用i或者u加位位宽表示, 比如i32 u64 i128等. 指针用isize或者usize表示, 在32位机器上是32位, 在64位机器上是64位.let var1 : i32 = 32; // 十进制表示 let var2 : i32 = 0xFF; // 以0x开头代表十六进制表示 let var3 : i32 = 0o55; // 以0o开头代表八进制表示 let var4 : i32 = 0b1001; // 以0b开头代表二进制表示 let var5 = 0x_1234_ABCD; //使用下划线分割数字,不影响语义,但是极大地提升了阅读体验。 let var6 = 123usize; // i6变量是usize类型 let var7 = 0x_ff_u8; // i7变量是u8类型 let var8 = 32; // 不写类型,默认为 i32 类型 rust可以在整型溢出时panic, 但需要\"debug\"版本编译, 比如rustc test.rs, 而rustc -O test.rs产生的\"release\"版本则不会panic, 而是自动截断. 通过开关rustc -C overflow-checks=no test.rs可以控制这个行为. 浮点let f1 = 123.0f64; // type f64 let f2 = 0.1f64; // type f64 let f3 = 0.1f32; // type f32 let f4 = 12E+99_f64; // type f64 科学计数法 let f5 : f64 = 2.; // type f64 指针 类型名 简介 Box 指向类型T的, 具有所有权的指针, 有权释放内存; T在堆中分配 &T 指向类型T的借用指针, 也称为引用, 无权释放内存, 无权写数据 &mut T 指向类型T的mut借用指针, 无权释放内存, 有权写数据 *const T 指向类型T的只读指针, 没有生命周期信息, 无权写数据 *mut T 指向类型T的读写指针, 没有生命周期信息, 有权写数据 注: &T是借用指针, 而*T实际上也存在的, 叫raw pointer. 但是必须以*mut T或*const T存在. 一般raw pointer不常用. 除此之外，在标准库中还有一种封装起来的可以当作指针使用的类型，叫“智能指针”（smart pointer） 类型名 简介 Rc 指向类型T的引用计数指针, 共享所有权, 线程不安全 Arc 指向类型T的原子引用计数指针, 共享所有权, 线程安全 Cow clone on write, 写时复制指针. 可能是借用指针, 也可能是具有所有权的指针 什么是Box Box是指向堆中类型为T的变量的指针. 这个T可以是unsized的. All values in Rust are stack allocated by default. Values can be boxed (allocated on the heap) by creating a Box. A box is a smart pointer to a heap allocated value of type T. When a box goes out of scope, its destructor is called, the inner object is destroyed, and the memory on the heap is freed. 默认变量是分配在栈上的, 用Box可以指定分配到堆上. 除了在堆上分配内存, Box没有其他的性能损失. 比如下面的代码: fn main() { let b = Box::new(5); //在堆中分配int32类型的5, Box这个\"指针\"是在栈上. 当b离开scope的时候, 堆上的数字5会被回收. println!(\"b = {}\", b); } 这个例子在堆里分配一个i32并没有实际意义, 只是演示Box的分配原理. Box的使用情况: When you have a type whose size can’t be known at compile time and you want to use a value of that type in a context that requires an exact size When you have a large amount of data and you want to transfer ownership but ensure the data won’t be copied when you do so 在堆里分配的数据在转移所有权的时候不拷贝. When you want to own a value and you care only that it’s a type that implements a particular trait rather than being of a specific type 什么是Rc To enable multiple ownership, Rust has a type called Rc, which is an abbreviation for reference counting. The Rc type keeps track of the number of references to a value to determine whether or not the value is still in use. If there are zero references to a value, the value can be cleaned up without any references becoming invalid. We use the Rc type when we want to allocate some data on the heap for multiple parts of our program to read and we can’t determine at compile time which part will finish using the data last. 比如b和c都\"拥有\"a这个链表 如果用Box是不行的: enum List { Cons(i32, Box), Nil, } use crate::List::{Cons, Nil}; fn main() { let a = Cons(5, Box::new(Cons(10, Box::new(Nil)))); let b = Cons(3, Box::new(a)); let c = Cons(4, Box::new(a)); // 当a move进b的时候, 所有权已经转给b了. a就不能再访问了. } The Cons variants own the data they hold, so when we create the b list, a is moved into b and b owns a. Then, when we try to use a again when creating c, we’re not allowed to because a has been moved. 下面的代码把Box换成了Rc Instead, we’ll change our definition of List to use Rc in place of Box, as shown in Listing 15-18. Each Cons variant will now hold a value and an Rc pointing to a List. When we create b, instead of taking ownership of a, we’ll clone the Rc that a is holding, thereby increasing the number of references from one to two and letting a and b share ownership of the data in that Rc. We’ll also clone a when creating c, increasing the number of references from two to three. Every time we call Rc::clone, the reference count to the data within the Rc will increase, and the data won’t be cleaned up unless there are zero references to it. enum List { Cons(i32, Rc), Nil, } use crate::List::{Cons, Nil}; use std::rc::Rc; fn main() { let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); let b = Cons(3, Rc::clone(&a)); //这里是clone应该只是clone包装, 而不是clone里面的数据, 但增加引用计数. let c = Cons(4, Rc::clone(&a)); } 注: 用Rc::clone(&a)和a.clone()是一样的. 前者更隐含了是浅拷贝的意思, 开销非常小. 类型转换 Rust对不同类型之间的转换控制得非常严格。即便是下面这样的程序，也会出现编译错误 fn main() { let var1 : i8 = 41; let var2 : i16 = var1; } Rust提供了一个关键字as，专门用于这样的类型转换 fn main() { let var1 : i8 = 41; let var2 : i16 = var1 as i16; } 类型不能随便转换: let a = \"some string\"; let b = a as u32; // 编译错误 有时必须用多个as转换 fn main() { let i = 42; // 先转为 *const i32,再转为 *mut i32 let p = &i as *const i32 as *mut i32; println!(\"{:p}\", p); } 字符串 Rust的字符串涉及两种类型，一种是&str，另外一种是String.str是Rust的内置类型。&str是对str的借用。Rust的字符串内部默认是使用utf-8编码格式的。而内置的char类型是4字节长度的，存储的内容是Unicode Scalar Value。所以，Rust里面的字符串不能视为char类型的数组，而更接近u8类型的数组. [T]是DST类型，对应的str是DST类型。 &[T]是数组切片类型，对应的&str是字符串切片类型.下面的代码能编过 &str是个胖指针, 它对指向的字符串没有所有权. let greeting : &str = \"Hello\"; fn main() { let greeting: &str = \"Hello\"; let substr: &str = &greeting[2..]; println!(\"{}\", substr); } &greeting[2..]去掉&就编译不过 我们没办法扩大greeting所引用的范围，在它后面增加内容。但是String类型可以: fn main() { let mut s = String::from(\"Hello\"); s.push(' '); s.push_str(\"World.\"); println!(\"{}\", s); } &String类型可以被编译器自动转换为&str类型: fn capitalize(substr: &mut str) { substr.make_ascii_uppercase(); } fn main() { let mut s = String::from(\"Hello World\"); capitalize(&mut s); println!(\"{}\", s); } 在这个例子中，capitalize函数调用的时候，形式参数要求是&mut str类型，而实际参数是&mut String类型，这里编译器给我们做了自动类型转换。在capitalize函数内部，它有权修改&mut str所指向的内容，但是无权给这个字符串扩容或者释放内存。 复合数据类型 tuple 元组 用一对 () 包括的一组数据，可以包含不同种类的数据 let a = (1i32, false); // 元组中包含两个元素,第一个是i32类型,第二个是bool类型 let b = (\"a\", (1i32, 2i32)); // 元组中包含两个元素,第二个元素本身也是元组,它又包含了两个元素 只有一个元素要加逗号 let a = (0,); // a是一个元组,它有一个元素 let b = (0); // b是一个括号表达式,它是i32类型 访问tuple可以用模式匹配 let p = (1i32, 2i32); let (a, b) = p; //模式匹配 let x = p.0; //数字索引 let y = p.1; //数字索引 println!(\"{} {} {} {}\", a, b, x, y); 空元组占用0内存空间: let empty : () = (); fn main() { println!(\"size of i8 {}\" , std::mem::size_of::()); println!(\"size of char {}\" , std::mem::size_of::()); println!(\"size of '()' {}\" , std::mem::size_of::()); } 注: size_of的原型是 pub const fn size_of() -> usize 这个函数没有入参, 但需要实例化类型参数T 本例中这样调用: std::mem::size_of::() 用了双冒号实例化类型参数的方式. 数组 用一对 [] 包括的同类型数据数组是一个容器，它在一块连续空间内存中，存储了一系列的同样类型的数据。数组中元素的占用空间大小必须是编译期确定的。数组本身所容纳的元素个数也必须是编译期确定的，执行阶段不可变。如果需要使用变长的容器，可以使用标准库中的Vec/LinkedList等。数组类型的表示方式为[T;n]。其中T代表元素类型；n代表元素个数；它必须是编译期常量整数；中间用分号隔开。 let a = [1, 2, 3, 4, 5]; // a 是一个长度为 5 的整型数组 let b = [\"January\", \"February\", \"March\"]; // b 是一个长度为 3 的字符串数组 let c: [i32; 5] = [1, 2, 3, 4, 5]; // c 是一个长度为 5 的 i32 数组 let d = [3; 5]; // 等同于 let d = [3, 3, 3, 3, 3]; let first = a[0]; let second = a[1]; // 数组访问 a[0] = 123; // 错误：数组 a 不可变 let mut a = [1, 2, 3]; a[0] = 4; // 正确 只有元素类型和元素个数都完全相同，这两个数组才是同类型的。数组与指针之间不能隐式转换。同类型的数组之间可以互相赋值 fn main() { let mut xs: [i32; 5] = [1, 2, 3, 4, 5]; let ys: [i32; 5] = [6, 7, 8, 9, 10]; xs = ys; xs[0] = 111; println!(\"new array {:?}\", xs); println!(\"old array {:?}\", ys); } //output new array [111, 7, 8, 9, 10] old array [6, 7, 8, 9, 10] 把数组xs作为参数传给一个函数，这个数组并不会退化成一个指针。而是会将这个数组完整复制进这个函数。函数体内对数组的改动不会影响到外面的数组。 这里再解释一下, rust的数组赋值(或者说是move), 是拷贝完整数组. rust默认在栈上分配变量, 如果想在退出作用域的时候继续使用数据, 用Box来声明变量. 数组可以直接比较: fn main() { let v1 = [1, 2, 3]; let v2 = [1, 2, 4]; println!(\"{:?}\", v1 数组支持for in fn main() { let v = [0_i32; 10]; for i in &v { println!(\"{:?}\", i); } } 数组切片 对数组取借用borrow操作，可以生成一个“数组切片”（Slice）。数组切片对数组没有“所有权”，我们可以把数组切片看作专门用于指向数组的指针，是对数组的另外一个“视图”。比如，我们有一个数组[T; n]，它的借用指针的类型就是&[T; n]。它可以通过编译器内部魔法转换为数组切片类型&[T]。数组切片实质上还是指针，它不过是在类型系统中丢弃了编译阶段定长数组类型的长度信息，而将此长度信息存储为运行期的值。示例如下: fn main() { fn mut_array(a: &mut [i32]) { a[2] = 5; } println!(\"size of &[i32; 3] : {:?}\", std::mem::size_of::()); println!(\"size of &[i32] : {:?}\", std::mem::size_of::()); let mut v: [i32; 3] = [1, 2, 3]; { let s: &mut [i32; 3] = &mut v; mut_array(s); } println!(\"{:?}\", v); } 变量v是[i32; 3]类型；变量s是&mut[i32; 3]类型，占用的空间大小与指针相同。它可以自动转换为&mut[i32]数组切片类型传入函数 mut_array，占用的空间大小等于两个指针的空间大小。通过这个指针，在函数内部，修改了外部的数组v的值。 数组切片是指向一个数组的指针，而它比指针又多了一点东西——它不止包含有一个指向数组的指针，切片本身还含带长度信息。又叫胖指针.由于不定长数组类型[T]在编译阶段是无法判断该类型占用空间的大小的，目前我们不能在栈上声明一个不定长大小数组的变量实例，也不能用它作为函数的参数、返回值。但是，指向不定长数组的胖指针的大小是确定的，&[T]类型可以用做变量实例、函数参数、返回值。 字符串切片 fn main() { let s = String::from(\"broadcast\"); let part1 = &s[0..5]; let part2 = &s[5..9]; println!(\"{}={}+{}\", s, part1, part2); } // broadcast=broad+cast 非字符串切片 fn main() { let arr = [1, 3, 5, 7, 9]; let part = &arr[0..3]; for i in part.iter() { println!(\"{}\", i); } } 索引和边界检查 rust的索引是会边界检查的. 如果越界会panic 数组的index操做执行的是下面的代码: impl ops::Index for [T] { type Output = T; fn index(&self, index: usize) -> &T { assert!(index 实际上, 自己也可以定义index操做, 只要满足 std::ops::Index trait //索引读操做 std::ops::IndexMut trait //索引写操做 一般情况下，Rust不鼓励大量使用“索引”操作。正常的“索引”操作 都会执行一次“边界检查”。从执行效率上来说，Rust比C/C++的数组索引效率低一点，因为C/C++的索引操作是不执行任何安全性检查的，它们对应的Rust代码相当于调用get_unchecked()函数更推荐使用迭代器 fn main() { use std::iter::Iterator; let v = &[10i32, 20, 30, 40, 50]; // 如果我们同时需要index和内部元素的值,调用enumerate()方法 for (index, value) in v.iter().enumerate() { println!(\"{} {}\", index, value); } // filter方法可以执行过滤,nth函数可以获取第n个元素 let item = v.iter().filter(|&x| *x % 2 == 0).nth(2); println!(\"{:?}\", item); } 注: filter的原型如下, 可以看到闭包的入参是引用&Self::Item fn filter(self, predicate: P) -> Filter where Self: Sized, P: FnMut(&Self::Item) -> bool, { Filter::new(self, predicate) } FnMut原型如下, 闭包都会自动实现FnMut. pub trait FnMut: FnOnce { extern \"rust-call\" fn call_mut( &mut self, args: Args ) -> Self::Output; } struct 普通结构体定义: struct Site { domain: String, name: String, nation: String, found: u32 } 普通结构体实例化: let runoob = Site { domain: String::from(\"www.runoob.com\"), name: String::from(\"RUNOOB\"), nation: String::from(\"China\"), found: 2013 }; 举例: struct Point { x: i32, y: i32, } fn main() { let p = Point { x: 0, y: 0}; println!(\"Point is at {} {}\", p.x, p.y); } fn main() { // 刚好局部变量名字和结构体成员名字一致 let x = 10; let y = 20; // 下面是简略写法,等同于 Point { x: x, y: y },同名字的相对应 let p = Point { x, y }; println!(\"Point is at {} {}\", p.x, p.y); } 访问struct内部的元素: fn main() { let p = Point { x: 0, y: 0}; // 声明了px 和 py,分别绑定到成员 x 和成员 y let Point { x : px, y : py } = p; println!(\"Point is at {} {}\", px, py); // 同理,在模式匹配的时候,如果新的变量名刚好和成员名字相同,可以使用简写方式 let Point { x, y } = p; println!(\"Point is at {} {}\", x, y); } 部分初始化 Rust设计了一个语法糖，允许用一种简化的语法赋值使用另外一个 struct的部分成员。比如： struct Point3d { x: i32, y: i32, z: i32, } fn default() -> Point3d { Point3d { x: 0, y: 0, z: 0 } } // 可以使用default()函数初始化其他的元素 // ..expr 这样的语法,只能放在初始化表达式中,所有成员的最后最多只能有一个 let origin = Point3d { x: 5, ..default()}; let point = Point3d { z: 1, x: 2, ..origin }; 输出结构体 调试中，完整地显示出一个结构体实例是非常有用的。但如果我们手动的书写一个格式会非常的不方便。所以 Rust 提供了一个方便地输出一整个结构体的方法： #[derive(Debug)] struct Rectangle { width: u32, height: u32, } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\"rect1 is {:?}\", rect1); } 如第一行所示：一定要导入调试库 #[derive(Debug)] ，之后在 println 和 print 宏中就可以用 {:?} 占位符输出一整个结构体： rect1 is Rectangle { width: 30, height: 50 } 如果属性较多的话可以使用另一个占位符 {:#?} rect1 is Rectangle { width: 30, height: 50 } tuple struct 元组结构体 有一种更简单的定义和使用结构体的方式：元组结构体。 元组结构体是一种形式是元组的结构体。 与元组的区别是它有名字和固定的类型格式。它存在的意义是为了处理那些需要定义类型（经常使用）又不想太复杂的简单数据： struct Color(u8, u8, u8); struct Point(f64, f64); let black = Color(0, 0, 0); let origin = Point(0.0, 0.0); \"颜色\"和\"点坐标\"是常用的两种数据类型，但如果实例化时写个大括号再写上两个名字就为了可读性牺牲了便捷性，Rust不会遗留这个问题。元组结构体对象的使用方式和元组一样，通过. 和下标来进行访问： fn main() { struct Color(u8, u8, u8); struct Point(f64, f64); let black = Color(0, 0, 0); let origin = Point(0.0, 0.0); println!(\"black = ({}, {}, {})\", black.0, black.1, black.2); println!(\"origin = ({}, {})\", origin.0, origin.1); } 举例 //以下三种都可以,内部可以没有成员: 空struct struct Foo1; struct Foo2(); struct Foo3{} // struct有名字, 但成员不用名字, 这种类型的叫tuple struct struct Color(i32, i32, i32); struct Point(i32, i32, i32); // 可以类似下面的结构体: struct Color{ 0: i32, 1: i32, 2: i32, } struct Point { 0: i32, 1: i32, 2: i32, } 举例: // define struct struct T1 { v: i32 } // define tuple struct struct T2(i32); fn main() { let v1 = T1 { v: 1 }; let v2 = T2(1); // init tuple struct let v3 = T2 { 0: 1 }; // init tuple struct let i1 = v1.v; let i2 = v2.0; let i3 = v3.0; } fn main() { struct Inches(i32); fn f1(value : Inches) {} fn f2(value : i32) {} let v : i32 = 0; f1(v); // 编译不通过,'mismatched types' f2(v); } fn type_alias() { type I = i32; fn f1(v : I) {} fn f2(v : i32) {} let v : i32 = 0; f1(v); //可以编译过, 因为type只是别名 f2(v); } 结构体方法 第一个入参是&self的函数就是这个结构体方法, 用impl块包住: struct Rectangle { width: u32, height: u32, } impl Rectangle { fn area(&self) -> u32 { self.width * self.height } } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\"rect1's area is {}\", rect1.area()); } //结果 //rect1's area is 1500 请注意，在调用结构体方法的时候不需要填写 self ，这是出于对使用方便性的考虑。 结构体关联函数 impl块里面的没有用&self的函数就是关联函数, 使用的时候要加这个结构体的前缀:: #[derive(Debug)] struct Rectangle { width: u32, height: u32, } impl Rectangle { fn create(width: u32, height: u32) -> Rectangle { Rectangle { width, height } } } fn main() { let rect = Rectangle::create(30, 50); println!(\"{:?}\", rect); } //结果 //Rectangle { width: 30, height: 50 } 普遍方法 在Rust中，我们可以为任何一个类型添加方法，整型也不例外。比如在标准库中，整数类型有一个方法是pow，它可以计算n次幂，于是我们可以这么使用： let x : i32 = 9; println!(\"9 power 3 = {}\", x.pow(3)); println!(\"9 power 3 = {}\", 9_i32.pow(3)); //也可以直接使用字面量来调用方法 静态方法 没有receiver参数的方法（第一个参数不是self参数的方法）称作“静态方法”。静态方法可以通过Type::FunctionName()的方式调用。 需要注意的是，即便我们的第一个参数是Self相关类型，只要变量名字不是self，就不能使用小数点的语法调用函数。 struct T(i32); impl T { // 这是一个静态方法 fn func(this: &Self) { println!{\"value {}\", this.0}; } } fn main() { let x = T(42); // x.func(); 小数点方式调用是不合法的 T::func(&x); } trait也可以定义静态函数: pub trait Default { fn default() -> Self; } Default trait实际上可以看作一个针对无参数构造函数的统一抽象 impl Default for Vec { fn default() -> Vec { Vec::new() } } enum 枚举类在 Rust 中并不像其他编程语言中的概念那样简单，但依然可以十分简单的使用： #[derive(Debug)] enum Book { Papery, Electronic } fn main() { let book = Book::Papery; println!(\"{:?}\", book); } // 结果 // Papery 书分为纸质书（Papery book）和电子书（Electronic book）。 如果你现在正在开发一个图书管理系统，你需要描述两种书的不同属性（纸质书有索书号，电子书只有 URL），你可以为枚举类成员添加元组属性描述： enum Book { Papery(u32), Electronic(String), } let book = Book::Papery(1001); let ebook = Book::Electronic(String::from(\"url://...\")); 如果你想为属性命名，可以用结构体语法： enum Book { Papery { index: u32 }, Electronic { url: String }, } let book = Book::Papery{index: 1001}; 虽然可以如此命名，但请注意，并不能像访问结构体字段一样访问枚举类绑定的属性。访问的方法在 match 语法中。 enum有或的意思, 下面的Number就是或者是Int, 或者是Float enum Number { Int(i32), Float(f32), } fn read_num(num: &Number) { match num { // 如果匹配到了 Number::Int 这个成员,那么value的类型就是 i32 &Number::Int(value) => println!(\"Integer {}\", value), // 如果匹配到了 Number::Float 这个成员,那么value的类型就是 f32 &Number::Float(value) => println!(\"Float {}\", value), } } fn main() { let n: Number = Number::Int(10); read_num(&n); } 在Rust中，enum和struct为内部成员创建了新的名字空间。如果要访问内部成员，可以使用::符号 enum Message { Quit, ChangeColor(i32, i32, i32), Move { x: i32, y: i32 }, Write(String), } let x: Message = Message::Move { x: 3, y: 4 }; enum BoardGameTurn { Move { squares: i32 }, Pass, } let y: BoardGameTurn = BoardGameTurn::Move { squares: 1 }; enum和match Rust 通过 match 语句来实现分支结构。先认识一下如何用 match 处理枚举类： fn main() { enum Book { Papery {index: u32}, Electronic {url: String}, } let book = Book::Papery{index: 1001}; let ebook = Book::Electronic{url: String::from(\"url...\")}; match book { Book::Papery { index } => { println!(\"Papery book {}\", index); }, Book::Electronic { url } => { println!(\"E-book {}\", url); } } } // 结果 //Papery book 1001 match 块也可以当作函数表达式来对待，它也是可以有返回值的： match 枚举类实例 { 分类1 => 返回值表达式, 分类2 => 返回值表达式, ... } 但是所有返回值表达式的类型必须一样！ 如果把枚举类附加属性定义成元组，在 match 块中需要临时指定一个名字： enum Book { Papery(u32), Electronic {url: String}, } let book = Book::Papery(1001); match book { Book::Papery(i) => { println!(\"{}\", i); }, Book::Electronic { url } => { println!(\"{}\", url); } } 经常出现的Option就是一种enum enum Option是个标准库里经常用到的类型, 已经被preclude了, 不用use能直接用: enum Option { None, Some(T), } 它表示的含义是“要么存在、要么不存在”。比如Option表达的意思 就是“可以是一个i32类型的值，或者没有任何值”。 Rust引入Option是为了解决Null指针问题 如果你想定义一个可以为空值的类，你可以这样： let opt = Option::Some(\"Hello\"); // 这个opt的类型是core::option::Option 如果你想针对 opt 执行某些操作，你必须先判断它是否是 Option::None： fn main() { let opt = Option::Some(\"Hello\"); match opt { Option::Some(something) => { println!(\"{}\", something); }, Option::None => { println!(\"opt is nothing\"); } } } //结果 //Hello 由于 Option 是 Rust 编译器默认引入的，在使用时可以省略 Option:: 直接写 None 或者 Some()。 fn main() { let t = Some(64); match t { Some(64) => println!(\"Yes\"), _ => println!(\"No\"), } } 总结一下: 如果从逻辑上说，我们需要一个变量确实是可空的，那么就应该显式标明其类型为Option，否则应该直接声明为T类型。从类型系 统的角度来说，这二者有本质区别，切不可混为一谈 不要轻易使用unwrap方法。这个方法可能会导致程序发生 panic。对于小工具来说无所谓，在正式项目中，最好是使用lint工具强制禁止调用这个方法 相对于裸指针，使用Option包装的指针类型的执行效率不会降低，这是“零开销抽象” 不必担心这样的设计会导致大量的match语句，使得程序可读性变差。因为Option类型有许多方便的成员函数，再配合上闭包功能，实际上在表达能力和可读性上要更胜一筹 if let代替match match需要强制做全匹配, 否则会编译报错. 用下划线可以解决编译错误, 但有点笨. 用if let可以更好的表达只关心一部分匹配的情况: if let 匹配值 = 源变量 { 语句块 } 比如 let i = 0; if let 0 = i { println!(\"zero\"); } 更完整的例子: fn main() { enum Book { Papery(u32), Electronic(String) } let book = Book::Electronic(String::from(\"url\")); if let Book::Papery(index) = book { println!(\"Papery {}\", index); } else { println!(\"Not papery book\"); } } 表达式 小知识: ! 按位取反或者逻辑取反, 按照operand类型决定Rust不支持++、--运算符，请使用+=1、-=1替代 rust里面每个表达式都是有类型的, 比如赋值表达式的类型为空的tuple (), 也叫unit fn main() { let x = 1; let mut y = 2; // 注意这里专门用括号括起来了 let z = (y = x); println!(\"{:?}\", z); //编译有警告, 但能运行, 结果为() } 连续语句块的类型是最后一个表达式的类型: // 语句块可以是表达式,注意后面有分号结尾,x的类型是() let x : () = { println!(\"Hello.\"); }; // Rust将按顺序执行语句块内的语句,并将最后一个表达式类型返回,y的类型是 i32 let y : i32 = { println!(\"Hello.\"); 5 }; 利用这个特点, 函数的返回可以不写return fn my_func() -> i32 { // ... blablabla 各种语句 100 //最后一个表达式是100, 是i32. 注意没有分号 } if else fn func(i : i32) { if n 0 { print!(\"{} is positive\", n); } else { print!(\"{} is zero\", n); } } if else也可以当作表达式: let x : i32 = if condition { 1 } else { 10 }; //注意1和10后面不加分号. 因为加了分号表达式的整体类型就变了 if let和while let while-let与if-let一样，提供了在while语句中使用“模式解构”的能力 if let Some(x) = optVal { doSomethingWith(x); } 相当于: match optVal { Some(x) => { doSomethingWith(x); } _ => {} } 也相当于: if optVal.is_some() { // 首先判断它一定是 Some(_) let x = optVal.unwrap(); // 然后取出内部的数据 doSomethingWith(x); } 循环 loop 没条件注意break和continue都可以跳转到外层 我们可以在loop while for循环前面加上“生命周期标识符”。该标识符以单引号开头，在内部的循环中可以使用break语句选择跳出到哪一层。 fn main() { // A counter variable let mut m = 1; let n = 1; 'a: loop { if m 50 { println!(\"break\"); break 'a; } else { continue 'a; } } } } } loop表达式也可以做右值: fn main() { let v = loop { break 10; }; println!(\"{}\", v); } 在loop内部break的后面可以跟一个表达式，这个表达式就是最终的 loop表达式的值。如果一个loop永远不返回，那么它的类型就是“发散类型”。示例如下： fn main() { let v = loop {}; println!(\"{}\", v); //永远到不了这里 } while是带条件的循环 for in是迭代器循环. 没有三段式的语法 函数 fn add1(t : (i32,i32)) -> i32 { t.0 + t.1 } // 模式解构传参 fn add2((x,y) : (i32,i32)) -> i32 { x + y //也可以用return x+y } 函数不写返回类型默认是unit () 函数是一等公民 函数内部可以定义函数, 类型, trait等 虽然add1和add2的入参和出参都一样, 但每个函数都有自己的类型fn main() { // 先让 func 指向 add1 let mut func = add1; // 再重新赋值,让 func 指向 add2 func = add2; //这样不行, 会编译报错. 原因就是函数名也是类型的一部分 } 上面的func声明改成下面的写法就不会出错了:// 写法一,用 as 类型转换 let mut func = add1 as fn((i32,i32))->i32; // 写法二,用显式类型标记 let mut func : fn((i32,i32))->i32 = add1; 但只有add1和add2形式一样的时候才行. 形式不同不能转换. 发散函数Diverging functions 返回类型是!的函数是发散函数, 比如: fn diverges() -> ! { panic!(\"This function never returns!\"); } !可以转换为任何类型 let x : i32 = diverges(); let y : String = diverges(); 比如下面的情况就很有用: let p = if x { panic!(\"error\"); } else { 100 }; 上面的代码能编译通过, 因为!也可以赋值给p 内置发散函数: panic! 以及基于它实现的各种函数/宏，比如unimplemented! unreachable! 死循环loop{} 进程退出函数std::process::exit以及类似的libc中的exec一类函数 main函数 main函数没有入参和返回值, 命令行参数用std::env::args() fn main() { for arg in std::env::args() { println!(\"Arg: {}\", arg); } std::process::exit(0); } const_fn 函数可以用const关键字修饰，这样的函数可以在编译阶段被编译器执行，返回值也被视为编译期常量 #![feature(const_fn)] const fn cube(num: usize) -> usize { num * num * num } fn main() { const DIM : usize = cube(2); const ARR : [i32; DIM] = [0; DIM]; println!(\"{:?}\", ARR); } trait trait的意思是特性 初看和go的interface差不多. trait Shape { fn area(&self) -> f64; } Rust中Self（大写S）和self（小写s）都是关键字，大写S的是类型名，小写s的是变量名 所有的trait中都有一个隐藏的类型Self（大写S），代表当前这个实现了此trait的具体类型 trait T { fn method1(self: Self); fn method2(self: &Self); fn method3(self: &mut Self); } // 上下两种写法是完全一样的 trait T { fn method1(self); fn method2(&self); fn method3(&mut self); } 上面定义的这个area方法的参数的名字为self，它的类型是&Self类型。我们可以把上面这个方法的声明看成： trait Shape { fn area(self: &Self) -> f64; } 假如我们有一个结构体类型Circle，它实现了这个trait，代码如下: struct Circle { radius: f64, } impl Shape for Circle { // Self 类型就是 Circle // self 的类型是 &Self,即 &Circle fn area(&self) -> f64 { // 访问成员变量,需要用 self.radius std::f64::consts::PI * self.radius * self.radius } } fn main() { let c = Circle { radius : 2f64}; // 第一个参数名字是 self,可以使用小数点语法调用 println!(\"The area is {}\", c.area()); } 默认trait 这是特性与接口的不同点：接口只能规范方法而不能定义方法，但特性可以定义方法作为默认方法，因为是\"默认\"，所以对象既可以重新定义方法，也可以不重新定义方法使用默认的方法 trait中可以包含方法的默认实现。如果这个方法在trait中已经有了方法体，那么在针对具体类型实现的时候，就可以选择不用重写 trait Descriptive { fn describe(&self) -> String { String::from(\"[Object]\") } } struct Person { name: String, age: u8 } impl Descriptive for Person { fn describe(&self) -> String { format!(\"{} {}\", self.name, self.age) } } fn main() { let cali = Person { name: String::from(\"Cali\"), age: 24 }; println!(\"{}\", cali.describe()); } //结果 //Cali 24 如果Person不实现describe, 则最后打印 [Object] trait做参数 fn output(object: impl Descriptive) { println!(\"{}\", object.describe()); } 任何实现了 Descriptive 特性的对象都可以作为这个函数的参数，这个函数没必要了解传入对象有没有其他属性或方法，只需要了解它一定有 Descriptive 特性规范的方法就可以了。当然，此函数内也无法使用其他的属性与方法。 特性参数还可以用这种等效语法实现： fn output(object: T) { println!(\"{}\", object.describe()); } 这是一种风格类似泛型的语法糖，这种语法糖在有多个参数类型均是特性的情况下十分实用： fn output_two(arg1: T, arg2: T) { println!(\"{}\", arg1.describe()); println!(\"{}\", arg2.describe()); } 特性作类型表示时如果涉及多个特性，可以用 + 符号表示，例如： fn notify(item: impl Summary + Display) fn notify(item: T) 复杂的实现关系可以使用 where 关键字简化，例如： fn some_function(t: T, u: U) 可以简化成: fn some_function(t: T, u: U) -> i32 where T: Display + Clone, U: Clone + Debug 匿名trait 针对一个类型，我们可以直接对它impl来增加成员方法，无须trait名字。比如： impl Circle { fn get_radius(&self) -> f64 { self.radius } } 我们可以把这段代码看作是为Circle类型impl了一个匿名的trait。用这种方式定义的方法叫作这个类型的“内在方法”（inherent methods）。 Box trait Shape { fn area(self: Box) -> f64; } struct Circle { radius: f64, } impl Shape for Circle { // Self 类型就是 Circle // self 的类型是 Box,即 Box fn area(self : Box) -> f64 { // 访问成员变量,需要用 self.radius std::f64::consts::PI * self.radius * self.radius } } fn main() { let c = Circle { radius : 2f64}; // 编译错误 // c.area(); let b = Box::new(Circle {radius : 4f64}); // 编译正确 b.area(); } impl trait for trait 语法: impl for Rust 同一个类可以实现多个特性，每个 impl 块只能实现一个。 trait Shape { fn area(&self) -> f64; } trait Round { fn get_radius(&self) -> f64; } struct Circle { radius: f64, } impl Round for Circle { fn get_radius(&self) -> f64 { self.radius } } // 注意这里是 impl Trait for Trait impl Shape for dyn Round { fn area(&self) -> f64 { std::f64::consts::PI * self.get_radius() * self.get_radius() } } fn main() { let c = Circle { radius : 2f64}; // 编译错误 // c.area(); // let b = Circle { radius : 2f64} as dyn Round; //这样也不行, error[E0620]: cast to unsized type: `Circle` as `dyn Round` let b = Box::new(Circle {radius : 4f64}) as Box; // 编译正确 b.area(); } 注: 以上代码在edition2021编译不过, 需要在Round前面加dyn关键词(已加)加了以后上面代码能编过, 但有个变量c没有使用的警告. 为别人的类型实现trait 比如下面的代码就给内置类型i32实现了Double方法: trait Double { fn double(&self) -> Self; } impl Double for i32 { fn double(&self) -> i32 { *self * 2 } } fn main() { // 可以像成员方法一样调用 let x : i32 = 10.double(); println!(\"{}\", x); } 要给别人的类型添加方法, 需要满足下面的条件:impl块要么与trait的声明在同一个的crate中，要么与类型的声明在同一个crate中 trait不能做为参数, 返回值, 实例变量 参数, 返回值, 实例变量等需要明确知道size的地方不能直接用trait.Rust是一种用户可以对内存有精确控制能力的强类型语言。我们可以自由指定一个变量是在栈里面，还是在堆里面，变量和指针也是不同的类型。类型是有大小（Size）的。有些类型的大小是在编译阶段可以确定的，有些类型的大小是编译阶段无法确定的。目前版本的Rust规定，在函数参数传递、返回值传递等地方，都要求这个类型在编译阶段有确定的大小。否则，编译器就不知道该如何生成代码了。 而trait本身既不是具体类型，也不是指针类型，它只是定义了针对类型的、抽象的“约束”。不同的类型可以实现同一个trait，满足同一个trait的类型可能具有不同的大小。因此，trait在编译阶段没有固定大小，目前我们不能直接使用trait作为实例变量、参数、返回值。 下面的代码是不对的: let x: Shape = Circle::new(); // Shape 不能做局部变量的类型 fn use_shape(arg : Shape) {} // Shape 不能直接做参数的类型 fn ret_shape() -> Shape {} // Shape 不能直接做返回值的类型 调用trait trait Cook { fn start(&self); } trait Wash { fn start(&self); } struct Chef; impl Cook for Chef { fn start(&self) { println!(\"Cook::start\"); } } impl Wash for Chef { fn start(&self) { println!(\"Wash::start\"); } } fn main() { let me = Chef; me.start(); //这里编不过, 因为两个trait都有start方法 } //应该用下面的格式来调用: fn main() { let me = Chef; // 函数名字使用更完整的path来指定,同时,self参数需要显式传递 // 下面两种格式都可以 ::start(&me); ::start(&me); } 方法的点引用是语法糖: 和go一样, 通过小数点语法调用方法调用，有一个“隐藏着”的“取引用”步骤。虽然我们看起来源代码长的是这个样子 me.start()，但是大家心里要清楚，真正传递给start()方法的参数是 &me而不是me，这一步是编译器自动帮我们做的。不论这个方法接受的self参数究竟是Self、&Self还是&mut Self，最终在源码上，我们都是统一的写法：variable.method() 方法和函数没有本质不同? struct T(usize); impl T { fn get1(&self) -> usize { self.0 } fn get2(&self) -> usize { self.0 } } fn get3(t: &T) -> usize { t.0 } fn check_type(_: fn(&T) -> usize) {} fn main() { check_type(T::get1); check_type(T::get2); check_type(get3); } 可以看到，get1、get2和get3都可以自动转成fn（&T）-> usize类型 trait约束 use std::fmt::Debug; fn my_print(x: T) { println!(\"The value is {:?}.\", x); } fn main() { my_print(\"China\"); my_print(41_i32); my_print(true); my_print(['a', 'b', 'c']) } 上面的代码能编过, 是因为my_print需要泛型T满足Debug约束(因为使用了{:?}), 而字符串, i32, bool, 数组都实现了Debug trait. 如果一个自定义类型没有实现Debug trait, 编译就会报错. 上面的约束还可以写成: fn my_print(x: T) where T: Debug { println!(\"The value is {:?}.\", x); } trait继承 实现Derived trait的struct也被要求实现Base trait trait Base {} trait Derived : Base {} //等同于trait Derived where Self：Base{} struct T; impl Derived for T {} impl Base for T {} //需要再加上这句 fn main() { ... } derive derive是个特殊的编译指示: #[derive(Copy, Clone, Default, Debug, Hash, PartialEq, Eq, PartialOrd, Ord)] struct Foo { data: i32, } fn main() { let v1 = Foo { data: 0 }; let v2 = v1; println!(\"{:?}\", v2); } 意思是编译器会自动生成如下的代码: impl Copy for Foo { ... } impl Clone for Foo { ... } impl Default for Foo { ... } impl Debug for Foo { ... } impl Hash for Foo { ... } impl PartialEq for Foo { ... } ... 从而让Foo能够继承列表里的trait. 能够被derive的trait有: Debug Clone Copy Hash RustcEncodable RustcDecodable PartialEq Eq ParialOrd Ord Default FromPrimitive Send Sync 常见trait 只有实现了Display trait的类型，才能用{}格式控制打印出来；只有实现了Debug trait的类型，才能用{:?} {:#?}格式控制打印出来 // std::fmt::Display pub trait Display { fn fmt(&self, f: &mut Formatter) -> Result; } // std::fmt::Debug pub trait Debug { fn fmt(&self, f: &mut Formatter) -> Result; } 带关联类型的trait 标准库中有一个trait叫FromStr，它有一个关联类型代表错误： pub trait FromStr { type Err; fn from_str(s: &str) -> Result; } 如果某些类型调用from_str方法永远不会出错，那么这个Err类型可以指定为! use std::mem::{size_of, size_of_val}; use std::str::FromStr; struct T(String); impl FromStr for T { type Err = !; fn from_str(s: &str) -> Result { Ok(T(String::from(s))) } } fn main() { let r: Result = T::from_str(\"hello\"); println!(\"Size of T: {}\", size_of::()); println!(\"Size of Result: {}\", size_of_val(&r)); // 将来甚至应该可以直接用 let 语句进行模式匹配而不发生编译错误 // 因为编译器有能力推理出 Err 分支没必要存在 // let Ok(T(ref s)) = r; // println!(\"{}\", s); } 模式解构 struct T1(i32, char); struct T2 { item1: T1, item2: bool, } fn main() { let x = T2 { item1: T1(0, 'A'), item2: false, }; let T2 { item1: T1(value1, value2), item2: value3, } = x; //从x解构出value1, value2, value3; 后者直接就当变量用了 println!(\"{} {} {}\", value1, value2, value3); } 下划线用来占位: struct P(f32, f32, f32); fn calc(arg: P) -> f32 { // 匹配 tuple struct,但是忽略第二个成员的值 let P(x, _, y) = arg; x * x + y * y } fn main() { let t = P(1.0, 2.0, 3.0); println!(\"{}\", calc(t)); } match rust的match初看和switch case意思差不多: enum Direction { East, West, South, North, } fn print(x: Direction) { match x { Direction::East => { println!(\"East\"); } Direction::West => { println!(\"West\"); } Direction::South => { println!(\"South\"); } Direction::North => { println!(\"North\"); } } } fn main() { let x = Direction::East; print(x); } 但match更严格, 比如我们删除North分支, 编译会报错. 解决办法就是把不需要的分支用_覆盖: fn print(x: Direction) { match x { Direction::East => { println!(\"East\"); } Direction::West => { println!(\"West\"); } Direction::South => { println!(\"South\"); } _ => { println!(\"Other\"); } } } 类似的, 下面的match如果没有下划线那个分支, 也是编译不过的: fn category(x: i32) { match x { -1 => println!(\"negative\"), 0 => println!(\"zero\"), 1 => println!(\"positive\"), _ => println!(\"error\"), } } fn main() { let x = 1; category(x); } match还支持|操做和..范围操做: fn category(x: i32) { match x { -1 | 1 => println!(\"true\"), 0 => println!(\"false\"), _ => println!(\"error\"), } } fn main() { let x = 1; category(x); } let x = 'X'; match x { 'a' ..= 'z' => println!(\"lowercase\"), 'A' ..= 'Z' => println!(\"uppercase\"), _ => println!(\"something else\"), } match还支持在分支内加if判断: match x { OptionalInt::Value(i) if i > 5 => println!(\"Got an int bigger than five!\"), OptionalInt::Value(..) => println!(\"Got an int!\"), OptionalInt::Missing => println!(\"No such luck.\"), } fn intersect(arg: i32) { match arg { i if i println!(\"case 1\"), i if i println!(\"case 2\"), i if i * i println!(\"case 3\"), _ => println!(\"default case\"), } } 还可以用@绑定变量. @符号前面是新声明的变量，后面是需要匹配的模式： let x = 1; match x { e @ 1 ..= 5 => println!(\"got a range element {}\", e), _ => println!(\"anything\"), } ref和mut ref: 引用, 避免出现所有权转移 mut: 借用 let mut x: &mut i32; 以上两处的mut含义是不同的。第1处mut，代表这个变量x本身可变，因此它能够重新绑定到另外一个变量上去，具体到这个示例来说，就是指针的指向可以变化。第2处mut，修饰的是指针，代表这个指针对于所指向的内存具有修改能力，因此我们可以用*x=1;这样的语句，改变它所指向的内存的值。 知晓变量类型 方案一: 利用编译错误来获取变量类型 // 这个函数接受一个 unit 类型作为参数 fn type_id(_: ()) {} fn main() { let ref x = 5_i32; // 实际参数的类型肯定不是 unit,此处必定有编译错误,通过编译错误,我们可以看到实参的具体类型 type_id(x); } 方案二: 使用标准库 #![feature(core_intrinsics)] fn print_type_name(_arg: &T) { unsafe { println!(\"{}\", std::intrinsics::type_name::()); } } fn main() { let ref x = 5_i32; print_type_name(&x); } 比如要知道下面的变量类型: let x = 5_i32; // i32 let x = &5_i32; // &i32 let ref x = 5_i32; // ??? let ref x = &5_i32; // ??? 代码: #![feature(core_intrinsics)] fn print_type_name(_arg: &T) { println!(\"{}\", std::intrinsics::type_name::()); } fn main() { let x = 5_i32; print_type_name(&x); //i32 let x = &5_i32; print_type_name(&x); //&i32 let ref x = 5_i32; print_type_name(&x); //&i32 let ref x = &5_i32; print_type_name(&x); //&&i32 } 注: 上面代码只能在debug优化模式和nightly channel下编译通过 方案三: 不需要nightly版本 fn print_type_of(_: &T) { println!(\"{}\", std::any::type_name::()) } 问号操作符 用在Result或Option后面, 用于提前返回或者unwrap value用在Result上, 可以提前返回Err(From::from(e)); 没有Error时则unwrap返回T fn try_to_parse() -> Result { let x: i32 = \"123\".parse()?; // x = 123 let y: i32 = \"24a\".parse()?; // returns an Err() immediately Ok(x + y) // Doesn't run. } let res = try_to_parse(); println!(\"{:?}\", res); 用在Option上, 可以提前返回None; 有值则unwrap返回T: fn try_option_some() -> Option { let val = Some(1)?; Some(val) } assert_eq!(try_option_some(), Some(1)); fn try_option_none() -> Option { let val = None?; Some(val) } assert_eq!(try_option_none(), None); 问号操作背后 代码rust/library/core/src/ops/try_trait.rs 问号operator背后是Try这个trait pub trait Try: FromResidual { type Output; type Residual; fn from_output(output: Self::Output) -> Self; fn branch(self) -> ControlFlow; } "},"notes/rust_入门2.html":{"url":"notes/rust_入门2.html","title":"泛型和内存所有权","keywords":"","body":" 宏 泛型 结构体的泛型 结构体泛型的具化 枚举的泛型 泛型参数可以有默认值 函数中的泛型 泛型实现重载 重载需要判断类型 impl块中的泛型 泛型的约束 关联类型 trait for trait 泛型的方法 内存安全 生命周期 生命周期标记 类型的生命周期标记 省略生命周期标记 所有权 所有权规则 数据赋值和拷贝 所有权与函数 返回值与作用域 println不会发生所有权转移(move) Rc允许多个所有权拥有者 引用和借用 copy和clone 析构函数 mut和&mut 借用指针 为什么rust是内存安全的? 解引用 自定义解引用 常见指针类型 自动解引用 Rc的自动解引用 引用计数 cow 智能指针 其他 在方法里定义struct是可以的 文件打开 unsafe unsafe可以操作裸指针 不用unsafe的swap例子 标准库的swap Vec代码 宏 比如打印当前文件和行号: fn main() { println!(\"file {} line {} \", file!(), line!()); } 比如避免重复: add_impl! { usize u8 u16 u32 u64 isize i8 i16 i32 i64 f32 f64 } 比如初始化一个动态数组: let v = vec![1, 2, 3, 4, 5]; 泛型 max函数的入参是泛型T的数组 fn max(array: &[T]) -> T { let mut max_index = 0; let mut i = 1; while i array[max_index] { max_index = i; } i += 1; } array[max_index] } 结构体的泛型 struct Point { x: T, y: T } 可以这样用: let p1 = Point {x: 1, y: 2}; let p2 = Point {x: 1.0, y: 2.0}; 但这样不行: let p = Point {x: 1, y: 2.0}; x 与 1 绑定时就已经将 T 设定为 i32，所以不允许再出现 f64 的类型。如果我们想让 x 与 y 用不同的数据类型表示，可以使用两个泛型标识符： struct Point { x: T1, y: T2 } 结构体泛型的具化 可以让编译器自动推断, 也可以指定类型, 在左侧和右侧都可以, 但在右侧不支持S的语法: fn print_type_of(_: &T) { println!(\"{}\", std::any::type_name::()) } struct S { data: T, } fn main() { //let four: u32 = \"4\".parse(); //println!(\"{:?}\", four); let x = S { data: 6 }; //编译器自动推断 let y = S { data: 5.5 }; //编译器自动推断 let y1: S = S { data: 5.5 }; //声明y1是S let y2: S:: = S { data: 5.5 }; //声明y2是S:: //let y3 = S {data: 5.5}; //NOK, 编译不过, 编译器认为<>是大于小于号. 据说是编译器图简单 let y3 = S:: { data: 5.5 }; //显式实例化y3, 在右侧只能用双冒号 print_type_of(&x); print_type_of(&y); print_type_of(&y1); print_type_of(&y2); print_type_of(&y3); print_type_of(&\"4\".parse::()); } //结果 playground::S playground::S playground::S playground::S playground::S core::result::Result 枚举的泛型 比如 enum Option { Some(T), None, } 这里的实际上是声明了一个“类型”参数。在这个Option内部，Some(T)是一个tuple struct，包含一个元素类型为T。这个泛型参数类型T，可以在使用时指定具体类型。 使用的时候: let x: Option = Some(42); let y: Option = None; 泛型参数可以有默认值 比如下面的泛型T默认是i32 struct S { data: T } fn main() { let v1 = S { data: 0}; let v2 = S:: { data: false}; println!(\"{} {}\", v1.data, v2.data); } 函数中的泛型 比如: fn compare_option(first: Option, second: Option) -> bool { match(first, second) { (Some(..), Some(..)) => true, (None, None) => true, _ => false } } 注:Some(..)中的双点表示ignore全部, Some(_)表示ignore第一个参数. 再举例: fn largest(list: &[T]) -> &T { let mut largest = &list[0]; for item in list.iter() { if item > largest { largest = item; } } largest } fn main() { let number_list = vec![34, 50, 25, 100, 65]; let result = largest(&number_list); println!(\"The largest number is {}\", result); let char_list = vec!['y', 'm', 'a', 'q']; let result = largest(&char_list); println!(\"The largest char is {}\", result); } //结果 The largest number is 100 The largest char is y 泛型实现重载 比如str的contains方法就接受不同类型的参数: fn main() { let s = \"hello\"; println!(\"{}\", s.contains('a')); println!(\"{}\", s.contains(\"abc\")); println!(\"{}\", s.contains(&['H'] as &[char])); println!(\"{}\", s.contains(|c : char| c.len_utf8() > 2)); } 这个contains的签名是: fn contains>(&'a self, pat: P) -> bool 第二个参数pat是个泛型P, 只要满足Pattern trait, 就能被contains所用. 重载需要判断类型 下面的代码编译不过, 因为let f = i.convert();中, 编译器无法知道f的类型, 于是无法推断出应该调用哪个. trait ConvertTo { fn convert(&self) -> T; } impl ConvertTo for i32 { fn convert(&self) -> f32 { *self as f32 } } impl ConvertTo for i32 { fn convert(&self) -> f64 { *self as f64 } } fn main() { let i = 1_i32; let f = i.convert(); // 这里编译不过 println!(\"{:?}\", f); } 要这样改: let f : f32 = i.convert(); // 或者 let f = ConvertTo::::convert(&i); impl块中的泛型 可以impl 某个trait for type, 也可以为trait impl trait. 即trait for trait. 这个impl trait for trait比如: impl Into for T where U: From, { fn into(self) -> U { U::from(self) } } 泛型的约束 下面的代码编译不通过: fn max(a: T, b: T) -> T { if a 因为并不是所有类型都实现了比较操作, 那么泛型T没有约束的话, 是编译不过的. 加约束有两个写法: 冒号方式 use std::cmp::PartialOrd; // 第一种写法：在泛型参数后面用冒号约束 fn max(a: T, b: T) -> T { where语法 // 第二种写法,在后面单独用 where 子句指定 fn max(a: T, b: T) -> T where T: PartialOrd where语法灵活性更好: trait Iterator { type Item; // Item 是一个关联类型 // 此处的where子句没办法在声明泛型参数的时候写出来 fn max(self) -> Option where Self: Sized, Self::Item: Ord, { ... } ... } 它要求Self类型满足Sized约束，同时关联类型Self::Item要满足Ord约束，这是用冒号语法写不出来的。 比较泛型的完整代码: use std::cmp::Ordering; use std::cmp::PartialOrd; fn max(a: T, b: T) -> T where T: PartialOrd, { if a Option { self.value.partial_cmp(&other.value) } } impl PartialEq for T { fn eq(&self, other: &T) -> bool { self.value == other.value } } fn main() { let t1 = T { value: 1 }; let t2 = T { value: 2 }; let m = max(t1, t2); } 注意由于标准库中的PartialOrd继承了PartialEq，因此单独实现PartialOrd 还是会产生编译错误，必须同时实现PartialEq才能编译通过。 关联类型 trait中不仅可以包含方法（包括静态方法）、常量，还可以包含“类型”。 比如迭代器中的Item就是个关联类型, 关联类型也必须指定才能实例化. pub trait Iterator { type Item; ... } 可以看到，我们希望参数是一个泛型迭代器，可以在约束条件中写Iterator。跟普通泛型参数比起来，关联类型参数必须使用名字赋值的方式。 use std::fmt::Debug; use std::iter::Iterator; fn use_iter(mut iter: ITER) where ITER: Iterator, ITEM: Debug, { while let Some(i) = iter.next() { println!(\"{:?}\", i); } } fn main() { let v: Vec = vec![1, 2, 3, 4, 5]; use_iter(v.iter()); } 也可以将ITEM ITER简化为一个, 因为满足ITER: Iterator, 就可以继续声明其关联类型需要满足的约束ITER::Item: Debug use std::fmt::Debug; use std::iter::Iterator; fn use_iter(mut iter: ITER) where ITER: Iterator, ITER::Item: Debug, { while let Some(i) = iter.next() { println!(\"{:?}\", i); } } fn main() { let v: Vec = vec![1, 2, 3, 4, 5]; use_iter(v.iter()); } trait for trait 下面的例子中, 为一个泛型T, 实现了ToString trait pub trait ToString { fn to_string(&self) -> String; } impl ToString for T { #[inline] fn to_string(&self) -> String { use core::fmt::Write; let mut buf = String::new(); let _ = buf.write_fmt(format_args!(\"{}\", self)); buf.shrink_to_fit(); buf } } 凡是实现了这个trait的类型，都可以调用to_string来得到一个String 类型的结果。同时，标准库中还存在一个std::fmt::Display trait， 也可以做到类似的事情。而且Display是可以通过#[derive（Display）]由 编译器自动实现的。所以，我们可以想到，针对所有满足T: Display的类型，我们可以为它们提供一个统一的实现. 泛型的方法 struct Point { x: T, y: T, } //注意下面的第一个是类型声明, 第二个是\"实例化\"这个Point, 虽然是用泛型来\"实例化\" //所以写成这样也可以的: impl Point:: { impl Point { fn x(&self) -> &T { &self.x } } fn main() { let p = Point { x: 1, y: 2 }; println!(\"p.x = {}\", p.x()); } 内存安全 生命周期 fn main() { let v = vec![1, 2, 3, 4, 5]; // --> v 的生命周期开始 { let center = v[2]; // --> center 的生命周期开始 println!(\"{}\", center); } // 生命周期标记 引用往往导致极其复杂的资源管理问题，首先认识一下垂悬引用： { let r; { let x = 5; r = &x; } println!(\"r: {}\", r); } 这段代码是不会通过 Rust 编译器的，原因是 r 所引用的值已经在使用之前被释放。上图中的绿色范围 'a 表示 r 的生命周期，蓝色范围 'b 表示 x 的生命周期。很显然，'b 比 'a 小得多，引用必须在值的生命周期以内才有效 下面的例子中 longer函数不能编译通过 fn longer(s1: &str, s2: &str) -> &str { if s2.len() > s1.len() { s2 } else { s1 } } 原因是返回值引用可能会返回过期的引用, 一般情况下, 编译器可以推导出返回值的生命周期标记, 比如函数只有唯一入参的时候; 但这里编译器不知道到底返回的引用是s1还是s2 fn main() { let r; { let s1 = \"rust\"; let s2 = \"ecmascript\"; r = longer(s1, s2); } println!(\"{} is longer\", r); } 把longer函数改成带生命周期声明的方式, 就可以成功运行了: fn longer(s1: &'a str, s2: &'a str) -> &'a str { if s2.len() > s1.len() { s2 } else { s1 } } fn main() { let r; { let s1 = \"rust\"; let s2 = \"ecmascript\"; r = longer(s1, s2); } println!(\"{} is longer\", r); //println!(\"s2: {}\", s2); } //ecmascript is longer 可以看到, r实际引用的s2, s2的内容在出了scope后还能被r引用. 但直接打印s2是不行的, 会报错误:cannot find value s2 in this scope 生命周期注释用单引号开头，跟着一个小写字母单词： &i32 // 常规引用 &'a i32 // 含有生命周期注释的引用 &'a mut i32 // 可变型含有生命周期注释的引用 'static // 特殊的生命周期标记, 表示静态, 好像是全局的意思 下面的写法是一样的: fn test(arg: &'a T) -> &'a i32 fn test(arg: &'a T) -> &'b i32 where 'a:'b //'a:'b表示'a比'b“活”得长 类型的生命周期标记 如果自定义类型中有成员包含生命周期参数，那么这个自定义类型 也必须有生命周期参数: struct Test { member: &'a str } 在使用impl的时候，也需要先声明再使用: impl Test { fn test(&self, s: &'a str) { } } 如果在泛型约束中有where T: 'a之类的条件，其意思是，类型T的所有生命周期参数必须大于等于'a。要特别说明的是，若是有where T: 'static的约束，意思则是，类型T里面不包含任何指向短生命周期的借用指针，意思是要么完全不包含任何借用，要么可以有指向'static的借用指针。 省略生命周期标记 fn get_str(s: &String) -> &str { s.as_ref() } 等同于 fn get_str(s: &'a String) -> &'a str { s.as_ref() } 所有权 下面的代码编译不过: fn main() { let s = String::from(\"hello\"); let s1 = s; println!(\"{}\", s); } 出现错误的原因是let s1 = s;导致了所有权转移, 转移后s就不能再访问了. 每个值只有一个所有者。变量s的生命周期从声明开始，到move给s1就结束了。变量s1的生命周期则是从它声明开始， 到函数结束。而字符串本身，由String::from函数创建出来，到函数结束的时候就会销毁。中间所有权的转换，并不会将这个字符串本身重新销毁再创建。在任意时刻，这个字符串只有一个所有者，要么是s， 要么是s1。 一个变量可以把它拥有的值转移给另外一个变量，称为“所有权转移”。赋值语句、函数调用、函数返回等，都有可能导致所有权转移。 Rust中的变量绑定操作，默认是move语义，执行了新的变量绑定后，原来的变量就不能再被使用！一定要记住！ 就是说rust里面的赋值语句实际上是移动语义.但是有例外: 比如下面的代码就可以编译通过: fn main() { let v1 : isize = 0; let v2 = v1; println!(\"{}\", v1); } 因为在Rust中有一部分“特殊照顾”的类型，其变量绑定操作是copy语义。实现了copy trait的类型就会在assign的时候使用copy. 所谓的copy语义，是指在执行变量绑定操作的时候，v2是对v1所属数据的一份复制。v1所管理的这块内存依然存在，并未失效，而v2是新开辟了一块内存，它的内容是从v1管理的内存中复制而来的。和手动调用clone方法效果一样，let v2=v1；等效于let v2=v1.clone() Rust中，在普通变量绑定、函数传参、模式匹配等场景下，凡是实 现了std::marker::Copy trait的类型，都会执行copy语义。基本类型，比如数字、字符、bool等，都实现了Copy trait，因此具备copy语 义。 对于自定义类型，默认是没有实现Copy trait的，但是我们可以手动添上。 要实现这个copy trait: #[derive(Copy, Clone)] struct Foo { data : i32 } fn main() { let v1 = Foo { data : 0 }; let v2 = v1; println!(\"{:?}\", v1.data); } Rust中的copy语义就是浅复制 所有权规则 Rust中的每一个值都有一个对应的变量作为它的所有者 。 在同一时间内，值有且仅有一个所有者。 Rc允许多个所有权的owner 当所有者离开自己的作用域时，它持有的值就会被释放掉。 数据赋值和拷贝 Rust永远不会自动地创 建数据的深度拷贝。因此在Rust中，任何自动的赋值操作都可以被视为高效的。 let s1 = String::from(\"hello\"); //s1在堆里 let s2 = s1; // s2是s1的浅拷贝, 同时s1失效 println!(\"{}, world!\", s1); //这里会报错, 因为所有权已经move了 //后面s2拥有对应的数据, s2退出作用域的时候, drop函数被自动调用以释放空间 但下面的代码也是对的, 因为i32有Copy trait let x = 5; let y = x; println!(\"x = {}, y = {}\", x, y); 有copy trait的类型有: 所有的整数类型，诸如u32 仅拥有两种值（true和false）的布尔类型：bool 字符类型：char 所有的浮点类型，诸如f64 如果元组包含的所有字段的类型都是Copy的，那么这个元组也 是Copy的。例如，(i32, i32)是Copy的，但(i32, String)则不是 所有权与函数 将值传递给函数在语义上类似于对变量进行赋值。将变量传递给 函数将会触发移动或复制，就像是赋值语句一样。 fn main() { let s = String::from(\"hello\"); // 变量s进入作用域 take_ownership(s); // s的值被移动进了函数 // 所以它从这里开始不再有效 let x = 5; // 变量x进入作用域 make_copy(x); // 变量x同样被传递进了函数 //但由于i32是copy的, 所以我们依然可以在这之后使用x } // x首先离开作用域, 随后是s. 但由于s的值已经发生了移动, 所以没什么特别的事情发生. fn take_ownership(some_string: String) { // some_string进入作用域 println!(\"{}\", some_string); } // some_string在这里离开作用域, 它的drop函数被自动调用, 其所占的内存也随之被释放了 fn make_copy(some_integer: i32) { // some_integer进入作用域 println!(\"{}\", some_integer); } // some_integer在这里离开了作用域, 没有什么特别的事情发生 返回值与作用域 函数在返回值的过程中也会发生所有权的转移。 fn main() { let s1 = give_ownership(); // 返回值移动至s1中 let s2 = String::from(\"hello\"); // s2进入作用域 let s3 = take_and_giveback(s2); // s2被移动进函数, 而这个函数的返回值又被移动到了s3上 } // s3在这里离开作用域并被销毁. 由于s2已经移动了, 所以它不会在离开作用域的时候发生任何事情. s1最后离开作用域并被销毁. // give_ownership 会将它的返回值移动至调用它的函数内 fn give_ownership() -> String { let some_string = String::from(\"hello\"); // some_string进入作用域 some_string // some_string做为返回值移动到调用函数 } // take_and_giveback 将取得一个String的所有权并将它做为结果返回 fn take_and_giveback(a_string: String) -> String { // a_string进入作用域 a_string // a_string做为返回值移动至调用函数 } println不会发生所有权转移(move) 因为println是宏, 比如下面的代码: fn main() { let x = 5; println!(\"{}\", x); } 用这个命令rustc -Z unstable-options --pretty expanded得到下面宏展开的代码: #![feature(prelude_import)] #[prelude_import] use std::prelude::v1::*; #[macro_use] extern crate std; fn main() { let x = 5; { ::std::io::_print(::core::fmt::Arguments::new_v1( &[\"\", \"\\n\"], &match (&x,) { (arg0,) => [::core::fmt::ArgumentV1::new( arg0, ::core::fmt::Display::fmt, )], }, )); }; } 化简后是借用传参的. use std::{fmt, io}; fn main() { let x = 5; io::_print(fmt::Arguments::new_v1( &[\"\", \"\\n\"], &[fmt::ArgumentV1::new(&x, fmt::Display::fmt)], // ^^ )); } Rc允许多个所有权拥有者 To enable multiple ownership, Rust has a type called Rc, which is an abbreviation for reference counting. The Rc type keeps track of the number of references to a value to determine whether or not the value is still in use. enum List { Cons(i32, Box), Nil, } use crate::List::{Cons, Nil}; fn main() { let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); println!(\"count after creating a = {}\", Rc::strong_count(&a)); let b = Cons(3, Rc::clone(&a)); println!(\"count after creating b = {}\", Rc::strong_count(&a)); { let c = Cons(4, Rc::clone(&a)); println!(\"count after creating c = {}\", Rc::strong_count(&a)); } println!(\"count after c goes out of scope = {}\", Rc::strong_count(&a)); } //结果 $ cargo run Compiling cons-list v0.1.0 (file:///projects/cons-list) Finished dev [unoptimized + debuginfo] target(s) in 0.45s Running `target/debug/cons-list` count after creating a = 1 count after creating b = 2 count after creating c = 3 count after c goes out of scope = 2 注: 用Rc::clone(&a)和a.clone()是一样的. 前者更隐含了是浅拷贝的意思, 开销非常小. 引用和借用 引用方式传递也叫借用, 所有权不转移. 在任何一段给定的时间里，你要么只能拥有一个可变引用，要么只能拥有任意数量的不可变引用。 引用总是有效的。 fn dangle() -> &String{ // dangle会返回一个指向String的引用 let s = String::from(\"hello\"); // s被绑定到新的String上 &s // 我们将指向s的引用返回给调用者 } // 变量s在这里离开作用域并随之被销毁, 它指向的内存自然也不再有效. // 危险! copy和clone copy是std::marker::Copy 带marker的都是特殊的trait, 编译器会有特殊处理一旦一个类型实现了Copy trait，那么它在变量绑定、函数参数传递、函数返回值传递等场景下，都是copy语义，而不再是默认的move语义。并不是所有的类型都可以实现Copy trait。Rust规定，对于自定义类型，只有所有成员都实现了Copy trait，这个类型才有资格实现Copy trait。常见的数字类型、bool类型、共享借用指针&，都是具有Copy属性的类型。而Box、Vec、可写借用指针&mut等类型都是不具备Copy属性的类型。 对于数组类型，如果它内部的元素类型是Copy，那么这个数组也是 Copy类型。 对于元组tuple类型，如果它的每一个元素都是Copy类型，那么这个 tuple也是Copy类型。 clone是std::clone::Clone pub trait Clone: Sized { fn clone(&self) -> Self; fn clone_from(&mut self, source: &Self) { *self = source.clone() } } 即使实现了clone trait的对象, 在赋值的时候也是move语义. 举例: // A unit struct without resources #[derive(Debug, Clone, Copy)] struct Unit; // A tuple struct with resources that implements the `Clone` trait #[derive(Clone, Debug)] struct Pair(Box, Box); fn main() { // Instantiate `Unit` let unit = Unit; // Copy `Unit`, there are no resources to move let copied_unit = unit; // Both `Unit`s can be used independently println!(\"original: {:?}\", unit); println!(\"copy: {:?}\", copied_unit); // Instantiate `Pair` let pair = Pair(Box::new(1), Box::new(2)); println!(\"original: {:?}\", pair); // Move `pair` into `moved_pair`, moves resources let moved_pair = pair; println!(\"moved: {:?}\", moved_pair); // Error! `pair` has lost its resources //println!(\"original: {:?}\", pair); // TODO ^ Try uncommenting this line // Clone `moved_pair` into `cloned_pair` (resources are included) let cloned_pair = moved_pair.clone(); // Drop the original pair using std::mem::drop drop(moved_pair); // Error! `moved_pair` has been dropped //println!(\"copy: {:?}\", moved_pair); // TODO ^ Try uncommenting this line // The result from .clone() can still be used! println!(\"clone: {:?}\", cloned_pair); } 总结: Copy内部没有方法，Clone内部有两个方法。 Copy trait是给编译器用的，告诉编译器这个类型默认采用copy语 义，而不是move语义。 Clone trait是给程序员用的，赋值操作还是move语义. 我们必须手动调用 clone方法，它才能发挥作用。 Copy trait不是想实现就能实现的，它对类型是有要求的，有些类型不可能impl Copy。而Clone trait则没有什么前提条件，任何类型都可以实现（unsized类型除外，因为无法使用unsized类型作为返回值） Copy trait规定了这个类型在执行变量绑定、函数参数传递、函数返回等场景下的操作方式。即这个类型在这种场景下，必然执行的 是“简单内存复制”操作，这是由编译器保证的，程序员无法控制。 Clone trait里面的clone方法究竟会执行什么操作，则是取决于程序员自己写的逻辑。一般情况下，clone方法应该执行一个“深复制”操作，但这不是强制性的，如果你愿意，在里面启动一个人工智能程序都是有可能的。 析构函数 rust没有构造函数, 但允许析构函数: 用户可以自己写满足std::ops::Drop的trait trait Drop { fn drop(&mut self); } 这个Drop会在变量声明周期结束的时候被调用. 自己调用Drop是非法的, 但可以间接调用标准库的drop函数: use std::mem::drop; fn main() { let mut v = vec![1, 2, 3]; // v的生命周期结束 v.push(4); // 错误的调用 } 其实, 标准库的drop就是入参是值传递的空函数: #[inline] pub fn drop(_x: T) { } 这里入参是值传递非常重要, 将对象的所有权移入函数中，什么都不用做，编译器就会自动释放掉这个对象了。 因为这个drop函数的关键在于使用move语义把参数传进来，使得变量的所有权从调用方移动到drop函数体内，参数类型一定要是T，而不是&T或者其他引用类型。函数体本身其实根本不重要，重要的是把变量的所有权move进入这个函数体中，函数调用结束的时候该变量的生命周期结束，变量的析构函数会自动调用，管理的内存空间也会自然释放。这个过程完全符合前面讲的生命周期、move语义，无须编译器做特殊处理。事实上，我们完全可以自己写一个类似的函数来实现同样的效果，只要保证参数传递是move语义即可。 因此, 有copy()语义的变量, 对其drop()是没有作用的, 因为这些变量是复制不是move. mut和&mut mut可以出现在绑定(=)的左右两侧 fn main() { let mut var = 0_i32; { let p1 = &mut var; // p1 指针本身不能被重新绑定,我们可以通过p1改变变量var的值 *p1 = 1; } { let temp = 2_i32; let mut p2 = &var; // 我们不能通过p2改变变量var的值,但p2指针本身指向的位置可以被改变 p2 = &temp; } { let mut temp = 3_i32; let mut p3 = &mut var; // 我们既可以通过p3改变变量var的值,而且p3指针本身指向的位置也可以改变 *p3 = 3; p3 = &mut temp; } } 借用指针 借用指针不能比它指向的变量存在的时间更长 &mut型借用只能指向本身具有mut修饰的变量，对于只读变量，不可以有&mut型借用 &mut型借用指针存在的时候，被借用的变量本身会处于“冻结”状态 如果只有&型借用指针，那么能同时存在多个；如果存在&mut型借用指针，那么只能存在一个；如果同时有其他的&或者&mut型借用指针存在，那么会出现编译错误 // 这里的参数采用的“引用传递”,意味着实参本身并未丢失对内存的管理权 fn borrow_semantics(v: &Vec) { // 打印参数占用空间的大小,在64位系统上,结果为8,表明该指针与普通裸指针的内部表示方法相同 println!(\"size of param: {}\", std::mem::size_of::>()); for item in v { print!(\"{} \", item); } println!(\"\"); } // 这里的参数采用的“值传递”,而Vec没有实现Copy trait,意味着它将执行move语义 fn move_semantics(v: Vec) { // 打印参数占用空间的大小,结果为24,表明实参中栈上分配的内存空间复制到了函数的形参中 println!(\"size of param: {}\", std::mem::size_of::>()); for item in v { print!(\"{} \", item); } println!(\"\"); } fn main() { let array = vec![1, 2, 3]; // 需要注意的是,如果使用引用传递,不仅在函数声明的地方需要使用&标记 // 函数调用的地方同样需要使用&标记,否则会出现语法错误 // 这样设计主要是为了显眼,不用去阅读该函数的签名就知道这个函数调用的时候发生了什么 // 而小数点方式的成员函数调用,对于self参数,会“自动转换”,不必显式借用,这里有个区别 borrow_semantics(&array); // 在使用引用传递给上面的函数后,array本身依然有效,我们还能在下面的函数中使用 move_semantics(array); // 在使用move语义传递后,array在这个函数调用后,它的生命周期已经完结 } 任何借用指针的存在，都会导致原来的变量被“冻结”（Frozen）: fn main() { let mut x = 1_i32; let p = &mut x; x = 2; // 因为p的存在，此时对x的改变被认为是非法的 println!(\"value of pointed : {}\", p); } 为什么rust是内存安全的? 比如c语言在迭代vector的时候, 改变vector自身, 编译的时候没问题, 但运行时会崩溃; 而rust在编译时就会报错, 因为rust的原则是: 共享不可变，可变不共享 首先我们介绍一下这两个概念Alias和Mutation。 Alias的意思是“别名”。如果一个变量可以通过多种Path来访问，那它们就可以互相看作alias。Alias意味着“共享”，我们可以通过多个入口访问同一块内存。 Mutation的意思是“改变”。如果我们通过某个变量修改了一块内存，就是发生了mutation。Mutation意味着拥有“修改”权限，我们可以写入数据。 Rust保证内存安全的一个重要原则就是，如果能保证alias和 mutation不同时出现，那么代码就一定是安全的. 为什么在Rust中永远不会出现迭代器失效这样的错误？因为通 过“mutation+alias”规则，就可以完全杜绝这样的现象，这个规则是Rust 内存安全的根，是解决内存安全问题的灵魂。 Rust防范“内存不安全”代码的原则极其清晰明了。如果你对同一块内存存在多个引用，就不要试图对这块内存做修改；如果你需要对一块内存做修改，就不要同时保留多个引用。只要保证了这个原则，我们就可以保证内存安全。它在实践中发挥了强大的作用，可以帮助我们尽早发现问题。这个原则是Rust的立身之本、生命之基、活力之源。 注: std::cell::Cell可以\"突破\"这个“唯一修改权”的原则. 但实际上, Cell被小心的设计成一个包裹, 支持多个共享引用, 可以内部可变. 解引用 和c一样, 用*解引用 自定义解引用 实现std::ops::Deref或者std::ops::DerefMut这两个trait就能自定义解引用 pub trait Deref { type Target: ?Sized; fn deref(&self) -> &Self::Target; } pub trait DerefMut: Deref { fn deref_mut(&mut self) -> &mut Self::Target; } *expr的类型是Target，而 deref()方法返回的类型却是&Target 常见指针类型 Box是“指针”，指向一个在堆上分配的对象 Vec是“指针”，指向一组同类型的顺序排列的堆上分配的对象，且携带有当前缓存空间总大小和元素个数大小的元数据 String是“指针”，指向的是一个堆上分配的字节数组，其中保存的内容是合法的utf8字符序列。且携带有当前缓存空间总大小和字符串实际长度的元数据 以上几个类型都对所指向的内容拥有所有权，管理着它们所指向的内存空间的分配和释放 Rc和Arc也是某种形式的、携带了额外元数据的“指针”，它们提供的是一种“共享”的所有权，当所有的引用计数指针都销毁之后，它们所指向的内存空间才会被释放 自动解引用 len的函数签名是:fn len(&self) -> usize 按理说只有形式是&str的参数才行, 但下面的代码都正确: fn main() { let s = \"hello\"; println!(\"length: {}\", str::len(&s)); println!(\"length: {}\", str::len(s)); println!(\"length: {}\", s.len()); println!(\"length: {}\", (&s).len()); println!(\"length: {}\", (&&&&&&&&&&&&&s).len()); } 这是因为Rust编译器帮我们做了隐式的deref调用，当它找不到这个成员方法的时候，会自动尝试使用deref方法后再找该方法，一 直循环下去。所以&&&&&&&&&&str会被正确解引用 自动deref的规则是，如果类型T可以解引用为U，即T：Deref， 则&T可以转为&U Rc的自动解引用 Rc是带引用计数的智能指针, 它实现了Deref trait impl Deref for Rc { type Target = T; #[inline(always)] fn deref(&self) -> &T { &self.inner().value } } 它的Target类型是它的泛型参数T。这么设计有什么好处呢？我们 看下面的用法： use std::rc::Rc; fn main() { let s = Rc::new(String::from(\"hello\")); println!(\"{:?}\", s.bytes()); } 我们创建了一个指向String类型的Rc指针，并调用了bytes()方 法。这里是不是有点奇怪？这里的机制是这样的：Rc类型本身并没有bytes()方法，所以编译器会尝试自动deref，试试s.deref().bytes()。 String类型其实也没有bytes()方法，但是String可以继续deref，于是再试试s.deref().deref().bytes()。 这次在str类型中找到了bytes()方法，于是编译通过。 我们实际上通过Rc类型的变量调用了str类型的方法，让这个智能指针透明。这就是自动Deref的意义。 这就是为什么String需要实现Deref trait，是为了让&String类型的变量可以在必要的时候自动转换为&str类型。所以String类型的变量可以直接调用str类型的方法。比如： let s = String::from(\"hello\"); let len = s.bytes(); 虽然s的类型是String，但它在调用bytes()方法的时候，编译器会自动查找并转换为s.deref().bytes()调用。所以String类型的变量就可以直接调用str类型的方法了。 同理：Vec类型也实现了Deref trait，目标类型是[T]，&Vec类型的变量就可以在必要的时候自动转换为&[T]数组切片类型；Rc类型也实现了Deref trait，目标类型是T，Rc类型的变量就可以直接调用T类型的方法。 引用计数 普通变量绑定自身消亡的时候，这块内存就会被释放。引用计数智能指针给我们提供了另外一种选择：一块不可变内存可以有多个所有者，当所有的所有者消亡后，这块内存才会被释放。 std：：rc：：Rc: Rc是普通的引用计数, 只能单线程使用 std：：sync：：Arc: Arc是atomic Rc, 多线程安全 一般Rust不允许多owner, 但Rc可以突破这个限制: use std::rc::Rc; struct SharedValue { value: i32, } fn main() { let shared_value: Rc = Rc::new(SharedValue { value: 42 }); let owner1 = shared_value.clone(); let owner2 = shared_value.clone(); //shared_value.value = 88; 这句编译不过, 因为Rc就被设计成引用计数, 而不是共享变量. 用Cell来解决变量共享问题. println!(\"value : {} {}\", owner1.value, owner2.value); println!(\"address : {:p} {:p}\", &owner1.value, &owner2.value); } 运行结果: $ ./test value : 42 42 address : 0x13958abdf20 0x13958abdf20 这说明，owner1 owner2里面包含的数据不仅值是相同的，而且地址也是相同的。这正是Rc的意义所在。 如果要创建指向同样 内存区域的多个Rc指针，需要显式调用clone函数。请注意，Rc指针是 没有实现Copy trait的。如果使用直接赋值方式，会执行move语义，导致前一个指针失效，后一个指针开始起作用，而且引用计数值不变。如果需要创造新的Rc指针，必须手工调用clone()函数，此时引用计数值才会加1。当某个Rc指针失效，会导致引用计数值减1。当引用计数值减到0的时候，共享内存空间才会被释放。 cow 写时拷贝. 它对指向的数据可能“拥有所有权”，或者 可能“不拥有所有权”。 当它只需要对所指向的数据进行只读访问的时候，它就只是一个借用指针；当它需要写数据功能时，它会先分配内存，执行复制操作，再对自己拥有所有权的内存进行写入操作。 在标准库里: pub enum Cow where B: ToOwned { /// Borrowed data. Borrowed(&'a B), /// Owned data. Owned(::Owned) } 它可以是Borrowed或者Owned两种状态。如果是Borrowed状态，可以通过调用to_mut()函数获取所有权。在这个过程中，它实际上会分配一块新的内存，并将原来Borrowed状态的数据通过调用to_owned()方法 构造出一个新的拥有所有权的对象，然后对这块拥有所有权的内存执行操作。 比如下面的remove_spaces()函数, 如果入参没有空格, 就只返回借用; 如果有空格, 就返回一个新申请的有所有权的对象buf. use std::borrow::Cow; fn remove_spaces(input: &'a str) -> Cow { if input.contains(' ') { let mut buf = String::with_capacity(input.len()); for c in input.chars() { if c != ' ' { buf.push(c); } } return Cow::Owned(buf); } return Cow::Borrowed(input); } fn main() { let s1 = \"no_spaces_in_string\"; let result1 = remove_spaces(s1); let s2 = \"spaces in string\"; let result2 = remove_spaces(s2); println!(\"{}\\n{}\", result1, result2); } 为什么这里要用Cow呢? 因为这个函数的返回值类型用&str类 型和String类型都不大合适。 如果返回类型指定为&str类型，那么需要新分配内存的时候，会出现生命周期编译错误。因为函数内部新分配的字符串的引用不能在函数调用结束后继续存在。 如果返回类型指定为String类型，那么对于那种不需要对输入参数做修改的情况，有一些性能损失。因为输入参数&str类型转为String类 型需要分配新的内存空间并执行复制，性能开销较大。这种时候使用Cow类型就是不二之选。既能满足编译器的生命周期要求，也避免了无谓的数据复制。Cow类型，就是优秀的“零性能损失抽象”的设计范例。 Cow类型还实现了Deref trait，所以当我们需要调用类型T的成员函数的时候，可以直接调用，完全无须考虑后面具体是“借用指针”还是“拥有所有权的指针”。所以我们也可以把它当成是一种“智能指针”。 智能指针 上面提到的Rc和Cow都是智能指针.Rust中允许一部分运算符可以由用户自定义行为，即“操作符重载”。其中“解引用”是一个非常重要的操作符，它允许重载。 而需要提醒大家注意的是，“取引用”操作符，如&、&mut，是不允许重载的。因此，“取引用”和“解引用”并非对称互补关系。*&T的类型 一定是T，而&*T的类型未必就是T。 更重要的是，读者需要理解，在某些情况下，编译器帮我们插入了自动deref的调用，简化代码。 在Deref的基础上，我们可以封装出一种自定义类型，它可以直接调用其内部的其他类型的成员方法，我们可以把这种类型称为智能指针类型 其他 在方法里定义struct是可以的 impl Clone for Box { fn clone(&self) -> Self { let mut new = BoxBuilder { data: RawVec::with_capacity(self.len()), len: 0, }; let mut target = new.data.ptr(); for item in self.iter() { unsafe { ptr::write(target, item.clone()); target = target.offset(1); }; new.len += 1; } return unsafe { new.into_box() }; // Helper type for responding to panics correctly. struct BoxBuilder { data: RawVec, len: usize, } impl BoxBuilder { unsafe fn into_box(self) -> Box { let raw = ptr::read(&self.data); mem::forget(self); raw.into_box() } } impl Drop for BoxBuilder { fn drop(&mut self) { let mut data = self.data.ptr(); let max = unsafe { data.offset(self.len as isize) }; while data != max { unsafe { ptr::read(data); data = data.offset(1); } } } } } } 为什么明明可以直接在一个方法里写完的代码，还要引入一个新的类型呢？原因就在于panic safety问题。注意我们这里调用了T类型的 clone方法。T是一个泛型参数，谁能保证clone方法不会产生panic？没有谁能保证，我们只能尽可能让clone发生panic的时候，RawVec的状态不会乱掉。 所以，标准库的实现利用了RAII机制，即便在clone的时候发生了 panic，这个BoxBuilder类型的局部变量的析构函数依然会正确执行，并在析构函数中做好清理工作。上面这段代码之所以搞这么复杂，就是为了保证在发生panic的时候逻辑依然是正确的。大家可以去翻一下标准库中的代码，有大量类似的模式存在，都是因为需要考虑panic safety问题。Rust的标准库在编写的时候有这样一个目标：即便发生了panic，也不会产生“内存不安全”和“线程不安全”的情况。 文件打开 use std::fs::File; use std::io::Read; fn main() { let f = File::open(\"/target/file/path\"); if f.is_err() { println!(\"file is not exist.\"); return; } let mut f = f.unwrap(); let mut content = String::new(); let result = f.read_to_string(&mut content); if result.is_err() { println!(\"read file error.\"); return; } println!(\"{}\", result.unwrap()); } unsafe unsafe可以修饰fn, 代码块, trait, impl等 unsafe有传递性, 比如使用unsafe的fn的代码块也必须用unsafe来修饰. unsafe可以操作裸指针 fn main() { let x = 1_i32; let mut y: u32 = 1; let raw_mut = &mut y as *mut u32 as *mut i32 as *mut i64; // 这是安全的 unsafe { *raw_mut = -1; // 这是不安全的,必须在 unsafe 块中才能通过编译 } println!(\"{:X} {:X}\", x, y); } 上面的例子中: 首先raw_mut必须经过三个as as as的转换才能从u32的指针转为i64的指针 对raw_mut的直接修改是unsafe的 修改了raw_mut, 也就是y, 但也\"一起\"修改了x, 因为x和y两个变量地址是挨着的. 又比如下面的例子: fn raw_to_ref(p: *const i32) -> &'a i32 { unsafe { &*p } } fn main() { let p: &i32 = raw_to_ref(std::ptr::null::()); println!(\"{}\", p); } 这个例子会运行错误, 因为传入了一个空指针, 而在unsafe里面对空指针解引用出现错误. 不加unsafe是不能对裸指针解引用的 在unsafe里, 用户要自己避免空指针问题, 编译器是不管的 要修复这个错误, 改成这样就好了: fn raw_to_ref(p: *const i32) -> Option { if p.is_null() { None } else { unsafe { Some(&*p) } } } fn main() { let p: Option = raw_to_ref(std::ptr::null::()); println!(\"{:?}\", p); } 不用unsafe的swap例子 下面的例子是我自己写的, 能正常工作, 没用unsafe. fn swap(x: &mut i32, y: &mut i32) { let z = *x; *x = *y; *y = z; } fn main() { let mut a = 5; let mut b = 8; swap(&mut a, &mut b); println!(\"a: {}, b: {}\", a, b) } 但如果用泛型, 就会出现编译错误: fn swap(x: &mut T, y: &mut T) { let z = *x; *x = *y; *y = z; } fn main() { let mut a = 5; let mut b = 8; swap(&mut a, &mut b); println!(\"a: {}, b: {}\", a, b) } 错误是:cannot move out of *x which is behind a mutable reference 编译器还提示move occurs because *x has type T, which does not implement the Copy trait 意思是assign的时候, 默认执行的是move语义, 但这里因为x只是借用, 但没有权限解引用. 但如果实现了Copy trait, 也可以调用Copy 那么添加T的约束为Copy, 也就好了: fn swap(x: &mut T, y: &mut T) { let z = *x; //这里用了copy语义 *x = *y; *y = z; } fn main() { let mut a = 5; let mut b = 8; swap(&mut a, &mut b); println!(\"a: {}, b: {}\", a, b) } 标准库的swap 标准的swap并没有要求copy, 而是直接操作指针 fn swap(x: &mut T, y: &mut T) { unsafe { let mut t: T = mem::uninitialized(); ptr::copy_nonoverlapping(&*x, &mut t, 1); ptr::copy_nonoverlapping(&*y, x, 1); ptr::copy_nonoverlapping(&t, y, 1); mem::forget(t); } } 首先，我们依然需要一个作为中转的局部变量。这个局部变量该怎么初始化呢？其实我们不希望它执行初始化，因为我们只需要这部分内存空间而已，它里面的内容马上就会被覆盖掉，做初始化是浪费性能。况且，我们也不知道用什么通用的办法初始化一个泛型类型，它连Default约束都未必满足。所以我们要用mem::uninitialized函数。接下来，我们可以直接通过内存复制来交换两个变量。因为在Rust中，所有的类型、所有的move操作，都是简单的内存复制，不涉及其他的语义。Rust语言已经假定任何一个类型的实例，随时都可以被move到另外的地方，不会产生任何问题。所以，我们可以直接使用ptr::copy系列函数来完成。再加上在safe代码中，&mut型指针具有排他性， 我们可以确信，x和y一定指向不同的变量。所以可以使用ptr::copy_nonoverlapping函数，比ptr::copy要快一点。 最后，一定要记得，要阻止临时的局部变量t执行析构函数。因为t本身并未被合理地初始化，它内部的值是直接通过内存复制获得的。在复制完成后，它内部的指针（如果有的话）会和y指向的变量是相同的。如果我们不阻止它，那么在函数结束的时候它的析构函数就会被自动调用，这样y指向的变量就变成非法的了。 这样我们才能正确地完成这个功能。虽然源代码看起来比较长，但是实际生成的代码并不多，就是3次内存块的复制。 Vec代码 下面的代码中, 用Vec的new创建出来的变量v1, 开始的capacity是0, length也是0, 增长的倍数也是2倍速. fn main() { let mut v1 = Vec::::new(); println!(\"Start: length {} capacity {}\", v1.len(), v1.capacity()); for i in 1..10 { v1.push(i); println!( \"[Pushed {}] length {} capacity {}\", i, v1.len(), v1.capacity() ); } let mut v2 = Vec::::with_capacity(1); println!(\"Start: length {} capacity {}\", v2.len(), v2.capacity()); v2.reserve(10); for i in 1..10 { v2.push(i); println!( \"[Pushed {}] length {} capacity {}\", i, v2.len(), v2.capacity() ); } } //结果 Start: length 0 capacity 0 [Pushed 1] length 1 capacity 4 [Pushed 2] length 2 capacity 4 [Pushed 3] length 3 capacity 4 [Pushed 4] length 4 capacity 4 [Pushed 5] length 5 capacity 8 [Pushed 6] length 6 capacity 8 [Pushed 7] length 7 capacity 8 [Pushed 8] length 8 capacity 8 [Pushed 9] length 9 capacity 16 Start: length 0 capacity 1 [Pushed 1] length 1 capacity 10 [Pushed 2] length 2 capacity 10 [Pushed 3] length 3 capacity 10 [Pushed 4] length 4 capacity 10 [Pushed 5] length 5 capacity 10 [Pushed 6] length 6 capacity 10 [Pushed 7] length 7 capacity 10 [Pushed 8] length 8 capacity 10 [Pushed 9] length 9 capacity 10 用with_capacity()创建的容量一开始就分配了. Vec的特点是空间会自动扩展, 并且当变量生命周 期结束的时候，它会自动释放它管理的内存空间 为什么Vec能够自动回收空间呢? 因为Vec实现了Drop: unsafe impl Drop for Vec { fn drop(&mut self) { unsafe { // use drop for [T] ptr::drop_in_place(&mut self[..]); } // RawVec handles deallocation } } "},"notes/rust_入门3.html":{"url":"notes/rust_入门3.html","title":"闭包 容器 迭代器 生成器 线程","keywords":"","body":" 静态分派和动态分派 trait不能用作入参或者返回值 impl Trait做为入参 impl trait只是语法糖 trait object impl trait 闭包 普通的函数不能捕获局部变量 闭包和函数 闭包如何捕获变量? move关键字 闭包和泛型 可以用Box封装闭包 容器 Vec VecDeque HashMap BTreeMap 迭代器 从容器创造迭代器 迭代器组合 for in 生成器 协程 标准库 类型转换 AsRef/AsMut borrow From/Into ToOwned ToString/FromStr 运算符重载 complex加法重载 IO OsString和OsStr 文件和路径 标准输入输出 进程启动参数 Any和反射 线程安全 创建线程 更多线程参数 rust怎么保证线程安全 Send & Sync 什么是Send类型 什么是Sync类型 保证线程安全的类型 Arc Mutex RwLock Atomic Barrier Condvar 全局变量 线程局部存储 异步管道 同步管道 相当于go channel 第三方线程库 静态分派和动态分派 trait不能用作入参或者返回值 比如下面的Bird这个trait, 有两个实现, Duck和Swan trait Bird { fn fly(&self); } struct Duck; struct Swan; impl Bird for Duck { fn fly(&self) { println!(\"duck duck\"); } } impl Bird for Swan { fn fly(&self) { println!(\"swan swan\"); } } 但Bird不能直接用作入参和出参, 因为trait是一种DST类型，它的大小在编译阶段是不固定的. 这点和go的interface是不同的. // 以下代码不能编译 fn test(arg: Bird) {} fn test() -> Bird {} 有两个办法: 用泛型传参, 即静态分派fn test(arg: T) { arg.fly(); } 用trait object, 即自己给trait穿个Box的马甲, 做到动态分派 // 根据不同需求,可以用不同的指针类型,如 Box/&/&mut 等 fn test(arg: Box) { arg.fly(); } 似乎还有个办法是加dyn关键词, dyn是比较新的关键词 trait Bird { fn fly(&self); } struct Duck; struct Swan; impl Bird for Duck { fn fly(&self) { println!(\"duck duck\"); } } impl Bird for Swan { fn fly(&self) { println!(\"swan swan\"); } } fn call_fly(f: &dyn Bird) { f.fly() } fn main() { let duck = Duck; call_fly(&duck); call_fly(&Swan{}); } //输出 duck duck swan swan impl Trait做为入参 比如下面的函数 fn parse_csv_document(src: R) -> std::io::Result>> { src.lines() .map(|line| { // For each line in the source line.map(|line| { // If the line was read successfully, process it, if not, return the error line.split(',') // Split the line separated by commas .map(|entry| String::from(entry.trim())) // Remove leading and trailing whitespace .collect() // Collect all strings in a row into a Vec }) }) .collect() // Collect all lines into a Vec> } 可以由泛型约束改成impl trait, 即声明src必须实现std::io::BufRead这个trait. 这点和golang传入interface有点像. fn parse_csv_document(src: impl std::io::BufRead) -> std::io::Result>> { src.lines() .map(|line| { // For each line in the source line.map(|line| { // If the line was read successfully, process it, if not, return the error line.split(',') // Split the line separated by commas .map(|entry| String::from(entry.trim())) // Remove leading and trailing whitespace .collect() // Collect all strings in a row into a Vec }) }) .collect() // Collect all lines into a Vec> } impl trait只是语法糖 比如下面的代码用了impl trait形式的入参: pub fn notify(item: &impl Summary) { println!(\"Breaking news! {}\", item.summarize()); } 它实际上是下面显式声明泛型约束的方法一样: pub fn notify(item: &T) { println!(\"Breaking news! {}\", item.summarize()); } trait object 指向trait的指针就是trait object。假如Bird是一个trait的名称，那么dyn Bird就是一个DST动态大小类型。&dyn Bird、&mut dyn Bird、Box、*const dyn Bird、*mut dyn Bird以及Rc等等都是Trait Object。 A trait object points to both an instance of a type implementing our specified trait as well as a table used to look up trait methods on that type at runtime. We create a trait object by specifying some sort of pointer, such as a & reference or a Box smart pointer, then the dyn keyword, and then specifying the relevant trait. impl trait 还有个impl trait语法, 比如: fn foo(n: u32) -> impl Iterator { (0..n).map(|x| x * 100) } 返回一个函数也可以用类似的语法: fn multiply(m: i32) -> impl Fn(i32) -> i32 { move |x| x * m } fn main() { let f = multiply(5); println!(\"{}\", f(2)); } //结果 10 闭包 闭包(closure)是一种匿名函数，具有“捕获”外部变量的能力。闭包有时候也被称作lambda表达式。它有两个特点: 可以像函数一 样被调用； 可以捕获当前环境中的变量。 语法如下: fn main() { let add = |a: i32, b: i32| -> i32 { return a + b; }; let x = add(1, 2); println!(\"result is {}\", x); } 以上闭包有两个参数，以两个|包围。执行语句包含在{}中。闭包的参数和返回值类型的指定与普通函数的语法相同。闭包的参 数和返回值类型都是可以省略的，因此以上闭包可省略为: let add = |a, b| a + b; //省略了类型, 括号, 和return 普通的函数不能捕获局部变量 rust支持函数中定义函数, 但不支持内部函数引用外部函数的局部变量. 比如下面的代码编译不过 fn main() { let x = 1_i32; fn inner_add() -> i32 { x + 1 } let x2 = inner_add(); println!(\"result is {}\", x2); } 要改为闭包: fn main() { let x = 1_i32; let inner_add = || x + 1; let x2 = inner_add(); println!(\"result is {}\", x2); } 闭包和函数 闭包的实现: fn main() { let x = 1_i32; let add_x = | a | x + a; let result = add_x( 5 ); println!(\"result is {}\", result); } 如果改为非闭包的普通实现: struct Closure { inner1: i32, } impl Closure { fn call(&self, a: i32) -> i32 { self.inner1 + a } } fn main() { let x = 1_i32; let add_x = Closure { inner1: x }; let result = add_x.call(5); println!(\"result is {}\", result); } 可以看到闭包的方式更简洁. 闭包如何捕获变量? Rust主要是通过分析外部变量在闭包中的使用方式，通过一系列的规则自动推导出来的。主要规则如下: 如果一个外部变量在闭包中，只通过借用指针&使用，那么这个变量就可通过引用&的方式捕获； 如果一个外部变量在闭包中，通过&mut指针使用过，那么这个变量就需要使用&mut的方式捕获； 如果一个外部变量在闭包中，通过所有权转移的方式使用过，那么这个变量就需要使用“by value”的方式捕获。 简单点总结规则是，在保证能编译通过的情况下，编译器会自动选择一种对外部影响最小的类型存储。对于被捕获的类型为T的外部变量，在匿名结构体中的存储方式选择为: 尽可能先选择&T类型，其次选择&mut T类型，最后选择T类型。 move关键字 闭包的捕获默认是引用捕获, 即捕获&T. 下面的例子编译不通过 fn make_adder(x: i32) -> Box i32> { Box::new(|y| x + y) } fn main() { let f = make_adder(3); println!(\"{}\", f(1)); // 4 println!(\"{}\", f(10)); // 13 } 函数make_adder中有一个局部变量x，按照前面所述的规则，它被闭包所捕获，而且可以使用引用&的方式完成闭包内部的逻辑，因此它是被引用捕获的。而闭包则作为函数返回值被传递出去了。于是，闭包被调用的时候，它内部的引用所指向的内容已经被释放了。 这个时候就要用move关键字了, 表示后面语句块的所有变量都强制使用\"值传递\": fn make_adder(x: i32) -> Box i32> { Box::new(move |y| x + y) // 使用move来强制使用值传递 } 闭包和泛型 下面的例子是传入一个闭包函数到泛型函数: fn call_with_closure(some_closure: F) -> i32 where F: Fn(i32) -> i32, { some_closure(1) } fn main() { let answer = call_with_closure(|x| x + 2); println!(\"{}\", answer); } 每个闭包，编译器都会为它生成一个匿名结构体类型；即使两个闭包的参数和返回值一致，它们也是完全不同的两个类 型，只是都实现了同一个trait而已。 可以用Box封装闭包 fn test() -> Box i32> { let c = |i: i32| i * 2; Box::new(c) } fn main() { let closure = test(); let r = closure(2); println!(\"{}\", r); } 容器 容器 描述 Vec 可变长数组, 连续存储 VecDeque 双向队列, 适用于从头部和尾部插入删除数据 LinkedList 双向链表, 非连续存储 HashMap 基于Hash算法存储key value HashSet 只有key没有value的HashMap BTreeMap 基于B树存储key value BTreeSet 只有key没有value的BtreeMap BinaryHeap 基于二叉堆的优先级队列 Vec 它就是一个可以自动扩展容量的动态数组。它重载了Index运算符，可以通过中括号取下标的形式访问内部成员。它还重载了Deref/DerefMut运算符，因此可 以自动被解引用为数组切片。 用法示例: fn main() { // 常见的几种构造Vec的方式 // 1. new() 方法与 default() 方法一样,构造一个空的Vec let v1 = Vec::::new(); // 2. with_capacity() 方法可以预先分配一个较大空间,避免插入数据的时候动态扩容 let v2: Vec = Vec::with_capacity(1000); // 3. 利用宏来初始化,语法跟数组初始化类似 let v3 = vec![1, 2, 3]; // 插入数据 let mut v4 = Vec::new(); // 多种插入数据的方式 v4.push(1); v4.extend_from_slice(&[10, 20, 30, 40, 50]); v4.insert(2, 100); println!(\"capacity: {} length: {}\", v4.capacity(), v4.len()); // 访问数据 // 调用 IndexMut 运算符,可以写入数据 v4[5] = 5; let i = v4[5]; println!(\"{}\", i); // Index 运算符直接访问,如果越界则会造成 panic,而 get 方法不会,因为它返回一个 Option if let Some(i) = v4.get(6) { println!(\"{}\", i); } // Index 运算符支持使用各种 Range 作为索引 let slice = &v4[4..]; println!(\"{:?}\", slice); } VecDeque A double-ended queue implemented with a growable ring buffer VecDeque是一个双向队列。在它的头部或者尾部执行添加或者删除操作，都是效率很高的。它的用法和Vec非常相似，主要是多了pop_front()和push_front()等方法 use std::collections::VecDeque; fn main() { let mut queue = VecDeque::with_capacity(64); // 向尾部按顺序插入一堆数据 for i in 1..10 { queue.push_back(i); } // 从头部按顺序一个个取出来 while let Some(i) = queue.pop_front() { println!(\"{}\", i); } } HashMap HashMap泛型参数K是键的类型，V是值的类型，S是哈希算法的类型。S这个泛型参数有一个默认值. Hash trait就是这个算法: trait Hash { fn hash(&self, state: &mut H); ... } trait Hasher { fn finish(&self) -> u64; fn write(&mut self, bytes: &[u8]); ... } 如果一个类型，实现了Hash，给定了一种哈希算法Hasher，就能计算出一个u64类型的哈希值, 比如类似下面的: struct Person { first_name: String, last_name: String, } impl Hash for Person { fn hash(&self, state: &mut H) { self.first_name.hash(state); self.last_name.hash(state); } } 但通常写作: #[derive(Hash)] struct Person { first_name: String, last_name: String, } 完整的写法如下: use std::collections::HashMap; #[derive(Hash, Eq, PartialEq, Debug)] struct Person { first_name: String, last_name: String, } impl Person { fn new(first: &str, last: &str) -> Self { Person { first_name: first.to_string(), last_name: last.to_string(), } } } fn main() { let mut book = HashMap::new(); book.insert(Person::new(\"John\", \"Smith\"), \"521-8976\"); book.insert(Person::new(\"Sandra\", \"Dee\"), \"521-9655\"); book.insert(Person::new(\"Ted\", \"Baker\"), \"418-4165\"); let p = Person::new(\"John\", \"Smith\"); // 查找键对应的值 if let Some(phone) = book.get(&p) { println!(\"Phone number found: {}\", phone); } // 删除 book.remove(&p); // 查询是否存在 println!(\"Find key: {}\", book.contains_key(&p)); } HashMap对查询和insert/delete这种组合, 提供了entry API, 可以节省一次hash运算. 比如下面的代码: if map.contains_key(key) { // 执行了一遍hash查找的工作 map.insert(key, value); // 又执行了一遍hash查找的工作 } 使用entry API可以写成: map.entry(key).or_insert(value); BTreeMap 和HashMap用起来类似, 但使用B树来存储key value. 和hash不同, 这个解构是有序的. BTreeMap对key的要求是满足Ord约束，即具备“全序”特征. BTreeMap使用起来和Hashap类似, 但多了一个range功能如下: use std::collections::BTreeMap; fn main() { let mut map = BTreeMap::new(); map.insert(3, \"a\"); map.insert(5, \"b\"); map.insert(8, \"c\"); for (k, v) in map.range(2..6) { println!(\"{} : {}\", k, v); } } 迭代器 迭代器的trait: trait Iterator { type Item; fn next(&mut self) -> Option; } 它最主要的一个方法就是next()，返回一个Option。一般情况返回Some(Item)；如果迭代完成，就返回None。 一个迭代器需要自己记录内部状态, 比如下面Seq结构体里的current: use std::iter::Iterator; struct Seq { current: i32, } impl Seq { fn new() -> Self { Seq { current: 0 } } } impl Iterator for Seq { type Item = i32; //指定关联类型 fn next(&mut self) -> Option { if self.current 从容器创造迭代器 从容器创造迭代器: iter()创造一个Item是&T类型的迭代器； iter_mut()创造一个Item是&mut T类型的迭代器； into_iter()创造一个Item是T类型的迭代器。--这里有问题, 不一定是T 比如Vec等容器创造迭代器: fn main() { let v = vec![1, 2, 3, 4, 5]; let mut iter = v.iter(); while let Some(i) = iter.next() { println!(\"{}\", i); } } 这个和用for in是一样的: fn main() { let v = vec![1, 2, 3, 4, 5]; for i in v { println!(\"{}\", i) } } 迭代器组合 比如下面的例子: fn main() { let v = vec![1, 2, 3, 4, 5, 6, 7, 8, 9]; let mut iter = v .iter() .take(5) .filter(|&x| x % 2 == 0) .map(|&x| x * x) .enumerate(); while let Some((i, v)) = iter.next() { println!(\"{} {}\", i, v); } } 直到执行iter.next()前, 创造iter使用的\"组合\"模式的代价很小, 它只是按照用户定义的组合, 初始化了一个迭代器对象, 并没有真正干活. 比如下面的代码只是构造了一个迭代器示例, 不会打印, 因为没有调用next()方法. let v = vec![1, 2, 3, 4, 5]; v.iter().map(|x| println!(\"{}\", x)); for in for in就是给迭代器设计的语法糖 use std::collections::HashMap; fn main() { let v = vec![1, 2, 3, 4, 5, 6, 7, 8, 9]; for i in v { println!(\"{}\", i); } //从array生成一个hashmap let map: HashMap = [(1, 'a'), (2, 'b'), (3, 'c')].iter().cloned().collect(); //比较新的版本>1.56, 可以用from函数 let map = HashMap::from([(1, 'a'), (2, 'b'), (3, 'c')]); for (k, v) in &map { println!(\"{} : {}\", k, v); } } 因为for调用的是 trait IntoIterator { type Item; type IntoIter: Iterator; //感觉这行是约束的意思 fn into_iter(self) -> Self::IntoIter; } 只要某个类型实现了IntoIterator，那么调用into_iter()方法就可以得到对应的迭代器。这个into_iter()方法的receiver是self，而不是&self，执行的是move语义。这么做，可以同时支持Item类型为T、&T 或者&mut T，用户有选择的权力。 那么如何实现这个trait呢? 需要三个版本一起实现: impl IntoIterator for BTreeMap { type Item = (K, V); type IntoIter = IntoIter; } impl IntoIterator for &'a BTreeMap { type Item = (&'a K, &'a V); type IntoIter = Iter; } impl IntoIterator for &'a mut BTreeMap { type Item = (&'a K, &'a mut V); type IntoIter = IterMut; } 对于一个容器类型，标准库里面对它impl了三次IntoIterator。当Self类型为BTreeMap的时候，Item类型为(K，V)，这意味着，每次next()方法都是把内部的元素move出来了；当Self类型为&BTreeMap的时候，Item类型为(&K，&V)，每次next()方法返回的是借用； 当Self类型为&mut BTreeMap的时候，Item类型为(&K，&mut V)，每次next()方法返回的key是只读的，value是可读写的。 所以，如果有个变量m，其类型为BTreeMap，那么用户可以选择使用m.into_iter()或者(&m).into_iter()或者(&mut m).into_iter()，分别达到不同的目的。 for in循环用了into_iter()方法, 对应上面三种实现, 使用方法如下: // container在循环之后生命周期就结束了,循环过程中的每个item是从container中move出来的 for item in container {} // 迭代器中只包含container的&型引用,循环过程中的每个item都是container中元素的借用 for item in &container {} // 迭代器中包含container的&mut型引用,循环过程中的每个item都是指向container中元素的可变借用 for item in &mut container {} 可以看到, 实现了IntoIterator, 就可以被for in所使用. 生成器 生成器的语法像闭包, 区别是在语句块中有yield关键词, 比如: // 方案一 #![feature(generators, generator_trait)] use std::ops::{Generator, GeneratorState}; fn main() { let mut g = || { let mut curr: u64 = 1; let mut next: u64 = 1; loop { let new_next = curr.checked_add(next); if let Some(new_next) = new_next { curr = next; next = new_next; yield curr; // println!(\"{}\", v), GeneratorState::Complete(_) => return, } } } } 注意以上代码编译不过, 但可以看看其中原理: 生成器最大的特点就是，程序的执行流程可以在生成器和调用者之间来回切换。当我们需要暂时从生成器中返回的时候，就使用yield关键字；当调用者希望再次进入生成器的时候，就调用resume()方法，这时程序执行的流程是从上次yield返回的那个点继续执行。 回想迭代器, next方法就很像resume. 迭代器需要自己维护内部状态, 生成器也是类似的, 感觉生成器能自动维护其内部状态. 协程 用户态调度的协程.Rust的协程设计，核心是async和await两个关键字，以及Future这个 trait: pub trait Future { type Output; fn poll(self: PinMut, cx: &mut Context) -> Poll; ...... } 比如下面的代码: async fn async_fn(x: u8) -> u8 { let msg = await!(read_from_network()); let result = await!(calculate(msg, x)); result } 在这个示例中，假设read_from_network()以及calculate()函数都是异步的。最外层的async_fn()函数当然也是异步的。当代码执行到 await！(read_from_network())里面的时候，发现异步操作还没有完成，它会直接退出当前这个函数，把CPU让给其他任务执行。当这个数据从网络上传输完成了，调度器会再次调用这个函数，它会从上次中断的地方恢复执行。所以用async/await的语法写代码，异步代码的逻辑在源码组织上跟同步代码的逻辑差别并不大。这里面状态保存和恢复这些琐碎的事情，都由编译器帮我们完成了。 async关键字可以修饰函数、闭包以及代码块。对于函数: async fn f1(arg: u8) -> u8 {} 实际上等同于: fn f1(arg: u8) -> impl Future {} rust和go不同的, rust需要显式的手动指定调度点, 比如上面的await宏就埋了调度的代码; 而go的调度代码是\"隐藏\"的, 表面上让人感觉不到发生了用户态调度. 标准库 类型转换 常用的类型转换已经被preclude 包括AsRef、AsMut、Into、From、ToOwned等 AsRef/AsMut AsRef这个trait代表的意思是，这个类型可以通过调用as_ref方法，得到另外一个类型的共享引用: pub trait AsRef { fn as_ref(&self) -> &T; } 这里的?Sized约束指T可以是Sized也可以不是Sized, 如果没有, 则默认T是Sized. 类似的, 还有AsMut有一个as_mut方法，可以得到另外一个类型的可读写 引用: pub trait AsMut { fn as_mut(&mut self) -> &mut T; } 比如标准库的String类型, 就针对好几个类型参数实现了 AsRef trait: impl AsRef for String impl AsRef for String impl AsRef for String impl AsRef for String AsRef这样的trait很适合用在泛型代码中，为一系列类型做统一抽 象。比如，我们可以写一个泛型函数，它接受各种类型，只要可以被转 换为&[u8]即可: fn iter_bytes>(arg: T) { for i in arg.as_ref() { println!(\"{}\", i); } } fn main() { let s: String = String::from(\"this is a string\"); let v: Vec = vec![1, 2, 3]; let c: &str = \"hello\"; // 相当于函数重载。只不过基于泛型实现的重载,一定需要重载的参数类型满足某种共同的约束 iter_bytes(s); iter_bytes(v); iter_bytes(c); } borrow pub trait Borrow { fn borrow(&self) -> &Borrowed; } From/Into AsRef/Borrow做的类型转换都是从一种引用&T到另一种引用&U的转换。而From/Into做的则是从任意类型T到U的类型转换: pub trait From { fn from(T) -> Self; } pub trait Into { fn into(self) -> T; } Into和From是逆操作, 如果存在U: From，则实现T: Into impl Into for T where U: From { fn into(self) -> U { U::from(self) } } 比如标准库的String就实现了From impl From for String 可以使用&str.into()或者String::from(s)调用 fn main() { let s: &'static str = \"hello\"; let str1: String = s.into(); let str2: String = String::from(s); } ToOwned ToOwned trait提供的是一种更“泛化”的Clone的功能。Clone一般是从&T类型变量创造一个新的T类型变量，而ToOwned一般是从一个&T类型变量创造一个新的U类型变量。 impl ToOwned for T where T: Clone, { type Owned = T; fn to_owned(&self) -> T { self.clone() } fn clone_into(&self, target: &mut T) { target.clone_from(self); } } ToString/FromStr ToString trait提供了其他类型转换为String类型的能力 pub trait ToString { fn to_string(&self) -> String; } 一般情况下，我们不需要自己为自定义类型实现ToString trait。因为标准库中已经提供了一个默认实现: impl ToString for T { #[inline] default fn to_string(&self) -> String { use core::fmt::Write; let mut buf = String::new(); buf.write_fmt(format_args!(\"{}\", self)) .expect(\"a Display implementation return an error unexpectedly\"); buf.shrink_to_fit(); buf } } 这意味着，任何一个实现了Display trait的类型，都自动实现了ToString trait。而Display trait是可以自动derive的，我们只需要为类型添加一个attribute即可。 FromStr则提供了从字符串切片&str向其他类型转换的能力: pub trait FromStr { type Err; fn from_str(s: &str) -> Result; } str类型有个方法是parse pub fn parse(&self) -> Result { … } 可以这样用: fn print_type_of(_: &T) { println!(\"{}\", std::any::type_name::()) } fn main() { print_type_of(&\"4\".parse::()); let four1 = \"4\".parse::(); //和结构体一样, 函数的泛型参数也可以用双冒号指定 let four2: Result = \"4\".parse(); println!(\"{:?}\", four1); println!(\"{:?}\", four2); } 运算符重载 Rust允许一部分运算符重载，用户可以让这些运算符支持自定义类型。运算符重载的方式是: 针对自定义类型，impl一些在标准库中预定 义好的trait，这些trait都存在于std::ops模块中。比如前面已经讲过了的Deref trait就属于运算符重载 比如加法运算符重载需要满足下面的trait: trait Add { type Output; fn add(self, rhs: RHS) -> Self::Output; } 基本库为i32实现的加法trait: impl Add for i32 type Output = i32; impl Add for &'a i32 type Output = >::Output; impl Add for i32 type Output = >::Output; impl Add for &'b i32 type Output = >::Output; 这意味着，不仅i32+i32是允许的，而且i32+&i32、&i32+i32、&i32+&i32这几种形式也都是允许的。它们的返回类型都是i32 complex加法重载 use std::ops::Add; #[derive(Copy, Clone, Debug, PartialEq)] struct Complex { real: i32, imaginary: i32, } impl Add for Complex { type Output = Complex; fn add(self, other: Complex) -> Complex { Complex { real: self.real + other.real, imaginary: self.imaginary + other.imaginary, } } } fn main() { let c1 = Complex { real: 1, imaginary: 2, }; let c2 = Complex { real: 2, imaginary: 4, }; println!(\"{:?}\", c1 + c2); } 可以实现多个类型的add: use std::ops::Add; #[derive(Copy, Clone, Debug, PartialEq)] struct Complex { real: i32, imaginary: i32, } impl Add for Complex { type Output = Complex; fn add(self, other: &'a Complex) -> Complex { Complex { real: self.real + other.real, imaginary: self.imaginary + other.imaginary, } } } impl Add for Complex { type Output = Complex; fn add(self, other: i32) -> Complex { Complex { real: self.real + other, imaginary: self.imaginary, } } } IO OsString和OsStr Rust的String和Str是utf-8编码的, 但操作系统的字符串不一定用什么格式. 所以rust设计了OsString和OsStr来屏蔽差异. 使用场景如下: use std::path::PathBuf; fn main() { let mut buf = PathBuf::from(\"/\"); buf.set_file_name(\"bar\"); if let Some(s) = buf.to_str() { println!(\"{}\", s); } else { println!(\"invalid path\"); } } 这里的set_file_name方法声明如下: fn set_file_name>(&mut self, file_name: S) 因为&str满足这个约束: impl AsRef for str 文件和路径 rust对文件的实现在std::fs::File. 对文件的读写，则需要用到std::io模块了. 这个模块内部定义了几个重要的trait，比如Read/Write。File类型也实现了Read和Write两个 trait，因此它拥有一系列方便读写文件的方法. use std::fs::File; use std::io::prelude::*; use std::io::BufReader; fn test_read_file() -> Result { let mut path = std::env::home_dir().unwrap(); path.push(\".rustup\"); path.push(\"settings\"); path.set_extension(\"toml\"); let file = File::open(&path)?; let reader = BufReader::new(file); for line in reader.lines() { println!(\"Read a line: {}\", line?); } Ok(()) } fn main() { match test_read_file() { Ok(_) => {} Err(e) => { println!(\"Error occured: {}\", e); } } } 标准输入输出 use std::io::prelude::*; use std::io::BufReader; fn test_stdin() -> Result { let stdin = std::io::stdin(); let handle = stdin.lock(); let reader = BufReader::new(handle); for line in reader.lines() { let line = line?; if line.is_empty() { return Ok(()); } println!(\"Read a line: {}\", line); } Ok(()) } fn main() { match test_stdin() { Ok(_) => {} Err(e) => { println!(\"Error occured: {}\", e); } } } 进程启动参数 在Rust中，进程启动参数是调用独立的函数std::env::args()来得到的，或者使用std::env::args_os()来得到，进程返回值也是调用独立函数std::process::exit()来指定的。 比如: fn main() { if std::env::args().any(|arg| arg == \"-kill\") { std::process::exit(1); } for arg in std::env::args() { println!(\"{}\", arg); } } Any和反射 Rust标准库中提供了一个乞丐版的“反射”功能，那就是std::any模块。这个模块内，有个trait名字叫作Any。所有的类型都自动实现了Any这个trait，因此我们可以把任何一个对象的引用转为&Any这个trait object，然后调用它的方法。 它可以判断这个对象是什么类型，以及强制转换&Any为某个具体类型。另外，成员函数get_type_id()暂时要求'static约束，这个限制条件以后会放宽。 #![feature(get_type_id)] use std::any::Any; use std::fmt::Display; fn log(value: &T) { let value_any = value as &Any; if let Some(s) = value_any.downcast_ref::() { println!(\"String: {}\", s); } else if let Some(i) = value_any.downcast_ref::() { println!(\"i32: {}\", i); } else { let type_id = value_any.get_type_id(); println!(\"unknown type {:?}: {}\", type_id, value); } } fn do_work(value: &T) { log(value); } fn main() { let my_string = \"Hello World\".to_string(); do_work(&my_string); let my_i32: i32 = 100; do_work(&my_i32); let my_char: char = '❤'; do_work(&my_char); } 线程安全 创建线程 use std::thread; thread::spawn(move || { // 这里是新建线程的执行逻辑 }); 如果我们需要等待子线程执行结束，那么可以使用join方法: use std::thread; // child 的类型是 JoinHandle,这个T是闭包的返回类型 let child = thread::spawn(move || { // 子线程的逻辑 }); // 父线程等待子线程结束 let res = child.join(); 更多线程参数 use std::thread; thread::Builder::new().name(\"child1\".to_string()).spawn(move || { println!(\"Hello, world!\"); }); thread的常用API: thread::sleep(dur: Duration) 使得当前线程等待一段时间继续执行。在等待的时间内，线程调度器会调度其他的线程来执行。 thread::yield_now() 放弃当前线程的执行，要求线程调度器执行线程切换。 thread::current() 获得当前的线程。 thread::park() 暂停当前线程，进入等待状态。当thread::Thread::unpark(&self)方法被调用的时候，这个线程可以被恢复执行。 thread::Thread::unpark(&self) 综合例子如下: use std::thread; use std::time::Duration; fn main() { let t = thread::Builder::new() .name(\"child1\".to_string()) .spawn(move || { println!(\"enter child thread.\"); thread::park(); println!(\"resume child thread\"); }) .unwrap(); println!(\"spawn a thread\"); thread::sleep(Duration::new(5, 0)); t.thread().unpark(); t.join(); println!(\"child thread finished\"); } rust怎么保证线程安全 下面的代码编译不过: use std::thread; fn main() { let mut health = 12; thread::spawn(|| { health *= 2; }); println!(\"{}\", health); } spawn函数接受的参数是一个闭包。我们在闭包里面引用了函数体内的局部变量，而这个闭包是运行在另外一个线程上，编译器无法肯定局部变量health的生命周期一定大于闭包的生命周期，于是发生了错误. 如果在闭包前面加move, 虽然能够编译过, 但运行结果是health还是12, 因为move的语义是copy, 导致在闭包里面的health已经不是外面的health了. rust编译器可以识别下面的代码, 带不带move都编译不过. use std::thread; fn main() { let mut v: Vec = vec![]; thread::spawn(|| { v.push(1); }); println!(\"{:?}\", v); } 那么rust能不能让一个变量在不同的线程中共享呢? 答: 不能. 我们没有办法在多线程中直接读写普通的共享变量，除非使用Rust提供的线程安全相关的设施 。 The compiler prevents all data races. “共享不可变，可变不共享” Send & Sync std::marker::Sync: 如果类型T实现了Sync类型，那说明在不同的线程中使用&T访问同一个变量是安全的。 std::marker::Send: 如果类型T实现了Send类型，那说明这个类型的变量在不同的线程中传递所有权是安全的。 在spawn签名中: pub fn spawn(f: F) -> JoinHandle where F: FnOnce() -> T, F: Send + 'static, T: Send + 'static 我们需要注意的是，参数类型F有重要的约束条件F: Send+'static， T: Send+'static。它要求参数满足传递所有权的约束, 但凡在线程之间传递所有权会发生安全问题的类型，都无法在这个参数中出现，否则就是编译错误。另外，Rust对全局变量也有很多限制，你不可能简单地通过全局变量在多线程中随意共享状态。这样，编译器就会禁止掉可能有危险的线程间共享数据的行为。 什么是Send类型 Types that can be transferred across thread boundaries. This trait is automatically implemented when the compiler determines it's appropriate. Send trait由编译器自动判断并实现. 如果一个类型可以安全地从一个线程move进入另一个线程，那它就是Send类型。比如: 普通的数字类型是Send，因为我们把数字move进入另一个线程之后，两个线程同时执行也不会造成什么安全问题. 更进一步，内部不包含引用的类型，都是Send。因为这样的类型跟外界没有什么关联，当它被move进入另一个线程之后，它所有的部分都跟原来的线程没什么关系了，不会出现并发访问的情况。比如String类型。 稍微复杂一点的，具有泛型参数的类型，是否满足Send大多是取决于参数类型是否满足Send。比如Vec，只要我们能保证T: Send，那么Vec肯定也是Send，把它move进入其他线程是没什么问题的。再比如Cell、RefCell、Option、Box，也都是这种情况。 还比如加锁的类型也是Send类型, 比如Mutex就是这种。 Mutex这个类型实际上不关心它内部类型是怎样的，反正要访问内部数据，一定要调用lock()方法上锁，它的所有权在哪个线程中并不重要，所以把它move到其他线程也是没有问题的. 那什么不是send类型呢? 答案是编译器报错的就不是. 比如Rc 什么是Sync类型 Types for which it is safe to share references between threads. This trait is automatically implemented when the compiler determines it's appropriate. Sync trait由编译器自动判断并实现. 如果类型T实现了Sync trait，那说明在不 同的线程中使用&T访问同一个变量是安全的。注意这里是&T是只读的. 显然，基本数字类型肯定是Sync。假如不同线程都拥有指向同一个i32类型的只读引用&i32，这是没什么问题的。因为这个类型引用只能读，不能写。多个线程读同一个整数是安全的。 -- 这里我有疑问, 如果所有权的线程去写呢? 不就不安全了么? 大部分具有泛型参数的类型是否满足Sync，很多都是取决于参数类 型是否满足Sync。像Box、Vec Option 这种也是Sync的，只要其中的参数T是满足Sync的。 也有一些类型，不论泛型参数是否满足Sync，它都是满足Sync的。 这种类型把不满足Sync条件的类型用它包起来，就变成了满足Sync条件 的。Mutex就是这种。多个线程同时拥有&Mutex型引用，指向同一个变量是没问题的。 保证线程安全的类型 Arc Arc是Rc的线程安全版本。它的全称是“Atomic reference counter”。 use std::sync::Arc; use std::thread; fn main() { let numbers: Vec = (0..100u32).collect(); // 引用计数指针,指向一个 Vec let shared_numbers = Arc::new(numbers); // 循环创建 10 个线程 for _ in 0..10 { // 复制引用计数指针,所有的 Arc 都指向同一个 Vec let child_numbers = shared_numbers.clone(); // move修饰闭包,上面这个 Arc 指针被 move 进入了新线程中 thread::spawn(move || { // 我们可以在新线程中使用 Arc,读取共享的那个 Vec let local_numbers = &child_numbers[..]; // 继续使用 Vec 中的数据 }); } } Mutex 下面我们用一个示例来演示一下Arc和Mutex配合。使用多线程修改共享变量: use std::sync::Arc; use std::sync::Mutex; use std::thread; const COUNT: u32 = 1000000; fn main() { let global = Arc::new(Mutex::new(0)); let clone1 = global.clone(); let thread1 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone1.lock().unwrap(); *value += 1; } }); let clone2 = global.clone(); let thread2 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone2.lock().unwrap(); *value -= 1; } }); thread1.join().ok(); thread2.join().ok(); println!(\"final value: {:?}\", global); } 而MutexGuard类型则是一个“智能指针”类型，它实现了DerefMut和Deref这两个trait，所以它可以被当作指向内部数据的普通指针使用。 MutexGuard实现了一个析构函数，通过RAII手法，在析构函数中调用了unlock()方法解锁。因此，用户是不需要手动调用方法解锁的 RwLock use std::sync::Arc; use std::sync::RwLock; use std::thread; const COUNT: u32 = 1000000; fn main() { let global = Arc::new(RwLock::new(0)); let clone1 = global.clone(); let thread1 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone1.write().unwrap(); *value += 1; } }); let clone2 = global.clone(); let thread2 = thread::spawn(move || { for _ in 0..COUNT { let mut value = clone2.write().unwrap(); *value -= 1; } }); thread1.join().ok(); thread2.join().ok(); println!(\"final value: {:?}\", global); } Atomic use std::sync::atomic::{AtomicIsize, Ordering}; use std::sync::Arc; use std::thread; const COUNT: u32 = 1000000; fn main() { // Atomic 系列类型同样提供了线程安全版本的内部可变性 let global = Arc::new(AtomicIsize::new(0)); let clone1 = global.clone(); let thread1 = thread::spawn(move || { for _ in 0..COUNT { clone1.fetch_add(1, Ordering::SeqCst); } }); let clone2 = global.clone(); let thread2 = thread::spawn(move || { for _ in 0..COUNT { clone2.fetch_sub(1, Ordering::SeqCst); } }); thread1.join().ok(); thread2.join().ok(); println!(\"final value: {:?}\", global); } Barrier use std::sync::{Arc, Barrier}; use std::thread; fn main() { let barrier = Arc::new(Barrier::new(10)); let mut handlers = vec![]; for _ in 0..10 { let c = barrier.clone(); // The same messages will be printed together. // You will NOT see any interleaving. let t = thread::spawn(move || { println!(\"before wait\"); c.wait(); println!(\"after wait\"); }); handlers.push(t); } for h in handlers { h.join().ok(); } } 这个程序创建了一个多个线程之间共享的Barrier，它的初始值是10。我们创建了10个子线程，每个子线程都有一个Arc指针指向了这个Barrier，并在子线程中调用了Barrier::wait方法。这些子线程执行到 wait方法的时候，就开始进入等待状态，一直到wait方法被调用了10 次，10个子线程都进入等待状态，此时Barrier就通知这些线程可以继续了。然后它们再开始执行下面的逻辑。 Condvar 等待和通知的机制 use std::sync::{Arc, Condvar, Mutex}; use std::thread; use std::time::Duration; fn main() { let pair = Arc::new((Mutex::new(false), Condvar::new())); let pair2 = pair.clone(); thread::spawn(move || { thread::sleep(Duration::from_secs(1)); let &(ref lock, ref cvar) = &*pair2; let mut started = lock.lock().unwrap(); *started = true; cvar.notify_one(); println!(\"child thread {}\", *started); }); // wait for the thread to start up let &(ref lock, ref cvar) = &*pair; let mut started = lock.lock().unwrap(); println!(\"before wait {}\", *started); while !*started { started = cvar.wait(started).unwrap(); } println!(\"after wait {}\", *started); } 全局变量 Rust中允许存在全局变量。在基本语法章节讲过，使用static关键字修饰的变量就是全局变量。全局变量有一个特点: 如果要修改全局变量，必须使用unsafe关键字 线程局部存储 线程局部(Thread Local)的意思是，声明的这个变量看起来是一个变量，但它实际上在每一个线程中分别有自己独立的存储地址，是不同的变量，互不干扰。在不同线程中，只能看到与当前线程相关联的那个副本，因此对它的读写无须考虑线程安全问题。 可以使用#[thread_local]attribute 可以使用thread_local！宏 异步管道 相当于无限扩容的go channel, 但只是多生产单消费异步管道是最常用的一种管道类型。它的特点是: 发送端和接收端之间存在一个缓冲区，发送端发送数据的时候，是先将这个数据扔到缓冲区，再由接收端自己去取。因此，每次发送，立马就返回了，发送端不用管数据什么时候被接收端处理 use std::sync::mpsc::channel; use std::thread; fn main() { let (tx, rx) = channel(); thread::spawn(move || { for i in 0..10 { tx.send(i).unwrap(); //这里依次发送10个数字, 改成tx.send(\"hello\")发字符串也行的. } }); while let Ok(r) = rx.recv() { println!(\"received {}\", r); } } channel是个泛型函数: pub fn channel() -> (Sender, Receiver) Sender和Receiver 都是泛型类型，且一组发送者和接收者必定是同样的类型参数，因此保 证了发送和接收端都是同样的类型。因为Rust中的类型推导功能的存在，使我们可以在调用channel的时候不指定具体类型参数，而通过后续的方法调用，推导出正确的类型参数。 Sender和Receiver的泛型参数必须满足T: Send约束。这个条件是显而易见的: 被发送的消息会从一个线程转移到另外一个线程，这个约束是为了满足线程安全。如果用户指定的泛型参数没有满足条件，在编译的时候会发生错误，提醒我们修复bug。 发送者调用send方法，接收者调用recv方法，返回类型都是Result类型，用于错误处理，因为它们都有可能调用失败。当发送者已经被销毁 的时候，接收者调用recv则会返回错误；同样，当接收者已经销毁的时候，发送者调用send也会返回错误。 在管道的接收端，如果调用recv方法的时候还没有数据，它会进入等待状态阻塞当前线程，直到接收到数据才继续往下执行。 同步管道 相当于go channel 异步管道内部有一个不限长度的缓冲区，可以一直往里面填充数据，直至内存资源耗尽。异步管道的发送端调用send方法不会发生阻塞，只要把消息加入到缓冲区，它就马上返回。 同步管道的特点是: 其内部有一个固定大小的缓冲区，用来缓存消息。如果缓冲区被填满了，继续调用send方法的时候会发生阻塞，等待接收端把缓冲区内的消息拿走才能继续发送。缓冲区的长度可以在建立管道的时候设置，而且0是有效数值。如果缓冲区的长度设置为0，那就 意味着每次的发送操作都会进入等待状态，直到这个消息被接收端取走才能返回。 第三方线程库 threadpool: threadpool是一个基本的线程池实现use std::sync::mpsc::channel; use threadpool::ThreadPool; fn main() { let n_workers = 4; let n_jobs = 8; let pool = ThreadPool::new(n_workers); let (tx, rx) = channel(); for _ in 0..n_jobs { let tx = tx.clone(); pool.execute(move || { tx.send(1) .expect(\"channel will be there waiting for the pool\"); }); } assert_eq!(rx.iter().take(n_jobs).fold(0, |a, b| a + b), 8); } scoped-threadpool在前面的章节中，我们已经知道，如果要在多线程之间共享变量， 必须使用Arc这样的保证线程安全的智能指针。然而，Arc是有运行期开销的(虽然很小)。假如我们有时候需要子线程访问当前调用栈中的局部变量，而且能保证当前函数的生命周期一定大于子线程的生命周期， 子线程一定先于当前函数退出，那我们能不能直接在子线程中使用最简单的借用指针&来访问父线程栈上的局部对象呢？ parking_lotRust标准库帮我们封装了一些基本的操作系统的同步原语，比如 Mutex Condvar等。一般情况下这些够我们使用了。但是还有一些对性能有极致要求的开发者对标准库的实现并不满意，于是社区里又有人开发出来了一套替代品，在性能和易用性方面，都比标准库更好，这就是 parking_lot库。 crossbeam标准库给了一份mpsc(多生产者单消费者)管道的实现， 但是它有许多缺陷。crossbeam-channel这个库给我们提供了另外一套管 道的实现方式。不仅包括mpsc，还包括mpmc(多生产者多消费者)， 而且使用便捷，执行效率也很高。下面是一个双端管道的使用示例。它基本实现了go语言的内置管道 功能，在执行效率上甚至有过之而无不及:extern crate crossbeam; #[macro_use] extern crate crossbeam_channel as channel; use channel::{Receiver, Sender}; fn main() { let people = vec![\"Anna\", \"Bob\", \"Cody\", \"Dave\", \"Eva\"]; let (tx, rx) = channel::bounded(1); // Make room for one unmatched send. let (tx, rx) = (&tx, &rx); crossbeam::scope(|s| { for name in people { s.spawn(move || seek(name, tx, rx)); } }); if let Ok(name) = rx.try_recv() { println!(\"No one received {}’s message.\", name); } } // Either send my name into the channel or receive someone else's, whatever happens first. fn seek(name: &'a str, tx: &Sender, rx: &Receiver) { select_loop! { recv(rx, peer) => println!(\"{} received a message from {}.\", name, peer), send(tx, name) => {}, // Wait for someone to receive my message. } } rayon Rayon是Rust核心组成员Nicholas Matsakis开发的一个并行迭代器项目。它可以把一个按顺序执行的任务轻松变成并行执行。它非常轻量级，效率极高，而且使用非常简单。而且它保证了无数据竞争的线程安全。 "},"notes/rust_工程构建.html":{"url":"notes/rust_工程构建.html","title":"工程构建","keywords":"","body":" 测试和文档测试 详细解释crate和mod的文档 项目和模块 cargo cargo.toml 错误处理 问号运算符 和C的ABI兼容 从C调用Rust库 从Rust调用C库 文档 测试和文档测试 rust原生支持测试, 还支持对文档中的example代码进行测试. https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/testing.html 详细解释crate和mod的文档 https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/crates-and-modules.html cargo build会根据约定俗成的规则来编译bin或者lib, 大体上是通过分析目录结构, 和特殊的文件名, 比如main.rs, lib.rs, mod.rs等. $ tree . . ├── Cargo.lock ├── Cargo.toml ├── src │ ├── english │ │ ├── farewells.rs │ │ ├── greetings.rs │ │ └── mod.rs │ ├── japanese │ │ ├── farewells.rs │ │ ├── greetings.rs │ │ └── mod.rs │ └── lib.rs └── target ├── deps ├── libphrases-a7448e02a0468eaa.rlib └── native 项目和模块 Rust用了两个概念来管理项目：一个是crate，一个是mod。 crate简单理解就是一个项目。crate是Rust中的独立编译单元。每个 crate对应生成一个库或者可执行文件（如.lib .dll .so .exe等）。官方有一 个crate仓库https://crates.io/ ，可以供用户发布各种各样的库，用户也可 以直接使用这里面的开源库。 mod简单理解就是命名空间。mod可以嵌套，还可以控制内部元素的可见性。 crate和mod有一个重要区别是：crate之间不能出现循环引用；而mod是无所谓的，mod1要使用mod2的内容，同时mod2要使用mod1的内容，是完全没问题的。在Rust里面，crate才是一个完整的编译单元 （compile unit）。也就是说，rustc编译器必须把整个crate的内容全部读进去才能执行编译，rustc不是基于单个的.rs文件或者mod来执行编译的。作为对比，C/C++里面的编译单元是单独的.c/.cpp文件以及它们所有的include文件。每个.c/.cpp文件都是单独编译，生成.o文件，再把这些.o文件链接起来。 cargo Cargo是官方的项目管理工具 新建一个hello world工程cargo new hello_world --bin 新建一个hello world库cargo new hello_world --lib 编译cargo build --release cargo.toml 举例: [package] name = \"seccompiler\" version = \"1.1.0\" authors = [\"Amazon Firecracker team \"] edition = \"2018\" build = \"../../build.rs\" description = \"Program that compiles multi-threaded seccomp-bpf filters expressed as JSON into raw BPF programs, serializing them and outputting them to a file.\" homepage = \"https://firecracker-microvm.github.io/\" license = \"Apache-2.0\" [[bin]] name = \"seccompiler-bin\" path = \"src/seccompiler_bin.rs\" [dependencies] bincode = \"1.2.1\" libc = \">=0.2.39\" serde = { version = \">=1.0.27\", features = [\"derive\"] } serde_json = \">=1.0.9\" utils = { path = \"../utils\" } The Cargo.toml file for each package is called its manifest. It is written in the TOML format. Every manifest file consists of the following sections:参考: https://doc.rust-lang.org/cargo/reference/manifest.html cargo-features — Unstable, nightly-only features. [package] — Defines a package. name — The name of the package. version — The version of the package. authors — The authors of the package. edition — The Rust edition. rust-version — The minimal supported Rust version. description — A description of the package. documentation — URL of the package documentation. readme — Path to the package's README file. homepage — URL of the package homepage. repository — URL of the package source repository. license — The package license. license-file — Path to the text of the license. keywords — Keywords for the package. categories — Categories of the package. workspace — Path to the workspace for the package. build — Path to the package build script. links — Name of the native library the package links with. exclude — Files to exclude when publishing. include — Files to include when publishing. publish — Can be used to prevent publishing the package. metadata — Extra settings for external tools. default-run — The default binary to run by cargo run. autobins — Disables binary auto discovery. autoexamples — Disables example auto discovery. autotests — Disables test auto discovery. autobenches — Disables bench auto discovery. resolver — Sets the dependency resolver to use. Target tables: (see configuration for settings) [lib] — Library target settings. [[bin]] — Binary target settings. [[example]] — Example target settings. [[test]] — Test target settings. [[bench]] — Benchmark target settings. Dependency tables: [dependencies] — Package library dependencies. [dev-dependencies] — Dependencies for examples, tests, and benchmarks. [build-dependencies] — Dependencies for build scripts. [target] — Platform-specific dependencies. [badges] — Badges to display on a registry. [features] — Conditional compilation features. [patch] — Override dependencies. [replace] — Override dependencies (deprecated). [profile] — Compiler settings and optimizations. [workspace] — The workspace definition. 错误处理 比如使用Option表示some和none两种可能, 返回Result既有值又有错误 impl str { pub fn find>(&'a self, pat: P) -> Option {} } impl File { pub fn open>(path: P) -> io::Result {} } 比如 use std::mem::{size_of, size_of_val}; use std::str::FromStr; use std::string::ParseError; fn main() { let r: Result = FromStr::from_str(\"hello\"); println!(\"Size of String: {}\", size_of::()); println!(\"Size of `r`: {}\", size_of_val(&r)); } 问号运算符 问号运算符意思是，如果结果是Err，则提前返回一个Result类型，否则继续执行。 标准库的Option、Result实现了问号需要的trait fn file_double>(file_path: P) -> Result { let mut file = File::open(file_path).map_err(|e| e.to_string())?; let mut contents = String::new(); file.read_to_string(&mut contents) .map_err(|err| err.to_string())?; let n = contents .trim() .parse::() .map_err(|err| err.to_string())?; Ok(2 * n) } 进一步简化: use std::fs::File; use std::io::Read; use std::path::Path; fn file_double>(file_path: P) -> Result> { let mut file = File::open(file_path)?; let mut contents = String::new(); file.read_to_string(&mut contents)?; let n = contents.trim().parse::()?; Ok(2 * n) } fn main() { match file_double(\"foobar\") { Ok(n) => println!(\"{}\", n), Err(err) => println!(\"Error: {:?}\", err), } } 跟其他很多运算符一样，问号运算符也对应着标准库中的一个trait std::ops::Try trait Try { type Ok; type Error; fn into_result(self) -> Result; fn from_error(v: Self::Error) -> Self; fn from_ok(v: Self::Ok) -> Self; } 和C的ABI兼容 Rust有一个非常好的特性，就是它支持与C语言的ABI兼容. 所以，我们可以用Rust写一个库，然后直接把它当成C写的库来使用。或者反过来，用C写的库，可以直接在Rust中被调用。而且这个过程是没有额外性能损失的。C语言的ABI是这个世界上最通用的ABI，大部分编程语言都支持与C的ABI兼容。这也意味着，Rust与其他语言之间的交互是没问题的，比如用Rust为Python/Node.js/Ruby写一个模块等。 rust编译选项有--crate-type [bin|lib|rlib|dylib|cdylib|staticlib|proc-macro]其中，cdylib和staticlib就是与C的ABI兼容的 Rust 中有泛型，C语言里面没有，所以泛型这种东西是不可能暴露出来给C语言使用的，这就不是C语言的ABI的一部分。只有符合C语言的调用方式的函数，才能作为FFI的接口。这样的函数有以下基本要求： 使用extern \"C\"修饰，在Rust中extern fn默认等同于extern \"C\" fn； 使用#[no_mangle]修饰函数，避免名字重整； 函数参数、返回值中使用的类型，必须在Rust和C里面具备同样的内存布局。 从C调用Rust库 假设我们要在Rust中实现一个把字符串从小写变大写的函数，然后 由C语言调用这个函数: 在Rust侧: #[no_mangle] pub extern \"C\" fn rust_capitalize(s: *mut c_char) { unsafe { let mut p = s as *mut u8; while *p != 0 { let ch = char::from(*p); if ch.is_ascii() { let upper = ch.to_ascii_uppercase(); *p = upper as u8; } p = p.offset(1); } } } 我们在Rust中实现这个函数，考虑到C语言调用的时候传递的是char*类型，所以在Rust中我们对应的参数类型是*mut std::os:: raw::c_char。这样两边就对应起来了。 用下面的命令生成一个c兼容的静态库: rustc --crate-type=staticlib capitalize.rs 在C里面调用: #include #include // declare extern void rust_capitalize(char *); int main() { char str[] = \"hello world\"; rust_capitalize(str); printf(\"%s\\n\", str); return 0; } 用下面的命令链接: gcc -o main main.c -L. -l:libcapitalize.a -Wl,--gc-sections -lpthread -ldl 从Rust调用C库 比如c的函数 int add_square(int a, int b) { return a * a + b * b; } 在rust里面调用: use std::os::raw::c_int; #[link(name = \"simple_math\")] extern \"C\" { fn add_square(a: c_int, b: c_int) -> c_int; } fn main() { let r = unsafe { add_square(2, 2) }; println!(\"{}\", r); } //编译: //rustc -L . call_math.rs 文档 特殊的文档注释 是///、//！、/**…*/、/*！…*/，它们会被视为文档 mod foo { //! 这块文档是给 `foo` 模块做的说明 /// 这块文档是给函数 `f` 做的说明 fn f() { // 这块注释不是文档的一部分 } } 文档还支持markdown格式 "},"notes/rust_vmm_brief.html":{"url":"notes/rust_vmm_brief.html","title":"VMM(virtual machine monitor)","keywords":"","body":"介绍Firecracker Cloud-hypervisor以及virtio基础概念. 转录自我的PPT VMM brief Virtio devices MMIO based virtio devices PCI based virtio devices Memory Manager in cloud-hypervisor Device Manager Virtio Net example VMM brief Virtio devices Virtio is a protocol that defines how guest drivers talk to virtual devices. See the spec v1.2.Virtio devices can be exposed by PCI or MMIO PCI: a device with PCI vendor ID 0x1AF4 is a virtio device, device configuration structures are mapped to PCI configuration header BAR 0 Common configuration: feature bits, queue num, queue size, queue select, queue address Notifications: driver writes to notification address triggers an event to device ISR Status: not used when msi-x is enabled Device-specific configuration: different virtio types(net, block…) have different layouts PCI configuration access: provide an alternative way to access above registers other than BAR MMIO: a region of predefined register layout starting at base address, with compatible = \"virtio,mmio“ in DTS, which can be “discovered” by guest driver. All registers are little endian MMIO based virtio devices PCI based virtio devices Memory Manager in cloud-hypervisor Defines VM physical memory layout, just like a new SOC Uses BtreeMap to record memory ranges Uses KVM_SET_USER_MEMORY_REGION ioctl to map the layout to VMM virtual memory. (VM_PA to HOST_VA) When guest VM access memory, 2 stages translate happens(e.g. AARCH64): VM_VA -> VM_PA HOST_VA -> HOST_PA Mainly focus on PCI MMIO space PCI MMCONFIG space AARCH64 VM_PA layout Device Manager Manages all PCI devices Virtio PCI devices VFIO PCI devices Normally has 2 PCI segments Segment 0 is default Each PCI segment has PCI root, vendor ID intel, device ID VIRT_PCIE_HOST Uses HashMap to map bdf to PciDevice A pci config mmio BusDevice to route mm config access to corresponding PciDevice A MMIO address Allocator And many VirtioPciDevices Virtio Net example Virtio net has at least 3 virtqueues Transmitq Receiveq Controlq Driver sends and receives packet driver puts a packet into transmitq Notifies device by writing the notification address of the queue Kvm delivers the notification VMM handles the packet, typically by forwarding it to tap VMM receives the reply packet from tap VMM injects interrupt through KVM Guest irq handler receives the packet Guest driver handles the received packet and hands over it to upper network stack. The content in the virtqueue is virtio_net_hdr + packet data "},"notes/rust_vmm_简介.html":{"url":"notes/rust_vmm_简介.html","title":"rust-vmm简介","keywords":"","body":"https://github.com/rust-vmm Rust-Vmm 是一个开源工程，是一个可以自由定制的 VMM（virtual machine monitor）虚拟机管理器，用户可以按照自己的方式订制它。它是基于 Rust 语言实现的 VMM，有着 Rust 语言带来的优点和特性。 首先，Rust 语言一个内存安全的语言，相比于用 C 或者 C++ 会频繁遇到的各种内存的问题，比如内存的溢出、空指针、野指针、越界访问等等，更进一步会造成安全的问题、性能的问题，以及各种崩溃的问题。Rust 语言很好地解决了这一点，从它的语法、编译规则等杜绝了内存级别访问的漏洞以及风险，所以用 Rust 写的 Rust-Vmm 天然的就是内存安全的。 第二，Rust-Vmm 是不易被攻击的，Rust-VMM 是从零开始的，它是从最小的硬件虚拟化出发的，最小的硬件虚拟化意味着它有着最小的攻击面，被攻击的面就非常少，所以它会很安全。 第三，Rust-Vmm 能够很灵活的定制。Rust-VMM 可以灵活定制它的每一个组件，所有的对于设备的模拟或者关键特性的处理都是封装成了一个一个的 Rust-Vmm crates 包，比如有 VCPU，有 linuxloader，vm-virtIO 等等。其中 crates 是 Rust 语言中的包管理工具，可以理解 JAVA 或 golang 里面的 package，它是以发行不同的包或者库的形式对外发布它的 feature。 第四，Rust-Vmm 有非常高的性能，基于 Rust 语言的 without garbage collection 特性，它是没有 GC 回收检查机制的，不像 JAVA 或者其他更高级的语言会有一个 runtime，Rust-Vmm 的性能上会更好，同时基于 KVM 实现的虚拟化方案也是性能的保证。 简单介绍一下 Rust-Vmm 的一个历史，它是由谷歌首先实现的，谷歌首先实现一个 Rust based 的轻量级的 VMM，它叫做 crosVM，大家也可以从链接里面看到，它是一个为 chrome 浏览器做的一个微内核。然后 AWS，亚马逊基于谷歌开源出来的 crosVM，实现了自己的基于 rust 的 VMM 叫 Firecracker。两个项目的开发人员会发现做这两个项目的时候，会有很多重复的重叠的通用的代码，很自然的把可以开源的、通用的部分结合到一块，就有了 Rust-Vmm 的项目。 使用rust vmm crosvm 使用rust vmm 参考https://opensource.com/article/19/3/rust-virtual-machine要自己搭一个vmm, 可以使用rust rmm提供的各种模块, 这些模块都是独立的项目, rust里面叫crate. KVM interface: Creating our VMM on top of KVM requires an interface that can invoke KVM functionality from Rust. The kvm-bindings crate represents the Rust Foreign Function Interface (FFI) to KVM kernel headers. Because headers only include structures and defines, we also have wrappers over the KVM ioctls (kvm-ioctls) that we use for opening dev/kvm, creating a VM, creating vCPUs, and so on. Virtio devices and rate limiting: Virtio has a frontend-backend architecture. Currently in rust-vmm, the frontend is implemented in the virtio-devices crate, and the backend lies in the vhost package. Vhost has support for both user-land and kernel-land drivers, but users can also plug virtio-devices to their custom backend. The virtio-bindings are the bindings for Virtio devices generated using the Virtio Linux headers. All devices in the virtio-devices crate are exported independently as modules using conditional compilation. Some devices, such as block, net, and vsock support rate limiting in terms of I/O per second and bandwidth. This can be achieved by using the functionality provided in the rate-limiter crate. The kernel-loader is responsible for loading the contents of an ELF kernel image in guest memory. rust-vmm的github上, 各个模块是单独成库的: crosvm crosvm是google的为chrome OS上运行的VMM, 安全性好, Rust写的. Rust也是静态binary 每个虚拟设备是个进程,fork出来的, 但不exec. 这个进程用了minijail做沙盒处理, 应该类似seccomp. 基于KVM 使用Rust 支持x86, aarch64 virtual device使用socket和VM通信 设备模型的核心是bus, 一个读/写操做到bus上, bus会按这个读或写的地址, 找到对应的BusDevice, 转发读/写请求到该BusDevice. 一个地址上只能有一个BusDevice BusDevice可能出现在多个地址 每个BusDevice都自带mutex, 所以BusDevice的实现里就不需要再加锁了. "},"notes/rust_firecracker_代码.html":{"url":"notes/rust_firecracker_代码.html","title":"firecracker代码","keywords":"","body":"firecracker是最终的可执行文件: run_without_api流程 build_microvm_from_json event manager aarch64 物理内存layout devices::Bus 底层serial 用法 Serial结构体 三个Trait 自定义Error 用NoEvents的实例化的Serial driver在哪里读写? SerialWrapper 从stdin读输入发给guest流程 实现了BusDevice的按地址读写的trait attach_virtio_device vm.register_ioevent(queue_evt, &io_addr, i as u32) vm.register_irqfd kvm的irq相关API KVM_CREATE_IRQCHIP KVM_SET_GSI_ROUTING KVM_IRQFD KVM_CREATE_DEVICE 都有哪些可以被create ARM gic v3 KVM_DEV_ARM_VGIC_GRP_ADDR MmioTransport impl MmioTransport 实现BusDevice device device的状态有 IrqTrigger VirtioDevice trait VirtIO设备框图 virtIO net Net实现了VirtioDevice Net还实现了MutEventSubscriber run_without_api流程 这里重点考察build/cargo_target/x86_64-unknown-linux-musl/release/firecracker --no-api --config-file myvmconfig.json方式运行的firecrackermyvmconfig.json内容如下: { \"boot-source\": { \"kernel_image_path\": \"build/kernel/linux-5.10/vmlinux-5.10-x86_64.bin\", \"boot_args\": \"console=ttyS0 reboot=k panic=1 pci=off\", \"initrd_path\": null }, \"drives\": [ { \"drive_id\": \"rootfs\", \"path_on_host\": \"build/rootfs/bionic.rootfs.ext4\", \"is_root_device\": true, \"partuuid\": null, \"is_read_only\": false, \"cache_type\": \"Unsafe\", \"io_engine\": \"Sync\", \"rate_limiter\": null } ], \"machine-config\": { \"vcpu_count\": 2, \"mem_size_mib\": 1024, \"smt\": false, \"track_dirty_pages\": false }, \"balloon\": null, \"network-interfaces\": [], \"vsock\": null, \"logger\": null, \"metrics\": null, \"mmds-config\": null } 经过前面的命令行参数解析, 最后调用 run_without_api( &seccomp_filters, //这个是seccomp的bpf代码 vmm_config_json, //这个是配置文件的字符串 instance_info, boot_timer_enabled, mmds_size_limit, metadata_json.as_deref(), ) 这个函数先从json构建vmm, 然后在循环里run: fn run_without_api( seccomp_filters: &BpfThreadMap, config_json: Option, instance_info: InstanceInfo, bool_timer_enabled: bool, mmds_size_limit: usize, metadata_json: Option, ) -> FcExitCode { let mut event_manager = EventManager::new().expect(\"Unable to create EventManager\"); // Create the firecracker metrics object responsible for periodically printing metrics. let firecracker_metrics = Arc::new(Mutex::new(metrics::PeriodicMetrics::new())); event_manager.add_subscriber(firecracker_metrics.clone()); // Build the microVm. We can ignore VmResources since it's not used without api. let (_, vmm) = match build_microvm_from_json( seccomp_filters, &mut event_manager, // Safe to unwrap since '--no-api' requires this to be set. config_json.unwrap(), instance_info, bool_timer_enabled, mmds_size_limit, metadata_json, ) { Ok((res, vmm)) => (res, vmm), Err(exit_code) => return exit_code, }; // Start the metrics. firecracker_metrics .lock() .expect(\"Poisoned lock\") .start(metrics::WRITE_METRICS_PERIOD_MS); // Run the EventManager that drives everything in the microVM. loop { event_manager .run() .expect(\"Failed to start the event manager\"); if let Some(exit_code) = vmm.lock().unwrap().shutdown_exit_code() { return exit_code; } } } build_microvm_from_json就用到了核心模块vmm firecracker/src/vmm/src build_microvm_from_json build_microvm_from_json //根据json填充VmResources结构体并初始化 let mut vm_resources = VmResources::from_json() let vmm = vmm::builder::build_microvm_for_boot(&vm_resources) //建立guest内存, 思路是在host上mmap, 并记录内存region到变量 let guest_memory = create_guest_memory() //在x86上, 0-768M是内存, 768M到4G是MMIO, 4G以上还是内存 let arch_mem_regions = arch::arch_memory_regions(mem_size) vm_memory::create_guest_memory(&arch_mem_regions) 为每个region mmap一个region //先mmap一个大的size, size=原size+2个page, 属性是libc::PROT_NONE // Map the guarded range to PROT_NONE let guard_addr = unsafe { libc::mmap( std::ptr::null_mut(), guarded_size, libc::PROT_NONE, libc::MAP_ANONYMOUS | libc::MAP_PRIVATE | libc::MAP_NORESERVE, -1, 0, ) }; //再在刚刚map的region里面, 用原size map一个读写region // Inside the protected range, starting with guard_addr + PAGE_SIZE, // map the requested range with received protection and flags let region_addr = unsafe { libc::mmap( region_start_addr as *mut libc::c_void, //前面返回的addr加个page size, prot, flags | libc::MAP_FIXED, fd, offset as libc::off_t, ) }; //最后build MmapRegion并返回, 用的是https://github.com/rust-vmm/vm-memory //到这里好像只是生成GuestMemoryMmap数据结果, 并没有实际操作啥 //加载linux 内核, 代码在firecracker/src/vmm/src/builder.rs let entry_addr = load_kernel(boot_config, &guest_memory)?; let kernel_file = 先open kernel文件 //使用了https://github.com/rust-vmm/linux-loader //下面的Loader在x86上是ELF, 在ARM上是PE //把kernel_file加载到guest_memory let entry_addr = Loader::load::( &guest_memory, &kernel_file, arch::get_kernel_start()) //上面这个get_kernel_start()在x86上是1MB, aarch64上是2GB //先读elf header, 解析所有program header到 let mut phdrs: Vec = vec![]; for 每个phdr //写入guest内存, 似乎只是写入host上mmap的内存. 可能后面会用kvm的api把这些内存映射成guest内存 guest_mem.read_exact_from(mem_offset, kernel_image, phdr.p_filesz as usize) //从guest_memory find 一个region, 并写入initrd的内容; //在我们的配置里, initrd是null let initrd = load_initrd_from_config(boot_config, &guest_memory)?; //重写cmdline, 再原基础上增加virtio等配置 //创建VM let (mut vmm, mut vcpus) = create_vmm_and_vcpus( instance_info, event_manager, guest_memory, None, track_dirty_pages, vcpu_config.vcpu_count, )?; // Set up Kvm Vm and register memory regions. //调用kvm-ioctls let mut vm = setup_kvm_vm(&guest_memory, track_dirty_pages)?; //open /dev/kvm, 然后ioctl KVM_CREATE_VM let mut vm = Vm::new() vm.memory_init() //每个region调用 ioctl KVM_SET_USER_MEMORY_REGION //MMIO_MEM_START在x86上是(4G-768M), 在aarch64上是1G //IRQ_BASE到IRQ_MAX在x86上是5到23, 在aarch64上是32到128 //这里说的是virtio设备用的irq号范围 //mmio_device_manager包括mmio_base, irq, 和bus let mmio_device_manager = MMIODeviceManager::new(arch::MMIO_MEM_START, (arch::IRQ_BASE, arch::IRQ_MAX)); //IrqManager是管理(first..last)irq范围的简单结构体 IrqManager::new() //device的bus是个BtreeMap组织的按地址空间划分的设备的集合 devices::Bus::new() //创建中断控制器 setup_interrupt_controller(&mut vm)?; //x86上是ioctl KVM_CREATE_IRQCHIP //aarch64上是GICv2::create(vm, vcpu_count) vm.setup_irqchip() //新建个eventfd let vcpus_exit_evt = EventFd::new(libc::EFD_NONBLOCK) vcpus = create_vcpus(&vm, vcpu_count, &vcpus_exit_evt) //for里创建n个vCPU, ioctl KVM_CREATE_VCPU let vcpu = Vcpu::new() vcpu.kvm_vcpu.init(vm.fd()) set_stdout_nonblocking(); // servial device是pio设备, 在x86上有, aarch64上没有 let serial_device = setup_serial_device(event_manager, stdin, stdout) //由Serial device写1产生event let interrupt_evt = EventFdTrigger::new(EventFd::new(EFD_NONBLOCK)) //表示in buffer ready let kick_stdin_read_evt = EventFdTrigger::new(EventFd::new(EFD_NONBLOCK)) //SerialWrapper是event和Servial的桥梁 let serial = SerialWrapper { serial: Serial::with_events( interrupt_evt, SerialEventsWrapper { metrics: METRICS.uart.clone(), buffer_ready_event_fd: Some(kick_stdin_read_evt), }, out, ), input: Some(input), } //加入event manager, 最后的event loop里面会监听stdin和kick_stdin_read_evt fd event_manager.add_subscriber(serial.clone()); //只有x86有pio device, 把上面的serial_device加入到pio_device_manager let pio_device_manager = create_pio_dev_manager_with_legacy_devices(&vm, serial_device, reset_evt) let vmm = Vmm { events_observer: Some(Box::new(SerialStdin::get())), instance_info: instance_info.clone(), shutdown_exit_code: None, vm, guest_memory, uffd, vcpus_handles: Vec::new(), vcpus_exit_evt, mmio_device_manager, #[cfg(target_arch = \"x86_64\")] pio_device_manager, }; //最后返回vmm, vcpus Ok((vmm, vcpus)) //这个是给测试用的, kernel启动完成后, test版本的init会直接写/dev/mem某个地址魔术字(123) attach_boot_timer_device(&mu vmm, request_ts)?; let boot_timer = devices::pseudo::BootTimer::new(request_ts); //在mmio里面分配地址空间, 所谓的注册就是按地址空间assign设备, 设备有读写函数 vmm.mmio_device_manager.register_mmio_boot_timer(boot_timer) //目前balloon设备没使能 attach_balloon_device(&mut vmm, &mut boot_cmdline, balloon, event_manager)?; attach_virtio_device(event_manager, vmm, id, balloon.clone(), cmdline) event_manager.add_subscriber(device.clone()); let device = MmioTransport::new(vmm.guest_memory().clone(), device); //分配mmio地址范围, 注册到mmio manager; 并修改cmdline vmm.mmio_device_manager.register_mmio_virtio_for_boot(vmm.vm.fd(), id, device, cmdline) //可能有多个virtio块设备 attach_block_devices( &mut vmm, &mut boot_cmdline, vm_resources.block.list.iter(), event_manager, )?; for 每个 block //如果是root device, 就增加cmdline \"root=/dev/vda\"或\"root=PARTUUID=partuuid\" //见下面的函数分析 attach_virtio_device(event_manager, vmm, id, block.clone(), cmdline)?; //可能有多个virtio net设备 attach_net_devices( &mut vmm, &mut boot_cmdline, vm_resources.net_builder.iter(), event_manager, )?; //对应virtio socket device //guest可以通过AF_VSOCK通过vsock device和host的AF_UNIX socket通信 attach_unixsock_vsock_device(&mut vmm, &mut boot_cmdline, unix_vsock, event_manager)?; configure_system_for_boot( &vmm, vcpus.as_mut(), vcpu_config, entry_addr, &initrd, boot_cmdline, )?; //启动vcpu到pause状态 // Move vcpus to their own threads and start their state machine in the 'Paused' state. vmm.start_vcpus( vcpus, seccomp_filters .get(\"vcpu\") .ok_or_else(|| MissingSeccompFilters(\"vcpu\".to_string()))? .clone(), ) //给每个vcpu起个thread thread::Builder::new().spawn(move || { //Runs the vCPU in KVM context in a loop. Handles KVM_EXITs then goes back in. //run的逻辑是执行StateMachine循环 //state machine从paused开始 self.run(filter); //状态机循环 while let Some(state_fn) = state_machine.function { // Run the current state handler, and get the next one. state_machine = state_fn(machine); } }) //使能seccomp seccompiler::apply_filter() // The vcpus start off in the `Paused` state, let them run. vmm.resume_vm().map_err(Internal)?; self.mmio_device_manager.kick_devices(); //对每个vCPU send event let vmm = Arc::new(Mutex::new(vmm)); event_manager.add_subscriber(vmm.clone()); VmResources定义如下: 一个VMM就由block vsock balloon net等builder构成 #[derive(Default)] pub struct VmResources { /// The vCpu and memory configuration for this microVM. vm_config: VmConfig, /// The boot configuration for this microVM. boot_config: Option, /// The block devices. pub block: BlockBuilder, /// The vsock device. pub vsock: VsockBuilder, /// The balloon device. pub balloon: BalloonBuilder, /// The network devices builder. pub net_builder: NetBuilder, /// The optional Mmds data store. // This is initialised on demand (if ever used), so that we don't allocate it unless it's // actually used. pub mmds: Option>>, /// Data store limit for the mmds. pub mmds_size_limit: usize, /// Whether or not to load boot timer device. pub boot_timer: bool, } event manager https://github.com/rust-vmm/event-manager 使用了epoll机制的事件驱动库 基本上是个epoll的event loop, event subscriber注册的时候掉哟init, 在loop里有对应的event就调用process. aarch64 物理内存layout // ==== Address map in use in ARM development systems today ==== // // - 32-bit - - 36-bit - - 40-bit - //1024GB + + +-------------------+ devices::Bus 一个device都对应一段地址空间, 一个bus包括多个device, 按BtreeMap组织, key是device的地址范围, value是BusDevice /// A device container for routing reads and writes over some address space. /// /// This doesn't have any restrictions on what kind of device or address space this applies to. The /// only restriction is that no two devices can overlap in this address space. #[derive(Clone, Default)] pub struct Bus { //bus下面是BtreeMap管理的device devices: BTreeMap>>, } Bus有get_device, insert, read, write方法. read和write的基本逻辑是通过地址来判断是哪个device, 然后lock这个设备, 然后read/write 比如: /// Reads data from the device that owns the range containing `addr` and puts it into `data`. /// /// Returns true on success, otherwise `data` is untouched. pub fn read(&self, addr: u64, data: &mut [u8]) -> bool { //self.get_device(addr)返回(offset,dev), offset就是\"设备内\"偏移地址 if let Some((offset, dev)) = self.get_device(addr) { // OK to unwrap as lock() failing is a serious error condition and should panic. dev.lock() .expect(\"Failed to acquire device lock\") .read(offset, data); true } else { false } } 底层serial vm-superio-0.5.0/src/serial.rs serial是个泛型的结构体: The serial console emulation is done by emulating a serial COM port. Each serial COM port (COM1-4) has an associated Port I/O address base and 12 registers mapped into 8 consecutive Port I/O locations (with the first one being the base). This structure emulates the registers that make sense for UART 16550 (and below) and helps in the interaction between the driver and device by using a Trigger object for notifications. It also writes the guest's output to an out Write object. serial模拟了UART的16550的12个寄存器 用法 use std::io::{sink, Error, Result}; use std::ops::Deref; use vm_superio::Trigger; use vm_superio::Serial; use vmm_sys_util::eventfd::EventFd; struct EventFdTrigger(EventFd); impl Trigger for EventFdTrigger { type E = Error; fn trigger(&self) -> Result { self.write(1) } } impl Deref for EventFdTrigger { type Target = EventFd; fn deref(&self) -> &Self::Target { &self.0 } } impl EventFdTrigger { pub fn new(flag: i32) -> Self { EventFdTrigger(EventFd::new(flag).unwrap()) } pub fn try_clone(&self) -> Self { EventFdTrigger((**self).try_clone().unwrap()) } } let intr_evt = EventFdTrigger::new(libc::EFD_NONBLOCK); let mut serial = Serial::new(intr_evt.try_clone(), Vec::new()); // std::io::Sink can be used if user is not interested in guest's output. let serial_with_sink = Serial::new(intr_evt, sink()); // Write 0x01 to THR register. serial.write(0, 0x01).unwrap(); // Read from RBR register. let value = serial.read(0); // Send more bytes to the guest in one shot. let input = &[b'a', b'b', b'c']; // Before enqueuing bytes we first check if there is enough free space // in the FIFO. if serial.fifo_capacity() >= input.len() { serial.enqueue_raw_bytes(input).unwrap(); } Serial结构体 这是个泛型, 需要用三个trait: Trigger, SerialEvents, Write来实例化. pub struct Serial { // Some UART registers. baud_divisor_low: u8, baud_divisor_high: u8, interrupt_enable: u8, interrupt_identification: u8, line_control: u8, line_status: u8, modem_control: u8, modem_status: u8, scratch: u8, // This is the buffer that is used for achieving the Receiver register // functionality in FIFO mode. Reading from RBR will return the oldest // unread byte from the RX FIFO. in_buffer: VecDeque, // Used for notifying the driver about some in/out events. interrupt_evt: T, events: EV, out: W, } 三个Trait pub trait SerialEvents { /// The driver reads data from the input buffer. fn buffer_read(&self); /// The driver successfully wrote one byte to serial output. fn out_byte(&self); /// An error occurred while writing a byte to serial output resulting in a lost byte. fn tx_lost_byte(&self); /// This event can be used by the consumer to re-enable events coming from /// the serial input. fn in_buffer_empty(&self); } //一般都是EventFD, 用于trigger通知guest driver? pub trait Trigger { /// Underlying type for the potential error conditions returned by `Self::trigger`. type E; /// Trigger an event. fn trigger(&self) -> Result; } //Write就是io哪个Write 自定义Error /// Errors encountered while handling serial console operations. #[derive(Debug)] pub enum Error { /// Failed to trigger interrupt. Trigger(E), /// Couldn't write/flush to the given destination. IOError(io::Error), /// No space left in FIFO. FullFifo, } 用NoEvents的实例化的Serial NoEvents结构体就是实现了一个啥也不干的SerialEvents pub struct NoEvents; impl SerialEvents for NoEvents { fn buffer_read(&self) {} fn out_byte(&self) {} fn tx_lost_byte(&self) {} fn in_buffer_empty(&self) {} } 一个更具体的实例化: impl Serial { /// Creates a new `Serial` instance which writes the guest's output to /// `out` and uses `trigger` object to notify the driver about new /// events. /// /// # Arguments /// * `trigger` - The Trigger object that will be used to notify the driver /// about events. /// * `out` - An object for writing guest's output to. In case the output /// is not of interest, /// [std::io::Sink](https://doc.rust-lang.org/std/io/struct.Sink.html) /// can be used here. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn new(trigger: T, out: W) -> Serial { Self::with_events(trigger, NoEvents, out) } } 同样的Serial是范围更大的泛型: impl Serial { /// Creates a new `Serial` instance which writes the guest's output to /// `out`, uses `trigger` object to notify the driver about new /// events, and invokes the `serial_evts` implementation of `SerialEvents` /// during operation. /// /// # Arguments /// * `trigger` - The `Trigger` object that will be used to notify the driver /// about events. /// * `serial_evts` - The `SerialEvents` implementation used to track the occurrence /// of significant events in the serial operation logic. /// * `out` - An object for writing guest's output to. In case the output /// is not of interest, /// [std::io::Sink](https://doc.rust-lang.org/std/io/struct.Sink.html) /// can be used here. pub fn with_events(trigger: T, serial_evts: EV, out: W) -> Self { //用了很多const定义个u8的常量, 比如DEFAULT_BAUD_DIVISOR_LOW是0x0C Serial { baud_divisor_low: DEFAULT_BAUD_DIVISOR_LOW, baud_divisor_high: DEFAULT_BAUD_DIVISOR_HIGH, interrupt_enable: DEFAULT_INTERRUPT_ENABLE, interrupt_identification: DEFAULT_INTERRUPT_IDENTIFICATION, line_control: DEFAULT_LINE_CONTROL, line_status: DEFAULT_LINE_STATUS, modem_control: DEFAULT_MODEM_CONTROL, modem_status: DEFAULT_MODEM_STATUS, scratch: DEFAULT_SCRATCH, in_buffer: VecDeque::new(), interrupt_evt: trigger, events: serial_evts, out, } } /// Provides a reference to the interrupt event object. pub fn interrupt_evt(&self) -> &T { &self.interrupt_evt } /// Provides a reference to the serial events object. pub fn events(&self) -> &EV { &self.events } //具体操作, 私有方法, 基本上是对结构体的各field进行操作 fn is_dlab_set(&self) -> bool { (self.line_control & LCR_DLAB_BIT) != 0 } //还有很多, 省略 //读写函数, 谁来读写? driver //write不是io Write的格式, offset是预定义的常量表中的常量 /// Handles a write request from the driver at `offset` offset from the /// base Port I/O address. /// /// # Arguments /// * `offset` - The offset that will be added to the base PIO address /// for writing to a specific register. /// * `value` - The byte that should be written. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn write(&mut self, offset: u8, value: u8) -> Result> { match offset { DLAB_LOW_OFFSET if self.is_dlab_set() => self.baud_divisor_low = value, DLAB_HIGH_OFFSET if self.is_dlab_set() => self.baud_divisor_high = value, //关键路径, 每次写入一个字节; 写到stdout DATA_OFFSET => { let res = self .out //重点是这里, 这个out一般是stdout, guest driver的write, 通过这里的Serial Device(Self), 写到stdout .write_all(&[value]) .map_err(Error::IOError) .and_then(|_| self.out.flush().map_err(Error::IOError)) .map(|_| self.events.out_byte()) .map_err(|err| { self.events.tx_lost_byte(); err }); // Because we cannot block the driver, the THRE interrupt is sent // irrespective of whether we are able to write the byte or not self.thr_empty_interrupt().map_err(Error::Trigger)?; return res; } _ => {} } Ok(()) } //读的逻辑是从self.in_buffer pop出一个字节, 返回给调用者. /// Handles a read request from the driver at `offset` offset from the /// base Port I/O address. /// /// Returns the read value. /// /// # Arguments /// * `offset` - The offset that will be added to the base PIO address /// for reading from a specific register. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn read(&mut self, offset: u8) -> u8 { match offset { DLAB_LOW_OFFSET if self.is_dlab_set() => self.baud_divisor_low, DLAB_HIGH_OFFSET if self.is_dlab_set() => self.baud_divisor_high, DATA_OFFSET => { // Here we emulate the reset method for when RDA interrupt // was raised (i.e. read the receive buffer and clear the // interrupt identification register and RDA bit when no // more data is available). self.del_interrupt(IIR_RDA_BIT); let byte = self.in_buffer.pop_front().unwrap_or_default(); if self.in_buffer.is_empty() { self.clear_lsr_rda_bit(); self.events.in_buffer_empty(); } self.events.buffer_read(); byte } LCR_OFFSET => self.line_control, MCR_OFFSET => self.modem_control, LSR_OFFSET => self.line_status, _ => 0, } } /// Returns how much space is still available in the FIFO. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). #[inline] pub fn fifo_capacity(&self) -> usize { FIFO_SIZE - self.in_buffer.len() } /// Helps in sending more bytes to the guest in one shot, by storing /// `input` bytes in UART buffer and letting the driver know there is /// some pending data to be read by setting RDA bit and its corresponding /// interrupt when not already triggered. /// /// # Arguments /// * `input` - The data to be sent to the guest. /// /// # Returns /// /// The function returns the number of bytes it was able to write to the fifo, /// or `FullFifo` error when the fifo is full. Users can use /// [`fifo_capacity`](#method.fifo_capacity) before calling this function /// to check the available space. /// /// # Example /// /// You can see an example of how to use this function in the /// [`Example` section from `Serial`](struct.Serial.html#example). pub fn enqueue_raw_bytes(&mut self, input: &[u8]) -> Result> { let mut write_count = 0; if !self.is_in_loop_mode() { if self.fifo_capacity() == 0 { return Err(Error::FullFifo); } write_count = std::cmp::min(self.fifo_capacity(), input.len()); if write_count > 0 { self.in_buffer.extend(&input[0..write_count]); self.set_lsr_rda_bit(); //就是给Self.interrupt_evt这个eventfd写1 self.received_data_interrupt().map_err(Error::Trigger)?; } } Ok(write_count) } } driver在哪里读写? 待续 SerialWrapper SerialWrapper包括了底层Serial设备和input SerialWrapper: firecracker/src/devices/src/legacy/serial.rs 底层Serial: vm-superio-0.5.0/src/serial.rs pub struct SerialWrapper { pub serial: Serial, pub input: Option>, } 这个结构体是Serial device和event loop之间的桥梁. 之间用eventfd来通知 Host VMM Guest stdin/stdout Serial设备 read/write driver 具体来讲, guest driver通过BusDevice向Serial设备发出读写请求, VMM调用Serial设备的read/write函数来完成响应并在某些情况下触发中断通知(可能是给PioManager), 比如在给in_buffer读到data后产生received_data_interrupt. Serial结构体来维护UART16550的硬件的寄存器level的行为. 从stdin读输入发给guest流程 SerialWrapper的的实例实现了recv_bytes impl SerialWrapper { fn recv_bytes(&mut self) -> io::Result { let avail_cap = self.serial.fifo_capacity(); if let Some(input) = self.input.as_mut() { let mut out = vec![0u8; avail_cap]; //指定cap的vec //从stdin读 let count = input.read(&mut out)?; //看来&mut Vec能当作&mut [u8] if count > 0 { self.serial //这个有点讲究了, raw_input并不是底层Serial的方法, 而是本文件定义的trait //底层调用的是Servial设备的enqueue_raw_bytes方法, 往底层Servial的in_buffer填数据 .raw_input(&out[..count]) .map_err(|_| io::Error::from_raw_os_error(libc::ENOBUFS))?; } return Ok(count); } Err(io::Error::from_raw_os_error(libc::ENOTTY)) } } 这个recv_bytes被MutEventSubscriber trait调用, SerialWrapper也实现了MutEventSubscriber 里面的process就调用了recv_bytes 具体没怎么看懂 impl MutEventSubscriber for SerialWrapper { //process会在发生event的时候被调用, 传入event和ops用来表示event类型和维护event //可能有多个fd的源头, 但都共用这一个process函数. /// Handle events on the serial input fd. fn process(&mut self, event: Events, ops: &mut EventOps) { #[inline] fn unregister_source(ops: &mut EventOps, source: &T) { match ops.remove(Events::new(source, EventSet::IN)) { Ok(_) => (), Err(_) => error!(\"Could not unregister source fd: {}\", source.as_raw_fd()), } } let input_fd = self.serial_input_fd(); let buffer_ready_fd = self.buffer_ready_evt_fd(); if input_fd (), Err(err) => { error!(\"Detach serial device input source due to error in consuming the buffer ready event: {:?}\", err); unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); return; } } } // We expect to receive: `EventSet::IN`, `EventSet::HANG_UP` or // `EventSet::ERROR`. To process all these events we just have to // read from the serial input. match self.recv_bytes() { Ok(count) => { // Handle EOF if the event came from the input source. if input_fd == event.fd() && count == 0 { unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); warn!(\"Detached the serial input due to peer close/error.\"); } } Err(e) => { match e.raw_os_error() { Some(errno) if errno == libc::ENOBUFS => { unregister_source(ops, &input_fd); } //这里是none-block read没东西的时候会返回EAGAIN或者EWOULDBLOCK, 都差不多 Some(errno) if errno == libc::EWOULDBLOCK => { self.handle_ewouldblock(ops); } Some(errno) if errno == libc::ENOTTY => { error!(\"The serial device does not have the input source attached.\"); unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); } Some(_) | None => { // Unknown error, detach the serial input source. unregister_source(ops, &input_fd); unregister_source(ops, &buffer_ready_fd); warn!(\"Detached the serial input due to peer close/error.\"); } } } } } /// Initial registration of pollable objects. /// If serial input is present, register the serial input FD as readable. fn init(&mut self, ops: &mut EventOps) { //input就是stdin, buffer_ready_event_fd就是前面的kick_stdin_read_evt这个eventfd if self.input.is_some() && self.serial.events().buffer_ready_event_fd.is_some() { let serial_fd = self.serial_input_fd(); let buf_ready_evt = self.buffer_ready_evt_fd(); if serial_fd != -1 { //实际上是把stdin加到epoll if let Err(e) = ops.add(Events::new(&serial_fd, EventSet::IN)) { warn!(\"Failed to register serial input fd: {}\", e); } } //这个实际上是kick_stdin_read_evt这个eventfd if let Err(e) = ops.add(Events::new(&buf_ready_evt, EventSet::IN)) { warn!(\"Failed to register serial buffer ready event: {}\", e); } } } } 实现了BusDevice的按地址读写的trait 按总线地址读写, 最终转化为设备内偏移地址读写 impl BusDevice for SerialWrapper { //读是从内部in_buffer读 fn read(&mut self, offset: u64, data: &mut [u8]) { if data.len() != 1 { self.serial.events().metrics.missed_read_count.inc(); return; } data[0] = self.serial.read(offset as u8); } //写是写到stdout fn write(&mut self, offset: u64, data: &[u8]) { if data.len() != 1 { self.serial.events().metrics.missed_write_count.inc(); return; } if let Err(e) = self.serial.write(offset as u8, data[0]) { // Counter incremented for any handle_write() error. error!(\"Failed the write to serial: {:?}\", e); self.serial.events().metrics.error_count.inc(); } } } attach_virtio_device /// Attaches a VirtioDevice device to the device manager and event manager. fn attach_virtio_device( event_manager: &mut EventManager, vmm: &mut Vmm, id: String, device: Arc>, cmdline: &mut LoaderKernelCmdline, ) -> std::result::Result { use self::StartMicrovmError::*; //注册事件订阅 event_manager.add_subscriber(device.clone()); let device = MmioTransport::new(vmm.guest_memory().clone(), device); vmm.mmio_device_manager .register_mmio_virtio_for_boot(vmm.vm.fd(), id, device, cmdline) //分配mmio的addr len和irq资源, 策略是依次顺序分配 let mmio_slot = self.allocate_new_slot(1)?; self.register_mmio_virtio(vm, device_id, mmio_device, &mmio_slot)?; let locked_device = mmio_device.locked_device(); identifier = (DeviceType::Virtio(locked_device.device_type()), device_id); //对每个queue for (i, queue_evt) in locked_device.queue_events().iter().enumerate() //NOTIFY_REG_OFFSET是0x50, 加上slot.addr这个mmio device的base地址 //注意, 并不是所有的mmio设备的地址空间访问都会触发event, 这个io_addr只是特定地址, 用来notify device的. let io_addr = IoEventAddress::Mmio(slot.addr + u64::from(devices::virtio::NOTIFY_REG_OFFSET)); //这个queue_evt是每个queue的eventfd, 写io_addr就会触发event, 说明guest driver要通知device来干活了 //调用了kvm的ioctl vm.register_ioevent(queue_evt, &io_addr, i as u32) //写这指定地址的时候发event到queue_evt vm.register_irqfd() //注册中断注入guest的eventfd和irq号, 调用kvm ioctl KVM_IRQFD; 意思是只要这个eventfd被写入, 内核的kvm模块就会给guest发指定的irq号中断. register_mmio_device() } vm.register_ioevent(queue_evt, &io_addr, i as u32) 三个参数如下: fd - EventFd which will be signaled. When signaling, the usual vmexit to userspace is prevented.addr - Address being written to.datamatch - Limits signaling fd to only the cases where the value being written is equal to this parameter. The size of datamatch is important and it must match the expected size of the guest's write. guest驱动需要某种方法来通知device, kvm的ioeventfd就是干这个用的. 用eventfd的好处是这个guest driver到device的通知不需要vmexit. Registers an event to be signaled whenever a certain address is written to. When signaling, the usual vmexit to userspace is prevented. 对应KVM的KVM_IOEVENTFD This ioctl attaches or detaches an ioeventfd to a legal pio/mmio address within the guest. A guest write in the registered address will signal the provided event instead of triggering an exit. If datamatch flag is set, the event will be signaled only if the written value to the registered address is equal to datamatch in struct kvm_ioeventfd. 注意: 这个对每个queue都调用了vm.register_ioevent(queue_evt, &io_addr, i as u32), 作用是给io_addr地址绑定一个queue_evt, 当driver写i到这个io_aadr地址的时候, signal给queue_evt. 但问题是, 如果是多个queue, 多个queue_evt都\"绑定\"到同一个io_addr.我猜测这个API是支持多个一个地址对应多个eventfd的, 可能由datamatch的值来区分这个signal发送到哪个eventfd vm.register_irqfd vm.register_irqfd(locked_device.interrupt_evt(), slot.irqs[0]) 调用kvm的ioctl的KVM_IRQFD(见下面) IRQFD是device写eventfd, 通过kvm触发guest中断的机制. kvm的irq相关API https://www.kernel.org/doc/html/latest/virt/kvm/api.html KVM_CREATE_IRQCHIP Creates an interrupt controller model in the kernel. On x86, creates a virtual ioapic, a virtual PIC (two PICs, nested), and sets up future vcpus to have a local APIC. IRQ routing for GSIs 0-15 is set to both PIC and IOAPIC; GSI 16-23 only go to the IOAPIC. On arm64, a GICv2 is created. Any other GIC versions require the usage of KVM_CREATE_DEVICE, which also supports creating a GICv2. Using KVM_CREATE_DEVICE is preferred over KVM_CREATE_IRQCHIP for GICv2. On s390, a dummy irq routing table is created. KVM_SET_GSI_ROUTING Sets the GSI routing table entries, overwriting any previously set entries. KVM_IRQFD Allows setting an eventfd to directly trigger a guest interrupt. kvm_irqfd.fd specifies the file descriptor to use as the eventfd and kvm_irqfd.gsi specifies the irqchip pin toggled by this event. When an event is triggered on the eventfd, an interrupt is injected into the guest using the specified gsi pin. The irqfd is removed using the KVM_IRQFD_FLAG_DEASSIGN flag, specifying both kvm_irqfd.fd and kvm_irqfd.gsi. With KVM_CAP_IRQFD_RESAMPLE, KVM_IRQFD supports a de-assert and notify mechanism allowing emulation of level-triggered, irqfd-based interrupts. When KVM_IRQFD_FLAG_RESAMPLE is set the user must pass an additional eventfd in the kvm_irqfd.resamplefd field. When operating in resample mode, posting of an interrupt through kvm_irq.fd asserts the specified gsi in the irqchip. When the irqchip is resampled, such as from an EOI, the gsi is de-asserted and the user is notified via kvm_irqfd.resamplefd. It is the user’s responsibility to re-queue the interrupt if the device making use of it still requires service. Note that closing the resamplefd is not sufficient to disable the irqfd. The KVM_IRQFD_FLAG_RESAMPLE is only necessary on assignment and need not be specified with KVM_IRQFD_FLAG_DEASSIGN. On arm64, gsi routing being supported, the following can happen: in case no routing entry is associated to this gsi, injection fails in case the gsi is associated to an irqchip routing entry, irqchip.pin + 32 corresponds to the injected SPI ID. in case the gsi is associated to an MSI routing entry, the MSI message and device ID are translated into an LPI (support restricted to GICv3 ITS in-kernel emulation). KVM_CREATE_DEVICE Creates an emulated device in the kernel. The file descriptor returned in fd can be used with KVM_SET/GET/HAS_DEVICE_ATTR. If the KVM_CREATE_DEVICE_TEST flag is set, only test whether the device type is supported (not necessarily whether it can be created in the current vm). Individual devices should not define flags. Attributes should be used for specifying any behavior that is not implied by the device type number. 都有哪些可以被create Devices ARM Virtual Interrupt Translation Service (ITS) ARM Virtual Generic Interrupt Controller v2 (VGIC) ARM Virtual Generic Interrupt Controller v3 and later (VGICv3) MPIC interrupt controller FLIC (floating interrupt controller) Generic vcpu interface VFIO virtual device Generic vm interface XICS interrupt controller POWER9 eXternal Interrupt Virtualization Engine (XIVE Gen1) ARM gic v3 Only one VGIC instance may be instantiated through this API. The created VGIC will act as the VM interrupt controller, requiring emulated user-space devices to inject interrupts to the VGIC instead of directly to CPUs. It is not possible to create both a GICv3 and GICv2 on the same VM. Creating a guest GICv3 device requires a host GICv3 as well. KVM_DEV_ARM_VGIC_GRP_ADDR 定义了vgic寄存器在guest物理地址空间的基地址 KVM_VGIC_V3_ADDR_TYPE_DIST (rw, 64-bit) Base address in the guest physical address space of the GICv3 distributor register mappings. Only valid for KVM_DEV_TYPE_ARM_VGIC_V3. This address needs to be 64K aligned and the region covers 64 KByte. KVM_VGIC_V3_ADDR_TYPE_REDIST (rw, 64-bit) Base address in the guest physical address space of the GICv3 redistributor register mappings. There are two 64K pages for each VCPU and all of the redistributor pages are contiguous. Only valid for KVM_DEV_TYPE_ARM_VGIC_V3. This address needs to be 64K aligned. MmioTransport mplements the MMIO transport for virtio devices. This requires 3 points of installation to work with a VM: Mmio reads and writes must be sent to this device at what is referred to here as MMIO base. Mmio::queue_evts must be installed at virtio::NOTIFY_REG_OFFSET offset from the MMIO base. Each event in the array must be signaled if the index is written at that offset. Mmio::interrupt_evt must signal an interrupt that the guest driver is listening to when it is written to. Typically one page (4096 bytes) of MMIO address space is sufficient to handle this transport and inner virtio device. 对应的结构体: pub struct MmioTransport { device: Arc>, // The register where feature bits are stored. pub(crate) features_select: u32, // The register where features page is selected. pub(crate) acked_features_select: u32, pub(crate) queue_select: u32, pub(crate) device_status: u32, pub(crate) config_generation: u32, mem: GuestMemoryMmap, pub(crate) interrupt_status: Arc, } impl MmioTransport impl MmioTransport { /// Constructs a new MMIO transport for the given virtio device. pub fn new(mem: GuestMemoryMmap, device: Arc>) -> MmioTransport { //这里小知识点: device.lock()返回的是mutextGuard, 它会在生命周期结束后自动调用unlock. //不用担心一直会lock, 因为device.lock()的声明周期只有下面一行 //这行结束了其实就已经unlock了. let interrupt_status = device.lock().expect(\"Poisoned lock\").interrupt_status(); //new这个结构体 MmioTransport { device, features_select: 0, acked_features_select: 0, queue_select: 0, device_status: device_status::INIT, config_generation: 0, mem, interrupt_status, } } pub fn locked_device(&self) -> MutexGuard { self.device.lock().expect(\"Poisoned lock\") } // Gets the encapsulated VirtioDevice. pub fn device(&self) -> Arc> { self.device.clone() } fn check_device_status(&self, set: u32, clr: u32) -> bool { self.device_status & (set | clr) == set } fn are_queues_valid(&self) -> bool { self.locked_device() .queues() .iter() .all(|q| q.is_valid(&self.mem)) } //注意到泛型U, 并没有约束; //这里的意思是入参d的类型是U, 表示默认值. fn with_queue(&self, d: U, f: F) -> U where F: FnOnce(&Queue) -> U, { match self .locked_device() .queues() .get(self.queue_select as usize) { Some(queue) => f(queue), None => d, } } fn with_queue_mut(&mut self, f: F) -> bool { if let Some(queue) = self .locked_device() .queues_mut() .get_mut(self.queue_select as usize) { f(queue); true } else { false } } fn update_queue_field(&mut self, f: F) { if self.check_device_status( device_status::FEATURES_OK, device_status::DRIVER_OK | device_status::FAILED, ) { self.with_queue_mut(f); } else { warn!( \"update virtio queue in invalid state 0x{:x}\", self.device_status ); } } fn reset(&mut self) { 重置结构体\"寄存器\" } //根据VirtIO Spec 1.0, section 2.1.1 and 3.1.1 //在device的write里面调用, 实际上是给guest的driver用的 fn set_device_status(&mut self, status: u32) { } } 实现BusDevice 根据virtIO规范MMIO transport方式:https://docs.oasis-open.org/virtio/virtio/v1.2/csd01/virtio-v1.2-csd01.html#x1-1650002 impl BusDevice for MmioTransport { fn read(&mut self, offset: u64, data: &mut [u8]) { match offset { 0x00..=0xff if data.len() == 4 => { let v = match offset { 0x0 => MMIO_MAGIC_VALUE, 0x04 => MMIO_VERSION, 0x08 => self.locked_device().device_type(), 0x0c => VENDOR_ID, // vendor id 0x10 => { //32bit的feature flag let mut features = self .locked_device() .avail_features_by_page(self.features_select); if self.features_select == 1 { features |= 0x1; // enable support of VirtIO Version 1 } features } //对已经选中的queue(QueueSel), 读出queue内元素个数; Reading from the register returns the maximum size (number of elements) of the queue the device is ready to process or zero (0x0) if the queue is not available. 0x34 => self.with_queue(0, |q| u32::from(q.get_max_size())), //对已经选中的queue, 写1表示ready. 读是读上一次的值 0x44 => self.with_queue(0, |q| q.ready as u32), //中断状态寄存器, 要么是Used Buffer Notification(bit 0), 要么是Configuration Change Notification(bit 1) 0x60 => self.interrupt_status.load(Ordering::SeqCst) as u32, //设备状态寄存器. 0x70 => self.device_status, //配置空间原子性寄存器, 两次读的一样就是原子的? 0xfc => self.config_generation, _ => { warn!(\"unknown virtio mmio register read: 0x{:x}\", offset); return; } }; byte_order::write_le_u32(data, v); //注意这里, 使用byte_order的小端写 } 0x100..=0xfff => self.locked_device().read_config(offset - 0x100, data), _ => { warn!( \"invalid virtio mmio read: 0x{:x}:0x{:x}\", offset, data.len() ); } }; } fn write(&mut self, offset: u64, data: &[u8]) { fn hi(v: &mut GuestAddress, x: u32) { *v = (*v & 0xffff_ffff) | (u64::from(x) { let v = byte_order::read_le_u32(data); //按小端方式理解data match offset { //Device (host) features word selection. 写这个寄存器选择feature flag 0x14 => self.features_select = v, //Flags representing device features understood and activated by the driver 0x20 => { if self.check_device_status( device_status::DRIVER, device_status::FEATURES_OK | device_status::FAILED, ) { self.locked_device() .ack_features_by_page(self.acked_features_select, v); } else { warn!( \"ack virtio features in invalid state 0x{:x}\", self.device_status ); } } //Activated (guest) features word selection 0x24 => self.acked_features_select = v, //这个就是QueueSel, 也叫Virtual queue index, 从0开始 0x30 => self.queue_select = v, //Virtual queue size 0x38 => self.update_queue_field(|q| q.size = v as u16), //queue read //Writing one (0x1) to this register notifies the device that it can execute requests from this virtual queue. 0x44 => self.update_queue_field(|q| q.ready = v == 1), //中断应答 0x64 => { if self.check_device_status(device_status::DRIVER_OK, 0) { self.interrupt_status .fetch_and(!(v as usize), Ordering::SeqCst); } } //Device status: Writing non-zero values to this register sets the status flags, indicating the driver progress 0x70 => self.set_device_status(v), //Virtual queue’s Descriptor Area 64 bit long physical address 0x80 => self.update_queue_field(|q| lo(&mut q.desc_table, v)), 0x84 => self.update_queue_field(|q| hi(&mut q.desc_table, v)), //Virtual queue’s Driver Area 64 bit long physical address 0x90 => self.update_queue_field(|q| lo(&mut q.avail_ring, v)), 0x94 => self.update_queue_field(|q| hi(&mut q.avail_ring, v)), //Virtual queue’s Device Area 64 bit long physical address 0xa0 => self.update_queue_field(|q| lo(&mut q.used_ring, v)), 0xa4 => self.update_queue_field(|q| hi(&mut q.used_ring, v)), _ => { warn!(\"unknown virtio mmio register write: 0x{:x}\", offset); } } } 0x100..=0xfff => { if self.check_device_status(device_status::DRIVER, device_status::FAILED) { self.locked_device().write_config(offset - 0x100, data) } else { warn!(\"can not write to device config data area before driver is ready\"); } } _ => { warn!( \"invalid virtio mmio write: 0x{:x}:0x{:x}\", offset, data.len() ); } } } } device device的状态有 /// Enum that indicates if a VirtioDevice is inactive or has been activated /// and memory attached to it. pub enum DeviceState { Inactive, Activated(GuestMemoryMmap), } 这个enum也有方法, 其中mem()方法返回GuestmemoryMmap impl DeviceState { /// Checks if the device is activated. pub fn is_activated(&self) -> bool { match self { DeviceState::Inactive => false, DeviceState::Activated(_) => true, } } /// Gets the memory attached to the device if it is activated. pub fn mem(&self) -> Option { match self { DeviceState::Activated(ref mem) => Some(mem), DeviceState::Inactive => None, } } } IrqTrigger IrqTrigger包含一个eventFd叫irq_evt, trigger_irq方法就是写这个eventFd. /// Helper struct that is responsible for triggering guest IRQs pub struct IrqTrigger { pub(crate) irq_status: Arc, pub(crate) irq_evt: EventFd, } impl IrqTrigger { pub fn new() -> std::io::Result { Ok(Self { irq_status: Arc::new(AtomicUsize::new(0)), irq_evt: EventFd::new(libc::EFD_NONBLOCK)?, }) } pub fn trigger_irq(&self, irq_type: IrqType) -> std::result::Result { let irq = match irq_type { IrqType::Config => VIRTIO_MMIO_INT_CONFIG, IrqType::Vring => VIRTIO_MMIO_INT_VRING, }; //irq状态 self.irq_status.fetch_or(irq as usize, Ordering::SeqCst); //eventfd写1 self.irq_evt.write(1).map_err(|e| { error!(\"Failed to send irq to the guest: {:?}\", e); e })?; Ok(()) } } VirtioDevice trait /// Trait for virtio devices to be driven by a virtio transport. /// /// The lifecycle of a virtio device is to be moved to a virtio transport, which will then query the /// device. The virtio devices needs to create queues, events and event fds for interrupts and expose /// them to the transport via get_queues/get_queue_events/get_interrupt/get_interrupt_status fns. pub trait VirtioDevice: AsAny + Send { /// Get the available features offered by device. fn avail_features(&self) -> u64; /// Get acknowledged features of the driver. fn acked_features(&self) -> u64; /// Set acknowledged features of the driver. /// This function must maintain the following invariant: /// - self.avail_features() & self.acked_features() = self.get_acked_features() fn set_acked_features(&mut self, acked_features: u64); fn has_feature(&self, feature: u64) -> bool { (self.acked_features() & 1 u32; /// Returns the device queues. fn queues(&self) -> &[Queue]; /// Returns a mutable reference to the device queues. fn queues_mut(&mut self) -> &mut [Queue]; /// Returns the device queues event fds. fn queue_events(&self) -> &[EventFd]; /// Returns the device interrupt eventfd. fn interrupt_evt(&self) -> &EventFd; /// Returns the current device interrupt status. fn interrupt_status(&self) -> Arc; /// The set of feature bits shifted by `page * 32`. fn avail_features_by_page(&self, page: u32) -> u32 { let avail_features = self.avail_features(); match page { // Get the lower 32-bits of the features bitfield. 0 => avail_features as u32, // Get the upper 32-bits of the features bitfield. 1 => (avail_features >> 32) as u32, _ => { warn!(\"Received request for unknown features page.\"); 0u32 } } } /// Acknowledges that this set of features should be enabled. fn ack_features_by_page(&mut self, page: u32, value: u32) { let mut v = match page { 0 => u64::from(value), 1 => u64::from(value) { warn!(\"Cannot acknowledge unknown features page: {}\", page); 0u64 } }; // Check if the guest is ACK'ing a feature that we didn't claim to have. let avail_features = self.avail_features(); let unrequested_features = v & !avail_features; if unrequested_features != 0 { warn!(\"Received acknowledge request for unknown feature: {:x}\", v); // Don't count these features as acked. v &= !unrequested_features; } self.set_acked_features(self.acked_features() | v); } /// Reads this device configuration space at `offset`. fn read_config(&self, offset: u64, data: &mut [u8]); /// Writes to this device configuration space at `offset`. fn write_config(&mut self, offset: u64, data: &[u8]); /// Performs the formal activation for a device, which can be verified also with `is_activated`. fn activate(&mut self, mem: GuestMemoryMmap) -> ActivateResult; /// Checks if the resources of this device are activated. fn is_activated(&self) -> bool; /// Optionally deactivates this device and returns ownership of the guest memory map, interrupt /// event, and queue events. fn reset(&mut self) -> Option)> { None } } VirtIO设备框图 virtIO net virtIO net的定义很复杂 pub struct Net { pub(crate) id: String, pub tap: Tap, //对接的tap设备 pub(crate) avail_features: u64, pub(crate) acked_features: u64, pub(crate) queues: Vec, pub(crate) queue_evts: Vec, pub(crate) rx_rate_limiter: RateLimiter, pub(crate) tx_rate_limiter: RateLimiter, pub(crate) rx_deferred_frame: bool, rx_deferred_irqs: bool, rx_bytes_read: usize, rx_frame_buf: [u8; MAX_BUFFER_SIZE], tx_iovec: Vec, tx_frame_buf: [u8; MAX_BUFFER_SIZE], pub(crate) irq_trigger: IrqTrigger, //中断触发, 里面是eventfd pub(crate) config_space: ConfigSpace, pub(crate) guest_mac: Option, pub(crate) device_state: DeviceState, pub(crate) activate_evt: EventFd, pub mmds_ns: Option, #[cfg(test)] pub(crate) mocks: Mocks, } Net实现了很多方法, 比如交换tap设备和queue的数据: impl Net { new_with_tap() id() guest_mac() iface_name() mmds_ns() signal_used_queue() {self.irq_trigger.trigger_irq()} signal_rx_used_queue() do_write_frame_to_guest( write_frame_to_guest() read_from_mmds_or_tap() //处理从tap设备来的数据, 然后给guest发irq: //self.signal_used_queue() -> self.irq_trigger.trigger_irq(IrqType::Vring) 还是写eventfd process_rx() handle_deferred_frame() resume_rx() process_tx() read_tap() process_rx_queue_event() process_tap_rx_event() process_tx_queue_event() process_virtio_queues() } Net实现了VirtioDevice 相对比较薄的一层, 实现了下面的方法: Net还实现了MutEventSubscriber impl MutEventSubscriber for Net { fn process(&mut self, event: Events, ops: &mut EventOps) { let source = event.fd(); let event_set = event.event_set(); // TODO: also check for errors. Pending high level discussions on how we want // to handle errors in devices. let supported_events = EventSet::IN; if !supported_events.contains(event_set) { warn!( \"Received unknown event: {:?} from source: {:?}\", event_set, source ); return; } if self.is_activated() { let virtq_rx_ev_fd = self.queue_evts[RX_INDEX].as_raw_fd(); let virtq_tx_ev_fd = self.queue_evts[TX_INDEX].as_raw_fd(); let rx_rate_limiter_fd = self.rx_rate_limiter.as_raw_fd(); let tx_rate_limiter_fd = self.tx_rate_limiter.as_raw_fd(); let tap_fd = self.tap.as_raw_fd(); let activate_fd = self.activate_evt.as_raw_fd(); // Looks better than C style if/else if/else. match source { _ if source == virtq_rx_ev_fd => self.process_rx_queue_event(), _ if source == tap_fd => self.process_tap_rx_event(), //tap设备来数据了 _ if source == virtq_tx_ev_fd => self.process_tx_queue_event(), _ if source == rx_rate_limiter_fd => self.process_rx_rate_limiter_event(), _ if source == tx_rate_limiter_fd => self.process_tx_rate_limiter_event(), _ if activate_fd == source => self.process_activate_event(ops), _ => { warn!(\"Net: Spurious event received: {:?}\", source); METRICS.net.event_fails.inc(); } } } else { warn!( \"Net: The device is not yet activated. Spurious event received: {:?}\", source ); } } fn init(&mut self, ops: &mut EventOps) { // This function can be called during different points in the device lifetime: // - shortly after device creation, // - on device activation (is-activated already true at this point), // - on device restore from snapshot. if self.is_activated() { self.register_runtime_events(ops); } else { self.register_activate_event(ops); } } } "},"notes/rust_firecracker_使用.html":{"url":"notes/rust_firecracker_使用.html","title":"firecracker使用","keywords":"","body":" 编译 编译firecracker 编译kernel 编译rootfs 运行 配置文件方式运行 rest API方式运行 devctr镜像 顶层cargo firecracker/tools/devtool脚本 cmd_build 先build seccompiler 再build rebase-snap build firecracker build jailer build_kernel build_rootfs firecracker/resources/tests/init.c firecracker/resources/tests/fillmem.c firecracker/resources/tests/readmem.c 做镜像 编译 先clone代码: git clone https://github.com/firecracker-microvm/firecracker 编译firecracker firecracker是rust写的, 但编译不需要本地依赖rust环境, 而是在docker内完成的. 使用了docker imagepublic.ecr.aws/firecracker/fcuvm:v35, 大小3.25G 因为使用了x86_64-unknown-linux-musl做为target, 所以最后的可执行文件是静态链接的 默认debug版本:tools/devtool build生成:build/cargo_target/x86_64-unknown-linux-musl/debug/firecracker 38M, 静态链接, 带符号 指定release版本tools/devtool build --release生成:build/cargo_target/x86_64-unknown-linux-musl/release/firecracker 4.1M, 静态链接, 带符号 编译kernel tools/devtool build_kernel -c resources/guest_configs/microvm-kernel-x86_64-5.10.config -n 8生成:build/kernel/linux-5.10/vmlinux-5.10-x86_64.bin 42M, 带符号的linux elf, 模块全部编入kernel. 编译rootfs tools/devtool build_rootfs -s 300MB生成:build/rootfs/bionic.rootfs.ext4 300M 运行 配置文件方式运行 build/cargo_target/x86_64-unknown-linux-musl/release/firecracker --api-sock /tmp/firecracker.socket --config-file myvmconfig.json会打印kernel启动过程, 并自动以root登陆 myvmconfig.json内容如下: { \"boot-source\": { \"kernel_image_path\": \"build/kernel/linux-5.10/vmlinux-5.10-x86_64.bin\", \"boot_args\": \"console=ttyS0 reboot=k panic=1 pci=off\", \"initrd_path\": null }, \"drives\": [ { \"drive_id\": \"rootfs\", \"path_on_host\": \"build/rootfs/bionic.rootfs.ext4\", \"is_root_device\": true, \"partuuid\": null, \"is_read_only\": false, \"cache_type\": \"Unsafe\", \"io_engine\": \"Sync\", \"rate_limiter\": null } ], \"machine-config\": { \"vcpu_count\": 2, \"mem_size_mib\": 1024, \"smt\": false, \"track_dirty_pages\": false }, \"balloon\": null, \"network-interfaces\": [], \"vsock\": null, \"logger\": null, \"metrics\": null, \"mmds-config\": null } 跑的是ubuntu, 带systemd的 启动迅速 reboot会触发kernel退出, 但并不重启 没有网络接口 根文件系统挂在/dev/vda上 VM配置了1024M内存, 但运行时firecracker进程占用95M, 虚拟内存1032M. rest API方式运行 firecracker启动的时候要指定一个API socket, 每个VM一个. 使用这个socket, 可以用rest API方式来运行和管理VM. devctr镜像 devctr是开发中使用的镜像, 所有的操作都通过这个镜像完成. 基于ubuntu18 安装了常用的开发工具binutils-dev clang cmake gcc 等等 安装了rustcurl https://sh.rustup.rs -sSf | sh -s -- -y rustup target add x86_64-unknown-linux-musl rustup component add rustfmt rustup component add clippy-preview rustup install \"stable\" 使用了开源的init程序, 静态编译版本# Add the tini init binary. ADD https://github.com/krallin/tini/releases/download/${TINI_VERSION_TAG}/tini-static-amd64 /sbin/tini RUN chmod +x /sbin/tini WORKDIR \"$FIRECRACKER_SRC_DIR\" ENTRYPOINT [\"/sbin/tini\", \"--\"] 顶层cargo cargo.toml [workspace] members = [\"src/firecracker\", \"src/jailer\", \"src/seccompiler\", \"src/rebase-snap\"] default-members = [\"src/firecracker\"] [profile.dev] panic = \"abort\" [profile.release] panic = \"abort\" lto = true [patch.crates-io] kvm-bindings = { git = \"https://github.com/firecracker-microvm/kvm-bindings\", tag = \"v0.5.0-1\", features = [\"fam-wrappers\"] } cargo的build系统会自动维护cargo.lock来描述版本信息. 下面的命令可以更新依赖的版本信息: $ cargo update # updates all dependencies $ cargo update -p regex # updates just “regex” firecracker/tools/devtool脚本 # By default, all devtool commands run the container transparently, removing # it after the command completes. Any persisting files will be stored under # build/. # If, for any reason, you want to access the container directly, please use # `devtool shell`. This will perform the initial setup (bind-mounting the # sources dir, setting privileges) and will then drop into a BASH shell inside # the container. # # Building: # Run `./devtool build`. # By default, the debug binaries are built and placed under build/debug/. # To build the release version, run `./devtool build --release` instead. # You can then find the binaries under build/release/. # # Testing: # Run `./devtool test`. # This will run the entire integration test battery. The testing system is # based on pytest (http://pytest.org). # # Opening a shell prompt inside the development container: # Run `./devtool shell`. # # Additional information: # Run `./devtool help`. run_devctr函数写的很好. docker -v的z参数表示可以共享, 参考https://docs.docker.com/storage/bind-mounts/#configure-the-selinux-label # Helper function to run the dev container. # Usage: run_devctr -- # Example: run_devctr --privileged -- bash -c \"echo 'hello world'\" run_devctr() { docker_args=() ctr_args=() docker_args_done=false while [[ $# -gt 0 ]]; do [[ \"$1\" = \"--\" ]] && { docker_args_done=true shift continue } [[ $docker_args_done = true ]] && ctr_args+=(\"$1\") || docker_args+=(\"$1\") shift done # If we're running in a terminal, pass the terminal to Docker and run # the container interactively [[ -t 0 ]] && docker_args+=(\"-i\") [[ -t 1 ]] && docker_args+=(\"-t\") # Try to pass these environments from host into container for network proxies proxies=(http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY) for i in \"${proxies[@]}\"; do if [[ ! -z ${!i} ]]; then docker_args+=(\"--env\") && docker_args+=(\"$i=${!i}\") fi done # Finally, run the dev container # Use 'z' on the --volume parameter for docker to automatically relabel the # content and allow sharing between containers. docker run \"${docker_args[@]}\" \\ --rm \\ --volume /dev:/dev \\ --volume \"$FC_ROOT_DIR:$CTR_FC_ROOT_DIR:z\" \\ --env OPT_LOCAL_IMAGES_PATH=\"$(dirname \"$CTR_MICROVM_IMAGES_DIR\")\" \\ --env PYTHONDONTWRITEBYTECODE=1 \\ \"$DEVCTR_IMAGE\" \"${ctr_args[@]}\" } cmd_build 默认debug版本, 默认libc是musl target是x86_64-unknown-linux-musl 先build seccompiler seccompiler是个单独的binary, 把json转成BPF程序保存到文件中. # Build seccompiler-bin. run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build -p seccompiler --bin seccompiler-bin \\ --target-dir \"$CTR_CARGO_SECCOMPILER_TARGET_DIR\" \\ \"${cargo_args[@]}\" ret=$? 注: -p seccompiler: 只build seccompiler 再build rebase-snap Tool that copies all the non-sparse sections from a diff file onto a base file # Build rebase-snap. run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build -p rebase-snap \\ --target-dir \"$CTR_CARGO_REBASE_SNAP_TARGET_DIR\" \\ \"${cargo_args[@]}\" ret=$? build firecracker # Build Firecracker. run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build \\ --target-dir \"$CTR_CARGO_TARGET_DIR\" \\ \"${cargo_args[@]}\" ret=$? build jailer # Build jailer only in case of musl for compatibility reasons. if [ \"$libc\" == \"musl\" ];then run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ ${extra_args} \\ -- \\ cargo build -p jailer \\ --target-dir \"$CTR_CARGO_TARGET_DIR\" \\ \"${cargo_args[@]}\" fi build_kernel 比如:./tools/devtool build_kernel -c resources/guest_configs/microvm-kernel-arm64-4.14.config # arch不同, vmlinux的format也不同 arch=$(uname -m) if [ \"$arch\" = \"x86_64\" ]; then target=\"vmlinux\" cfg_pattern=\"x86\" format=\"elf\" elif [ \"$arch\" = \"aarch64\" ]; then target=\"Image\" cfg_pattern=\"arm64\" format=\"pe\" recipe_url=\"https://raw.githubusercontent.com/rust-vmm/vmm-reference/$recipe_commit/resources/kernel/make_kernel.sh\" # 从自己的github的另一个库rust-vmm/vmm-reference下载 make_kernel.sh run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$kernel_dir_ctr\" \\ -- /bin/bash -c \"curl -LO \"$recipe_url\" && source make_kernel.sh && extract_kernel_srcs \"$KERNEL_VERSION\"\" cp \"$KERNEL_CFG\" \"$kernel_dir_host/linux-$KERNEL_VERSION/.config\" KERNEL_BINARY_NAME=\"vmlinux-$KERNEL_VERSION-$arch.bin\" #真正的make kernel run_devctr \\ --user \"$(id -u):$(id -g)\" \\ --workdir \"$kernel_dir_ctr\" \\ -- /bin/bash -c \"source make_kernel.sh && make_kernel \"$kernel_dir_ctr/linux-$KERNEL_VERSION\" $format $target \"$nprocs\" \"$KERNEL_BINARY_NAME\"\" build_rootfs default rootfs size是300M, 用ubuntu18.04, 目标是$flavour.rootfs.ext4 先编译几个c文件, 用作测试? run_devctr \\ --workdir \"$CTR_FC_ROOT_DIR\" \\ -- /bin/bash -c \"gcc -o $rootfs_dir_ctr/init $resources_dir_ctr/init.c && \\ gcc -o $rootfs_dir_ctr/fillmem $resources_dir_ctr/fillmem.c && \\ gcc -o $rootfs_dir_ctr/readmem $resources_dir_ctr/readmem.c\" firecracker/resources/tests/init.c 在调用/sbin/openrc-init之前, 向/dev/mem的特定地址(比如aarch64的0x40000000 1G)写入数字123 用于通知VMM kernel已经启动完毕 // Base address values are defined in arch/src/lib.rs as arch::MMIO_MEM_START. // Values are computed in arch/src//mod.rs from the architecture layouts. // Position on the bus is defined by MMIO_LEN increments, where MMIO_LEN is // defined as 0x1000 in vmm/src/device_manager/mmio.rs. #ifdef __x86_64__ #define MAGIC_MMIO_SIGNAL_GUEST_BOOT_COMPLETE 0xd0000000 #endif #ifdef __aarch64__ #define MAGIC_MMIO_SIGNAL_GUEST_BOOT_COMPLETE 0x40000000 #endif #define MAGIC_VALUE_SIGNAL_GUEST_BOOT_COMPLETE 123 int main () { int fd = open(\"/dev/mem\", (O_RDWR | O_SYNC | O_CLOEXEC)); int mapped_size = getpagesize(); char *map_base = mmap(NULL, mapped_size, PROT_WRITE, MAP_SHARED, fd, MAGIC_MMIO_SIGNAL_GUEST_BOOT_COMPLETE); *map_base = MAGIC_VALUE_SIGNAL_GUEST_BOOT_COMPLETE; msync(map_base, mapped_size, MS_ASYNC); const char *init = \"/sbin/openrc-init\"; char *const argv[] = { \"/sbin/init\", NULL }; char *const envp[] = { }; execve(init, argv, envp); } firecracker/resources/tests/fillmem.c Usage: ./fillmem mb_count先mmap再memset firecracker/resources/tests/readmem.c Usage: ./readmem mb_count value 做镜像 用ubuntu18.04 container的 truncate -s \"$SIZE\" \"$img_file\" mkfs.ext4 -F \"$img_file\" docker run -v \"$FC_ROOT_DIR:/firecracker\" ubuntu:18.04 bash -s 注: 使用'EOF'格式的heredoc, 其内部的变量不会展开 "},"notes/rust_cloud-hypervisor_代码.html":{"url":"notes/rust_cloud-hypervisor_代码.html","title":"cloud hypervisor代码","keywords":"","body":"cloud hypervisor是一种基于rust-vmm的VMM实现. 它和其他VMM的对比在这里 code walk in single picture 编译 build时可选的feature列表 REST API和CLI 先用cli创建一个empty的实例, 默认1vCPU, 512M内存. 随后用REST API来创建vm 然后boot这个实例 其他命令 cli和REST的关系 http路由 内部channel 代码梳理 main hypervisor的抽象 vm抽象基本上是基于kvm api的 vmops cli create vm代码流程 REST API流程实例 用户发REST API 这个VMM对应的http server响应请求 从http的raw data里(json格式)解析VmConfig vm_create使用内部channel向VMM的API发送请求 内部channel处理请求 处理这次的VmCreate 返回response impl Vmm x86_64和aarch64的mem layout vm_boot DeviceManager DeviceManager结构体 DeviceManager方法 DeviceNode包括id, 资源, 层级, pci信息 PCI segment PciBus PciDevice virtio设备 virtionet Net结构体 impl VirtioDevice for Net activate NetQueuePair 其他trait virtio block IO Bus和MMIO Bus Bus方法 中断 interrupt group 中断控制器 msi中断控制器 MsiInterruptGroup KVM_IRQFD code walk in single picture 编译 git clone https://github.com/cloud-hypervisor/cloud-hypervisor.git cd cloud-hypervisor/ # docker方式编译 -- 推荐 # 如果需要proxy, 在cmd_build函数docker run命令行加--env http_proxy=\"http://10.158.100.6:8080/\" scripts/dev_cli.sh build --release --libc musl # 产生的bin: build/cargo_target/x86_64-unknown-linux-musl/release/cloud-hypervisor # 本地方式编译, 完全静态链接版本要使用x86_64-unknown-linux-musl rustup target add x86_64-unknown-linux-musl # 完全静态版本一定要加--all, 还要安装musl-tools sudo apt install musl-tools cargo build --release --target=x86_64-unknown-linux-musl --all # 产生的bin: target/x86_64-unknown-linux-musl/release/cloud-hypervisor build时可选的feature列表 #[cfg(target_arch = \"x86_64\")] #[cfg(target_arch = \"aarch64\")] #[cfg(feature = \"guest_debug\")] #[cfg(feature = \"fwdebug\")] #[cfg(feature = \"tdx\")] #[cfg(feature = \"kvm\")] #[cfg(all(feature = \"mshv\", target_arch = \"x86_64\"))] #[cfg(feature = \"gdb\")] REST API和CLI cloud hypervisor以cli方式启动, 并启动http服务, 提供REST接口. 如果cli传入vmm的参数, 则http服务会根据后面的REST api来创建VM 先用cli创建一个empty的实例, 默认1vCPU, 512M内存. $ ./target/debug/cloud-hypervisor --api-socket /tmp/cloud-hypervisor.sock Cloud Hypervisor Guest API server: /tmp/cloud-hypervisor.sock vCPUs: 1 Memory: 512 MB Kernel: None Kernel cmdline: Disk(s): None 随后用REST API来创建vm curl --unix-socket /tmp/cloud-hypervisor.sock -i \\ -X PUT 'http://localhost/api/v1/vm.create' \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"cpus\":{\"boot_vcpus\": 4, \"max_vcpus\": 4}, \"kernel\":{\"path\":\"/opt/clh/kernel/vmlinux-virtio-fs-virtio-iommu\"}, \"cmdline\":{\"args\":\"console=ttyS0 console=hvc0 root=/dev/vda1 rw\"}, \"disks\":[{\"path\":\"/opt/clh/images/focal-server-cloudimg-amd64.raw\"}], \"rng\":{\"src\":\"/dev/urandom\"}, \"net\":[{\"ip\":\"192.168.10.10\", \"mask\":\"255.255.255.0\", \"mac\":\"12:34:56:78:90:01\"}] }' 所有的json选项可在vmm/src/config.rs的struct VmConfig里面查看. struct VmConfig用了rust的序列化框架serde, 把结构体直接映射成 然后boot这个实例 curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.boot' 其他命令 # dump vm的config curl --unix-socket /tmp/cloud-hypervisor.sock -i \\ -X GET 'http://localhost/api/v1/vm.info' \\ -H 'Accept: application/json' # reboot vm curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.reboot' # shut down curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.shutdown' cli和REST的关系 http路由 HTTP_ROUTES是个全局变量 lazy_static! { /// HTTP_ROUTES contain all the cloud-hypervisor HTTP routes. pub static ref HTTP_ROUTES: HttpRoutes = { let mut r = HttpRoutes { routes: HashMap::new(), }; r.routes.insert(endpoint!(\"/vm.add-device\"), Box::new(VmActionHandler::new(VmAction::AddDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-user-device\"), Box::new(VmActionHandler::new(VmAction::AddUserDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-disk\"), Box::new(VmActionHandler::new(VmAction::AddDisk(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-fs\"), Box::new(VmActionHandler::new(VmAction::AddFs(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-net\"), Box::new(VmActionHandler::new(VmAction::AddNet(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-pmem\"), Box::new(VmActionHandler::new(VmAction::AddPmem(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vdpa\"), Box::new(VmActionHandler::new(VmAction::AddVdpa(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vsock\"), Box::new(VmActionHandler::new(VmAction::AddVsock(Arc::default())))); r.routes.insert(endpoint!(\"/vm.boot\"), Box::new(VmActionHandler::new(VmAction::Boot))); r.routes.insert(endpoint!(\"/vm.counters\"), Box::new(VmActionHandler::new(VmAction::Counters))); r.routes.insert(endpoint!(\"/vm.create\"), Box::new(VmCreate {})); r.routes.insert(endpoint!(\"/vm.delete\"), Box::new(VmActionHandler::new(VmAction::Delete))); r.routes.insert(endpoint!(\"/vm.info\"), Box::new(VmInfo {})); r.routes.insert(endpoint!(\"/vm.pause\"), Box::new(VmActionHandler::new(VmAction::Pause))); r.routes.insert(endpoint!(\"/vm.power-button\"), Box::new(VmActionHandler::new(VmAction::PowerButton))); r.routes.insert(endpoint!(\"/vm.reboot\"), Box::new(VmActionHandler::new(VmAction::Reboot))); r.routes.insert(endpoint!(\"/vm.receive-migration\"), Box::new(VmActionHandler::new(VmAction::ReceiveMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.remove-device\"), Box::new(VmActionHandler::new(VmAction::RemoveDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize\"), Box::new(VmActionHandler::new(VmAction::Resize(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize-zone\"), Box::new(VmActionHandler::new(VmAction::ResizeZone(Arc::default())))); r.routes.insert(endpoint!(\"/vm.restore\"), Box::new(VmActionHandler::new(VmAction::Restore(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resume\"), Box::new(VmActionHandler::new(VmAction::Resume))); r.routes.insert(endpoint!(\"/vm.send-migration\"), Box::new(VmActionHandler::new(VmAction::SendMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.shutdown\"), Box::new(VmActionHandler::new(VmAction::Shutdown))); r.routes.insert(endpoint!(\"/vm.snapshot\"), Box::new(VmActionHandler::new(VmAction::Snapshot(Arc::default())))); r.routes.insert(endpoint!(\"/vmm.ping\"), Box::new(VmmPing {})); r.routes.insert(endpoint!(\"/vmm.shutdown\"), Box::new(VmmShutdown {})); r }; } 内部channel rust标准库的channel是mpsc, 创建channel: // 编译器会从下文推断出这个channel传输的是ApiRequest let (api_request_sender, api_request_receiver) = std::sync::mpsc::channel(); 这个ApiRequest是个enum, 所有的http请求都定义在这; 注意这里回复还是一个Sender, 里面是ApiResponse. 这个就是rust版本的channel in channel: 发出http请求的一方, 构造请求和一个专有的Sender句柄给服务方, 并等待在对应的Receiver; 服务方把ApiResponse响应写回到这个Sender里面; #[allow(clippy::large_enum_variant)] #[derive(Debug)] pub enum ApiRequest { /// Create the virtual machine. This request payload is a VM configuration /// (VmConfig). /// If the VMM API server could not create the VM, it will send a VmCreate /// error back. VmCreate(Arc>, Sender), /// Boot the previously created virtual machine. /// If the VM was not previously created, the VMM API server will send a /// VmBoot error back. VmBoot(Sender), /// Delete the previously created virtual machine. /// If the VM was not previously created, the VMM API server will send a /// VmDelete error back. /// If the VM is booted, we shut it down first. VmDelete(Sender), /// Request the VM information. VmInfo(Sender), /// Request the VMM API server status VmmPing(Sender), /// Pause a VM. VmPause(Sender), /// Resume a VM. VmResume(Sender), /// Get counters for a VM. VmCounters(Sender), /// Shut the previously booted virtual machine down. /// If the VM was not previously booted or created, the VMM API server /// will send a VmShutdown error back. VmShutdown(Sender), /// Reboot the previously booted virtual machine. /// If the VM was not previously booted or created, the VMM API server /// will send a VmReboot error back. VmReboot(Sender), /// Shut the VMM down. /// This will shutdown and delete the current VM, if any, and then exit the /// VMM process. VmmShutdown(Sender), /// Resize the VM. VmResize(Arc, Sender), /// Resize the memory zone. VmResizeZone(Arc, Sender), /// Add a device to the VM. VmAddDevice(Arc, Sender), /// Add a user device to the VM. VmAddUserDevice(Arc, Sender), /// Remove a device from the VM. VmRemoveDevice(Arc, Sender), /// Add a disk to the VM. VmAddDisk(Arc, Sender), /// Add a fs to the VM. VmAddFs(Arc, Sender), /// Add a pmem device to the VM. VmAddPmem(Arc, Sender), /// Add a network device to the VM. VmAddNet(Arc, Sender), /// Add a vDPA device to the VM. VmAddVdpa(Arc, Sender), /// Add a vsock device to the VM. VmAddVsock(Arc, Sender), /// Take a VM snapshot VmSnapshot(Arc, Sender), /// Restore from a VM snapshot VmRestore(Arc, Sender), /// Incoming migration VmReceiveMigration(Arc, Sender), /// Outgoing migration VmSendMigration(Arc, Sender), // Trigger power button VmPowerButton(Sender), } 代码梳理 main main函数在cloud-hypervisor/src/main.rs fn main() { // Ensure all created files (.e.g sockets) are only accessible by this user let _ = unsafe { libc::umask(0o077) }; //默认vCPU=1, 物理地址46bit; mem=512M; 使用/dev/urandom let (default_vcpus, default_memory, default_rng) = prepare_default_values(); //使用了流行的cli库clap, 瀑布式的定义args //get_matches就是parse()命令行 let cmd_arguments = create_app(&default_vcpus, &default_memory, &default_rng).get_matches(); let exit_code = match start_vmm(cmd_arguments); //支持kvm或mshv, 编译时选择 let hypervisor = hypervisor::new() let kvm_obj = Kvm::new() Ok(KvmHypervisor { kvm: kvm_obj }) let vmm_thread = vmm::start_vmm_thread( env!(\"CARGO_PKG_VERSION\").to_string(), &api_socket_path, api_socket_fd, api_evt.try_clone().unwrap(), http_sender, api_request_receiver, #[cfg(feature = \"gdb\")] gdb_socket_path, #[cfg(feature = \"gdb\")] debug_evt.try_clone().unwrap(), #[cfg(feature = \"gdb\")] vm_debug_evt.try_clone().unwrap(), &seccomp_action, hypervisor, //这个是上面的kvm实例化的hypervisor ) let thread = { //新建thread做主event处理循环 thread::Builder::new() .name(\"vmm\".to_string()) .spawn(move || { //新建vmm, 主要是注册event, 并没有开始真正干活 let mut vmm = Vmm::new( vmm_version.to_string(), api_event, vmm_seccomp_action, hypervisor, exit_evt, )?; //event循环 vmm.control_loop(Arc::new(api_receiver)) let epoll_fd = self.epoll.as_raw_fd(); //在loop里epoll wait, 并根据注册epoll add的token来分发 for event in events.iter().take(num_events) { let dispatch_event: EpollDispatch = event.data.into(); match dispatch_event { EpollDispatch::Unknown => {} EpollDispatch::Exit => {} EpollDispatch::Reset => {} EpollDispatch::ActivateVirtioDevices => {} EpollDispatch::Api => { //consume 触发内部channel的eventfd self.api_evt.read().map_err(Error::EventFdRead)?; //处理内部channel过来的请求并返回结果 let api_request = api_receiver.recv() match api_request { ApiRequest::VmCreate(config, sender) => {} ApiRequest::VmBoot(sender) => {} ... } } } } } }; // 起http线程, 用的是micro_http的库 api::start_http_path_thread() let server = HttpServer::new_from_fd() start_http_thread(server) hread::Builder::new() //新线程 loop { match server.requests() { Ok(request_vec) => { for server_request in request_vec { server.respond(server_request.process( |request| { handle_http_request(request, &api_notifier, &api_sender) } )) } } } } //带api前缀的都是发http请求到vmm.control_loop的. vmm::api::vm_create() vmm::api::vm_boot() //或者vmm::api::vm_restore() vmm_thread.join() std::process::exit(exit_code); } hypervisor的抽象 能在最顶层抽象一个hypervisor, 同时支持多种虚拟化技术. 用了抽象函数返回另一个抽象的模式, 即create_vm返回一个Vm trait object /// /// Trait to represent a Hypervisor /// /// This crate provides a hypervisor-agnostic interfaces /// pub trait Hypervisor: Send + Sync { /// /// Create a Vm using the underlying hypervisor /// Return a hypervisor-agnostic Vm trait object /// fn create_vm(&self) -> Result>; /// /// Create a Vm of a specific type using the underlying hypervisor /// Return a hypervisor-agnostic Vm trait object /// fn create_vm_with_type(&self, _vm_type: u64) -> Result> { unreachable!() } #[cfg(target_arch = \"x86_64\")] /// /// Get the supported CpuID /// fn get_cpuid(&self) -> Result; /// /// Check particular extensions if any /// fn check_required_extensions(&self) -> Result { Ok(()) } #[cfg(target_arch = \"x86_64\")] /// /// Retrieve the list of MSRs supported by the hypervisor. /// fn get_msr_list(&self) -> Result; #[cfg(target_arch = \"aarch64\")] /// /// Retrieve AArch64 host maximum IPA size supported by KVM. /// fn get_host_ipa_limit(&self) -> i32; /// /// Retrieve TDX capabilities /// #[cfg(feature = \"tdx\")] fn tdx_capabilities(&self) -> Result; } vm抽象基本上是基于kvm api的 /// /// Trait to represent a Vm /// /// This crate provides a hypervisor-agnostic interfaces for Vm /// pub trait Vm: Send + Sync { #[cfg(target_arch = \"x86_64\")] /// Sets the address of the one-page region in the VM's address space. fn set_identity_map_address(&self, address: u64) -> Result; #[cfg(target_arch = \"x86_64\")] /// Sets the address of the three-page region in the VM's address space. fn set_tss_address(&self, offset: usize) -> Result; /// Creates an in-kernel interrupt controller. fn create_irq_chip(&self) -> Result; /// Registers an event that will, when signaled, trigger the `gsi` IRQ. fn register_irqfd(&self, fd: &EventFd, gsi: u32) -> Result; /// Unregister an event that will, when signaled, trigger the `gsi` IRQ. fn unregister_irqfd(&self, fd: &EventFd, gsi: u32) -> Result; /// Creates a new KVM vCPU file descriptor and maps the memory corresponding fn create_vcpu(&self, id: u8, vm_ops: Option>) -> Result>; /// Registers an event to be signaled whenever a certain address is written to. fn register_ioevent( &self, fd: &EventFd, addr: &IoEventAddress, datamatch: Option, ) -> Result; /// Unregister an event from a certain address it has been previously registered to. fn unregister_ioevent(&self, fd: &EventFd, addr: &IoEventAddress) -> Result; // Construct a routing entry fn make_routing_entry(&self, gsi: u32, config: &InterruptSourceConfig) -> IrqRoutingEntry; /// Sets the GSI routing table entries, overwriting any previously set fn set_gsi_routing(&self, entries: &[IrqRoutingEntry]) -> Result; /// Creates a memory region structure that can be used with {create/remove}_user_memory_region fn make_user_memory_region( &self, slot: u32, guest_phys_addr: u64, memory_size: u64, userspace_addr: u64, readonly: bool, log_dirty_pages: bool, ) -> MemoryRegion; /// Creates a guest physical memory slot. fn create_user_memory_region(&self, user_memory_region: MemoryRegion) -> Result; /// Removes a guest physical memory slot. fn remove_user_memory_region(&self, user_memory_region: MemoryRegion) -> Result; /// Creates an emulated device in the kernel. fn create_device(&self, device: &mut CreateDevice) -> Result>; /// Returns the preferred CPU target type which can be emulated by KVM on underlying host. #[cfg(any(target_arch = \"arm\", target_arch = \"aarch64\"))] fn get_preferred_target(&self, kvi: &mut VcpuInit) -> Result; /// Enable split Irq capability #[cfg(target_arch = \"x86_64\")] fn enable_split_irq(&self) -> Result; #[cfg(target_arch = \"x86_64\")] fn enable_sgx_attribute(&self, file: File) -> Result; /// Retrieve guest clock. #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] fn get_clock(&self) -> Result; /// Set guest clock. #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] fn set_clock(&self, data: &ClockData) -> Result; #[cfg(feature = \"kvm\")] /// Checks if a particular `Cap` is available. fn check_extension(&self, c: Cap) -> bool; /// Create a device that is used for passthrough fn create_passthrough_device(&self) -> Result>; /// Get the Vm state. Return VM specific data fn state(&self) -> Result; /// Set the VM state fn set_state(&self, state: VmState) -> Result; /// Start logging dirty pages fn start_dirty_log(&self) -> Result; /// Stop logging dirty pages fn stop_dirty_log(&self) -> Result; /// Get dirty pages bitmap fn get_dirty_log(&self, slot: u32, base_gpa: u64, memory_size: u64) -> Result>; #[cfg(feature = \"tdx\")] /// Initalize TDX on this VM fn tdx_init(&self, cpuid: &CpuId, max_vcpus: u32) -> Result; #[cfg(feature = \"tdx\")] /// Finalize the configuration of TDX on this VM fn tdx_finalize(&self) -> Result; #[cfg(feature = \"tdx\")] /// Initalize a TDX memory region for this VM fn tdx_init_memory_region( &self, host_address: u64, guest_address: u64, size: u64, measure: bool, ) -> Result; } vmops vm的op主要针对gpa, guest physical address pub trait VmOps: Send + Sync { // 对guest dram来说的 fn guest_mem_write(&self, gpa: u64, buf: &[u8]) -> Result; fn guest_mem_read(&self, gpa: u64, buf: &mut [u8]) -> Result; // 对guest mmio来说的 fn mmio_read(&self, gpa: u64, data: &mut [u8]) -> Result; fn mmio_write(&self, gpa: u64, data: &[u8]) -> Result; // 对guest pio来说的 #[cfg(target_arch = \"x86_64\")] fn pio_read(&self, port: u64, data: &mut [u8]) -> Result; #[cfg(target_arch = \"x86_64\")] fn pio_write(&self, port: u64, data: &[u8]) -> Result; } cli create vm代码流程 命令行传入的kernel选项, 会被parse成vm config, 再创建vm let vm_params = config::VmParams::from_arg_matches(&cmd_arguments); let vm_config = config::VmConfig::parse(vm_params) // Create and boot the VM based off the VM config we just built. let sender = api_request_sender.clone(); vmm::api::vm_create( api_evt.try_clone().unwrap(), api_request_sender, Arc::new(Mutex::new(vm_config)), ) 这个vm_create就是给内部http服务发请求: pub fn vm_create( api_evt: EventFd, api_sender: Sender, config: Arc>, ) -> ApiResult { let (response_sender, response_receiver) = channel(); // Send the VM creation request. api_sender .send(ApiRequest::VmCreate(config, response_sender)) .map_err(ApiError::RequestSend)?; api_evt.write(1).map_err(ApiError::EventFdWrite)?; response_receiver.recv().map_err(ApiError::ResponseRecv)??; Ok(()) } REST API流程实例 用户发REST API A user or operator sends an HTTP request to the Cloud Hypervisor REST API in order to creates a virtual machine: #!/bin/bash curl --unix-socket /tmp/cloud-hypervisor.sock -i \\ -X PUT 'http://localhost/api/v1/vm.create' \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"cpus\":{\"boot_vcpus\": 4, \"max_vcpus\": 4}, \"kernel\":{\"path\":\"/opt/clh/kernel/vmlinux-virtio-fs-virtio-iommu\"}, \"cmdline\":{\"args\":\"console=ttyS0 console=hvc0 root=/dev/vda1 rw\"}, \"disks\":[{\"path\":\"/opt/clh/images/focal-server-cloudimg-amd64.raw\"}], \"rng\":{\"src\":\"/dev/urandom\"}, \"net\":[{\"ip\":\"192.168.10.10\", \"mask\":\"255.255.255.0\", \"mac\":\"12:34:56:78:90:01\"}] }' 这个VMM对应的http server响应请求 The Cloud Hypervisor HTTP thread processes the request and de-serializes the HTTP request JSON body into an internal VmConfig structure. micro_http响应这个请求, 调用提前注册好的EndpointHandler: // /api/v1/vm.create handler pub struct VmCreate {} impl EndpointHandler for VmCreate { fn handle_request( &self, req: &Request, api_notifier: EventFd, api_sender: Sender, ) -> Response { match req.method() { Method::Put => { match &req.body { Some(body) => { // Deserialize into a VmConfig let vm_config: VmConfig = match serde_json::from_slice(body.raw()) .map_err(HttpError::SerdeJsonDeserialize) { Ok(config) => config, Err(e) => return error_response(e, StatusCode::BadRequest), }; // Call vm_create() match vm_create(api_notifier, api_sender, Arc::new(Mutex::new(vm_config))) .map_err(HttpError::ApiError) { Ok(_) => Response::new(Version::Http11, StatusCode::NoContent), Err(e) => error_response(e, StatusCode::InternalServerError), } } None => Response::new(Version::Http11, StatusCode::BadRequest), } } _ => error_response(HttpError::BadRequest, StatusCode::BadRequest), } } } 从http的raw data里(json格式)解析VmConfig let vm_config: VmConfig = match serde_json::from_slice(body.raw()) vm_create使用内部channel向VMM的API发送请求 vm_create使用内部channel向VMM的API发送请求, 请求的内容是VmConfig, 并使用channel in channel来等待回复 VmCreate(Arc>, Sender) // 构造内部channel let (response_sender, response_receiver) = std::sync::mpsc::channel(); // Send the VM creation request. api_sender .send(ApiRequest::VmCreate(config, response_sender)) .map_err(ApiError::RequestSend)?; api_evt.write(1).map_err(ApiError::EventFdWrite)?; response_receiver.recv().map_err(ApiError::ResponseRecv)??; 内部channel处理请求 // Read from the API receiver channel let api_request = api_receiver.recv().map_err(Error::ApiRequestRecv)?; 处理这次的VmCreate The Cloud Hypervisor control loop matches the received internal API against the VmCreate payload, and extracts both the VmConfig structure and the Sender from the command payload. It stores the VmConfig structure and replies back to the sender ((The HTTP thread): match api_request { ApiRequest::VmCreate(config, sender) => { // We only store the passed VM config. // The VM will be created when being asked to boot it. let response = if self.vm_config.is_none() { self.vm_config = Some(config); Ok(ApiResponsePayload::Empty) } else { Err(ApiError::VmAlreadyCreated) }; sender.send(response).map_err(Error::ApiResponseSend)?; } 这里create vm并没有真正的create, 而只是保存vmconfig, 待到boot的时候再创建 返回response 可以看到, 用户的curl请求等到动作执行完毕后, 就会收到response impl Vmm 代码在cloud-hypervisor/vmm/src/lib.rsvm_create和vm_boot等真正执行在Vmm的方法里: impl Vmm { new() vm_create() vm_boot() } x86_64和aarch64的mem layout 和firecracker相比, cloudhypervisor重点在pci mmio. vm_boot 前面说过, vm_create只是保存vmconfig, 而vm_boot是真正创建并运行vm的地方 let vm = Vm::new( Arc::clone(vm_config), exit_evt, reset_evt, &self.seccomp_action, self.hypervisor.clone(), activate_evt, None, None, None, )?; //vm代码在cloud-hypervisor/vmm/src/vm.rs let vm = hypervisor.create_vm().unwrap(); //kvm ioctl KVM_CREATE_VM //return Arc::new(KvmVm {fd: vm_fd, state: VmState {}, ...} //下面3个事x86独有 vm.set_identity_map_address(KVM_IDENTITY_MAP_START.0) vm.set_tss_address(KVM_TSS_START.0 as usize) vm.enable_split_irq() //KVM_ENABLE_CAP let memory_manager = MemoryManager::new(vm.clone(), ...) //建立内存region Vec, 这个Vec的元素是(start, size, type) //比如一般内存分2G, [(0,2G,ram), (3G, 640M, SubRegion), (3G+640M, 大概200M, Reserved)] let arch_mem_regions = arch::arch_memory_regions(ram_size); //很复杂 ... let allocator = SystemAllocator::new( io_base:0 io_size: 64K platform_mmio_base: max_mem - 1M platform_mmio_size: 1M mmio_hole_base: 0xc000_0000 mmio_hole_size: 640M X86_64_IRQ_BASE: 5 irq_num: 24-5 ) //acpi在地址空间最后1M的platform mmio区域 acpi_address = allocator.lock().unwrap().allocate_platform_mmio_addresses(MEMORY_MANAGER_ACPI_SIZE) //从0开始到start_of_device_area的区域是ram let ram_allocator = AddressAllocator::new(GuestAddress(0), start_of_device_area.0) let mut memory_manager = MemoryManager { boot_guest_memory, guest_memory, next_memory_slot, start_of_device_area, end_of_device_area, end_of_ram_area, vm, hotplug_slots, selected_slot, mergeable: config.mergeable, allocator, hotplug_method: config.hotplug_method, boot_ram, current_ram, next_hotplug_slot, shared: config.shared, hugepages: config.hugepages, hugepage_size: config.hugepage_size, prefault: config.prefault, user_provided_zones, snapshot_memory_ranges: MemoryRangeTable::default(), memory_zones, guest_ram_mappings: Vec::new(), acpi_address, log_dirty: dynamic, // Cannot log dirty pages on a TD arch_mem_regions, ram_allocator, dynamic, }; memory_manager.allocate_address_space()?; for (zone_id, regions) in list { for (region, virtio_mem) in regions { //ioctl KVM_SET_USER_MEMORY_REGION //记录user memory region和slot的关系到Vec self.guest_ram_mappings.push(GuestRamMapping { gpa: region.start_addr().raw_value(), size: region.len(), slot, zone_id: zone_id.clone(), virtio_mem, file_offset, }); } } for 每个非ram的region self.ram_allocator .allocate(Some(region.start_addr()), region.len(), None) //内部使用BtreeMap来管理内存ranges, 把每个range insert到BtreeMap //应该都是针对guest 物理地址 self.ranges.insert(new_addr, size); let new_vm = Vm::new_from_memory_manager(memory_manager, vm, ...) //1. 起一个后台线程load kernel //支持load ELF 或 firmware, firmware load到4G地址 Self::load_kernel_async(&kernel, &memory_manager, &config)? linux_loader::loader::elf::Elf::load() linux_loader::loader::load_cmdline() //到CMDLINE_START地址 //或者强制load firmware到4G-size地址, 并手动添加映射 //2. create numa node //主要是从vm config里面提取config.memory_zones和config.distances信息填充到BTreeMap let numa_nodes = Self::create_numa_nodes() //3. 创建device manager, 见下面的详解 //cloud-hypervisor/vmm/src/device_manager.rs let device_manager = DeviceManager::new( vm.clone(), config.clone(), memory_manager.clone(), &exit_evt, &reset_evt, seccomp_action.clone(), numa_nodes.clone(), &activate_evt, force_iommu, restoring, boot_id_list, timestamp, ) /* 1. 新建device tree: HashMap 2. num_pci_segments默认为1, 可以配 3. 确定device区域(其实就是PCI设备区域), 见上面layout图 4. 新建address_manager { allocator: memory_manager.lock().unwrap().allocator(), io_bus: Arc::new(Bus::new()), mmio_bus: Arc::new(Bus::new()), vm: vm.clone(), device_tree: Arc::clone(&device_tree), pci_mmio_allocators, } 5. 新建msi_interrupt_manager, IOAPIC需要它, legacy_interrupt_manager需要IOAPIC gsi_msi_routes是个HashMap, 所有pci的device都共享这个gsi RoutingEntry对应kvm_irq_routing_entry 6. 分配acpi_address 7. 为pci预留legacy的中断slot: pci_irq_slots = [0; 32]; 8. 新建默认的pci_segment, id为0, 一个pci segment包括一个pci root桥, 一个PCI bus 9. 构建pci_segments Vec, 目前看包括id 0和id1的pci_segment 10. 用上面的材料构建device_manager结构体 11. 把device_manager insert到address_manager 12. 返回device_manager */ let memory = memory_manager.lock().unwrap().guest_memory(); //只有x86有io bus let io_bus = Arc::clone(device_manager.lock().unwrap().io_bus()); let mmio_bus = Arc::clone(device_manager.lock().unwrap().mmio_bus()); //只有x86有pci io let pci_config_io = device_manager.lock().unwrap().pci_config_io() as Arc>; //4. vm_ops let vm_ops: Arc = Arc::new(VmOpsHandler { memory, #[cfg(target_arch = \"x86_64\")] io_bus, mmio_bus, #[cfg(target_arch = \"x86_64\")] pci_config_io, }); //5. 创建cpu_manager 通过上面的device_manager memory_manager vm_ops来\"操作\"VM cpu::CpuManager::new() //6. 从文件准备initramfs //7. 构建vm结构体并返回 Ok(Vm { #[cfg(any(target_arch = \"aarch64\", feature = \"tdx\"))] kernel, initramfs, device_manager, config, on_tty, threads: Vec::with_capacity(1), signals: None, state: RwLock::new(VmState::Created), cpu_manager, memory_manager, vm, #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] saved_clock: None, numa_nodes, seccomp_action: seccomp_action.clone(), exit_evt, #[cfg(all(feature = \"kvm\", target_arch = \"x86_64\"))] hypervisor, stop_on_boot, #[cfg(target_arch = \"x86_64\")] load_kernel_handle, }) //根据vm config创建设备, 主要是pci的virtio设备, vfio设备等 new_vm.device_manager.create_devices(serial_pty, console_pty, console_resize_pipe) /* 1. 创建interrupt_controller 对x86来说是IOAPIC, 它的上游是self.msi_interrupt_manager 并把这个中断控制器添加到address_manager bus_devices 和device_tree 对aarch64来说是GIC, gic::Gic::new(), 上游也是self.msi_interrupt_manager 2. 创建legacy的interrupt_controller, 基于上面的interrupt_controller 3. add_legacy_devices() 4. add_acpi_devices() 5. add_console_device() 6. make_virtio_devices() let mut virtio_devices: Vec = Vec::new(); make_virtio_block_devices() make_virtio_net_devices() make_virtio_rng_devices() make_virtio_fs_devices() make_virtio_pmem_devices() make_virtio_vsock_devices() make_virtio_mem_devices() make_virtio_balloon_devices() make_virtio_watchdog_devices() make_vdpa_devices() 7. add_pci_devices(上面的virtio设备) 创建iommu_device: virtio_devices::Iommu::new() //对每个virtio设备 for handle in virtio_devices { add_virtio_pci_device() // 默认add到pci segment 0, 没有iommu, 没有dma 1. id为\"xxx_virtio-pci\" 2. 给这个pci device分配pci资源, bdf号等 (pci_segment_id, pci_device_bdf, resources) = self.pci_resources() 3. msi中断个数为queue个数+1 4. 创建virtio_pci_device //Constructs a new PCI transport for the given virtio device. virtio_pci_device = VirtioPciDevice::new( id, memory, virtio_device, msix_num, access_platform, &self.msi_interrupt_manager, pci_device_bdf.into(), self.activate_evt, use_64bit_bar, //除了virtio block都是64位. dma_handler ) 每个queue都配一个eventfd 创建queues, queue有两个泛型参数 根据virtio规范, pci_device_id是0x1040+device_type. 创建interrupt group, 即把下面的每个irq都绑定一个eventfd到irq 配置msix_config 配置class, 比如PciClassCode::NetworkController等 组成configuration space需要的信息: let configuration = PciConfiguration::new( VIRTIO_PCI_VENDOR_ID, pci_device_id, 0x1, // For modern virtio-PCI devices class, subclass, None, PciHeaderType::Device, VIRTIO_PCI_VENDOR_ID, pci_device_id, msix_config_clone, ); 组成virtio pci device let mut virtio_pci_device = VirtioPciDevice { id, configuration, common_config: VirtioPciCommonConfig { access_platform, driver_status: 0, config_generation: 0, device_feature_select: 0, driver_feature_select: 0, queue_select: 0, msix_config: Arc::new(AtomicU16::new(VIRTQ_MSI_NO_VECTOR)), msix_queues: Arc::new(Mutex::new(vec![VIRTQ_MSI_NO_VECTOR; num_queues])), }, msix_config, msix_num, device, device_activated: Arc::new(AtomicBool::new(false)), interrupt_status: Arc::new(AtomicUsize::new(0)), virtio_interrupt: None, queues, queue_evts, memory: Some(memory), settings_bar: 0, use_64bit_bar, interrupt_source_group, cap_pci_cfg_info: VirtioPciCfgCapInfo::default(), bar_regions: vec![], activate_evt, activate_barrier: Arc::new(Barrier::new(2)), dma_handler, }; //设置msix中断控制器 virtio_pci_device.virtio_interrupt = VirtioInterruptMsix::new() return 这个virtio_pci_device 5. add到pci, 返回bar地址信息 new_resources = self.add_pci_device(virtio_pci_device) 分配bar空间, 返回Vec.这是PciDevice本身的方法 pci_bus.add_device() //添加到hashmap 记录这个Bus_device到bus_devices pci_bus.register_mapping() //注册bar地址到device manager的MMIO Bus, 关联本BusDevice到这个bar地址 6. virtio设备的每个queue, 都有个\"通知\"地址 = bar地址base+NOTIFICATION_BAR_OFFSET+queue index*4, 每个通知地址都有一个eventfd self.address_manager.register_ioevent() 调用KVM的KVM_IOEVENTFD ioctl 7. 把本设备加入到device_tree } add_vfio_devices() add_user_devices() self.bus_devices .push(Arc::clone(&segment.pci_config_mmio) as Arc>); 8. done self.virtio_devices = virtio_devices */ vm.boot() //新建thread处理signal: SIGWINCH, SIGTERM, SIGINT self.setup_signal_handler() //stdin设为raw mode self.setup_tty() //load kernel let entry_point = self.entry_point() self.cpu_manager.create_boot_vcpus() for each vcpu kvm create vcpu self.cpu_manager.start_boot_vcpus() for each vcpu 创建新线程, 在里面loop: vcpu.run() VcpuExit::IoIn VcpuExit::IoOut VcpuExit::Shutdown VcpuExit::SystemEvent VcpuExit::MmioRead VcpuExit::MmioWrite VcpuExit::Hyperv DeviceManager DeviceManager结构体 pub struct DeviceManager { // Manage address space related to devices address_manager: Arc, // Console abstraction console: Arc, // console PTY console_pty: Option>>, // serial PTY serial_pty: Option>>, // Serial Manager serial_manager: Option>, // pty foreground status, console_resize_pipe: Option>, // Interrupt controller #[cfg(target_arch = \"x86_64\")] interrupt_controller: Option>>, #[cfg(target_arch = \"aarch64\")] interrupt_controller: Option>>, // Things to be added to the commandline (e.g. aarch64 early console) #[cfg(target_arch = \"aarch64\")] cmdline_additions: Vec, // ACPI GED notification device ged_notification_device: Option>>, // VM configuration config: Arc>, // Memory Manager memory_manager: Arc>, // The virtio devices on the system virtio_devices: Vec, // List of bus devices // Let the DeviceManager keep strong references to the BusDevice devices. // This allows the IO and MMIO buses to be provided with Weak references, // which prevents cyclic dependencies. bus_devices: Vec>>, // Counter to keep track of the consumed device IDs. device_id_cnt: Wrapping, pci_segments: Vec, #[cfg_attr(target_arch = \"aarch64\", allow(dead_code))] // MSI Interrupt Manager msi_interrupt_manager: Arc>, #[cfg_attr(feature = \"mshv\", allow(dead_code))] // Legacy Interrupt Manager legacy_interrupt_manager: Option>>, // Passthrough device handle passthrough_device: Option>, // VFIO container // Only one container can be created, therefore it is stored as part of the // DeviceManager to be reused. vfio_container: Option>, // Paravirtualized IOMMU iommu_device: Option>>, iommu_mapping: Option>, // PCI information about devices attached to the paravirtualized IOMMU // It contains the virtual IOMMU PCI BDF along with the list of PCI BDF // representing the devices attached to the virtual IOMMU. This is useful // information for filling the ACPI VIOT table. iommu_attached_devices: Option)>, // Tree of devices, representing the dependencies between devices. // Useful for introspection, snapshot and restore. device_tree: Arc>, // Exit event exit_evt: EventFd, reset_evt: EventFd, #[cfg(target_arch = \"aarch64\")] id_to_dev_info: HashMap, // seccomp action seccomp_action: SeccompAction, // List of guest NUMA nodes. numa_nodes: NumaNodes, // Possible handle to the virtio-balloon device balloon: Option>>, // Virtio Device activation EventFd to allow the VMM thread to trigger device // activation and thus start the threads from the VMM thread activate_evt: EventFd, acpi_address: GuestAddress, selected_segment: usize, // Possible handle to the virtio-mem device virtio_mem_devices: Vec>>, #[cfg(target_arch = \"aarch64\")] // GPIO device for AArch64 gpio_device: Option>>, #[cfg(target_arch = \"aarch64\")] // Flash device for UEFI on AArch64 uefi_flash: Option>, // Flag to force setting the iommu on virtio devices force_iommu: bool, // Helps identify if the VM is currently being restored restoring: bool, // io_uring availability if detected io_uring_supported: Option, // List of unique identifiers provided at boot through the configuration. boot_id_list: BTreeSet, // Start time of the VM timestamp: Instant, } DeviceManager方法 impl DeviceManager { new() serial_pty() console_pty() console_resize_pipe() create_devices() state() set_state() get_msi_iova_space() get_device_info() add_pci_devices() add_interrupt_controller() get_interrupt_controller() add_acpi_devices() add_legacy_devices() add_serial_device() modify_mode() set_raw_mode() add_virtio_console_device() add_console_device() make_virtio_devices() make_virtio_block_devices() make_virtio_net_devices() make_virtio_rng_devices() make_virtio_fs_devices() make_virtio_pmem_devices() make_virtio_vsock_devices() make_virtio_mem_devices() make_virtio_balloon_devices() make_virtio_watchdog_devices() make_vdpa_devices() next_device_name() add_passthrough_device() create_vfio_container() add_vfio_devices() add_vfio_user_device() add_pci_device() add_virtio_pci_device() pci_resources() io_bus() mmio_bus() allocator() //address_manager.allocator interrupt_controller() pci_config_io() pci_segments() console() cmdline_additions() update_memory() activate_virtio_devices() notify_hotplug() add_device() add_user_device() remove_device() eject_device() hotplug_virtio_pci_device() is_iommu_segment() add_disk() add_fs() add_pmem() add_net() add_vdpa() add_vsock() counters() resize_balloon() device_tree() restore_devices() notify_power_button() iommu_attached_devices() uefi_flash() validate_identifier() } DeviceNode包括id, 资源, 层级, pci信息 尤其是每个Device都是PCI的device #[derive(Clone, Serialize, Deserialize)] pub struct DeviceNode { pub id: String, pub resources: Vec, pub parent: Option, pub children: Vec, #[serde(skip)] pub migratable: Option>>, pub pci_bdf: Option, #[serde(skip)] pub pci_device_handle: Option, } PCI segment pub(crate) struct PciSegment { pub(crate) id: u16, pub(crate) pci_bus: Arc>, pub(crate) pci_config_mmio: Arc>, pub(crate) mmio_config_address: u64, #[cfg(target_arch = \"x86_64\")] pub(crate) pci_config_io: Option>>, // Bitmap of PCI devices to hotplug. pub(crate) pci_devices_up: u32, // Bitmap of PCI devices to hotunplug. pub(crate) pci_devices_down: u32, // List of allocated IRQs for each PCI slot. pub(crate) pci_irq_slots: [u8; 32], // Device memory covered by this segment pub(crate) start_of_device_area: u64, pub(crate) end_of_device_area: u64, pub(crate) allocator: Arc>, } pci的config空间是vmm的一个结构体: /// Contains the configuration space of a PCI node. /// See the [specification](https://en.wikipedia.org/wiki/PCI_configuration_space). /// The configuration space is accessed with DWORD reads and writes from the guest. pub struct PciConfiguration { registers: [u32; NUM_CONFIGURATION_REGISTERS], writable_bits: [u32; NUM_CONFIGURATION_REGISTERS], // writable bits for each register. bars: [PciBar; NUM_BAR_REGS], rom_bar_addr: u32, rom_bar_size: u32, rom_bar_used: bool, // Contains the byte offset and size of the last capability. last_capability: Option, msix_cap_reg_idx: Option, msix_config: Option>>, } new一个segment impl PciSegment { pub(crate) fn new() { 1. 新建一个pci root桥 默认是VENDOR_ID_INTEL(0x8086)和DEVICE_ID_INTEL_VIRT_PCIE_HOST(0xD57) PciClassCode::BridgeDevice &PciBridgeSubclass::HostBridge PciHeaderType::Device 2. 新建PCI bus, PCI bus用hashmap来管理pci 设备: HashMap>> 3. 新建pci_config_mmio, 一个就是一个PciBus实例 4. 把pci_config_mmio insert到address_manager的mmio_bus 5. 组装一个segment并返回 } } PciBus impl PciBus { new() register_mapping() add_device() remove_by_device() next_device_id() get_device_id() put_device_id() } PciDevice pub trait PciDevice: BusDevice { allocate_bars() free_bars() write_config_register() read_config_register() detect_bar_reprogramming() read_bar() write_bar() move_bar() as_any() id() } virtio设备 virtionet 代码cloud-hypervisor/virtio-devices/src/net.rs //主要是创建tap设备, 配置virtio net的属性 make_virtio_net_devices() 1. 生成id, 即xxx_net 2. 支持vhost user, 但一般还是virtio-net对接tap设备 virtio_devices::Net::new() tap设备有名就open有名的, 没名就默认叫vmtap%d tap设备可以配IP 这里为了模拟多queue, 使用了多个tap Self::new_with_tap() 设置feature标记各种offload, tso, 多队列 Ok(Net { common: VirtioCommon { device_type: VirtioDeviceType::Net as u32, avail_features, queue_sizes: vec![queue_size; queue_num], paused_sync: Some(Arc::new(Barrier::new((num_queues / 2) + 1))), min_queues: 2, ..Default::default() }, id, taps, config, ctrl_queue_epoll_thread: None, counters: NetCounters::default(), seccomp_action, rate_limiter_config, exit_evt, }) 3. 插入到设备树 self.device_tree.insert() 4. 返回MetaVirtioDevice Ok(MetaVirtioDevice { virtio_device, iommu: net_cfg.iommu, id, pci_segment: net_cfg.pci_segment, dma_handler: None, }) Net结构体 pub struct Net { common: VirtioCommon, id: String, taps: Vec, config: VirtioNetConfig, ctrl_queue_epoll_thread: Option>, counters: NetCounters, seccomp_action: SeccompAction, rate_limiter_config: Option, exit_evt: EventFd, } impl VirtioDevice for Net impl VirtioDevice for Net { device_type() queue_max_sizes() features() ack_features() read_config() activate() //这里应该是入口 reset() counters() set_access_platform() } activate 在vmm.control_loop的事件循环里, 会有EpollDispatch::ActivateVirtioDevices事件来触发virtio设备的使能: fn activate { 1. self.common.activate() 2. 创建NetCtrlEpollHandler, 起个线程\"_net1_ctrl\", 在里面epoll循环处理ctrl queue的事件 3. 每个q都创建NetEpollHandler, 起个线程\"_net1_qp%i\", 在epoll里循环处理data queue的事件 } data queue的事件: match ev_type { RX_QUEUE_EVENT: self.handle_rx_event() TX_QUEUE_EVENT: self.handle_tx_event() TX_TAP_EVENT: self.handle_tx_event() RX_TAP_EVENT: self.handle_rx_tap_event() 还有rate limit事件... } NetQueuePair cloud-hypervisor/net_util/src/queue_pair.rs 前面的事件, 最后都会落脚到 impl NetQueuePair { process_tx() self.tx.process_desc_chain() 基本上就是在循环里直接操作desc指向的buffer, 最后调用libc::writev把这些buffer写到tap的fd里面. 最后更新used index process_rx() self.rx.process_desc_chain 基本上是从desc链的信息中, 找到guest driver提前准备好的buffer, 组成iovecs, 用libc::readv函数读到这个iovecs里 } 其他trait Net还满足: Drop trait Pausable trait Snapshottable trait Transportable trait Migratable trait virtio block make_virtio_block_device() 1. 生成id, 一般是xxx_disk 2. 支持vhost user对接spdk 3. 打开块设备文件, 支持qcow2, vhd和raw, 返回一个trait object: Box 4. 传入上面的材料, 创建virtio block设备 virtio_devices::Block::new() 设置feature标记, FLUSH, CONFIG_WCE, BLK_SIZE, TOPOLOGY 计算disk参数, 比如block size, sector个数, writeback, 多队列等 返回Block设备 Ok(Block { common: VirtioCommon { device_type: VirtioDeviceType::Block as u32, avail_features, paused_sync: Some(Arc::new(Barrier::new(num_queues + 1))), queue_sizes: vec![queue_size; num_queues], min_queues: 1, ..Default::default() }, id, disk_image, disk_path, disk_nsectors, config, writeback: Arc::new(AtomicBool::new(true)), counters: BlockCounters::default(), seccomp_action, rate_limiter_config, exit_evt, }) 5. 插入到设备树 self.device_tree.insert() 6. 返回MetaVirtioDevice Ok(MetaVirtioDevice { virtio_device, iommu: net_cfg.iommu, id, pci_segment: net_cfg.pci_segment, dma_handler: None, }) IO Bus和MMIO Bus 顶层的device manager包括两个bus: io bus只有x86有io bus mmio busmmio bus是最常用的. io或者mmio的Bus抽象都是一个BtreeMap, 靠地址range来路由读写操作到底指向哪个具体的设备 pub struct Bus { devices: RwLock>>>, } Bus设备必须有offset读写的方法 pub trait BusDevice: Send { /// Reads at `offset` from this device fn read(&mut self, base: u64, offset: u64, data: &mut [u8]) {} /// Writes at `offset` into this device fn write(&mut self, base: u64, offset: u64, data: &[u8]) -> Option> { None } } 注: 对比firecracker的Bus定义, 和这里差不多: pub struct Bus { //bus下面是BtreeMap管理的device devices: BTreeMap>>, } Bus方法 一个BusDevice对应一个地址范围 impl Bus { new() //根据地址找上一个设备 resolve(&self, addr: u64) -> Option>)> //在指定地址范围插入设备 insert(&self, device: Arc>, base: u64, len: u64) //删除指定地址范围的设备 remove(&self, base: u64, len: u64) //读写 read(&self, addr: u64, data: &mut [u8]) write(&self, addr: u64, data: &[u8]) } 中断 和硬件的irq稍有区别, virt irq在这里被叫做Interrupt Source A device may support multiple types of interrupts, and each type of interrupt may support one or multiple interrupt sources. For example, a PCI device may support: Legacy Irq: exactly one interrupt source. PCI MSI Irq: 1,2,4,8,16,32 interrupt sources. PCI MSIx Irq: 2^n(n=0-11) interrupt sources. 一个设备可以有多个中断源, 比如MSI可以有32个源, MSIx可以有4096个源. A distinct Interrupt Source Identifier (ISID) will be assigned to each interrupt source. An ID allocator will be used to allocate and free Interrupt Source Identifiers for devices. To decouple the vm-device crate from the ID allocator, the vm-device crate doesn't take the responsibility to allocate/free Interrupt Source IDs but only makes use of assigned IDs. 每个中断源都被分配一个ID, 即ISID. vm-device只负责使用这些ID The overall flow to deal with interrupts is: The VMM creates an interrupt manager The VMM creates a device manager, passing on an reference to the interrupt manager The device manager passes on an reference to the interrupt manager to all registered devices The guest kernel loads drivers for virtual devices The guest device driver determines the type and number of interrupts needed, and update the device configuration The virtual device backend requests the interrupt manager to create an interrupt group according to guest configuration information 中断并不是在一开始就固定分配好的, 而是需要guest kernel驱动来触发. VMM创建好中断管理器后, 由设备管理器把中断控制器的引用传递给每个具体的设备; guest kernel驱动在初始化虚拟设备的时候, 决定自己的中断类型, 比如MSI, 和中断个数; 对应虚拟设备的backend根据guest驱动提供的信息, 向中断管理器请求创建一个中断group. interrupt group InterruptManager只有两个API, create_group()和destroy_group(), 用于新建/销毁 InterruptSourceGroup /// Trait to manage interrupt sources for virtual device backends. /// /// The InterruptManager implementations should protect itself from concurrent accesses internally, /// so it could be invoked from multi-threaded context. pub trait InterruptManager: Send + Sync { type GroupConfig; /// Create an [InterruptSourceGroup](trait.InterruptSourceGroup.html) object to manage /// interrupt sources for a virtual device /// /// An [InterruptSourceGroup](trait.InterruptSourceGroup.html) object manages all interrupt /// sources of the same type for a virtual device. /// /// # Arguments /// * interrupt_type: type of interrupt source. /// * base: base Interrupt Source ID to be managed by the group object. /// * count: number of Interrupt Sources to be managed by the group object. fn create_group(&self, config: Self::GroupConfig) -> Result>; /// Destroy an [InterruptSourceGroup](trait.InterruptSourceGroup.html) object created by /// [create_group()](trait.InterruptManager.html#tymethod.create_group). /// /// Assume the caller takes the responsibility to disable all interrupt sources of the group /// before calling destroy_group(). This assumption helps to simplify InterruptSourceGroup /// implementations. fn destroy_group(&self, group: Arc) -> Result; } InterruptSourceGroup负责具体中断的维护: 使能/禁止/向guest注入中断/更新中断配置 pub trait InterruptSourceGroup: Send + Sync { /// Enable the interrupt sources in the group to generate interrupts. fn enable(&self) -> Result { // Not all interrupt sources can be enabled. // To accommodate this, we can have a no-op here. Ok(()) } /// Disable the interrupt sources in the group to generate interrupts. fn disable(&self) -> Result { // Not all interrupt sources can be disabled. // To accommodate this, we can have a no-op here. Ok(()) } /// Inject an interrupt from this interrupt source into the guest. fn trigger(&self, index: InterruptIndex) -> Result; /// Returns an interrupt notifier from this interrupt. /// /// An interrupt notifier allows for external components and processes /// to inject interrupts into a guest, by writing to the file returned /// by this method. #[allow(unused_variables)] fn notifier(&self, index: InterruptIndex) -> Option; /// Update the interrupt source group configuration. /// /// # Arguments /// * index: sub-index into the group. /// * config: configuration data for the interrupt source. /// * masked: if the interrupt is masked fn update( &self, index: InterruptIndex, config: InterruptSourceConfig, masked: bool, ) -> Result; } 中断控制器 分为两大类, msi和legacy msi中断控制器 pub struct MsiInterruptManager { allocator: Arc>, vm: Arc, gsi_msi_routes: Arc>>, } MsiInterruptManager实现了InterruptManager trait: impl InterruptManager for MsiInterruptManager { type GroupConfig = MsiIrqGroupConfig; fn create_group(&self, config: Self::GroupConfig) -> Result> { let mut allocator = self.allocator.lock().unwrap(); //把这次group里的所有中断插入到irq_routes, 以hashmap形式索引, key是u32 //每个中断源对应一个eventfd和一个gsi号组成的InterruptRoute let mut irq_routes: HashMap = HashMap::with_capacity(config.count as usize); for i in config.base..config.base + config.count { irq_routes.insert(i, InterruptRoute::new(&mut allocator)?); } Ok(Arc::new(MsiInterruptGroup::new( self.vm.clone(), self.gsi_msi_routes.clone(), irq_routes, ))) } fn destroy_group(&self, _group: Arc) -> Result { Ok(()) } } MsiInterruptGroup impl InterruptSourceGroup for MsiInterruptGroup { //对这个group下面的每个中断源 fn enable(&self) -> Result { for (_, route) in self.irq_routes.iter() { route.enable(&self.vm)?; //调用kvm的ioctl KVM_IRQFD注册eventfd, 绑定到对应的gsi. 写这个eventfd会触发kvm注入中断到irqchip的gsi pin vm.register_irqfd(&self.irq_fd, self.gsi) } } disable() //取消注册 trigger() //就是写对应的eventfd notifier() //返回eventfd的clone } KVM_IRQFD Allows setting an eventfd to directly trigger a guest interrupt. kvm_irqfd.fd specifies the file descriptor to use as the eventfd and kvm_irqfd.gsi specifies the irqchip pin toggled by this event. When an event is triggered on the eventfd, an interrupt is injected into the guest using the specified gsi pin kvm的ioctl KVM_IRQFD注册eventfd, 绑定到对应的gsi. 写这个eventfd会触发kvm注入中断到irqchip的gsi pin "},"notes/rust_cloud-hypervisor_使用.html":{"url":"notes/rust_cloud-hypervisor_使用.html","title":"cloud hypervisor使用","keywords":"","body":" 命令记录 命令行启动 ch-remote启动 启动 可选参数 virtiofsd rest API ping dump vm info reboot shutdown 其他 guest kernel启动打印 gdb调试 rust-gdb 测试场景: vm内virtio-net网口ping对应的tap口 gdb观察 ping是否会触发VM exit -- 否 vmm后端怎么工作 写文件是否会触发VM exit -- 否 lspci是否会触发VM exit -- 是 最小化启动 参考集成 release过程 命令记录 命令行启动 bin/cloud-hypervisor --seccomp false --api-socket clh.sock --cpus boot=2 --memory size=2048M,shared=on --kernel kernel/vmlinux.bin --initramfs rootfs/boot/rootfs.cpio.gz --cmdline \"console=hvc0 config_overlay=linux_shell_only=1 init=/init\" ch-remote启动 # 先启动主程序, 主程序等待命令 bin/cloud-hypervisor --seccomp false --api-socket clh.sock # create bin/ch-remote --api-socket clh.sock create 启动 # virt-customize需要这个 apt install libguestfs-tools # 默认ubuntu的cloud image是没有默认用户的, 也没有root密码 # 用下面的命令配置一个 sudo virt-customize -a focal-server-cloudimg-amd64.img --root-password password:ubuntu wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw wget https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/download/0.4.0/hypervisor-fw 启动示例: $ sudo setcap cap_net_admin+ep ./cloud-hypervisor/target/release/cloud-hypervisor # 如果有权限问题, 把/dev/kvm的other设为读写 # 或者加入kvm组 sudo chmod o+rw /dev/kvm $ ./cloud-hypervisor/target/release/cloud-hypervisor \\ --kernel ./hypervisor-fw \\ --disk path=focal-server-cloudimg-amd64.raw \\ --cpus boot=4 \\ --memory size=1024M \\ --net \"tap=,mac=,ip=,mask=\" 可选参数 cloud-hypervisor -h --api-socket /path/to/uds --kernel --cmdline --console --cpus --device --disk --event-monitor --fs --initramfs --log-file --memory --memory-zone --net --numa --platform --pmem --restore --rng --seccomp --serial --vsock --watchdog virtiofsd virtiofsd是用virtiofs协议来共享host文件系统到guest的一个工具.host上需要运行virtiofsd, 指定socket路径和要共享的目录; 同时给cloud hypervisor指定一个tag virtiofsd --log-level error --seccomp none --cache=never --socket-path=$WORK_DIR/run/rootextra.sock --shared-dir=$WORK_DIR/rootfs & ch-remote --api-socket $WORK_DIR/run/clh.sock add-fs tag=rootextra,socket=$WORK_DIR/run/rootextra.sock 在guest里面, 用指定的tag来mount: mount rootextra /rootextra -t virtiofs -o noatime rest API ping curl --unix-socket /tmp/clh.sock -i -X GET 'http://localhost/api/v1/vmm.ping' dump vm info 假设使用--api-socket /tmp/clh.sock启动clh curl --unix-socket /tmp/clh.sock -i -X GET 'http://localhost/api/v1/vm.info' -H 'Accept: application/json' | tail -1 | jq . 列表如下: { \"config\": { \"cpus\": { \"boot_vcpus\": 1, \"max_vcpus\": 1, \"topology\": null, \"kvm_hyperv\": false, \"max_phys_bits\": 46, \"affinity\": null, \"features\": {} }, \"memory\": { \"size\": 1073741824, \"mergeable\": false, \"hotplug_method\": \"Acpi\", \"hotplug_size\": null, \"hotplugged_size\": null, \"shared\": false, \"hugepages\": false, \"hugepage_size\": null, \"prefault\": false, \"zones\": null }, \"kernel\": { \"path\": \"./hypervisor-fw\" }, \"initramfs\": null, \"cmdline\": { \"args\": \"\" }, \"disks\": [ { \"path\": \"focal-server-cloudimg-amd64.raw\", \"readonly\": false, \"direct\": false, \"iommu\": false, \"num_queues\": 1, \"queue_size\": 128, \"vhost_user\": false, \"vhost_socket\": null, \"poll_queue\": true, \"rate_limiter_config\": null, \"id\": \"_disk0\", \"disable_io_uring\": false, \"pci_segment\": 0 } \"net\": [ { \"tap\": null, \"ip\": \"192.168.249.1\", \"mask\": \"255.255.255.0\", \"mac\": \"2e:cc:5f:b8:cd:dc\", \"host_mac\": \"82:22:4f:c3:21:da\", \"iommu\": false, \"num_queues\": 2, \"queue_size\": 256, \"vhost_user\": false, \"vhost_socket\": null, \"vhost_mode\": \"Client\", \"id\": \"_net1\", \"fds\": null, \"rate_limiter_config\": null, \"pci_segment\": 0 } ], \"rng\": { \"src\": \"/dev/urandom\", \"iommu\": false }, \"balloon\": null, \"fs\": null, \"pmem\": null, \"serial\": { \"file\": null, \"mode\": \"Null\", \"iommu\": false }, \"console\": { \"file\": null, \"mode\": \"Tty\", \"iommu\": false }, \"devices\": null, \"user_devices\": null, \"vdpa\": null, \"vsock\": null, \"iommu\": false, \"sgx_epc\": null, \"numa\": null, \"watchdog\": false, \"platform\": null }, \"state\": \"Running\", \"memory_actual_size\": 1073741824, \"device_tree\": { \"__rng\": { \"id\": \"__rng\", \"resources\": [], \"parent\": \"_virtio-pci-__rng\", \"children\": [], \"pci_bdf\": null }, \"_disk0\": { \"id\": \"_disk0\", \"resources\": [], \"parent\": \"_virtio-pci-_disk0\", \"children\": [], \"pci_bdf\": null }, \"_net1\": { \"id\": \"_net1\", \"resources\": [], \"parent\": \"_virtio-pci-_net1\", \"children\": [], \"pci_bdf\": null }, \"_virtio-pci-__console\": { \"id\": \"_virtio-pci-__console\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 70364448686080, \"size\": 524288, \"type_\": \"Mmio64\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"__console\" ], \"pci_bdf\": \"0000:00:01.0\" }, \"__serial\": { \"id\": \"__serial\", \"resources\": [], \"parent\": null, \"children\": [], \"pci_bdf\": null }, \"_virtio-pci-_disk0\": { \"id\": \"_virtio-pci-_disk0\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 3891789824, \"size\": 524288, \"type_\": \"Mmio32\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"_disk0\" ], \"pci_bdf\": \"0000:00:02.0\" }, \"_virtio-pci-_net1\": { \"id\": \"_virtio-pci-_net1\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 70364448161792, \"size\": 524288, \"type_\": \"Mmio64\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"_net1\" ], \"pci_bdf\": \"0000:00:03.0\" }, \"__console\": { \"id\": \"__console\", \"resources\": [], \"parent\": \"_virtio-pci-__console\", \"children\": [], \"pci_bdf\": null }, \"__ioapic\": { \"id\": \"__ioapic\", \"resources\": [], \"parent\": null, \"children\": [], \"pci_bdf\": null }, \"_virtio-pci-__rng\": { \"id\": \"_virtio-pci-__rng\", \"resources\": [ { \"PciBar\": { \"index\": 0, \"base\": 70364447637504, \"size\": 524288, \"type_\": \"Mmio64\", \"prefetchable\": false } } ], \"parent\": null, \"children\": [ \"__rng\" ], \"pci_bdf\": \"0000:00:04.0\" } } } reboot shutdown curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.reboot' curl --unix-socket /tmp/cloud-hypervisor.sock -i -X PUT 'http://localhost/api/v1/vm.shutdown' 其他 比如暂停, 恢复, add net, add disk, remove device, dump counters等等都支持. 例如: curl --unix-socket /tmp/clh.sock -i -X GET 'http://localhost/api/v1/vm.counters' guest kernel启动打印 以ubuntu的云镜像为例: Command line: BOOT_IMAGE=/boot/vmlinuz-5.4.0-113-generic root=LABEL=cloudimg-rootfs ro console=tty1 console=ttyS0 BIOS-provided physical RAM map efi: EFI v2.80 by Hypervisor detected: KVM clocksource: kvm-clock tsc: Detected 2394.454 MHz processor Zone ranges: DMA [mem 0x0000000000001000-0x0000000000ffffff] DMA32 [mem 0x0000000001000000-0x000000003fffffff] Normal empty Device empty Early memory node ranges node 0: [mem 0x0000000000001000-0x000000000009ffff] node 0: [mem 0x000000000013f000-0x000000003fffffff] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffffff] On node 0 totalpages: 261984 //1G Booting paravirtualized kernel on KVM //guest kernel知道自己是在KVM上启动的 NR_IRQS: 524544, nr_irqs: 256, preallocated irqs: 0 printk: console [tty1] enabled printk: console [ttyS0] enabled LSM: Security Framework initializing Yama: becoming mindful. AppArmor: AppArmor initialized PCI host bridge to bus 0000:00 pci_bus 0000:00: root bus resource [mem 0xe8000000-0xe80fffff] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xe7ffffff window] pci_bus 0000:00: root bus resource [mem 0x100000000-0x3ffeffffffff window] pci_bus 0000:00: root bus resource [io 0x0000-0x0cf7 window] pci_bus 0000:00: root bus resource [io 0x0d00-0xffff window] pci_bus 0000:00: root bus resource [bus 00] pci 0000:00:00.0: [8086:0d57] type 00 class 0x060000 //INTEL pci 0000:00:01.0: [1af4:1043] type 00 class 0xffff00 //virtio pci 0000:00:01.0: reg 0x10: [mem 0x3ffefff80000-0x3ffeffffffff 64bit] //资源已经分配好 pci 0000:00:02.0: [1af4:1042] type 00 class 0x018000 pci 0000:00:02.0: reg 0x10: [mem 0xe7f80000-0xe7ffffff] pci 0000:00:03.0: [1af4:1041] type 00 class 0x020000 pci 0000:00:03.0: reg 0x10: [mem 0x3ffefff00000-0x3ffefff7ffff 64bit] pci 0000:00:04.0: [1af4:1044] type 00 class 0xffff00 pci 0000:00:04.0: reg 0x10: [mem 0x3ffeffe80000-0x3ffeffefffff 64bit] pci_bus 0000:00: on NUMA node 0 iommu: Default domain type: Translated PCI: Using ACPI for IRQ routing PCI: pci_cache_line_size set to 64 bytes tcpip协议栈初始化 virtio-pci 0000:00:01.0: enabling device (0000 -> 0002) virtio-pci 0000:00:02.0: enabling device (0000 -> 0002) virtio-pci 0000:00:03.0: enabling device (0000 -> 0002) virtio-pci 0000:00:04.0: enabling device (0000 -> 0002) Serial: 8250/16550 driver, 32 ports, IRQ sharing enabled loop, tun, vfio, usb, i2c驱动初始化 systemd开始工作 一堆的audit打印... gdb调试 用上面的命令启动hypervisor后, 用gdb调试: gdb cloud-hypervisor -p 18294 Reading symbols from cloud-hypervisor...done (gdb) b mmio_read Breakpoint 1 at 0x7f766eb1d1ee: file vmm/src/vm.rs, line 384. (gdb) b mmio_write Breakpoint 2 at 0x7f766eb1d3a1: file vmm/src/vm.rs, line 391. (gdb) info b Num Type Disp Enb Address What 1 breakpoint keep y 0x00007f766eb1d1ee in ::mmio_read at vmm/src/vm.rs:384 2 breakpoint keep y 0x00007f766eb1d3a1 in ::mmio_write at vmm/src/vm.rs:391 (gdb) b src/kvm/mod.rs:1145 Breakpoint 4 at 0x7f766f2759d7: file hypervisor/src/kvm/mod.rs, line 1145. //只对thread 4打断点 (gdb) b kvm_ioctls::ioctls::vcpu::VcpuFd::run thread 4 rust-gdb 参考https://bitshifter.github.io/rr+rust/index.html#1 需要在root用户下安装rust. 我从普通用户拷贝~/.cargo和~/.rustp好像也能用. # su root ~/.cargo/bin/rust-gdb -p 19507 b kvm_ioctls::ioctls::vcpu::VcpuFd::run 测试场景: vm内virtio-net网口ping对应的tap口 启动hypervisor后, VM内有virtio-net网口: root@ubuntu:~# ethtool -i ens3 driver: virtio_net version: 1.0.0 bus-info: 0000:00:03.0 查看pci拓扑: 注: lspci执行过程中, 会频繁的触发vm exit, 断点表面是VM在做VcpuExit::IoOut root@ubuntu:~# lspci 00:00.0 Host bridge: Intel Corporation Device 0d57 00:01.0 Unassigned class [ffff]: Red Hat, Inc. Virtio console (rev 01) 00:02.0 Mass storage controller: Red Hat, Inc. Virtio block device (rev 01) 00:03.0 Ethernet controller: Red Hat, Inc. Virtio network device (rev 01) 00:04.0 Unassigned class [ffff]: Red Hat, Inc. Virtio RNG (rev 01) 同时, hypervisor会在host上创建一个网口vmtap0, 并配置IP192.168.249.1/24 默认vm的ens3是down的, 下面配置其为up, ip为192.168.249.2 ip link set up dev ens3 ip addr add 192.168.249.2/24 dev ens3 此时可以ping通vmtap0: ping 192.168.249.1 gdb观察 设断点: # su root ~/.cargo/bin/rust-gdb -p 19507 b kvm_ioctls::ioctls::vcpu::VcpuFd::run 这里的kvm_ioctls::ioctls::vcpu::VcpuFd::run是下面代码:是KVM_RUN的循环主体. ping是否会触发VM exit -- 否 一直ping, 同时做gdb观察 gdb设置上面的断点后, continue执行, 除了第一次continue后会触发断点, 后面不管怎么ping, 都没有触发断点. 说明: virtio-net在ping的过程中, VM并没有exit, VM一直\"全速\"运行 因为VM没有exit, 也就没有mmio_read, mmio_write等触发VMM后端的动作; 就是说guest driver在收发报文的时候, 对vring的操作, 对bar寄存器的操作, 统统没有触发mmio exit. vmm后端怎么工作 前面看到, ping的过程中没有观察到VM exit, 那VMM后端如何响应guest driver的读写寄存器请求的呢? 会不会在其他代码路径下面调用了寄存器访问的函数呢? 先看看有没有人调用mmio_write和mmio_read (gdb) b mmio_read (gdb) b mmio_write 注: 用b vmm::vm::VmOpsHandler::mmio_read是不认的. 用这样的语法gdb可以认: (gdb) b ::mmio_read 继续在VM里ping, 没有触发断点. 再增加 (gdb) b vm_device::bus::Bus::read (gdb) b vm_device::bus::Bus::write 依旧没触发. 看看有没有认调用VirtioPciDevice的read: b ::read b ::write 还是没有触发 继续看pci的读写bar操作: b ::read_bar b ::write_bar 还是没有触发 至此, VM exit路径没有触发virtio-net后端的动作. 所以, 到这里很清楚了, virtio-net设备在工作的时候, 完全不需要在VM exit和VM enter之间进行切换. guest driver和vmm device在virtio ring的协议下, 通过ioeventfd和irqfd来互相\"通知\", 在VM不exit的情况下, 完成报文的交互. 见cloud-hypervisor/net_util/src/queue_pair.rs的process_tx()和process_rx()函数. 再次确认, pci::device::PciDevice::read_bar/write_bar并没有在virtio-net报文交换的过程中被调用. 写文件是否会触发VM exit -- 否 echo abc > abc.txt sync //执行的很快 dd if=/dev/zero of=out.dd bs=1M count=4 4194304 bytes (4.2 MB, 4.0 MiB) copied, 0.0129554 s, 324 MB/s lspci是否会触发VM exit -- 是 在vm里面执行lspci, 可以看到断点被触发: (gdb) bt #0 kvm_ioctls::ioctls::vcpu::VcpuFd::run #1 0x00007fee2b19b9c5 in ::run #2 0x00007fee2aca1b45 in vmm::cpu::Vcpu::run #3 0x00007fee2ac7f5cb in vmm::cpu::CpuManager::start_vcpu::{{closure}}::{{closure}} () #4 0x00007fee2acd51bb in std::panicking::try::do_call #5 0x00007fee2acd5c5b in __rust_try #6 0x00007fee2acd46e1 in std::panicking::try #7 0x00007fee2ab64211 in std::panic::catch_unwind #8 0x00007fee2ac7eaf4 in vmm::cpu::CpuManager::start_vcpu::{{closure}} #9 0x00007fee2aa607c3 in std::sys_common::backtrace::__rust_begin_short_backtrace #10 0x00007fee2a9cbde0 in std::thread::Builder::spawn_unchecked_::{{closure}}::{{closure}} #11 0x00007fee2acdc7c4 in #12 0x00007fee2acd50a2 in std::panicking::try::do_call #13 0x00007fee2acd5c5b in __rust_try #14 0x00007fee2acd44e7 in std::panicking::try #15 0x00007fee2ab64254 in std::panic::catch_unwind #16 0x00007fee2a9cafb3 in std::thread::Builder::spawn_unchecked_::{{closure}} #17 0x00007fee2a82f74f in core::ops::function::FnOnce::call_once{{vtable-shim}} #18 0x00007fee2b423ff3 in as core::ops::function::FnOnce>::call_once #19 as core::ops::function::FnOnce>::call_once #20 std::sys::unix::thread::Thread::new::thread_start #21 0x00007fee2b44c2e5 in start #22 0x00007fee2b44d3d9 in __clone (gdb) n (gdb) n (gdb) finish (gdb) n 1147 VcpuExit::IoIn(addr, data) => { 最后跟下来vm在做VcpuExit::IoIn和VcpuExit::IoOut, vmm调用对应的pio_read和pio_write来响应. 注: lspci没有触发mmio相关的调用, 只有pio. 最小化启动 https://bl.ocks.org/gdamjan/1f260b58eb9fb1ba62d2234958582405 https://alpinelinux.org/downloads/ 参考集成 见: cloud-hypervisor/scripts/run_integration_tests_x86_64.sh release过程 jobs: steps: - name: Code checkout uses: actions/checkout@v2 - name: Install musl-gcc run: sudo apt install -y musl-tools //需要musl-tools - name: Install Rust toolchain (x86_64-unknown-linux-gnu) //gnu target是动态链接 uses: actions-rs/toolchain@v1 with: toolchain: \"1.60\" target: x86_64-unknown-linux-gnu - name: Install Rust toolchain (x86_64-unknown-linux-musl) //musl target是静态链接 uses: actions-rs/toolchain@v1 with: toolchain: \"1.60\" target: x86_64-unknown-linux-musl - name: Build uses: actions-rs/cargo@v1 with: toolchain: \"1.60\" command: build args: --all --release --target=x86_64-unknown-linux-gnu - name: Static Build uses: actions-rs/cargo@v1 with: toolchain: \"1.60\" command: build args: --all --release --target=x86_64-unknown-linux-musl - name: Strip cloud-hypervisor binaries run: strip target/*/release/cloud-hypervisor //strip - name: Install Rust toolchain (aarch64-unknown-linux-musl) //aarch64 musl uses: actions-rs/toolchain@v1 with: toolchain: \"1.60\" target: aarch64-unknown-linux-musl override: true - name: Static Build (AArch64) uses: actions-rs/cargo@v1 with: use-cross: true command: build args: --all --release --target=aarch64-unknown-linux-musl - name: Upload static cloud-hypervisor //上传asset id: upload-release-static-cloud-hypervisor uses: actions/upload-release-asset@v1 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: upload_url: ${{ steps.create_release.outputs.upload_url }} asset_path: target/x86_64-unknown-linux-musl/release/cloud-hypervisor asset_name: cloud-hypervisor-static asset_content_type: application/octet-stream "},"notes/rust_cloud-hypervisor_问题与解决.html":{"url":"notes/rust_cloud-hypervisor_问题与解决.html","title":"cloud hypervisor问题与解决","keywords":"","body":" cloud hypervisor无法启动 会是什么原因 检查kvm是否nested enable nested KVM 不是nested没开 升级kernel 编译virtiofsd target是musl也不总是完全的静态链接 如何静态链接virtiofsd cloud hypervisor无法启动 直接启动会报错:看提示已经能够显示出错的具体代码位置了. 加上RUST_BACKTRACE=1会更具体: 又提示RUST_BACKTRACE=full会更详细: 可以看到: rust的调用层级很多, 和go有的一拼 RUST_BACKTRACE=1会过滤掉最近的0到12层调用栈, 这些都是rust_begin_unwind的内部流程, 一般用户不需要关心 真正出问题的是vmm::vm::Vm::new, 即RUST_BACKTRACE=full时的第16层调用栈, 很奇怪的是在调用栈里没提示是哪一行. 但调用栈打印之前就有打印提示出错文件和行号:vmm/src/vm.rs:729:48 unwrap出错会直接panic 用环境变量RUST_BACKTRACE=这招和go很像GOTRACEBACK= 会是什么原因 突然想到这个机器本来就是kvm的虚拟机, 是否是kvm嵌套没打开呢? 参考:https://docs.fedoraproject.org/en-US/quick-docs/using-nested-virtualization-in-kvm/ 检查kvm是否nested cat /sys/module/kvm_intel/parameters/nested 果然这个机器显示N enable nested KVM To enable nested virtualization for Intel processors: Shut down all running VMs and unload the kvm_probe module:sudo modprobe -r kvm_intel Activate the nesting feature:sudo modprobe kvm_intel nested=1 Nested virtualization is enabled until the host is rebooted. To enable it permanently, add the following line to the /etc/modprobe.d/kvm.conf file:options kvm_intel nested=1 AMD的CPU把上面的kvm_intel改成kvm_amd 不是nested没开 按照上面的方法, 重新加载kvm_intel并使能nested=1, 也成功了. 但问题依旧.那估计就是kernel版本太低了:Linux spine.novalocal 3.10.0-1160.2.2.el7.x86_64 不支持KVM_CAP_IMMEDIATE_EXIT功能 https://github.com/rust-vmm/kvm-ioctls/src/cap.rs ImmediateExit = KVM_CAP_IMMEDIATE_EXIT, 升级kernel centos 7的kernel比较老, 直接用标准方式升级版本还是3.10. 下面用epel升级kernel yum --enablerepo=elrepo-kernel install kernel-lt 改grub默认从新kernel启动, 启动后版本是: $ uname -a Linux spine.novalocal 5.4.207-1.el7.elrepo.x86_64 #1 SMP Tue Jul 19 10:40:55 EDT 2022 x86_64 x86_64 x86_64 GNU/Linux 使用新kernel问题解决! 编译virtiofsd virtiofsd是rust版本的daemon进程, 用来通过viriofs协议和VM共享host目录. git clone https://gitlab.com/virtio-fs/virtiofsd cargo build --release 错误: /usr/bin/ld: cannot find -lseccomp /usr/bin/ld: cannot find -lcap-ng collect2: error: ld returned 1 exit status 解决: sudo apt install libseccomp-dev libcap-ng-dev target是musl也不总是完全的静态链接 比如这个virtiofsd, 用了musl libc之后, libc的部分是静态链接的. 但还是引用了libseccomp和libcap 如何静态链接virtiofsd virtiofsd的官方repo就可以编译出完全静态的二进制, 它是如何做到的? 见https://gitlab.com/virtio-fs/virtiofsd/-/blob/main/.gitlab-ci.yml apk add libcap-ng-static libseccomp-static musl-dev RUSTFLAGS='-C target-feature=+crt-static -C link-self-contained=yes' LIBSECCOMP_LINK_TYPE=static LIBSECCOMP_LIB_PATH=/usr/lib LIBCAPNG_LINK_TYPE=static LIBCAPNG_LIB_PATH=/usr/lib cargo build --release --target x86_64-unknown-linux-musl "},"notes/rust_coding_brief.html":{"url":"notes/rust_coding_brief.html","title":"代码积累","keywords":"","body":"记录平时积累的rust知识. "},"notes/rust_序列化.html":{"url":"notes/rust_序列化.html","title":"序列化原理","keywords":"","body":" 主流的serde框架 简单例子 serde_json 理论 untype的例子 Index操作符重载 反序列化自定义struct json!宏构建json 序列化结构体 性能 依赖 理论 29种类型 derive 属性 自己实现序列化 序列化 反序列化 反序列化的zero copy和生命周期标记 主流的serde框架 Serde is a framework for _ser_ializing and _de_serializing Rust data structures efficiently and generically. 简单例子 use serde::{Serialize, Deserialize}; extern crate serde_json; // 1.0.82 #[derive(Serialize, Deserialize, Debug)] struct Point { x: i32, y: i32, } fn main() { let point = Point { x: 1, y: 2 }; // Convert the Point to a JSON string. let serialized = serde_json::to_string(&point).unwrap(); // Prints serialized = {\"x\":1,\"y\":2} println!(\"serialized = {}\", serialized); // Convert the JSON string back to a Point. let deserialized: Point = serde_json::from_str(&serialized).unwrap(); // Prints deserialized = Point { x: 1, y: 2 } println!(\"deserialized = {:?}\", deserialized); } serde_json 理论 比如下面的json { \"name\": \"John Doe\", \"age\": 43, \"address\": { \"street\": \"10 Downing Street\", \"city\": \"London\" }, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] } json中的每个\"value\", 都是一个serde_json::Value enum Value { Null, Bool(bool), Number(Number), String(String), Array(Vec), Object(Map), } 用serde_json::from_str从string里反序列化json 用from_slice从&[u8]反序列化json 用from_reader从文件或者TCP的socket的io::Read反序列化json untype的例子 所谓的untype就是说没有预定义好一个struct, 而是直接从JSON字符串里反序列化出一个对象, 这个对象的类型永远是serde_json::Value use serde_json::{Result, Value}; fn untyped_example() -> Result { // Some JSON input data as a &str. Maybe this comes from the user. let data = r#\" { \"name\": \"John Doe\", \"age\": 43, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] }\"#; // Parse the string of data into serde_json::Value. let v: Value = serde_json::from_str(data)?; // Access parts of the data by indexing with square brackets. println!(\"Please call {} at the number {}\", v[\"name\"], v[\"phones\"][0]); Ok(()) } fn main() { untyped_example(); } //结果 Please call \"John Doe\" at the number \"+44 1234567\" rust的enum真是强大, 可以对serde_json::Value在运行时做各种操作, 比如v[\"name\"], 甚至v[\"phones\"][0]都是合法的. -- 是因为serde_json::Value自己实现了Index操作符. 显然我们知道这些是合理的, 那如果故意用\"不可能\"的key去访问呢? 比如: println!(\"Please call {} at the number {}\", v[\"nnnnnnnnnnnn\"], v[\"phones\"][0][0][0]); //能正常运行, 没有崩溃, 没有index越界, 结果为null Please call null at the number null 如果最后整个打印v, 会得到: println!(\"{:?}\", v); //结果 Object({\"age\": Number(43), \"name\": String(\"John Doe\"), \"phones\": Array([String(\"+44 1234567\"), String(\"+44 2345678\")])}) Index操作符重载 看起来v支持用index来访问, 是这个库有特殊的实现: https://github.com/serde-rs/json/blob/master/src/value/index.rs impl ops::Index for Value where I: Index, { ... } 这个Index是下面: 关键先match v的类型, 再操作. 相当于操作符重载, 应该是rust比较高阶的用法. impl Index for str { fn index_into(&self, v: &'v Value) -> Option { match v { Value::Object(map) => map.get(self), _ => None, } } fn index_into_mut(&self, v: &'v mut Value) -> Option { match v { Value::Object(map) => map.get_mut(self), _ => None, } } fn index_or_insert(&self, v: &'v mut Value) -> &'v mut Value { if let Value::Null = v { *v = Value::Object(Map::new()); } match v { Value::Object(map) => map.entry(self.to_owned()).or_insert(Value::Null), _ => panic!(\"cannot access key {:?} in JSON {}\", self, Type(v)), } } } 自己实现的Index逻辑: The result of square bracket indexing like v[\"name\"] is a borrow of the data at that index, so the type is &Value. A JSON map can be indexed with string keys, while a JSON array can be indexed with integer keys. If the type of the data is not right for the type with which it is being indexed, or if a map does not contain the key being indexed, or if the index into a vector is out of bounds, the returned element is Value::Null. 反序列化自定义struct 上面untype的例子中, 反序列化出来的对象只能是serde_json::Value, 虽然也可以按照json对号入座的访问里面的filed, 但实际是走的\"通用\"代码. 下面的例子可以直接返回一个strongly typed结构体: use serde::{Deserialize, Serialize}; use serde_json::Result; #[derive(Serialize, Deserialize)] struct Person { name: String, age: u8, phones: Vec, } fn typed_example() -> Result { // Some JSON input data as a &str. Maybe this comes from the user. let data = r#\" { \"name\": \"John Doe\", \"age\": 43, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] }\"#; // Parse the string of data into a Person object. This is exactly the // same function as the one that produced serde_json::Value above, but // now we are asking it for a Person as output. let p: Person = serde_json::from_str(data)?; //同样是from_str这个API, 会根据左侧变量的type来适配, 强大! // Do things just like with any other Rust data structure. println!(\"Please call {} at the number {}\", p.name, p.phones[0]); //这里对name的访问也变成了p.name Ok(()) } This is the same serde_json::from_str function as before, but this time we assign the return value to a variable of type Person so Serde will automatically interpret the input data as a Person and produce informative error messages if the layout does not conform to what a Person is expected to look like. Any type that implements Serde's Deserialize trait can be deserialized this way. This includes built-in Rust standard library types like Vec and HashMap, as well as any structs or enums annotated with #[derive(Deserialize)]. from_str()会返回不同的类型, 是因为它是个泛型函数: pub fn from_str(s: &'a str) -> Result where T: de::Deserialize, { //这里实际上是return from_trait(read::StrRead::new(s)) //伴随着return, 返回类型T被传递进from_trait from_trait(read::StrRead::new(s)) } 这个泛型函数实例化类型T的传入是从返回值Result推断出来的. 而这个返回值从变量类型而来:let p: Person = serde_json::from_str(data)?编译器推断出T就是Person from_str继续把这个类型传递给from_trait. fn from_trait(read: R) -> Result where R: Read, T: de::Deserialize, { let mut de = Deserializer::new(read); let value = tri!(de::Deserialize::deserialize(&mut de)); // Make sure the whole stream has been consumed. tri!(de.end()); Ok(value) } json!宏构建json serde_json提供了json!宏来在代码里定义原始json文本数据. use serde_json::json; fn main() { // The type of `john` is `serde_json::Value` let john = json!({ \"name\": \"John Doe\", \"age\": 43, \"phones\": [ \"+44 1234567\", \"+44 2345678\" ] }); println!(\"first phone number: {}\", john[\"phones\"][0]); // Convert to a string of JSON and print it out println!(\"{}\", john.to_string()); } json宏还提供更高级的功能: 引用变量 let full_name = \"John Doe\"; let age_last_year = 42; // The type of `john` is `serde_json::Value` let john = json!({ \"name\": full_name, \"age\": age_last_year + 1, //这里可以引用上面的变量 \"phones\": [ format!(\"+44 {}\", random_phone()) //也可以调用其他宏和函数 ] }); One neat thing about the json! macro is that variables and expressions can be interpolated directly into the JSON value as you are building it. Serde will check at compile time that the value you are interpolating is able to be represented as JSON. 序列化结构体 serde_json::to_string 序列化到string serde_json::to_vec序列化到Vec serde_json::to_writer序列化到文件或者TCP stream Any type that implements Serde's Serialize trait can be serialized this way. This includes built-in Rust standard library types like Vec and HashMap, as well as any structs or enums annotated with #[derive(Serialize)]. 性能 性能很好. 比最快的C实现还快 It is fast. You should expect in the ballpark of 500 to 1000 megabytes per second deserialization and 600 to 900 megabytes per second serialization, depending on the characteristics of your data. This is competitive with the fastest C and C++ JSON libraries or even 30% faster for many use cases. Benchmarks live in the serde-rs/json-benchmark repo. 依赖 只依赖内存allocator. 可以禁止其他default的feature, 只保留alloc Disable the default \"std\" feature and enable the \"alloc\" feature: [dependencies] serde_json = { version = \"1.0\", default-features = false, features = [\"alloc\"] } 理论 不同于其他使用发射来实现序列化的语言, serde用的是rust的trait. 实现了Serde's Serialize and Deserialize的struct都可以被序列化/反序列化. 29种类型 serde归纳了29种基础类型: 注意没有指针! 这点和tinygo不一样, tinygo用了反射, 而反射是支持指针的. 14 primitive types bool i8, i16, i32, i64, i128 u8, u16, u32, u64, u128 f32, f64 char string UTF-8 bytes with a length and no null terminator. May contain 0-bytes. When serializing, all strings are handled equally. When deserializing, there are three flavors of strings: transient, owned, and borrowed. This distinction is explained in Understanding deserializer lifetimes and is a key way that Serde enabled efficient zero-copy deserialization. byte array - [u8] Similar to strings, during deserialization byte arrays can be transient, owned, or borrowed. option Either none or some value. unit The type of () in Rust. It represents an anonymous value containing no data. unit_struct For example struct Unit or PhantomData. It represents a named value containing no data. unit_variant For example the E::A and E::B in enum E { A, B }. newtype_struct For example struct Millimeters(u8). newtype_variant For example the E::N in enum E { N(u8) }. seq A variably sized heterogeneous sequence of values, for example Vec or HashSet. When serializing, the length may or may not be known before iterating through all the data. When deserializing, the length is determined by looking at the serialized data. Note that a homogeneous Rust collection like vec![Value::Bool(true), Value::Char('c')] may serialize as a heterogeneous Serde seq, in this case containing a Serde bool followed by a Serde char. tuple A statically sized heterogeneous sequence of values for which the length will be known at deserialization time without looking at the serialized data, for example (u8,) or (String, u64, Vec) or [u64; 10]. tuple_struct A named tuple, for example struct Rgb(u8, u8, u8). tuple_variant For example the E::T in enum E { T(u8, u8) }. map A variably sized heterogeneous key-value pairing, for example BTreeMap. When serializing, the length may or may not be known before iterating through all the entries. When deserializing, the length is determined by looking at the serialized data. struct A statically sized heterogeneous key-value pairing in which the keys are compile-time constant strings and will be known at deserialization time without looking at the serialized data, for example struct S { r: u8, g: u8, b: u8 }. struct_variant For example the E::S in enum E { S { r: u8, g: u8, b: u8 } }. 大多数的rust类型, 都能映射到serde类型: rust bool --> serde bool rust Rgb(u8,u8,u8) --> serde tuple struct ... derive 用#[derive(Serialize, Deserialize)]给每个结构体生成一对Serialize and Deserialize traits. 属性 有很多实用的属性, 比如: #[serde(rename = \"name\")] #[serde(rename_all = \"...\")] //比如UPPERCASE, camelCase...等等 #[serde(default)] #[serde(alias = \"name\")] #[serde(flatten)] ...很多... 自己实现序列化 一般用#[derive(Serialize, Deserialize)]配合attributes就够了. 但特殊case如果想自定义序列化, 可以自己实现Serialize and Deserialize这两个trait 每个trait都只有一个方法 pub trait Serialize { fn serialize(&self, serializer: S) -> Result where S: Serializer; } pub trait Deserialize: Sized { fn deserialize(deserializer: D) -> Result where D: Deserializer; } 序列化 pub trait Serialize { fn serialize(&self, serializer: S) -> Result where S: Serializer; } This method's job is to take your type (&self) and map it into the Serde data model by invoking exactly one of the methods on the given Serializer. Serializer也是个trait, 这个trait是不同类型的format(比如json, Bincode等). 并不是所有的序列化输出都是text或者bin的, 比如serde_json::value::Serializer(注意, 不是serde_json::serializer)就序列化到内存. serde把结构体的到29种内部数据类型抽象成trait Serialize, 而把29种数据类型到输出format, 抽象成trait Serializer, 让二者解耦: 从结构体到29种数据类型OK, 就和最后的output格式无关. 这是个很巧妙的设计. Serialize ==> 29种内部数据类型 ==> Serializer 比如序列化一个Map impl Serialize for MyMap where K: Serialize, V: Serialize, { fn serialize(&self, serializer: S) -> Result where S: Serializer, { let mut map = serializer.serialize_map(Some(self.len()))?; for (k, v) in self { //因为知道self就是个map, 所以能用for in map.serialize_entry(k, v)?; } map.end() } } 结构体有4类: 普通结构体, tuple结构体, newtype, unit结构体 // An ordinary struct. Use three-step process: // 1. serialize_struct // 2. serialize_field // 3. end struct Color { r: u8, g: u8, b: u8, } // A tuple struct. Use three-step process: // 1. serialize_tuple_struct // 2. serialize_field // 3. end struct Point2D(f64, f64); // A newtype struct. Use serialize_newtype_struct. struct Inches(u64); // A unit struct. Use serialize_unit_struct. struct Instance; 反序列化 pub trait Deserialize: Sized { fn deserialize(deserializer: D) -> Result where D: Deserializer; } This method's job is to map the type into the Serde data model by providing the Deserializer with a Visitor that can be driven by the Deserializer to construct an instance of your type. Deserializer需要deserialize传入visitor trait. 反序列化比序列化更复杂点. 大体上根据序列化的format不同, 可以分为: 自解释的文本. 比如json, 序列化后的文本就能看出来对应的结构体. 这个情况可以用通用的反序列化apideserialize_any, 产生的对象是serde_json::Value 非自解释的bincode. 比如二进制的序列化方式, 只看output是不可能知道原始结构体的layout的. 这个情况需要编程时明确目标结构体的类型, 产生的对象是非serde_json::Value 反序列化的zero copy和生命周期标记 rust能做到zero copy是因为生成的目标结构体, 能引用原始buffer里面的比如string等类型, 不用拷贝. 因为有生命周期标记. 比如: #[derive(Deserialize)] struct User { id: u32, name: &'a str, screen_name: &'a str, location: &'a str, } Zero-copy deserialization means deserializing into a data structure, like the User struct above, that borrows string or byte array data from the string or byte array holding the input. This avoids allocating memory to store a string for each individual field and then copying string data out of the input over to the newly allocated field. Rust guarantees that the input data outlives the period during which the output data structure is in scope, meaning it is impossible to have dangling pointer errors as a result of losing the input data while the output data structure still refers to it. 上面的User结构体有多个对str的引用, 这些引用直接引用到原始buffer, 没有拷贝. rust保证原始buffer会一直有效直到这个结构体的生命周期结束. 注: User结构体本身不用生命周期标记, 它的标记'a是给里面的成员用的, 表示所有成员都有同样的生命周期. 反序列化的复杂点在于, 目标结构体要分配内存: where T: Deserialize 其引用的内存可能来自原始input的buffer中, 比如serde_json::from_str中, 原始str的生命周期也是caller提供的, 带生命周期标记的, 就可以被最终的目标结构体引用. This means \"T can be deserialized from some lifetime.\" The caller gets to decide what lifetime that is. Typically this is used when the caller also provides the data that is being deserialized from, for example in a function like serde_json::from_str. In that case the input data must also have lifetime 'de, for example it could be &'de str. where T: DeserializeOwned 原始的input, 以及其伴随的buffer, 在反序列化之后会被free. 此时不能引用. 比如io的reader This means \"T can be deserialized from any lifetime.\" The callee gets to decide what lifetime. Usually this is because the data that is being deserialized from is going to be thrown away before the function returns, so T must not be allowed to borrow from it. For example a function that accepts base64-encoded data as input, decodes it from base64, deserializes a value of type T, then throws away the result of base64 decoding. Another common use of this bound is functions that deserialize from an IO stream, such as serde_json::from_reader. "},"notes/rust_知识点积累.html":{"url":"notes/rust_知识点积累.html","title":"知识点更新","keywords":"","body":" 生命周期标记 线程 宏 简单例子 例子1 例子2 迭代器 闭包 rust指针cheatsheet ownership 方法和瀑布式设计 小知识点 std库的catch_unwind catch_unwind和FnOnce 什么是FnOnce catch_unwind 代码解释 std库的同步功能 u32可以调用checked_add做溢出检查 tuple返回值 宏调用使用()或{}都行? 该传值的时候传借用也行? 方法impl块里面的Self 条件编译 static变量 trait object 可以在函数定义里干任何事? 结构体定义和C对比 crate和mod bin文件的例子 lib的例子 firecracker/src/utils/src/arg_parser.rs代码走读 use 使用了BTreeMap 重定义了Result ArgParser对象 ArgParser对象方法 new这个对象: 从命令行parse 增加arg项 格式化help output Argument对象 test std collections Sequences性能 Maps性能 BTreeMap iter() keys()和values() 生命周期标记 只有引用才有生命周期标记的说法, 其他都没有: 没有结构体生命周期标记的说法. 看见一个struct带标记, 实际上是对其内部的field的引用的标记 编译器会自动推导一般的生命标记. 比如: fn announce(value: &impl Display) { println!(\"Behold! {}!\", value); } fn main() { let num = 42; let num_ref = &num; announce(num_ref); } 去掉编译器语法糖的版本fn announce(value: &'a T) where T: Display { println!(\"Behold! {}!\", value); } fn main() { 'x: { let num = 42; 'y: { let num_ref = &'y num; 'z: { announce(num_ref); } } } } 线程 use std::thread; fn main() { let guard = thread::scoped(|| { println!(\"Hello from a thread!\"); }); // guard goes out of scope here. 就是说在这里会等着上面的线程结束 } scoped原型是 fn scoped(self, f: F) -> JoinGuard where T: Send + 'a, F: FnOnce() -> T, F: Send + 'a Specifically, F, the closure that we pass to execute in the new thread. It has two restrictions: It must be a FnOnce from () to T. Using FnOnce allows the closure to take ownership of any data it mentions from the parent thread. The other restriction is that F must be Send. We aren't allowed to transfer this ownership unless the type thinks that's okay. 如果用spawn就不会卡住了, main退出会强制退出线程. fn main() { thread::spawn(|| { println!(\"Hello from a thread!\"); }); timer::sleep(Duration::milliseconds(50)); } 宏 比如Vec!宏: let x: Vec = vec![1, 2, 3]; 展开后是: let x: Vec = { let mut temp_vec = Vec::new(); temp_vec.push(1); temp_vec.push(2); temp_vec.push(3); temp_vec }; 对应的宏实现是: macro_rules! vec { ( $( $x:expr ),* ) => { { let mut temp_vec = Vec::new(); $( temp_vec.push($x); )* temp_vec } }; } ( $( $x:expr ),* ) => {...}里, $x:expr是类似match的语法, $(...),*是类似正则的语法, 表示match expr 0次或多次; $x是个临时变量. =>右边的$()*表示重复每个匹配 简单例子 macro_rules! five_times { ($x:expr) => (5 * $x); } fn main() { assert_eq!(25, five_times!(2 + 3)); } 例子1 macro_rules! foo { (x => $e:expr) => (println!(\"mode X: {}\", $e)); (y => $e:expr) => (println!(\"mode Y: {}\", $e)); } fn main() { foo!(y => 3); //这里的y => 3被宏做匹配 //foo!(z => 3);这样调用不行, 会报错. error: no rules expected the token `z` } //输出 mode Y: 3 例子2 macro_rules! o_O { ( $( $x:expr; [ $( $y:expr ),* ] );* ) => { &[ $($( $x + $y ),*),* ] } } fn main() { let a: &[i32] = o_O!(10; [1, 2, 3]; 20; [4, 5, 6]); assert_eq!(a, [11, 12, 13, 24, 25, 26]); 迭代器 for x in 0..10 { println!(\"{}\", x); } for相当于在loop里不断的调用range这个迭代器的next方法. let mut range = 0..10; loop { match range.next() { Some(x) => { println!(\"{}\", x); }, None => { break } } } vec的iter方法返回一个迭代器: let nums = vec![1, 2, 3]; for num in nums.iter() { //这里的num是个引用, println默认会解引用. println!(\"{}\", num); //下面的写法也行 println!(\"{}\", *num); } Now we're explicitly dereferencing num. Why does iter() give us references? Well, if it gave us the data itself, we would have to be its owner, which would involve making a copy of the data and giving us the copy. With references, we're just borrowing a reference to the data, and so it's just passing a reference, without needing to do the copy. 见: https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/iterators.html 有些概念挺有用的: Iterator adapters, 比如map, filter等API Consumers, 比如collect等 闭包 let add_one = |x| { 1 + x }; println!(\"The sum of 5 plus 1 is {}.\", add_one(5)); fn main() { let x: i32 = 5; let printer = || { println!(\"x is: {}\", x); }; printer(); // prints \"x is: 5\" } 带move关键词的闭包的语义是take ownership: a moving closure always takes ownership of all variables that it uses. Ordinary closures, in contrast, just create a reference into the enclosing stack frame. 每个闭包的type都是独特的, 下面的例子用了F和G两个fn, 虽然签名是一模一样的, 但F和G是两个不同的type, 对应了两个不同的闭包. fn compose(x: i32, f: F, g: G) -> i32 where F: Fn(i32) -> i32, G: Fn(i32) -> i32 { g(f(x)) } fn main() { compose(5, |n: i32| { n + 42 }, |n: i32| { n * 2 }); // evaluates to 94 } rust指针cheatsheet Type Name Summary &T Reference Allows one or more references to read T &mut T Mutable Reference Allows a single reference to read and write T Box Box Heap allocated T with a single owner that may read and write T. Rc \"arr cee\" pointer Heap allocated T with many readers Arc Arc pointer Same as above, but safe sharing across threads *const T Raw pointer Unsafe read access to T *mut T Mutable raw pointer Unsafe read and write access to T ownership 说的很细 https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/ownership.html 方法和瀑布式设计 https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/method-syntax.html 小知识点 std库的catch_unwind panic::catch_unwind可以捕获rust运行时的panic use std::panic; let result = panic::catch_unwind(|| { println!(\"hello!\"); }); assert!(result.is_ok()); let result = panic::catch_unwind(|| { panic!(\"oh no!\"); }); assert!(result.is_err()); catch_unwind和FnOnce std::panic::catch_unwind(AssertUnwindSafe(f)) 上面的代码是ok的, 只要F满足约束: where F: FnOnce(), F: Send + 'static, 什么是FnOnce pub trait FnOnce { type Output; extern \"rust-call\" fn call_once(self, args: Args) -> Self::Output; } Instances of FnOnce can be called, but might not be callable multiple times. Because of this, if the only thing known about a type is that it implements FnOnce, it can only be called once. FnOnce只能被调用一次. FnOnce is implemented automatically by closure that might consume captured variables, as well as all types that implement FnMut, e.g. (safe) function pointers (since FnOnce is a supertrait of FnMut). 闭包自动实现了FnOnce, Fn, FnMut中的一个. Since both Fn and FnMut are subtraits of FnOnce, any instance of Fn or FnMut can be used where a FnOnce is expected. Fn和FnMut是FnOnce的子trait Use FnOnce as a bound when you want to accept a parameter of function-like type and only need to call it once. If you need to call the parameter repeatedly, use FnMut as a bound; if you also need it to not mutate state, use Fn. Also of note is the special syntax for Fn traits (e.g. Fn(usize, bool) -> usize). FnOnce是个函数形式的trait, 和Fn一样拥有特殊语法:Fn(usize, bool) -> usize 详见: Closures: Anonymous Functions catch_unwind std::panic::catch_unwind()的入参类型是FnOnce() -> R + UnwindSafe这个特殊语法的Fn trait pub fn catch_unwind R + UnwindSafe, R>(f: F) -> Result { unsafe { panicking::r#try(f) } } 代码解释 std::panic::catch_unwind(AssertUnwindSafe(f)) AssertUnwindSafe是个元组结构体: pub struct AssertUnwindSafe(pub T); 它实现了FnOnce: impl R> FnOnce for AssertUnwindSafe { type Output = R; extern \"rust-call\" fn call_once(self, _args: ()) -> R { (self.0)() } } 所以: FnOnce不一定非要是个闭包, 也可以是个结构体, 比如struct AssertUnwindSafe 记住Fn这个特殊的trait std库的同步功能 在多线程的情况下, 希望所有线程在某个点\"集合\": use std::sync::{Arc, Barrier}; use std::thread; let mut handles = Vec::with_capacity(10); let barrier = Arc::new(Barrier::new(10)); for _ in 0..10 { let c = Arc::clone(&barrier); // The same messages will be printed together. // You will NOT see any interleaving. handles.push(thread::spawn(move|| { println!(\"before wait\"); c.wait(); println!(\"after wait\"); })); } // Wait for other threads to finish. for handle in handles { handle.join().unwrap(); } u32可以调用checked_add做溢出检查 //self.next_gsi类型是u32 self.next_gsi = self.next_gsi.checked_add(1).ok_or(Error::Overflow)?; tuple返回值 一个函数如果想返回多个返回值, 可以这样: fn prepare_default_values() -> (String, String, String) { let default_vcpus = format! {\"boot={},max_phys_bits={}\", config::DEFAULT_VCPUS,config::DEFAULT_MAX_PHYS_BITS}; let default_memory = format! {\"size={}M\", config::DEFAULT_MEMORY_MB}; let default_rng = format! {\"src={}\", config::DEFAULT_RNG_SOURCE}; (default_vcpus, default_memory, default_rng) } 使用的时候用模式匹配: let (default_vcpus, default_memory, default_rng) = prepare_default_values(); 宏调用使用()或{}都行? 比如下面的代码, format和println宏, 用小括号和大括号调用, 作用一模一样. let default_vcpus = format! {\"boot={},max_phys_bits={}\", 8, 6.78}; let default_vcpus2 = format!(\"boot={},max_phys_bits={}\", 8, 6.78); println!(\"{}\", default_vcpus); println! {\"{}\", default_vcpus2}; 该传值的时候传借用也行? 比如这个函数, 第二个参数guest_mem的类型要求是&GuestMemoryMmap pub fn memory_init( &mut self, guest_mem: &GuestMemoryMmap, kvm_max_memslots: usize, track_dirty_pages: bool, ) -> Result 调用的时候: //已知guest_memory是&GuestMemoryMmap类型 guest_memory: &GuestMemoryMmap let mut vm = Vm::new() //这样可以编译, guest_memory的借用传入 vm.memory_init(&guest_memory, kvm.max_memslots(), track_dirty_pages) //这样也可以, 直接传入guest_memory, 这个应该是更符合函数signature vm.memory_init(guest_memory, kvm.max_memslots(), track_dirty_pages) //这样竟然也行 vm.memory_init(&&&&&&&&&guest_memory, kvm.max_memslots(), track_dirty_pages) 可能GuestMemoryMmap实现了Dref trait? 还是这种形式的传参都是被rust支持的????? 方法impl块里面的Self 一个结构体的方法, 并不都是入参一定是Self, 比如类似new()方法, 返回值才是Self(或者&Self等) 比如: pub struct VmResources { ... } impl VmResources { //new函数 pub fn from_json() -> std::result::Result { ...实例化Self } //其他方法 pub fn set_vsock_device(&mut self, config: VsockDeviceConfig) -> Result //等等 } 调用\"new\"方法的时候, 用的是VmResources::from_json(), 调用其他方法的时候, 用的是对象.xxx(). 而且, 一般的方法第一个入参是&mut self或者&self 它们都在一个impl块里. 条件编译 比如只有再cfg的target_arch是aarch64时才编译: #[cfg(target_arch = \"aarch64\")] enable_ssbd_mitigation(); static变量 比如下面的代码: use lazy_static::lazy_static; lazy_static! { static ref _LOGGER_INNER: Logger = Logger::new(); /// Static instance used for handling human-readable logs. pub static ref LOGGER: &'static Logger = { set_logger(_LOGGER_INNER.deref()).expect(\"Failed to set logger\"); _LOGGER_INNER.deref() }; } static说的是被static标记的变量在整个程序的周期内都有效 ref说的是后面的变量在被match做pattern匹配的时候, 使用借用方式.注: match默认采用move方式, 比如下面的maybe_name变量被match后就没法用了.let maybe_name = Some(String::from(\"Alice\")); // The variable 'maybe_name' is consumed here ... match maybe_name { Some(n) => println!(\"Hello, {}\", n), _ => println!(\"Hello, world\"), } // ... and is now unavailable. println!(\"Hello again, {}\", maybe_name.unwrap_or(\"world\".into())); 用ref就可以: 注意Some(ref n)那句let maybe_name = Some(String::from(\"Alice\")); // Using `ref`, the value is borrowed, not moved ... match maybe_name { Some(ref n) => println!(\"Hello, {}\", n), _ => println!(\"Hello, world\"), } // ... so it's available here! println!(\"Hello again, {}\", maybe_name.unwrap_or(\"world\".into())); _LOGGER_INNER.deref()这种神奇操作来自lazy_static!宏, 这是github上实现的第三方库, 用来在运行时声明static变量, 比如:lazy_static! { static ref NAME: TYPE = EXPR; } 大义是自动实现了Deref trait, 在第一次deref的时候, 执行后面的EXPR, 后面再解引用的时候, 就直接返回第一次的值的引用. trait object 比如下面的代码中, 返回值Arc是个trait object, 和golang的iface差不多的意思. 编译时选择虚拟化平台, 比如选了kvm, kvm的那个new函数返回具体的结构体. pub fn new() -> std::result::Result, HypervisorError> { #[cfg(feature = \"kvm\")] let hv = kvm::KvmHypervisor::new()?; #[cfg(feature = \"mshv\")] let hv = mshv::MshvHypervisor::new()?; Ok(Arc::new(hv)) } 可以在函数定义里干任何事? 比如可以在函数定义里定义结构体, 并实现一个trait fn write_fmt(&mut self, fmt: fmt::Arguments) -> Result { // Create a shim which translates a Write to a fmt::Write and saves // off I/O errors. instead of discarding them struct Adapter { inner: &'a mut T, error: Result, } impl fmt::Write for Adapter { fn write_str(&mut self, s: &str) -> fmt::Result { match self.inner.write_all(s.as_bytes()) { Ok(()) => Ok(()), Err(e) => { self.error = Err(e); Err(fmt::Error) } } } } let mut output = Adapter { inner: self, error: Ok(()) }; match fmt::write(&mut output, fmt) { Ok(()) => Ok(()), Err(..) => { // check if the error came from the underlying `Write` or not if output.error.is_err() { output.error } else { Err(error::const_io_error!(ErrorKind::Uncategorized, \"formatter error\")) } } } } 结构体定义和C对比 同样的结构体, C的定义和rust定义分别如下: struct sock_fprog { unsigned short len; /* Number of BPF instructions */ struct sock_filter *filter; /* Pointer to array of BPF instructions */ }; struct sock_filter { /* Filter block */ __u16 code; /* Actual filter code */ __u8 jt; /* Jump true */ __u8 jf; /* Jump false */ __u32 k; /* Generic multiuse field */ }; rust对应的定义更严谨(啰嗦): /// BPF instruction structure definition. /// See /usr/include/linux/filter.h . #[repr(C)] #[derive(Clone, Debug, PartialEq, Deserialize, Serialize)] #[doc(hidden)] pub struct sock_filter { pub code: ::std::os::raw::c_ushort, pub jt: ::std::os::raw::c_uchar, pub jf: ::std::os::raw::c_uchar, pub k: ::std::os::raw::c_uint, } /// Program made up of a sequence of BPF instructions. pub type BpfProgram = Vec; crate和mod bin文件的例子 firecracker工程下, 有个seccompiler目录: 上面的图中: toml文件里的关键字都是规范定的, 见https://doc.rust-lang.org/cargo/reference/manifest.html Cargo.toml里面说这个seccompiler目录是个crate, 会产生一个seccompiler-bin文件, 产生这个bin的源文件是src/seccompiler_bin.rs; [[bin]]是个表数组, 表示可能会有多个bin. src里面每个文件名都是个mod 在主文件seccompiler_bin.rs里要声明这些mod lib的例子 比如下面这个utils, 是多个工具库的集合. 因为都是库, 就没有一个叫utils.rs的文件 外部crate要引用其中某个库的时候, 用use utils::arg_parser::{ArgParser, Argument, Arguments as ArgumentsBag}; firecracker/src/utils/src/arg_parser.rs代码走读 use 使用了BTreeMap use std::collections::BTreeMap; use std::env; use std::fmt; use std::result; 重定义了Result std::result::Result是个泛型, 是对函数返回值的\"标准\"抽象 pub type Result = result::Result; //这个Error就是下面的Error arg_parser自己的Error定义: 其中每个field基本上都是\"元组结构体\"的形式: /// Errors associated with parsing and validating arguments. #[derive(Debug, PartialEq)] pub enum Error { /// The argument B cannot be used together with argument A. ForbiddenArgument(String, String), /// The required argument was not provided. MissingArgument(String), /// A value for the argument was not provided. MissingValue(String), /// The provided argument was not expected. UnexpectedArgument(String), /// The argument was provided more than once. DuplicateArgument(String), } Error这个enum实现了fmt::Display impl fmt::Display for Error { fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result { use self::Error::*; match *self { ForbiddenArgument(ref arg1, ref arg2) => write!( f, \"Argument '{}' cannot be used together with argument '{}'.\", arg2, arg1 ), MissingArgument(ref arg) => write!(f, \"Argument '{}' required, but not found.\", arg), MissingValue(ref arg) => write!( f, \"The argument '{}' requires a value, but none was supplied.\", arg ), UnexpectedArgument(ref arg) => write!( f, \"Found argument '{}' which wasn't expected, or isn't valid in this context.\", arg ), DuplicateArgument(ref arg) => { write!(f, \"The argument '{}' was provided more than once.\", arg) } } } } 这里面用了write!这个宏, 把一个formated文本写入f. ArgParser对象 ArgParser对象是程序的命令行对象: 这里面一直都带着生命周期标记'a /// Keep information about the argument parser. #[derive(Clone, Default)] pub struct ArgParser { arguments: Arguments, } arguments是个BTree /// Stores the arguments of the parser. #[derive(Clone, Default)] pub struct Arguments { // A BTreeMap in which the key is an argument and the value is its associated `Argument`. args: BTreeMap>, // The arguments specified after `--` (i.e. end of command options). extra_args: Vec, } 再里面的Argument是命令行的option的抽象: /// Stores the characteristics of the `name` command line argument. #[derive(Clone, Debug, PartialEq)] pub struct Argument { name: &'a str, required: bool, requires: Option, forbids: Vec, takes_value: bool, allow_multiple: bool, default_value: Option, help: Option, user_value: Option, } ArgParser对象方法 所有对象方法都包在impl块中: impl ArgParser { } new这个对象: new返回Self本身, 而不能返回借用(&Self), 因为这个函数结束后, 所有local的东西都会被drop, 那显然就没有什么可以借用的. /// Create a new ArgParser instance. pub fn new() -> Self { ArgParser::default() } 从命令行parse 从下面的函数能看到, ArgParser对象虽然只包括Arguments, 但明显没有继承. 所以这里还要显式的转一把: /// Parse the command line arguments. pub fn parse_from_cmdline(&mut self) -> Result { self.arguments.parse_from_cmdline() } 增加arg项 这里用了\"瀑布式\"的函数形式, 入参和出参都是Self类型: 这个过程发生了所有权转移, 这里的mut self入参会导致Self move, 但最后返回的时候又move出去了. /// Add an argument with its associated `Argument` in `arguments`. pub fn arg(mut self, argument: Argument) -> Self { self.arguments.insert_arg(argument); self } 调用形式, 在其他的模块中: 下面的连续.arg()调用, 我理解没有发生Self的拷贝. fn build_arg_parser() -> ArgParser { ArgParser::new() .arg( Argument::new(\"input-file\") .required(true) .takes_value(true) .help(\"File path of the JSON input.\"), ) .arg( Argument::new(\"output-file\") .required(false) .takes_value(true) .default_value(DEFAULT_OUTPUT_FILENAME) .help(\"Optional path of the output file.\"), ) .arg( Argument::new(\"target-arch\") .required(true) .takes_value(true) .help(\"The computer architecture where the BPF program runs. Supported architectures: x86_64, aarch64.\"), ) .arg( Argument::new(\"basic\") .takes_value(false) .help(\"Deprecated! Transforms the filters into basic filters. Drops all argument checks \\ and rule-level actions. Not recommended.\"), ) } 格式化help output // Filter arguments by whether or not it is required. // Align arguments by setting width to length of the longest argument. fn format_arguments(&self, is_required: bool) -> String { let filtered_arguments = self .arguments .args .values() //这是个实体的Values, 实现了Iterator; //但它声明了自己实现了Iterator, 能编译过, 那就\"继承\"了Iterator的其他N多方法 //比如就继承了下面的filter .filter(|arg| is_required == arg.required) .collect::>(); //编译器会自动推导出返回类型是Vec let max_arg_width = filtered_arguments .iter() .map(|arg| arg.format_name().len()) .max() .unwrap_or(0); //因为上面的max函数返回Option类型, 这里unwrap Some层, 取得raw数据. filtered_arguments .into_iter() .map(|arg| arg.format_help(max_arg_width)) .collect::>() .join(\"\\n\") //Vec并没有join方法, 这里自动解引用了, 调用了[String]的join } 上面的Values是stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/alloc/src/collections/btree/map.rs定义的结构体 pub struct Values { inner: Iter, } 而且它还实现了Iterator impl Iterator for Values { } 在这里这个泛型结构体被实例化成了struct Values 那么这个struct Values对象就能享受Iterator的一系列方法 那么接下来的filter方法, 返回的Filter依旧是个Iterator fn filter(self, predicate: P) -> Filter where Self: Sized, P: FnMut(&Self::Item) -> bool, { Filter::new(self, predicate) } 这里的Self就是struct Values对象本身, filter函数需要一个predicate(谓语)函数来执行filter的具体动作, 而它的入参是&Self::Item, 那么struct Values的Iterator关联类型是什么呢? 见下面, 是&'a V, 这里实例化后是&Argument impl Iterator for Values { type Item = &'a V; fn next(&mut self) -> Option { self.inner.next().map(|(_, v)| v) } fn size_hint(&self) -> (usize, Option) { self.inner.size_hint() } fn last(mut self) -> Option { self.next_back() } } 那么就能得出: .filter(|arg| is_required == arg.required) 其中: arg是struct Values的关联类型&Argument的借用, 即&&Argument rust有自动解引用机制, 所以arg.required可以直接用 Argument对象 这里全程都带生命周期标记, 怎么看着挺啰嗦的. #[derive(Clone, Debug, PartialEq)] pub struct Argument { name: &'a str, required: bool, requires: Option, forbids: Vec, takes_value: bool, allow_multiple: bool, default_value: Option, help: Option, user_value: Option, } test 这个文件1k多行, 有一般都是test test从#[cfg(test)]开始 包在mod里面: #[cfg(test)] mod tests { use super::*; use crate::arg_parser::Value; //即使在同一个文件, 也要显式引用 } 测试项以#[test]标记, 函数以test_开头 fn test_value() { //Test `as_string()` and `as_flag()` functions behaviour. let mut value = Value::Flag; assert!(Value::as_single_value(&value).is_none()); value = Value::Single(\"arg\".to_string()); assert_eq!(Value::as_single_value(&value).unwrap(), \"arg\"); value = Value::Single(\"arg\".to_string()); assert!(!Value::as_flag(&value)); value = Value::Flag; assert!(Value::as_flag(&value)); } 使用了大量的assert_eq!宏, 比如: assert_eq!( arg_parser.formatted_help(), \"optional arguments:\\n \\ --config-file 'config-file' info.\\n \\ --id 'id' info.\\n \\ --seccomp-filter 'seccomp-filter' info.\" ); 判断Result是否ok assert!(arguments.parse(&args).is_ok()); 没有看到golang类似的benchmark测试 std collections 代码在.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/collections/mod.rs 主要是对其他crate的重新引用: pub use alloc_crate::collections::{binary_heap, btree_map, btree_set}; pub use alloc_crate::collections::{linked_list, vec_deque}; pub use alloc_crate::collections::{BTreeMap, BTreeSet, BinaryHeap}; pub use alloc_crate::collections::{LinkedList, VecDeque}; pub use self::hash_map::HashMap; pub use self::hash_set::HashSet; Rust's collections can be grouped into four major categories: Sequences: Vec, VecDeque, LinkedList Maps: HashMap, BTreeMap Sets: HashSet, BTreeSet Misc: BinaryHeap Sequences性能 get(i) insert(i) remove(i) append split_off(i) Vec O(1) O(n-i) O(n-i) O(m) O(n-i) VecDeque O(1) O(min(i, n-i)) O(min(i, n-i)) O(m) O(min(i, n-i)) LinkedList O(min(i, n-i)) O(min(i, n-i)) O(min(i, n-i)) O(1) O(min(i, n-i)) Maps性能 get insert remove range append HashMap O(1)~ O(1)~ O(1)~ N/A N/A BTreeMap O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n+m) BTreeMap iter() BTreeMap的iter()方法返回Iter结构体 这是个 pub struct Iter { range: LazyLeafRange, K, V>, length: usize, } 它实现了Iterator: #[stable(feature = \"rust1\", since = \"1.0.0\")] impl Iterator for Iter { type Item = (&'a K, &'a V); fn next(&mut self) -> Option { if self.length == 0 { None } else { self.length -= 1; Some(unsafe { self.range.next_unchecked() }) } } fn size_hint(&self) -> (usize, Option) { (self.length, Some(self.length)) } fn last(mut self) -> Option { self.next_back() } fn min(mut self) -> Option { self.next() } fn max(mut self) -> Option { self.next_back() } } BTreeMap的iter使用举例: use std::collections::BTreeMap; let mut map = BTreeMap::new(); map.insert(3, \"c\"); map.insert(2, \"b\"); map.insert(1, \"a\"); for (key, value) in map.iter() { println!(\"{}: {}\", key, value); } let (first_key, first_value) = map.iter().next().unwrap(); assert_eq!((*first_key, *first_value), (1, \"a\")); keys()和values() BTreeMap还有keys()和values()方法, 分别返回keys和values. 比如: let mut a = BTreeMap::new(); a.insert(2, \"b\"); a.insert(1, \"a\"); let keys = a.keys(); let values = a.values(); println!(\"{:?}\", keys); println!(\"{:?}\", values); 结果: [1, 2] [\"a\", \"b\"] key就是key, value就只有value, 很通顺. 但实际上, keys()和values()方法分别返回Keys和Values结构体, 而他们的内部都是inner: Iter pub struct Keys { inner: Iter, } pub struct Values { inner: Iter, } 区别在于它们各自实现的迭代器不同, 比如: impl Iterator for Values { type Item = &'a V; fn next(&mut self) -> Option { self.inner.next().map(|(_, v)| v) //把(k,v)map成v } fn size_hint(&self) -> (usize, Option) { self.inner.size_hint() } fn last(mut self) -> Option { self.next_back() } } "},"notes/rust_adaptiveservice.html":{"url":"notes/rust_adaptiveservice.html","title":"rust版本的adaptiveservice探索","keywords":"","body":" 5种\"动态\"类型 rust的泛型是静态的 静态分发 动态分发 即trait objects 从指针获取trait objects adaptiveservice是我用go写的微服务消息框架, 其核心之一是用了go的反射来给每个数据struct绑定一个handler方法. if st.svc.canHandle(tm.msg) { mm := &metaKnownMsg{ stream: ss, msg: tm.msg.(KnownMessage), } mq.putMetaMsg(mm) } else { ss.privateChan 在rust里面没有反射, 如何实现从字节流数据(stream buffer)到具体结构体的生成? 生成的数据结构体能否\"断言\"成实现了KnownMessage的trait? 先看看rust从类型上提供了什么语义, 这些语义能干什么. 5种\"动态\"类型 use std::any::Any; struct Header { uuid: u64, protocol: String } // 第一种, 静态类型, 泛型是静态分发的, 即在编译的时候就生成好了\"类型化\"的代码. // statically typed, no pointer dereference struct GenericPacket { header: Header, data: T } // 第二种, 用Any，任何类型都实现了Any // uses the \"Any\" type to have dynamic typing struct AnyPacket { header: Header, data: Any, } // 第三种，用enum穷尽所有可能的类型 // uses an enum to capture the differnet possible types enum DataEnum { Integer(i32), Float(f32) } struct EnumPacket { header: Header, data: DataEnum, } // 第四种: 用trait object trait DataTrait { // interface your data conforms to } struct TraitPacket { header: Header, data: &'a dyn DataTrait, // uses a pointer dereference to something that implements DataTrait } // 第五种: 和第一种类型类似, 但是带具体方法的trait // statically typed, but will accept any type that conforms to DataTrait struct StaticTraitPacket { header: Header, data: T, } rust的泛型是静态的 参考: https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/static-and-dynamic-dispatch.html 比如下面的trait: trait Foo { fn method(&self) -> String; } impl Foo for u8 { fn method(&self) -> String { format!(\"u8: {}\", *self) } } impl Foo for String { fn method(&self) -> String { format!(\"string: {}\", *self) } } 静态分发 比如下面的代码: fn do_something(x: T) { x.method(); } fn main() { let x = 5u8; let y = \"Hello\".to_string(); do_something(x); do_something(y); } rust会在编译阶段就知道do_something()的入参类型, 会静态的生成类型下面的静态代码: fn do_something_u8(x: u8) { x.method(); } fn do_something_string(x: String) { x.method(); } fn main() { let x = 5u8; let y = \"Hello\".to_string(); do_something_u8(x); do_something_string(y); } 虽然\"静态分发\"会有一定的代码\"重复\"带来代码段的膨胀, 但一般问题不大, 直接函数调用的性能会好点, 比如可以被inline优化 动态分发 即trait objects Rust provides dynamic dispatch through a feature called trait objects. Trait objects, like &Foo or Box, are normal values that store a value of any type that implements the given trait, where the precise type can only be known at runtime. The methods of the trait can be called on a trait object via a special record of function pointers (created and managed by the compiler). A function that takes a trait object is not specialised to each of the types that implements Foo: only one copy is generated, often (but not always) resulting in less code bloat. However, this comes at the cost of requiring slower virtual function calls, and effectively inhibiting any chance of inlining and related optimisations from occurring. Trait objects are both simple and complicated: their core representation and layout is quite straight-forward, but there are some curly error messages and surprising behaviours to discover. 从指针获取trait objects There's two similar ways to get a trait object value: casts and coercions. If T is a type that implements a trait Foo (e.g. u8 for the Foo above), then the two ways to get a Foo trait object out of a pointer to T look like: let ref_to_t: &T = ...; // `as` keyword for casting let cast = ref_to_t as &Foo; // using a `&T` in a place that has a known type of `&Foo` will implicitly coerce: let coerce: &Foo = ref_to_t; fn also_coerce(_unused: &Foo) {} also_coerce(ref_to_t); These trait object coercions and casts also work for pointers like &mut T to &mut Foo and Box to Box, but that's all at the moment. Coercions and casts are identical. This operation can be seen as \"erasing\" the compiler's knowledge about the specific type of the pointer, and hence trait objects are sometimes referred to \"type erasure\" "},"notes/rust_常用设施.html":{"url":"notes/rust_常用设施.html","title":"常用设施","keywords":"","body":" structopt log env_logger 常用宏1 常用宏2 由编译器实现的builtin宏 trait Iterator 比较常用的Iterator方法 collect IntoIterator 数组泛型的方法impl [T] Vec Option Result Result的方法: Result的方法 其他Result Result实现了如下的trait env 取消impl trait 文件 使用举例 写文件 读文件到String 更有效率的读文件 不同选项open &File也能modify 文件 File对象 常用函数 File的方法 其他impl的trait 实现Read trait 实现Write trait 实现Seek trait Read Write Seek for &File又来一遍!!!!! open最后调用 IO 常用函数 Read trait Write trait Seek trait BufRead是Read的派生trait structopt structopt用来把命令行参数转成结构体 定义结构体的时候, 用structopt来\"标记\", 比如: #[derive(Clone, Debug, StructOpt)] #[structopt(name = \"virtiofsd backend\", about = \"Launch a virtiofsd backend.\")] struct Opt { /// Shared directory path #[structopt(long)] shared_dir: Option, /// vhost-user socket path [deprecated] #[structopt(long, required_unless_one = &[\"fd\", \"socket-path\", \"print-capabilities\"])] socket: Option, /// vhost-user socket path #[structopt(long = \"socket-path\", required_unless_one = &[\"fd\", \"socket\", \"print-capabilities\"])] socket_path: Option, ... } 注: structopt已经停止开发, 建议使用clap: Command Line Argument Parser for Rust log https://crates.io/crates/log 要在cargo.toml里面声明依赖: [dependencies] log = \"0.4\" 这个库设计的很合理. 对用户提供几个log的宏: error!, warn!, info!, debug! and trace! lib里面, 只使用这几个输出宏 bin里面, 负责初始化后端的logging实现, 如果没有初始化, 那上面的几个输出宏就类似noop 使用set_boxed_logger Sets the global logger to a Box. 或set_logger Sets the global logger to a &'static Log. 可选的logging实现有: Simple minimal loggers: env_logger simple_logger simplelog pretty_env_logger stderrlog flexi_logger Complex configurable frameworks: log4rs fern Adaptors for other facilities: syslog slog-stdlog systemd-journal-logger android_log win_dbg_logger [db_logger] For WebAssembly binaries: console_log For dynamic libraries: You may need to construct an FFI-safe wrapper over log to initialize in your libraries env_logger 比如这样在代码里: use log::{debug, error, log_enabled, info, Level}; env_logger::init(); debug!(\"this is a debug {}\", \"message\"); error!(\"this is printed by default\"); if log_enabled!(Level::Info) { let x = 3 * 4; // expensive computation info!(\"the answer was: {}\", x); } 使用时: $ RUST_LOG=debug ./main [2017-11-09T02:12:24Z DEBUG main] this is a debug message [2017-11-09T02:12:24Z ERROR main] this is printed by default [2017-11-09T02:12:24Z INFO main] the answer was: 12 可以按module来指定level $ RUST_LOG=main=info ./main [2017-11-09T02:12:24Z ERROR main] this is printed by default [2017-11-09T02:12:24Z INFO main] the answer was: 12 又比如在virtiofsd里面是这样用的: fn set_default_logger(log_level: LevelFilter) { if env::var(\"RUST_LOG\").is_err() { env::set_var(\"RUST_LOG\", log_level.to_string()); } env_logger::init(); } 常用宏1 代码在lib/rustlib/src/rust/library/std/src/macros.rs panic print println eprint eprintln dbg 常用宏2 代码在lib/rustlib/src/rust/library/core/src/macros/mod.rs panic!panic!(); panic!(\"this is a {} {message}\", \"fancy\", message = \"message\"); assert_eq! assert_ne!assert_eq!(a, b); // a b是两个表达式 assert_ne!(a, b); assert_matches!assert_matches!(a, Some(_)); assert_matches!(b, None); let c = Ok(\"abc\".to_string()); assert_matches!(c, Ok(x) | Err(x) if x.len() debug_assert! debug_assert_eq! debug_assert_ne! 只有在debug版本里才使能debug_assert!(true); matches!let foo = 'f'; assert!(matches!(foo, 'A'..='Z' | 'a'..='z')); let bar = Some(4); assert!(matches!(bar, Some(x) if x > 2)); ?和r#try!try!是个宏, 但需要用raw方式来调用, r#try. 现在可以用?来代替enum MyError { FileWriteError } impl From for MyError { fn from(e: io::Error) -> MyError { MyError::FileWriteError } } // The preferred method of quick returning Errors fn write_to_file_question() -> Result { let mut file = File::create(\"my_best_friends.txt\")?; file.write_all(b\"This is a list of my best friends.\")?; Ok(()) } // The previous method of quick returning Errors fn write_to_file_using_try() -> Result { let mut file = r#try!(File::create(\"my_best_friends.txt\")); r#try!(file.write_all(b\"This is a list of my best friends.\")); Ok(()) } write! writeln! 写入bufferfn main() -> std::io::Result { let mut w = Vec::new(); write!(&mut w, \"test\")?; write!(&mut w, \"formatted {}\", \"arguments\")?; assert_eq!(w, b\"testformatted arguments\"); Ok(()) } let mut s = String::new(); writeln!(&mut s, \"{} {}\", \"abc\", 123)?; // uses fmt::Write::write_fmt unreachable! unimplemented! todo! 代码实现阶段用到的宏 由编译器实现的builtin宏 compile_error!#[cfg(not(any(feature = \"foo\", feature = \"bar\")))] compile_error!(\"Either feature \\\"foo\\\" or \\\"bar\\\" must be enabled for this crate.\"); format_args! const_format_args! format_args_nl! 格式化宏, 用于format!宏 env! option_env! 在编译时获取env, 注意不是运行时let path: &'static str = env!(\"PATH\"); let key: Option = option_env!(\"SECRET_KEY\"); concat_idents! 多个标识符连起来成为一个fn foobar() -> u32 { 23 } let f = concat_idents!(foo, bar); println!(\"{}\", f()); concat_bytes! 连接字符 concat!let s = concat!(\"test\", 10, 'b', true); assert_eq!(s, \"test10btrue\"); line! column! file! 编译的文件, 行号等; module_path! module路径let current_line = line!(); println!(\"defined on line: {}\", current_line); stringify!let one_plus_one = stringify!(1 + 1); assert_eq!(one_plus_one, \"1 + 1\"); include_str! 编译时从文件读入string; include_bytes! 编译时从文件读入bytes; 文件是相对当前编译文件的路径.//spanish.in里面是adiós let my_str = include_str!(\"spanish.in\"); assert_eq!(my_str, \"adiós\\n\"); cfg!let my_directory = if cfg!(windows) { \"windows-specific-directory\" } else { \"unix-directory\" }; include! 把文件导入进来按表达式来编译 assert! derive! test bench global_allocator cfg_accessible trait Iterator 看起来只要实现了next就是个Iterator了... 其他都有默认实现, 真方便 pub trait Iterator { type Item; //需要用户实现的: fn next(&mut self) -> Option; //有默认实现的: fn size_hint(&self) -> (usize, Option) //默认返回0, 用户要自己实现更适合自己的方法. fn count(self) -> usize fn last(self) -> Option fn advance_by(&mut self, n: usize) -> Result fn nth(&mut self, n: usize) -> Option fn step_by(self, step: usize) -> StepBy fn chain(self, other: U) -> Chain fn zip(self, other: U) -> Zip fn intersperse(self, separator: Self::Item) -> Intersperse fn intersperse_with(self, separator: G) -> IntersperseWith fn map(self, f: F) -> Map fn for_each(self, f: F) fn filter(self, predicate: P) -> Filter fn filter_map(self, f: F) -> FilterMap fn enumerate(self) -> Enumerate //还是返回一个Iterator, 元素是(index, value) fn peekable(self) -> Peekable fn skip_while(self, predicate: P) -> SkipWhile fn take_while(self, predicate: P) -> TakeWhile fn map_while(self, predicate: P) -> MapWhile fn skip(self, n: usize) -> Skip fn take(self, n: usize) -> Take fn scan(self, initial_state: St, f: F) -> Scan fn flat_map(self, f: F) -> FlatMap fn flatten(self) -> Flatten fn fuse(self) -> Fuse fn inspect(self, f: F) -> Inspect fn by_ref(&mut self) -> &mut Self fn collect>(self) -> B fn try_collect(&mut self) -> ChangeOutputType fn partition(self, f: F) -> (B, B) fn partition_in_place(mut self, ref mut predicate: P) -> usize fn is_partitioned(mut self, mut predicate: P) -> bool fn try_fold(&mut self, init: B, mut f: F) -> R fn try_for_each(&mut self, f: F) -> R fn fold(mut self, init: B, mut f: F) -> B fn reduce(mut self, f: F) -> Option fn try_reduce(&mut self, f: F) -> ChangeOutputType> fn all(&mut self, f: F) -> bool fn any(&mut self, f: F) -> bool fn find(&mut self, predicate: P) -> Option fn find_map(&mut self, f: F) -> Option fn try_find(&mut self, f: F) -> ChangeOutputType> fn position(&mut self, predicate: P) -> Option fn rposition(&mut self, predicate: P) -> Option fn max(self) -> Option fn min(self) -> Option fn max_by_key(self, f: F) -> Option fn max_by(self, compare: F) -> Option fn min_by_key(self, f: F) -> Option fn min_by(self, compare: F) -> Option fn rev(self) -> Rev fn unzip(self) -> (FromA, FromB) fn copied(self) -> Copied fn cloned(self) -> Cloned fn cycle(self) -> Cycle fn sum(self) -> S fn product(self) -> P fn cmp(self, other: I) -> Ordering fn cmp_by(mut self, other: I, mut cmp: F) -> Ordering fn partial_cmp(self, other: I) -> Option fn partial_cmp_by(mut self, other: I, mut partial_cmp: F) -> Option fn eq(self, other: I) -> bool fn eq_by(mut self, other: I, mut eq: F) -> bool fn ne(self, other: I) -> bool fn lt(self, other: I) -> bool fn le(self, other: I) -> bool fn gt(self, other: I) -> bool fn ge(self, other: I) -> bool fn is_sorted(self) -> bool fn is_sorted_by(mut self, compare: F) -> bool fn is_sorted_by_key(self, f: F) -> bool } 比较常用的Iterator方法 filter: 对Self的关联类型的借用&Self::Item调用闭包函数, 返回另一个Iterator map: 也是返回另一个Iterator 最后collect: 把Iterator\"重组\"成一个collect对象. collect filter在前面讲过. 这里看一下collect: collect基础用法如下: let a = [1, 2, 3]; let doubled: Vec = a.iter() .map(|&x| x * 2) .collect(); assert_eq!(vec![2, 4, 6], doubled); 注意, 目标变量doubled需要显式指定类型, 要不然collect不知道你要\"重组\"成什么样的collect对象. 常用的就是collect成Vec. 下面是Iterator的默认collect实现: //这里面很晦涩, collect返回一个泛型B, 这个B是要满足`FromIterator`即Iterator的关联类型实例化的`FromIterator` //这个B是编译器自己推断的, 或者根据左值(比如上面的let doubled: Vec), 或者用户指定, 比如更上面的.collect::>(); fn collect>(self) -> B where Self: Sized, { //这里trait名称::trait函数这个调用方式看起来无比奇怪, 有点自己调用自己的意思 //但我理解下面的FromIterator已经是个具体的类型, 由编译器自动推导出来的: //比如上面的左值let doubled: Vec, 到这里就应该是调用Vec的from_iter FromIterator::from_iter(self) } //这里是说要想满足FromIterator这个trait, 就必须实现from_iter这个函数; //而from_iter这个函数入参是个满足泛型T约束的iter, 这个T需要是个IntoIterator(一般的容器类型(collect类型)都实现了IntoIterator) pub trait FromIterator: Sized { fn from_iter>(iter: T) -> Self; } 到这里就清楚了, 对左值let doubled: Vec的用.collect方法生成的情况, 最后调用的是Vec的from_iter()函数 impl FromIterator for Vec { #[inline] fn from_iter>(iter: I) -> Vec { >::from_iter(iter.into_iter()) } } 这里把Self转换成了SpecFromIter, 实例化后是SpecFromIter 而这里的I::IntoIter其实就是变量a的类型vec的IntoIter SpecFromIter说的是要干一件从IntoIter I到Self的事. pub(super) trait SpecFromIter { fn from_iter(iter: I) -> Self; } impl SpecFromIter for Vec where I: Iterator, { default fn from_iter(iterator: I) -> Self { SpecFromIterNested::from_iter(iterator) } } 最后调用到: pub(super) trait SpecFromIterNested { fn from_iter(iter: I) -> Self; } impl SpecFromIterNested for Vec where I: Iterator, { default fn from_iter(mut iterator: I) -> Self { // Unroll the first iteration, as the vector is going to be // expanded on this iteration in every case when the iterable is not // empty, but the loop in extend_desugared() is not going to see the // vector being full in the few subsequent loop iterations. // So we get better branch prediction. let mut vector = match iterator.next() { None => return Vec::new(), Some(element) => { let (lower, _) = iterator.size_hint(); let initial_capacity = cmp::max(RawVec::::MIN_NON_ZERO_CAP, lower.saturating_add(1)); let mut vector = Vec::with_capacity(initial_capacity); unsafe { // SAFETY: We requested capacity at least 1 ptr::write(vector.as_mut_ptr(), element); vector.set_len(1); } vector } }; // must delegate to spec_extend() since extend() itself delegates // to spec_from for empty Vecs as SpecExtend>::spec_extend(&mut vector, iterator); vector } } IntoIterator IntoIterator的关联类型type IntoIter是个trait, 即这个关联类型的具体类型要符合Iterator约束. pub trait IntoIterator { /// The type of the elements being iterated over. type Item; /// Which kind of iterator are we turning this into? type IntoIter: Iterator; fn into_iter(self) -> Self::IntoIter; } 自己实现IntoIterator // A sample collection, that's just a wrapper over Vec #[derive(Debug)] struct MyCollection(Vec); // Let's give it some methods so we can create one and add things // to it. impl MyCollection { fn new() -> MyCollection { MyCollection(Vec::new()) } fn add(&mut self, elem: i32) { self.0.push(elem); } } // and we'll implement IntoIterator impl IntoIterator for MyCollection { type Item = i32; type IntoIter = std::vec::IntoIter; //注意这里实例化了IntoIter类型 fn into_iter(self) -> Self::IntoIter { self.0.into_iter() } } // Now we can make a new collection... let mut c = MyCollection::new(); // ... add some stuff to it ... c.add(0); c.add(1); c.add(2); // ... and then turn it into an Iterator: for (i, n) in c.into_iter().enumerate() { assert_eq!(i as i32, n); } 比如BTreeMap就实现了into_iter的方法 impl IntoIterator for &'a BTreeMap { type Item = (&'a K, &'a V); type IntoIter = Iter; fn into_iter(self) -> Iter { self.iter() } } 可以看到BTreeMap的into_iter其实就是self.iter(), 反回的都是Iter这个结构体(这个结构体实现了Iterator). 数组泛型的方法impl [T] 数组泛型实现了多种方法, 比如join. impl [T] { pub fn sort(&mut self) where T: Ord, pub fn sort_by(&mut self, mut compare: F) where F: FnMut(&T, &T) -> Ordering, pub fn sort_by_key(&mut self, mut f: F) where F: FnMut(&T) -> K, K: Ord, pub fn sort_by_cached_key(&mut self, f: F) where F: FnMut(&T) -> K, K: Ord, pub fn to_vec(&self) -> Vec where T: Clone, pub fn to_vec_in(&self, alloc: A) -> Vec where T: Clone, pub fn into_vec(self: Box) -> Vec pub fn repeat(&self, n: usize) -> Vec where T: Copy, pub fn concat(&self) -> >::Output where Self: Concat, pub fn join(&self, sep: Separator) -> >::Output where Self: Join, //这里首先约束Self是Join { Join::join(self, sep) //这里调用了约束的join函数. } pub fn connect(&self, sep: Separator) -> >::Output where Self: Join, } 但因为T是泛型, 要实现有用的方法, 比如对T进行约束. 比如join就要求[T]满足:Self: Join pub trait Join { /// The resulting type after concatenation type Output; /// Implementation of [`[T]::join`](slice::join) fn join(slice: &Self, sep: Separator) -> Self::Output; } 注意上面的Separator是泛型的类型指示符, 指代具体类型. 上面的例子非常有趣, 泛型[T]实现了join方法, 而这个join方法看起来又调用了\"Self\"的join. 是Self有两套join实现吗? -- 是. [T]有join方法, 没毛病. 而[V]实现了Join trait, 也实现了join函数. 如下: impl> Join for [V] { type Output = Vec; fn join(slice: &Self, sep: &T) -> Vec { let mut iter = slice.iter(); let first = match iter.next() { Some(first) => first, None => return vec![], }; let size = slice.iter().map(|v| v.borrow().len()).sum::() + slice.len() - 1; let mut result = Vec::with_capacity(size); result.extend_from_slice(first.borrow()); for v in iter { result.push(sep.clone()); result.extend_from_slice(v.borrow()) } result } } 这是两套语义, rust并没有因为看见Self有join方法, 就像go一样, 自动推断Self实现了Join trait; 相反的, 用户需要明确声明, 我实现了Join trait(for 关键词). 这种情况下, 会同时存在两套join. 在本例中, 前者还调用了后者. 这不是多此一举吗? 一个同名的join调来调去有意思吗? --不是. 有意思. 因为Separator不同, 实际调用的Join trait也不同. 比如如果Separator是&T, 就需要实现Join的trait. 代码见上面 如果Separator是&[T], 就需要实现Join的trait, 如下: impl> Join for [V] { type Output = Vec; fn join(slice: &Self, sep: &[T]) -> Vec { let mut iter = slice.iter(); let first = match iter.next() { Some(first) => first, None => return vec![], }; let size = slice.iter().map(|v| v.borrow().len()).sum::() + sep.len() * (slice.len() - 1); let mut result = Vec::with_capacity(size); result.extend_from_slice(first.borrow()); for v in iter { result.extend_from_slice(sep); result.extend_from_slice(v.borrow()) } result } } 比如字符串的: impl> Join for [S] { type Output = String; fn join(slice: &Self, sep: &str) -> String { unsafe { String::from_utf8_unchecked(join_generic_copy(slice, sep.as_bytes())) } } } Vec Vec结构体: pub struct Vec { buf: RawVec, len: usize, } 方法: impl Vec { pub const fn new() -> Self pub fn with_capacity(capacity: usize) -> Self pub unsafe fn from_raw_parts(ptr: *mut T, length: usize, capacity: usize) -> Self } 带allocator的Vec有更多的方法: impl Vec { pub const fn new_in(alloc: A) -> Self pub fn with_capacity_in(capacity: usize, alloc: A) -> Self pub fn capacity(&self) -> usize pub fn reserve(&mut self, additional: usize) pub fn try_reserve(&mut self, additional: usize) -> Result pub fn shrink_to_fit(&mut self) pub fn shrink_to(&mut self, min_capacity: usize) pub fn into_boxed_slice(mut self) -> Box pub fn truncate(&mut self, len: usize) pub fn as_slice(&self) -> &[T] pub fn as_mut_slice(&mut self) -> &mut [T] pub fn as_ptr(&self) -> *const T pub fn allocator(&self) -> &A pub unsafe fn set_len(&mut self, new_len: usize) pub fn swap_remove(&mut self, index: usize) -> T pub fn insert(&mut self, index: usize, element: T) pub fn remove(&mut self, index: usize) -> T pub fn retain(&mut self, mut f: F) pub fn dedup_by(&mut self, mut same_bucket: F) pub fn push(&mut self, value: T) pub fn pop(&mut self) -> Option pub fn append(&mut self, other: &mut Self) pub fn drain(&mut self, range: R) -> Drain //返回一个iterator, 包括range内的所有元素 pub fn clear(&mut self) //移出所有元素 pub fn len(&self) -> usize pub fn is_empty(&self) -> bool pub fn split_off(&mut self, at: usize) -> Self pub fn resize_with(&mut self, new_len: usize, f: F) pub fn leak(self) -> &'a mut [T] } 更具化的泛型 impl Vec { pub fn resize(&mut self, new_len: usize, value: T) pub fn extend_from_slice(&mut self, other: &[T]) pub fn extend_from_within(&mut self, src: R) } Vec实现了解引用 impl ops::Deref for Vec { type Target = [T]; fn deref(&self) -> &[T] { unsafe { slice::from_raw_parts(self.as_ptr(), self.len) } } } Option Option的方法如下: impl Option { pub const fn is_some(&self) -> bool pub fn is_some_with(&self, f: impl FnOnce(&T) -> bool) -> bool pub const fn is_none(&self) -> bool pub const fn as_ref(&self) -> Option pub const fn as_mut(&mut self) -> Option pub const fn as_pin_ref(self: Pin) -> Option> pub const fn as_pin_mut(self: Pin) -> Option> pub const fn expect(self, msg: &str) -> T pub const fn unwrap(self) -> T pub const fn unwrap_or(self, default: T) -> T pub const fn map(self, f: F) -> Option pub const fn filter(self, predicate: P) -> Self pub const fn inspect(self, f: F) -> Self pub const fn ok_or(self, err: E) -> Result pub const fn iter(&self) -> Iter pub const fn and_then(self, f: F) -> Option pub const fn and(self, optb: Option) -> Option pub const fn or(self, optb: Option) -> Option pub const fn or_else(self, f: F) -> Option pub const fn xor(self, optb: Option) -> Option pub const fn insert(&mut self, value: T) -> &mut T pub const fn get_or_insert(&mut self, value: T) -> &mut T pub const fn take(&mut self) -> Option pub const fn replace(&mut self, value: T) -> Option pub const fn contains(&self, x: &U) -> bool pub const fn zip(self, other: Option) -> Option } Result Result是经常用的rust抽象, 用于返回值的处理, 很优雅. 代码在lib/rustlib/src/rust/library/core/src/result.rs #[derive(Copy, PartialEq, PartialOrd, Eq, Ord, Debug, Hash)] pub enum Result { /// Contains the success value #[lang = \"Ok\"] Ok(#[stable(feature = \"rust1\", since = \"1.0.0\")] T), /// Contains the error value #[lang = \"Err\"] Err(#[stable(feature = \"rust1\", since = \"1.0.0\")] E), } Result的方法: impl Result { pub const fn is_ok(&self) -> bool /// let x: Result = Ok(2); /// assert_eq!(x.is_ok_with(|&x| x > 1), true); /// /// let x: Result = Ok(0); /// assert_eq!(x.is_ok_with(|&x| x > 1), false); /// /// let x: Result = Err(\"hey\"); /// assert_eq!(x.is_ok_with(|&x| x > 1), false); pub fn is_ok_with(&self, f: impl FnOnce(&T) -> bool) -> bool pub const fn is_err(&self) -> bool /// let x: Result = Err(Error::new(ErrorKind::NotFound, \"!\")); /// assert_eq!(x.is_err_with(|x| x.kind() == ErrorKind::NotFound), true); /// /// let x: Result = Err(Error::new(ErrorKind::PermissionDenied, \"!\")); /// assert_eq!(x.is_err_with(|x| x.kind() == ErrorKind::NotFound), false); /// /// let x: Result = Ok(123); /// assert_eq!(x.is_err_with(|x| x.kind() == ErrorKind::NotFound), false); pub fn is_err_with(&self, f: impl FnOnce(&E) -> bool) -> bool pub fn ok(self) -> Option //把Result转换为Option pub fn err(self) -> Option pub const fn as_ref(&self) -> Result pub const fn as_mut(&mut self) -> Result //调用F把Result转为Result pub fn map U>(self, op: F) -> Result pub fn map_or U>(self, default: U, f: F) -> U pub fn map_or_else U, F: FnOnce(T) -> U>(self, default: D, f: F) -> U pub fn map_err F>(self, op: O) -> Result pub fn inspect(self, f: F) -> Self pub fn inspect_err(self, f: F) -> Self /// let x: Result = Ok(\"hello\".to_string()); /// let y: Result = Ok(\"hello\"); /// assert_eq!(x.as_deref(), y); /// /// let x: Result = Err(42); /// let y: Result = Err(&42); pub fn as_deref(&self) -> Result where T: Deref, pub fn iter(&self) -> Iter pub fn iter_mut(&mut self) -> IterMut //返回Ok里面的T, 如果Error就panic pub fn expect(self, msg: &str) -> T where E: fmt::Debug, // unwrap也返回T, 也可能panic, 但似乎就没有panic message pub fn unwrap(self) -> T where E: fmt::Debug, // 也是unwrap, 但不panic, 不Ok就返回default pub fn unwrap_or_default(self) -> T where T: Default, //unwrap不panic, 不ok则返回指定的default pub fn unwrap_or(self, default: T) -> T pub fn unwrap_or_else T>(self, op: F) -> T // 实际上是unwrap E pub fn expect_err(self, msg: &str) -> E where T: fmt::Debug, pub fn unwrap_err(self) -> E where T: fmt::Debug, pub fn into_ok(self) -> T where E: Into, pub fn into_err(self) -> E where T: Into, // and表示检测x, y中只要有Error, 就返回Error /// let x: Result = Ok(2); /// let y: Result = Err(\"late error\"); /// assert_eq!(x.and(y), Err(\"late error\")); pub fn and(self, res: Result) -> Result /// assert_eq!(Ok(2).and_then(sq_then_to_string), Ok(4.to_string())); /// assert_eq!(Err(\"not a number\").and_then(sq_then_to_string), Err(\"not a number\")); pub fn and_then Result>(self, op: F) -> Result pub fn or(self, res: Result) -> Result pub fn or_else Result>(self, op: O) -> Result /// let x: Result = Ok(2); /// assert_eq!(x.contains(&2), true); /// /// let x: Result = Ok(3); /// assert_eq!(x.contains(&2), false); /// /// let x: Result = Err(\"Some error message\"); /// assert_eq!(x.contains(&2), false); pub fn contains(&self, x: &U) -> bool where U: PartialEq, } 注: const fn表示这个fn可以用在const上下文中 Result的方法 Result也能调用Result的方法, 比如下面copied函数中, 直接用了self.map, 因为Result是个范围很广的泛型, 自然也就包括了Result, 这里要把T看成是&T' impl Result { pub fn copied(self) -> Result where T: Copy, { self.map(|&t| t) //注意这里, map的F是FnOnce(T), 是针对Result来说的; 这里应该传入\"&T\", 那么形式上&t就是T, 然后返回t就是返回T. 看起来挺难理解的... } pub fn cloned(self) -> Result where T: Clone, { self.map(|t| t.clone()) //这里就没有那么绕, t就是&T } } 其他Result impl Result impl Result, E> impl Result, E> impl Result Result实现了如下的trait impl Clone for Result impl IntoIterator for Result impl IntoIterator for &'a Result impl IntoIterator for &'a mut Result env // 这个就是golang的os.args let args: Vec = env::args().collect(); 取消impl trait 就是取消 取消 取消! impl !Send for Args {} impl !Sync for Args {} 文件 lib/rustlib/src/rust/library/std/src/fs.rs 使用举例 写文件 use std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut file = File::create(\"foo.txt\")?; file.write_all(b\"Hello, world!\")?; Ok(()) } 读文件到String use std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut file = File::open(\"foo.txt\")?; let mut contents = String::new(); file.read_to_string(&mut contents)?; assert_eq!(contents, \"Hello, world!\"); Ok(()) } 注意这里, file.read_to_string(), file对象impl Read, 有read_to_string()方法, 就在本文件; 而vscode点击进去, 却是lib/rustlib/src/rust/library/std/src/io/mod.rs中io:Read这个trait的默认实现. 更有效率的读文件 use std::fs::File; use std::io::BufReader; use std::io::prelude::*; fn main() -> std::io::Result { let file = File::open(\"foo.txt\")?; let mut buf_reader = BufReader::new(file); let mut contents = String::new(); buf_reader.read_to_string(&mut contents)?; assert_eq!(contents, \"Hello, world!\"); Ok(()) } 不同选项open let file = OpenOptions::new() .read(true) .write(true) .create(true) .open(\"foo.txt\"); &File也能modify 文件 Note that, although read and write methods require a &mut File, because of the interfaces for [Read] and [Write], the holder of a &File can still modify the file, either through methods that take &File or by retrieving the underlying OS object and modifying the file that way. Additionally, many operating systems allow concurrent modification of files by different processes. Avoid assuming that holding a &File means that the file will not change. 这里是说read和write方法都要求&mut File, 但实际上, &File的持有者也可以修改文件. 这里提醒大家不要认为持有&File的人就\"没危险\"了, 他们也可以修改你的文件, 因为文件系统允许多进程打开一个文件. File对象 pub struct File { inner: fs_imp::File, } 还有几个\"辅助\"元组对象定义: pub struct Metadata(fs_imp::FileAttr); pub struct ReadDir(fs_imp::ReadDir); pub struct DirEntry(fs_imp::DirEntry); pub struct OpenOptions(fs_imp::OpenOptions); pub struct Permissions(fs_imp::FilePermissions); pub struct FileType(fs_imp::FileType); pub struct DirBuilder { inner: fs_imp::DirBuilder, recursive: bool, } 常用函数 读所有文件内容到Vec pub fn read>(path: P) -> io::Result>use std::fs; use std::net::SocketAddr; fn main() -> Result> { let foo: SocketAddr = String::from_utf8_lossy(&fs::read(\"address.txt\")?).parse()?; Ok(()) } 读所有文件内容到String pub fn read_to_string>(path: P) -> io::Resultuse std::fs; use std::net::SocketAddr; use std::error::Error; fn main() -> Result> { let foo: SocketAddr = fs::read_to_string(\"address.txt\")?.parse()?; Ok(()) } 简单的写slice到文件 pub fn write, C: AsRef>(path: P, contents: C) -> io::Resultuse std::fs; fn main() -> std::io::Result { fs::write(\"foo.txt\", b\"Lorem ipsum\")?; //&str可以被认为是AsRef fs::write(\"bar.txt\", \"dolor sit\")?; Ok(()) } remove文件 pub fn remove_file>(path: P) -> io::Resultuse std::fs; fn main() -> std::io::Result { fs::remove_file(\"a.txt\")?; Ok(()) } metadatafn main() -> std::io::Result { let attr = fs::metadata(\"/some/file/path.txt\")?; // inspect attr ... Ok(()) } symlink_metadata rename copy hard_link soft_link read_link canonicalize 可能和abs path差不多 create_dir create_dir_all remove_dir remove_dir_all read_dir 例子1use std::io; use std::fs::{self, DirEntry}; use std::path::Path; // one possible implementation of walking a directory only visiting files fn visit_dirs(dir: &Path, cb: &dyn Fn(&DirEntry)) -> io::Result { if dir.is_dir() { for entry in fs::read_dir(dir)? { let entry = entry?; let path = entry.path(); if path.is_dir() { visit_dirs(&path, cb)?; } else { cb(&entry); } } } Ok(()) } 例子2use std::{fs, io}; fn main() -> io::Result { let mut entries = fs::read_dir(\".\")? .map(|res| res.map(|e| e.path())) .collect::, io::Error>>()?; // The order in which `read_dir` returns entries is not guaranteed. If reproducible // ordering is required the entries should be explicitly sorted. entries.sort(); // The entries have now been sorted by their path. Ok(()) } set_permissionsuse std::fs; fn main() -> std::io::Result { let mut perms = fs::metadata(\"foo.txt\")?.permissions(); perms.set_readonly(true); fs::set_permissions(\"foo.txt\", perms)?; Ok(()) } File的方法 impl File { } open pub fn open>(path: P) -> io::Resultuse std::fs::File; fn main() -> std::io::Result { let mut f = File::open(\"foo.txt\")?; Ok(()) } create pub fn create>(path: P) -> io::Resultuse std::fs::File; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; Ok(()) } options pub fn options() -> OpenOptionsuse std::fs::File; fn main() -> std::io::Result { let mut f = File::options().append(true).open(\"example.log\")?; Ok(()) } sync_all 就是fsync pub fn sync_all(&self) -> io::Resultuse std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; f.write_all(b\"Hello, world!\")?; f.sync_all()?; Ok(()) } sync_data 比sync_all少一些disk操作 pub fn sync_data(&self) -> io::Resultuse std::fs::File; use std::io::prelude::*; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; f.write_all(b\"Hello, world!\")?; f.sync_data()?; Ok(()) } set_len 设文件大小, 若原本size小, 就shrink文件到新size; 如果原size小, 则剩下的都填0use std::fs::File; fn main() -> std::io::Result { let mut f = File::create(\"foo.txt\")?; f.set_len(10)?; Ok(()) } metadata try_clone set_permissions 其他impl的trait impl AsInner for File impl FromInner for File impl IntoInner for File impl fmt::Debug for File 根据注释, 还实现了比如AsFd等trait. 但不知道藏在哪里实现的??? // In addition to the `impl`s here, `File` also has `impl`s for // `AsFd`/`From`/`Into` and // `AsRawFd`/`IntoRawFd`/`FromRawFd`, on Unix and WASI, and // `AsHandle`/`From`/`Into` and // `AsRawHandle`/`IntoRawHandle`/`FromRawHandle` on Windows. 实现Read trait pub struct File { inner: fs_imp::File, } 这里显得很啰嗦, 基本都是调用inner的对应函数. 因为File包括了inner. 因为rust没有继承就要再写一遍wrapper吗??? impl Read for File { fn read(&mut self, buf: &mut [u8]) -> io::Result { self.inner.read(buf) } fn read_vectored(&mut self, bufs: &mut [IoSliceMut]) -> io::Result { self.inner.read_vectored(bufs) } fn read_buf(&mut self, buf: &mut ReadBuf) -> io::Result { self.inner.read_buf(buf) } #[inline] fn is_read_vectored(&self) -> bool { self.inner.is_read_vectored() } // Reserves space in the buffer based on the file size when available. fn read_to_end(&mut self, buf: &mut Vec) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_end(self, buf) } // Reserves space in the buffer based on the file size when available. fn read_to_string(&mut self, buf: &mut String) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_string(self, buf) } } 实现Write trait impl Write for File { fn write(&mut self, buf: &[u8]) -> io::Result { self.inner.write(buf) } fn write_vectored(&mut self, bufs: &[IoSlice]) -> io::Result { self.inner.write_vectored(bufs) } #[inline] fn is_write_vectored(&self) -> bool { self.inner.is_write_vectored() } fn flush(&mut self) -> io::Result { self.inner.flush() } } 实现Seek trait impl Seek for File { fn seek(&mut self, pos: SeekFrom) -> io::Result { self.inner.seek(pos) } } Read Write Seek for &File又来一遍!!!!! 有意思吗? impl Read for &File { fn read(&mut self, buf: &mut [u8]) -> io::Result { self.inner.read(buf) } fn read_buf(&mut self, buf: &mut ReadBuf) -> io::Result { self.inner.read_buf(buf) } fn read_vectored(&mut self, bufs: &mut [IoSliceMut]) -> io::Result { self.inner.read_vectored(bufs) } #[inline] fn is_read_vectored(&self) -> bool { self.inner.is_read_vectored() } // Reserves space in the buffer based on the file size when available. fn read_to_end(&mut self, buf: &mut Vec) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_end(self, buf) } // Reserves space in the buffer based on the file size when available. fn read_to_string(&mut self, buf: &mut String) -> io::Result { buf.reserve(buffer_capacity_required(self)); io::default_read_to_string(self, buf) } } open最后调用 use crate::sys::fs as fs_imp; fn _open(&self, path: &Path) -> io::Result { fs_imp::File::open(path, &self.0).map(|inner| File { inner }) } fs_imp::File::open代码在lib/rustlib/src/rust/library/std/src/sys/unix/fs.rs 里面调用了很多libc的函数. IO 常用函数 pub fn read_to_string(mut reader: R) -> Result //这个是内部使用的函数 fn read_until(r: &mut R, delim: u8, buf: &mut Vec) -> Result Read trait pub trait Read { /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = [0; 10]; /// /// // read up to 10 bytes /// let n = f.read(&mut buffer[..])?; /// /// println!(\"The bytes: {:?}\", &buffer[..n]); /// Ok(()) /// } //也是传入一个[u8]的数组, 返回大小 fn read(&mut self, buf: &mut [u8]) -> Result; //vector方式读 fn read_vectored(&mut self, bufs: &mut [IoSliceMut]) -> Result { default_read_vectored(|b| self.read(b), bufs) } //有没有vector读, 默认false fn is_read_vectored(&self) -> bool { false } /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = Vec::new(); /// /// // read the whole file /// f.read_to_end(&mut buffer)?; /// Ok(()) /// } //读完所有byte fn read_to_end(&mut self, buf: &mut Vec) -> Result { default_read_to_end(self, buf) } /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = String::new(); /// /// f.read_to_string(&mut buffer)?; /// Ok(()) /// } //读完所有string fn read_to_string(&mut self, buf: &mut String) -> Result { default_read_to_string(self, buf) } /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = [0; 10]; /// /// // read exactly 10 bytes /// f.read_exact(&mut buffer)?; /// Ok(()) /// } //一直读到size fn read_exact(&mut self, buf: &mut [u8]) -> Result { default_read_exact(self, buf) } //read到ReadBuf fn read_buf(&mut self, buf: &mut ReadBuf) -> Result { default_read_buf(|b| self.read(b), buf) } fn read_buf_exact(&mut self, buf: &mut ReadBuf) -> Result //借用 fn by_ref(&mut self) -> &mut Self //把这个Read转换为byte iterator fn bytes(self) -> Bytes /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f1 = File::open(\"foo.txt\")?; /// let mut f2 = File::open(\"bar.txt\")?; /// /// let mut handle = f1.chain(f2); /// let mut buffer = String::new(); /// /// // read the value into a String. We could use any Read method here, /// // this is just one example. /// handle.read_to_string(&mut buffer)?; /// Ok(()) /// } //和next Read成链, 先读Self, 接着读next fn chain(self, next: R) -> Chain /// use std::io; /// use std::io::prelude::*; /// use std::fs::File; /// /// fn main() -> io::Result { /// let mut f = File::open(\"foo.txt\")?; /// let mut buffer = [0; 5]; /// /// // read at most five bytes /// let mut handle = f.take(5); /// /// handle.read(&mut buffer)?; /// Ok(()) /// } //返回一个新的Read, 但只读limit字节 fn take(self, limit: u64) -> Take } Write trait pub trait Write { //很自然的, 这里的buf是个借用 //和read一样, write也可以部分写 fn write(&mut self, buf: &[u8]) -> Result; fn write_vectored(&mut self, bufs: &[IoSlice]) -> Result fn is_write_vectored(&self) -> bool //这个flush是write独有的 fn flush(&mut self) -> Result; //全写 fn write_all(&mut self, mut buf: &[u8]) -> Result fn write_all_vectored(&mut self, mut bufs: &mut [IoSlice]) -> Result //写格式化string到Write fn write_fmt(&mut self, fmt: fmt::Arguments) -> Result fn by_ref(&mut self) -> &mut Self } Seek trait pub trait Seek { fn seek(&mut self, pos: SeekFrom) -> Result; //从头开始 fn rewind(&mut self) -> Result //返回这个stream的字节数 fn stream_len(&mut self) -> Result //stream的当前位置 fn stream_position(&mut self) -> Result } BufRead是Read的派生trait BufRead自带内部buffer 比如stdin.lock()就实现了BufRead use std::io; use std::io::prelude::*; let stdin = io::stdin(); for line in stdin.lock().lines() { println!(\"{}\", line.unwrap()); } 比如可以用BufReader::new(r)把Reader r转换为BufReader use std::io::{self, BufReader}; use std::io::prelude::*; use std::fs::File; fn main() -> io::Result { let f = File::open(\"foo.txt\")?; let f = BufReader::new(f); for line in f.lines() { println!(\"{}\", line.unwrap()); } Ok(()) } 下面是BufRead的定义: pub trait BufRead: Read { //读出内部buffer, 并从内部reader填入新数据 fn fill_buf(&mut self) -> Result; //amt数量的字节已经被consume了 fn consume(&mut self, amt: usize); fn has_data_left(&mut self) -> Result fn read_until(&mut self, byte: u8, buf: &mut Vec) -> Result fn read_line(&mut self, buf: &mut String) -> Result //返回一个按照分隔符byte分割的iterator fn split(self, byte: u8) -> Split //返回按行分隔的iterator fn lines(self) -> Lines } "},"notes/rust_代码小段.html":{"url":"notes/rust_代码小段.html","title":"代码小段","keywords":"","body":" micro_http channel in channel epoll 反序列化到结构体 match语句块做为值 命令行参数拿到文件名并读出其中字符串 从Vec到Vec 从&str返回任意类型 map_err(Error::Arch)? json文件 compile 序列化 Err的使用方法 micro_http 用的是 micro_http = { git = \"https://github.com/firecracker-microvm/micro-http\", branch = \"main\" } // 起http线程, 用的是micro_http的库 api::start_http_path_thread() let server = HttpServer::new_from_fd() start_http_thread(server) hread::Builder::new() //新线程 loop { match server.requests() { Ok(request_vec) => { for server_request in request_vec { server.respond(server_request.process( |request| { handle_http_request(request, &api_notifier, &api_sender) } )) } } } } 处理就是从全局url路由表中get route 即HTTP_ROUTES.routes.get(&path), 然后调用route的handle_request函数, 即调用route.handle_request(): fn handle_http_request( request: &Request, api_notifier: &EventFd, api_sender: &Sender, ) -> Response { let path = request.uri().get_abs_path().to_string(); let mut response = match HTTP_ROUTES.routes.get(&path) { Some(route) => match api_notifier.try_clone() { Ok(notifier) => route.handle_request(request, notifier, api_sender.clone()), Err(_) => error_response( HttpError::InternalServerError, StatusCode::InternalServerError, ), }, None => error_response(HttpError::NotFound, StatusCode::NotFound), }; response.set_server(\"Cloud Hypervisor API\"); response.set_content_type(MediaType::ApplicationJson); response } 全局变量route是提前静态注册好的: HTTP_ROUTES是个全局变量 lazy_static! { /// HTTP_ROUTES contain all the cloud-hypervisor HTTP routes. pub static ref HTTP_ROUTES: HttpRoutes = { let mut r = HttpRoutes { routes: HashMap::new(), }; r.routes.insert(endpoint!(\"/vm.add-device\"), Box::new(VmActionHandler::new(VmAction::AddDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-user-device\"), Box::new(VmActionHandler::new(VmAction::AddUserDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-disk\"), Box::new(VmActionHandler::new(VmAction::AddDisk(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-fs\"), Box::new(VmActionHandler::new(VmAction::AddFs(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-net\"), Box::new(VmActionHandler::new(VmAction::AddNet(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-pmem\"), Box::new(VmActionHandler::new(VmAction::AddPmem(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vdpa\"), Box::new(VmActionHandler::new(VmAction::AddVdpa(Arc::default())))); r.routes.insert(endpoint!(\"/vm.add-vsock\"), Box::new(VmActionHandler::new(VmAction::AddVsock(Arc::default())))); r.routes.insert(endpoint!(\"/vm.boot\"), Box::new(VmActionHandler::new(VmAction::Boot))); r.routes.insert(endpoint!(\"/vm.counters\"), Box::new(VmActionHandler::new(VmAction::Counters))); r.routes.insert(endpoint!(\"/vm.create\"), Box::new(VmCreate {})); r.routes.insert(endpoint!(\"/vm.delete\"), Box::new(VmActionHandler::new(VmAction::Delete))); r.routes.insert(endpoint!(\"/vm.info\"), Box::new(VmInfo {})); r.routes.insert(endpoint!(\"/vm.pause\"), Box::new(VmActionHandler::new(VmAction::Pause))); r.routes.insert(endpoint!(\"/vm.power-button\"), Box::new(VmActionHandler::new(VmAction::PowerButton))); r.routes.insert(endpoint!(\"/vm.reboot\"), Box::new(VmActionHandler::new(VmAction::Reboot))); r.routes.insert(endpoint!(\"/vm.receive-migration\"), Box::new(VmActionHandler::new(VmAction::ReceiveMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.remove-device\"), Box::new(VmActionHandler::new(VmAction::RemoveDevice(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize\"), Box::new(VmActionHandler::new(VmAction::Resize(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resize-zone\"), Box::new(VmActionHandler::new(VmAction::ResizeZone(Arc::default())))); r.routes.insert(endpoint!(\"/vm.restore\"), Box::new(VmActionHandler::new(VmAction::Restore(Arc::default())))); r.routes.insert(endpoint!(\"/vm.resume\"), Box::new(VmActionHandler::new(VmAction::Resume))); r.routes.insert(endpoint!(\"/vm.send-migration\"), Box::new(VmActionHandler::new(VmAction::SendMigration(Arc::default())))); r.routes.insert(endpoint!(\"/vm.shutdown\"), Box::new(VmActionHandler::new(VmAction::Shutdown))); r.routes.insert(endpoint!(\"/vm.snapshot\"), Box::new(VmActionHandler::new(VmAction::Snapshot(Arc::default())))); r.routes.insert(endpoint!(\"/vmm.ping\"), Box::new(VmmPing {})); r.routes.insert(endpoint!(\"/vmm.shutdown\"), Box::new(VmmShutdown {})); r }; } 比如create的处理是这样的: // /api/v1/vm.create handler pub struct VmCreate {} impl EndpointHandler for VmCreate { fn handle_request( &self, req: &Request, api_notifier: EventFd, api_sender: Sender, ) -> Response { match req.method() { Method::Put => { match &req.body { Some(body) => { // Deserialize into a VmConfig let vm_config: VmConfig = match serde_json::from_slice(body.raw()) .map_err(HttpError::SerdeJsonDeserialize) { Ok(config) => config, Err(e) => return error_response(e, StatusCode::BadRequest), }; // Call vm_create() match vm_create(api_notifier, api_sender, Arc::new(Mutex::new(vm_config))) .map_err(HttpError::ApiError) { Ok(_) => Response::new(Version::Http11, StatusCode::NoContent), Err(e) => error_response(e, StatusCode::InternalServerError), } } None => Response::new(Version::Http11, StatusCode::BadRequest), } } _ => error_response(HttpError::BadRequest, StatusCode::BadRequest), } } } channel in channel 使用标准库的channel方法 pub fn channel() -> (Sender, Receiver) 发送方: // 编译器会从下文推断出这个channel传输的是ApiRequest let (api_request_sender, api_request_receiver) = std::sync::mpsc::channel(); // 构造内部channel let (response_sender, response_receiver) = std::sync::mpsc::channel(); api_request_sender .send(ApiRequest::VmCreate(config, response_sender)) .map_err(ApiError::RequestSend)?; //send也会出错, 一般都是对端链接断了 response_receiver.recv().map_err(ApiError::ResponseRecv)??; //这里有两个?, 解开2层Result, 因为外层的Result是recv加的. 上面的ApiRequest是类型下面的enum: pub enum ApiRequest { /// Create the virtual machine. This request payload is a VM configuration /// (VmConfig). /// If the VMM API server could not create the VM, it will send a VmCreate /// error back. VmCreate(Arc>, Sender), /// Boot the previously created virtual machine. /// If the VM was not previously created, the VMM API server will send a /// VmBoot error back. VmBoot(Sender), ... } ApiResponse是: /// This is the response sent by the VMM API server through the mpsc channel. pub type ApiResponse = std::result::Result; epoll 用的是rust的epoll // 新建epoll let mut epoll = EpollContext::new().map_err(Error::Epoll)?; // 底层是epoll create let epoll_fd = epoll::create(true) //增加event. 第一个参数是fd, 第二个是关联的dispatch时候用的token epoll.add_event(&exit_evt, EpollDispatch::Exit) // 底层是epoll ctl, 和c版本一样, ctl add可以给fd绑定一个data // wait let num_events = match epoll::wait(epoll_fd, -1, &mut events[..]) //处理 for event in events.iter().take(num_events) { //这个就是当时add event的时候关联的data let dispatch_event: EpollDispatch = event.data.into(); //根据dispatch_event来分发 // 这样的好处是看到这个token, 就知道是哪个事件了, 就知道用哪个fd match dispatch_event { EpollDispatch::Unknown => { } EpollDispatch::Exit => { } EpollDispatch::Api => { } } } 反序列化到结构体 VmmConfig是个结构体: /// Used for configuring a vmm from one single json passed to the Firecracker process. #[derive(Debug, Default, Deserialize, PartialEq, Serialize)] pub struct VmmConfig { #[serde(rename = \"balloon\")] balloon_device: Option, #[serde(rename = \"drives\")] block_devices: Vec, #[serde(rename = \"boot-source\")] boot_source: BootSourceConfig, #[serde(rename = \"logger\")] logger: Option, #[serde(rename = \"machine-config\")] machine_config: Option, #[serde(rename = \"metrics\")] metrics: Option, #[serde(rename = \"mmds-config\")] mmds_config: Option, #[serde(rename = \"network-interfaces\", default)] net_devices: Vec, #[serde(rename = \"vsock\")] vsock_device: Option, } 用第三方库serde_json来反序列化, 得到结构体 let vmm_config: VmmConfig = serde_json::from_slice::(config_json.as_bytes()) .map_err(Error::InvalidJson)?; from_slice::是实例化泛型函数中T的意思 pub fn from_slice(v: &'a [u8]) -> Result match语句块做为值 // let后面pattern匹配, 匹配的是match语句块的值, 即最后的(res, vmm) let (_, vmm) = match build_microvm_from_json( seccomp_filters, &mut event_manager, // Safe to unwrap since '--no-api' requires this to be set. config_json.unwrap(), instance_info, bool_timer_enabled, mmds_size_limit, metadata_json, ) { Ok((res, vmm)) => (res, vmm), Err(exit_code) => return exit_code, }; 命令行参数拿到文件名并读出其中字符串 两个map搞定: 第一个map传入的函数fs::read_to_string就已经把文件内容读出来了. 第二个map把上面的Option>转换成Option, 出错就panic let vmm_config_json = arguments .single_value(\"config-file\") .map(fs::read_to_string) .map(|x| x.expect(\"Unable to open or read from the configuration file\")); 从Vec到Vec let args = vec![\"binary-name\", \"--exec-file\", \"foo\", \"--help\"] .into_iter() .map(String::from) //这里并没有自己写闭包,而是用了现成的函数 .collect::>(); 从&str返回任意类型 比如要从字符串转换为如下enum /// Supported target architectures. #[allow(non_camel_case_types)] #[derive(Debug, PartialEq, Clone, Copy)] pub(crate) enum TargetArch { /// x86_64 arch x86_64, /// aarch64 arch aarch64, } 代码如下 let target_arch: TargetArch = \"x86_64\".try_into().map_err(Error::Arch)?; try_info是个trait方法, 实现了TryInfo, 而后者是个泛型 pub trait TryInto: Sized { /// The type returned in the event of a conversion error. type Error; /// Performs the conversion. fn try_into(self) -> Result; } 实际上, &str有很多种try_into的实现, 它们都和目标类型有关. 这里的目标类型是自己定义的enum TargetArch 因为TryInfo是个泛型, 所以, 这里自己给&str实现了针对性的try_into: impl TryInto for &str { type Error = TargetArchError; fn try_into(self) -> std::result::Result { match self.to_lowercase().as_str() { \"x86_64\" => Ok(TargetArch::x86_64), \"aarch64\" => Ok(TargetArch::aarch64), _ => Err(TargetArchError::InvalidString(self.to_string())), } } } 这也说明, 在rust里, 可以在自己模块给\"别人\"的类型实现某个trait. 注意这里, 原始trait要求try_into的签名是 fn try_into(self) -> Result 而我们实现的时候, 可以实例化: fn try_into(self) -> std::result::Result map_err(Error::Arch)? 有点奇怪, map_err的入参应该是个函数, 但Error::Arch只是个enum, 这样竟然也行? #[derive(Debug)] enum Error { Bincode(BincodeError), FileOpen(PathBuf, io::Error), FileFormat(FilterFormatError), Json(JSONError), MissingInputFile, MissingTargetArch, Arch(TargetArchError), } json文件 compile 序列化 // &mut dyn Read时trait object吗 fn parse_json(reader: &mut dyn Read) -> Result { //用了serde_json库, 在本crate的cargo.toml里面dependencies有 // 从reader读json, 返回JsonFile // 如果有错误, 转换为本模块的Json错误 serde_json::from_reader(reader).map_err(Error::Json) } fn compile(args: &Arguments) -> Result { //一句话打开文件 let input_file = File::open(&args.input_file) .map_err(|err| Error::FileOpen(PathBuf::from(&args.input_file), err))?; // new一个BufReader let mut input_reader = BufReader::new(input_file); // 从这个input_reader读 let filters = parse_json(&mut input_reader)?; // new一个compiler let compiler = Compiler::new(args.target_arch); // transform the IR into a Map of BPFPrograms let bpf_data: HashMap = compiler .compile_blob(filters.0, args.is_basic) //filters.0是元组tuple的数字下标访问方式 .map_err(Error::FileFormat)?; // serialize the BPF programs & output them to a file let output_file = File::create(&args.output_file) .map_err(|err| Error::FileOpen(PathBuf::from(&args.output_file), err))?; bincode::serialize_into(output_file, &bpf_data).map_err(Error::Bincode)?; Ok(()) } 注: Open以后没有Close, 因为input_file会被move进BufReader::new, 再被move出来, 所有权在这个函数结束的时候会被清理. Err的使用方法 fn main() { let mut arg_parser = build_arg_parser(); //这里和golang的if err := xxx(); err != nil {}意思一样 if let Err(err) = arg_parser.parse_from_cmdline() { eprintln!( \"Arguments parsing error: {} \\n\\n\\ For more information try --help.\", err ); process::exit(EXIT_CODE_ERROR); } if arg_parser.arguments().flag_present(\"help\") { println!(\"Seccompiler-bin v{}\\n\", SECCOMPILER_VERSION); println!(\"{}\", arg_parser.formatted_help()); return; } if arg_parser.arguments().flag_present(\"version\") { println!(\"Seccompiler-bin v{}\\n\", SECCOMPILER_VERSION); return; } let args = get_argument_values(arg_parser.arguments()).unwrap_or_else(|err| { eprintln!( \"{} \\n\\n\\ For more information try --help.\", err ); process::exit(EXIT_CODE_ERROR); }); if let Err(err) = compile(&args) { eprintln!(\"Seccompiler error: {}\", err); process::exit(EXIT_CODE_ERROR); } println!(\"Filter successfully compiled into: {}\", args.output_file); } "},"notes/others.html":{"url":"notes/others.html","title":"其他","keywords":"","body":"其他杂项. "},"notes/rust_mdbook_使用.html":{"url":"notes/rust_mdbook_使用.html","title":"使用mdbook","keywords":"","body":"mdBook是rust写的一个工具, 用来把md文档转成html book.guide: https://rust-lang.github.io/mdBook mdBook本身也是个git repo: https://github.com/rust-lang/mdBook 更新 2022.08 安装 book组织 mdbook使用 book.toml SUMMARY.md build book 更新 2022.08 mdbook不支持中文搜索, 故弃用. 使用gitbook代替gitbook参考:https://github.com/zhangjikai/gitbook-usehttps://github.com/snowdreams1006/snowdreams1006.github.io/blob/master/book.jsonhttps://snowdreams1006.github.io/ 安装 可以直接去github页面下载: https://github.com/rust-lang/mdBook/releases也可以自己编译, 但需要先安装rust编译器 cargo install mdbook cargo命令会自动从crates.io下载mdbook, 编译, 然后安装到cargo的bin目录(默认是~/.cargo/bin/). crates.io上的版本会比github代码稍微滞后一点, 可以指定用github代码编译: cargo install --git https://github.com/rust-lang/mdBook.git mdbook book组织 book由chapter组成, 每个chapter是一个独立的page, chapter可以有子chapter. mdbook使用 # 新建一个book mdbook init my-first-book cd my-first-book # 开启一个webserver, 修改的内容可以自动刷新到web page mdbook serve book.toml 一个book需要几个特殊文件来定义排版和布局. 根目录下的book.toml就是其中一个: 最常用的, 最简单的: [book] title = \"My First Book\" mdbook自己的实例:https://github.com/rust-lang/mdBook/blob/master/guide/book.toml SUMMARY.md 这个文件在src目录下, 定义了chapter结构: # Summary [Introduction](README.md) - [My First Chapter](my-first-chapter.md) - [Nested example](nested/README.md) - [Sub-chapter](nested/sub-chapter.md) 实例: https://github.com/rust-lang/mdBook/blob/master/guide/src/SUMMARY.md build book mdbook build 这个命令会根据md文件在本地book目录下生成html. "},"notes/shell_变量.html":{"url":"notes/shell_变量.html","title":"shell变量","keywords":"","body":" Variable Description ${parameter:-defaultValue} Get default shell variables value ${parameter:=defaultValue} Set default shell variables value ${parameter:?\"Error Message\"} Display an error message if parameter is not set ${#var} Find the length of the string ${var%pattern} Remove from shortest rear (end) pattern ${var%%pattern} Remove from longest rear (end) pattern ${var:num1:num2} Substring ${var#pattern} Remove from shortest front pattern ${var##pattern} Remove from longest front pattern ${var/pattern/string} Find and replace (only replace first occurrence) ${var//pattern/string} Find and replace all occurrences ${!prefix*} Expands to the names of variables whose names begin with prefix. ${var,} ${var,pattern} Convert first character to lowercase. ${var,,} ${var,,pattern} Convert all characters to lowercase. ${var^} ${var^pattern} Convert first character to uppercase. ${var^^} ${var^^pattern} Convert all character to uppercase. "},"notes/shell_基础篇.html":{"url":"notes/shell_基础篇.html","title":"shell命令和脚本记录-基础篇","keywords":"","body":" 带超时的重试命令 Here Document的用法: 一行输入 if判断和&&的区别 bash的双中括号 举例 date举例 网络脚本直接执行 ulimit和prlimit curl下载 暂停和继续一个进程的执行, 不用gdb 补充发送其他信号的行为 查看一个进程的子进程 跳过前几行 重定向前面不能有空格 shell单引号和双引号的重要区别 保存多行输出到shell变量 pstree pgrep and ps rsync 实例 sar 汇总 从变量read out put htop 为什么&后面加分号不行? sort按多列排序 shell注释一块代码 默认变量值 mtr 一个更好用的traceroute ssh config 快捷登录 给log文件加时间戳 cp最好加-a 如何查丢包 sar 查看block io的使用情况 telnet记录log kill某用户所有进程 UUID和GUID 关于grub 使用netcat导出打印 查看CPU运行队列情况 网络流量监控 查看uuid 为什么静态ip会丢失 用tail查看系统log 代码打补丁 如何查看io占用高的进程 linux访问win共享 ubuntu杀进程和服务 去掉最后几个字符 在shell里用exec eval source区别 查看线程, 大写H linux启动脚本顺序 文件权限 SELinux的文件权限扩展 shell for 观察82599的中断 关于中断balance 多个jpg图片转到pdf ssh X11及VNC firefox over ssh x11 forwarding 让远程的firefox更快 tools change tmux prefix tmux复制 network mount fae storage 新建一个用户到特定组 查看虚拟分区 thunder通过服务器上网 linux路由参考 brctl就是个交换机 wiz的搜索功能 批量修改jpg图片大小--xarg位置指代 ubuntu查看一个文件属于哪个package ubuntu查看一个package包含哪些文件 egrep 分组或 删除mysql的cmake相关的文件 cpu hotplug grub reserve 内存 给用户组加写权限 修改文件所属用户 增加共享库路经 查看端口占用 查找大于1M的文件 wget下载 通过gcc查找libc路径 -- -print-file-name=xxx 各种进制转十进制 bc --shell下的C计算器 CPU热插拔 hexdump查ascii码 -v选项 hexdump指定格式 查看温感 trap命令 --指定shell中处理signal 创建ram文件系统 heredoc格式代码 install命令 readlink --读取链接文件 重新修改tmpfs的大小 fg bg --前台运行 后台运行 shell写字符串, 以'\\0'结尾 写十六进制数据到文件, 关键在于引号 批量处理软链接之cscope.files readelf结果用sort排序, 按照第三列数字排序 批量删除ZF ZL ZG 批量格式化代码 带时间的平均负载 rpm解压 大小写转换 解析C文件全部函数到h文件声明, 用于偷懒声明所有函数到头文件 strace 重定向 通过elf生成工程文件列表 --利用gdb sync命令使用, 把file buffer 刷进物理器件 查找src下面的代码目录, find可以限制搜索深度 查看当前文件夹大小 删除文件夹下面的所有链接文件 压缩当前目录下sw_c文件夹 根据一个文本文件列表压缩 --hT tar.xz格式压缩解压 在当前路径下的所有文件中，搜索关键字符串 ls按修改时间排序 ls按大小排序 查看键盘映射 限制深度的find 查看系统支持的文件系统类型 替换字符串 批量软链接 tee 处理软链接, Thomas版 关闭printk打印 usb串口 --lsusb --minicom locate--linux下面的everything rsync拷贝目录，去除hg 带超时的重试命令 用timeout和until的组合:比如下面的dockerfile里面的RUN语句, code-server可能会在装extension的时候卡住, 用timeout来强制2m退出, 并用until循环来重试. RUN until timeout 2m code-server \\ --user-data-dir /usr/local/share/code-server \\ --install-extension golang.go \\ --install-extension ms-python.python \\ --install-extension formulahendry.code-runner \\ --install-extension eamodio.gitlens \\ --install-extension oderwat.indent-rainbow \\ --install-extension vscode-icons-team.vscode-icons \\ --install-extension esbenp.prettier-vscode \\ --install-extension streetsidesoftware.code-spell-checker \\ ;do echo Retry installing extensions...; done Here Document的用法: 一行输入 用可以达到bash -c一样的效果 $ bash -c \"echo hello\" hello $ bash 令一个例子是 $ ./gshell 具体见man bash, 搜索Here Strings if判断和&&的区别 返回值不同比如 if true; then echo 111; fi #结果为 111 echo $? #返回值为 0 if false; then echo 111; fi #没有输出, 说明if条件不成立 echo $? #返回值还是 0, 说明shell认为没有错误 而&&就不一样 false echo $? #直接返回 1 false && echo 111 #没有输出, 说明echo没有执行; 到这里和if的效果是一样的 echo $? #但返回值为 1 true && echo 111 #打印111 echo $? #返回值为 0 结论: if和&&都有根据条件控制执行的功能 if语句块结束后, 永远返回0值, 表示成功; 而&&返回值由最后一个语句决定, 可能是0, 也可能是1. 所以在某些脚本中, 如果最后的返回值重要, 就要考虑用哪种判断方式. bash的双中括号 help里面说的很清楚, [[ expression ]]的语义更明确, help [[ [[ ... ]]: [[ expression ]] 是test的扩展语法, 支持 ( EXPRESSION ) ! EXPRESSION EXPR1 && EXPR2 EXPR1 || EXPR2 特别的, 当使用==或!=时, 右侧的string会被当作pattern来匹配; 这个匹配和case in的语义一样 当使用=~时, 右侧的string是正则表达式. 举例 #!/bin/bash # Only continue for 'develop' or 'release/*' branches BRANCH_REGEX=\"^(develop$|release//*)\" if [[ $BRANCH =~ $BRANCH_REGEX ]]; then echo \"BRANCH '$BRANCH' matches BRANCH_REGEX '$BRANCH_REGEX'\" else echo \"BRANCH '$BRANCH' DOES NOT MATCH BRANCH_REGEX '$BRANCH_REGEX'\" fi [[ $TEST =~ ^[[:alnum:][:blank:][:punct:]]+$ ]] 参考: https://stackoverflow.com/questions/18709962/regex-matching-in-a-bash-if-statement/18710850 date举例 #给文件名用 $ date +\"%Y%m%d%H%M%S\" 20201020115510 #给log时间戳用 date +\"%F %H:%M:%S.%N\" 网络脚本直接执行 curl -s http://10.182.105.179:8088/godevtools/godevtool | bash -s -h curl -s http://10.182.105.179:8088/godevtools/godevtool | bash -s vscode start curl下载文件, 输出到stdout; -s是quiet模式 如果加-O就是保存同名文件到本地 bash -s可以加参数 如何通过pipe给bash传参数 -s If the -s option is present, or if no arguments remain after option processing, then commands are read from the standard input. This option allows the positional parameters to be set when invoking an interactive shell. ulimit和prlimit ulimit可以配置当前shell的资源限制, 一般用: ulimit -n 限制打开文件的个数 prlimit是个命令, 对应同名的系统调用, 可以动态配置一个pid的资源 prlimit --pid 13134 --rss --nofile=1024:4095 Display the limits of the RSS, and set the soft and hard limits for the number of open files to 1024 and 4095, respectively. prlimit --pid $$ --nproc=unlimited Set for the current process both the soft and ceiling values for the number of processes to unlimited. prlimit --cpu=10 sort -u hugefile Set both the soft and hard CPU time limit to ten seconds and run 'sort'. 显示当前进程(即执行prlimit进程的进程)的limit $ prlimit --pid $$ RESOURCE DESCRIPTION SOFT HARD UNITS AS address space limit unlimited unlimited bytes CORE max core file size 0 unlimited bytes CPU CPU time unlimited unlimited seconds DATA max data size unlimited unlimited bytes FSIZE max file size unlimited unlimited bytes LOCKS max number of file locks held unlimited unlimited locks MEMLOCK max locked-in-memory address space 16777216 16777216 bytes MSGQUEUE max bytes in POSIX mqueues 819200 819200 bytes NICE max nice prio allowed to raise 0 0 NOFILE max number of open files 1024 1048576 files NPROC max number of processes 289710 289710 processes RSS max resident set size unlimited unlimited bytes RTPRIO max real-time priority 0 0 RTTIME timeout for real-time tasks unlimited unlimited microsecs SIGPENDING max number of pending signals 289710 289710 signals STACK max stack size 8388608 unlimited bytes curl下载 curl -o go.tar.gz -L https://dl.google.com/go/go$GOLANG_VERSION.linux-amd64.tar.gz # -L的意思是让curl follow redirection 暂停和继续一个进程的执行, 不用gdb 我在前台跑了topid程序 #前台运行 ./topid #其他窗口执行 #暂停进程 kill -SIGSTOP `pidof topid` #效果和ctrl+z一样, 原窗口会打印 #[1]+ Stopped ./topid #继续执行 kill -SIGCONT `pidof topid` #最后的效果是程序转入后台执行 补充发送其他信号的行为 kill -SIGTRAP `pidof topid` : go程序退出, 打印调用栈 kill -SIGQUIT `pidof topid` : 同上 kill -SIGSEGV `pidof topid` : 同上, 就像程序本身segment fault一样 kill -SIGTERM `pidof topid` : 没有打印, 直接退出 查看一个进程的子进程 cat /proc/pid/task/tid/children 跳过前几行 #这里的tail -n +2就是跳过n-1行, 也就是跳过1行 (echo time Goroutine Thread numGC heapSys heapIdle heapInuse heapReleased && tail -n +2 vonuerr.log | awk '{printf(\"%s %s %s %s %s %s %s %s\\n\", $3,$5,$7,$9,$13,$17,$19,$21)}') > go.csv 重定向前面不能有空格 重定向前面有空格不行: find / -type d -name usr 2 > /dev/null 错误提示find: paths must precede expression: 2 下面的可以: find / -type d -name usr 2>/dev/null find / -type d -name usr 2> /dev/null shell单引号和双引号的重要区别 双引号展开, 单引号不展开 #单引号 cmd='echo date: $(date +%s%6N)' #执行有变化 $ eval $cmd date: 1539248827389418 bai@CentOS-43 ~/repo/save $ eval $cmd date: 1539248829149500 #双引号 cmd=\"echo date: $(date +%s%6N)\" #执行无变化 $ eval $cmd date: 1539248841366200 bai@CentOS-43 ~/repo/save $ eval $cmd date: 1539248841366200 bai@CentOS-43 ~/repo/save $ eval $cmd date: 1539248841366200 bai@CentOS-43 ~/repo/save #结论: 双引号有展开属性, 这里在赋值的时候就把date算好了 #赋给cmd时date值已经固定了, 所以双引号无变化 #单引号不会展开 保存多行输出到shell变量 #多行的输出可以保存到变量 v1=$(ethtool -S enP5p1s0 | grep packets | grep -v \": 0\" && echo date: $(date +%s%6N)) #但在使用的时候, 要加\"\"来保存换行 echo \"$v1\" #不加\"\",换行会变成空格 echo $v1 pstree pgrep and ps $ pstree `pgrep qemu` qemu-system-aar───9*[{qemu-system-aar}] $ ps -eLo tid,pid,ppid,psr,stat,%cpu,rss,cmd --sort=-%cpu rsync 实例 #第一个是用ssh传输 rsync -av --progress -e ssh DATA white@192.168.2.3:/var/services/homes/white/shl rsync -av --progress white@192.168.2.3:/var/services/homes/white/shl sar 汇总 watch -dn1 'sar -Bwqr -dp -n DEV -u ALL 1 1 | grep Average' sar -Bwqr -dp -n DEV -u ALL 1 sar -qr -dp -n DEV --human -u ALL -P ALL 1 1 -B: 页表 -w: task -q:CPU task q -r: mem -dp: block IO -n DEV: network -u: CPU -P:cpu_list | ALL 后面是interval和count 从变量read # Split the TARGET variable into three elements separated by hyphens IFS=- read -r NAME ARCH SUFFIX out put htop yingjieb@yingjieb-gv ~/tmp $ echo q | htop | aha --black --line-fix >> htop.html 为什么&后面加分号不行? $ for i in {1..10};do echo $i &; done -bash: syntax error near unexpected token `;' 不加分号是可以的 $ for i in {1..10};do echo $i & done 因为&符号表示前面的命令后台执行, 本身就隐含了分隔符的作用. 而此时再加一个分隔符, 但shell认为前面并没有命令, 所以报错. sort按多列排序 #先按第三列排序, 相同再按第二列排序, 最后按第一列 sort -k3,3 -k2,2 -k1 shell注释一块代码 #!/bin/bash echo before comment : 一个冒号是个空命令, 什么都不干. The ' and ' around the END delimiter are important, otherwise things inside the block like for example $(command) will be parsed and executed. That said -- it's running a command (:) that doesn't read its input and always exits with a successful value, and sending the \"comment\" as input. 默认变量值 关键是:- interface=\"$1\" interrupt_name=${interface:-\"eth3\"}\"-TxRx-\" 如果interface不为空, 就用interface, 否则用默认的eth3 也可以从位置参数获取变量值, 如果用户没有传入位置参数, 则使用默认值.比如: work_dir=`pwd` dev=${1:-/dev/sdc} ubuntu_size=${2:-500G} tar_fedora=${3:-fedora-with-native-kernel-repo-gcc-update-to-20150423.tar.bz2} mtr 一个更好用的traceroute mtr -n baidu.com ssh config 快捷登录 man ssh_config cat ~/.ssh/config Host aliclient Hostname 192.168.10.2 User root IdentityFile ~/.ssh/id_rsa_alibaba_bench ServerAliveInterval 60 Host aliserver Hostname 30.2.47.247 User root IdentityFile ~/.ssh/id_rsa_alibaba_bench ProxyCommand ssh -q -W %h:%p aliclient ServerAliveInterval 60 注: ProxyCommand 这句可神奇了, 它可以让ssh先登录到一台中转机器上, 然后再登录到目标机器 给log文件加时间戳 用ts命令 apt install moreutils $ ping www.baidu.com | ts Dec 24 12:59:04 PING www.a.shifen.com (111.13.100.91) 56(84) bytes of data. Dec 24 12:59:04 64 bytes from 111.13.100.91: icmp_seq=1 ttl=54 time=52.2 ms Dec 24 12:59:05 64 bytes from 111.13.100.91: icmp_seq=2 ttl=54 time=40.2 ms Dec 24 12:59:06 64 bytes from 111.13.100.91: icmp_seq=3 ttl=54 time=53.1 ms Dec 24 12:59:07 64 bytes from 111.13.100.91: icmp_seq=4 ttl=54 time=47.8 ms Dec 24 12:59:09 64 bytes from 111.13.100.91: icmp_seq=6 ttl=54 time=39.3 ms Dec 24 12:59:10 64 bytes from 111.13.100.91: icmp_seq=7 ttl=54 time=37.1 ms Dec 24 12:59:11 64 bytes from 111.13.100.91: icmp_seq=8 ttl=54 time=36.1 ms Dec 24 12:59:12 64 bytes from 111.13.100.91: icmp_seq=9 ttl=54 time=51.8 ms Dec 24 12:59:13 64 bytes from 111.13.100.91: icmp_seq=10 ttl=54 time=54.2 ms cp最好加-a 比如当前目录下, *.lua都是链接文件 普通cp会follow这个链接, 拷真正的文件 cp *.lua /tmp/tmp/ -a选项会保留软链接 cp -a *.lua /tmp/tmp/ 如何查丢包 接口侧 $ sudo ethtool -S wlan0 网络测 $ netstat -i sar 查看block io的使用情况 $ sar -dp 1 Linux 3.16.2-031602-generic (mint) 11/03/2015 _x86_64_ (4 CPU) 09:20:27 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 09:20:28 PM sda 1.00 0.00 8.00 8.00 0.03 76.00 32.00 3.20 09:20:28 PM sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 09:20:28 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 09:20:29 PM sda 1.00 0.00 240.00 240.00 0.00 4.00 4.00 0.40 09:20:29 PM sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -d: 查看block dev, 一般-dp一起用, 可以看到具体的sda/sdb名称 telnet记录log telnet 192.168.1.31 10001 | tee crb2s_reboot_at_os.log kill某用户所有进程 [root@cavium tmp]# killall -9 -u james [root@cavium tmp]# killall -9 -u guest UUID和GUID GUID是微软对UUID的一种实现 如何查看UUID 注意, 用dd命令clone的盘有着一样的UUID, 由此可见, UUID是保存在分区的某个地方--据说是超级块里. ls -l /dev/disk/by-uuid/ $ sudo blkid /dev/sdb1 /dev/sdb1: UUID=\"d039c104-49d4-464a-b3df-a962574fd46f\" TYPE=\"ext4\" 在Grub中的应用 title Ubuntu hardy (development branch), kernel 2.6.24-16-generic root (hd2,0) kernel /boot/vmlinuz-2.6.24-16-generic root=UUID=c73a37c8-ef7f-40e4-b9de-8b2f81038441 ro quiet splash initrd /boot/initrd.img-2.6.24-16-generic quiet 关于grub 设dtb devicetree 设kernel linux 使用netcat导出打印 前提是两台机器的ip能连上 服务端: dmesg | nc -l 1234 客户端: nc 127.0.0.1 1234 缺点是在客户端输入的东西好像在服务端解析的不好. 查看CPU运行队列情况 sar -q 1 07:12:09 PM runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked 07:12:10 PM 0 557 0.02 0.04 0.05 0 07:12:11 PM 0 557 0.02 0.04 0.05 0 07:12:12 PM 0 557 0.02 0.04 0.05 0 07:12:13 PM 0 557 0.02 0.04 0.05 0 07:12:14 PM 0 557 0.01 0.04 0.05 0 07:12:15 PM 0 557 0.01 0.04 0.05 0 07:12:16 PM 0 557 0.01 0.04 0.05 0 07:12:17 PM 0 557 0.01 0.04 0.05 0 其中runq-sz就是等待队列的长度 mpstat -A 可以报告更多详细的CPU使用率等信息 网络流量监控 sar -n DEV 1 这里的-n选项指的是network, 里面有很多子项 DEV, EDEV, NFS, NFSD, SOCK, IP, EIP, ICMP, EICMP, TCP, ETCP, UDP, SOCK6, IP6, EIP6, ICMP6, EICMP6 and UDP6 查看uuid blkid lsblk -f 为什么静态ip会丢失 eth7配了ip以后一会就丢失了 ifconfig eth7 8.8.8.4 up 因为一个service, 叫NetworkManager, 它会感知到eth-all的状态, 然后用dhclient配ip 用tail -f /var/log/messages就能看到dhclient和NetworkManager对eth7的操作 停止NetworkManager就OK. service NetworkManager stop 补充: 在cetos下, /etc/sysconfig/network-scripts下面的脚本应该是管网络的 用tail查看系统log tail -f /var/log/messages 也有人说 tail -f /var/log/kern.log 或 watch 'dmesg | tail -50' 或 cat /proc/kmsg 我的结论: 看这个文件就行了/var/log/messages, 已经包括了demsg的内容 代码打补丁 注意看当前的目录和patch文件的相对关系 比如patch文件里 diff -Naurp base/megaraid_sas.h fc19/megaraid_sas.h 而当前目录下就有megaraid_sas.h, 说明该P1 $ patch -p1 如何查看io占用高的进程 io总体使用情况 iostat -x 1 apt install iotop iotop linux访问win共享 apt install samba-client 这里有个问题, 就是主机名字没法解析, 此时需要先在window上ping主机名win7: ping socrates 得到Ping cafp01.caveonetworks.com [10.17.5.53] ping mafp01 得到Ping mafp01.caveonetworks.com [10.11.1.36] linux: 查看共享 $ smbclient -L //10.17.5.53 -N mount $ sudo mount -t cifs //10.17.5.53/ftproot /mnt -o user=,password= 拷贝--断点续传 $ rsync -v --progress --append \"/mnt/FAE/Users/VarunS/ThunderX/Ubuntu FS/ThunderX-ubuntu-8G-v3-FAE.tar.bz2\" ThunderX-ubuntu-8G-v3-FAE.tar.bz2 ubuntu杀进程和服务 ps aux | grep -v \"\\[.*\\]\" | grep -E \"cron|dhclient|38400|rsyslogd\" | awk '{print $2}' | xargs kill -9 一般上面的命令杀了进程以后, 那些进程又会自动生成. 下面的方法杀的彻底 services=\"cron resolvconf rsyslog udev dbus upstart-file-bridge upstart-socket-bridge upstart-udev-bridge tty1 tty2 tty3 tty4 tty5 tty6 tty7 tty8 tty9\" for s in $services;do service $s stop;done 去掉最后几个字符 byj@byj-Aspire-1830T ~ $echo abcd | sed s'/.$//' abc byj@byj-Aspire-1830T ~ $echo abcd | sed s'/..$//' ab 在shell里用exec eval source区别 eval 执行一个命令 exec 在新进程中执行一个命令，并且终止当前进程 source 在当前进程中执行脚本 查看线程, 大写H $ ps auxH | wc -l 查看tid号 ps -efL LWP那一列就是线程号, 如果是单独的线程, 应该和进程号一样. [byj]注: ps -eLf更实用一点 linux启动脚本顺序 init rc-->/etc/rc.d/rc3.d/*-->rc.local getty-->login-->/bin/bash /etc/profile-->~/.bash_profile-->~/.bash_login-->~/.profile-->~/.bashrc 文件权限 other不可写 chmod o-w repo -R 所有可执行, 一般目录都是这个属性 chmod a+x repo -R 用户组可写 chmod g+w repo/ -R SELinux的文件权限扩展 [root@cavium cavium]# ll total 313568 drwxr-xr-x 2 root root 4096 Jan 19 13:14 nfs drwxrwxr-x 6 root cavium 4096 Dec 28 21:18 repo -rw-r--r-- 1 yingjie cavium 303327016 Jan 19 11:19 RHELSA-1.6-Server.img.xz drwxrwxrwx. 2 root cavium 4096 Dec 23 17:29 share -rw-r--r-- 1 root root 158761 Jan 12 15:19 tests.tar.gz -rw-r--r-- 1 root root 17590232 Jan 20 20:12 thunder-bootfs.img 一般的权限后面有个., 这个是selinux security context, 很多时候, 这个东西会很麻烦 比如明明有写权限的文件不能访问, git库不能push等等 ls -Z可以查看这个权限 [root@cavium cavium]# ls -Z drwxr-xr-x root root ? nfs drwxrwxr-x root cavium ? repo -rw-r--r-- yingjie cavium ? RHELSA-1.6-Server.img.xz drwxrwxrwx. root cavium unconfined_u:object_r:home_root_t:s0 share -rw-r--r-- root root ? tests.tar.gz -rw-r--r-- root root ? thunder-bootfs.img chcon命令可以改这个selinux security context权限 setfattr -x security.selinux 可以去掉这个扩展权限 find . -exec setfattr -x security.selinux {} ; 或者 [root@cavium /]# find cavium/ -exec setfattr -x security.selinux {} ; shell for $ for i in {1..5};do echo next $i;done next 1 next 2 next 3 next 4 next 5 repos='\".\" \"bootloader/edk2/\" \"bootloader/grub2/grub/\" \"bootloader/trusted-firmware/atf/\" \"bootloader/u-boot/\" \"linux/kernel/linux-aarch64/\"' $ for i in $repos;do echo 1111111 $i;done 1111111 \".\" 1111111 \"bootloader/edk2/\" 1111111 \"bootloader/grub2/grub/\" 1111111 \"bootloader/trusted-firmware/atf/\" 1111111 \"bootloader/u-boot/\" 1111111 \"linux/kernel/linux-aarch64/\" 注:做为一个变量, repos表示一个list, 此时也可不加每个元素的双引号\"\", 也可以打印每个元素; 但在for里面直接写引号, 比如for i in '1 2 3 4 ';do echo dddd$i;done则只能打印一行. 观察82599的中断 watch -d -n 1 \"cat /proc/interrupts | egrep 'eth5|CPU0'\" 关于中断balance 设置哪几个CPU可以处理中断 $ echo f0 > /proc/irq/11/smp_affinity 在网络非常 heavy 的情况下，对于文件服务器、高流量 Web 服务器这样的应用来说，把不同的网卡 IRQ 均衡绑定到不同的 CPU 上将会减轻某个 CPU 的负担，提高多个 CPU 整体处理中断的能力；对于数据库服务器这样的应用来说，把磁盘控制器绑到一个 CPU、把网卡绑定到另一个 CPU 将会提高数据库的响应时间、优化性能。合理的根据自己的生产环境和应用的特点来平衡 IRQ 中断有助于提高系统的整体吞吐能力和性能。 注意：在手动绑定 IRQ 到 CPU 之前需要先停掉 irqbalance 这个服务，irqbalance 是个服务进程、是用来自动绑定和平衡 IRQ 的： $ /etc/init.d/irqbalance stop 使用的脚本 #!/bin/sh -e interrupt_name=\"eth3-TxRx-\" core_num=`cat /proc/cpuinfo | grep \"processor.*:\" -c` irq_num=`cat /proc/interrupts | grep $interrupt_name -c` [ $irq_num -eq $core_num ] || (echo 'Error, Call Cavium FAE!!!' && exit) irq_list=`cat /proc/interrupts | grep $interrupt_name | awk -F \":\" '{print $1}'` first_riq=`cat /proc/interrupts | grep ${interrupt_name}'0' | awk -F \":\" '{print $1}'` for irq in $irq_list do duty_core=$(($irq - $first_riq)) cpu_mask=$((1/proc/irq/$irq/smp_affinity done 多个jpg图片转到pdf convert *.jpg myeduction.pdf ssh X11及VNC firefox over ssh x11 forwarding 本来想开VNC server来远程图形方式访问办公室的机器, 但发现其实ssh的xorg forwarding功能就基本满足需求: 需要打开-X选项, 默认是关闭的. 比如在我的笔记本上: ssh -X baiyingjie@caviumsh.f3322.net 而此时登录到了办公室DELL的机器上, 此时敲firefox, 会在我的笔记本上打开DELL机器的firefox baiyingjie@mserver-dell ~ $ firefox 此时的firefox里面的内容其实是DELL机器上的, 比如我可以访问inventec2机器的BMC, 直接在地址栏里192.168.1.12就OK了. 让远程的firefox更快 上面的方法在功能上已经没什么问题了, 但使用下来感觉很卡, 延时太高. 这里面的原因, 网上说法是ssh的加密算法问题, 而不是firefox本身的问题--有待确认, 但感觉加了压缩选项就好很多, 似乎和加密算法关系不大. 默认的ssh由于使用比较强力的加解密算法, 比如AES, 可能会比较卡; 改成下面的加密算法会好很多 ssh -X -C -c blowfish-cbc,arcfour baiyingjie@caviumsh.f3322.net -X: 使能x11 forwarding -C: 使能压缩, 经验证这个选项提升速度最明显 -c: 指定cipher, 大约就是加解密算法吧 tools change tmux prefix C-b : set prefix C-a tmux复制 .tmuxrc里面加 bind-key -t vi-copy 'v' begin-selection bind-key -t vi-copy 'y' copy-selection 先C-b [进入copy mode v选中, y复制 C-b ]粘贴 network mount fae storage sudo mount -t cifs castr1:/FAE -o username=ybai,password=CQUbyj@2010 castorage 这个地址好像不认, 但没关系, 可以这样找到ip $ ping castr1.caveonetworks.com PING castr1.caveonetworks.com (10.18.5.15) 56(84) bytes of data. 所以这样应该可以了--还是不行 sudo mount -t cifs 10.18.5.15:/FAE -o username=ybai,password=CQUbyj@2010 castorage 最终版本 --验证可以 sudo mount -t cifs //10.18.5.15/FAE -o username=ybai,password=CQUbyj@2011 castorage 如果想断点续传 rsync -rv --progress --append /mnt/MARKETING/Product_Releases/ThunderX/CDK/Linux/GoldenImage . 新建一个用户到特定组 useradd joel -g cavium 查看虚拟分区 kpatx和losetup --原理可能是自动检测image的分区表 先创建一个1G大小的映像文件来做实验 dd bs=4096 if=/dev/zero of=~/hd.img count=262144 将映像文件挂接到loopX中去 losetup /dev/loopX ~/hd.img 对loopX进行分区 fdisk /dev/loopX 我这里分了两个区，每个去512M大小 Device Boot Start End Blocks Id System /dev/loopXpY 2048 1050623 524288 83 Linux /dev/loopXpY 1050624 2097151 523264 83 Linux 正戏来了，使用kpartd装载映像，使用kpartx是需要root用户的，因为是用root登录的，所以不用使用sudo。从前面的命令就可以看出来... kpartx -av ～/hd.img 装载之后，就可以在/dev/mapper/目录下看到两个loopXpY的文件了。 接下来对loopXpY进行格式化了。 mkfs.vfat /dev/mapper/loopXpY 然后挂载文件系统。 mount /dev/mapper/loop1p1 /media/hd1 OK，罗嗦完了。 thunder通过服务器上网 服务器em1 192.168.1.5可上外网 eth5是10G口, 和thunder的10G口eth3相连 首先, iptables是个用户态工具, 负责配规则. kernel里面的netfilter负责执行这些规则. 编译内核时需要打开netfilter功能 在服务器上: 先查link状态 ethtool eth5 设ip ifconfig eth5 9.9.9.99 up 打开转发 sysctl -w net.ipv4.ip_forward=1 设iptable, 所有9.9.9.0网络通过em1走nat iptables -t nat -A POSTROUTING -j MASQUERADE -s 9.9.9.0/24 -o em1 所有配置OK 但这里我记两个问题: 为什么看不到POSTROUTING链? 也看不到刚才设的规则. 在mint上也一样, 但可以工作 [root@cavium yingjie]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:domain ACCEPT tcp -- anywhere anywhere tcp dpt:domain ACCEPT udp -- anywhere anywhere udp dpt:bootps ACCEPT tcp -- anywhere anywhere tcp dpt:bootps Chain FORWARD (policy ACCEPT) target prot opt source destination ACCEPT all -- anywhere 192.168.122.0/24 state RELATED,ESTABLISHED ACCEPT all -- 192.168.122.0/24 anywhere ACCEPT all -- anywhere anywhere REJECT all -- anywhere anywhere reject-with icmp-port-unreachable REJECT all -- anywhere anywhere reject-with icmp-port-unreachable Chain OUTPUT (policy ACCEPT) target prot opt source destination 解答: iptables -L这个命令没有指定table, 默认是filter, 那只显示filter涉及的链, 就只有三个. 用这个可以查刚才的nat规则 iptables -t nat -L 我没有配route. --需要确认是不是真的不用配? 在thunder上: 配ip ifconfig eht3 9.9.9.98 up 配路由 route add default gw 9.9.9.9 配DNS --这里需要确认以下, DNS没有更好的办法配了么? cat /et/resolv.conf ping一下对端 `ping 9.9.9.9`` ping一下真正的网关 ping 192.168.1.1 ping一下baidu ping www.baidu.com linux路由参考 在linux主机中开启iptables,做SNAT(源地址转换)；下面我就以RHEL为例了，， 1.eth0(网卡1----外网)，设置公网IP，开启路由转发（#vim /etc/sysctl.conf 修改net.ipv4.ip_forward = 1）， 2.eth1(网卡2----内网)，设置内网IP， 3.iptalbes添加规则： iptables -t nat -A POSTROUTING -o eth1 -s 192.168.100.0/24 -j SNAT --to-source 外网IP 注：192.168.100.0/24是内网网段，如果外网地址不是静态的，SNAT也可以如下添加：iptables -t nat -A POSTROUTING -o eth1 -s 192.168.100.0 -j MASQUERADE（表示自动匹配IP地址） 4.就是设置路由器了，自己搞定吧。 brctl就是个交换机 brctl addbr testbridge brctl addif testbridge eth5 brctl addif testbridge eth6 这里需要解释一下, br下面的port应该是没有ip的, 从逻辑上, 几个port合并成一个聚合的interface, 就是br, 对外只有一个ip 这也是为什么要给br设一个ip ifconfig eth5 0.0.0.0 ifconfig eth6 0.0.0.0 ifconfig testbridge up ifconfig testbridge 192.168.1.30 netmask 255.255.255.0 up wiz的搜索功能 一般为\"或\"搜索 linux版可以这样搜: \"struct*file\" windows版: s:struct AND file 批量修改jpg图片大小--xarg位置指代 find . -iname \"*.jpg\" | xargs -l -i convert -resize 50% {} /tmp/{} mkdir tmp && find . -iname \"*.jpg\" | xargs -l -i convert -resize 40% -rotate 180 {} tmp/{} 注: xargs有个参数-i 表示用{}替代上个命令的输出; 但现在推荐用-I replace-str 我自己的例子: 把CNNIC-SDK-SRC目录下的源文件考到src目录下, 去掉路径 find CNNIC-SDK-SRC/ -iname \"*.[ch]\" | xargs -i cp {} src ubuntu查看一个文件属于哪个package 第一种情况, 检查已经安装的文件 $ dpkg -S /usr/share/man/man1/qemu-system-mips.1.gz qemu-system-mips: /usr/share/man/man1/qemu-system-mips.1.gz 第二种情况, 即使没装过这个文件 apt install apt-file sudo apt-file update $ apt-file search /usr/share/doc/qemu/q35-chipset.cfg qemu: /usr/share/doc/qemu/q35-chipset.cfg ubuntu查看一个package包含哪些文件 dpkg -L qemu dpkg -L qemu-system-mips egrep 分组或 hg st -q | egrep -vi \"cmake|Makefile\" 删除mysql的cmake相关的文件 find -iname '*cmake*' -not -name CMakeLists.txt -not -path \"*/.hg/*\" -exec rm -rf {} \\+ cpu hotplug echo 0 > /sys/devices/system/cpu/cpuX/online grub reserve 内存 改/boot/grub/grub.conf, 在kernel 一行加 memmap=10M$1024M memmap=7G$1G memmap=nn[KMG]@ss[KMG] [KNL] Force usage of a specific region of memory Region of memory to be used, from ss to ss+nn. memmap=nn[KMG]#ss[KMG] [KNL,ACPI] Mark specific memory as ACPI data. Region of memory to be used, from ss to ss+nn. memmap=nn[KMG]$ss[KMG] [KNL,ACPI] Mark specific memory as reserved. Region of memory to be used, from ss to ss+nn. Example: Exclude memory from 0x18690000-0x1869ffff memmap=64K$0x18690000 or memmap=0x10000$0x18690000 给用户组加写权限 chmod g+w OCTEON-SDK-3.1.0 -R 修改文件所属用户 chown byj.byj Makefile 增加共享库路经 LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH export LD_LIBRARY_PATH 查看端口占用 netstat -apn | grep 500 -a: all -p: 显示进程名 -n: 不解析地址名, 这会快很多 显示是ipsec charon这个进程, 进程号是1670 udp 0 0 0.0.0.0:4500 0.0.0.0:* 1670/charon udp 0 0 0.0.0.0:500 0.0.0.0:* 1670/charon udp6 0 0 :::4500 :::* 1670/charon udp6 0 0 :::500 :::* 1670/charon 先不着急用kill命令 用ipsec stop 查找大于1M的文件 find -type f -size +1M | xargs ls -lh wget下载 $ wget --no-check-certificate https://www.kernel.org/pub/software/scm/git/git-2.1.0.tar.gz 通过gcc查找libc路径 -- -print-file-name=xxx $ mips64-octeon-linux-gnu-gcc -march=octeon3 -mabi=n32 -EB -pipe -msoft-float -print-file-name=libc.a /repo/yingjieb/fgltb/sw/vobs/esam/build/reborn/buildroot-isam-reborn-cavium-fgltb/output/host/opt/ext-toolchain/bin/../mips64-octeon-linux-gnu/sys-root/usr/lib/../lib32-fp/libc.a 各种进制转十进制 $ echo $((2#111111)) 63 $ echo $((16#4f)) 79 $ echo $((0x4f)) 79 附: 十进制转十六进制, 以下几种都行 printf \"%x\\n\" 34 echo \"obase=16; 34\" | bc ( echo \"obase=16\" ; cat file_of_integers ) | bc bc --shell下的C计算器 其实bc可以进行任意进制转换 ibase是输入的进制 obase是输出的进制 bc其实是个语言, 语法类似C $ echo \"i=10; i++;i++\" | bc 10 11 CPU热插拔 # echo 0 > /sys/devices/system/cpu/cpu2/online Reset core 2. Available Coremask = 3fc # grep \"processor\" /proc/cpuinfo processor : 0 processor : 1 # echo 1 > /sys/devices/system/cpu/cpu2/online SMP: Booting CPU02 (CoreId 2)... CPU revision is: (Cavium Octeon II) Cpu 2 online # grep \"processor\" /proc/cpuinfo processor : 0 processor : 1 processor : 2 hexdump查ascii码 -v选项 //-v表示接受输入, -n8表示有8个字节的数据, 缺点是只能输入键盘字符 /isam/user # hexdump -v -n8 01abAB%^ 0000000 3031 6162 4142 255e 0000008 hexdump指定格式 //跳过6个字节, 显示6个字节, 1/1表示1次, 每次1个字节, 按照%02X格式 /isam/user # hexdump -v -n6 -s6 -e'1/1 \"%02X\"' /isam/prozone/PBDD 060000000010/isam/user # 查看温感 dts i2c compatible = \"ti,tmp432\",\"ti,tmp431\"; compatible = \"ti,lm75\"; cat /sys/class/hwmon/hwmon1/device/temp3_input 45250 表示45.25°C trap命令 --指定shell中处理signal 用kill -l查看所有的signal号 # Ignore SIGPIPE # When a script is run from an ssh session that is closed before the script is # finished, and the script writes to stdout (which no longer is connected to # something) then the script would get a SIGPIPE signal and be aborted. # This is normally not desired, so ignore the SIGPIPE signal entirely. log_sigpipe() { # only if __sigpipe_occurred is not set if [ -z ${__sigpipe_occurred+x} ]; then echo \"$(date): $0 ($$): SIGPIPE occurred, ignoring (parent $(pid_to_procname $PPID) ($PPID))\" >> /isam/logs/info_siglog __sigpipe_occurred=1 fi } trap log_sigpipe SIGPIPE 创建ram文件系统 mount -o size=16G -t tmpfs none /mnt/tmpfs heredoc格式代码 astyle --mode=c --style=linux -spfUcH install命令 在做共享库的Makefile中, 用到了install命令, 这个命令和cp功能差不多. mkdir -p $(DESTDIR)/usr/lib install $(LIB) $(DESTDIR)/usr/lib ln -sf $(LIB) $(DESTDIR)/usr/lib/$(NAME) ln -sf $(LIB) $(DESTDIR)/usr/lib/$(SONAME) readlink --读取链接文件 比如build是个链接 $ readlink -f build /repo/yingjieb/fdt063/sw/vobs/esam/build 重新修改tmpfs的大小 mount -o remount,size=XXX /tmp 或者 $ hg diff -c7639b7191348 diff --git a/board/Alcatel-Lucent/isam-reborn/common/post_build.sh b/board/Alcatel-Lucent/isam-reborn/common/post_build.sh --- a/board/Alcatel-Lucent/isam-reborn/common/post_build.sh +++ b/board/Alcatel-Lucent/isam-reborn/common/post_build.sh @@ -37,3 +37,10 @@ sed -i 's%^root:[^:]*:%root:$6$Pb/CNtO0N # cat $archdir/mdev-extra.conf >> $targetdir/etc/mdev.conf # cat $commondir/mdev-base.conf > $targetdir/etc/mdev.conf + +# Restrict size of /tmp +# By default /tmp has a maximum size of RAMsize/2, which is very big. +# This means that someone can write up to RAMsize/2 to /tmp, causing only half +# of RAM memory to be usable by real software. Since we should not need that +# large a /tmp directory, limit its size. +sed -i 's%^.*[ \\t]/tmp[ \\t].*$%tmpfs /tmp tmpfs defaults,size=64M 0 0%' $targetdir/etc/fstab fg bg --前台运行 后台运行 fg %1 bg后台运行的好处是程序还在跑, 而ctrl+z程序不跑了 hello: 后台运行的程序用printf向默认控制台打印也能输出 shell写字符串, 以'\\0'结尾 printf \"$string\\0\" > $tmpfile 写十六进制数据到文件, 关键在于引号 /isam/user # printf '\\xde\\xad\\xbe\\xef' > file /isam/user # hexdump -C file 00000000 de ad be ef |....| 00000004 /isam/user # echo -ne \"\\xde\\xad\\xbe\\xef\" > file /isam/user # hexdump -C file 00000000 de ad be ef |....| 00000004 没有引号就不行 /isam/user # echo -e \\xde\\xad\\xbe\\xef > file /isam/user # hexdump -C file 00000000 78 64 65 78 61 64 78 62 65 78 65 66 0a |xdexadxbexef.| 0000000d 批量处理软链接之cscope.files cat cscope.files | while read f; do if [ ! -h $f ]; then echo $f; fi; done readelf结果用sort排序, 按照第三列数字排序 cat uboot.readelf | sed -e '1,79d' -e '3128,$d' | sort -rnk 3 批量删除ZF ZL ZG cat cscope.files | egrep \"isam|fpxt|fglt|nvps|vipr|rant\" | xargs sed -i -e \"s%Z[LFG]_%%g\" 批量格式化代码 使用4个空格 cat cscope.files | xargs astyle --mode=c --style=linux -spfUcH 使用tab cat cscope.files | xargs astyle --mode=c --style=linux -tpfUcH 最终版 cat cscope.files | egrep \"isam|fpxt|fglt|nvps|vipr|rant\" | xargs astyle --mode=c --style=linux -tpfUcH 带时间的平均负载 $ echo \"$(date +%H:%M:%S) # $(cat /proc/loadavg)\" 10:07:14 # 0.98 1.00 1.15 2/723 26465 rpm解压 rpm2cpio OCTEON-LINUX-2.3.0-427.i386.rpm | cpio -div 大小写转换 tr '[:upper:]' '[:lower:]' output.txt sed -e 's/\\(.*\\)/\\L\\1/' input.txt > output.txt sed -e 's/\\(.*\\)/\\U\\1/' input.txt > output.txt 解析C文件全部函数到h文件声明, 用于偷懒声明所有函数到头文件 cat src/board_cpld.c | egrep \"(void|unsigned char|u_int8)[[:blank:]]+[0-9a-zA-Z_]+\\(.*\\)\" | sed -e 's/\\(.*\\)/\\1;/g' strace 重定向 strace echo \"groad\" &> myfile.txt strace echo \"groad\" > myfile.txt 2>&1 通过elf生成工程文件列表 --利用gdb mips64-octeon-linux-gnu-gdb -ex=\"info sources\" -ex=\"quit\" isam_app.nostrip | sed -e '1,15d' -e 's/,/\\n/g' | sed -e '/^ *$/d' -e 's/^ *//g' > temp.list find -L `cat cscope.files| egrep \"/flat/\" | sed 's!\\(.*/flat/[^/]*\\).*!\\1!g' | sort -u` -iname \"*.h\" -o -iname \"*.hh\" -o -iname \"*.hpp\" sync命令使用, 把file buffer 刷进物理器件 / # time dd if=/dev/zero of=/bigfile bs=65536 count=2048 2048+0 records in 2048+0 records out real 0m 0.29s user 0m 0.00s sys 0m 0.30s The command line (and similar ones) I used when sync was in order: / # time dd if=/dev/zero of=/bigfile bs=65536 count=2048 && time sync 2048+0 records in 2048+0 records out real 0m 3.11s user 0m 0.01s sys 0m 0.15s 查找src下面的代码目录, find可以限制搜索深度 output=`find -maxdepth 1 -type d | grep -i socket` echo $output echo $output >> src_dirs.byj sort -u src_dirs.byj mkcsfiles `cat src_dirs.byj.sort` 注: sort -u能够去掉重复行 查看当前文件夹大小 du -sh 删除文件夹下面的所有链接文件 find . -type l | xargs rm -rf 压缩当前目录下sw_c文件夹 tar -zcvf sw_c.tar.gz sw_c 根据一个文本文件列表压缩 --hT tar cvf /repo1/yingjieb/isam_lis/sw/build/fant-f/OS/fant-f_osw.tar -hT /repo1/yingjieb/isam_lis/sw/build/fant-f/OS/path tar.xz格式压缩解压 压缩 tar -Jcvf etc.tar.xz /etc 解压 tar -Jxf etc.tar.xz 在当前路径下的所有文件中，搜索关键字符串 grep -rn byj . ls按修改时间排序 cat cscope.files | xargs ls -lt | more ls按大小排序 cat cscope.files | xargs ls -lhS | more 查看键盘映射 stty -a 限制深度的find find -maxdepth 2 -name \".stamp*\" | xargs rm -f 查看系统支持的文件系统类型 cat /proc/filesystems 替换字符串 $ sst=abcdefcd 只替换第一个位置 $ echo ${sst/cd/55} ab55efcd ASBLX28:/home/yingjieb 全替换 $ echo ${sst//cd/55} ab55ef55 ${string/#substring/replacement} 如果$substring匹配$string的开头部分, 那么就用$replacement来替换$substring. ${string/%substring/replacement} 如果$substring匹配$string的结尾部分, 那么就用$replacement来替换$substring. 批量软链接 for file in *; do; if [ ! -L $file -a \"$file\" != \"Makefile\" ]; then; echo ln $file...;ln -sf ../../../../../executive/$file $file;fi;done tee tee指令会从标准输入设备读取数据，将其内容输出到标准输出设备,同时保存成文件。我们可利用tee把管道导入的数据存成文件，甚至一次保存数份文件。 处理软链接, Thomas版 find arch -type l | xargs ls -1l | grep executive | awk '{sub(\"../../\",\"\",$11); printf \"ln -sf %s %s\\n\",$11,$9}' 关闭printk打印 echo 1 1 1 1>/proc/sys/kernel/printk usb串口 --lsusb --minicom 插入usb串口以后，lsusb可以查看usb总线下面的设备。动态的。 $lsusb 此时查看 $ls /dev/tty* 可以看到新增了四个ttyUSB /dev/ttyUSB0 /dev/ttyUSB1 /dev/ttyUSB2 /dev/ttyUSB3 现在可以安装minicom apt install minicom locate--linux下面的everything byj@byj-mint ~/repo/hg/OCTEON-SDK-3.1-tools $locate OCTEON-SDK-3.1-p2-tools.tar.xz /home/byj/repo/alu/buildroot-isam-reborn-cavium-fgltb/dl/OCTEON-SDK-3.1-p2-tools.tar.xz /home/byj/repo/alu/fgltb/sw/vobs/esam/build/reborn/buildroot-isam-reborn-cavium-fgltb/dl/OCTEON-SDK-3.1-p2-tools.tar.xz /home/byj/share/OCTEON-SDK-3.1-p2-tools.tar.xz rsync拷贝目录，去除hg rsync -av --exclude .hg OCTEON-SDK-3.1-pristine OCTEON-SDK-3.1 "},"notes/shell_高级篇.html":{"url":"notes/shell_高级篇.html","title":"shell命令和脚本记录-高级篇","keywords":"","body":" 用socat连接pty 什么是tty pty 读写pts socat概览 常用选项 地址格式 地址类型 选项 FD组 NAMED option group OPEN option group REG and BLK option group PROCESS option group APPLICATION option group SOCKET option group IP4 and IP6 option groups TERMIOS option group FORK option group 例子 脚本命令行解析之declare -f shell变量扩展和引号保留 背景: 简单wrapper 参数重载 变量赋值导致字符串多变一 shell变量扩展方式 printf 最终版, 用eval 补充: shell的变量扩展 curl使用说明和举例 使用举例1 使用举例2 使用举例3 URL格式 curl和RESTful gitlab API举例 简介 举例 创建新project 获取gitignore模板 分支维护 sed解析log CPU利用率条件触发perf record top的记录导入到excel 比较粗糙的版本 CPU mem 同时导出CPU利用率和mem 只导出cpu利用率 改进版 用tr处理多余字符 一次shell重定向过程 shell重定向和exec 动态变量名及其引用: eval的使用 用eval生成动态变量名 间接引用变量 举例: 读出*.conf文件内容到动态文件名变量 uaes进程管理, 关系数组方式实现 判断字串是否包含字串 exec重定向 在shell里直接重定向stdin 重定向整个shell的stdout 输入和输出的例子 crosstool ng的例子 补充: test可以检测FD是否是terminal shell读写socket 更简单的写法 /dev/tcp是shell内建的设备节点 shell进程间通信 有名管道和nc shell检查一个脚本是否已经被include了 sed 向sed传递变量 sed使用记录 sed命令 sed匹配2行之间的内容 提取文件特定行 sed正则表达式 sed定址替换 sed删除 sed替换引用 sed的分组匹配, 用()分组, 用\\1引用 awk shell变量传给awk 再说patten awk在if里匹配 awk支持浮点 awk逻辑与 awk多行解析 awk分组提取 awk变量 awk数组 awk字符串替换 awk的条件判断和数字运算 awk执行其他程序 awk替换命令 shell管道和循环 看一个interface是否存在 用/proc/net/dev 用ifconfig intf返回值 awk计算时间差 ping延迟大于0.5ms触发动作 计算cpu掩码, mask shell的进程创建 粘贴多行文本管道后再用后续命令处理 关系数组 sed 和 awk 改进版 awk多维数组 原始版 shell关系数组 -- 或者说是list shell数组 shell脚本解析文件, 输出可以导入到excel的文本 shell处理命令行选项 shell也可以递归调用函数 改进版本 local system monitor system monitor for pangu 增加fedora分区的脚本 用socat连接pty 什么是tty pty linux终端(Terminals)有三种: 串口: 比如ttyS0, ttyUSB0 pty: /dev/pts/xx 屏幕命令行终端: tty1, tty2... 这里我们使用pty, pty是master slave模式的, master用于创建slave, 向slave读写内容; slave就是模拟的终端 master: /dev/ptmx slave: /dev/pts/* 读写pts 比如cloud-hypervisor使用pty文件/dev/pts/2做为VM的控制台, cat /dev/pts/2能够在host上查看VM的输出, echo xxxx > /dev/pts/2可以向VM输入. 但怎么同时输入输出? 就像进入VM的控制台一样? 先给出结果, 用socat: socat -,rawer,escape=29 /dev/pts/2 这个命令的意思是, 建立从raw模式的stdio到/dev/pts/2的双向stream连接 -: 表示stdin和stdout rawer是raw模式, 不echo; 在raw模式下, 比如ctrl+c会发送给VM, 不再用来退出socat escape=29: 使用ctrl+]来退出socat /dev/pts/2: 是pty文件 socat概览 socat是强大的双向stream对接工具, 基本作用就是建立address1到address2的双向byte stream连接. socat [options] 常用选项 -d -d: 打印verbose debug信息, 可多个-d -T: 空闲timeout时间自动退出 -u/-U: 单向数据传输 -L: lock文件 地址格式 socat支持多种地址类型, 格式为地址类型:地址,选项1,选项2 某些常用地址类型可以用简化写法: -: stdio TCP: TCP4 数字: FD 地址类型 CREATE: 创建文件写入 EXEC: 使用command做为input/output FD: 使用已经存在的fd GOPEN: 打开文件读写. 文件可以是unix socket, 会自动connect, connect失败则假定用sendto. 可以省略GOPEN. INTERFACE: 带L2的raw packet IP-DATAGRAM:: IP4-DATAGRAM:: IP6-DATAGRAM:: IP-RECVFROM: IP4-RECVFROM: IP6-RECVFROM: IP-RECV: IP-SENDTO:: IP4-SENDTO:: IP6-SENDTO:: raw/datagram socket PIPE: PIPE 有名和无名管道 PROXY::: proxy PTY 创建新的pty slave SCTP-CONNECT:: SCTP协议 SOCKET-CONNECT::: SOCKET-DATAGRAM:::: SOCKET-RECV:::: SOCKS4::: socket STDIN STDIO STDOUT SYSTEM: 感觉和exec差不多 TCP:: TCP-LISTEN: TUN[:/] 新建tun设备做为写侧 UDP:: UDP-LISTEN: udp还有listen? UNIX-CONNECT: UNIX-LISTEN: UNIX-SENDTO: UNIX-RECVFROM: UNIX-RECV: UNIX-CLIENT: ABSTRACT-CONNECT: unix socket 选项 socat支持很多选项, 比如上面例子中的raw 不同的group支持不同的option FD组 这个组里的option支持对fd配置某种参数. cloexec setlk flock-ex lock user mode append nonblock null-eof ... 很多 NAMED option group 作用于文件名 umask unlink-close OPEN option group creat noatime rdonly rsync ... REG and BLK option group seek ... PROCESS option group chroot setgid su ... APPLICATION option group 作用于数据 cr Converts the default line termination character NL (’\\n’, 0x0a) to/from CR (’\\r’, 0x0d) when writing/reading on this channel. escape SOCKET option group bind= broadcast rcvbuf sndbuf IP4 and IP6 option groups tos ip-pktinfo TERMIOS option group b0 波特率0, 即断开连接 b19200 echo= rawer ignbrk brkint ... 很多关于特殊字符控制的 FORK option group pipes sighup, sigint, sigquit 例子 #把stdio转到tcp socat - TCP4:www.domain.org:80 #和上面差不多, 但支持line edit socat -d -d READLINE,history=$HOME/.http_history TCP4:www.domain.org:www,crnl #转发listen, 但只accept一个connection socat TCP4-LISTEN:www TCP4:www.domain.org:www #加了fork就能允许多个connection socat TCP4-LISTEN:5555,fork,tcpwrap=script EXEC:/bin/myscript,chroot=/home/sandbox,su-d=sandbox,pty,stderr #stdion转到ttyS0, 用control-O退出socat socat -,escape=0x0f /dev/ttyS0,rawer,crnl 脚本命令行解析之declare -f 下面的代码中, 脚本main里面解析命令行, 只看了通用的--help等, 而其他的命令都通过declare -f \"cmd_$1\" > /dev/null先\"声明\"函数, 再调用:$cmd \"$@\" main() { if [ $# = 0 ]; then die \"No command provided. Please use \\`$0 help\\` for help.\" fi # Parse main command line args. # while [ $# -gt 0 ]; do case \"$1\" in -h|--help) { cmd_help; exit 1; } ;; -y|--unattended) { OPT_UNATTENDED=true; } ;; -*) die \"Unknown arg: $1. Please use \\`$0 help\\` for help.\" ;; *) break ;; esac shift done # $1 is now a command name. Check if it is a valid command and, if so, # run it. # declare -f \"cmd_$1\" > /dev/null ok_or_die \"Unknown command: $1. Please use \\`$0 help\\` for help.\" cmd=cmd_$1 shift # $@ is now a list of command-specific args # $cmd \"$@\" } main \"$@\" 比如想实现$0 build_rootfs命令, 用上面的方法, 只需要增加cmd_build_rootfs()函数: 但需要每个\"子命令\"函数都自己实现命令解析 # `./devtool build_rootfs -s 500MB` # Build a rootfs of custom size. # cmd_build_rootfs() { # Default size for the resulting rootfs image is 300MB. SIZE=\"300MB\" FROM_CTR=ubuntu:18.04 flavour=\"bionic\" # Parse the command line args. while [ $# -gt 0 ]; do case \"$1\" in \"-h\"|\"--help\") { cmd_help; exit 1; } ;; \"-s\"|\"--size\") shift SIZE=\"$1\" ;; \"-p\"|\"--partuuid\") shift PARTUUID=1 ;; *) die \"Unknown argument: $1. Please use --help for help.\" ;; esac shift done ... } shell变量扩展和引号保留 shell变量扩展语法 背景: 这里的测试命令是: go list -f \"{{context.GOARCH}} {{context.Compiler}}\" -- unsafe #正常的结果是 amd64 gc #说明go命令能正确理解传入的参数 但我这里需要用一个bash wrapper封装原始的go命令(重命名为_go), 把原始参数修改后再传入_go 简单wrapper 这样是可以的 #!/bin/bash exec _go \"$@\" 这里 \"$@\"会把所有的参数\"原封不动\"的传入底层命令 补充一下: $#是参数个数, 这里为5, 用for a in \"$@\"来遍历参数, 这5个参数分别是 list -f ` : 这里说明 for in对位置参数的遍历, 不是以空白符为分隔的. 因为这里虽然有空格, 但它们会做为一个整体被赋值到变量a` -- unsafe 参数重载 但我的需求是更改参数, 有如下尝试: #!/bin/bash cmd=$1 shift exec _go $cmd \"$@\" 这个可以. 说明shift对参数移位了, 但不会影响\"$@\"对原始字符串的操作 变量赋值导致字符串多变一 但下面的代码不正常工作: #!/bin/bash cmd=$1 shift args=\"$@\" exec _go $cmd \"$args\" #或者下面的命令 exec _go $cmd $args 的结果是flag provided but not defined: -f {{context.GOARCH}} {{context.Compiler}} -- unsafe 经过检查, 和这样执行原始命令是一样的: _go list \"-f {{context.GOARCH}} {{context.Compiler}} -- unsafe\" 说明: args=\"$@\"的结果是, args把-f -- unsafe会变成一个整体的string shell变量扩展方式 下面的都不行 #!/bin/bash cmd=$1 shift exec _go $cmd ${*@Q} #结果 can't load package: package '-f': malformed module path \"'-f'\": invalid char '\\'' exec _go $cmd \"${*@Q}\" #结果 can't load package: package '-f' '{{context.GOARCH}} {{context.Compiler}}' '--' 'unsafe': malformed module path \"'-f' '{{context.GOARCH}} {{context.Compiler}}' '--' 'unsafe'\": invalid char '\\'' 这里用到了shell的变量扩展: ${parameter@operator} The expansion is either a transformation of the value of parameter or information about parameter itself, depending on the value of operator. Each operator is a single letter: Q The expansion is a string that is the value of parameter quoted in a format that can be reused as input. If parameter is ‘@’ or ‘*’, the operation is applied to each positional parameter in turn, and the expansion is the resultant list. If parameter is an array variable subscripted with ‘@’ or ‘*’, the operation is applied to each member of the array in turn, and the expansion is the resultant list. 意思是把$*当作一个list, 对其中的每个成员做Q操作. 从结果来看Q操作实际上把成员做了转义-引号:比如-f变成了\\'-f\\', {{context.GOARCH}} {{context.Compiler}}变成了\\'{{context.GOARCH}} {{context.Compiler}}\\'传递给_go命令时, 这些转义被当作原始输入, 不能被正确解析.${*@Q}和\"${*@Q}\"的区别是, 后者被当作一个整体的string被传入. printf printf也支持 printf: printf [-v var] format [arguments] %b expand backslash escape sequences in the corresponding argument %q quote the argument in a way that can be reused as shell input The format is re-used as necessary to consume all of the arguments. 比如 #!/bin/bash args=\"$@\" echo \"${args@Q}\" #输出 'list -f {{context.GOARCH}} {{context.Compiler}} -- unsafe' printf \"====%s\\n\" ${args@Q} #输出 ===='list ====-f ===={{context.GOARCH}} ===={{context.Compiler}} ====-- ====unsafe' ${args@Q}中, ${args}被当作一个整体, 加上了引号. 这个整体传入printf的时候, printf按空白符分割, 被当作6个argument, 并分别用\"====%s\\n\"来格式化. 最终版, 用eval #!/bin/bash cmd=$1 shift args=${*@Q} echo $cmd $args eval exec _go $cmd $args #不用exec也是可以的 eval _go $cmd $args 解释: 既然${*@Q}能够把每个成员都加转义-引号, 那么用shell的eval命令, 重新解析一下这个命令, 就能正常运作了. 补充: shell的变量扩展 还是这个链接 变量扩展能够: 变量重定向: ${!var} If the first character of parameter is an exclamation point (!), and parameter is not a nameref, it introduces a level of indirection. Bash uses the value formed by expanding the rest of parameter as the new parameter; this is then expanded and that value is used in the rest of the expansion, rather than the expansion of the original parameter. This is known as indirect expansion. 变量替换: ${parameter/pattern/string} 根据匹配规则, 用string替换变量$parameter中的pattern串. 可以全部替换, 可以只替换第一个 parameter支持list模式, 比如array[@] 大小写转换: ${parameter^pattern} ${parameter,pattern} 匹配和删除: ${parameter#word} ${parameter##word} ${parameter%word} ${parameter%%word} 字符个数: ${#parameter} 如果是array[@]的形式, 返回成员个数 变量默认值: ${parameter:-word} ${parameter:=word} ${parameter:?word} ${parameter:+word} ${!prefix*} ${!prefix@} ${!name[@]} ${!name[*]} 没看懂有啥用 Expands to the names of variables whose names begin with prefix, separated by the first character of the IFS special variable. 子串扩展: ${parameter:offset} ${parameter:offset:length} 支持负数 $ string=01234567890abcdefgh $ echo ${string:7} 7890abcdefgh $ echo ${string:7:0} $ echo ${string:7:2} 78 $ echo ${string:7:-2} 7890abcdef $ echo ${string: -7} bcdefgh $ echo ${string: -7:0} $ echo ${string: -7:2} bc $ echo ${string: -7:-2} bcdef $ set -- 01234567890abcdefgh $ echo ${1:7} 7890abcdefgh $ echo ${1:7:0} $ echo ${1:7:2} 78 $ echo ${1:7:-2} 7890abcdef $ echo ${1: -7} bcdefgh $ echo ${1: -7:0} $ echo ${1: -7:2} bc $ echo ${1: -7:-2} bcdef $ array[0]=01234567890abcdefgh $ echo ${array[0]:7} 7890abcdefgh $ echo ${array[0]:7:0} $ echo ${array[0]:7:2} 78 $ echo ${array[0]:7:-2} 7890abcdef $ echo ${array[0]: -7} bcdefgh $ echo ${array[0]: -7:0} $ echo ${array[0]: -7:2} bc $ echo ${array[0]: -7:-2} bcdef 支持list模式(array模式). $ array=(0 1 2 3 4 5 6 7 8 9 0 a b c d e f g h) $ echo ${array[@]:7} 7 8 9 0 a b c d e f g h $ echo ${array[@]:7:2} 7 8 $ echo ${array[@]: -7:2} b c $ echo ${array[@]: -7:-2} bash: -2: substring expression curl使用说明和举例 curl不仅可以传输http, 还支持几乎所有的传输协议:比如tftp telnet smbs imap 等等等等 curl有非常多的选项 使用举例1 # https://www.jfrog.com/confluence/display/JFROG/Artifactory+REST+API#ArtifactoryRESTAPI-WorkingwithArtifactoryCloud curl -X PUT $ARTIFACTORY_URL/$RELEASE_BASE/$versiondir/$subdir/$arch/$remote_package_name -T $package # https://www.jfrog.com/confluence/display/JFROG/Artifactory+REST+API#ArtifactoryRESTAPI-FileInfo curl -s -X GET $ARTIFACTORY_URL/api/storage/$RELEASE_BASE/$versiondir/$subdir/$arch curl -s -X GET $ARTIFACTORY_URL/api/storage/$RELEASE_BASE/$versiondir/$subdir/$arch/$package_name curl -s -X GET $ARTIFACTORY_URL/$RELEASE_BASE/$versiondir/$subdir/$arch/$package_name -o $local_package 说明: -X, --request (HTTP) Specifies a custom request method to use when communicating with the HTTP server. The specified request method will be used instead of the method otherwise used (which defaults to GET). Read the HTTP 1.1 specification for details and explanations. Common additional HTTP requests include PUT and DELETE, but related technologies like WebDAV offers PROPFIND, COPY, MOVE and more. Normally you don't need this option. All sorts of GET, HEAD, POST and PUT requests are rather invoked by using dedicated command line options. This option only changes the actual word used in the HTTP request, it does not alter the way curl behaves. So for example if you want to make a proper HEAD request, using -X HEAD will not suffice. You need to use the -I, --head option. The method string you set with -X, --request will be used for all requests, which if you for example use -L, --location may cause unintended side-effects when curl doesn't change request method according to the HTTP 30x response codes - and similar. -T, --upload-file This transfers the specified local file to the remote URL. If there is no file part in the specified URL, curl will append the local file name. NOTE that you must use a trailing / on the last directory to really prove to Curl that there is no file name or curl will think that your last directory name is the remote file name to use. That will most likely cause the upload operation to fail. If this is used on an HTTP(S) server, the PUT command will be used. Use the file name \"-\" (a single dash) to use stdin instead of a given file. Alternately, the file name \".\" (a single period) may be specified instead of \"-\" to use stdin in non-blocking mode to allow reading server output while stdin is being uploaded. You can specify one -T, --upload-file for each URL on the command line. Each -T, --upload-file + URL pair specifies what to upload and to where. curl also supports \"globbing\" of the -T, --upload-file argument, meaning that you can upload multiple files to a single URL by using the same URL globbing style supported in the URL, like this: curl --upload-file \"{file1,file2}\" http://www.example.com or even curl -T \"img[1-1000].png\" ftp://ftp.example.com/upload/ 使用举例2 #For example, the following cURL and build-info-permission.json define a new permission target called “java-developers”, for a build called “test-maven”: curl -uadmin:password -XPUT \"http://localhost:8081/artifactory/api/v2/security/permissions/java-developers\" -H \"Content-type: application/json\" -T build-info-permission.json 说明: -u, --user Specify the user name and password to use for server authentication. Overrides -n, --netrc and --netrc-optional. If you just give the user name (without entering a colon) curl will prompt for a password. If you use an SSPI-enabled curl binary and do NTLM authentication, you can force curl to pick up the user name and password from your environment by simply specifying a single colon with this option: \"-u :\". If this option is used several times, the last one will be used. -H, --header (HTTP) Extra header to use when getting a web page. You may specify any number of extra headers. Note that if you should add a custom header that has the same name as one of the internal ones curl would use, your externally set header will be used instead of the internal one. This allows you to make even trickier stuff than curl would normally do. You should not replace internally set headers without knowing perfectly well what you're doing. Remove an internal header by giving a replacement without content on the right side of the colon, as in: -H \"Host:\". If you send the custom header with no-value then its header must be terminated with a semicolon, such as -H \"X-Custom-Header;\" to send \"X-Custom-Header:\". curl will make sure that each header you add/replace is sent with the proper end-of-line marker, you should thus not add that as a part of the header content: do not add newlines or carriage returns, they will only mess things up for you. See also the -A, --user-agent and -e, --referer options. This option can be used multiple times to add/replace/remove multiple headers. 使用举例3 下载vscode server curl -#fL -o ~/.cache/code-server/code-server-3.6.0-linux-amd64.tar.gz.incomplete -C - https://github.com/cdr/code-server/releases/download/v3.6.0/code-server-3.6.0-linux-amd64.tar.gz -# 使用简化的进度条 -f Fail silently (no output at all) on server errors. 主要的目的是给远程执行脚本用的 -L 之前遇到过, follow redirection -C - 这两个连起来是说curl会 continue/Resume a previous file transfer URL格式 curl支持多个url地址, 比如 http://site.{one,two,three}.com ftp://ftp.example.com/file[1-100].txt ftp://ftp.example.com/file[a-z].txt #在一个url里面包含多个可变部分 http://example.com/archive[1996-1999]/vol[1-4]/part{a,b,c}.html #带步进的 http://example.com/file[1-100:10].txt http://example.com/file[a-z:2].txt curl和RESTful gitlab API举例 简介 gitlab API的根目录是https://gitlab.example.com/api/v4 比如 # 获取gitlabe1.ext.net.nokia.com下所有的projects, 返回值是json格式的 curl \"https://gitlabe1.ext.net.nokia.com/api/v4/projects\" POST是新建, PUT是更新: 使用curl的-X, --request选项指定. 默认是GET Methods Description --header \"PRIVATE-TOKEN: \" Use this method as is, whenever authentication needed --request POST Use this method when creating new objects --request PUT Use this method when updating existing objects --request DELETE Use this method when removing existing objects 有些API是需要权限的, 没有权限可能返回public data或者直接返回错误. 有几种方式提供权限, 比如 # 在参数里 curl https://gitlab.example.com/api/v4/projects?private_token= # 在header里 curl --header \"Private-Token: \" https://gitlab.example.com/api/v4/projects 比如获取group信息 curl --header \"PRIVATE-TOKEN: \" \"https://gitlab.example.com/api/v4/groups/gitlab-org\" 举例 创建新project 使用POST curl --request POST --header \"PRIVATE-TOKEN: \" \"https://gitlab.example.com/api/v4/projects?name=foo\" 也可以使用curl的--data curl --data \"name=foo\" --header \"PRIVATE-TOKEN: \" \"https://gitlab.example.com/api/v4/projects\" 再举个创建新group的例子: 这个例子使用json格式的数据做为输入 curl --request POST --header \"PRIVATE-TOKEN: \" --header \"Content-Type: application/json\" --data '{\"path\": \"my-group\", \"name\": \"My group\"}' \"https://gitlab.example.com/api/v4/groups\" 获取gitignore模板 对每个语言, gitlab都有gitignore模板, 对应GET /templates/gitignores请求 # 获取所有模板, 返回json格式的列表 curl https://gitlab.example.com/api/v4/templates/gitignores # 实例返回结果 [ { \"key\": \"Autotools\", \"name\": \"Autotools\" }, { \"key\": \"C\", \"name\": \"C\" }, { \"key\": \"C++\", \"name\": \"C++\" }, { \"key\": \"CFWheels\", \"name\": \"CFWheels\" }, { \"key\": \"CMake\", \"name\": \"CMake\" }, { \"key\": \"CUDA\", \"name\": \"CUDA\" } ] 比如看Ruby的gitignore模板, 需要用这样的语法:GET /templates/gitignores/:key curl https://gitlab.example.com/api/v4/templates/gitignores/Ruby #结果 { \"name\": \"Ruby\", \"content\": \"*.gem\\n*.rbc\\n/.config\\n/coverage/\\n/InstalledFiles\\n/pkg/\\n/spec/reports/\\n/spec/examples.txt\\n/test/tmp/\\n/test/version_tmp/\\n/tmp/\\n\\n# Used by dotenv library to load environment variables.\\n# .env\\n\\n## Specific to RubyMotion:\\n.dat*\\n.repl_history\\nbuild/\\n*.bridgesupport\\nbuild-iPhoneOS/\\nbuild-iPhoneSimulator/\\n\\n## Specific to RubyMotion (use of CocoaPods):\\n#\\n# We recommend against adding the Pods directory to your .gitignore. However\\n# you should judge for yourself, the pros and cons are mentioned at:\\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\\n#\\n# vendor/Pods/\\n\\n## Documentation cache and generated files:\\n/.yardoc/\\n/_yardoc/\\n/doc/\\n/rdoc/\\n\\n## Environment normalization:\\n/.bundle/\\n/vendor/bundle\\n/lib/bundler/man/\\n\\n# for a library or gem, you might want to ignore these files since the code is\\n# intended to run in multiple environments; otherwise, check them in:\\n# Gemfile.lock\\n# .ruby-version\\n# .ruby-gemset\\n\\n# unless supporting rvm 分支维护 获取分支格式 GET /projects/:id/repository/branches 或者 GET /projects/:id/repository/branches/:branch 比如: curl https://gitlabe1.ext.net.nokia.com/api/v4/projects/57103/repository/branches curl https://gitlabe1.ext.net.nokia.com/api/v4/projects/57103/repository/branches/master 创建分支格式 POST /projects/:id/repository/branches 需要下面的参数: Attribute Type Required Description id integer yes ID or URL-encoded path of the project owned by the authenticated user. branch string yes Name of the branch. ref string yes Branch name or commit SHA to create branch from. 举例: curl --request POST --header \"PRIVATE-TOKEN: \" https://gitlab.example.com/api/v4/projects/5/repository/branches?branch=newbranch&ref=master # 返回 { \"commit\": { \"author_email\": \"john@example.com\", \"author_name\": \"John Smith\", \"authored_date\": \"2012-06-27T05:51:39-07:00\", \"committed_date\": \"2012-06-28T03:44:20-07:00\", \"committer_email\": \"john@example.com\", \"committer_name\": \"John Smith\", \"id\": \"7b5c3cc8be40ee161ae89a06bba6229da1032a0c\", \"short_id\": \"7b5c3cc\", \"title\": \"add projects API\", \"message\": \"add projects API\", \"parent_ids\": [ \"4ad91d3c1144c406e50c7b33bae684bd6837faf8\" ] }, \"name\": \"newbranch\", \"merged\": false, \"protected\": false, \"default\": false, \"developers_can_push\": false, \"developers_can_merge\": false, \"can_push\": true } 删除分支:DELETE /projects/:id/repository/branches/:branch 举例: curl --request DELETE --header \"PRIVATE-TOKEN: \" https://gitlab.example.com/api/v4/projects/5/repository/branches/newbranch sed解析log 要在一个很大的log里面提取OMCI的消息: 格式1 [trace] 08:36:48.888471 Dir: Tx --> Onu: ont1-fwlt-b Retry: 0 00000000 1c ee 49 0a 00 02 00 00 80 00 00 00 00 00 00 00 |..I.............| 00000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00000020 00 00 00 00 00 00 00 00 00 00 00 28 |...........(| 格式2 [2018/04/28 07:54:20.393226][omci][INFO]Dir: Rx 格式1和格式2就是打印的header不一样 用下面的sed命令提取 sed -rn -e '/.*Dir: .*--.*/,+4{s/.* (..:..:..\\.......).*(Dir.*)/\\1 \\2/g;p}' stdout_824128194_ok.log 其中 -r 使用扩展正则 -n 不自动打印pattern空间. 不加-n会打印所有原始行和修改行 -e 后面跟定址 /.*Dir: .*--.*/,+4 意思是所有匹配到Dir: Tx --> Onu和Dir: Rx CPU利用率条件触发perf record 条件是两个进程pidof onumgnt_hypervisor_app和pidof onu_engine的CPU利用率同时到10%以上. 注意用整个while块使用小括号括起来的, 小括号会产生子进程, 目的是让块内的exit退出这个子进程. 不用小括号的话, 这个代码块是在当前shell进程执行, 那exit会退出当前shell. ./topid -p `pidof onumgnt_hypervisor_app` -p `pidof onu_engine` > pid.log & ( while true do if [[ $(tail -n 2 pid.log | awk '{if ($3>10) print $5}' | wc -l) == 2 ]];then echo doing profiling LD_LIBRARY_PATH=`pwd` ./perf record -F 500 -e cycles -g --call-graph dwarf -p `pidof onumgnt_hypervisor_app` -- sleep 60 exit fi sleep 3 done ) 另外, 这个这个代码块不要用tab来缩进, 否则会被shell解析成auto completion来自动联想命令. top的记录导入到excel 比较粗糙的版本 CPU (echo time switch_hwa_app vonu xpon_hwa_app xponhwadp && cat top.log | awk '/GMT/{printf \"\\n\"$4} /run\\/switch_hwa_app/{printf(\" switch_hwa_app>%s\",$8)} /run\\/xpon_hwa_app/{printf(\" xpon_hwa_app>%s\",$8)} /run\\/xponhwadp/{printf(\" xponhwadp>%s\",$8)} /vONU-PoC-1 -skipav yes/{printf(\" vonu>%s\",$8)}' | while read line; do echo $line | xargs -n1 | sort | xargs; done | tr \">\" \" \" | awk '{printf(\"%s %s %s %s %s\\n\", $1, $3, $5, $7, $9)}' ) > ~/sf_work/tmp/$(basename `pwd`).csv mem #这里实际上是统计的VSS, 是虚拟内存占用 cat top.log | awk '/GMT/{printf \"\\n\"$4\"\\t\"} /vONU-PoC-1 -skipav yes/ {if($5 ~ /.*m/) printf $5; else printf $5/1024}' | tr -d 'm' > ~/sf_work/tmp/$(basename `pwd`).csv 同时导出CPU利用率和mem 这个top.log是用如下命令记录的, 每秒一次. #grep -E记录的是RSS, 物理内存. while true; do date top -bn1 | grep -E \"$patten|CPU|Mem|COMMAND\" top -bn1 -m | grep -E \"$patten|COMMAND\" sleep 1 done >> log/top.log 原始的log如下: Tue Jan 6 13:05:29 GMT 1970 Mem: 884920K used, 1072956K free, 152152K shrd, 42636K buff, 356908K cached CPU: 54% usr 16% sys 0% nic 29% idle 0% io 0% irq 0% sirq PID PPID USER STAT VSZ %VSZ CPU %CPU COMMAND 24514 1 root S 110m 6% 1 50% ./vONU-PoC-1 -profilingperiod 5 18455 165 root S 204m 11% 1 0% /isam/slot_default/xpon_hwa_app/run/xpon_hwa_app --json=/isam/slot_default/xpon_hwa_app/config/app_config --pty=/isam/slot_default/xpon_hwa_app/run/tty1_ext --tnd-client 18047 131 root S 184m 10% 0 0% /isam/slot_default/switch_hwa_app/run/switch_hwa_app --json=/isam/slot_default/switch_hwa_app/config/app_config --pty=/isam/slot_default/switch_hwa_app/run/tty1_ext --tnd-client --json=/isam/slot_default/switch_hwa_app/config/app_config --pty=/isam/slot_default/switch_hwa_app/run/tty1_ext --tnd-client 22037 1 root S 51844 3% 1 0% //lib/confd/erts/bin/confd -K false -MHe true -- -root //lib/confd -progname confd -- -home / -- -smp disable -boot confd -delayed-detach -noshell -noinput -yaws embedded true -stacktrace_depth 24 -shutdown_time 30000 -conffile //etc/confd/confd.conf -start_phase0 -max_fds 1024 -detached-fd 4 18067 166 root S 36168 2% 1 0% /isam/slot_default/xponhwadp/run/xponhwadp --json=/isam/slot_default/xponhwadp/config/app_config --pty=/isam/slot_default/xponhwadp/run/tty1_ext --tnd-client 18601 124 root S 34260 2% 1 0% /isam/slot_default/dmsp_app/run/dmsp_app --json=/isam/slot_default/dmsp_app/config/app_config --pty=/isam/slot_default/dmsp_app/run/tty1_ext --tnd-client 24522 24515 root S 2952 0% 1 0% grep -E vONU-PoC-1|xponhwadp|switch_hwa_app|xpon_hwa_app|confd|dmsp_app|CPU|Mem|COMMAND 124 1 root S 2788 0% 0 0% s6-supervise dmsp_app 131 1 root S 2788 0% 0 0% s6-supervise switch_hwa_app 165 1 root S 2788 0% 0 0% s6-supervise xpon_hwa_app 166 1 root S 2788 0% 0 0% s6-supervise xponhwadp PID^^^VSZ^VSZRW RSS (SHR) DIRTY (SHR) STACK COMMAND 18047 176m 148m 123m 6948 95676 5896 132 /isam/slot_default/switch_hwa_app/run/switch_hwa_app --json=/isam/slot_default/switch_hwa_app/config/app_config --pty=/isam/slot_default/switch_hwa_app/run/tty1_ext --tnd-client --json=/isam/slot_default/switch_hwa_app/config/app_config --pty=/isam/slot_default/switch_hwa_app/run/tty1_ext --tnd-client 24514 110m 100m 11020 0 11020 0 132 ./vONU-PoC-1 -profilingperiod 5 22037 51844 39868 38424 2608 38420 2604 132 //lib/confd/erts/bin/confd -K false -MHe true -- -root //lib/confd -progname confd -- -home / -- -smp disable -boot confd -delayed-detach -noshell -noinput -yaws embedded true -stacktrace_depth 24 -shutdown_time 30000 -conffile //etc/confd/confd.conf -start_phase0 -max_fds 1024 -detached-fd 4 18067 36168 7624 20760 11224 11272 6816 128 /isam/slot_default/xponhwadp/run/xponhwadp --json=/isam/slot_default/xponhwadp/config/app_config --pty=/isam/slot_default/xponhwadp/run/tty1_ext --tnd-client 18601 34260 14452 22652 11304 17688 6916 132 /isam/slot_default/dmsp_app/run/dmsp_app --json=/isam/slot_default/dmsp_app/config/app_config --pty=/isam/slot_default/dmsp_app/run/tty1_ext --tnd-client 18455 29104 8324 14208 7192 8392 5540 132 /isam/slot_default/xpon_hwa_app/run/xpon_hwa_app --json=/isam/slot_default/xpon_hwa_app/config/app_config --pty=/isam/slot_default/xpon_hwa_app/run/tty1_ext --tnd-client 24527 2952 384 1532 1464 1528 1460 132 grep -E vONU-PoC-1|xponhwadp|switch_hwa_app|xpon_hwa_app|confd|dmsp_app|COMMAND 124 2788 400 1464 1348 1460 1344 132 s6-supervise dmsp_app 166 2788 400 1424 1312 1420 1308 132 s6-supervise xponhwadp 131 2788 400 1396 1284 1392 1280 132 s6-supervise switch_hwa_app 165 2788 400 1396 1284 1392 1280 132 s6-supervise xpon_hwa_app 用下面的脚本解析 cat top.log | grep -v -E \"s6-supervise|grep|COMMAND|confd -B| tar| cat\" | awk '/GMT/{printf \"\\ntime=\"$4} /Mem:/{sub(\"K\",\"\",$4);printf \" free=\" $4/1024} /CPU:/{printf(\" usr=%s sys=%s idle=%s sirq=%s\",$2,$4,$8,$14)} $1 ~ /[0-9]+/{sub(\".*/\",\"\",$9);printf(\" %s\",$9);if($8 ~ /.*%/) printf \":cpu=\"$8;else {printf \":rss=\";if($4 ~ /.*m/) {sub(\"m\",\"\",$4);printf $4} else printf $4/1024}}' | while read line; do echo $line | xargs -n1 | sort | xargs; done awk的行匹配支持表达式, 这里的$1 ~ /[0-9]+/就是, 意思是第一个field匹配一个number sub是原地替换, 不返回字符串 输出如下: confd:cpu=0% confd:rss=37.5234 dmsp_app:cpu=0% dmsp_app:rss=22.1211 free=1047.81 idle=29% sirq=0% switch_hwa_app:cpu=0% switch_hwa_app:rss=123 sys=16% time=13:05:29 usr=54% vONU-PoC-1:cpu=50% vONU-PoC-1:rss=10.7617 xpon_hwa_app:cpu=0% xpon_hwa_app:rss=13.875 xponhwadp:cpu=0% xponhwadp:rss=20.2734 confd:cpu=0% confd:rss=37.5234 dmsp_app:cpu=0% dmsp_app:rss=22.1211 free=1047.55 idle=75% sirq=0% switch_hwa_app:cpu=4% switch_hwa_app:rss=123 sys=16% time=13:05:30 usr=8% vONU-PoC-1:cpu=0% vONU-PoC-1:rss=10.7617 xpon_hwa_app:cpu=0% xpon_hwa_app:rss=13.875 xponhwadp:cpu=0% xponhwadp:rss=20.2734 confd:cpu=0% confd:rss=37.5234 dmsp_app:cpu=0% dmsp_app:rss=22.1211 free=1047.42 idle=83% sirq=4% switch_hwa_app:cpu=4% switch_hwa_app:rss=123 sys=4% time=13:05:32 usr=8% vONU-PoC-1:cpu=0% vONU-PoC-1:rss=10.7617 xpon_hwa_app:cpu=0% xpon_hwa_app:rss=13.875 xponhwadp:cpu=0% xponhwadp:rss=20.2734 confd:cpu=0% confd:rss=37.5234 dmsp_app:cpu=0% dmsp_app:rss=22.1211 free=1047.24 idle=90% sirq=0% switch_hwa_app:cpu=2% switch_hwa_app:rss=123 sys=4% time=13:05:33 usr=4% vONU-PoC-1:cpu=0% vONU-PoC-1:rss=10.7617 xpon_hwa_app:cpu=0% xpon_hwa_app:rss=13.875 xponhwadp:cpu=0% xponhwadp:rss=20.2734 confd:cpu=0% confd:rss=37.5234 dmsp_app:cpu=0% dmsp_app:rss=22.1211 free=1047.22 idle=81% sirq=0% switch_hwa_app:cpu=4% switch_hwa_app:rss=123 sys=13% time=13:05:35 usr=4% vONU-PoC-1:cpu=0% vONU-PoC-1:rss=10.7852 xpon_hwa_app:cpu=0% xpon_hwa_app:rss=13.875 xponhwadp:cpu=0% xponhwadp:rss=20.2734 最后用tr \"=\" \" \"休整一下. 最终版: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 confd:cpu 0% confd:rss 37.5234 dmsp_app:cpu 0% dmsp_app:rss 22.1211 free 1047.81 idle 29% sirq 0% switch_hwa_app:cpu 0% switch_hwa_app:rss 123 sys 16% time 13:05:29 usr 54% 25 26 27 28 29 30 31 32 33 34 35 36 vONU-PoC-1:cpu 50% vONU-PoC-1:rss 10.7617 xpon_hwa_app:cpu 0% xpon_hwa_app:rss 13.875 xponhwadp:cpu 0% xponhwadp:rss 20.2734 (echo time free usr sys idle sirq confd:cpu confd:rss dmsp:cpu dmsp:rss switch_hwa:cpu switch_hwa:rss vONU:cpu vONU:rss xpon_hwa:cpu xpon_hwa:rss xponhwadp:cpu xponhwadp:rss && cat top.log | grep -v -E \"s6-supervise|grep|COMMAND|confd -B| tar| cat\" | awk '/GMT/{printf \"\\ntime=\"$4} /Mem:/{sub(\"K\",\"\",$4);printf \" free=\" $4/1024} /CPU:/{printf(\" usr=%s sys=%s idle=%s sirq=%s\",$2,$4,$8,$14)} $1 ~ /[0-9]+/{sub(\".*/\",\"\",$9);printf(\" %s\",$9);if($8 ~ /.*%/) printf \":cpu=\"$8;else {printf \":rss=\";if($4 ~ /.*m/) {sub(\"m\",\"\",$4);printf $4} else printf $4/1024}}' | while read line; do echo $line | xargs -n1 | sort | xargs; done | tr \"=\" \" \" | awk 'NF == 36 {printf(\"%s %s %s %s %s %s %s %s %s %s %s %s %s %s %s %s %s %s\\n\", $22,$10,$24,$20,$12,$14,$2,$4,$6,$8,$16,$18,$26,$28,$30,$32,$34,$36)}') > top.csv 只导出cpu利用率 top的输出, 每秒记录一次, 这里的patten是xponhwadp switch_hwa_app xpon_hwa_app vONU-PoC-1这几个app的名字前面打个时间戳date && top -bn1 | grep -E $patten 输出是这样的: 怎么把这个输出, 导入到excel里面, 然后对每个app做cpu占用的图呢? 要用到awk, xargs, sort cat top.log | awk '/GMT/{printf \"\\n\"$4} /run\\/switch_hwa_app/{printf(\" switch_hwa_app:%s\",$8)} /run\\/xpon_hwa_app/{printf(\" xpon_hwa_app:%s\",$8)} /run\\/xponhwadp/{printf(\" xponhwadp:%s\",$8)} /vONU-PoC-1 -skipav yes/{printf(\" vonu:%s\",$8)}' | while read line; do echo $line | xargs -n1 | sort | xargs; done awk负责过滤关键词, 用/patten/{action}的形式 awk过滤后, 每个时间戳下, 这四个app都列出来了, 但顺不一定一样, 因为top输出会按照CPU排序 此时要用read, 从stdin读每一行, 然后对该行排序 xargs -n1实际上是对每个字段加回车, 因为默认的xargs会对每个输入做echo sort是按行工作的, 前面的xargs的输出就是多行 最后的xargs把排好序的多行输出还原成一行 最后的输出: 改进版 (echo time switch_hwa_app vonu xpon_hwa_app xponhwadp && cat top.log | awk '/GMT/{printf \"\\n\"$4} /run\\/switch_hwa_app/{printf(\" switch_hwa_app>%s\",$8)} /run\\/xpon_hwa_app/{printf(\" xpon_hwa_app>%s\",$8)} /run\\/xponhwadp/{printf(\" xponhwadp>%s\",$8)} /vONU-PoC-1 -skipav yes/{printf(\" vonu>%s\",$8)}' | while read line; do echo $line | xargs -n1 | sort | xargs; done | tr \">\" \" \" | awk '{printf(\"%s %s %s %s %s\\n\", $1, $3, $5, $7, $9)}' ) > top.csv 用()括起来echo和后面的处理, 否则echo不会重定向到top.csv 用tr处理多余字符 原始文件是带^M字符的, 它实际上是windows的\\r (to get ^M type CTRL+V followed by CTRL+M i.e. don’t just type the carat symbol and a capital M. It will not work) #重点是tr -d, 把两边的方括号删掉, 把\\r删掉 cat onustatus.log | tr -d '[]\\r' | awk '/onustatus/{printf $6 \" \"} /ONUs done/{print $3}' 一次shell重定向过程 用strace观察一个重定向的过程: strace bash -c \"echo 5555 > testpipe\" 这里的testpipe是个有名管道, 用mkfifo testpipe生成的 注意, 我用了'bash -c'命令, 意思是新起一个bash进程来执行-c后面的命令, 目的是观察bash怎么处理重定向的. 不加'bash -c'是看不到这个过程的. #本bash执行另外一个bash, 从这里到结束都没有再次exec bash execve(\"/bin/bash\", [\"bash\", \"-c\", \"echo 5555 > testpipe\"] #省略动态库加载过程, 省略brk 和mmap过程, 省略挂载sighandler过程 ... #进入主题 # 打开testpipe, fd是3 openat(AT_FDCWD, \"testpipe\", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3 fcntl(1, F_GETFD) = 0 #保存现在的fd1, 到fd10 fcntl(1, F_DUPFD, 10) = 10 fcntl(1, F_GETFD) = 0 #如果后面调用了exec, 则exec出的子进程不继承fd10; 换句话说, exec成功后, fd10会被close #这个例子里, 都没有再次exec子进程, 所以这个语句实际没起到作用. fcntl(10, F_SETFD, FD_CLOEXEC) = 0 #int dup2(int oldfd, int newfd); #把fd3复制到fd1, 即现在fd1就是fd3 dup2(3, 1) = 1 #关闭fd3 close(3) write(1, \"5555\\n\", 5) = 5 #从fd10还原fd1 dup2(10, 1) = 1 fcntl(10, F_GETFD) = 0x1 (flags FD_CLOEXEC) close(10) = 0 shell重定向和exec 把上面例子的命令修改一下, 把echo改成外部程序cat, 用strace的-f选项跟踪全部进程. strace -f -o s.log bash -c \"cat testpipe > testpipe2\" 过程简析如下: #8123进程执行bash 8123 execve(\"/bin/bash\", [\"bash\", \"-c\", \"cat testpipe > testpipe2\"] #省略动态库加载过程, 省略brk 和mmap过程, 省略挂载sighandler过程 #找到cat命令 8123 access(\"/bin/cat\", R_OK) = 0 8123 rt_sigprocmask(SIG_BLOCK, [INT CHLD], [], 8) = 0 #clone父进程 8123 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7fefa27eda10) = 8124 #8123进入wait 8123 wait4(-1, #省略子进程挂载sighandler ... #处理重定向, 打开testpipe2为fd3, fd3复制到fd1, 随即close fd3 8124 openat(AT_FDCWD, \"testpipe2\", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3 8124 dup2(3, 1) = 1 8124 close(3) = 0 #重定向发生在exec cat之前, 是bash做的工作 #exec执行cat, 替换原进程空间 8124 execve(\"/bin/cat\", [\"cat\", \"testpipe\"], 0x5600ee4a38f0 /* 26 vars */) = 0 #以此调用brk扩展内存空间, mmap等, 装载so #打开要cat的文件 8124 openat(AT_FDCWD, \"testpipe\", O_RDONLY) = 3 #从fd3(即testpipe)读, 写到fd1 8124 read(3, \"5555\\n\", 131072) = 5 8124 write(1, \"5555\\n\", 5) = 5 #关闭相关fd ... 8124 +++ exited with 0 +++ #父进程bash的wait4返回 8123 [{WIFEXITED(s) && WEXITSTATUS(s) == 0}], 0, NULL) = 8124 #父进程处理SIGCHLD信号 #再次wait4发现没有子进程了, 父进程退出 8123 rt_sigaction(SIGINT, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x7fefa1df5f20}, {sa_handler=0x5600edd40160, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x7fefa1df5f20}, 8) = 0 8123 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0 8123 --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=8124, si_uid=1003, si_status=0, si_utime=0, si_stime=0} --- 8123 wait4(-1, 0x7ffd543dca50, WNOHANG, NULL) = -1 ECHILD (No child processes) 8123 +++ exited with 0 +++ 动态变量名及其引用: eval的使用 有时候, 我们想根据某些条件, 来生成一个shell变量, 其名字可以是用户输入, 也可以是从文件里读出来的某个字段. 用eval可以做到 用eval生成动态变量名 #option的值可以从任何地方, 比如取自文件名 option=vendor_name #这个值被eval后, 成为了新的变量名. 在当前shell就有效. eval $option=my_vendor echo $vendor_name #输出 my_vendor 注意: 不加eval是不行的: $ $option=my_vendor vendor_name=my_vendor: command not found eval后面有空格不行, 除非加两层引号, 先单后双 $ eval $option=my vendor vendor: command not found $ eval $option='my vendor' vendor: command not found $ eval $option=\"'my vendor'\" byj@byj-envy-notebook ~/tmp/uaes $ echo $vendor_name my vendor 间接引用变量 变量是动态生成的时候, 我们在写脚本的当下, 是不知道具体的变量名的, 就没办法直接引用. 要间接引用, 用${!var}的格式 dvar=hello var=dvar echo ${!var} #输出 hello #用eval也行, $var先被替换为dvar, 转义$再传入eval eval \"echo \\${$var}\" #这样写不行 $ echo ${$var} bash: ${$var}: bad substitution 举例: 读出*.conf文件内容到动态文件名变量 for f in *.conf;do eval ${f%.conf}='`cat $f`';done uaes进程管理, 关系数组方式实现 #! /bin/bash StartProcess() { echo Starting process [$1] ...Done } StopProcess() { echo Stoping process [$1] ...Done } GetTargetState() { cat msgfifo } ReportState() { echo $1 > rplfifo } stopList=\"\" AddToStopList() { stopList=\"$1 $stopList\" } DoStopList() { for p in $stopList; do StopProcess $p done stopList=\"\" } declare -A processes SwitchState(){ local from=$1 local to=$2 if test -z \"$from\"; then from=null processes[$from]=\"\" elif test -z \"${processes[$from]}\"; then processes[$from]=$(cat ${from}.conf) echo Loading ${from}.conf ...Done fi if test -z \"${processes[$to]}\"; then processes[$to]=$(cat ${to}.conf) echo Loading ${to}.conf ...Done fi OLDIFS=$IFS IFS=$'\\n' for p in ${processes[$from]}; do if [[ \"${processes[$to]}\" != *\"$p\"* ]]; then IFS=$OLDIFS #StopProcess $p AddToStopList $p fi done DoStopList IFS=$'\\n' for p in ${processes[$to]}; do if [[ \"${processes[$from]}\" != *\"$p\"* ]]; then StartProcess \"$p\" fi done IFS=$OLDIFS } if ! test -e IDL.conf; then echo Please add IDL.conf first! exit 1 fi SwitchState \"\" IDL current=IDL echo Initial state $current running ... while true; do target=$(GetTargetState) if test \"$target\" = \"$current\"; then echo Keep state $current unchanged continue fi if test -e ${target}.conf; then echo Switching state from $current to $target ... echo \">>>>>>>>\" SwitchState $current $target else echo File ${target}.conf not found! continue fi current=$target ReportState $current if test \"$current\" = \"DOWN\"; then echo ========Shutdown. exit 1 fi echo Running in state $current .. done 判断字串是否包含字串 判断一个字符串是否包含一个字串 注意, 不带通配符的必须在判断的左边; 否则永远为false if [[ \"$str\" == *\"$substr\"* ]]; then exec重定向 对某个命令的重定向很常见, 比如 cat : cat从stdin读取字符, 并显示到stdou上. 这里用README文件重定向到stdin 当然直接cat README也是可以的, 因为cat命令后面带文件名, 它会打开这个文件作为输入.这种情况它不从stdin读取东西, 和重定向没关系. 那这里说的是对整个脚本重定向. 要用到shell的内置命令exec 在shell里直接重定向stdin #新建fd6(或重新打开), 复制fd0给fd6, 箭头表示fd是只读的 #也可以理解成Link file descriptor #6 with stdin #这里的意思是, 把fd0保存到新建的fd6中. 单独用这个没什么意思 exec 6 完整例子 #!/bin/bash # Redirecting stdin using 'exec'. #新建fd6(或重新打开), 复制fd0给fd6, 箭头表示fd是只读的 exec 6 重定向整个shell的stdout #新建fd6(或重新打开), 复制fd1给fd6, 箭头表示fd是只写. 并不是把6赋值给1 #这里的意思是保存fd1到fd6, 即保存原始的stdout exec 6>&1 #从这里开始, 输出变为logfile.txt exec > logfile.txt #输出 echo xxx ... #从fd6还原fd1, 即还原原始的stdout. #并关闭fd6 exec 1>&6 6>&- 完整例子 #!/bin/bash # reassign-stdout.sh LOGFILE=logfile.txt # 新建fd6(或重新打开), 复制fd1给fd6, 箭头表示fd是只写. 并不是把6赋值给1 exec 6>&1 # Link file descriptor #6 with stdout. # Saves stdout. exec > $LOGFILE # stdout replaced with file \"logfile.txt\". # ----------------------------------------------------------- # # All output from commands in this block sent to file $LOGFILE. echo -n \"Logfile: \" date echo \"-------------------------------------\" echo echo \"Output of \\\"ls -al\\\" command\" echo ls -al echo; echo echo \"Output of \\\"df\\\" command\" echo df # ----------------------------------------------------------- # exec 1>&6 6>&- # Restore stdout and close file descriptor #6. echo echo \"== stdout now restored to default == \" echo ls -al echo exit 0 输入和输出的例子 #!/bin/bash # upperconv.sh # Converts a specified input file to uppercase. E_FILE_ACCESS=70 E_WRONG_ARGS=71 if [ ! -r \"$1\" ] # Is specified input file readable? then echo \"Can't read from input file!\" echo \"Usage: $0 input-file output-file\" exit $E_FILE_ACCESS fi # Will exit with same error #+ even if input file ($1) not specified (why?). if [ -z \"$2\" ] then echo \"Need to specify output file.\" echo \"Usage: $0 input-file output-file\" exit $E_WRONG_ARGS fi exec 4&1 exec > $2 # Will write to output file. # Assumes output file writable (add check?). # ----------------------------------------------- cat - | tr a-z A-Z # Uppercase conversion. # ^^^^^ # Reads from stdin. # ^^^^^^^^^^ # Writes to stdout. # However, both stdin and stdout were redirected. # Note that the 'cat' can be omitted. # ----------------------------------------------- exec 1>&7 7>&- # Restore stout. exec 0 crosstool ng的例子 # Log policy: # - first of all, save stdout so we can see the live logs: fd #6 # (also save stdin and stderr for use by CT_DEBUG_INTERACTIVE) # FIXME: it doesn't look like anyone is overriding stdin/stderr. Do we need # to save/restore them? CT_LogEnable() { local clean=no local arg for arg in \"$@\"; do eval \"$arg\"; done #复制1到6, 2到7, 0到8；箭头只表示输入还是输出 exec 6>&1 7>&2 8>\"${CT_BUILD_LOG}\" } # Restore original stdout, stderr and stdin CT_LogDisable() { exec >&6 2>&7 补充: test可以检测FD是否是terminal test -t FD -t FD True if FD is opened on a terminal. shell读写socket 用nc命令可以方便的读写socket 其实shell还有更简单的方法: 在一个窗口里, 用nc监听一个端口 nc -l 1985 在另外一个窗口里 #用socket做文件fd 3 exec 3<>/dev/tcp/localhost/1985 #读 echo 111 >&3 #写 cat 更简单的写法 在另一个窗口里 echo 111 > /dev/tcp/localhost/1985 直接就可以发送. 但前提是1985端口有人监听. 如果对端没有监听, 会出现Connection refused /dev/tcp是shell内建的设备节点 这个节点在文件系统里是没有的. 这是shell提供的访问socket的方法. shell进程间通信 我们经常用的管道就是shell进程间通信的一种: 比如ls | grep txt 这是匿名管道. 还有有名管道, shell的mkfifo命令就能创建个有名管道 mkfifo pipe2 会在当前目录下创建一个管道文件 Linux Mint 19.1 Tessa $ ll pipe2 #管道文件以p开头 prw-rw-r-- 1 yingjieb yingjieb 0 Oct 12 14:31 pipe2 以后两个独立的进程就可以重定向到这个文件通信了. ls > pipe2 在另一个窗口里 cat 注: 单独读写这个管道会阻塞进程. 比如echo abcd > pipe2如果没人读的话, 会阻塞. 读一个空的pipe也会阻塞. 有名管道和nc 上面的图片实现了一个远程登陆shell的服务在服务端:cat pipe2 | /bin/sh -i 2>&1 | nc -l 1985 > pipe2 在client端:nc localhost 1985 解释: 服务端起了三个进程, 这三个进程是独立的, 并不存在先后顺序. cat pipe2的作用是, 如果有名管道pipe2有东西, 则输出到stdout; 如果没有则阻塞在read /bin/sh -i 2>&1从stdin读数据, 也就是前面cat pipe2的输出, 然后做shell交互, 输出到stdout nc -l 1985 > pipe2从stdin读数据, 也就是前面sh的输出, 再重定向到pipe2; 注意这里不是管道到pipe2 重定向到pipe2是写, 写了pipe就有东西了, cat pipe2就能读到数据了. 这是个\"乌洛波洛斯\"蛇, 头尾相连, 无限循环. nc -l 1985建立了双向的tcp连接, client的输入, 会被nc接收重定向到pipe2. /bin/sh的输出, 会被nc通过tcp连接, 在client端显示. nc默认用tcp, 用选项-u可以使用udp. -u在上面的例子里效果是一样的. shell检查一个脚本是否已经被include了 用type命令 $ type echo echo is a shell builtin $ type find find is /usr/bin/find # -t输出类型, 可以是`alias', `keyword',`function', `builtin', `file' or `' $ type -t find file $ type -t echo builtin 那么可以用type命令来看, 比如一个shell函数在另外一个文件里定义, 想看看是否它已经被包含了. type -t source_once >/dev/null || . /isam/scripts/prepare_script_env.sh sed sed的逻辑和awk一样, 也是按行处理的, 被处理的那一行叫做pattern空间; 而且, sed也有行匹配功能. 基本的命令格式是: sed -r -n -e '行定址/{命令1;命令2}' file 其中: -E, -r, --regexp-extended 使用扩展正则 -n, --quiet, --silent 不自动打印pattern空间. 默认每行都打印, 即使不匹配的行也打印; 区别是匹配到的行, 执行了命令才打印. 行定址见下文. 命令两侧的大括号{}可以省略 向sed传递变量 用双括号就行: instacne=yingjieb_devtool_vscode sed -e \"/$instacne /d\" test sed使用记录 # 使用grep先正则匹配, 然后用sed删除匹配到的字符串(即用空串替换) bzcat build.log.bz2 | grep -E '\\[DEBUG\\][[:space:]]*(# )?CT_' | sed s'/\\[DEBUG\\] //' sed命令 sed命令的对象是当前的pattern空间, 大部分情况是正在处理的那行. sed命令如果没有指定address, 就会对所有行操作. 如果有指定address区间, 对区间内的所有行操作. Sed commands can be given with no addresses, in which case the command will be executed for all input lines; with one address, in which case the command will only be executed for input lines which match that address; or with two addresses, in which case the command will be executed for all input lines which match the inclusive range of lines start‐ ing from the first address and continuing to the second address. 0地址命令 : label 用于后续的跳转label命令, 比如b或t命令 0地址或1个地址命令 = 打印行号 a \\text append text i \\text 插入text q [exit-code] 退出 r filename 追加filename的内容 可以使用定址的命令: b label 跳转到label c \\text 使用text替换pattern space, text的换行前面加\\ d 删除pattern space h H Copy/append pattern space to hold space. g G Copy/append hold space to pattern space. l List out the current line in a ``visually unambiguous'' form. n N Read/append the next line of input into the pattern space. p Print the current pattern space. P Print up to the first embedded newline of the current pattern space. 只打印一行 s/regexp/replacement/ 替换 w filename Write the current pattern space to filename. x Exchange the contents of the hold and pattern spaces. y/source/dest/ Transliterate the characters in the pattern space which appear in source to the corresponding character in dest. sed匹配2行之间的内容 some.log里面, 保留abc和efg之间的行, 删掉其他行 sed -e '/abc/,/efg/!d' some.log 这里!表示逻辑反, 否则会删掉之间的行. 提取文件特定行 grep方式 cat ddr_test.log | egrep \"Evaluating Read-Leveling Scoreboard|Initializing cgroup subsys|EDAC MC.:.. [UC]E DIMM\" > ddr_test.log.analysis 但是有个缺陷, 不能提取连续的多行信息. 可能grep是按行处理的. sed方式 $ sed -rn -e '/Evaluating Read-Leveling Scoreboard/,/Rlevel Rank/p' -e '/Initializing cgroup subsys/p' -e '/EDAC MC.:.. [UC]E DIMM/p' ddr_test.log | sed -r -e '/Evaluating Read-Leveling Scoreboard/i ==============' | sed 's/^M//' > ddr_test.log.analysis $ sed -rn -e '/Cavium Inc. OCTEON SDK version/,/DRAM: 2 GiB/p' -e '/Initializing cgroup subsys/p' -e '/EDAC MC.:.. [UC]E DIMM/p' ddr_test.log | cut -d' ' -f 4- | sed -r -e '/Cavium Inc. OCTEON SDK version/i \\\\n==============' | sed 's/^M//' > ddr_test.log.analysis sed的定址可以达到此目的 解释如下: -r 使用扩展正则 -n 不打印pattern空间 -e 多重操作. 注意, sed会把匹配到的行全部进行-e后面的command, 所以多个-e的操作应该是互不影响的 /pattern1/,/pattern2/ 匹配范围 p 打印模式空间 /pattern/i \\text 在pattern之前插入text, a是在之后插入 sed 's/^M//' 是删除^M, 输入^M的方法是先ctrl+v, 在ctrl+m sed正则表达式 注意: sed -r 选项直接可以使用扩展正则 默认使用basic regexp, 但也能解释\\|',+', \\?',`', \\'',\\\\>',\\b', \\B',\\w', and `\\W' 比如 `x\\+' matches one or more occurrences of `x'. `abc\\|def' matches either `abc' or `def'. 在/regexp/后面加I可以大小写不敏感, 比如 /regexp/Ip, 打印匹配regexp的行, 大小写不敏感 比如查找所有源文件, $ find -type f | sed -n '/\\.\\([chs]\\)\\1\\{0,1\\}\\(pp\\)\\?$/Ip' ./test.c ./test.h ./test.cc ./test.hh ./test.cpp ./test.hpp ./test.s ./test.S ./test.C ./test.H sed定址替换 sed -i -e '/# GENERIC_SERIAL$/s%^\\(.*\\)::.*#%\\1::respawn:/usr/bin/chrt -r 30 /bin/sh -l #%' $targetdir/etc/inittab sed 中的操作符比如s或者d, 都可以指定范围, 即定址. 不定址的操作默认是对全部行. 定址有一下几种: addr1 addr1所在行 addr1,addr2 所有addr1和addr2之间的行. 特别的, $代表最后一行 first~step 比如1~2p会打印所有奇数行 addr1,~N 和上面差不多意思 /regexp/ 所有匹配到regexp的行 \\cregexpc 和上面差不多, 但c可以是任意字符, 用于分隔 addr1,+N addr1 所在行以及下面连续N行 sed删除 sed -i -n -e '/^#OUTPUT-MARKER-BEGIN/,/^#OUTPUT-MARKER-END/d; p' $targetdir/etc/init.d/rcS sed替换引用 sed -i -e \"s%#!/bin/sh%&${output_redirection}%\" $targetdir/etc/init.d/rcS sed的分组匹配, 用()分组, 用\\1引用 echo /repo/yingjieb/fdt063/sw/vobs/dsl/sw/flat/fpxt-b_OFLT_MAIN/src/bcm_commands.c | sed 's!\\(.*/flat/[^/]*\\).*!\\1!g' awk shell变量传给awk 向awk传入变量, 用-v, shell变量用双引号括起来:-v td=\"$TimeDiff\" 再说patten 一般的pattern是这样的: awk '/search regex pattern1/ {Actions} /search regex pattern2/ {Actions}' file //中间的是regex pattern 也可以不用//, 其实{}前面的都是pattern 比较表达式也可以做pattern#最后一个字段不是A则执行 awk '$NF != \"A\" { print $0 }' BEGIN核END也是特殊的patternawk 'BEGIN { n=5 } NR==n { print $0 } END { print $0 }' pattern可以是个范围, pattern1, pattern2: pattern1匹配到则开闸放水, pattern2匹配到则关闸. 在开关闸之间做action awk在if里匹配 cat log/top.log | awk '{printf NR\" \"; {if($5 ~ /.*m/) printf $5; else printf $5/1024} printf \" \" $8 \"\\n\"}' | tr -d 'm' 这里的if($5 ~ /.*m/)就是正则匹配, 用~和/patten/的形式 awk支持浮点 bash只支持整数运算, 而awk支持浮点 #比如ping.log最后一行 64 bytes from 5.5.5.12: icmp_seq=11 ttl=64 time=0.187 ms #我想比较time是否大于某个值, 因为time是个浮点, 用bash直接比较会出错 $ tail ping.log -n 1 | awk -F\" *|=\" '{if ($10>0.1) print $10}' 0.187 #改成0.2则无输出 $ tail ping.log -n 1 | awk -F\" *|=\" '{if ($10>0.2) print $10}' awk逻辑与 这样写比下文的ss -ant |awk '{if(NR>1)++s[$1]} END {for(k in s) print k,s[k]}'更简洁一些 #打印五到十行，并在前面加上行号 awk -F: 'NR>=5 && NR awk多行解析 比如nmap的输出如下, 想解析ip和mac的对应关系 Nmap scan report for 10.239.120.208 Host is up (0.00049s latency). MAC Address: EC:B1:D7:2F:90:67 (Unknown) Nmap scan report for 10.239.120.209 Host is up (0.00019s latency). MAC Address: 34:64:A9:CF:8E:62 (Unknown) Nmap scan report for 10.239.120.212 Host is up (0.00020s latency). MAC Address: 8C:FD:F0:06:8B:A1 (Qualcomm Incorporated) sudo nmap -n -sP 10.239.120.1/24 | awk '/Nmap scan report/{printf $5;printf \" \";getline;getline;print $3;}' 重点是getline 另外一种写法我认为更好: sudo nmap -n -sP 10.239.120.1/24 | awk '/Nmap scan report for/{printf $5;}/MAC Address:/{print \" => \"$3;}' | sort awk分组提取 CentOS 7.3 $ cat log/test_report.csv | grep ^[0-9] 1,127.0.0.1,50,500000,10,1,1,set, 81024 1,127.0.0.1,50,500000,10,1,1,get, 89078 1,127.0.0.1,50,25000000,10,1,100,get, 315923 2,127.0.0.1,50,500000,10,1,1,set, 160236 2,127.0.0.1,50,500000,10,1,1,get, 174584 2,127.0.0.1,50,25000000,10,1,100,get, 616733 4,127.0.0.1,50,500000,10,1,1,set, 310916 4,127.0.0.1,50,500000,10,1,1,get, 333704 4,127.0.0.1,50,25000000,10,1,100,get, 1155443 8,127.0.0.1,50,500000,10,1,1,set, 617204 8,127.0.0.1,50,500000,10,1,1,get, 640997 8,127.0.0.1,50,25000000,10,1,100,get, 2244430 16,127.0.0.1,50,500000,10,1,1,set, 433805 16,127.0.0.1,50,500000,10,1,1,get, 435868 16,127.0.0.1,50,25000000,10,1,100,get, 4253953 #现在想对上面的输出, 按照第一列的信息整理 #tmp[$1]=tmp[$1]\",\"$9是说把tmp[$1]拼接上第九个字段, 还赋值回tmp[$1], 这就有点像PATH=xxxxx:$PATH awk -F, '{tmp[$1]=tmp[$1]\",\"$9}; END{ for(i in tmp) {print i tmp[i]}}' | sort -h 1, 81024, 89078, 315923 2, 160236, 174584, 616733 4, 310916, 333704, 1155443 8, 617204, 640997, 2244430 16, 433805, 435868, 4253953 awk变量 CentOS 7.3 $ awk '{s+=$1} END {print s}' log/*.csv 1.18365e+07 CentOS 7.3 $ awk '{s+=$1} END {printf(\"%d\\n\", s)}' log/*.csv 11836539 s是个变量, 直接用, 不加$, 那么和字符串的区别在于字符串需要加双引号 print默认用科学计数法 awk数组 $ ss -ant |awk '{if(NR>1)++s[$1]} END {for(k in s) print k,s[k]}' LISTEN 15 ESTAB 10 注: 数组的下标可以是数字也可以是字符串, ++s[$1]是统计个数 awk字符串替换 for f in log.fio*; do echo -n \"$f \"; awk '/IOPS/ {sub(\",\",\"\",$2);match($4,\"[0-9]*MB/s\",arr);printf \"BW=%s %s \",arr[0],$2} /95.00th/ {print $2 $3, $8 $9}' $f; done | column -t 解释: awk 后面斜杠中间的部分是匹配字符串, 匹配到的行才做后面的事情 match函数可以传入arr, arr[0]表示匹配到的字符串, 如果正则里面有分组标记(), 则arr[1], arr[2]依次是子分组awk '/search pattern1/ {Actions} /search pattern2/ {Actions}' file awk '{pattern + action}' {filenames}, 按行处理, 对匹配patten的行, 顺序执行{}里面的操作, - patten就是//里面的东西 - $0代表整行,$1是第一个字段 sub(match, replace, string)是字符串替换, 上面的sub(/,/,\"\",$2)也是可以的, 效果一样. BEGIN是说在扫描之前执行的, 相对的END是在最后都扫描完了再执行的 OFS是输出的分隔符, FS是输入的分隔符, 默认都是space print输出字符串要加\"\", 比如print \"hello\" echo -n 不换行 printf不换行, 而print换行 awk的条件判断和数字运算 cat iperf3_client_x710.log | awk '{if($8==\"Mbits/sec\") printf $7\" \";if ($8==\"Gbits/sec\") printf $7*1024\" \"}' awk执行其他程序 $ awk '{system(\"echo \"$1 \" and \"$2)}' ../linklist awk替换命令 $ echo $var | awk '{sub(\" \", \"_\", $0); printf(\"%s\\n\", $0);}' $ echo $var | awk '{gsub(\" \", \"_\", $0); printf(\"%s\\n\", $0);}' shell管道和循环 for f in `find -name *.so`; do echo $f; readelf -h $f | grep Flag | grep fp64; done > so.log for里面可以直接用pipe done后面可以直接跟重定向 看一个interface是否存在 用/proc/net/dev ~ # cat /proc/net/dev Inter-| Receive | Transmit face |bytes packets errs drop fifo frame compressed multicast|bytes packets errs drop fifo colls carrier compressed dummy0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 npi1: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 loop1: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 lo: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 npi2: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 loop2: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 bond0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 eth0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 agl0: 123857375 91502 0 0 0 0 0 6 4491714 52744 0 0 0 0 0 0 npi3: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 loop3: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 npi0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 loop0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 eth1: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 用ifconfig intf返回值 ~ # ifconfig itefwd ifconfig: itefwd: error fetching interface information: Device not found ~ # echo $? 1 ~ # ifconfig eth0 eth0 Link encap:Ethernet HWaddr 00:BA:0B:AB:00:0A BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) ~ # echo $? 0 awk计算时间差 # sudo perf script | grep -n1 netdev_send 207567- pmd8 6965 [013] 111673.977146: probe_ovs:netdev_rxq_recv: (698e80) 207568: pmd8 6965 [013] 111673.977193: probe_ovs:netdev_send: (698fd8 #第一个awk得出时间字段, 比如111673.977146: 第二awk用分隔符集合.或:在NR除4余2的时候, 打印$2-t; 而t每行都保存 sudo perf script | grep -n1 netdev_send | awk '{print $5}' | awk -F\"[.:]\" 'NR%4==2 {print $2-t} {t=$2}' # 结果 47 19 43 19 42 19 42 ping延迟大于0.5ms触发动作 ping 5.5.5.11 | tee ping.log tail ping.log -n 1 | awk -F\" *|=\" '{if ($10>0.5) {printf \"ping latency %s ms\\n\", $10; system(\"sudo perf sched record -a\")}}' 注: awk也支持-F\"[.:]\"的方式来指定分隔符, 这里指用.和:分割. while true do #用[[ $(command) ]]来判断command是否有输出 if [[ $(tail ping.log | awk -F\" *|=\" '{if ($10>0.1) print $10}') ]];then sudo perf sched record -a exit fi sleep 10 done 计算cpu掩码, mask bitmask() { #eg. 0,5,8-11 17,26-30 return 7c020f21 local bm=0 for arg in $(echo $* | tr ',' ' ');do #[ expression ] && statement1 || statement2 is equal to if expression then statement1 else statement2 #for i in $([ $(echo \"$arg\" | cut -d'-' -f1) == $arg ] && echo $arg || echo $arg | tr '-' ' ' | xargs seq);do #for i in $(seq ${arg%-*} ${arg#*-});do for ((i=${arg%-*};i>1,i++));do #这里的for的循环体为空, 用:表示空操作. for不能没有do ... done for ((h=l=i; x&1; x = x>>1,i++,h++));do :;done #双小括号里面是C格式的运算, 变量前可以不要$; 也可以用作逻辑判断 ((h - l == 1)) && echo -n \"$l \" ((h - l > 1)) && echo -n \"$l-$((h-1)) \" done echo } shell的进程创建 ls -l /proc/self是当前的进程号 echo $$显示当前进程号 这两个不是一回事, echo是shell内建命令, 不会起子进程; 而ls是外部命令, shell会folk子进程来跑外部命令; 所以这俩的进程号不一样, 比如下面一个是41427, 一个是4141 [root@rep2-130 debug]# echo $$ 41427 [root@rep2-130 debug]# ls -l /proc/self lrwxrwxrwx 1 root root 0 Jan 1 1970 /proc/self -> 4141 其次, &&逻辑与的操作, 也不影响shell创建新进程的逻辑. 目前我的理解是, 外部命令会创建新进程. [root@rep2-130 debug]# ls -l /proc/self && ls -l /proc/self && ls -l /proc/self lrwxrwxrwx 1 root root 0 Jan 1 1970 /proc/self -> 3926 lrwxrwxrwx 1 root root 0 Jan 1 1970 /proc/self -> 3927 lrwxrwxrwx 1 root root 0 Jan 1 1970 /proc/self -> 3928 如果想在当前进程下执行命令, 用exec, 会用后面传的命令替换当前shell进程. 注意如果exec写在一个脚本里, 那么下面的行没有机会执行, 因为当前shell被替换掉了 eval执行命令的效果和shell直接执行一样, 只是多了输入解析这一步. 粘贴多行文本管道后再用后续命令处理 # 这里\"和\"空格*\"来分割, strtonum把16进制转成10进制计算, awk不认16进制计算 cat | *\" '{printf \"%s %s %dK\\n\",$2,$3,(strtonum($3)-strtonum($2))/1024}' 0xffff9d070000->0xffff9d080000 at 0x03630000: load100 ALLOC LOAD READONLY HAS_CONTENTS 0xffff9d080000->0xffff9d880000 at 0x03640000: load101 ALLOC LOAD HAS_CONTENTS 0xffff9d880000->0xffff9d890000 at 0x03e40000: load102 ALLOC LOAD READONLY HAS_CONTENTS 0xffff9d890000->0xffff9e090000 at 0x03e50000: load103 ALLOC LOAD HAS_CONTENTS 0xffff9e090000->0xffff9e0a0000 at 0x04650000: load104 ALLOC LOAD READONLY HAS_CONTENTS 0xffff9e0a0000->0xffff9e8a0000 at 0x04660000: load105 ALLOC LOAD HAS_CONTENTS 0xffff9e8a0000->0xffff9e8b0000 at 0x04e60000: load106 ALLOC LOAD READONLY HAS_CONTENTS 0xffff9e8b0000->0xffff9f0b0000 at 0x04e70000: load107 ALLOC LOAD HAS_CONTENTS 0xffff9f0b0000->0xffff9f0c0000 at 0x05670000: load108 ALLOC LOAD READONLY HAS_CONTENTS 0xffff9f0c0000->0xffff9f8d0000 at 0x05680000: load109 ALLOC LOAD HAS_CONTENTS 0xffff9f8d0000->0xffff9f8d0000 at 0x05e90000: load110 ALLOC 0xffff9f910000->0xffff9f920000 at 0x05e90000: load111a ALLOC LOAD READONLY CODE HAS_CONTENTS EOF 关系数组 sed 和 awk 改进版 awk多维数组 要解析的文本样式: $ sudo ovs-appctl dpctl/show --statistics netdev@ovs-netdev: lookups: hit:0 missed:0 lost:0 flows: 0 port 0: ovs-netdev (tap) RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 aborted:0 carrier:0 collisions:0 RX bytes:0 TX bytes:0 port 1: dpdkp0 (dpdk: configured_rx_queues=4, configured_rxq_descriptors=2048, configured_tx_queues=9, configured_txq_descriptors=2048, lsc_interrupt_mode=false, mtu=1500, requested_rx_queues=4, requested_rxq_descriptors=2048, requested_tx_queues=9, requested_txq_descriptors=2048, rx_csum_offload=true) RX packets:0 errors:0 dropped:0 overruns:? frame:? TX packets:0 errors:0 dropped:0 aborted:? carrier:? collisions:? RX bytes:0 TX bytes:0 port 2: dpdkvhostuser1 (dpdkvhostuserclient: configured_rx_queues=4, configured_tx_queues=4, mtu=1500, requested_rx_queues=4, requested_tx_queues=4) RX packets:0 errors:0 dropped:0 overruns:? frame:? TX packets:0 errors:? dropped:0 aborted:? carrier:? collisions:? RX bytes:0 TX bytes:0 port 3: dpdkvhostuser0 (dpdkvhostuserclient: configured_rx_queues=4, configured_tx_queues=4, mtu=1500, requested_rx_queues=4, requested_tx_queues=4) RX packets:0 errors:0 dropped:0 overruns:? frame:? TX packets:0 errors:? dropped:0 aborted:? carrier:? collisions:? RX bytes:0 TX bytes:0 port 4: ovsbr0 (tap) RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 aborted:0 carrier:0 collisions:0 RX bytes:0 TX bytes:0 换了命令, 重新改了思路; 这次不用shell关系数组, 但会用到awk多维数组 ovs-appctl dpctl/show > /dev/null if [ $? -ne 0 ]; then printf \"execution failed, you may need sudo?\\n\" exit 1 fi prep () { #string #grep -o是说只输出正则匹配的部分; 而且匹配到的输出都是单独一行, 便于后续处理 # awk的 -F [ :]是说用空格和:做分隔符;后面的NR表示行号, 从1开始; NF是当前行的field个数 #a[port,$1,$i]=$(i+1), 这是个三维数组, 但awk内部会把下标都连起来, 比如foo[5,12] = \"value\", 内部变成foo[\"5@12\"]=\"value\", 这里的@是个不可见的符号(SUBSEP) ###grep后的文本: #port 0: ovs #RX packets:0 errors:0 dropped:0 overruns:0 frame:0 #TX packets:0 errors:0 dropped:0 aborted:0 carrier:0 ### #三维数组是要把报文统计的数值用三元(port名, 方向, 统计项名称)来标记, 比如a[\"ovs\",\"RX\", \"packets\"]=0 ###最后打印出来每行都是如下形式的统计 #ovs TX aborted:0 #dpdkp1 RX dropped:0 #dpdkp1 RX packets:170 #dpdkvhostuser0 RX dropped:0 ### echo \"$1\" | grep -Eo \"port [0-9]*: [[:alnum:]]*|RX packets.*|TX packets.*\" | tr \"?\" \"0\" \\ | awk -F'[ :]' '{if(NR%3==1) port=$4; else{for(i=2;i 原始版 ovs-vsctl list interface > /dev/null if [ $? -ne 0 ]; then printf \"ovs-vsctl execution failed, you may need sudo?\\n\" exit 1 fi #注意cmd要用单引号, 单引号不会展开变量 #sed -r是用扩展正则, 这里用到了替换, 反向引用等, sed会对行依次进行-e后面的处理, 处理的那行叫做patten空间 cmd='(ovs-vsctl list interface && echo date: $(date +%s%6N)) | grep -E \"^name|^statistics|^date\" | sed -r -e \"s/,|\\{|\\}//g\" -e \"s/name *: (.*)/\\1:/g\" -e \"s/statistics *://g\"' #t1 t2 t3不加引号, 视为单独元素, 用for可以遍历; 加了\"\"就变成一个元素了 for t in t1 t2 t3; do test $t = t1 && v1=$(eval $cmd) #本来该用if, 这里用test和&&做简化处理; 主进程会等着sleep执行完才往后执行 test $t = t2 && sleep 10 && v2=$(eval $cmd) if test $t = t3; then i=0 #声明关系数组, 关系数组就是可以用string做下标的数组 declare -A map1 map2 #NF是awk解析的feild个数, 每行 v1=$(echo \"$v1\" | awk -F: '{printf $0; if(NF==1 || $1==\"date\") print \"\"}') #每行类似于\"dpdkp1\": rx_bytes=865352722 rx_dropped=0 rx_errors=0 rx_packets=14419925 tx_bytes=0 tx_dropped=0 tx_errors=0 tx_packets=0 #先把它以第一个空格为界分割为两部分:k和v, 其实v是第一个空格后面所有的部分 while read k v; do #关系数组赋值 map1[$k]=$v #这里用 shell关系数组 -- 或者说是list 参考: https://www.artificialworlds.net/blog/2012/10/17/bash-associative-array-examples/ 需要bash版本高于4 declare -A map $ map[foo]=bar $ echo ${map[foo]} bar $ K=baz bai@CentOS-43 ~/repo/save $ map[$K]=quux bai@CentOS-43 ~/repo/save $ echo ${map[$K]} quux 遍历 $ declare -A MYMAP=( [foo a]=bar [baz b]=quux ) $ echo \"${!MYMAP[@]}\" # Print all keys - quoted, but quotes removed by echo foo a baz b $ # Loop through all keys in an associative array $ for K in \"${!MYMAP[@]}\"; do echo $K; done foo a baz b $ # Loop through all values in an associative array $ for V in \"${MYMAP[@]}\"; do echo $V; done bar quux shell数组 #括号括起来定义数组 my_array=(A B \"C\" D) #或者 array_name[0]=value0 array_name[1]=value1 array_name[2]=value2 #数组元素 echo \"第一个元素为: ${my_array[0]}\" echo \"第二个元素为: ${my_array[1]}\" #所有元素 echo \"数组的元素为: ${my_array[*]}\" echo \"数组的元素为: ${my_array[@]}\" #数组长度 echo \"数组元素个数为: ${#my_array[*]}\" echo \"数组元素个数为: ${#my_array[@]}\" #数组遍历 for data in ${array[@]} do echo ${data} done 又比如: #这里ETHTOOL是个数组, 而T_PKT也是数组, 由入参index来控制 update_stats () { # $name $index TS_LAST[$2]=${TS[$2]} R_PKT_LAST[$2]=${R_PKT[$2]} R_BYTE_LAST[$2]=${R_BYTE[$2]} T_PKT_LAST[$2]=${T_PKT[$2]} T_BYTE_LAST[$2]=${T_BYTE[$2]} ETHTOOL=($(ethtool -S $1 | awk '/tx_packets_phy/{print $2} /rx_packets_phy/{print $2} /tx_bytes_phy/{print $2} /rx_bytes_phy/{print$2}')) if [ -z \"$ETHTOOL\" ]; then ETHTOOL=($(ethtool -S $1 | awk '/tx_packets/{print $2} /rx_packets/{print $2} /tx_bytes/{print $2} /rx_bytes/{print$2}')) fi TS[$2]=$(date +%s%6N) # in usec T_PKT[$2]=${ETHTOOL[0]} R_PKT[$2]=${ETHTOOL[1]} T_BYTE[$2]=${ETHTOOL[2]} R_BYTE[$2]=${ETHTOOL[3]} } # set initial value index=0 for name in $NETIF; do update_stats $name $index ((index++)) done shell脚本解析文件, 输出可以导入到excel的文本 测了大约500次的stream, 想在excel上绘图. 原始数据格式 STREAM2 fill latency: 0.92 nanoseconds STREAM2 fill bandwidth: 121083.29 MB/sec STREAM2 copy latency: 2.12 nanoseconds STREAM2 copy bandwidth: 105697.16 MB/sec STREAM2 daxpy latency: 3.24 nanoseconds STREAM2 daxpy bandwidth: 103654.31 MB/sec STREAM2 sum latency: 1.57 nanoseconds STREAM2 sum bandwidth: 71472.48 MB/sec STREAM2 fill latency: 1.68 nanoseconds STREAM2 fill bandwidth: 66475.08 MB/sec STREAM2 copy latency: 2.11 nanoseconds STREAM2 copy bandwidth: 105921.94 MB/sec STREAM2 daxpy latency: 3.24 nanoseconds STREAM2 daxpy bandwidth: 103562.46 MB/sec STREAM2 sum latency: 1.57 nanoseconds STREAM2 sum bandwidth: 71506.36 MB/sec 用下面的脚本可以输出一个excel认识的文本 for i in \"fill latency\" \"copy latency\" \"daxpy latency\" \"sum latency\" \"fill bandwidth\" \"copy bandwidth\" \"daxpy bandwidth\" \"sum bandwidth\"; do (printf \"$i \\t\" && cat stream*.log | awk \"/$i/\"'{printf $4 \"\\t\"}' && echo) >> test.txt; done for后面的东西用空格分割 awk是按行操作的, 比如第一行会一次执行多个{ }操作 awk里面用printf输出没有换行 shell变量要传入awk, 用双引号, 上面是用双引号括的/pattern/, awk \"/$i/\"'{printf $4 \"\\t\"}'注意后面不加空格. 参考https://www.gnu.org/software/gawk/manual/html_node/Using-Shell-Variables.html shell的小括号可以一起重定向 脚本输出数据示例: 一共八行 fill latency 0.92 1.68 1.70 1.67 1.69 1.69 0.92 1.67 1.65 copy latency 2.12 2.11 2.12 2.27 2.25 2.23 2.22 2.27 2.11 daxpy latency 3.24 3.24 3.24 3.24 3.11 3.24 3.24 3.24 3.25 sum latency 1.57 1.57 1.55 1.57 1.56 1.57 1.57 1.57 1.57 fill bandwidth 121083.29 66475.08 66018.47 67102.43 66170.01 66209.27 copy bandwidth 105697.16 105921.94 105900.48 98852.60 99648.56 100382.3 daxpy bandwidth 103654.31 103562.46 103639.09 103740.30 108061.48 1036 sum bandwidth 71472.48 71506.36 72182.22 71490.27 71900.50 71472.48 shell处理命令行选项 注意shell变量的删除 插入操作 比如 var=${arg/#--no-} # remove all dashes for variable names: eval ${var//-}=0 while (($#)) do arg=$1 shift case \"${arg:-}\" in --verbose|-v) set -x ;; --help|-h|'') help exit 0 ;; --*\\=*) # make variables from options IFS='=' read var value shell也可以递归调用函数 下面这个例子的作用是深度清除git库下面的未被跟踪的文件, 包括其下面的子git库 #!/bin/sh gitpurge_r() { local cwd=`pwd` local subgit=$1 cd $subgit echo \"deep cleaning $subgit\" local subgits=\"`git clean -fdx | grep 'Skipping repository' | cut -d' ' -f3`\" if [ -n \"$subgits\" ]; then for g in $subgits; do gitpurge_r $g done fi cd $cwd } gitpurge_r . 改进版本 #!/bin/bash B=\"\\033[1;37;40m\" N=\"\\033[0m\" top_dir=`pwd` remote=`git remote -v | grep fetch | awk '{print $2}'` repos_branch='./master bootloader/edk2/thunder-stable bootloader/grub2/grub/master bootloader/trusted-firmware/atf/thunder-stable bootloader/u-boot/thunder-stable linux/kernel/linux-aarch64/thunder-stable' function reset_current() { remote_branch=`git branch -vv | grep \"\\*\" | sed -r 's/.*\\[(.*)\\].*/\\1/g' | cut -d: -f1` echo ===reseting with $remote_branch git reset --hard $remote_branch } for repo_branch in $repos_branch; do repo=`dirname $repo_branch` branch=`basename $repo_branch` cd $top_dir if [ ! -d $repo ]; then echo cloning $repo cd `dirname $repo` if [ $repo == bdk ]; then git clone $remote/$repo else git clone -b fae $remote/$repo fi fi cd $top_dir/$repo echo -e $B\">>>`pwd`\"$N case \"$1\" in purge) echo ==deep cleaning... git clean -fdx ;; fetch) echo ==fetching from remote... git fetch --all ;; merge) echo ==merging workspace with $branch... git merge origin/$branch --no-commit ;; #upsync MUST be only used on my mint mechine upsync) echo ==fetching all git fetch --all echo ==reseting with remote master reset_current echo ==chekouting $branch git checkout $branch echo ==reseting with remote stable reset_current echo ==going back to master git checkout - ;; *) echo ==doing [\"$@\"] \"$@\" ;; esac echo done local system monitor ./sysmonitor.sh -f test.f -t \"just want to test it\" #! /bin/bash B=\"\\033[1;37;40m\" N=\"\\033[0m\" file= interval=5 sleepsec=10 title= while getopts \"f:i:s:t:\" arg #: needs para do case $arg in f) file=$OPTARG #$OPTARG is the para ;; i) interval=$OPTARG ;; s) sleepsec=$OPTARG ;; t) title=$OPTARG ;; ?) echo \"unkonw argument\" exit 1 ;; esac done #exec &> $output #output to file function do_syscollect() { echo; echo $title echo -e $B\"start system statistics collecting\"$N dmesg -c while test -f \"$file\"; do echo; echo -e $B\"========================collecting system status===========================\"$N echo; echo -e $B\"===date\"$N date echo; echo -e $B\"===dmesg\"$N dmesg -c echo; echo -e $B\"===top\"$N top -bn1 | head -15 echo; echo -e $B\"===sar\"$N sar -n DEV -u -dp -r $interval 1 | grep Average sleep $sleepsec done } do_syscollect | ts system monitor for pangu $ cat statistics.sh #! /bin/bash B=\"\\033[1;37;40m\" N=\"\\033[0m\" echo -e $B\"start system statistics collecting\"$N ./alldo.sh dmesg -c while true; do echo -e $B\"========================collecting system status===========================\"$N echo; echo -e $B\"===date\"$N ./alldo.sh 'date' echo; echo -e $B\"===dmesg\"$N ./alldo.sh 'dmesg' echo; echo -e $B\"===top\"$N ./alldo.sh 'top -bn1 | head -15' echo; echo -e $B\"===pangu\"$N ./alldo.sh \"ps -ef | egrep 'pangu|tubo|nuwa_agent|deploy_agent|chunkserver'\" echo; echo -e $B\"===sar\"$N ./alldo.sh 'sar -n DEV -u -dp -r 5 1 | grep Average' sleep $((60*1)) done $ cat logstat.sh #! /bin/bash B=\"\\033[1;37;40m\" N=\"\\033[0m\" logfile=${1:-log} ./statistics.sh | ts | tee $logfile $ cat alldo.sh #! /bin/bash B=\"\\033[1;37;40m\" N=\"\\033[0m\" atlocal=F servers=\" yingjie@192.168.85.10 byj@localhost \" cvmservers=\" root@10.97.219.6 root@10.97.219.55 root@10.97.219.21 root@10.97.219.44 root@10.97.219.53 root@10.97.219.50 root@10.97.219.214 root@10.97.219.13 root@10.97.219.47 root@10.97.219.69 \" if [ \"$1\" = \"-l\" ]; then atlocal=T shift fi for i in $cvmservers; do ip=${i#*@} echo echo -e $B\">>>$i\"$N if [ \"$atlocal\" = \"T\" ]; then eval \"$*\" else ssh $i \"$*\" fi done 增加fedora分区的脚本 这里面有shrink原分区(ubuntu), 增加fedora分区并拷贝fedora的fs work_dir=`pwd` dev=${1:-/dev/sdc} ubuntu_size=${2:-500G} tar_fedora=${3:-fedora-with-native-kernel-repo-gcc-update-to-20150423.tar.bz2} if [ ! -b $dev ]; then echo \"$dev not found\" exit 1 fi if [ -b ${dev}3 ]; then echo \"fedora already exists, nothing to do\" exit 0 fi if [ ! -f $tar_fedora ]; then echo \"file $tar_fedora not found\" exit 1 fi echo \"resizing ubuntu fs\" e2fsck -f ${dev}2 -y resize2fs ${dev}2 $ubuntu_size echo \"resizing ubuntu partition\" gdisk $dev etc/fstab ##grub #sed -i \"/set timeout/a\\\\\\nmenuentry 'Thunder Fedora Boot' {\\n\\tlinux /boot/vmlinuz root=/dev/sda3 console=ttyAMA0,115200n8 earlycon=pl011,0x87e024000000 coherent_pool=16M rootwait rw transparent_hugepage=never\\n\\tboot\\n}\\n\" boot/grub/grub.cfg #find lib/modules -name rtc-efi.ko | xargs -i mv {} {}.bak #cd .. #umount mnt sync cd $work_dir "},"notes/python_记录.html":{"url":"notes/python_记录.html","title":"python记录","keywords":"","body":" class的数据成员不用声明 python 调用其他可执行文件 一个节拍发生器的算法 补充:自然对数 解析寄存器 secureCRT停止所有linux启动脚本 class的数据成员不用声明 #!/usr/bin/python3 #类定义 class people: #定义基本属性 name = '' age = 0 #定义私有属性,私有属性在类外部无法直接进行访问 __weight = 0 #定义构造方法 def __init__(self,n,a,w): self.name = n self.age = a self.__weight = w def speak(self): print(\"%s 说: 我 %d 岁。\" %(self.name,self.age)) # 实例化类 p = people('runoob',10,30) p.speak() 下面的代码有没有第6行的name = ''都能正常运行, 结果都是 $ python3 test.py runoob 说: 我 10 岁。 如果同时把第17行的self去掉, 只保留name = n, 那么相当于声明了函数的局部变量. 执行时会报错: people类没有name成员 python 调用其他可执行文件 #返回值是uint16, 高8位是executable的返回值 ret = os.system(\"/path/to/executable para1 para2\") 一个节拍发生器的算法 log(1- x/1073741823)/-1 import math import random def test(rate, count): s = 0 for i in range(count): r = math.log(1 - random.uniform(0,0x3fffffff)/0x3fffffff)/-rate s += r print r print \"avg rate: \", s/count 这个函数的牛逼之处在于, 虽然有random操作, 但最后的发生rate的平均值都在rate左右如果按平均值来说, 即使把0x3fffffff改为10, 平均值也是1 >>> test(1, 140000) 0.999586366008 >>> test(1, 140000) 0.997003720261 >>> test(1, 140000) 1.00136841452 >>> test(1, 140000) 0.996789930059 >>> test(1, 140000) 1.00041864097 >>> test(1, 140000) 1.0004003745 >>> test(1, 140000) 1.00209053795 >>> test(1, 140000) 1.00115873931 >>> test(1, 140000) 0.997373828955 取自sysbench --tx-rate发生进程的算法, 这个进程每次先用这个函数算一个时间t, 然后sleep t的时间, 然后发令牌给其他线程;这样, 不管有多少个线程, 每个都在等令牌, 先到先得. 补充:自然对数 lim（1+1/x）^x＝e, e=2.71828 举个例子：年利率100%，存1年，1元钱最多能变成多少？ 如果存满1年，也就是n=1，那么1年后， 1(1+1/1)^1=2，1元变成2元； 如果半年一存，让这半年的利息在下半年也生利息，也就是n=2，存满1年后，式子应该写作 1(1+1/2)^2=2.25，1元变成2.25元，比第一种存法划算； 如果一个季度一存，每个季度的利息在后面的时间里也生利息，也就是n=4，式子写作 1*(1+1/4)^4 =2.44140625，比第二种存法还划算； 看上去，存的次数越多，每次存期越短，1年到期时的利息越多。但是数学告诉你，这个利息不是无限增加的，随着存的次数增多，1年后的本息合计趋于一个极限，也就是文中所提到的e。也就是说，在年利率为100%的情况下，不管你存得多么勤快，1年后1元钱最多变成e=2.71828182845904523536...元钱。 解析寄存器 def reg_decode64(val, high=63, low=0): reg = bin(val)[2:] reg64 = '0' * (64 - len(reg)) + reg field = reg64[-1-high:-1-low] + reg64[-1-low] print 'Bin:', field print 'Dec:', int(field, 2) print 'Hex:', hex(int(field, 2)) secureCRT停止所有linux启动脚本 def main(): crt.Screen.Synchronous = True while True: result = crt.Screen.WaitForStrings([\"ISAM:Press 'f' to enter UBOOT prompt\", \"Starting linux\", \"To interrupt normal boot\", \"/isam/user #\"]) if result == 1: crt.Screen.Send(\"f\\n\") if result == 2: at_linux_shell = 0 if result == 3 and at_linux_shell == 0: crt.Screen.Send(\"stop\\n\") if result == 4: at_linux_shell = 1 main() "},"notes/lua_记录.html":{"url":"notes/lua_记录.html","title":"lua记录","keywords":"","body":" pktgen lua脚本 pktgen lua脚本 package.path = package.path ..\";?.lua;test/?.lua;app/?.lua;../?.lua\" -- 加载Pktgen.lua, 该文件位于pktgen根目录下, 提供一些辅助函数 require \"Pktgen\"; function number2ip(number) -- string.format和printf挺像 local str=string.format(\"%08x\", number); -- 分组匹配, 连续赋值很赞 local s4,s3,s2,s1 = str:match(\"(%x%x)(%x%x)(%x%x)(%x%x)\"); -- ..是字符串连接 return string.format(\"%d.%d.%d.%d\", \"0x\"..s4,\"0x\"..s3,\"0x\"..s2,\"0x\"..s1); end function number2mac(number) local str=string.format(\"%012x\", number); local s6,s5,s4,s3,s2,s1 = str:match(\"(%x%x)(%x%x)(%x%x)(%x%x)(%x%x)(%x%x)\"); return string.format(\"%s:%s:%s:%s:%s:%s\", s6,s5,s4,s3,s2,s1); end function setFlow(port, pkt_size, nb_L2, nb_L3, nb_L4) pktgen.range.ip_proto(port, \"udp\"); pktgen.range.pkt_size(port, \"start\", pkt_size); pktgen.range.pkt_size(port, \"inc\", 0); pktgen.range.pkt_size(port, \"min\", pkt_size); pktgen.range.pkt_size(port, \"max\", pkt_size); pktgen.range.dst_mac(port, \"inc\", \"00:00:00:00:00:00\"); pktgen.range.src_mac(port, \"start\", \"00:00:00:00:00:01\"); pktgen.range.src_mac(port, \"inc\", \"00:00:00:00:00:01\"); pktgen.range.src_mac(port, \"min\", \"00:00:00:00:00:01\"); pktgen.range.src_mac(port, \"max\", number2mac(nb_L2)); pktgen.range.dst_ip(port, \"start\", \"0.0.0.1\"); pktgen.range.dst_ip(port, \"inc\", \"0.0.0.1\"); pktgen.range.dst_ip(port, \"min\", \"0.0.0.1\"); pktgen.range.dst_ip(port, \"max\", number2ip(nb_L3)); pktgen.range.src_ip(port, \"inc\", \"0.0.0.0\"); pktgen.range.dst_port(port, \"inc\", 0); pktgen.range.src_port(port, \"start\", 1); pktgen.range.src_port(port, \"inc\", 1); pktgen.range.src_port(port, \"min\", 1); pktgen.range.src_port(port, \"max\", nb_L4); pktgen.set_range(port, \"on\"); end -- run 64B signle flow 10s or 100000000 packets, full rate, log performance data to file \"whatever_64B_1L2-1L3-1L4_flow.data\" -- runFlowTest(\"whatever\", 0, 0, 100, 64, 1, 1, 1, 10, 100000000) -- run from pktgen shell -- Pktgen:/> load /home/bai/repo/save/pktgen/range-flow.lua -- Pktgen:/> lua 'runFlowTest(\"single\", 0, 0, 100, 64, 1, 1, 1, 10, 0)' -- Pktgen:/> lua 'runFlowTest(\"single\", 0, 0, 100, 64, 1, 1, 1, 0, 100000000)' -- Pktgen:/> lua 'runFlowTest(\"multi\", 0, 0, 100, 64, 2000, 128, 128, 10, 0)' function runFlowTest(mark, sendport, recvport, rate, pkt_size, nb_L2, nb_L3, nb_L4, duration, nb_pkts) sendport = tostring(sendport); recvport = tostring(recvport); local datafile = tostring(mark) .. \"_\" .. pkt_size .. \"B_\" .. nb_L2 .. \"L2-\" .. nb_L3 .. \"L3-\" .. nb_L4 .. \"L4_flow.data\" local file = io.open(datafile, \"w\"); pktgen.stop(\"all\"); pktgen.clr(); pktgen.set(sendport, \"rate\", rate); pktgen.set(sendport, \"count\", nb_pkts); pktgen.latency(\"all\", \"enable\"); setFlow(sendport, pkt_size, nb_L2, nb_L3, nb_L4); pktgen.start(sendport); print(\"Running flow test and collecting data to \" .. datafile); -- local如果在下面的repeat语句块里, 就只在该语句块内可见; local rateTx, rateRx; -- lua的table就是shell的关系数组, python的map local ppsTxTable = {}; local ppsRxTable = {}; local i = 0; repeat pktgen.delay(1 * 1000); rateTx = pktgen.portStats(sendport, \"rate\")[tonumber(sendport)]; rateRx = pktgen.portStats(recvport, \"rate\")[tonumber(recvport)]; i = i + 1; -- lua从1开始计数 ppsTxTable[i] = rateTx.pkts_tx; ppsRxTable[i] = rateRx.pkts_rx; until(i == duration or rateTx.pkts_tx == 0) pktgen.stop(sendport); pktgen.delay(1 * 1000); -- i//2是\"地板除法\", lua数字都是浮点, 所以使用\"地板除法\", 只保留整数部分. local ppsTx = ppsTxTable[i//2]; local ppsRx = ppsRxTable[i//2]; local statTx = pktgen.portStats(sendport, \"port\")[tonumber(sendport)]; local statRx = pktgen.portStats(recvport, \"port\")[tonumber(recvport)]; local num_tx = statTx.opackets; local num_rx = statRx.ipackets; local num_dropped = num_tx - num_rx; local statPkt = pktgen.pktStats(\"all\")[tonumber(recvport)]; -- file:write是个语法糖 file:write(\"Tx pps: \" .. ppsTx .. \"\\n\"); file:write(\"Rx pps: \" .. ppsRx .. \"\\n\"); file:write(\"Tx pkts: \" .. num_tx .. \"\\n\"); file:write(\"Rx pkts: \" .. num_rx .. \"\\n\"); file:write(\"Dropped pkts: \" .. num_dropped .. \"\\n\"); file:write(\"Min avg latency(usec): \" .. statPkt.min_latency .. \"\\n\"); file:write(\"Max avg latency(usec): \" .. statPkt.max_latency .. \"\\n\"); file:close(); pktgen.set(\"all\", \"rate\", 100); pktgen.set(\"all\", \"count\", 0); pktgen.set_range(\"all\", \"off\"); pktgen.latency(\"all\", \"disable\"); end "},"notes/shell_rds脚本阅读.html":{"url":"notes/shell_rds脚本阅读.html","title":"RDS脚本阅读","keywords":"","body":" simsim_charts脚本 process_data.sh create_charts.sh R语言 rds lua脚本 rds bash脚本 simsim_charts脚本 process_data.sh 使用方法 BENCH_SERIES=thunder_optimized_xfs MYSQL_TEMPLATES_NAME=optimized SYSBENCH_MAX_TIME=180 bash ./start_benchmarks.sh SYSBENCH_MAX_TIME=180 CHART_SERIES=results/{thx_optimized_60s,thx_network_60s,x86_baseline_60s} CHART_NAME=\"_optimized_vs_network_vs_x86\" sh ./process_data.sh SYSBENCH_MAX_TIME=180 CHART_SERIES=results/{thx_optimized_60s,thx_network_60s,x86_baseline_60s} CHART_NAME=\"_optimized_vs_network_vs_x86\" sh ./create_charts.sh 这个脚本是把所有的CHART_SERIES的tps和lat的相关信息, 全部提取到文件里 for series in $(eval echo $CHART_SERIES)里面eval echo $CHART_SERIES的作用是展开变量 $ CHART_SERIES=results/{thx_optimized_60s,thx_network_60s,x86_baseline_60s} $ echo $CHART_SERIES results/{thx_optimized_60s,thx_network_60s,x86_baseline_60s} $ eval echo $CHART_SERIES results/thx_optimized_60s results/thx_network_60s results/x86_baseline_60s 一个标准的shell从usage开始 usage() { cat for conf in A200 B5 C1 C2 C4 C8重点是in后面的集合就只是用空格隔开 要把一段脚本的输出重定向到文件, 可以这样 ( some commands ) > output-filename awk的例子 awk ' BEGIN {OFS=\",\"} /tps:/ { sub(\"\\\\[ *\", \"\", $0); sub(\"s]\",\"\",$1); sub(\",\",\"\",$5); sub(\"ms\",\"\",$12); print '\\\"$s\\\",\\\"$conf\\\",\\\"$threads\\\",$((counter*duration))'+$1,$1,\"tps\",$5; print '\\\"$s\\\",\\\"$conf\\\",\\\"$threads\\\",$((counter*duration))'+$1,$1,\"lat\",$12 }' $filename awk ' BEGIN {OFS=\",\"} /transactions:/ {sub(\"\\\\(\",\"\",$3); print '\\\"$s\\\",\\\"$conf\\\",\\\"$threads\\\",\\\"tps\\\",'$3} /approx./ {sub(\"ms\",\"\",$4); print '\\\"$s\\\",\\\"$conf\\\",\\\"$threads\\\",\\\"lat\\\",'$4}' $f awk '/search pattern1/ {Actions} /search pattern2/ {Actions}' file - awk '{pattern + action}' {filenames}, 按行处理, 对匹配patten的行, 顺序执行{}里面的操作 - patten就是//里面的东西 - $0代表整行,$1是第一个字段 - sub(match, replace, string)是字符串替换 - BEGIN是说在扫描之前执行的, 相对的END是在最后都扫描完了再执行的 - OFS是输出的分隔符, FS是输入的分隔符, 默认都是space - print输出字符串要加\"\", 比如print \"hello\"; 上面转义了\", 因为print后面接了单引号 输出文件的效果如 thunder_xfs,A200,1,tps,3737.49 thunder_xfs,A200,1,lat,75.43 thunder_xfs,A200,4,tps,5261.52 thunder_xfs,A200,4,lat,216.29 thunder_xfs,A200,8,tps,7595.05 thunder_xfs,A200,8,lat,313.97 thunder_xfs,B5,1,tps,245.66 thunder_xfs,B5,1,lat,25.24 thunder_xfs,B5,4,tps,715.88 thunder_xfs,B5,4,lat,39.76 thunder_xfs,B5,8,tps,1160.96 thunder_xfs,B5,8,lat,50.93 create_charts.sh R语言 先要安装R, 似乎不用装那么多 apt install r-base $ cat /etc/apt/sources.list deb http://mirror.bjtu.edu.cn/cran/bin/linux/ubuntu trusty/ apt install libxt-dev apt install libcurl4-openssl-dev apt install gfortran apt install libmpfr-dev apt install liblapack-dev apt install r-base apt install r-cran* 还要进R的shell install.packages('ggplot2', dep = TRUE) install.packages('gridExtra', dep = TRUE) install.packages('reshape2', dep = TRUE) install.packages('plyr', dep = TRUE) install.packages('Matrix', dep = TRUE) data.frame是个表格, 一般每个列都是同样类型的元素(似乎不是必须?), 而每行好像是条记录的感觉 > student student ID Name Gender Birthdate 1 11 Devin M 1984-12-29 2 12 Edward M 1983-5-6 3 13 Wenli F 1986-8-8 代码注释之tps和latency #sb是data.frame类型 sb 代码注释之variance sb rds lua脚本 注释 单行注释-- 多行注释 --[[ **************************************************************************** Input parameters: --simsim-databases = N: the number of databases to create/use (1 by default) **************************************************************************** --]] 感觉上lua和shell的语法类似 sysbench的lua脚本可以用db相关操作 db_query(\"DROP DATABASE IF EXISTS \" .. database_name) db_query(\"CREATE DATABASE \" .. database_name) 在db_query(\"BEGIN\")和db_query(\"COMMIT\")之间的东西就是一次transaction的内容 主要的东西在event里面, sysbench的runner线程会调用 void *runner_thread(void *arg) do execute_request(test, &request, thread_id) test->ops.execute_request(r, thread_id) sb_lua_op_execute_request(sb_request_t *sb_req, int thread_id) lua_getglobal(L, \"event\") //见下面 lua_pcall(L, 1, 1, 0) while ((request.type != SB_REQ_TYPE_NULL) && (!sb_globals.error) ); simsim里面, event里做的事情是很多insert到不同的表, 这些表的格式都是在prepare阶段准备好的. rds bash脚本 set -eu shell内建的命令, 可以用help xxx来看帮助, 比如help for 这里 -e: 如果有命令返回非零值则立刻推出 -u: 没定义的变量直接使用时当成错误 小括号和后台(&)的异同 相同的地方都是会新建一个子进程来执行, 那么既然是子进程, 里面的变量啦,路径啦都不会影响父进程. 不同点在与: 后台执行是非阻塞的, 而小括号是阻塞的; 后台进程id mysqld --defaults-file=$mysql_basedir/my.cnf \\ --user=root >/dev/null 2>&1 & pids[$i]=$! 这里面有两个知识点, $!是最新加入后台的进程id; pids是个数组, 展开后如:pids[1]=1022 如何打印大块文字? --用cat Starting a benchmark series with the following parameters: Data root directory: $BENCH_ROOT Benchmark series label: $BENCH_SERIES Single socket: $BENCH_SINGLE_SOCKET Results directory: $RESULTS_DIR sysbench directory: $SYSBENCH_DIR Configurations to run: $MYSQL_CONFIGURATIONS Subconfiguration for case C: $MYSQL_C_INSTANCES Threads combinations: $SYSBENCH_THREAD_LIST sysbench extra arguments: $SYSBENCH_SIMSIM_ARGS Single run duration: ${SYSBENCH_MAX_TIME}s EOF * wait用来等待所有的后台进程结束 不加参数是等待所有后台进程, 也可以这样 比如在for循环里 `job_ids=\"$job_ids $!\"` 在循环外面: `wait $job_ids` * sysbench测试mysql的时候, 支持不同的端口号;下面的SB_PORTS就是这么一个变量\"3001,3002,3003...\" ```shell SB_SOCKETS=\"$BENCH_ROOT/${conf}${instances}/data3001/tmp/mysql.sock\" SB_PORTS=\"3001\" for i in $(seq 2 $instances) do mysql_port=$((3000 + i)); mysql_basedir=$BENCH_ROOT/${conf}${instances}/data$mysql_port mysql_tmpdir=$mysql_basedir/tmp SB_SOCKETS=\"$SB_SOCKETS,$mysql_tmpdir/mysql.sock\" SB_PORTS=\"$SB_PORTS,$mysql_port\" done # SB_CONNECT_ARGS=\"--mysql-socket=$SB_SOCKETS\" SB_CONNECT_ARGS=\"--mysql-host=127.0.0.1 --mysql-port=$SB_PORTS\" 这里面SB_PORTS=\"$SB_PORTS,$mysql_port\"相当于一个列表变量 "},"notes/system_原理杂记.html":{"url":"notes/system_原理杂记.html","title":"原理杂记","keywords":"","body":" seccomp系统调用 系统权限 smaps解析性能 打开smaps文件本身 加上字符串操做 结论 使用其他用户启动进程 改变文件的owner为nobody:nogroup, 设置setuid属性 ruid euid 什么是uid euid? 补充 实验 然后用普通user启动 用root启动 进程的权限是看ruid, 而不是euid golang权限降级 什么是defunct进程? cgroup v2 进程 线程 控制器使能 不推荐动态迁移pid 资源限制类型 控制器类型 CPU 内存 IO PID Cpuset 配置文件交互 和V1的对比 系统内存占用分析 其他统计 vm参数 文件缓存 CPU占用率分析 per CPU统计 user + sys + softirq + idle + iowait = 100 softirq现象 结论 补充 系统调用都会触发调度吗? Preemption and Context Switching User Preemption Kernel Preemption 调度代码 一些系统调用, 可能会阻塞, 此时会触发调度 调度器的参考文章 signal的默认行为和打断系统调用 默认行为 signal和系统调用 内核收报文的时间片算在哪里? 背景: 驱动中断在哪里执行? 中断线程化后的CPU load 到底什么是中断上下文? 软中断上下文 softirq激活 ksoftirqd线程 上下文分类 收报的时间算在哪里? socket什么情况下会发生短读short read/partial read? socket通信的时候, 要在应用侧做字节序转换吗? socket的stream模式和datagram模式有什么不同? socket基础 SOCK_STREAM SOCK_SEQPACKET SOCK_DGRAM man 7 ip man 7 tcp man 7 udp man 7 unix 什么是message boundires? TCP的stream模式怎么定界? cgroup配置 写入pid rt调度域的配额 一些命令 linux调度方式有哪些? 非实时调度 实时调度 preemptive kernel是什么意思? 为什么一直说内核抢占? 嵌入式设备需要抢占吗? 用户态上下文切换和ucontex.h 用户态上下文 例子 使用ucontext.h的api实现用户态协程 多线程的情况下, signal被deliver到哪个线程? 信号处理函数执行的上下文是什么? 为什么能打印当前进程的调用栈? sighandler执行的上下文 sigaltstack函数用于指定sighandler栈 回答 信号处理原理 sigaction pending和blocked向量 signal的产生和投递 signal和系统调用 siglongjmp futex系统调用 libevent主循环处理timer 再议rm 普通用户可以rm root用户的文件 关于热升级, 正在使用的文件可以被rm 用户态通过系统调用陷入到内核态, 内存映射会变吗? uboot传mtdpart的时候，名字从哪来的？ 为什么直接考过来的ls不能用？ fork与malloc seccomp系统调用 很多sandbox机制都使用了这个系统调用, 它是个系统调用的filter机制. #include #include #include #include #include int seccomp(unsigned int operation, unsigned int flags, void *args); seccomp设置calling进程的Secure Computing属性,有几种operation: SECCOMP_SET_MODE_STRICT: 只有基本的read, write, exit和sigreturn可以用. 其他的系统调用会触发SIGKILL SECCOMP_SET_MODE_FILTER: args指向sock_fprog, 这是个bpf的指令, 可以设置任意组合的系统调用filter规则struct sock_fprog { unsigned short len; /* Number of BPF instructions */ struct sock_filter *filter; /* Pointer to array of BPF instructions */ }; struct sock_filter { /* Filter block */ __u16 code; /* Actual filter code */ __u8 jt; /* Jump true */ __u8 jf; /* Jump false */ __u32 k; /* Generic multiuse field */ }; SECCOMP_RET_KILL_PROCESS: 导致进程终止 SECCOMP_RET_KILL_THREAD: 导致调用者线程终止, 其他线程不受影响. SECCOMP_RET_TRAP: 系统调用会触发SIGSYS信号 SECCOMP_RET_ERRNO: SECCOMP_RET_TRACE: SECCOMP_RET_LOG: SECCOMP_RET_ALLOW: 系统权限 man capabilities 权限检查是基于thread的, 特权用户(root, euid=0)的thread不用检查, 其他用户会走权限检查流程. linux权限有很多类, 可以单独打开和关闭 比如 CAP_DAC_OVERRIDE: 有这个属性就可以跳过文件或目录的rwx检查 CAP_DAC_READ_SEARCH: 跳过read属性检查 CAP_KILL: 是否有kill权限 CAP_MKNOD: 是否能创建ssh设备文件 CAP_NET_ADMIN: 网络配置 CAP_NET_RAW: 使用raw socket CAP_SYS_ADMIN: 比如mount, setns, clone等 还有其他很多属性, 见man capabilities 子进程继承父进程的属性 smaps解析性能 我要解析/proc/1/smaps, 它的格式如下: ~ # cat /proc/1/smaps 00010000-00013000 r-xp 00000000 00:02 8237 /usr/bin/s6-svscan Size: 12 kB Rss: 12 kB Pss: 12 kB Shared_Clean: 0 kB Shared_Dirty: 0 kB Private_Clean: 0 kB Private_Dirty: 12 kB Referenced: 12 kB Anonymous: 0 kB AnonHugePages: 0 kB ShmemPmdMapped: 0 kB Shared_Hugetlb: 0 kB Private_Hugetlb: 0 kB Swap: 0 kB SwapPss: 0 kB KernelPageSize: 4 kB MMUPageSize: 4 kB Locked: 0 kB VmFlags: rd ex mr mw me dw 00022000-00023000 r--p 00002000 00:02 8237 /usr/bin/s6-svscan Size: 4 kB Rss: 4 kB Pss: 4 kB Shared_Clean: 0 kB Shared_Dirty: 0 kB Private_Clean: 0 kB Private_Dirty: 4 kB Referenced: 4 kB Anonymous: 4 kB AnonHugePages: 0 kB ShmemPmdMapped: 0 kB Shared_Hugetlb: 0 kB Private_Hugetlb: 0 kB Swap: 0 kB SwapPss: 0 kB KernelPageSize: 4 kB MMUPageSize: 4 kB Locked: 0 kB VmFlags: rd mr mw me dw ac ... 我写了代码把所有Pss: xx kB加起来. CPU消耗很高. 这里的消耗包括打开这个文件本身, 和字符串搜索和转换的消耗. 打开smaps文件本身 只是打开这个文件就已经很高了: htop显示CPU在40到70之间, 均值大概在50.perf发现大部分时间在内核的smaps_account()函数, 这个函数在for里计算每个page, 确实比较耗时. 加上字符串操做 buf, err := os.ReadFile(\"/proc/\" + pid + \"/smaps_rollup\") if err == nil { i := bytes.Index(buf, []byte(\"\\nPss:\")) if i != -1 { buf = buf[i+1:] size, _ := strconv.ParseUint(string(bytes.TrimSpace(buf[4:24])), 10, 64) //fmt.Fprintln(os.Stderr, string(bytes.TrimSpace(buf[4:24])), size) pssSize = size return } } 感觉CPU没有升高多少, 平均也在50+%. 结论 打开\"/proc/\" + pid + \"/smaps_rollup\"或\"/proc/\" + pid + \"/smaps\"本身就很消耗CPU. 因为kernel在open的时候才去调用smaps_account()函数. 使用其他用户启动进程 在shell里手动启动一个可执行程序, 其user是当前的登陆用户. 但有的时候, 比如开一个daemon进程, 不想用自己的用户来启动, 下面是方法: 改变文件的owner为nobody:nogroup, 设置setuid属性 这步需要sudo权限 # nobody和nogroup一般的linux系统都有 sudo chown nobody:nogroup gshell # user和group都要设置setuid属性 sudo chmod ugo+ws gshell # ls -l看到gshell程序已经是nobody:nogroup了, 而且u和g都有s属性 # 我专门把o的w属性也加上了 -rwsrwsrwx 1 nobody nogroup 22610134 Sep 26 01:14 gshell ruid euid 什么是uid euid? 最主要是看man setuid和man seteuid The distinction between a real and an effective user id is made because you may have the need to temporarily take another user's identity (most of the time, that would be root, but it could be any user). If you only had one user id, then there would be no way of changing back to your original user id afterwards (other than taking your word for granted, and in case you are root, using root's privileges to change to any user). So, the real user id is who you really are (the one who owns the process), and the effective user id is what the operating system looks at to make a decision whether or not you are allowed to do something (most of the time, there are some exceptions). When you log in, the login shell sets both the real and effective user id to the same value (your real user id) as supplied by the password file. Now, it also happens that you execute a setuid program, and besides running as another user (e.g. root) the setuid program is also supposed to do something on your behalf. How does this work? After executing the setuid program, it will have your real id (since you're the process owner) and the effective user id of the file owner (for example root) since it is setuid. The program does whatever magic it needs to do with superuser privileges and then wants to do something on your behalf. That means, attempting to do something that you shouldn't be able to do should fail. How does it do that? Well, obviously by changing its effective user id to the real user id! Now that setuid program has no way of switching back since all the kernel knows is your id and... your id. Bang, you're dead. This is what the saved set-user id is for. 参考: https://stackoverflow.com/questions/32455684/difference-between-real-user-id-effective-user-id-and-saved-user-id https://mudongliang.github.io/2020/09/17/ruid-euid-suid-usage-in-linux.html https://stackoverflow.com/questions/33982789/difference-between-euid-suid-and-ruid-in-linux-systems 补充 使用ps -eo user,pid,euid,ruid,suid,cmd | grep gshell可以查看各种id euid EUID effective user ID (alias uid). ruid RUID real user ID. suid SUID saved user ID. (alias svuid). 实验 当我sudo chmod ugo+ws bin/gshell后, 看到 -rwsrwsrwx 1 nobody nogroup 23M Oct 22 05:34 gshell 然后用普通user启动 bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 看到: $ ps -eo user,pid,euid,ruid,suid,cmd | grep gshell nobody 27870 65534 1003 65534 bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 yingjieb 27893 1003 1003 1003 grep gshell 很明显: 普通进程grep, 其euid ruid suid都是一致的, 即都是1003(yingjieb) 但bin/gshell带s属性(即setuid属性), 用普通用户运行, euid和suid是65534(nobody), ruid是启动用户 用root启动 sudo bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 看到: $ ps -eo user,pid,euid,ruid,suid,cmd | grep gshell root 27897 0 0 0 sudo bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 nobody 27898 65534 0 65534 bin/gshell -loglevel debug daemon -registry 10.182.105.179:11985 -bcast 9923 yingjieb 27910 1003 1003 1003 grep gshell 可以看到, 先用root启动了该程序, 但会以nobody fork这个进程运行, fork的进程的euid和suid是nobody, 但ruid还是root. 进程的权限是看ruid, 而不是euid 比如上面的例子, root启动的进程27898, 虽然euid变成了nobody, 但实际该进程还是可以有root权限, 创建删除权限都是root的. 那euid有啥用? golang权限降级 思路是先让bin文件的owner是nobody, 带setuid属性. 然后任何用户启动这个文件, euid都是nobody的. 但ruid还是启动用户的. 要在代码里改ruid: euid := os.Geteuid() if err := syscall.Setreuid(euid, euid); err != nil { return err } 改了ruid后, 再用ps -eo user,pid,euid,ruid,suid,cmd | grep gshell看, 所有的UID都是nobody了. 这个进程就只有nobody权限了. 补充, gid也要设置: ps -eo user,pid,euid,ruid,suid,egid,rgid,sgid,cmd | grep gshell 什么是defunct进程? gshell起了一个自己的new version的进程, 但显示: $ ps -ef | grep gshell yingjieb 6762 9291 2 12:18 pts/9 00:00:02 bin/gshell -wd .working -loglevel debug daemon -registry 10.182.105.138:11985 -bcast 9923 -root -repo gitlabe1.ext.net.nokia.com/godevsig/grepo/master -update http://10.182.105.179:8088/gshell/release/latest/%s yingjieb 6777 6762 0 12:18 pts/9 00:00:00 bin/gshell -wd .working -loglevel debug __start -e master.v1.1.3 yingjieb 6799 6762 0 12:20 pts/9 00:00:00 [gshell] 注意这里的[gshell] 是僵尸进程: Processes marked are dead processes (so-called \"zombies\") that remain because their parent has not destroyed them properly. These processes will be destroyed by init(8) if the parent process exits. 僵尸进程不能被kill, 因为它已经死了. 它还在这里显示是因为其父进程还在, 但没有清理这个死掉的子进程. 对应的go代码: 因为Start()并不会等待并清理子进程. if err := exec.Command(cmdArgs[0], cmdArgs[1:]...).Start(); err != nil { lg.Errorf(\"start new gshell failed: %v\", err) } else { lg.Infof(\"new version gshell started\") } 注: 这里子进程死掉的原因可以用下面的代码捕捉 out, err := exec.Command(cmdArgs[0], cmdArgs[1:]...).Output() lg.Debugf(\"out: %s, err: %v\", out, err) 是因为传入的-update选项新的binary不认识. cgroup v2 https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html mount -t cgroup2 none $MOUNT_POINT 和v1不同, cgroup v2只有一个树结构 一个进程只能属于一个cgroup mkdir $CGROUP_NAME创建一个子cgroup 进程 把进程pid写进cgroup.procs会migrate这个进程到该cgroup, 包括其所有线程. 每次只能写一个PID到cgroup.procs文件, 即一次write系统调用移动一个pid 没有子cgroup并且里面没有pid的cgrouup可以删除: rmdir $CGROUP_NAME 如果里面只有zombie进程, 也是可以删除的 /proc/$PID/cgroup可以显式pid所属的cgroup # cat /proc/842/cgroup ... 0::/test-cgroup/test-cgroup-nested 如果这个cgroup被删除了, 会是这样: 这个情况下, 这个进程一定是个僵尸进程 # cat /proc/842/cgroup ... 0::/test-cgroup/test-cgroup-nested (deleted) 线程 官方解释 cgroup v2 supports thread granularity for a subset of controllers to support use cases requiring hierarchical resource distribution across the threads of a group of processes. By default, all threads of a process belong to the same cgroup, which also serves as the resource domain to host resource consumptions which are not specific to a process or thread. The thread mode allows threads to be spread across a subtree while still maintaining the common resource domain for them. 默认所有线程属于同一个cgroup, 但也支持分属于多个subtree. 就是说在同一个tree下面 支持thread模式的controller叫threaded controllers; 不支持的叫domain controllers 默认创建的cgroup是domain模式, 用echo threaded > cgroup.type可以将其改为threaded模式, 但要满足如下条件: As the cgroup will join the parent’s resource domain. The parent must either be a valid (threaded) domain or a threaded cgroup. When the parent is an unthreaded domain, it must not have any domain controllers enabled or populated domain children. The root is exempt from this requirement. threaded cgroup下面新建的cgroup默认是无效的 A (threaded domain) - B (threaded) - C (domain, just created) 这样的cgroup树, 在C刚刚创建的时候, 默认是domain控制器, 但它的父节点上都不是domain控制器. 这样C的cgroup.type文件会报告domain (invalid), 直到配置其为threaded模式. 一个cgroup变为threaded模式会导致其父domain cgroup变为threaded domain 一个进程的线程只能在一个threaded domain下存在. The threaded domain cgroup serves as the resource domain for the whole subtree, and, while the threads can be scattered across the subtree, all the processes are considered to be in the threaded domain cgroup. “cgroup.procs” in a threaded domain cgroup contains the PIDs of all processes in the subtree and is not readable in the subtree proper. However, “cgroup.procs” can be written to from anywhere in the subtree to migrate all threads of the matching process to the cgroup. 这段说的是线程domain组的cgroup.procs包含了子树的所有进程, 因为此时子树里面都是线程ID A (threaded domain) - B (threaded)在这个模式下, 一个线程在B中, 那B只算这个线程的资源. 但B所属的进程所有资源都算在A的头上, 因为A是domain控制器 控制器使能 每个cgroup都支持控制器类型# cat cgroup.controllers cpu io memory 默认全部都是不使能的. 需要显式使能: # echo \"+cpu +memory -io\" > cgroup.subtree_control 只有空的domain cgroup才能使能domain控制器. 但root不受此限制 不推荐动态迁移pid Migrating a process across cgroups is a relatively expensive operation and stateful resources such as memory are not moved together with the process. This is an explicit design decision as there often exist inherent trade-offs between migration and various hot paths in terms of synchronization cost. As such, migrating processes across cgroups frequently as a means to apply different resource restrictions is discouraged. A workload should be assigned to a cgroup according to the system’s logical and resource structure once on start-up. Dynamic adjustments to resource distribution can be made by changing controller configuration through the interface files. 以上说的是动态迁移pid的cost有点大. 动态的配置可以作用在控制器的相关接口文件上. 就是说要静态pid到group, 但group的配置可以改. 资源限制类型 Weights 比例方式. 范围从[1, 10000], 默认100 可以超配 Limits 限额方式, 从[0, max], 默认max. 可以超配(这点和v1不一样?) -- 为什么可以超配? 因为普通模式收CFS调度, 完全公平, CPU 100%忙也受调度限制. Protections 保护方式. 看起来是保护最低限额. Allocations 分配方式. 不能超配. 似乎就是现在的用法? 控制器类型 CPU The “cpu” controllers regulates distribution of CPU cycles. This controller implements weight and absolute bandwidth limit models for normal scheduling policy and absolute bandwidth allocation model for realtime scheduling policy. 说的很清楚, CPU类型的控制器实现了普通调度模式下的限额方式(可以超配)以及实时调度模式下的分配方式(不能超配) WARNING: cgroup2 doesn’t yet support control of realtime processes and the cpu controller can only be enabled when all RT processes are in the root cgroup. Be aware that system management software may already have placed RT processes into nonroot cgroups during the system boot process, and these processes may need to be moved to the root cgroup before the cpu controller can be enabled. 这个warn的意思是cgroup2对RT的支持还不好? 接口文件 cpu.stat 统计信息. 竟然就有利用率和用户态 内核态时间 cpu.weight normal调度用的比例方式 cpu.max 应该是给RT用的 allocation方式 内存 内存控制器是有状态的, 实现了limit方式和protection方式. 目前有三种类型的内存使用能够被统计到: 用户态页表: Userland memory - page cache and anonymous memory. 内核态数据: Kernel data structures such as dentries and inodes. TCP的内存: TCP socket buffers. 如下接口文件: memory.current 目前mem占用, 应是实际值 memory.min 受保护的最小值, 默认是0 memory.low 在low下都不会被kernel回收 memory.high 超过high会被kernel严格回收 memory.max 硬上限. 超过OOM memory.stat 详细统计: 匿名页 有名页 文件 共享内存 slab IO 传统上应该是指disk IO PID 用于限制PID可以fork和clone的次数 Cpuset 指定核. 主要用于NUMA场景. 可以和CPU以及mem联用. 比如在一个cgroup tree下面, 同时限制CPU使用, MEM使用以及指定CPU核 cpuset.cpus 配置文件交互 cgroup.type 控制cgroup是否为threaded模式 cgroup.procs 进程加入cgroup. 所有线程也一起加入 在threaded模式下, 读这个文件返回EOPNOTSUPP, 因为这个cgroup只管线程, 线程所属的进程归这个threaded domain管(在cgroup tree的上游). 但写还是一样的语义. cgroup.threads 线程加入cgroup. 只有在同一个domain的线程才能加入. 即一个进程的线程, 只能在同一个domain的子树上. cgroup.subtree_control 管使能控制器的 cgroup.events 能显示这个cgroup及其子树当前是否有有效的pid. 有效就是指有至少一个非zombine的pid cgroup.freeze 写1就freeze这个cgroup 和V1的对比 v1允许多个树, 而v2只有一个树. 看似v1更灵活, 每个tree里面还可以有任意的控制器. 但过设计了. v1允许进程的线程分属于多个cgroup. 而v2只能是在一个domain; ok, 还是v1过设计了. v1会有父子竞争现象, 因为线程可以任意所属. 系统内存占用分析 参考文章: https://www.cnblogs.com/arnoldlu/p/8568330.html http://linuxperf.com/?p=142cat /proc/meminfo MemTotal: 8054880 kB---------------------物理内存总容量，对应totalram_pages大小。 MemFree: 4004312 kB---------------------空闲内存容量，对应vm_stat[NR_FREE_PAGES]大小。 MemAvailable: 5678888 kB---------------------MemFree减去保留内存，加上部分pagecache和部分SReclaimable。 Buffers: 303016 kB---------------------块设备缓冲区大小. Cached: 2029616 kB---------------------主要是vm_stat[NR_FILE_PAGES],再减去swap出的大小和块设备缓冲区大小。Buffers+Cached=Active(file)+Inactive(file)+Shmem。 SwapCached: 0 kB---------------------交换缓存上的内容容量。 Active: 2123084 kB---------------------Active=Active(anon)+Active(file)。 Inactive: 1476268 kB---------------------Inactive=Inactive(anon)+Inactive(file)。 Active(anon): 1273544 kB---------------------活动匿名内存，匿名指进程中堆上分配的内存，活动指最近被使用的内存。 Inactive(anon): 547988 kB---------------------不活动匿名内存，在内存不足时优先释放。 Active(file): 849540 kB---------------------活动文件缓存，表示内存内容与磁盘上文件相关联。 Inactive(file): 928280 kB---------------------不活动文件缓存。 Unevictable: 17152 kB---------------------不可移动的内存，当然也不可释放，所以不会放在LRU中。 Mlocked: 17152 kB---------------------使用mlocked()处理的页面。 SwapTotal: 7812092 kB---------------------交换空间总容量。 SwapFree: 7812092 kB---------------------交换空间剩余容量。 Dirty: 6796 kB---------------------脏数据，在磁盘缓冲区中尚未写入磁盘的内存大小。 Writeback: 0 kB---------------------待回写的页面大小。 AnonPages: 1283984 kB---------------------内核中存在一个rmap(Reverse Mapping)机制，负责管理匿名内存中每一个物理页面映射到哪个进程的那个逻辑地址等信息。rmap中记录的内存页综合就是AnonPages值。 Mapped: 455248 kB---------------------映射的文件占用内存大小。 Shmem: 550260 kB---------------------vm_stat[NR_SHMEM]，tmpfs所使用的内存，tmpfs即利用物理内存来提供RAM磁盘功能。在tmpfa上保存文件时，文件系统暂时将他们保存到RAM中。 Slab: 268208 kB---------------------slab分配器总量，通过slabinfo工具或者/proc/slabinfo来查看更详细的信息。 SReclaimable: 206964 kB---------------------不存在活跃对象，可回收的slab缓存vm_stat[NR_SLAB_RECLAIMABLE]。 SUnreclaim: 61244 kB---------------------对象处于活跃状态，不能被回收的slab容量。 KernelStack: 12736 kB---------------------内核代码使用的堆栈区。 PageTables: 50376 kB---------------------PageTables就是页表，用于存储各个用户进程的逻辑地址和物理地址的变化关系，本身也是一个内存区域。 NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 11839532 kB Committed_AS: 7934688 kB VmallocTotal: 34359738367 kB------------------理论上内核可以用来映射的逻辑地址范围。 VmallocUsed: 0 kB---------------------内核将空闲内存页。 VmallocChunk: 0 kB HardwareCorrupted: 0 kB AnonHugePages: 0 kB ShmemHugePages: 0 kB ShmemPmdMapped: 0 kB CmaTotal: 0 kB CmaFree: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB DirectMap4k: 226256 kB DirectMap2M: 5953536 kB DirectMap1G: 3145728 kB /proc/meminfo和free的对应关系如下： free /proc/meminfo total =MemTotal used =MemTotal - MemFree - (Cached + SReclaimable) - Buffers free =MemFree shared =Shmem buffers =Buffers cache =Cached + SReclaimable available =MemAvailable 其他统计 /proc/buddyinfo /proc/pagetypeinfo /proc/vmstat /proc/vmallocinfo /proc/self/statm /proc/self/maps /proc/zoneinfo /proc/slabinfo /sys/kernel/mm/ksm /proc/sys/vm/compact_memory /proc/sys/vm/panic_on_oom /proc/sys/vm/oom_kill_allocating_task /proc/sys/vm/oom_dump_tasks vm参数 /proc/sys/vm/highmem_is_dirtyable /proc/sys/vm/legacy_va_layout /proc/sys/vm/lowmem_reserve_ratio /proc/sys/vm/max_map_count /proc/sys/vm/mmap_min_addr /proc/sys/vm/min_free_kbytes /proc/sys/vm/stat_interval /proc/sys/vm/vfs_cache_pressure /proc/sys/vm/page-cluster 文件缓存 /proc/sys/vm/dirty_background_bytes /proc/sys/vm/dirty_background_ratio /proc/sys/vm/dirty_bytes /proc/sys/vm/dirty_ratio /proc/sys/vm/dirty_expire_centisecs /proc/sys/vm/drop_caches CPU占用率分析 下面的数据全部都是从proc文件系统里读出来的. per CPU统计 user + sys + softirq + idle + iowait = 100 看到图中core1的这几个值加起来是绝对的100 core0也一样, 绝对的100 softirq现象 系统在打流的时候, 大约每2分钟就有10秒的冲高, 2个核加起来刚好100. 从上面的图看, 在softirq高的时候, 有100的CPU占用. 按理说2核的CPU共200, 那么应该只剩下100的CPU了. 也就是说, 如果softirq也算是\"独立\"的统计的话, 按进程的叠加不应该超过剩下的100. 是吗? 不是. 见下图: 在蓝色尖峰的时候, 按进程的统计已经超过了150. 结论 按CPU视角来统计, softirq是独立的 按进程视角来统计, softirq被统计进了sys. 因为proc文件系统只提供user和sys的占用, 目前我的结论是softirq在这个进程的占比(或者说\"抢占了\"这个进程的占比)会被加到这个进程的sys占比中. 当softirq高发生时, 通常都是burst的网络报文的处理导致的. 如果只看进程的CPU占用, 要注意里面已经包括了softirq的占用. 补充 上图显示了cpu1的softirq + idle + system + irq + user = 100注意softirq和irq不是一个.有个进程ksoftirqd也占了十几个点的CPU. 如果把它加到sys类里, 就超了100.又因为CPU1的system + user都只有不到5个点, 所以ksoftirqd内核线程的时间是算在softirq里面的. 系统调用都会触发调度吗? 不是. 虽然内核会在返回到用户态之前, 检查是否调度, 但是有条件的: 它检查任务描述符里need_resched字段以判断是否需要调度. 这个字段在进程时间片用尽的时候, 由函数scheduler_tick()来置位, 或者是高优先级任务来的时候, 也要置位这个flag. Preemption and Context Switching Context switching, the switching from one runnable task to another, is handled by the context_switch() function defined in kernel/sched.c. It is called by schedule() when a new process has been selected to run. It does two basic jobs: Calls switch_mm(), which is defined in include/asm/mmu_context.h, to switch the virtual memory mapping from the previous process's to that of the new process. Calls switch_to(), defined in include/asm/system.h, to switch the processor state from the previous process's to the current's. This involves saving and restoring stack information and the processor registers. The kernel, however, must know when to call schedule(). If it only called schedule() when code explicitly did so, user-space programs could run indefinitely. Instead, the kernel provides the need_resched flag to signify whether a reschedule should be performed (See Table 3.2). This flag is set by scheduler_tick() when a process runs out of timeslice and by try_to_wake_up() when a process that has a higher priority than the currently running process is awakened. The kernel will check the flag, see that it is set, and call schedule() to switch to a new process. The flag is a message to the kernel that the scheduler should be invoked as soon as possible because another process deserves to run. Functions for Accessing and Manipulating need_resched Function Purpose set_tsk_need_resched(task) Set the need_resched flag in the given process clear_tsk_need_resched(task) Clear the need_resched flag in the given process need_resched() Test the value of the need_resched flag; return true if set and false otherwise Upon returning to user-space or returning from an interrupt, the need_resched flag is checked. If it is set, the kernel invokes the scheduler before continuing. The flag is per-process, and not simply global, because it is faster to access a value in the process descriptor (because of the speed of current and because it might be in a cache line) than a global variable. Historically, the flag was global before the 2.2 kernel. In 2.2 and 2.4, the flag was an int inside the task_struct. In 2.6, it was moved into a single bit of a special flag variable inside the thread_info structure. As you can see, the kernel developers are never satisfied. User Preemption User preemption occurs when the kernel is about to return to user-space, need_resched is set, and therefore, the scheduler is invoked. If the kernel is returning to user-space, it knows it is in a safe quiescent state. In other words, if it is safe to continue executing the current task, it is also safe to pick a new task to execute. Consequently, whenever the kernel is preparing to return to user-space, either on return from an interrupt or after a system call, the value of need_resched is checked. If it is set, the scheduler is invoked to select a new (more fit) process to execute. Both the return paths for return from interrupt and return from system call are architecture-dependent and typically implemented in assembly in entry.S (which, aside from kernel entry code, also contains kernel exit code). In short, user preemption can occur When returning to user-space from a system call When returning to user-space from an interrupt handler Kernel Preemption The Linux kernel, unlike most other Unix variants and many other operating systems, is a fully preemptive kernel. In non-preemptive kernels, kernel code runs until completion. That is, the scheduler is not capable of rescheduling a task while it is in the kernel—kernel code is scheduled cooperatively, not preemptively. Kernel code runs until it finishes (returns to user-space) or explicitly blocks. In the 2.6 kernel, however, the Linux kernel became preemptive; it is now possible to preempt a task at any point, so long as the kernel is in a state in which it is safe to reschedule. So when is it safe to reschedule? The kernel is capable of preempting a task running in the kernel so long as it does not hold a lock. That is, locks are used as markers of regions of non-preemptibility. Because the kernel is SMP-safe, if a lock is not held, the current code is reentrant and capable of being preempted. The first change in supporting kernel preemption was the addition of a preemption counter, preempt_count, to each process's task_struct. This counter begins at zero and increments for each lock that is acquired and decrements for each lock that is released. When the counter is zero, the kernel is preemptible. Upon return from interrupt, if returning to kernel-space, the kernel checks the values of need_resched and preempt_count. If need_resched is set and preempt_count is zero, then a more important task is runnable and it is safe to preempt. Thus, the scheduler is invoked. If preempt_count is nonzero, a lock is held and it is unsafe to reschedule. In that case, the interrupt returns as usual to the currently executing task. When all the locks that the current task is holding are released, preempt_count returns to zero. At that time, the unlock code checks if need_resched is set. If so, the scheduler will be invoked. Enabling and disabling kernel preemption is sometimes required in kernel code and will be discussed in Chapter 8. Kernel preemption can also occur explicitly, when a task in the kernel blocks or explicitly calls schedule(). This form of kernel preemption has always been supported because no additional logic is required to ensure the kernel is in a state that is safe to preempt. It is assumed that the code that explicitly calls schedule() knows it is safe to reschedule. Kernel preemption can occur When returning to kernel-space from an interrupt handler When kernel code becomes preemptible again If a task in the kernel explicitly calls schedule() If a task in the kernel blocks (which results in a call to schedule()) 调度代码 调度发生时, schedule()调用context_switch()完成调度 一些系统调用, 可能会阻塞, 此时会触发调度 基本上大部分IO相关的系统调用都可能阻塞, 比如 open() read() write()等. 这里列出了常见的可能阻塞的系统调用 调度器的参考文章 https://www.cs.montana.edu/~chandrima.sarkar/AdvancedOS/SchedulingLinux/index.html https://www.cs.columbia.edu/~smb/classes/s06-4118/l13.pdf http://lass.cs.umass.edu/~shenoy/courses/spring20/lectures/Lec09.pdf https://medium.com/@bundetcom/understanding-linux-scheduler-5c683ff482d0 signal的默认行为和打断系统调用 man 7 signal 默认行为 Signal Value Action Comment ────────────────────────────────────────────────────────────────────── SIGHUP 1 Term Hangup detected on controlling terminal or death of controlling process SIGINT 2 Term Interrupt from keyboard SIGQUIT 3 Core Quit from keyboard SIGILL 4 Core Illegal Instruction SIGABRT 6 Core Abort signal from abort(3) SIGFPE 8 Core Floating-point exception SIGKILL 9 Term Kill signal SIGSEGV 11 Core Invalid memory reference SIGPIPE 13 Term Broken pipe: write to pipe with no readers; see pipe(7) SIGALRM 14 Term Timer signal from alarm(2) SIGTERM 15 Term Termination signal SIGUSR1 30,10,16 Term User-defined signal 1 SIGUSR2 31,12,17 Term User-defined signal 2 SIGCHLD 20,17,18 Ign Child stopped or terminated SIGCONT 19,18,25 Cont Continue if stopped SIGSTOP 17,19,23 Stop Stop process SIGTSTP 18,20,24 Stop Stop typed at terminal SIGTTIN 21,21,26 Stop Terminal input for background process SIGTTOU 22,22,27 Stop Terminal output for background process 注: 有的signal是发给整个group的, 比如SIGINT, 会发给整个PGRP, 也就是说, 如果一个前台父进程A起了子进程B, 那么在前台Ctrl+C掉进程A, 那么除了进程A会收到SIGINT, 进程B也会收到SIGINT 但如果是用kill命令, 比如kill -SIGINT 进程A, 那么只有进程A会收到SIGINT, 其子进程B不会收到SIGINT. 进程A的退出也不会导致其子进程B退出 用setpgid 或 setsid来改变子进程的进程组, 可以避免子进程收到前台的SIGINT 详见https://stackoverflow.com/questions/6803395/child-process-receives-parents-sigint signal和系统调用 signal打断系统调用的行为有几种, 和系统调用的类型以及注册sigaction的时候有没有SA_RESTART标记有关 下面的系统调用, 如果有SA_RESTART标记一般会被内核自动重新启动这个调用. 否则返回error EINTR * read(2), readv(2), write(2), writev(2), and ioctl(2) calls on \"slow\" devices. A \"slow\" device is one where the I/O call may block for an indefinite time, for example, a terminal, pipe, or socket. If an I/O call on a slow device has already transferred some data by the time it is interrupted by a signal handler, then the call will return a success status (normally, the number of bytes transferred). Note that a (local) disk is not a slow device according to this definition; I/O operations on disk devices are not interrupted by signals. * open(2), if it can block (e.g., when opening a FIFO; see fifo(7)). * wait(2), wait3(2), wait4(2), waitid(2), and waitpid(2). * Socket interfaces: accept(2), connect(2), recv(2), recvfrom(2), recvmmsg(2), recvmsg(2), send(2), sendto(2), and sendmsg(2), unless a timeout has been set on the socket (see below). * File locking interfaces: flock(2) and the F_SETLKW and F_OFD_SETLKW operations of fcntl(2) * POSIX message queue interfaces: mq_receive(3), mq_timedreceive(3), mq_send(3), and mq_timedsend(3). * futex(2) FUTEX_WAIT (since Linux 2.6.22; beforehand, always failed with EINTR). * getrandom(2). * pthread_mutex_lock(3), pthread_cond_wait(3), and related APIs. * futex(2) FUTEX_WAIT_BITSET. * POSIX semaphore interfaces: sem_wait(3) and sem_timedwait(3) (since Linux 2.6.22; beforehand, always failed with EINTR). * read(2) from an inotify(7) file descriptor (since Linux 3.8; beforehand, always failed with EINTR). 下面的系统调用直接返回EINTR, 不管是否有SA_RESTART * \"Input\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): accept(2), recv(2), recvfrom(2), recvmmsg(2) (also with a non-NULL timeout argument), and recvmsg(2). * \"Output\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): connect(2), send(2), sendto(2), and sendmsg(2). * Interfaces used to wait for signals: pause(2), sigsuspend(2), sigtimedwait(2), and sigwaitinfo(2). * File descriptor multiplexing interfaces: epoll_wait(2), epoll_pwait(2), poll(2), ppoll(2), select(2), and pselect(2). * System V IPC interfaces: msgrcv(2), msgsnd(2), semop(2), and semtimedop(2). * Sleep interfaces: clock_nanosleep(2), nanosleep(2), and usleep(3). * io_getevents(2). 内核收报文的时间片算在哪里? 背景: 驱动中断在哪里执行? 驱动收报要注册irq handler, 一般的, 使用: int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id) 其中: handler: 在中断上下文执行 thread_fn: 不为NULL就会新建一个内核线程\"irq/%irq-%irq_name\"来处理中断下半部. 当kernel启动参数包括threadirqs时, 即使thread_fn为null, 也会强制新建一个内核线程, 在该内核线程内处理中断. threadirqs只有在CONFIG_IRQ_FORCED_THREADING=y的时候才生效. 在板子上实验, 不加threadirqs, fglt-b上没有irq/xxx等进程. 加了threadirqs, 多了十几个irq/xxx进程, 每个中断一个. 一般的系统不会配置threadirqs强制把中断线程化. 所以, 根据驱动中断注册中断处理函数request_threaded_irq()是否有thread_fn, 决定中断是在内核线程上下文还是中断上下文 中断线程化后的CPU load 下面是打开threadirqs后, irq/24-eth0就是板子eth0网口收报的中断被强制线程化后的线程名. 可以看到, 在打流的时候, 这个线程load挺高的. 默认的eth0驱动并没有使用线程化中断, 这里面大概15%的CPU load可能被均摊到其他进程中(看起来是的). 打1000/2000/4000/6000pps 上行dhcpv4 discovery 打开threadirqs功能:topid: http://10.182.105.138:9888/switchPerf/152917918 关闭threadirqs功能:topid：http://10.182.105.138:9888/fgltb_dhcpv4/3501403790 对比两组数据, 基本上可以得到, 每个app的CPU load里, 都包含了中断处理时间, 比较均匀, 大概都是在2%左右. 中断线程化了之后, 每个app的cpu占用统计都稍微降了一点, 这些CPU都被算到irq/24-eth0上了. 另外, 这里面没有看到ksoftirqd等软中断进程, 说明softirq大部分都在\"中断\"中处理了. 到底什么是中断上下文? interrupt context : it specifies that the kernel is currently executing either an interrupt handler or a deferrable function 根据上面的定义, softirq是中断上下文. 从属性上说, 是的. 但严格从CPU角度来讲, softirq并不总是在硬件中断上下文中执行的. 下文会讲到, softirq并不是硬件上的某种\"软件触发中断\", 而是kernel的一种延迟执行的机制, 这些执行可能在硬件中断上下文中, 也可能是在普通的内核态上下文, 但其环境还是类似\"中断\"环境的, 比如抢占级别很高(只能被硬件中断抢占), 单独的softirq栈等等. 软中断上下文 一般硬中断会关中断(比如关闭eth的中断), 而软中断虽然也是在中断上下文执行(这点并不是always true), 但软中断是在使能中断的状态下执行的; 并且, 软中断可以多核同时执行. >中, 把软中断和tasklet叫做延迟执行. 原文 对硬件中断来说, 是关中断情况下串行执行的, 速度越快越好. softirq和tasklet和workqueue就是用来跑下半部的. softirq和tasklet又叫deferrable functions tasklet是基于softirq的 中断上下问的意思是kernel在执行interrupt handler, 或者在执行deferrable functions mpstat可以看软中断统计, 实际上也是从/proc/softirqs得到的数据 下面是个4核A53的ARM板子上的统计 ~ # mpstat -I SCPU Linux 4.9.199-Arm-Cortex_a53 (fglt-b) 03/08/70 _aarch64_ (4 CPU) 01:47:49 CPU HI/s TIMER/s NET_TX/s NET_RX/s BLOCK/s IRQ_POLL/s TASKLET/s SCHED/s HRTIMER/s RCU/s 01:47:49 0 0.00 100.00 0.00 3.58 0.00 0.00 0.14 98.45 0.00 48.13 01:47:49 1 0.00 87.55 0.00 8.61 0.00 0.00 0.00 98.95 0.00 38.53 01:47:49 2 0.00 79.42 0.00 6.46 0.00 0.00 3.09 98.73 0.00 47.22 01:47:49 3 0.00 65.90 0.00 2.41 0.00 0.00 0.00 97.61 0.00 39.11 softirq是静态分配的 tasklet可以动态分配, 比如加载一个内核模块时 同类型的softirq也可以同时运行在多核上, 必须可重入, 用锁保护关键区. 同类tasklet同时只能一个核运行, 不用担心竞争问题. deferrable functions在使用上, 类似中断, 都有如下操作: 初始化(Initialization): 定义一个延迟函数, 一般在kernel初始化时候确定或者在module load的时候做 激活(Activation): 标记为pending, pending的延迟函数会在下次调度到的时候执行. 在中断里也可以标记. 屏蔽(Masking): 临时禁止执行 执行(Execution): 执行pending的deferrable functions, 如果pending的很多, 只执行预定义的一部分. 激活和执行操作是同一个CPU, 这么设计主要是考虑到cache的利用率会高一点. softirq激活 在用open_softirq()注册softirq后, raise_softirq()函数用来激活softirq, 执行流程: 关本地中断 给这个softirq标记为pending 调用wakeup_softirqd()唤醒ksoftirqd进程 开本地中断 kernel会在关键点上检查softirq的pending状态, 这些关键点(checkpoints)包括: kernel调用local_bh_enable 当中断处理函数do_IRQ()完成硬中断处理, 最后调用irq_exit()时 apic timersmp_apic_timer_interrupt()结束时 核间中断处理完成时 ksoftirqd 内核进程运行时 可以看到, 这里面既有中断上下文, 又有进程上下文. 即软中断函数可能在不同的上下文中执行. 当以上checkpoint检查得知有softirq要处理时, 就会调用do_softirq(), 其执行流程如下: in_interrupt()如果是1, 表示已经在中断里调用过了do_softirq(), 或者这个softirq被禁止了. 直接return local_irq_save()关中断 切换到softirq自己的栈 执行_ _do_softirq( ) 这里应该把所有pending的事情都做完, 但这个函数可能是在中断上下文中, 执行太久会有问题. 所以只能执行固定数量的work, 剩下的交给ksoftirqd线程处理. 默认处理10个work local_bh_disable()禁止并发的_ _do_softirq( )执行? why? 不是说好了softirq支持并发吗? local_irq_enable()开中断 执行对应的softirq_vec[n]->action wakeup_softirqd( )唤醒ksoftirqd处理这里剩下的work softirq counter减一, 再次使能 切换回之前的栈 local_irq_restore()开中断 ksoftirqd线程 这个线程是用来做剩下来的工作的. for(;;) { set_current_state(TASK_INTERRUPTIBLE ); schedule( ); /* now in TASK_RUNNING state */ while (local_softirq_pending( )) { preempt_disable(); do_softirq( ); preempt_enable(); cond_resched( ); } } 这个线程是为了解决softirq过快产生的时候, 占用中断时间太长的问题的. 因为softirq可以被自己, 或者被外部事件激活. Softirq functions may reactivate themselves; in fact, both the networking softirqs and the tasklet softirqs do this. Moreover, external events, such as packet flooding on a network card, may activate softirqs at very high frequency. 上下文分类 前面分析了, 软中断上下文可以在硬中断中, 也可能是kernel checkpoints, 但都不是用户进程上下文(可能也不是绝对的, 比如用户态的系统调用里面, 调用的driver函数里有local_bh_enable()调用, 那么softirq就是在这个进程上下文处理的) 用户上下文永远可能被抢占 纯内核线程没有MM softirq是在预定义的kernel \"checkpoint\"里执行的 中断里不能sleep 收报的时间算在哪里? 从用户态调用recv开始, 用户态等待packet 网卡收报, 中断上下文驱动处理, 激活softirq 这个图有点片面. 大概率是在中断上下文处理10个, 剩下的叫给ksoftirqd 唤醒用户进程 补充: kernel的一些api用于判断当前上下文 实际上, 网卡驱动收报, IP层处理, 都不会算在进程上下文上. 但到TCP阶段, 已经绑定到socket了, tcp_v4_do_rcv()有可能在进程上下执行, 也有可能在softirq上下文执行. 结合>的分析, 如果正好用户进程在run, 但还没有调用recv(), 就会在softirq上下文执行tcp_v4_do_rcv() 那么收报的时间算在进程头上吗?答: 应该说大部分时间不会. 比如驱动收报和IP层处理. socket什么情况下会发生短读short read/partial read? 答: 应该主要是和syscall的被打断有关; 或者当时receive queue里面确实没有那么多的字节. A characteristic of earlier UNIX systems was that if a process caught a signal while the process was blocked in a ‘‘slow’’ system call, the system call was interrupted. The system call returned an error and errno was set to EINTR. This was done under the assumption that since a signal occurred and the process caught it, there is a good chance that something has happened that should wake up the blocked system call. To prevent applications from having to handle interrupted system calls, 4.2BSD introduced the automatic restarting of certain interrupted system calls. The system calls that were automatically restarted are ioctl, read, readv, write, writev, wait, and waitpid. As we’ve mentioned, the first five of these functions are interrupted by a signal only if they are operating on a slow device; wait and waitpid are always interrupted when a signal is caught. Since this caused a problem for some applications that didn’t want the operation restarted if it was interrupted, 4.3BSD allowed the process to disable this feature on a per-signal basis. stackoverflow的回答: Interruption of a system call by a signal handler occurs only in the case of various blocking system calls, and happens when the system call is interrupted by a signal handler that was explicitly established by the programmer. Furthermore, in the case where a blocking system call is interrupted by a signal handler, automatic system call restarting is an optional feature. You elect to automatically restart system calls by specifying the SA_RESTART flag when establishing the signal handler. As stated in (for example) the Linux signal(7) manual page: If a signal handler is invoked while a system call or library function call is blocked, then either: * the call is automatically restarted after the signal handler returns; or * the call fails with the error EINTR. Which of these two behaviors occurs depends on the interface and whether or not the signal handler was established using the SA_RESTART flag (see sigaction(2)). As hinted by the last sentence quoted above, even when you elect to use this feature, it does not work for all system calls, and the set of system calls for which it does work varies across UNIX implementations. The Linux signal(7) manual page notes a number of system calls that are automatically restarted when using the SA_RESTART flag, but also goes on to note various system calls that are never restarted, even if you specify that flag when establishing a handler, including: * \"Input\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): accept(2), recv(2), recvfrom(2), recvmmsg(2) (also with a non-NULL timeout argu‐ ment), and recvmsg(2). * \"Output\" socket interfaces, when a timeout (SO_RCVTIMEO) has been set on the socket using setsockopt(2): connect(2), send(2), sendto(2), and sendmsg(2). * File descriptor multiplexing interfaces: epoll_wait(2), epoll_pwait(2), poll(2), ppoll(2), select(2), and pselect(2). * System V IPC interfaces: msgrcv(2), msgsnd(2), semop(2), and semtimedop(2). For these system calls, manual restarting using a loop of the form described in APUE is essential, something like: while ((ret = some_syscall(...)) == -1 && errno == EINTR) continue; if (ret == -1) /* Handle error */ ; socket通信的时候, 要在应用侧做字节序转换吗? 答: 要. 尤其是binary编码情况下. 一般类似GPB的codec已经做了. socket的stream模式和datagram模式有什么不同? socket基础 man socket #include /* See NOTES */ #include int socket(int domain, int type, int protocol); domain有如下方式 Name Purpose Man page AF_UNIX, AF_LOCAL Local communication unix(7) AF_INET IPv4 Internet protocols ip(7) AF_INET6 IPv6 Internet protocols ipv6(7) AF_IPX IPX - Novell protocols AF_NETLINK Kernel user interface device netlink(7) AF_X25 ITU-T X.25 / ISO-8208 protocol x25(7) AF_AX25 Amateur radio AX.25 protocol AF_ATMPVC Access to raw ATM PVCs AF_APPLETALK AppleTalk ddp(7) AF_PACKET Low level packet interface packet(7) AF_ALG Interface to kernel crypto API type有 SOCK_STREAM Provides sequenced, reliable, two-way, connection-based byte streams. An out-of-band data transmission mechanism may be supported. SOCK_DGRAM Supports datagrams (connectionless, unreliable messages of a fixed maximum length). SOCK_SEQPACKET Provides a sequenced, reliable, two-way connection-based data transmission path for datagrams of fixed maximum length; a consumer is required to read an entire packet with each input system call. SOCK_RAW Provides raw network protocol access. SOCK_RDM Provides a reliable datagram layer that does not guarantee ordering. SOCK_PACKET Obsolete and should not be used in new programs; see packet(7). type还支持OR标记 SOCK_NONBLOCK Set the O_NONBLOCK file status flag on the new open file description. Using this flag saves extra calls to fcntl(2) to achieve the same result. SOCK_CLOEXEC Set the close-on-exec (FD_CLOEXEC) flag on the new file descriptor. See the description of the O_CLOEXEC flag in open(2) for reasons why this may be useful. socket的选项是SO_xxxx形式的, 用setsockopt(2)来设置. 用getsockopt(2) 来获取. SO_SNDBUF Sets or gets the maximum socket send buffer in bytes. The kernel doubles this value (to allow space for bookkeeping overhead) when it is set using setsockopt(2), and this doubled value is returned by getsockopt(2). The default value is set by the /proc/sys/net/core/wmem_default file and the maximum allowed value is set by the /proc/sys/net/core/wmem_max file. The minimum (doubled) value for this option is 2048. 我这里显示, 默认的发送buf是229K ~ # cat /proc/sys/net/core/wmem_default 229376 ~ # cat /proc/sys/net/core/wmem_max 229376 SOCK_STREAM AF_INET domain里面对应TCP, 有链接, 可靠, 保序. 没有记录边界. 这就是字节流的核心要义. 通俗来讲, 发送方发2次5字节, 接收方可以一次读到10个字节. 并且, 接收方并不知道这10个字节是两次发送的还是一次发送的. send()和recv()API, 支持带外数据发送 如果超时后还是有段数据没有收到, 则这个连接就是broken了. 对broken的连接读写会产生SIGPIPE信号 SOCK_SEQPACKET 底层和SOCK_STREAM一致, 有链接, 可靠, 保序 是packet模式, 有界. 一次读会把这个packet的所有数据读出, 超出的数据会被丢弃. all message boundaries in incoming datagrams are preserved SOCK_DGRAM 无连接, 有size限制的数据报模式 使用sendto()和recvfrom() API. recvfrom()返回下一个数据报. Datagrams are generally received with recvfrom(2), which returns the next datagram along with the address of its sender. 天然有界: 所有的收报都是一个packet. 小报直接收, 大包被截断, 剩余部分丢弃. All receive operations return only one packet. When the packet is smaller than the passed buffer, only that much data is returned; when it is bigger, the packet is truncated and the MSG_TRUNC flag is set. 发送端的sendto()和接收端的recvfrom()永远是1:1的, 一个对一个. 比如sendto()两次, 也必须recvfrom()两次才能收完报文. 这点和TCP不一样. 这也是data gram的含义. 有个api, 支持一次系统调用, 收多个datagram: recvmmsg() 估计是在内核态多次recv收报. man 7 ip #include #include #include /* superset of previous */ tcp_socket = socket(AF_INET, SOCK_STREAM, 0); udp_socket = socket(AF_INET, SOCK_DGRAM, 0); raw_socket = socket(AF_INET, SOCK_RAW, protocol); proc下面有些全局的配置: /proc/sys/net/ipv4/ man 7 tcp #include #include #include tcp_socket = socket(AF_INET, SOCK_STREAM, 0); 一些全局的配置~ # cat /proc/sys/net/ipv4/tcp_wmem 4096 16384 4194304 ~ # cat /proc/sys/net/ipv4/tcp_rmem 4096 87380 6291456 /proc/sys/net/core/rmem_max /proc/sys/net/core/wmem_max 支持urgent data, 用send的MSG_OOB选项发送 支持ioctl man 7 udp #include #include #include udp_socket = socket(AF_INET, SOCK_DGRAM, 0); 默认最大MTU, 写报文超过MTU会有EMSG‐SIZE错误. man 7 unix #include #include unix_socket = socket(AF_UNIX, type, 0); error = socketpair(AF_UNIX, type, 0, int *sv); 同时支持SOCK_STREAM和SOCK_DGRAM, 并且SOCK_DGRAM是可靠和保序的 也支持SOCK_SEQPACKET 不支持out-of-band数据 支持fd传递到其他进程, 见SCM_RIGHTS Send or receive a set of open file descriptors from another process. The data portion contains an integer array of the file descriptors. The passed file descriptors behave as though they have been created with dup(2). datagram模式时, SO_SNDBUF起作用, 这个是send()数据报的上限. 上限是: 2*SO_SNDBUF-32 SO_RCVBUF没有作用 什么是message boundires? UDP preserves message boundaries. If you send \"FOO\" and then \"BAR\" over UDP, the other end will receive two datagrams, one containing \"FOO\" and the other containing \"BAR\". If you send \"FOO\" and then \"BAR\" over TCP, no message boundary is preserved. The other end might get \"FOO\" and then \"BAR\". Or it might get \"FOOBAR\". Or it might get \"F\" and then \"OOB\" and then \"AR\". TCP does not make any attempt to preserve application message boundaries -- it's just a stream of bytes in each direction. 对于datagram类型的报文接收, 用 ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); The recvfrom function reads one packet from the socket socket into the buffer buffer. The size argument specifies the maximum number of bytes to be read. UDP operates on messages, not streams like TCP does. There is a 1-to-1 relationship between sendto() and recvfrom() when using UDP If the packet is longer than size bytes, then you get the first size bytes of the packet and the rest of the packet is lost. There’s no way to read the rest of the packet. Thus, when you use a packet protocol, you must always know how long a packet to expect. The arguments to this call are basically the same as the standard socket call. The Recvfrom() call reads one packet at a time. It returns the length of the message written to the buffer pointed to by the buf argument (the second argument). Even if one packet worth of message does not fill up the buffer, Recvfrom() will return immediately and will not read the second packet. However, if a message in a packet is too long to fit in the supplied buffer, the excess bytes are discarded. By default, Recvfrom() is blocking: when a process issues a Recvfrom() that cannot be completed immediately (because there is no packet), the process is put to sleep waiting for a packet to arrive at the socket. Therefore, a call to Recvfrom() will return immediately only if a packet is available on the socket. When the argument flags of Recvfrom() is set to MSG_NOBLOCK, Recvfrom() does not block if there is no data to be read, but returns immediately with a return value of 0 bytes. MSG_NOBLOCK is defined in $PDIR/include/systm.h. In an actual UNIX system, socket descriptors are set to be non-blocking using fcntl() with type O_NONBLOCK, and Recvfrom() returns errno EWOULDBLOCK when there is no data to be read on the non-blocking socket. TCP的stream模式怎么定界? stream流, 接收方并不知道发送放分多少次发送的. 接收方只看到一个字节流. 这就需要在应用层定界, 即双方约定如何分割和理解这个字节流. 通常的方法有: 加固定size的头. 这个头里有size信息 So you first receive the header (fixed size), extract the message size information and then receive in a second loop the real user data. 加delimiter, 即特殊符号标记 Alternatively some protocols are using delimiters to mark message boundaries. cgroup配置 写入pid /sys/fs/cgroup/cpu的cgroups树下面, 有两个文件 cgroup.procs : 将pid写入这个文件, 这个pid下面的所有线程都受cgroups控制 tasks : 只有这个pid的线程受cgroups控制 rt调度域的配额 /mnt/cgroups/cpu # cat cpu.rt_runtime_us 950000 一些命令 # 查看cgBase组里的进程 cat /mnt/cgroups/cpu/cgBase/cgroup.procs | xargs -i cat /proc/{}/comm # 查看cgBase组里的线程 cat /mnt/cgroups/cpu/cgBase/tasks | xargs -i cat /proc/{}/comm # 查看cgNonDelayCrit组里的进程 cat /mnt/cgroups/cpu/cgBase/cgNonDelayCrit/cgroup.procs | xargs -i cat /proc/{}/comm # 查看cgNonDelayCrit组里的线程 cat /mnt/cgroups/cpu/cgBase/cgNonDelayCrit/tasks | xargs -i cat /proc/{}/comm # 查看onu_engine group cat /mnt/cgroups/cpu/cgBase/cgNonDelayCrit/onu_engine/cgroup.procs | xargs -i cat /proc/{}/comm # 查看所有不在cgroup组的进程 cat /mnt/cgroups/cpu/cgroup.procs | xargs -i cat /proc/{}/comm linux调度方式有哪些? man sched 所有的调度策略是对同一个优先级下面的runnable队列而言的; 高优先级抢占低优先级是宇宙法则, 所有调度策略必须都要遵守. 非实时调度 SCHED_OTHER, SCHED_IDLE, SCHED_BATCH: 静态优先级是0 实时调度 SCHED_FIFO, SCHED_RR: 静态优先级是1 - 99 SCHED_FIFO: 没有时间片, 低优先级随时被高优先级抢占. 同一个优先级按先进先出排队 SCHED_RR: 有时间片, 按时间片轮转. 对于实时调度, 所有的实时优先级组都共享三个配置: sched_rr_timeslice_ms : 管轮转的时间片的 sched_rt_period_us : 实时优先级和普通优先级的总时间. 默认1秒. 对应100% CPU. sched_rt_runtime_us : 可以认为是所有实时优先级占比. 默认0.95秒. 即95% CPU ~ # cat /proc/sys/kernel/sched_rr_timeslice_ms 10 ~ # cat /proc/sys/kernel/sched_rt_period_us 1000000 ~ # cat /proc/sys/kernel/sched_rt_runtime_us 950000 ~ # ls ~ # zcat /proc/config.gz | grep -i empt # CONFIG_PREEMPT_NONE is not set # CONFIG_PREEMPT_VOLUNTARY is not set CONFIG_PREEMPT=y CONFIG_PREEMPT_COUNT=y CONFIG_PREEMPT_RCU=y CONFIG_DEBUG_PREEMPT=y ~ # zcat /proc/config.gz | grep -i hz # CONFIG_HZ_24 is not set # CONFIG_HZ_48 is not set CONFIG_HZ_100=y # CONFIG_HZ_128 is not set # CONFIG_HZ_250 is not set # CONFIG_HZ_256 is not set # CONFIG_HZ_1000 is not set # CONFIG_HZ_1024 is not set CONFIG_SYS_SUPPORTS_ARBIT_HZ=y CONFIG_HZ=100 CONFIG_HZ_PERIODIC=y # CONFIG_NO_HZ_IDLE is not set # CONFIG_NO_HZ_FULL is not set # CONFIG_NO_HZ is not set 解释一下: 几乎所有的moswa app 都是SCHED_RR, 静态分配优先级; 同一个优先级内按时间片轮转. 默认时间片10ms 所有实时优先级进程占CPU比例上限 95% 即有5%的CPU留给了非实时优先级, 目前只有内核线程loop* bio* ubi* spi1等几个线程享用 这个不归cgroup管, 也是为什么cgroup的cg_base最大只能配950000 目前是抢占式调度, 也就是说虽然5%留给了非实时进程, 但这些进程大概率经常被抢占. 应该说系统越忙, 雪崩效应越明显: 有更多的抢占发生 推荐优化思路: 禁止内核抢占CONFIG_PREEMPT=n或者CONFIG_PREEMPT_VOLUNTARY=y 重新整理系统实时进程和非实时进程策略, 一个比较粗糙的想法是业务处理搞SCHED_RR, 并且不那么在内部细分优先级, 比如按业务组定几个就好了, 让调度器去轮转调度; 其他进程, 比如ping, ssh, 各种脚本的衍生进程, 非核心path下的eqpt等进程, 都放到非实时 可以尝试增大SCHED_RR到100ms 调整实时进程组和非实时进程组的比例, 现在是95% : 5% preemptive kernel是什么意思? 内核现在有三个抢占模式: CONFIG_PREEMPT=y的时候, 打开内核抢占; 为n的时候关闭内核抢占 后来又加了CONFIG_PREEMPT_VOLUNTARY, 意思是主动在内核特定点可以抢占. 抢占的意思是低优先级被高优先级抢占. 为什么一直说内核抢占? 答: 因为用户态代码总是可以被抢占的, 无论CONFIG_PREEMPT怎么配置. 例如用户态代码的死循环变量加一, 也是有时间片的, 时间片耗尽也是要被kernel切换出去的. 内核抢占说的是, 当一个进程陷入到内核态, 代表这个进行运行的内核代码能否被抢占. 在古老的kernel版本里面, 内核态代码是不能被抢占的. 后来为了能够即使响应桌面等UI互动等场景, 加入了抢占. CONFIG_PREEMPT的解释如下: This option reduces the latency of the kernel by making all kernel code (that is not executing in a critical section) preemptible. This allows reaction to interactive events by permitting a low priority process to be preempted involuntarily even if it is in kernel mode executing a system call and would otherwise not be about to reach a natural preemption point. This allows applications to run more 'smoothly' even when the system is under load, at the cost of slightly lower throughput and a slight runtime overhead to kernel code. Select this if you are building a kernel for a desktop or embedded system with latency requirements in the milliseconds range. 嵌入式设备需要抢占吗? 抢占主要是给用户体验用的, 比如用户的鼠标键盘希望能响应快一点. 对时延要求高的系统, 比如工业控制系统, 需要打开内核抢占. 而一般的嵌入式系统, 应该更追求处理业务的吞吐量, 此时不抢占更合适. 一般的x86服务器, 都开的是CONFIG_PREEMPT_VOLUNTARY=y, 这是一种介于中间的状态. 这篇文章对比过 CONFIG_PREEMPT_VOLUNTARY有很好的平衡, 所以一般的主流OS(CentOS, Ubuntu, SUSE)都默认此模式(估计是server版本). 用户态上下文切换和ucontex.h 参考: 我所理解的ucontext族函数(主要是概念和使用) 协程：posix::ucontext用户级线程实现原理分析(包括汇编实现原理) posix提供了用户态上下文切换的API #include int getcontext(ucontext_t *ucp); int setcontext(const ucontext_t *ucp); void makecontext(ucontext_t *ucp, void (*func)(), int argc, ...); int swapcontext(ucontext_t *oucp, const ucontext_t *ucp); man getcontext 用户态上下文 ucontext_t描述了用户态上下文: 其中mcontext_t是个硬件相关的结构 typedef struct ucontext_t { struct ucontext_t *uc_link; sigset_t uc_sigmask; stack_t uc_stack; mcontext_t uc_mcontext; ... } ucontext_t; getcontext()函数把当前的上下文保存在ucp指针指向的ucontext_t中 setcontext()函数恢复到ucp指向的上下文, 然后从那个上下文执行. 这个函数不retrun. makecontext()函数新生成一个上下文, 并指定在这个上下文中执行的func sighandler也可以返回一个上下文 例子 下面的程序不断打印\"hello world\" 因为第10行转而在第7行保存的上下文中执行, 效果就像直接goto到第8行一样. #include #include #include int main(int argc, char *argv[]) { ucontext_t context; getcontext(&context); puts(\"Hello world\"); sleep(1); setcontext(&context); return 0; } 使用ucontext.h的api实现用户态协程 基于ucontext.h的轻量级协程库 协程可以理解为一种用户态的轻量级线程, 切换由用户定义 协程上下文切换很快, 因为不会陷入内核态 协程拥有自己的寄存器上下文和栈, 协程调度切换时，将寄存器上下文和栈保存到其他地方，在切换回来的时候，恢复先前保存的寄存器上下文和栈 协程具有极高的执行效率 因为子程序切换不是线程切换，是由程序自身控制，因此协程没有线程切换的开销, 多线程的线程数量越多，协程的性能优势就越明显 访问共享资源不需要多线程的锁机制, 因为只有一个线程, 也不存在同时写变量冲突, 所以在协程中控制共享资源无需加锁, 只需要判断状态就好了，执行效率比多线程高很多, 而且代码编写难度也可以相应降低 以同步代码的方式写异步逻辑 无法利用多核资源, 除非和多进程配合 多线程的情况下, signal被deliver到哪个线程? 问答: https://stackoverflow.com/questions/11679568/signal-handling-with-multiple-threads-in-linux 先准备几个知识: 所有线程都在一个进程空间 signal都是先入queue, 待线程被调度到运行时再执行的. signal是共享的, 但每个thread可以有自己的maskpthread_sigmask(3) 内核里deliver signal的代码: /* * Now find a thread we can wake up to take the signal off the queue. * * If the main thread wants the signal, it gets first crack. * Probably the least surprising to the average bear. */ if (wants_signal(sig, p)) t = p; else if (!group || thread_group_empty(p)) /* * There is just one thread and it does not need to be woken. * It will dequeue unblocked signals before it runs again. */ return; else { /* * Otherwise try to find a suitable thread. */ t = signal->curr_target; while (!wants_signal(sig, t)) { t = next_thread(t); if (t == signal->curr_target) /* * No thread needs to be woken. * Any eligible threads will see * the signal in the queue soon. */ return; } signal->curr_target = t; } /* * Found a killable thread. If the signal will be fatal, * then start taking the whole group down immediately. */ if (sig_fatal(p, sig) && !(signal->flags & SIGNAL_GROUP_EXIT) && !sigismember(&t->real_blocked, sig) && (sig == SIGKILL || !p->ptrace)) { /* * This signal will be fatal to the whole group. */ 结论: 默认是deliver给main thread, 如果main thread不want这个signal, 就尝试下一个thread 用户可以用pthread_sigmask(3)设置thread的mask, 从而让signal被deliver到特定的thread. 可以向指定的thread发signal. 见pthread_kill(3) tgkill(2) 一些同步异常, 比如SIGSEGV和SIGFPE, 是由当前thread的某个指令引起的, 那么signal就直接被deliver到这个线程. 有些signal是以进程为单位产生的, 理论上会被deliver到任意一个线程. 但参考第一条, 通常是deliver到main thread. 信号处理函数执行的上下文是什么? 为什么能打印当前进程的调用栈? 目前已知的知识, 以golang的signal处理为例: SIGKILL and SIGSTOP不能被捕获 同步的signal, 一般是SIGBUS, SIGFPE, and SIGSEGV, 是由正在执行的go程序引起的 在go里, 这些signal被转换为运行时的panic 剩下的signal, 是其他进程异步通知的signal, 用os/signal包来处理 经过实验得到的现象, 还是以golang为例: case 1: 对于一个纯用户态循环, ctrl+c(SIGINT)能够立即终止该进程 for { i++ } 从shell执行kill -SIGQUIT命令发送SIGQUIT信号给目标进程, 目标进程的call stack能精确定位到for循环里的i++那一行 $ ./signal hello ^\\SIGQUIT: quit PC=0x48cfd5 m=0 sigcode=128 goroutine 1 [running]: main.main() /repo/yingjieb/godev/practice/src/signal/main.go:15 +0x75 fp=0xc0000aef60 sp=0xc0000aef00 pc=0x48cfd5 runtime.main() /usr/local/go/src/runtime/proc.go:203 +0x206 fp=0xc0000aefe0 sp=0xc0000aef60 pc=0x42b136 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc0000aefe8 sp=0xc0000aefe0 pc=0x453651 case 2: 对上面的for稍加一句sleep for { i++ time.Sleep(time.Second * 10) } 发送SIGQUIT也一样能够立即打印调用栈; 不意外的, ctrl+c也能够立即终止这个进程. 都不受sleep的干扰. 调用栈显示两个goroutine(实际上, 如果有环境变量GOTRACEBACK=system, 能显示更多goroutine), sleep的调用栈就是main程序当前的代码. 结合代码和现象来看, 这个进程在收到SIGQUIT时, 大概率是在sleep, 没有在运行. 这时操作系统发现有人发送SIGQUIT给该进程, 就执行该进程的sighandler. 在本例中, 这个sighandler就是golang默认的处理. $ ./signal hello ^\\SIGQUIT: quit PC=0x455813 m=0 sigcode=128 goroutine 6 [syscall]: runtime.notetsleepg(0x5613a0, 0x2540bc392, 0x0) /usr/local/go/src/runtime/lock_futex.go:227 +0x34 fp=0xc000064760 sp=0xc000064730 pc=0x409d04 runtime.timerproc(0x561380) /usr/local/go/src/runtime/time.go:311 +0x2f1 fp=0xc0000647d8 sp=0xc000064760 pc=0x4450b1 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc0000647e0 sp=0xc0000647d8 pc=0x453911 created by runtime.(*timersBucket).addtimerLocked /usr/local/go/src/runtime/time.go:169 +0x10e goroutine 1 [sleep]: runtime.goparkunlock(...) /usr/local/go/src/runtime/proc.go:310 time.Sleep(0x2540be400) /usr/local/go/src/runtime/time.go:105 +0x157 main.main() /repo/yingjieb/godev/practice/src/signal/main.go:24 +0x88 golang对于各种signal, 都有默认的sighandler, 那么如标题的问题 sighandler一般被认为是异步的方式执行, 和正常的进程代码是两回事. 那么sighandler究竟是在什么上下文执行的? 以SIGQUIT的handler为例, 为什么一个异步执行的handler, 能够知道正常代码的调用栈? 结合case 1和2, sighandler被调用的时机是怎样的? case 2中, 大概率是在进程没有被执行的时候发生了SIGQUIT. 但case 1中, 进程死循环做i++, 会用尽调度器分给它的时间片. 那么sighandler又是什么时候执行呢? sighandler执行的上下文 程序运行在用户态时->进程由于系统调用或中断进入内核->转向用户态执行信号处理函数->信号处理函数完毕后进入内核->返回用户态继续执行程序首先程序执行在用户态，在进程陷入内核并从内核返回的前夕，会去检查有没有信号没有被处理，如果有且没有被阻塞就会调用相应的信号处理程序去处理。首先，内核在用户栈上创建一个层，该层中将返回地址设置成信号处理函数的地址，这样，从内核返回用户态时，就会执行这个信号处理函数。当信号处理函数执行完，会再次进入内核，主要是检测有没有信号没有处理，以及恢复原先程序中断执行点，恢复内核栈等工作，这样，当从内核返回后便返回到原先程序执行的地方了。 关键点在kernel在收到signal的时候, 会在用户栈上新建一个栈帧, 作用是给sighandler提供运行上下文. 我理解, 如果这个进程正在运行(在另外一个核上), 内核应该会把它调度出去, 再建立sighandler的栈帧. sigaltstack函数用于指定sighandler栈 man sigaltstack解释到: sigaltstack用于显式建立一个栈帧. 默认情况下, kernel会在用户栈上建立这个栈帧, 但对于用户栈溢出造成的SIGSEGV的情况, 在用户栈上的sighandler也就不能执行了. sigaltstack()函数用于这种情况, 在别处指定这个栈帧. #include int sigaltstack(const stack_t *ss, stack_t *old_ss); The most common usage of an alternate signal stack is to handle the SIGSEGV signal that is generated if the space available for the normal process stack is exhausted: in this case, a signal handler for SIGSEGV cannot be invoked on the process stack; if we wish to handle it, we must use an alternate signal stack. Establishing an alternate signal stack is useful if a process expects that it may exhaust its standard stack. This may occur, for example, because the stack grows so large that it encounters the upwardly growing heap, or it reaches a limit established by a call to setrlimit(RLIMIT_STACK, &rlim). If the standard stack is exhausted, the kernel sends the process a SIGSEGV signal. In these circumstances the only way to catch this signal is on an alternate signal stack. 回答 sighandler一般被认为是异步的方式执行, 和正常的进程代码是两回事. 那么sighandler究竟是在什么上下文执行的?答: 默认在用户栈上新建新的栈帧来执行. 可以用sigaltstack改变这个栈帧的位置 以SIGQUIT的handler为例, 为什么一个异步执行的handler, 能够知道正常代码的调用栈?答: handler执行的时候, 是异步的. 此时\"正常\"的进程代码位置应该可以通过上下文的PC指针查到, 那么就可以栈回溯. 结合case 1和2, sighandler被调用的时机是怎样的? case 2中, 大概率是在进程没有被执行的时候发生了SIGQUIT. 但case 1中, 进程死循环做i++, 会用尽调度器分给它的时间片. 那么sighandler又是什么时候执行呢?答: 内核在返回用户态进程的时候, 会执行sighandler. 从实验结果来看, 向进程发送信号会唤醒这个进程. 信号处理原理 signal原理讲义 sigaction sigaction结构体定义了handler的形式: 第三个参数就是ucontext pending和blocked向量 kernel给每个进程维护这两个向量 顾名思义, pending向量是要发给目标进程的向量表; 而blocked向量是不允许发送给进程的向量表. 当一个signal已经被deliver到进程, 该signal会自动被kernel放到blocked向量, 阻止进程在处理singal的时候, 又被同类型signal中断. 类似于关中断. 但不同类型的signal可以打断当前的siganl handler函数. signal的产生和投递 signal产生时, kernel要填的结构体 产生和投递是两个过程 产生signal是填一些结构体, 然后把进程状态转为ready(如果之前是睡眠) 投递signal到进程, 进程必须拥有CPU执行权才能运行其handler 默认的handler由内核执行, 自定义的handler必须等到用户态执行 handler执行完还要回到内核态 signal可以打断系统调用 handler可以调用系统调用, 系统调用返回后还是回到handler上下文 handler可以调用siglongjmp()来跳转到用户态的其他部分代码, 但执行上下文还在handler? SIGCHLD默认是ignore的, handler是SIGIGN也是要被跳过的.![](img/system原理杂记_20220829152133.png) 默认的handler SIG_DFL在内核执行: 不到用户态 不是内核处理的signal, 内核要唤醒这个进程到其用户态处理. 不能简单的把sighandler设为这次返回用户态的入口, 而是要为sighandler建立自己的上下文; 有一部分的上下文是从kernel栈拷到用户栈的. 新建的sighandler栈帧在用户态栈上, 称为uctxt handler返回的时候, 要返回到内核态. 这是通过一个间接的sigreturn系统调用实现的.man sigreturn说的很清楚: 现代linux系统上, 是vdso或libc提供的sigreturn wrapper, 它的作用是利用之前保存在栈上的相关信息, undo所有之前为sig handler运行做的准备工作, 回复进程被signal中断之前的上下文.do_signal是给用户的sighandler设置运行环境, 实际的handler不是在它里面执行的, 而是后面内核态切换到用户态时, 因为eip的改变, 导致用户的sighandler被执行. sighandler可以执行系统调用, 没有任何问题. signal和系统调用 系统调用会被signal打断, 内核需要返回EINTR来指示系统调用被打断了. 被打断的read和write可能会被内核重新执行. 可以配置是返回EINTR还是rerun 进程在系统调用期间收到signal, 那它的之前都在内核态. siglongjmp 调用siglongjmp会导致handler退出, 并把执行上下文交给用户态进程的那部分代码段. siglongjmp和longjmp差不多, 只是多了一些sig mask的操作. siglongjmp并没有破环内核的sig投递 执行 返回的流程. futex系统调用 man futex linux的futex可以当作比较-阻塞的原子操作使用. #include #include int futex(int *uaddr, int futex_op, int val, const struct timespec *timeout, /* or: uint32_t val2 */ int *uaddr2, int val3); Note: There is no glibc wrapper for this system call; see NOTES. int *uaddr是个用户提供的地址, 其值时32位的, 即使在64位机器上, 也是32位. 这个地址可以在共享内存中, 比如用mmap(2) or shmat(2)创建的共享内存, 这样不同的进程也可以使用同一个futex, futex在内核中看的是这个指针的物理地址. futex支持像epoll等系统调用的超时机制. 当futex_op可以是FUTEX_WAIT也可以是FUTEX_WAKE, 即futex有wait和wakeup两种功能. FUTEX_WAIT时, futex比较这个地址指向的32位值, 如果和val相等则休眠; 不等的话, 马上返回, errorno为EAGAIN. FUTEX_WAKE时, 唤醒val个等待在uaddr上的线程. 通常val为1个随机的线程, 或者所有(INT_MAX)的线程. libevent主循环处理timer 在libevent/event.c int event_base_loop(struct event_base *base, int flags) while (!done) { //没有event则退出循环 //从定时器堆里算下次超时时间 timeout_next(base, &tv_p); //调用底层poll, 对linux来说, 是epoll res = evsel->dispatch(base, tv_p); //handle 定时器堆, 把有效的(active)的定时器回调函数加入base的active队列, 带优先级的入队列 timeout_process(base); //真正执行active队列里面的回调; int n = event_process_active(base); } /* Activate every event whose timeout has elapsed. */ static void timeout_process(struct event_base *base) { gettime(base, &now); //获取每个timer while ((ev = min_heap_top_(&base->timeheap))) { if (evutil_timercmp(&ev->ev_timeout, &now, >)) break; /* delete this event from the I/O queues */ event_del_nolock_(ev, EVENT_DEL_NOBLOCK); event_debug((\"timeout_process: event: %p, call %p\", ev, ev->ev_callback)); //正如上面打印的提示一样, 执行每个timer的回调. event_active_nolock_(ev, EV_TIMEOUT, 1); //实际上这里是加入到一个链表: base->activequeues, 由event_process_active()执行这个链表 } } 再议rm rm实际上是unlink调用, 实际上是减小文件的link计数. 如果link减小到0, 而且没有进程open它, 文件会被删除. 如果link减小到0, 但有进程在使用它, 那么文件在进程close它之前都存在. 见man 2 unlink 实验中, 我用vim打开一个文件, 在另外一个窗口rm这个文件, rm没有返回任何错误, 文件已经从文件系统不可见. 但实际上, 这个文件还存在, vim依旧可以访问它.普通用户可以rm root用户的文件 在一次实验中, 我在test文件夹中, 用root账户创建了文件aaa, 但退出root后, 用普通账户就能删除aaa文件.yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ ll total 0 yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ sudo touch aaa yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ ll total 0 -rw-r--r-- 1 root root 0 Mar 4 21:12 aaa yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ rm -f aaa yingjieb@yingjieb-VirtualBox ~/test Linux Mint 19.1 Tessa $ ll total 0 怎么, aaa是-rw-r--r--权限, 理论上不应该能被普通用户删除呀? 有人问了这个问题, 见: https://superuser.com/questions/1336951/user-can-delete-root-owned-files-in-their-home-directory-or-what-are-the-rules其实原理是:目录和文件的关系是, 目录是对其下文件的link, 所以shell命令rm其实是unlink调用, unlink减小对文件的link引用数.如果引用数减到0, 这个文件就没人引用了, 就被删除了.删除一个文件, 并不是作用于这个文件, 而是作用于它的目录, 减小目录对文件的引用.所以, 在本例中, rm作用于目录~/test, 这是个用户有权限访问的目录. rm操作和文件aaa的权限没有关系. 关于热升级, 正在使用的文件可以被rm 比如ubuntu系统在update的时候, 一般是不需要重启的. 但既然要升级, 就必然要替换掉原来的bin或者so之类的文件, 又要app不重启, 怎么做到的呢? 以vim为例, 当前正在打开vim窗口编辑, 同时在另外一个窗口升级vim, 升级成功了, 原来打开的vim还能继续使用. 那打开的vim是新版本还是老版本呢? --是老版本 这主要是文件系统的工作, 每个打开的文件, 都有个文件句柄, 这个句柄是这个文件的一个访问实例; 句柄里保存了文件的实体(inode)在文件系统中的引用. 升级的过程, 是先删除旧文件, 再写入新文件, 虽然文件名相同, 但inode不同. 已经打开的旧文件, 在其句柄里保存的inode, 指向的文件\"看起来\"不存在了, 但实际还在文件系统里. 所有对这个老的inode的引用结束后, 文件系统把这部分在磁盘上的实体空间标记为空闲. #打开vim, 进程是28919 #pmap发现其mmap的文件 Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk 000055683333b000 64K r---- vim.gtk 000055683334b000 104K rw--- vim.gtk #此时, 对vim.gtk的open是不能写的, 因为写是对同一个inode操作. Linux Mint 19.1 Tessa $ sudo dd if=/dev/zero of=/usr/bin/vim.gtk bs=4M count=1 dd: failed to open '/usr/bin/vim.gtk': Text file busy yingjieb@yingjieb-VirtualBox ~ Linux Mint 19.1 Tessa $ sudo cp /usr/bin/x86_64-linux-gnu-gcc-7 /usr/bin/vim.gtk cp: cannot create regular file '/usr/bin/vim.gtk': Text file busy #但是可以删除 Linux Mint 19.1 Tessa $ sudo rm -f /usr/bin/vim.gtk #此时pmap能知道这个文件被删除了 #但28919进程的vim还能继续使用, 因为1. 其文件并没有真正消亡. 2. 文件被装载到内存里了(page). #我估计这两项都为真. 文件被mmap到进程内存空间, 即使只有部分文件被page了, 访问另外的文件部分, 会有page fault, 进而通过文件系统装载文件内容到物理页. #我认为即使page fault, 也会访问到老的inode的文件, 也会成功 -- 未验证 Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk (deleted) 000055683333b000 64K r---- vim.gtk (deleted) 000055683334b000 104K rw--- vim.gtk (deleted) #也可以mv Linux Mint 19.1 Tessa $ sudo mv /usr/bin/vim.gtk /usr/bin/vim.gtk.back #此时pmap知道inode没变, 文件变了. Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk.back 000055683333b000 64K r---- vim.gtk.back 000055683334b000 104K rw--- vim.gtk.back #删除vim.gtk后, 可以新建个同名文件; 但新文件有新的inode Linux Mint 19.1 Tessa $ sudo cp vim.gtk.save /usr/bin/vim.gtk Linux Mint 19.1 Tessa $ llh /usr/bin/vim.gtk -rwxr-xr-x 1 root root 3.1M Jun 13 17:08 /usr/bin/vim.gtk #pmap依然显示vim.gtk是已经删除状态, 因为这里用的老的inode Linux Mint 19.1 Tessa $ pmap 28919 28919: vim drivers/spi/spidev.c 0000556832e5d000 2940K r-x-- vim.gtk (deleted) 000055683333b000 64K r---- vim.gtk (deleted) 000055683334b000 104K rw--- vim.gtk (deleted) 结论: mv文件不改变文件的inode, 只改变文件名; cp新文件到正在打开的文件是非法的, 因为cp要open这个目的文件, 是对同一个inode操作. 如果合法, 那正在执行的文件, 其内容更改会引发未知错误. rm打开的文件是可以的, 或者说\"看起来\"是马上生效的, 但实际上, 如果老的inode还在被引用, 还是能被文件系统访问到. 升级正在运行的可执行文件, 比如vim.gtk, 要制造新的inode, 具体是: 先rm, 再cp成同名文件 升级后的文件, 只有app重新加载的时候才生效. 用户态通过系统调用陷入到内核态, 内存映射会变吗? 不会 You've got the general idea mostly right, but make this adjustment: there's only one \"kernelspace\" for the whole machine, and all processes share it. When a process is active, it can either be running in \"user mode\" or \"kernel mode\". In user mode, the instructions being executed by the CPU are in the userspace side of the memory map. The program is running its own code, or code from a userspace library. In user mode, a process has limited abilities. There is a flag in the CPU which tells it not to allow the use of privileged instructions, and kernel memory, although it exists in the process's memory map, is inaccessible. (You wouldn't want let any program just read and write the kernel's memory - all security would be gone.) When a process wants to do something other than move data around in its own (userspace) virtual memory, like open a file for example, it must make a syscall. Each CPU architecture has its own unique quirky method of making syscalls, but they all boil down to this: a magic instruction is executed, the CPU turns on the \"privileged mode\" flag, and jumps to a special address in kernelspace, the \"syscall entry point\". Now the process is running in kernel mode. Instructions being executed are located in kernel memory, and they can read and write any memory they want to. The kernel examines the request that the process just made and decides what to do with it. In the open example, the kernel receives 2 or 3 parameters corresponding to the arguments of int open(const char *filename, int flags[, int mode]). The first argument provides an example of when kernelspace needs access to userspace. You said open(\"foo\", O_RDONLY) so the string \"foo\" is part of your program in userspace. The syscall mechanism only passed a pointer, not a string, so the kernel must read the string from user memory. To find the requested file, the kernel may consult with filesystem drivers (to figure out where the file is) and block device drivers (to load the necessary blocks from disk) or network device drivers and protocols (to load the file from a remote source). All of those things are part of the kernel, i.e. in kernelspace, regardless of whether they are built-in or were loaded as modules. If the request can't be satisfied immediately, the kernel may put the process to sleep. That means the process will be taken off the CPU until a response is received from the disk or network. Another process may get a chance to run now. Later, when the response comes in, your process starts running again (still in kernel mode). Now that it's found the file, the open syscall can finish up (check the permissions, create a file descriptor) and return to userspace. Returning to userspace is a simple matter of putting the CPU back in non-privileged mode and restoring the registers to what they were before the user->kernel transition, with the instruction pointer pointing at the instruction after the magic syscall instruction. Besides syscalls, there are other things that can cause a transition from user mode to kernel mode, including: page faults - if your process accesses a virtual memory address that doesn't have a physical address assigned to it, the CPU enters kernel mode and jumps to the page fault handler. The kernel then decides whether the virtual address is valid or not, and it either creates a physical page and resumes the process in userspace where it left off, or sends a SIGSEGV. interrupts - some hardware (network, disk, serial port, etc.) notifies the CPU that it requires attention. The CPU enters kernel mode and jumps to a handler, the kernel responds to it and then resumes the userspace process that was running before the interrupt. Loading a module is done with a syscall that asks the kernel to copy the module's code and data into kernelspace and run its initialization code in kernel mode. This is pretty long, so I'm stopping. I hope the walk-through focusing on user-kernel transitions has provided enough examples to solidify the idea. uboot传mtdpart的时候，名字从哪来的？ 比如uboot会传cmdline给内核 mtdparts=octeon_nand0:0x20000000@0x0(nand);bootflash:0x20000@0x140000(statusA),0x20000@0x160000(statusB),0x140000@0x180000(bootA),0x140000@0x2c0000(bootB),0x1900000@0x400000(linuxA),0x1900000@0x1d00000(linuxB) 那么octeon_nand0和bootflash怎么来的？ 下面是内核的启动记录： [02.11] [ 30.741082] Bootbus flash: Setting flash for 64MB flash at 0x1bc00000 [02.11] [ 30.760360] bootflash: Found 1 x16 devices at 0x0 in 8-bit bank. Manufacturer ID 0x0000c2 Chip ID 0x00007e [02.11] [ 30.782739] Amd/Fujitsu Extended Query Table at 0x0040 [02.11] [ 30.800628] Amd/Fujitsu Extended Query version 1.3. [02.11] [ 30.818400] number of CFI chips: 1 [02.11] [ 30.834545] 6 cmdlinepart partitions found on MTD device bootflash [02.11] [ 30.853523] Creating 6 MTD partitions on \"bootflash\": [02.11] [ 30.871305] 0x000000140000-0x000000160000 : \"statusA\" [02.11] [ 30.889434] 0x000000160000-0x000000180000 : \"statusB\" [02.11] [ 30.907519] 0x000000180000-0x0000002c0000 : \"bootA\" [02.11] [ 30.925437] 0x0000002c0000-0x000000400000 : \"bootB\" [02.11] [ 30.943334] 0x000000400000-0x000001d00000 : \"linuxA\" [02.11] [ 30.961321] 0x000001d00000-0x000003600000 : \"linuxB\" [02.11] [ 30.979710] cvmx_nand_initialize: Setting timing parameter mode to 0 [02.11] [ 30.998826] octeon-nand 1070001000000.nand-flash-interface: NAND using BCH ecc [02.11] [ 31.018967] NAND 1 OOB size: 64, write size: 2048, erase size: 131072 [02.11] [ 31.038133] NAND device: Manufacturer ID: 0x2c, Chip ID: 0xf1 (Micron NAND 128MiB 3,3V 8-bit), 128MiB, page size: 2048, OOB size: 64 [02.11] [ 31.063631] Scanning device for bad blocks [02.11] [ 31.159228] mtd: octeon_nand0: partitioning exceeds flash size, truncating [02.11] [ 31.178825] 1 cmdlinepart partitions found on MTD device octeon_nand0 [02.11] [ 31.197990] Creating 1 MTD partitions on \"octeon_nand0\": [02.11] [ 31.216023] 0x000000000000-0x000008000000 : \"nand\" [02.11] [ 31.238898] Freeing unused kernel memory: 8952K (ffffffff80792000 - ffffffff81050000) 先说bootflash：在arch/mips/cavium-octeon/flash_setup.c中， 是cfi_flash的驱动 在它的probe函数里面，写死了名字：flash_map.name = \"bootflash\";并调用mtd_device_parse_register来解析mtd分区， 传入type cmdlinepart，意思是优先使用cmdlinepart来解析mtd分区 实际上，mtd支持两种，按顺序是\"cmdlinepart\"和\"ofpart\"这个函数里面调用：parse_mtd_partitions会根据以上两种规则创建mtd分区。 另外：uboot里面也有关于mtd的定义，估计是给uboot自己看的。 #define MTDPARTS_DEFAULT \\ \"octeon_nor0:2560k(bootloader)ro,\" \\ \"2m(kernel),\" \\ \"3520k(cramfs),\" \\ \"64k(environment)ro\\0\" #define MTDIDS_DEFAULT \"nor0=octeon_nor0\\0\" 为什么直接考过来的ls不能用？ mount debian的rootfs，从下面考了一个perl但不能直接运行，提示not found。 其实不是这个可执行文件找不到，而是它依赖的动态库不满足。本质上还是个依赖问题。 可以在编译的时候用-static来编成静态链接，这样随便考到哪里都能用了。 fork与malloc 问题: 在fork之前, 父进程malloc了内存, 比如char *p; 那么: 子进程能正常访问p吗? 内容与父进程一样吗? 子进程修改了p内存的内容, 父进程能看到吗? 子进程需要free(p)吗? 回答: #include #include #include #include #include int main(void) { char *something = malloc(256); sprintf(something, \"hello\"); pid_t child_pid = fork(); if (child_pid == 0) //child { /*子进程能够访问这个指针, 并且内容一样*/ printf(\"from child:%s\\n\", something); /*子进程修改这块内存, 但不影响父进程 C-O-W*/ sprintf(something, \"change to 11111\"); printf(\"from child:%s\\n\", something); /*虽然父子进程是独立的进程空间, 但这里指针的地址却是一样的*/ printf(\"from child:addr %p\\n\", something); /*如果不调用exec*函数, 和exit*函数, 那么确实需要在子进程也free, 所以这个例子里free应该写在最后return之前, 这样父子都都要调用*/ free(something); } else //parent { int status; while(wait(&status) != child_pid); printf(\"from parent:%s\\n\", something); printf(\"from parent:addr %p\\n\", something); free(something); } printf(\"dddddddddddddddddd\\n\"); return 0; } 运行结果 $ gcc test_fork_malloc.c ASBLX28:/home/yingjieb/tmp $ ./a.out from child:hello from child:change to 11111 from child:addr 0x84ec010 dddddddddddddddddd from parent:hello from parent:addr 0x84ec010 dddddddddddddddddd "},"notes/system_alpine.html":{"url":"notes/system_alpine.html","title":"Alpine Linux","keywords":"","body":" 现代化的工程系统 使用subgroup来组织repo 组织清爽, 源代码干净 aports bootstrap.sh 现代化的工程系统 alpine linux的全部开发都在 https://gitlab.alpinelinux.org/alpine 自己搭建的gitlab服务器, 允许外部用户注册, fork库, 并提交MR 使用gitlab-ci的CI/CD做build test 用gitlab issue来跟踪bug 文档也是repo管理, 使用Antora Playbook发布, 网页入口是 https://alpinelinux.org/ 使用subgroup来组织repo 比如CI/CD工具库在alpine/infra/docker/alpine-gitlab-ci下面, 先是根alpine, 再是infra, 再是docker, 最后是repo 组织清爽, 源代码干净 比如alpine-gitlab-ci/-/blob/master/overlay/usr/local/bin/build.sh里面的shell 输出代码: : \"${CI_ALPINE_BUILD_OFFSET:=0}\" : \"${CI_ALPINE_BUILD_LIMIT:=9999}\" msg() { local color=${2:-green} case \"$color\" in red) color=\"31\";; green) color=\"32\";; yellow) color=\"33\";; blue) color=\"34\";; *) color=\"32\";; esac printf \"\\033[1;%sm>>>\\033[1;0m %s\\n\" \"$color\" \"$1\" | xargs >&2 } verbose() { echo \"> \" \"$@\" # shellcheck disable=SC2068 $@ } debugging() { [ -n \"$CI_DEBUG_BUILD\" ] } debug() { if debugging; then verbose \"$@\" fi } die() { msg \"$1\" red exit 1 } capture_stderr() { \"$@\" 2>&1 } report() { report=$1 reportsdir=$APORTSDIR/logs/ mkdir -p \"$reportsdir\" tee -a \"$reportsdir/$report.log\" } aports alpine支持的package都放在aports这个库下面. main: alpine core team直接支持的package community: 由社区支持的package 参考: https://wiki.alpinelinux.org/wiki/Repositories /etc/apk/repositories是package的配置 / # cat /etc/apk/repositories https://dl-cdn.alpinelinux.org/alpine/v3.15/main https://dl-cdn.alpinelinux.org/alpine/v3.15/community 比如https://dl-cdn.alpinelinux.org/alpine/v3.15/main目录下包括了所有arch的预编译好的apk点进去看这些apk的修改时间是不一样的, 说明apk是按需编译的. bootstrap.sh 似乎可以用它来生成交叉编译的工具链 "},"notes/system_进程间通信.html":{"url":"notes/system_进程间通信.html","title":"进程间通信","keywords":"","body":" ipcs查看进程间通信的情况, 包括消息队列, 共享内存, semaphore 进程间通信类型 signal 匿名管道 有名管道和FIFO 消息队列 共享内存 信号量 futex Unix domain socket Netlink socket Network socket Inotify机制 FUSE文件系统 D-BUS 参考: http://www.chandrashekar.info/articles/linux-system-programming/introduction-to-linux-ipc-mechanims.html https://tldp.org/LDP/tlk/ipc/ipc.html#:~:text=1%20System%20V%20IPC%20Mechanisms,all%20share%20common%20authentication%20methods. ipcs查看进程间通信的情况, 包括消息队列, 共享内存, semaphore Linux Mint 19 Tara $ ipcs ------ Message Queues -------- key msqid owner perms used-bytes messages ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status 0x00000000 65536 bai 600 524288 2 dest 0x00000000 163841 bai 600 33554432 2 dest 0x00000000 196610 bai 600 33554432 2 dest 0x00000000 294915 bai 600 524288 2 dest 0x00000000 393220 bai 600 524288 2 dest 0x00000000 491525 bai 600 4194304 2 dest 0x00000000 524294 bai 777 2006712 2 0x00000000 622599 bai 777 3035136 2 0x00000000 655368 bai 600 4194304 2 dest 0x00000000 753673 bai 600 524288 2 dest 0x00000000 786442 bai 600 1048576 2 dest 0x00000000 884747 bai 600 524288 2 dest 0x00000000 917516 bai 777 2304 2 0x00000000 950285 bai 600 33554432 2 dest ------ Semaphore Arrays -------- key semid owner perms nsems 进程间通信类型 signal overhead最小, 用来通知进程关于内核和其他进程状态的改变 内核打断进程正常的流程, 调用其注册的handler或者默认的handler Signals are the cheapest forms of IPC provided by Linux. Their primary use is to notify processes of change in states or events that occur within the kernel or other processes. We use signals in real world to convey messages with least overhead - think of hand and body gestures. For example, in a crowded gathering, we raise a hand to gain attention, wave hand at a friend to greet and so on. On Linux, the kernel notifies a process when an event or state change occurs by interrupting the process's normal flow of execution and invoking one of the signal handler functinos registered by the process or by the invoking one of the default signal dispositions supplied by the kernel, for the said event. 匿名管道 生成两个描述符分别用于读和写 用于父子进程, 父进程创建管道, 在folk的时候, 这个管道被dup进子进程的空间 Anonymous pipes (or simply pipes, for short) provide a mechanism for one process to stream data to another. A pipe has two ends associated with a pair of file descriptors - making it a one-to-one messaging or communication mechanism. One end of the pipe is the read-end which is associated with a file-descriptor that can only be read, and the other end is the write-end which is associated with a file descriptor that can only be written. This design means that pipes are essentially half-duplex. Anonymous pipes can be setup and used only between processes that share parent-child relationship. Generally the parent process creates a pipe and then forks child processes. Each child process gets access to the pipe created by the parent process via the file descriptors that get duplicated into their address space. This allows the parent to communicate with its children, or the children to communicate with each other using the shared pipe. Pipes are generally used to implement Producer-Consumer design amongst processes - where one or more processes would produce data and stream them on one end of the pipe, while other processes would consume the data stream from the other end of the pipe. 有名管道和FIFO 在两个独立的进程间, 打开一个特定的FIFO文件来通信 Named pipes (or FIFO) are variants of pipe that allow communication between processes that are not related to each other. The processes communicate using named pipes by opening a special file known as a FIFO file. One process opens the FIFO file from writing while the other process opens the same file for reading. Thus any data written by the former process gets streamed through a pipe to the latter process. The FIFO file on disk acts as the contract between the two processes that wish to communicate. 消息队列 类似于邮箱, 一个进程写消息然后退出, 另一个进程可以从同一个消息队列里读消息 通信双方不需要建立连接, 而作为对比, pipe是需要先建立连接的. 支持多对多 Message queues allow one or more processes to write messages, which will be read by one or more reading processes linux支持两种消息队列 system V: 带message号 posix: 带message优先级 man mq_overview mq_open mq_send mq_receive等函数都是系统调用 Message Queues are synonymous to mailboxes. One process writes a message packet on the message queue and exits. Another process can access the message packet from the same message queue at a latter point in time. The advantage of message queues over pipes/FIFOs are that the sender (or writer) processes do not have to wait for the receiver (or reader) processes to connect. Think of communication using pipes as similar to two people communicating over phone, while message queues are similar to two people communicating using mail or other messaging services. There are two standard specifications for message queues. SysV message queues. The AT&T SysV message queues support message channeling. Each message packet sent by senders carry a message number. The receivers can either choose to receive message that match a particular message number, or receive all other messages excluding a particular message number or all messages. POSIX message queues. The POSIX message queues support message priorities. Each message packet sent by the senders carry a priority number along with the message payload. The messages get ordered based on the priority number in the message queue. When the receiver tries to read a message at a later point in time, the messages with higher priority numbers get delivered first. POSIX message queues also support asynchronous message delivery using threads or signal based notification. 共享内存 一个进程把自己进程空间的一部分共享给另一个. 有两种类型: sysv: 比较古老 posix: 现代的, 使用ram文件系统的文件 As the name implies, this IPC mechanism allows one process to share a region of memory in its address space with another. This allows two or more processes to communicate data more efficiently amongst themselves with minimal kernel intervention. There are two standard specifications for Shared memory. SysV Shared memory. Many applications even today use this mechanism for historical reasons. It follows some of the artifacts of SysV IPC semantics. POSIX Shared memory. The POSIX specifications provide a more elegant approach towards implementing shared memory interface. On Linux, POSIX Shared memory is actually implemented by using files backed by RAM-based filesystem. I recommend using this mechanism over the SysV semantics due to a more elegant file based semantics. 信号量 Semaphores are locking and synchronization mechanism used most widely when processes share resources. Linux supports both SysV semaphores and POSIX semaphores. POSIX semaphores provide a more simpler and elegant implementation and thus is most widely used when compared to SysV semaphores on Linux. futex linux系统调用 Futexes are high-performance low-overhead locking mechanisms provided by the kernel. Direct use of futexes is highly discouraged in system programs. Futexes are used internally by POSIX threading API for condition variables and its mutex implementations. Unix domain socket C-S架构, 全双工, 支持stream和datagram方式 大型软件用的很多 UNIX Domain Sockets provide a mechanism for implementing applications that communicate using the Client-Server architecture. They support both stream and datagram oriented communication, are full-duplex and support a variety of options. They are very widely used for developing many large-scale frameworks. Netlink socket 和socket接口一样, 但主要用于: 内核线程和用户进程通信 用户控件的进程间的广播通信 Netlink sockets are similar to UNIX Domain Sockets in its API semantics - but used mainly for two purposes: For communication between a process in user-space to a thread in kernel-space For communication amongst processes in user-space using broadcast mode. Network socket 网络socket Based on the same API semantics like UNIX Domain Sockets, Network Sockets API provide mechanisms for communication between processes that run on different hosts on a network. Linux has rich support for features and various protocol stacks for using network sockets API. For all kinds of network programming and distributed programming - network socket APIs form the core interface. Inotify机制 监控文件系统改变的, 可以和poll select等联用. inotify是Linux内核2.6.13 (June 18, 2005)版本新增的一个子系统（API），它提供了一种监控文件系统（基于inode的）事件的机制，可以监控文件系统的变化如文件修改、新增、删除等，并可以将相应的事件通知给应用程序。该机制由著名的桌面搜索引擎项目beagle引入用于替代此前具有类似功能但存在诸多缺陷的dnotify。 The Inotify API on Linux provides a method for processes to know of any changes on a monitored file or a directory asynchronously. By adding a file to inotify watch-list, a process will be notified by the kernel on any changes to the file like open, read, write, changes to file stat, deleting a file and so on. FUSE文件系统 FUSE provides a method to implement a fully functional filesystem in user-space. Various operations on the mounted FUSE filesystem would trigger functions registered by the user-space filesystem handler process. This technique can also be used as an IPC mechanism to implement Client-Server architecture without using socket API semantics. D-BUS 桌面系统用的多, 是建立在socket API基础上的多进程通信的系统 D-Bus is a high-level IPC mechanism built generally on top of socket API that provides a mechanism for multiple processes to communicate with each other using various messaging patterns. D-Bus is a standards specification for processes communicating with each other and very widely used today by GUI implementations on Linux following Freedesktop.org specifications. "},"notes/system_特殊功能fd.html":{"url":"notes/system_特殊功能fd.html","title":"特殊功能fd","keywords":"","body":"除了普通文件fd, socket fd, Linux还提供了比较特殊的几种fd, 比如eventfd timerfd signalfd等等. signalfd timerfd timerfd API 注epoll使用简介 边沿触发和电平触发 epoll_wait eventfd概念 用法 进程间共享文件描述符 各种fd是系统调用 用perf看所有带fd的系统调用 perf list | grep syscalls | grep fd | grep enter root@godev-server:/home/yingjieb# perf list | grep syscalls | grep fd | grep enter syscalls:sys_enter_eventfd [Tracepoint event] syscalls:sys_enter_eventfd2 [Tracepoint event] syscalls:sys_enter_fdatasync [Tracepoint event] syscalls:sys_enter_gettimeofday [Tracepoint event] syscalls:sys_enter_memfd_create [Tracepoint event] syscalls:sys_enter_settimeofday [Tracepoint event] syscalls:sys_enter_signalfd [Tracepoint event] syscalls:sys_enter_signalfd4 [Tracepoint event] syscalls:sys_enter_timerfd_create [Tracepoint event] syscalls:sys_enter_timerfd_gettime [Tracepoint event] syscalls:sys_enter_timerfd_settime [Tracepoint event] syscalls:sys_enter_userfaultfd [Tracepoint event] 下面就介绍一下这些fd的使用. signalfd #include #include #include #include #include #define handle_error(msg) \\ do { perror(msg); exit(EXIT_FAILURE); } while (0) int main(int argc, char *argv[]) { sigset_t mask; int sfd; struct signalfd_siginfo fdsi; ssize_t s; sigemptyset(&mask); sigaddset(&mask, SIGINT); sigaddset(&mask, SIGQUIT); /* 阻塞信号以使得它们不被默认的处理试方式处理 */ if (sigprocmask(SIG_BLOCK, &mask, NULL) == -1) handle_error(\"sigprocmask\"); sfd = signalfd(-1, &mask, 0); if (sfd == -1) handle_error(\"signalfd\"); for (;;) { s = read(sfd, &fdsi, sizeof(struct signalfd_siginfo)); if (s != sizeof(struct signalfd_siginfo)) handle_error(\"read\"); if (fdsi.ssi_signo == SIGINT) { printf(\"Got SIGINT\\n\"); } else if (fdsi.ssi_signo == SIGQUIT) { printf(\"Got SIGQUIT\\n\"); exit(EXIT_SUCCESS); } else { printf(\"Read unexpected signal\\n\"); } } } 这个例子只是很简单的说明了使用signalfd的方法，并没有真正发挥它的作用，有了这个API，就可以将信号处理作为IO看待.每一个信号集合（或者某一个对应的信号）就会有对应的文件描述符，这样将信号处理的流程大大简化，将应用程序中的业务作为文件来操作，也体现了linux下的一切皆文件的说法，非常好，假如有很多种信号等待着处理，每一个信号描述符对待一种信号的处理，那么就可以将信号文件描述符设置为非阻塞，同时结合epoll使用，对信号的处理转化为IO复用，和这个有相似之处的API还有timerfd timerfd 使用timerfd的一个例子是libevent. 在linux下面, 默认的libevent使用epoll, epoll有个超时时间.libevent利用这个超时时间来做定时器的触发源, 即在event loop里面, 把定时器堆的时间做为超时时间.更具体一些, 在libevent初始化时:默认情况下, libevent不使用timerfd, epollop->timerfd = -1.但有EVENT_BASE_FLAG_PRECISE_TIMER情况下, if ((base->flags & EVENT_BASE_FLAG_PRECISE_TIMER) && base->monotonic_timer.monotonic_clock == CLOCK_MONOTONIC) { int fd; fd = epollop->timerfd = timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK|TFD_CLOEXEC); if (epollop->timerfd >= 0) { struct epoll_event epev; memset(&epev, 0, sizeof(epev)); epev.data.fd = epollop->timerfd; epev.events = EPOLLIN; //把这个fd加入epoll epoll_ctl(epollop->epfd, EPOLL_CTL_ADD, fd, &epev) 参考: https://blog.csdn.net/KangRoger/article/details/47844443 所以这里的timerfd_create()就是timerfd的使用方法. timerfd API #include int timerfd_create(int clockid, int flags); //这个时间精度应该比ms高. int timerfd_settime(int fd, int flags, const struct itimerspec *new_value, struct itimerspec *old_value); int timerfd_gettime(int fd, struct itimerspec *curr_value); read系统调用会返回超时次数, 如果一次超时都没到, read阻塞. timerfd_create用于创建一个定时器文件，函数返回值是一个文件句柄fd。 timerfd_settime用于设置新的超时时间，并开始计时。flag为0表示相对时间，为1表示绝对时间。new_value为这次设置的新时间，old_value为上次设置的时间。返回0表示设置成功。 timerfd_gettime用于获得定时器距离下次超时还剩下的时间。如果调用时定时器已经到期，并且该定时器处于循环模式（设置超时时间时struct itimerspec::it_interval不为0），那么调用此函数之后定时器重新开始计时。 注epoll使用简介 man epoll可以看到, epoll的API有 epoll_create() : 用于创建epoll对象 epoll_ctl() : 用于管理fd set epoll_wait() : 用于等待IO 边沿触发和电平触发 epoll有类似硬件的触发概念 edge-triggered (ET): 边沿触发, 只有fd的状态有变化才触发. 例如epoll_wait返回一个fd可读, 它实际有2k的数据可以读, 但回调函数里只读了1k. 即使还有1k数据可读, 在ET触发模式下, epoll不会再触发fd可读. 用ET触发的推荐场景是: 这个fd是非阻塞的 并且read或者write返回EAGAIN level-triggered (LT): 电平触发, 这是默认触发方式 epoll_wait #include int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 这里的timeout单位是ms, 是用CLOCK_MONOTONIC度量的. epoll_wait返回有几种可能: 底层driver有数据, event到达 超时, -1表示永久等待. 0表示立即返回 被signal eventfd概念 eventfd()是个系统调用, 生成一个event fd对象, 内核为其维护一个计数器, 用来做用户进程间的wait/nofify机制, 也可以被kernel用来通知用户态进程. 可以用来代替pipe(), 相比于pipe来说，少用了一个文件描述符，而且不必管理缓冲区，单纯的事件通知的话，方便很多在fork()的时候, 子进程继承eventfd, 对应同一个eventfd对象, 并且, 这个fd在execve()后仍然保持, 但如果有close-on-exec选项则不保持. 创建eventfd以后, 可以子进程写, 父进程读; 读的时候, 只要计数器非0, 就返回计数器值, 并reset到0; 计数器为0则block 计数器不溢出就可以写, 写的值加到计数器上. 溢出的话会阻塞. 也可以配合poll(), select()使用 用法 #include int eventfd(unsigned int initval, int flags); read() write() close() //glibc还提供: typedef uint64_t eventfd_t; int eventfd_read(int fd, eventfd_t *value); int eventfd_write(int fd, eventfd_t value); 进程间共享文件描述符 在 OVS架构和代码中, qemu通过unix socket传递eventfd的文件描述符给OVS, 实际上是用了socket的SCM_RIGHTS方法. 实际上, 也可以用pipe之类的进程间通信为载体, 其底层是通过ioctl的I_SENDFD和I_RECVFD完成的. 详见 http://poincare.matf.bg.ac.rs/~ivana/courses/ps/sistemi_knjige/pomocno/apue/APUE/0201433079/ch17lev1sec4.html 出自Advanced Programming in the UNIX® Environment: Second Edition 2005看来这技术有十几年的时间了发送进程: #include \"apue.h\" #include /* * Pass a file descriptor to another process. * If fd= 0) if (ioctl(fd, I_SENDFD, fd_to_send) 接收进程: //接收时, 第三个参数是strrecvfd 结构体 struct strrecvfd { int fd; /* new descriptor */ uid_t uid; /* effective user ID of sender */ gid_t gid; /* effective group ID of sender */ char fill[8]; }; #include \"apue.h\" #include /* * Receive a file descriptor from another process (a server). * In addition, any data received from the server is passed * to (*userfunc)(STDERR_FILENO, buf, nbytes). We have a * 2-byte protocol for receiving the fd from send_fd(). */ int recv_fd(int fd, ssize_t (*userfunc)(int, const void *, size_t)) { int newfd, nread, flag, status; char *ptr; char buf[MAXLINE]; struct strbuf dat; struct strrecvfd recvfd; status = -1; for ( ; ; ) { dat.buf = buf; dat.maxlen = MAXLINE; flag = 0; if (getmsg(fd, NULL, &dat, &flag) 0) if ((*userfunc)(STDERR_FILENO, buf, nread) != nread) return(-1); if (status >= 0) /* final data has arrived */ return(newfd); /* descriptor, or -status */ } } 下面的例子说明, 两个进程想要传递fd, 要先有个通道, 比如pipe, 或者socket, 用来传递fd. #include #include #include #include #include #define TESTFILE \"/dev/null\" main(int argc, char *argv[]) { int fd; int pipefd[2]; struct stat statbuf; stat(TESTFILE, &statbuf); statout(TESTFILE, &statbuf); pipe(pipefd); if (fork() == 0) { close(pipefd[0]); sendfd(pipefd[1]); } else { close(pipefd[1]) recvfd(pipefd[0]); } } sendfd(int p) { int tfd; tfd = open(TESTFILE, O_RDWR); ioctl(p, I_SENDFD, tfd); } recvfd(int p) { struct strrecvfd rfdbuf; struct stat statbuf; char fdbuf[32]; ioctl(p, I_RECVFD, &rfdbuf); fstat(rfdbuf.fd, &statbuf); sprintf(fdbuf, \"recvfd=%d\", rfdbuf.fd); statout(fdbuf, &statbuf); } statout(char *f, struct stat *s) { printf(\"stat: from=%s mode=0%o, ino=%ld, dev=%lx, rdev=%lx\\n\", f, s->st_mode, s->st_ino, s->st_dev, s->st_rdev); fflush(stdout); } "},"notes/gitlab_ci.html":{"url":"notes/gitlab_ci.html","title":"gitlab CI","keywords":"","body":" 安装和注册gitlab runner runner介绍 Group runner Set up a group Runner manually 前置条件:安装docker 安装runner 注册runner runner使用和.gitlab-ci.yml runner管理 image和services docker runner和shell runner job和script 全局配置 stages和workflow include其他yml 可配参数参考 预定义的变量 How to do continuous integration like a boss touble shooting 解决docker内git clone/下载失败问题 merge request gitlab支持pipeline, 官方详细参考, 很全, 很细节 docker方式参考, 实用 快速入门 安装和注册gitlab runner runner介绍 gitlab runner简介是用来执行工程根目录下的.gitlab-ci.yml. 有三种类型的runner Shared (for all projects) Group (for all projects in a group) Specific (for specific projects) 不同的job由不同的runner执行 这里我们实用Group runner Group runner group的admin可以创建group runner. 到gitlab Settings页面 CI/CD下面的Runner配置页面, 找下面的信息 比如这个是https://gitlabe1.ext.net.nokia.com/groups/godevsig 的group runner信息 Set up a group Runner manually Install GitLab Runner Specify the following URL during the Runner setup: https://gitlabe1.ext.net.nokia.com/ Use the following registration token during setup: Aprw1hQ6nuxyra5dzVwQ Start the Runner! 前置条件:安装docker docker安装官方参考 安装完毕后, 如果显示docker ps socket权限问题, 则需要把用户加入到docker组, 特别的, 这里要把gitlab-runner加进去 sudo usermod -a -G docker gitlab-runner 安装runner 增加gitlab源 # For Debian/Ubuntu/Mint curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash # For RHEL/CentOS/Fedora curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash 安装 # For Debian/Ubuntu/Mint export GITLAB_RUNNER_DISABLE_SKEL=true; sudo -E apt-get install gitlab-runner # For RHEL/CentOS/Fedora export GITLAB_RUNNER_DISABLE_SKEL=true; sudo -E yum install gitlab-runner 注册runner 根据上面工程的信息, 注册runner sudo gitlab-runner register \\ --url \"https://gitlabe1.ext.net.nokia.com/\" \\ --description \"docker-godevsig\" \\ --registration-token \"Aprw1hQ6nuxyra5dzVwQ\" \\ --executor \"docker\" \\ --tag-list \"docker-generic\" \\ --docker-image alpine:latest 在ubuntu上, 看runner服务的状态 yingjieb@cloud-server-1:~$ systemctl status gitlab-runner ● gitlab-runner.service - GitLab Runner Loaded: loaded (/etc/systemd/system/gitlab-runner.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2020-09-19 16:11:41 UTC; 2 days ago Main PID: 1944 (gitlab-runner) Tasks: 35 (limit: 4915) CGroup: /system.slice/gitlab-runner.service └─1944 /usr/bin/gitlab-runner run --working-directory /home/gitlab-runner --config /etc/gitlab-runner/config.toml --service gitlab-runner --syslog --user gitlab-runner 工作目录是/home/gitlab-runner config文件/etc/gitlab-runner/config.toml 使用gitlab-runner用户 runner使用和.gitlab-ci.yml runner管理 yingjieb@cloud-server-1:~$ gitlab-runner -h 支持很多命令 start stop restart status register unregister install uninstall 等等 image和services image: 可以放在default里面, 表示runner的基础docker镜像 services: 也是docker镜像, 是给image提供服务的镜像 service的玩法是启动一个service镜像, 可以指定镜像, 可以修改镜像的entrypoint, 可以改默认 docker runner和shell runner runner可以run在docker里面, 也可以是实际host的shell docker runner使用说明 shell runner使用说明 job和script job是runner的基础执行单元, job之间是并行执行的. job是用户定义的, 但不能是保留字 job的script是必须的, 可以有其他可选配置 官方例子for go: image: golang:latest variables: # Please edit to your GitLab project REPO_NAME: gitlab.com/namespace/project # The problem is that to be able to use go get, one needs to put # the repository in the $GOPATH. So for example if your gitlab domain # is gitlab.com, and that your repository is namespace/project, and # the default GOPATH being /go, then you'd need to have your # repository in /go/src/gitlab.com/namespace/project # Thus, making a symbolic link corrects this. before_script: - mkdir -p $GOPATH/src/$(dirname $REPO_NAME) - ln -svf $CI_PROJECT_DIR $GOPATH/src/$REPO_NAME - cd $GOPATH/src/$REPO_NAME stages: - test - build - deploy format: stage: test script: - go fmt $(go list ./... | grep -v /vendor/) - go vet $(go list ./... | grep -v /vendor/) - go test -race $(go list ./... | grep -v /vendor/) compile: stage: build script: - go build -race -ldflags \"-extldflags '-static'\" -o $CI_PROJECT_DIR/mybinary artifacts: paths: - mybinary 全局配置 有几个配置可以配成全局的 stages和workflow stages是顺序执行的 stages: - build - test - deploy workflow是全局的执行条件, 是条件规则集合, 规则依次匹配 workflow: rules: - if: '$CI_PIPELINE_SOURCE == \"schedule\"' when: never - if: '$CI_PIPELINE_SOURCE == \"push\"' when: never - when: always This example never allows pipelines for schedules or push (branches and tags) pipelines, but does allow pipelines in all other cases, including merge request pipelines. workflow有官方模板可以参考 include其他yml 有4种include类型 Method Description local Include a file from the local project repository. file Include a file from a different project repository. remote Include a file from a remote URL. Must be publicly accessible. template Include templates that are provided by GitLab. 可配参数参考 Parameter details 预定义的变量 有些变量是预定义的 比如 CI_PROJECT_DIR CI_BUILDS_DIR CI_PIPELINE_SOURCE CI_COMMIT_TAG CI_COMMIT_BRANCH 其中几个在if条件里挺有用: Example rules Details if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"' Control when merge request pipelines run. if: '$CI_PIPELINE_SOURCE == \"push\"' Control when both branch pipelines and tag pipelines run. if: $CI_COMMIT_TAG Control when tag pipelines run. if: $CI_COMMIT_BRANCH Control when branch pipelines run. How to do continuous integration like a boss 参考gitlab本身的ci配置 和这篇攻略 touble shooting 解决docker内git clone/下载失败问题 原因是docker内的mtu设置比host大. 修改方法如下 增加docker的配置文件, 指定mtu yingjieb@cloud-server-1:~$ cat /etc/docker/daemon.json { \"mtu\": 1400 } 然后重启docker daemon sudo systemctl restart docker merge request 一个forked repo的developer给parent发出merge request, 会在forked repo下面执行gitlab ci的. 过程如下 Fork a parent project. Create a merge request from the forked project that targets the master branch in the parent project. A pipeline runs on the merge request. A maintainer from the parent project checks the pipeline result, and merge into a target branch if the latest pipeline has passed. Currently, those pipelines are created in a forked project, not in the parent project. This means you cannot completely trust the pipeline result, because, technically, external contributors can disguise their pipeline results by tweaking their GitLab Runner in the forked project. There are multiple reasons why GitLab doesn’t allow those pipelines to be created in the parent project, but one of the biggest reasons is security concern. External users could steal secret variables from the parent project by modifying .gitlab-ci.yml, which could be some sort of credentials. This should not happen. 目前的状态是, forked repo发出的merge request不能在parent执行. 有个proposal解决这个问题: Allow fork pipelines to run in parent project 但现在的版本12.7.6还没有这个功能. "}}